@&#MAIN-TITLE@&#An on-line, real-time learning method for detecting anomalies in videos using spatio-temporal compositions

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A fast and accurate algorithm for anomalous event detection in videos.


                        
                        
                           
                           Densely sampling video to construct spatio-temporal video volumes.


                        
                        
                           
                           Handling uncertainties in codebook construction.


                        
                        
                           
                           Coding spatio-temporal composition of volumes by a probabilistic framework.


                        
                        
                           
                           Unsupervised and continuously learning new events.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Video surveillance

On-line anomaly detection

Suspicious event detection

Spatio-temporal video volumes

Spatio-temporal compositions

@&#ABSTRACT@&#


               
               
                  This paper presents an approach for detecting suspicious events in videos by using only the video itself as the training samples for valid behaviors. These salient events are obtained in real-time by detecting anomalous spatio-temporal regions in a densely sampled video. The method codes a video as a compact set of spatio-temporal volumes, while considering the uncertainty in the codebook construction. The spatio-temporal compositions of video volumes are modeled using a probabilistic framework, which calculates their likelihood of being normal in the video. This approach can be considered as an extension of the Bag of Video words (BOV) approaches, which represent a video as an order-less distribution of video volumes. The proposed method imposes spatial and temporal constraints on the video volumes so that an inference mechanism can estimate the probability density functions of their arrangements. Anomalous events are assumed to be video arrangements with very low frequency of occurrence. The algorithm is very fast and does not employ background subtraction, motion estimation or tracking. It is also robust to spatial and temporal scale changes, as well as some deformations. Experiments were performed on four video datasets of abnormal activities in both crowded and non-crowded scenes and under difficult illumination conditions. The proposed method outperformed all other approaches based on BOV that do not account for contextual information.
               
            

@&#INTRODUCTION@&#

In recent years video surveillance systems have become very popular due to heightened security concerns and low-hardware costs. They are widely used in many applications such as nursing care institutions, law enforcement, building security, and traffic analysis. Moreover, in most circumstances, it is necessary for humans to analyze the videos, which is inefficient in terms of accuracy and cost [1,2]. In light of this, together with the tremendous number of such videos produced on a daily basis, there is a great need for a real-time automated system that detects and locates suspicious behaviors and alerts security agents.

Consequently, detecting unusual or suspicious activities, uncommon behaviors, or irregular events in a scene is the primary objective of an automated video surveillance system. We refer to this activity as anomaly detection because the sought-after situations are not observed frequently. Although the term anomaly cannot be defined explicitly, all such systems are based on the implicit assumption that events that occur occasionally are potentially suspicious, and thus may be considered as being anomalous [3–12]. Therefore, the working definition of this term in this paper is taken to be the spatio-temporal compositions in a video or set of videos with low probability of occurrence with respect to the previous observations. This implies that the anomalies are spatial, temporal, or spatio-temporal outliers that are different from the regularly observed patterns. We define the anomalies with respect to a context, meaning that a particular activity in a particular context would be an anomaly, while in another context it might be normal [11].

A real-time video surveillance system can be considered to be a form of saliency detector, concerned with focusing attention on anomalies by localizing them in space and time. It is preferable to locate these as actual suspicious regions in each frame of the video, rather than just simply selecting the whole frame. Such precise localization makes it possible to attend to suspicious regions by either automated systems or human operators [5].

The detection of anomalies in a video is an active research area that has been addressed for both crowded and non-crowded scenes [10,13,14,4–7,15,3,11,8]. In the literature, detection has been achieved either by explicitly determining normal (or abnormal) behaviors (called rule-based) in the early work [16–18], or by statistically learning behaviors (lacking predefined rules) [3–5,19–22,15]. The latter is more promising due to its flexibility for describing observed data and generalization capabilities and is the one adopted here.

Most of the reported approaches are based on the trajectory analysis of the objects, which requires precise tracking methods [23–26,21,27,15,14]. Nevertheless, this still remains a significant challenge to computer vision, particularly in complex situations [28]. In general, a moving object is considered to be an amorphous blob that is tracked, thereby producing a trajectory. Any major deviation from the learnt trajectories is considered to be an anomaly. Tracking-based approaches are suitable for scenes with few objects but are impractical for detecting abnormal patterns in a crowded or complex scene. An additional issue is that human behavior analysis also requires a knowledge of what occurs within a blob.

Non-tracking approaches that focus on local spatio-temporal anomalies in videos also exist. These rely mainly on extracting and analyzing local low-level visual features, such as motion and texture, either by constructing a pixel-level background model and behavior template [29–32] or by employing spatio-temporal video volumes (dense sampling or interest point selection) [4,33–37,20,38–41,10,42,43]. In large part, the former relies on an analysis of the activity pattern (busy-idle rates) of each pixel in each frame as a function of time. These are employed to construct a background model, either by analyzing simple color features at each pixel [29] or more complex motion descriptors [30,32]. More advanced approaches also incorporate the spatio-temporal compositions of the motion-informative regions to build background and behavior templates [31,44,43] that are subtracted from newly observed behaviors in order to detect an anomaly. In [8], dynamic behaviors are modeled using spatio-temporal oriented energy filters to construct an activity pattern for each pixel in a video frame. Generally, the main drawback associated with these methods is their locality. Since the activity pattern of a pixel cannot be used for behavioral understanding, their applicability in surveillance systems is restricted to the detection of local temporal phenomena [8,30].

One representative approach to spatio-temporal anomaly detection is to use local spatio-temporal video volumes in the context of Bag of Video words (BOV) models. However, the relationships between the volumes are often ignored, even though they are crucial for anomaly detection. In fact, there is also psychological support suggesting that contextual information (spatio-temporal relationships between different objects and their surroundings) is necessary for scene understanding in human perception [45,46]. In general, in the literature, spatial and temporal information about the distribution of video volumes is only exploited implicitly, locally, and at a fixed temporal scale, which is inadequate for accurate event recognition [5,47,19,48,38,22,40,49]. Another drawback of all BOV approaches that employ clustering methods to group similar video volumes to reduce the search space is their finality. Once a video-volume has been assigned to an incorrect video word, there is no way to correct this error. In other words, they are unable to deal with uncertainty in the visual word assignment. Moreover, real-time performance is usually not possible. Another important issue in the current literature relates to the popularity of the use of supervised [23,50–52,16] or offline learning methods [4,50,5,6], which are wholly dependent on large numbers of training data. Clearly, in the case of anomaly detection in videos, it is necessary to incrementally update the learned model for both normal and abnormal events [3,10,11,53,54].

Thus the question arises as to how a set of new observations can be classified as being either normal or abnormal? Perhaps this is the most difficult challenge to this research. Among the proposed solutions in the literature, we believe that the most promising and reliable answer to this question should simultaneously determine both normal and abnormal compositions. The only difference between these is that the likelihood of the latter will be much smaller than that of the former. In light of this definition, it is possible to accomplish this task by considering the problem as one of reconstruction, as was done in [4]. Consequently, having a few video samples of a normal event (“training set”), a new normal observation would have high likelihood, while an abnormal event would have low likelihood. In the former case, video compositions should be capable of being reconstructed by finding similar regions to those already found in these videos.

In this paper, we present a fast online unsupervised method for anomaly detection in videos, based on spatio-temporal video volume construction, while using both local and global compositional information regarding the volumes. This is achieved using dense sampling at various spatial and temporal scales and is related to the method presented by Boiman and Irani [4]. These authors used a reconstruction framework for anomaly detection, in which an observation is considered to be anomalous if it cannot be reconstructed using previous observations.

By formulating anomaly detection as a reconstruction process, anomaly detection is reduced to being defined as an outlier detection problem, i.e., finding the events that are not similar enough to the previously observed events in the video. Therefore, given a video sequence, V, containing a set of events 
                        
                           V
                           =
                           
                              
                                 {
                                 
                                    
                                       e
                                    
                                    
                                       i
                                    
                                 
                                 }
                              
                              
                                 i
                                 =
                                 1
                              
                              
                                 N
                              
                           
                        
                      and a similarity measure S, the concept of an anomaly is defined for a particular event e
                     
                        q
                     , as follows:
                        
                           (1)
                           
                              
                                 
                                    
                                    
                                       
                                          
                                             
                                                e
                                             
                                             
                                                q
                                             
                                          
                                          ∈
                                          V
                                       
                                    
                                 
                                 
                                    
                                    
                                       
                                          
                                             
                                                s
                                             
                                             
                                                q
                                                ,
                                                i
                                             
                                          
                                          =
                                          S
                                          (
                                          
                                             
                                                e
                                             
                                             
                                                q
                                             
                                          
                                          ,
                                          
                                             
                                                e
                                             
                                             
                                                i
                                             
                                          
                                          )
                                          ,
                                          
                                          
                                             
                                                e
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          V
                                          -
                                          {
                                          
                                             
                                                e
                                             
                                             
                                                q
                                             
                                          
                                          }
                                       
                                    
                                 
                                 
                                    
                                    
                                       
                                          
                                             
                                                e
                                             
                                             
                                                q
                                             
                                          
                                          
                                          is
                                          
                                          anomaly
                                          
                                          iff
                                          
                                          ∀
                                          i
                                          ,
                                          
                                          
                                             
                                                s
                                             
                                             
                                                q
                                                ,
                                                i
                                             
                                          
                                          ⩽
                                          γ
                                       
                                    
                                 
                              
                           
                        
                     where γ is a threshold. This implies that the event e
                     
                        q
                      is not similar enough to any of the observed events. Similar to [4], in our approach, each event e
                     
                        i
                      consists of a set of spatio-temporal video volumes, p
                     
                        k
                     , defined for all pixels inside a much larger contextual region around each pixel. Such a set is called an ensemble of volumes around the particular pixel in the video. The ensemble of volumes 
                        
                           
                              
                                 E
                              
                              
                                 i
                              
                           
                        
                      is defined at each point (x
                     
                        i
                     , y
                     
                        i
                     , t
                     
                        i
                     ) in the video (where (x
                     
                        i
                     , y
                     
                        i
                     ) refers to the spatial position in the frame and t
                     
                        i
                      to the temporal location in the video):
                        
                           (2)
                           
                              
                                 
                                    e
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                p
                                             
                                             
                                                k
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 
                                    K
                                 
                              
                              
                              ≜
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                p
                                             
                                             
                                                k
                                             
                                          
                                          :
                                          
                                             
                                                p
                                             
                                             
                                                k
                                             
                                          
                                          ⊂
                                          
                                             
                                                R
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 
                                    K
                                 
                              
                           
                        
                     where p
                     
                        k
                      is a spatio-temporal video volume (e.g., of size 7×7×4) and 
                        
                           
                              
                                 R
                              
                              
                                 i
                              
                           
                        
                      is a larger region in space and time around each pixel (e.g., of size 50×50×50). Although this formulation is straightforward, finding an anomaly is not trivial. Using this definition, the problem of finding short-term anomalous events will be modeled by means of a set of spatio-temporal volumes while using a probabilistic model of their spatial and temporal arrangements. This will be described in Section 3.

In light of the above, our goal is to build a fast anomaly detection framework for surveillance systems that addresses practical requirements, such as real-time performance and reliable detection and localization of anomalies. In addition, we seek the ability to learn newly observed events without any offline and supervised training. Perhaps most important, we wish to eliminate tracking, background subtraction or other processes such as foreground segmentation methods with their attendant weaknesses, which form the basis for previously reported approaches. After initialization of the algorithm using just a few seconds of video,
                        1
                        The number of initialization frames required to construct the ensemble of volumes (contextual region in the time domain) is related to the temporal size of the ensembles, 
                              
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                              
                            (see Eq. (2)). We discuss the number of initialization frames in Section 4.3.
                     
                     
                        1
                      our method builds a model of normal behavior and detects anomalies while incrementally updating itself in an unsupervised manner when a new normal pattern is observed.

The main characteristics of our approach and also the contributions of this paper are as follows:
                        
                           •
                           We introduce a probabilistic framework to capture spatio-temporal configurations of video volumes. This is achieved by estimating probability density functions of the arrangements of video volumes. Consequently, anomalies are defined as those spatio-temporal compositions in a video or set of videos having very low probability of occurrence.

We significantly reduce the size of the database for finding similar examples to a new observation while retaining summary information, thereby speeding up the process and making it real-time.

We use an online unsupervised incremental method in order to update the probability distribution functions of the normal events. Thus, our method can adaptively learn newly observed normal patterns.

We have conducted extensive experiments to evaluate the capability of our approach for anomaly detection using four datasets with different abnormality patterns and different contextual compositions: anomalous walking patterns
                        2
                        
                           
                              http://www.wisdom.weizmann.ac.il/∼vision/Irregularities.html
                           
                        
                     
                     
                        2
                      
                     [4]; the UCSD pedestrian dataset, which consists of two datasets
                        3
                        
                           http://www.svcl.ucsd.edu/projects/anomaly.
                     
                     
                        3
                     : UCSD Ped1 and UCSD ped2 datasets[6]; subway surveillance videos
                        4
                        Obtained from the authors of [3].
                     
                     
                        4
                      
                     [3]; and an anomaly detection dataset
                        5
                        
                           http://www.cse.yorku.ca/vision/research/spatiotemporal-anomalous-behavior.shtml.
                     
                     
                        5
                      
                     [8]. The results indicate that our approach is comparable to the state-of-the-art in terms of accuracy, while requiring vastly fewer computations than alternative non-local approaches and hence, makes real-time video analysis possible. The rest of this paper is organized as follows. Section 2 reviews the related work for solving the problem of anomaly detection. Section 3 describes the proposed approach for anomalous event detection and the steps of the algorithm: the sampling process and codebook formation, capturing spatio-temporal compositions of the video volumes, similarity map construction and the inference mechanism. Section 4 discusses experimental results on four different datasets, and finally, Section 5 concludes the paper.

@&#RELATED WORK@&#

As discussed earlier, anomaly discovery can be considered as a problem of outlier detection, which is the inverse problem of spatio-temporal detection and localization of human actions, sometimes referred to as “action spotting” [55,49]. The former seeks to focus on “what spatio-temporal visual patterns are different in the video?” while the latter is concerned with characterizing “normal and reoccurring actions”. Obviously, these are associated by the fact that they exist within the same video or set of videos. Action spotting is a well-researched topic in computer vision domains such as human–computer interaction, video retrieval, and surveillance [56].

Similar to action spotting, existing approaches that do not rely on tracking for anomaly detection, employ an analysis of local image regions in a video that uses a variety of motion-related features. These include optical flow [42,7,6], spatio-temporal oriented energy filtering [8], temporal video filtering [9], spatio-temporal video filtering [10,4,5], histogram of oriented gradients and histogram of oriented flows [49]. Some even integrate other local features such as texture and size of objects [53,6,57]. The use of these local low level features is the primary advantage of such methods. It makes them more robust than those based on tracking since these features can be extracted reliably over time [3]. We refer to such methods as the spatio-temporal approaches since they frequently depend on sampling 2D spatial image patches in each frame or 3D spatio-temporal video volumes in a video.

The selection of spatio-temporal volumes in a video has been accomplished using a set of interest points found by means of applying a grid of non-overlapping cells to each frame [58,42,57], choosing salient interest points [59], or randomly or densely sampling the video pixels [4,33–37,20,38–41,49]. In general, the potential real-time performance of these approaches for anomaly detection is related to the number of video volume samples and their associated features [36].

Although the sparse nature of salient points makes them computationally efficient, the main challenge is their selection [5,39]. In general, space–time interest points reported in the literature rely on the assumption that a video contains critical events such as locations where the motion direction changes quickly. Hence, they cannot capture smooth motion, which often is also informative [36]. In the final analysis, it has been shown that densely sampling a video always achieves better results than a sparse set of interest points [60]. In this paper, we use dense sampling exclusively.

Different approaches have been proposed for distinguishing anomalies using spatio-temporal features in local regions. For example, an unsupervised method is presented in [53], in which a model for each normal and abnormal behavior is constructed using mixtures of Dynamic Bayesian Networks (DBNs). This is followed by a likelihood ratio test to determine whether a newly observed behavior is normal or abnormal. The main drawbacks associated with this method are that background subtraction is necessary and contextual information is modeled locally. In [42], space–time Markov random fields are employed to model normal activity using multiple probabilistic PCA models of local optical flow. This concept has been generalized to a mixture of dynamic textures in [6] to detect and localize spatial and temporal abnormalities. While [6] has indicated that this model can achieve more robust results in crowded scenes, this approach suffers from high computational cost, a common drawback of all DBNs.

As indicated earlier, the recent trend in anomaly detection is to use spatio-temporal video volumes in the context of BOV models.
                        6
                        Essentially the probabilistic topic models, such as that of [59], can also be considered as BOV approaches since they ignore the spatio-temporal order of the local features [61].
                     
                     
                        6
                      Their popularity is due to their low computational cost, as well as their ability to focus on abnormal behavior, even in extremely crowded scenes [5]. However, since classical BOV approaches group similar volumes, they destroy all compositional information in the process of grouping visual words [13,47]. Thus, the likelihood of each video volume is based on its similarity to the other volumes in the dataset, without considering the spatio-temporal properties of neighboring ones. For example, in [3], motion patterns in local regions are estimated using optical flow and then quantized to construct a histogram of optical flow in local regions. Dissimilar motion patterns are considered to be anomalies.

It has been shown that anomaly detection by spatio-temporal volumes and not considering their composition will produce unacceptable results [4,35,42,37,5,47,19,38,40,62]. Nevertheless, different approaches have been presented to improve this situation. These are often based on co-occurrence matrices that are employed to describe contextual information. In large part, these methods are used exclusively for action recognition, since they require a supervised learning process. For example, the well-known correlogram exploits spatio-temporal co-occurrence patterns [40]. In this case, only the relationship between the two nearest spatio-temporal volumes is taken into account, which makes this approach local and incapable of capturing complex relationships between different volumes. An alternative that does incorporate contextual information in a BOV framework is presented in [19], in which three-dimensional spatio-temporal pyramid matching is employed. This technique is based on the original two-dimensional spatial pyramid matching of multi-resolution histograms of patch features [47]. Likewise in [22], temporal relationships between clustered patches are modeled using ordinal criteria (e.g., equals, before, overlaps, during, after, etc.). In [35] the spatial information is coded through concatenation of video words detected in different spatial regions and data mining techniques to find frequently occurring combinations of features. Similarly, [48] addresses this issue by using the spatial configuration of the 2D patches by incorporating their weighted sum. In summary, most of these approaches are used for activity recognition rather than anomaly detection, and contextual information is represented locally and at fixed spatial or temporal scales.

In spite of the above discussion, some efforts have been made recently to incorporate contextual information. In [10] a local test for detecting abnormal video volumes measures the similarity of a particular video volume to its eight neighboring volumes; those that are not similar to all others in this set are marked as being anomalous. In [5], video volumes are represented using 3D Gaussian distributions of the spatio-temporal gradient. The temporal relationship between these distributions is modeled using HMMs.

Boiman and Irani [4] have presented an alternative approach based on the spatio-temporal composition of a large number of volumes. Each new observation is reconstructed using only the previously observed spatio-temporal volumes, which are obtained by densely sampling the video. To consider the relationship between these volumes, the likelihood of a large contextual region around each volume is computed using the examples already seen in the video. By using densely sampled volumes, Boiman and Irani [4] were able to produce a good approximation to the likelihood, thereby permitting the detection of normal and abnormal behavior using a star graph model. The primary drawbacks of the work of Boiman and Irani [4] are the high computational complexity of their method and the lack of any means of taking into account uncertainty about the BOVs. We deal with both of these aspects by using a probabilistic framework to determine the likelihood of the space–time cuboids in a video. However, the main problem with dense sampling is its excessive computational time. Furthermore, it requires a large amount of memory to store all of the volumes as well as their spatio-temporal relationships.

Some modifications of [4] have been presented, but these are strictly within the framework of action recognition [49]. For example a modified version of [4] has been presented in [38], in which a two-level clustering method is employed to speed-up the search process. At the first level, all similar volumes are categorized. Then clustering is performed on randomly selected groups of spatio-temporal volumes while considering the relationships in space and time between the five nearest spatio-temporal volumes. However, the small number of spatio-temporal volumes involved makes this method local in nature. Another hierarchical approach is presented in [37], which attempts to capture the compositional information of a subset of the most discriminative video volumes. We note that both of these approaches exploit supervised learning and hence cannot really be used for anomaly detection.

In order to avoid a computational bottleneck, we sort video volumes based on their spatio-temporal similarity, while considering the uncertainty in the grouping procedure. Although the method for clustering of similar video volumes may at first glance appear to be analogous to the Implicit Shape Model (ISM) in Leibe et al. for class-based object recognition [63], it actually differs in three ways. First, we examine the information in a large spatio-temporal context. Second, there is no need to create a predefined set of known object classes with predefined object centers. Our method adaptively determines these on its own. Third, we apply our method to videos, not just to images. By employing a probabilistic framework, the system we describe in this paper significantly reduces the computational time required for determining the similarity of the compositions of the many video volumes that need to be examined [4]. Moreover, our approach also dramatically reduces the amount of memory required for storing previously observed video arrangements. Thus the contribution of our paper is to demonstrate how videos can be processed for anomalies in real-time while summarizing the important information in the video. Ultimately, this will provide the ability to characterize and label all, not just anomalous, events. An overview of our approach is sketched in Fig. 1
                     .


                     Fig. 1 shows the steps of the proposed anomalous activity recognition algorithm, STC (Spatio-Temporal Compositions). At first, a codebook model is constructed to group similar spatio-temporal video volumes and remove redundant data; for example, in one minute of typical video, we have found experimentally that there are about 106 video volumes, while the number of codewords is around 20. Then, a large contextual region (in space and time) around each video volume is examined and the compositional relationships between video volumes are approximated using a mixture of Gaussians. To construct such a probabilistic model, a small number of video frames containing normal behaviors is necessary to initiate the on-line learning process. The minimum number of frames is governed by the extent of the size of the temporal context.
                        7
                        We discuss the number of initialization frames in Section 4.3.
                     
                     
                        7
                      Thus large numbers of training videos, containing valid behaviors, are unnecessary, as is usually the case in the current literature.

The problem is transformed to a reconstruction problem using the previous formulation for anomaly detection (1). This equation implies that the similarity between a newly observed video frame and all previous observations is calculated according to (1). In order to make a decision about new observations in a reasonable time, information regarding the spatio-temporal volumes and their relative arrangement in the regions of interest must be efficiently stored in the database. Here we focus on two issues, the reconstruction process, and a fast inference mechanism for anomaly detection. Therefore, the goal of the algorithm is to reduce the number of spatio-temporal volumes stored in the dataset in order to limit the search time, while still retaining a compact and accurate representation of the spatio-temporal arrangement of all volumes.

As illustrated in Fig. 1, the algorithm consists of three main steps: sampling and coding the video to construct spatio-temporal volumes, probabilistic modeling of relative compositions of the spatio-temporal volumes, and the inference mechanism to make decisions about newly observed videos. To construct a probabilistic model for an arrangement of the spatio-temporal volumes of “normal” actions, it is necessary to use a few sample video frames containing such behaviors. These examples must be observed in order to initialize (or train) the algorithm. In the rest of the paper, we refer to these video frames as the “training set”. Although, currently, this probabilistic model is created during initialization, any other valid action that has not actually been observed during initialization can also be used.

The essence of the method described in this paper is to measure the similarity between various spatio-temporal volumes in the observation set and the incoming video data in order to examine whether the actions are anomalous. Thus, newly observed data must be re-constructed using historical data. In this section, we first explain the sampling strategy, followed by codebook construction for grouping similar video volumes. The codebook is intended to reduce the redundancy in the video volumes, while retaining both informative volumes and the uncertainties in the codeword assignment.

Our work is based on the bag of features approach, i.e., a set of spatio-temporal volumes obtained using dense, random, or salient points. Although there are many methods for selecting the latter, dense sampling has been shown to be superior to the others in terms of retaining the informative features of a video [39]. Therefore, performance almost always increases with the number of sampled spatio-temporal volumes, making dense sampling the preferable choice [60,4].

The 3D spatio-temporal volumes in a video, 
                              
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                 
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             x
                                          
                                       
                                       ×
                                       
                                          
                                             n
                                          
                                          
                                             y
                                          
                                       
                                       ×
                                       
                                          
                                             n
                                          
                                          
                                             t
                                          
                                       
                                    
                                 
                              
                           , are constructed by assuming a small volume of size of n
                           
                              x
                           
                           ×
                           n
                           
                              y
                           
                           ×
                           n
                           
                              t
                            around each pixel in the video, in which n
                           
                              x
                           
                           ×
                           n
                           
                              y
                            is the size of the spatial (image) window and n
                           
                              t
                            is the depth of the video volume in time. Spatio-temporal volume construction is performed at various spatial and temporal scales, producing a sort of video pyramid. This yields a large number of volumes (“mini-video clips”) at each pixel in the video. Fig. 2
                            illustrates the process of spatio-temporal volume construction.

Each spatio-temporal volume in the video is characterized by a set of simple descriptors as in [4,34]. The descriptors are defined by the absolute value of the temporal derivatives of all pixels in each volume, p
                           
                              i
                           
                           
                              
                                 (3)
                                 
                                    ∀
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                    
                                       
                                          g
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    abs
                                    (
                                    
                                       
                                          Δ
                                       
                                       
                                          t
                                       
                                    
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    )
                                 
                              
                           
                        

Their values are then stacked in a vector and normalized to a unit length to form a “compact” feature descriptor for each video volume at various scales, 
                              
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             x
                                          
                                       
                                       
                                          
                                             n
                                          
                                          
                                             y
                                          
                                       
                                       
                                          
                                             n
                                          
                                          
                                             t
                                          
                                       
                                    
                                 
                              
                           . The procedure in (3) is actually performed at several spatial and temporal scales of a Gaussian space–time video pyramid of the original data. In other words, the spatio-temporal volumes are smoothed at different scales before computing the gradients. An interesting property of this descriptor is that it is largely invariant to roughly static backgrounds, which makes it possible to detect abnormal actions regardless of the background, although in surveillance systems the background does not change quickly. Notwithstanding its simplicity, the results obtained are very promising. Obviously the simple gradient descriptor defined in (3) could be replaced by others, and perhaps, thereby enhance the performance. Examples of more complicated descriptors are the ones in [41] and in [30], the spatio-temporal gradient filters in [10,9], the spatio temporal oriented energy measurements [8,55] and the popular three-dimensional Scale Invariant Feature Transform (SIFT) [64].

In the previous section, a set of spatio-temporal volumes was constructed at various spatial and temporal scales using dense sampling but their number is extremely large. For example, we have found experimentally that there are about 106 video volumes in a typical one minute video clip. Thus, the motivation for creating our method was premised on the fact that the approach proposed by Boiman and Irani [4] was not applicable to real-time video analysis. Moreover, although these densely computed spatio-temporal volumes are highly informative, they are also redundant. Thus, it would also seem to be advantageous to group similar spatio-temporal volumes to reduce the dimensions of the search space. This is commonly performed in all BOV approaches [19,41,49].

Here, similar spatio-temporal volumes are grouped by constructing a codebook, as detailed in Fig. 3
                           . This is a straightforward procedure. The first codeword is made equivalent to the first observed spatio-temporal volume. After that, by measuring the similarity between each observed volume and the codewords already in the codebook, either the codewords are updated or a new one is formed. Then, each codeword is updated with weight of w
                           
                              i,j
                           , which is based on the similarity between the volume and the existing codewords.
                              8
                              Later it will be seen that this facilitates the handling of uncertainty in codeword assignment.
                           
                           
                              8
                            Here, we utilize the Euclidean distance for this purpose. Thus, the normalized weight of assigning codeword c
                           
                              j
                            to video volume v
                           
                              i
                            is given by
                              9
                              Throughout the rest of the paper, each video volume will be represented by its descriptor vector.
                           
                           
                              9
                           :
                              
                                 (4)
                                 
                                    
                                       
                                          w
                                       
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                distance
                                                (
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      i
                                                   
                                                
                                                ,
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      j
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    ×
                                    
                                       
                                          1
                                       
                                       
                                          distance
                                          (
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

Another important parameter is the number of times that a codeword has been observed (f
                           
                              j
                           ). The codebook is continuously being pruned to eliminate those that are either infrequent or very similar to the others, which ultimately generates M different codewords that are taken as the labels for the video volumes, 
                              
                                 C
                                 =
                                 
                                    
                                       {
                                       
                                          
                                             c
                                          
                                          
                                             i
                                          
                                       
                                       }
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       M
                                    
                                 
                              
                           . Since the goal of the algorithm is to measure similarity of a new observation to a subset of previously observed normal actions, the codebook is formed using videos that contain valid actions.

After the initial codebook formation, each 3D volume, v
                           
                              i
                           , can be assigned to all labels, c
                           
                              j
                           ’s, with a degree of similarity, w
                           
                              i,j
                           , as shown in Fig. 4
                           . We note that the number of labels (shown in color), M, is much less than the number of volumes, N. Moreover, codebook construction can be performed using any other clustering method, such as k-means or mutual information [19].

The main drawback of most BOV approaches is that they do not consider the spatio-temporal context of each volume. Thus the outcome is a set of similar volumes, clustered regardless of their positions in space and time. Several methods for capturing such information have appeared in the literature (see [4,47,48]). In this paper, we present an alternative probabilistic framework for quantifying the arrangement of the spatio-temporal volumes at a pixel in the video.

Consider a new visual observation, the query. The goal is to estimate the likelihood of each pixel in the query of being normal. To accomplish this, a large region R (e.g., 50×50×50) around each pixel is considered and the likelihood is calculated by measuring the similarity between the volume arrangement in the query and the dataset as described by (1). R contains many volumes with different spatial and temporal sizes, as shown in Fig. 5
                        . Such a set is called an ensemble of volumes around the particular pixel in the video and is defined by (2). Given the representation of an ensemble of volumes in (2), abnormality detection is reduced to constructing a similarity map of new observations with respect to all of the previous ones. In doing this, the similarity between many different topologies of ensembles of volumes will be taken into account in order to capture the specific context of each pixel. The use of spatio-temporal context surrounding a pixel will tend to influence the ultimate choice of the codeword associated with a particular pixel.

Let us consider how we represent an ensemble of video volumes, E
                        
                           i
                        , at (x
                        
                           i
                        , y
                        
                           i
                        , t
                        
                           i
                        ) containing K spatio-temporal volumes. Thus the ensemble, E
                        
                           i
                        , is centered at a video volume v
                        
                           i
                         located at the point (x
                        
                           i
                        , y
                        
                           i
                        , t
                        
                           i
                        ) in absolute coordinates. Here we use the relative spatio-temporal coordinates of the volume in an ensemble to account for its position, as shown in Fig. 6a. Consider the kth volume in E
                        
                           i
                        . Define 
                           
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                           
                         as the relative position (in space and time) of the kth video volume, v
                        
                           k
                        , located at the point (x
                        
                           k
                        , y
                        
                           k
                        , t
                        
                           k
                        ), inside the ensemble of volumes. 
                           
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is defined by (5):
                           
                              (5)
                              
                                 
                                    
                                       Δ
                                    
                                    
                                       vk
                                    
                                    
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 =
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                                 -
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       k
                                    
                                 
                                 -
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       t
                                    
                                    
                                       k
                                    
                                 
                                 -
                                 
                                    
                                       t
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           
                        
                     

Then each ensemble of video volumes at location (x
                        
                           i
                        , y
                        
                           i
                        , t
                        
                           i
                        ) is represented by a set of such video volumes and their relative positions with respect to the central video volume. Hence (2) can be rewritten as:
                           
                              (6)
                              
                                 
                                    
                                       E
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Δ
                                                
                                                
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         E
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                             ,
                                             
                                                
                                                   v
                                                
                                                
                                                   k
                                                
                                             
                                             ,
                                             
                                                
                                                   v
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                    
                                       k
                                       =
                                       1
                                    
                                    
                                       K
                                    
                                 
                              
                           
                        where K is the total number of video volumes inside the ensemble.

During the codeword assignment process described in the Section 3.1.2, a codeword c
                        ∈
                        C was assigned to each video volume, v
                        
                           k
                        , inside each ensemble with an associated degree of similarity using (4). Given the codewords assigned to the video volumes, each ensemble of volumes can be represented by a set of codewords and their spatio-temporal relationships. Assume that 
                           
                              V
                              ⊂
                              
                                 
                                    R
                                 
                                 
                                    
                                       
                                          n
                                       
                                       
                                          x
                                       
                                    
                                    
                                       
                                          n
                                       
                                       
                                          y
                                       
                                    
                                    
                                       
                                          n
                                       
                                       
                                          t
                                       
                                    
                                 
                              
                           
                         is the space of the descriptors for a video volume (see Section 3.1.1), and C is the codebook constructed in Section 3.1.2. Let 
                           
                              c
                              :
                              V
                              →
                              C
                           
                         be a random variable, which assigns a codeword to a video volume. Assume that 
                           
                              
                                 
                                    c
                                 
                                 
                                    ′
                                 
                              
                              :
                              V
                              →
                              C
                           
                         is a random variable denoting the assigned codeword to the central video volume of an ensemble. Therefore, 
                           
                              δ
                              :
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                              →
                              
                                 
                                    R
                                 
                                 
                                    3
                                 
                              
                           
                         is a random variable denoting the relative position of a codeword c to the codeword assigned to the central video volume of the ensemble, c′. Given the above assumptions, an ensemble of volumes can be represented as a graph of codewords and their spatio-temporal relationship, as shown in Fig. 6
                        b.

Having defined the representation of an ensemble of volumes in (6), and given the assigned codewords to the video volumes as described above, a set of hypotheses describing the topology of each ensembles can be defined. Those hypotheses are then used for constructing a similarity map between the topologies of the ensembles in a new observation with respect to all of the previous ones. Let us consider each hypothesis, h, as a tuple h
                        =(c, c′, δ). Therefore, the set of hypotheses, 
                           
                              H
                           
                        ,
                           10
                           These hypotheses, 
                                 
                                    H
                                 
                              , are obtained by assuming that the codeword entries are independent.
                        
                        
                           10
                         which describe the topology of each ensemble is defined as follows:
                           
                              (7)
                              
                                 H
                                 =
                                 
                                    
                                       
                                          ⋃
                                       
                                       
                                          h
                                       
                                    
                                 
                                 {
                                 h
                                 }
                                 =
                                 
                                    
                                       
                                          ⋃
                                       
                                       
                                          
                                             
                                                
                                                   c
                                                   ∈
                                                   C
                                                
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∈
                                                   C
                                                
                                             
                                          
                                       
                                    
                                 
                                 {
                                 (
                                 c
                                 ,
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 ,
                                 δ
                                 )
                                 }
                              
                           
                        
                     

Suppose we now consider sampling the video frame-by-frame and pixel-by-pixel in each frame. Let 
                           
                              O
                              =
                              
                                 
                                    
                                       
                                          
                                             v
                                          
                                          
                                             k
                                          
                                       
                                       ,
                                       
                                          
                                             v
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             Δ
                                          
                                          
                                             
                                                
                                                   v
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         signify a single observation, where v
                        
                           k
                         denotes any observed video volume inside an ensemble, E
                        
                           i
                        ; v
                        
                           i
                         denotes the observed video volume at the center of the ensemble; and 
                           
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                         is the relative location of the observed video volume, v
                        
                           k
                        , with respect to the v
                        
                           i
                         inside E
                        
                           i
                        . The aim is to measure the probability of each hypothesis given the observation. Therefore, given an observation, 
                           
                              O
                           
                        , the posterior probability of each hypothesis, h, is written as:
                           
                              (8)
                              
                                 P
                                 (
                                 h
                                 |
                                 O
                                 )
                                 =
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The posterior probability in (8) defines the probability of observing the codewords c, c′, and their relative position, δ, given the observed video volumes, 
                           
                              (
                              
                                 
                                    v
                                 
                                 
                                    k
                                 
                              
                              ,
                              
                                 
                                    v
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              )
                           
                        . Then (8) can be rewritten as:
                           
                              (9)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 P
                                 
                                    
                                       
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          c
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Since an observed video volume, v
                        
                           k
                        , has been replaced by a postulated interpretation, c, the first factor on the right hand side of (9) can be treated as being independent of v
                        
                           k
                        . Moreover, it is assumed that video volumes v
                        
                           k
                         and v
                        
                           i
                         are independent.
                           11
                           Although in the case of overlapping video volumes such an assumption is not true, this is the standard Markovian assumption made for BOV.
                        
                        
                           11
                         Hence, v
                        
                           i
                         can be removed from the second factor on the right hand side of (9). Therefore (9) can be rewritten as:
                           
                              (10)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 P
                                 
                                    
                                       
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          c
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

On the other hand, the codeword assigned to a video volume is independent of its position, 
                           
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          v
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           
                        . Therefore (10) can be reduced to:
                           
                              (11)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 ,
                                 δ
                                 |
                                 c
                                 ,
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       Δ
                                    
                                    
                                       
                                          
                                             v
                                          
                                          
                                             k
                                          
                                       
                                    
                                    
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       v
                                    
                                    
                                       k
                                    
                                 
                                 )
                              
                           
                        so that rewriting (11) gives:
                           
                              (12)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 ,
                                 δ
                                 |
                                 c
                                 ,
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       Δ
                                    
                                    
                                       
                                          
                                             v
                                          
                                          
                                             k
                                          
                                       
                                    
                                    
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       v
                                    
                                    
                                       k
                                    
                                 
                                 )
                                 =
                                 P
                                 
                                    
                                       
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          |
                                          c
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       v
                                    
                                    
                                       k
                                    
                                 
                                 )
                              
                           
                        
                     

Similarly, by assuming independency between codewords and their locations, (12) can be reduced to:
                           
                              (13)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                v
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                v
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 P
                                 
                                    
                                       
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 |
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       v
                                    
                                    
                                       k
                                    
                                 
                                 )
                              
                           
                        
                     

Knowing the codeword assigned to the video volume, c, and the codeword assigned to the central video volume of the ensemble, c′, the first factor on the right hand side of (13), 
                           
                              P
                              
                                 
                                    
                                       δ
                                       |
                                       c
                                       ,
                                       
                                          
                                             c
                                          
                                          
                                             ′
                                          
                                       
                                       ,
                                       
                                          
                                             Δ
                                          
                                          
                                             
                                                
                                                   v
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        , is the probabilistic vote for a spatio-temporal position, δ. Thus, given a set of ensembles of video volumes, it can be formed using either a parametric model or non-parametric estimation. Here, we approximate this pdf using a mixture of Gaussians. The maximum number of Gaussians is set to three and the parameters of the Gaussians are optimized using an expectation–maximization procedure [65]. The second and third terms in the right hand side of (13), P(c′∣v
                        
                           i
                        ) and P(c∣v
                        
                           k
                        ), are the votes for each codeword entry and are obtained as a result of the codeword assignment procedure.
                           12
                           Codewords are assigned to the video volumes regardless of their location in space and time.
                        
                        
                           12
                        
                     

Thus, given an ensemble of spatio-temporal video volumes, the likelihood of its composition can be computed simply by using the pdfs instead of laboriously comparing all other video volumes compositions in the dataset. As discussed in the next section, anomalous events are determined from these pdfs by selecting those compositions with very low likelihood of occurrence. Comparing this with [4], in which an exhaustive search was employed to determine the optimal ensemble, our approach is capable of retaining adequate information about the spatio-temporal arrangement of the volumes while reducing the memory requirements. It also greatly reduces the dimension of the search space for finding similar regions in the dataset for a new observation.

Next, consider the scenario of a continuously operating surveillance system. At each temporal sample t, a single image is added to the already observed frames and the resulting video sequence, the query, 
                           
                              Q
                           
                        , is formed. In order to detect anomalous patterns, the posterior probability of each pixel in the query video is calculated using the ensemble of the spatio-temporal volumes around it to determine whether the point is related to the normal events or is suspicious.

Given (7) which details the ensemble topology hypotheses, 
                           
                              H
                           
                         obtained from the previous section, the posterior probability of an ensemble of volumes in the query is calculated as: 
                           
                              P
                              
                                 
                                    
                                       H
                                       |
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                          
                                             Q
                                          
                                       
                                    
                                 
                              
                           
                        . Here 
                           
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                                 
                                    Q
                                 
                              
                           
                         is an ensemble of video volumes in the query centered at point (x
                        
                           i
                        , y
                        
                           i
                        , t
                        
                           i
                        ).

Thus given 
                           
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                                 
                                    Q
                                 
                              
                           
                        , we wish to search for previously observed ensembles that are most similar to the newly observed ensemble in terms of both their video volumes and topologies. In other words, the posterior probability should be maximized:
                           
                              (14)
                              
                                 
                                    
                                       
                                          max
                                       
                                       
                                          h
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          H
                                          |
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                             
                                                Q
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          max
                                       
                                       
                                          
                                             
                                                
                                                   c
                                                   ∈
                                                   C
                                                
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∈
                                                   C
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                             
                                                Q
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Since we represent each ensemble by its spatio-temporal video volumes, relative position and the central volume, and assuming that the observed video volumes are independent,
                           13
                           This is the Markov assumption (see [4,38]).
                        
                        
                           13
                         the right side of the above equation can be written as the product of the posterior probability of every video volume inside the ensemble:
                           
                              (15)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                             
                                                Q
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          k
                                       
                                       
                                          K
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                q
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                q
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      q
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      Q
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where q
                        
                           k
                         is the video volume inside 
                           
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                                 
                                    Q
                                 
                              
                              ,
                              
                              
                                 
                                    q
                                 
                                 
                                    i
                                 
                              
                           
                         is the central volume of 
                           
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                                 
                                    Q
                                 
                              
                              ,
                              
                              
                                 
                                    Δ
                                 
                                 
                                    
                                       
                                          q
                                       
                                       
                                          k
                                       
                                    
                                 
                                 
                                    
                                       
                                          E
                                       
                                       
                                          i
                                       
                                       
                                          Q
                                       
                                    
                                 
                              
                           
                         is the relative position of the q
                        
                           k
                        , and K is the total number of spatio-temporal video volumes inside the ensemble. Referring to (13), it is obvious that 
                           
                              P
                              
                                 
                                    
                                       c
                                       ,
                                       
                                          
                                             c
                                          
                                          
                                             ′
                                          
                                       
                                       ,
                                       δ
                                       |
                                       
                                          
                                             q
                                          
                                          
                                             k
                                          
                                       
                                       ,
                                       
                                          
                                             q
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             Δ
                                          
                                          
                                             
                                                
                                                   q
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          
                                             
                                                
                                                   E
                                                
                                                
                                                   i
                                                
                                                
                                                   Q
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                         in (15) can be rewritten as follows:
                           
                              (16)
                              
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                             
                                                Q
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          k
                                       
                                       
                                          K
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      q
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      Q
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       k
                                    
                                 
                                 )
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           
                        
                     

Thus the maximum posterior probability in (14) can be rewritten as:
                           
                              (17)
                              
                                 
                                    
                                       
                                          max
                                       
                                       
                                          
                                             
                                                
                                                   c
                                                   ∈
                                                   C
                                                
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∈
                                                   C
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          δ
                                          |
                                          
                                             
                                                E
                                             
                                             
                                                i
                                             
                                             
                                                Q
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          max
                                       
                                       
                                          
                                             
                                                
                                                   c
                                                   ∈
                                                   C
                                                
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∈
                                                   C
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∏
                                       
                                       
                                          k
                                       
                                       
                                          K
                                       
                                    
                                 
                                 P
                                 
                                    
                                       
                                          δ
                                          |
                                          c
                                          ,
                                          
                                             
                                                c
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                Δ
                                             
                                             
                                                
                                                   
                                                      q
                                                   
                                                   
                                                      k
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      E
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      Q
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 P
                                 (
                                 c
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       k
                                    
                                 
                                 )
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       ′
                                    
                                 
                                 |
                                 
                                    
                                       q
                                    
                                    
                                       o
                                    
                                 
                                 )
                              
                           
                        
                     

This is a straightforward computation because the prior probability of each spatio-temporal volume in the query has been calculated during codeword assignment (described in Section 3.1). The posterior probability is calculated using the estimated probability distribution functions in Section 3.2. Fig. 7
                         shows the pseudo-code for the inference process.

In summary, at first, the query, 
                           
                              Q
                           
                         is densely sampled at different spatio-temporal scales in order to construct the video volumes. Each volume q
                        
                           k
                         is assigned to a codeword c
                        ∈
                        C with similarity obtained from (4). The probability of being normal of every pixel in a video frame is then calculated using the spatio-temporal arrangement of the volumes inside each ensemble, 
                           
                              
                                 
                                    E
                                 
                                 
                                    i
                                 
                                 
                                    Q
                                 
                              
                           
                        . As a result, the likelihood of every pixel in each frame is approximated (see Fig. 8
                        ). Ultimately, the likelihoods of all in the video frame will yield a similarity map of the whole frame. Clearly, the regions in a frame of the video containing suspicious behaviors will have less similarity to the examples already observed. Thus, decisions about anomalous actions can be made using the calculated similarity map, which is based on a threshold. In the experiments described in this paper, a single threshold
                        
                           14
                           This threshold was determined experimentally and was taken to be 4.5×10−4.
                        
                        
                           14
                         for all test sequences was applied to the similarity map. The similarity map was processed before thresholding by a spatio-temporal median filter to reduce noise effects and outliers.

We also note that the proposed statistical model of codeword assignment and the arrangement of the spatio-temporal volumes permit small local misalignments in the relative geometric arrangement of the composition. This property, in addition to the multi-scale volume construction in each ensemble, enables the algorithm to handle certain non-rigid deformations in space and time. This, of course, is necessary since human actions are not exactly reproducible, even for the same person. We conclude this section by examining computational complexity. Suppose there are K video volumes available in each ensemble and the number of codewords is M. For each ensemble, the time complexity of the codeword assignment is O(K
                        ×
                        M) and for the maximum posterior probability in (17) is O(K
                        ×
                        M
                        ×
                        M). Thus, the inference mechanism for each ensemble of video volumes in the query has the time complexity of O(K
                        ×
                        M
                        ×(M
                        +1)). On the other hand, the method proposed by Boiman and Irani [4], which is the exact solution to anomaly detection by reconstruction, has a time complexity of O(K
                        ×
                        N), in which N is the total number of video volumes previously observed. Moreover, in [4] 
                        N video volumes are required to be stored in memory as previous observations, while in our approach the total number video volumes stored is M. Noting that usually M
                        ≪
                        N, the approach proposed in this paper requires much fewer computations as well as a smaller amount of memory space.

Before continuing with the experimental results, we describe how the algorithm is initialized. The scenario we have considered in this paper implies on-line and continuous surveillance of a particular scene in order to detect anomalous patterns. Therefore, we require only that the first n frames of the video stream initiate the process. Furthermore, n should be taken at least equal to the temporal size of the ensembles, 
                           
                              
                                 
                                    R
                                 
                                 
                                    i
                                 
                              
                           
                        , (see Eq. (2)) in order to construct a successful model of the previous observations. These n frames must contain only normal events, and we have referred to them as the training or initialization sequence. The actual number of initialization frames (n) required and its effect on the detection results is discussed in the next section. To initiate the codebook during the first n frames, each video volume is assigned to a codeword with a similarity weight using the procedure explained in Section 3.1. In addition, probability distribution functions of spatio-temporal arrangements of the codewords are also estimated. This can be accomplished either online or offline. When the next frame, (n
                        +1) th frame, arrives it is densely sampled to construct spatio-temporal video volumes and the ensembles of these video volumes. Their similarity to the volumes that have already been obtained is computed using the codebook constructed during the initialization procedure and inference mechanism described in Section 3.3. In this way, the algorithm constantly learns newly observed normal events in an unsupervised manner (see experimental results). Similar to [3,4], dominant events are assumed to be normal while rarely observed activities are considered as anomalies.

@&#EXPERIMENTS@&#

The algorithm was tested on crowded and non-crowded scenes (one or two persons in the scene) in order to measure the capabilities of the proposed method for anomalous activity recognition. Four publicly available datasets of anomalous events were used: the anomalous walking patterns of a person
                        15
                        
                           
                              http://www.wisdom.weizmann.ac.il/∼vision/Irregularities.html
                           .
                     
                     
                        15
                      
                     [4]; the UCSD pedestrian dataset, which has recently been published and actually consists of two datasets
                        16
                        
                           http://www.svcl.ucsd.edu/projects/anomaly.
                     
                     
                        16
                      
                     [6]; the subway surveillance videos
                        17
                        Obtained from the authors of [3].
                     
                     
                        17
                      
                     [3]; and the anomaly detection dataset
                        18
                        
                           http://www.cse.yorku.ca/vision/research/spatiotemporal-anomalous-behavior.shtml.
                     
                     
                        18
                      
                     [8], the last containing videos captured under variable illumination conditions. Except for the first dataset, the others were gathered in realistic environments. To evaluate performance, we also compared the results with other pixel-level approaches of current interest, such as Inference by Composition (IBC) [4], Mixture of Dynamic Textures (MDT) [6], Space–Time Markov Random Fields (ST-MRF) [42], Local Optical Flows [3], and spatio-temporal oriented energy filters [8].
                        19
                        Note computer code for these methods is not available publicly and had to be programmed using just the original papers as references.
                     
                     
                        19
                      The IBC method is currently considered to be one of the most accurate for pixel level saliency detection
                        20
                        Our experimental results also support this claim.
                     
                     
                        20
                      and was tested to demonstrate that STC produced similar results.

IBC calculates the likelihood of every point in each frame. This is achieved by examining the spatio-temporal volumes and their arrangements in a large region surrounding the pixels in a query video. ST-MRF models the normal activity using multiple probabilistic PCA models of local optical flow [42], while MDT can be considered as an extension of the dynamic texture-based models and is capable of detecting both spatial and temporal abnormalities [6]. Although the latter requires a large training dataset, it was used here for comparing results because of its superior performance on the UCSD pedestrian dataset.

The first dataset we discuss illustrates the situation with one or two persons in the scene. The training
                        
                           21
                           Although our method does not actually require any specific number of training images, the training sequences specified for each dataset in the literature description of the experiments were used as the initialization frames.
                        
                        
                           21
                         video is short (24s) and contains normal acted behaviors representing two different actions, walking and jogging by a single person. Fig. 9
                         shows some sample images from this training set. The query is a long video clip which contains both acted normal and abnormal behaviors of one or two persons in the scene. In some sequences one of them performs a normal and the other, a suspicious action. The existence of the simultaneous occurrence of both normal and suspicious activities in the video provides an opportunity to evaluate the localization ability of the proposed method. The suspicious behaviors in the dataset are abnormal walking patterns, crawling, jumping over objects, falling down, etc. We show some frames in which the proposed algorithm detected suspicious behaviors in Fig. 9.
                           22
                           The videos showing results of our algorithm for abnormality detection are available at: 
                                 http://cim.mcgill.ca/∼javan/index_files/Abnormal_events.html
                              .
                        
                        
                           22
                        
                     

The second dataset used for performance evaluation of the proposed approach is the UCSD pedestrian dataset. It contains video sequences from two pedestrian walkways where abnormal events occur. The dataset contains different crowd densities, and the anomalous patterns are the presence of non-pedestrians on a walkway (bicyclists, skaters, small carts, and people in wheelchairs). The UCSD pedestrian dataset contains 34 normal video clips for the first scene (UCSD Ped 1) and 36 video clips containing one or more anomalies for testing; and 16 normal video clips for the second scene (UCSD Ped 2), together with 14 test video clips. Fig. 10
                         shows samples of these two scenes with the suspicious regions labeled by the proposed method.

The third dataset contains two actual surveillance videos of a subway station [3] recorded by a camera at the entrance and exit gates. The entrance gate surveillance video is 96min long. It shows normal events such as going down through the turnstiles and entering the platform. There are also scenes containing 66 anomalous events, mainly walking in the wrong direction, irregular interactions between people and some other events, including sudden stopping, running fast, etc. [3]. The second one, the exit gate surveillance video, is 43min long and contains 19 anomalous events, mainly walking in the wrong direction and loitering near the exit [3]. Neither the surveillance videos nor groups of frames within them are labeled as training or testing videos. Fig. 11
                         shows some frames from this dataset together with the detected anomalies using our approach.

The fourth dataset contains real-world videos with more complicated dynamic backgrounds plus variable illumination conditions. Notwithstanding the significant environmental changes in this dataset, the abnormalities are actually simplistic motions (e.g., motion in the scene or different motion direction). We used three videos from this dataset, which have variable illumination and dynamic backgrounds: the Train, the Belleview, and the Boat-Sea video sequences. The Train sequence is the most challenging one in this dataset [8] due to drastically varying illumination and camera jitter. In this sequence, the abnormalities relate to the movement of people. The other sequence is a traffic scene in which the lighting conditions change gradually during different times of the day and the abnormalities are cars entering the intersection from the left or right. In the last video sequence the abnormalities are the passing boats in the sea. Similar to the subway surveillance video dataset, there are no separate training and testing sequences. Fig. 12
                         shows some frames of this dataset together with the detected anomalies using our approach.

Performance evaluation of any anomaly detection method can be conducted either at the frame or pixel level. Frame level detection implies that a frame is marked as suspicious if it contains any abnormal pixel, regardless of its location. On the other hand, pixel level detection attempts to measure the localization ability of an algorithm. This requires the detected pixels in each video frame to be compared to a pixel level ground truth map. Clearly, such abnormality localization is more important than marking the whole frame as suspicious.

We first consider a quantitative comparison of different approaches for anomaly detection at the frame level. Fig. 13
                         shows the receiver operating characteristic (ROC) for the first dataset (containing anomalous walking patterns), plotted as a function of the detection threshold for different anomaly detection methods. Following the evaluation procedure of [3,4], each frame is marked as abnormal if it contains at least one pixel detected as an anomaly. Similarly we performed frame level detection on the UCSD pedestrian dataset and the ROC curves are illustrated in Fig. 14
                        a and b. It is clear from Figs. 13 and 14 that IBC and STC produce more accurate results than the others, particularly MDT on the UCSD pedestrian dataset. We note that MDT had been reported to have achieved the highest recognition rate for the UCSD dataset [10]. We observe that the similar performance of STC and IBC was probably predictable, because STC summarizes the spatio-temporal relationships between the video patches, while IBC maintains these by storing all spatio-temporal arrangements of all volumes in the dataset. This indicates that there was no performance loss, notwithstanding the fact that STC is based on probabilities and performs in real-time. Thus while the two methods may achieve similar results for anomalous event detection, our approach has two main advantages over IBC. First it is considerably faster (see Table 1) and
                        , second, it requires much less memory to store the learnt data. These issues would also be important if our approach were to be used to describe and summarize normal rather than just anomalous behaviors.

The second approach for performance evaluation is to measure the localization performance by evaluating it at the pixel level. To date, pixel level localization can only be measured for a small number of datasets among existing public databases, since it requires ground truth maps. USCD pedestrian datasets [6], and the anomaly detection dataset [8] are the two datasets that include ground truth maps in which each region containing an anomalous event is marked manually. Thus the detected pixels in each video frame are compared to the ground truth map at the pixel level. For UCSD pedestrian datasets, anomaly detection is deemed to have occurred when at least 40% of the actual anomalous pixels have been detected.
                           23
                           We used a single threshold for all videos in this study to mark suspicious regions. However, these are usually larger or smaller than the actual ground truth region. A degree of overlap of 40% is a typical overlapping ratio suggested as the standard protocol for UCSD pedestrian dataset [6] and also used in [10,57,66] for measuring the localization ability of the algorithms.
                        
                        
                           23
                         Otherwise it is considered to be a false alarm. The equal error rate (EER), the percentage of misclassified frames when the false positive rate is equal to the miss rate, is calculated for both pixel and frame level analyses and presented in Table 2
                        .

The results in Table 2 demonstrate that the proposed method (and, of course, IBC) outperformed other approaches both at the frame and pixel levels. Furthermore, it can detect anomalous patterns without significant performance degradation when there is perspective distortion and changes in spatial scale (UCSD Ped 1 dataset). This is in distinction to optical flow approaches that cannot handle this issue easily [6]. Moreover the computational time required by the method described in this paper is significantly lower than other non local-approaches in the literature. In order to make a fair comparison of different approaches, the STC algorithm must be judged against other real-time algorithms as indicated in Table 2. Thus, we observe that the STC algorithm outperforms all other real-time algorithms and achieves the best results for the UCSD pedestrian dataset at both frame level detection and pixel level localization. It should also be noted that the results reported in Table 2 for all other methods were obtained using 50 video sequences for training (6800 video frames), while our approach used just one short video sequence consisting of 200 frames. This is a major advantage of our algorithm, which does not require long video sequences for initialization. It is also interesting to note that among other approaches that do not account for spatio-temporal contextual information, spatio-temporal oriented energy filters [8] is the fastest and outperforms other local approaches with real-time performance.

We also carried out experiments on another real-world video dataset, the subway surveillance dataset. The training strategy for the subway surveillance video is different from the UCSD pedestrian dataset, since no training set containing only normal events is available. Therefore, we used two approaches for initialization. The first one exploited a fixed number of frames, which is similar to previously reported approaches. Analogous to [42,54], we picked the first 5min of the entrance gate video and the first 15min of the exit gate video for initialization. The second approach was to continue learning newly observed events while still detecting the anomalies. The results are presented in Table 3
                        . Compared with the other approaches for abnormality detection, the STC algorithm produces comparable results to the state of the art. We also observe that that performance of our algorithm is independent of the initialization strategy, although continuous learning does provide slightly better results.

We also evaluated the localization performance of our algorithm using pixel level ground truth. Abnormality detection was performed for the subway exit gate video using the same initialization strategy as the frame level detection. The ground truth map for this video was produced manually by the authors of [8] for wrong way motion abnormalities. Fig. 15
                         illustrates the precision-recall curves of the proposed algorithm and that of the spatio-temporal oriented energies method [8]. The method presented in this paper shows superior performance. We attribute this to the fact that it accounts for contextual information in the scene and hence, it is capable of learning complicated behaviors. Although adding contextual information increases the computational complexity of the STC algorithm when compared to local approaches, it is still fast enough for real-time abnormality detection and localization.

Although the experiments described above indicate that our method can detect complicated abnormal behaviors in realistic scenes (UCSD pedestrian dataset and subway surveillance videos), we also conducted experiments for the fourth dataset. Although this dataset contains relatively simple abnormal events, we tested it to evaluate the effect of continuous learning under variable and difficult illumination conditions. We followed the same strategy for initialization of the algorithm as in [8], in which the first 800 frames of the Train video and the first 200 frames of the Belleview and Boat-Sea video sequences were considered to be the initialization frames (these contain a total of 19218, 2918, and 2207 frames, respectively). We compared the results with two alternative pixel-level anomaly detection methods: spatio-temporal oriented energies [8] and local optical flow [3]. Although the abnormalities in this dataset are actually low level motions, we exclude pixel-level background models and behavior template approaches [30] from our comparisons as they do not achieve acceptable results [8]. The precision-recall curve of the STC method and two alternatives are presented in Fig. 16
                        .

Comparing first the performance in Fig. 16 of the two strategies (red and blue curves) employed by STC, it is obvious that using simultaneous and continuous learning and detection of abnormalities (red curve) is superior to employing only an initial training set (blue curve). On the other hand, we observe that simple local optical flow features, combined with online learning [3] (black curve), do not yield acceptable results in the former case. Notwithstanding this, we also note that [3] was actually fairly capable of detecting abnormalities in other realistic datasets (Tables 2 and 3). Therefore, it appears that the optical flow approach (black curve) has difficulty capturing temporal flicker and dynamic textures. In the case of rapid changes in illumination, using a more complex feature descriptor, such as oriented energies (green curve) in [8], produces slightly better results than STC (the Train sequence) with faster execution time. On the other hand, we stress that this method cannot be used for more complex behaviors for two reasons: it is too local and does not consider contextual information.
                           24
                           Experimental results presented in Table 2 and Fig. 15 also supports this claim.
                        
                        
                           24
                         
                        Fig. 17
                         illustrates two examples of abnormal behaviors in which this method fails.

As STC creates a codebook to group similar video volumes, it is necessary to analyze the effect of different codebook sizes on the performance of the algorithm. This is achieved by changing the threshold, ∊, during codeword formation (see Section 3.1). Various threshold values were used and the EER calculated. In Fig. 18
                        a, the EER value for frame level detection is plotted as a function of the codebook size (number of codewords) for the UCSD pedestrian dataset. We observe that large threshold values produce small codebooks, resulting in inadvertent merges of video volumes. This means that some local information may be lost, and furthermore, anomalous events may be grouped with the normal ones. On the other hand, as the number of the codewords increases, the algorithm stores more volumes, and in the extreme case, would be similar to the original IBC method. Using larger codebooks demands more memory and dramatically increases computational time, so that online implementation would become impossible. Although there is a trade-off between codeword size and the performance of the algorithm, it can be inferred from our experiments that using relatively small codebooks (e.g., 20 codewords) achieves acceptable results for anomaly detection.

Another major concern for learning algorithms in videos surveillance systems is the size of the training set, that is, how many valid examples are necessary for anomaly detection in a new video. We have tested this for STC using videos containing valid behaviors. The video size ranged from short sequences of 50 frames to longer ones containing 400 frames. Fig. 18b shows the learning curve for UCSD Ped 1 and Ped 2 based on the EER. We observe that convergence is very fast. Therefore the proposed method is capable of detecting suspicious actions by observing just a few valid behaviors (∼150 frames). Since, as indicated in Table 1, the present version of the program runs at about 4–5 frames per second, we can infer that initialization requires about 20 s for this dataset.

@&#SUMMARY@&#

The results presented in this paper indicate that the STC method has a competitive performance (in terms of accuracy and computational cost) compared to the other approaches for anomaly detection for four challenging datasets. Moreover, it is fast enough for online applications and requires fewer initialization frames. When a separate training set is not available, the algorithm is capable of continuously learning the dominant behavior in an unsupervised manner while simultaneously detecting anomalous patterns. Clearly, this is the preferred behavior for any potential visual surveillance system operating in an unconstrained environment.

Overall, the STC algorithm produces similar results to the state-of-the-art for complicated abnormality patterns, while the computational cost is much lower. On the other hand, for local abnormalities, such as changes in background and temporal flicker in a scene with a complicated background, the method presented in [8] appears to be faster than STC, but weaker at dealing with the non-local patterns created by anomalous behaviors.

The main advantage of STC is that it takes into account the compositional information of the video volumes in a large region. Notwithstanding the simple temporal difference feature used in this paper to describe the video volumes in STC, the algorithm is still capable of handling significant illumination variations. Thus using more complicated ones, most likely would further enhance the outcome. Although our results indicate that the STC method has competitive performance compared to other approaches, it still yields some errors. Analyzing these indicates that occlusion is the major source of error in crowded scenes. This was predictable as the video data were obtained using a single camera. Based on the experiments, we can summarize the results of our study as follows:
                           
                              In the case of complicated abnormal behaviors without drastic changes in illumination or dynamic backgrounds (in Walking patterns, UCSD pedestrian and Subway surveillance datasets):
                                    
                                       (a)
                                       STC outperforms all other realtime and non-realtime methods (except IBC) in terms of abnormality detection and localization.

STC produces similar results to IBC with vastly fewer computations.

In the case of simple abnormal events (motion/direction detection in the fourth dataset) with dynamic backgrounds and variable illumination conditions:
                                    
                                       (a)
                                       Continuous learning makes STC capable of handling environmental changes. Moreover, it is more robust to gradual changes, as it requires updating the pdfs to learn newly observed behaviors.

For drastically changing background and illumination, spatio-temporal oriented energy filters [8], which is dedicated to pixel level motion and direction detection, achieved better results than STC.

@&#CONCLUSION@&#

This paper presents a fast method for detecting anomalous patterns in densely sampled videos, based on spatio-temporal volumes. Given a short sequence containing valid behaviors, the method reconstructs newly observed behaviors using known examples of valid behaviors. The method computes the likelihood of each pixel in each frame by analyzing a relatively large contextual region around it. The compositional relationships of these spatio-temporal arrangements of volumes are modeled using a probabilistic framework. The volumes are grouped using a codebook based on their spatio-temporal information, which significantly reduces the computational time required for computing similarity. Using these codes, the proposed algorithm produces a likelihood or saliency map of all pixels in each frame, from which the anomalous patterns are inferred by selecting video arrangements with very low likelihood of occurrence.

We have tested the algorithm for anomaly detection on four popular benchmarks and shown that the algorithm is both effective and robust for both anomaly detection and localization tasks. Moreover, the results are highly competitive with state-of-the-art methods. However, a major advantage of our approach is that it does not require any feature analysis, background/foreground segmentation and tracking, and is susceptible to on-line real-time analysis. Moreover although our results are similar to IBC, we note that the latter requires significantly greater computational time since it compares all spatio-temporal volumes in the query to the previously accumulated dataset. In addition, STC does not require a large amount of valid behaviors for training, since the inferences can be made with as little as one sample of valid activities. Thus the initialization of the algorithm is very simple. We also emphasize that we require no prior knowledge of suspicious actions since these are inferred automatically.

Based on the experimental results, we summarize the method as follows:
                        
                           1.
                           It can precisely localize anomalous patterns in a video frame and achieves this comparable to the state-of-the-art.

It handles uncertainty during codeword assignment to avoid error propagation to the inference mechanism.

The similarity computation for each ensemble in a video is O(K
                              ×
                              M
                              ×(M
                              +1)), in which K is the number of the spatio-temporal volumes in an ensemble and M is the total number of codewords. Thus, by keeping the number of codewords small enough, our method is much faster than either IBC or MDT.

Compared to IBC in [4], it requires less memory and processing time while producing similar results.

It learns new normal behaviors incrementally on-the-fly by calculating and updating the probability density functions.

An interesting aspect of our approach is that, although a simple temporal derivative was used as the feature for the video volumes, the results are competitive with the state-of-the-art. Thus, replacing this feature by a more powerful one would definitely enhance the performance of the algorithm. A drawback of the method is that the inference of suspicious patterns requires a threshold, which was determined experimentally. On the other hand, this is generally the case for all anomaly detection methodologies; they require a specification of the minimum acceptable absolute similarity. We note that for the experiments reported in this paper, it was only necessary to employ a single threshold for all video frames in all test sequences. The performance of the algorithm could probably be improved significantly using more advanced thresholding methods, such as adaptive or hysteresis approaches.

@&#ACKNOWLEDGMENTS@&#

The authors would like to acknowledge the financial support of the Natural Sciences and Engineering Research Council of Canada (NSERC) and the McGill International Doctoral Awards (MIDA). They would also like to thank the anonymous reviewers for their helpful and cogent comments.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cviu.2013.06.007.


                     
                        
                           Supplementary video
                           
                        
                     
                  

@&#REFERENCES@&#


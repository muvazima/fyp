@&#MAIN-TITLE@&#An integrative cooperative search framework for multi-decision-attribute combinatorial optimization: Application to the MDPVRP

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           New methodology for multi-attribute combinatorial optimization.


                        
                        
                           
                           Decomposition method based on decision-set attributes of the problem.


                        
                        
                           
                           New cooperative search framework with adaptive search-guidance mechanism.


                        
                        
                           
                           Extensive numerical experiments to characterize the new methodology.


                        
                        
                           
                           Improve the state-of-art for the multi-depot, periodic vehicle routing problem.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Multi-attribute combinatorial optimization

Integrative cooperative search

Meta-heuristics

Decision-set decomposition

Multi-depot periodic vehicle routing

@&#ABSTRACT@&#


               
               
                  We introduce the integrative cooperative search method (ICS), a multi-thread cooperative search method for multi-attribute combinatorial optimization problems. ICS musters the combined capabilities of a number of independent exact or meta-heuristic solution methods. A number of these methods work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others combine the resulting partial solutions into complete ones and, eventually, improve them. All these methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm. Extensive numerical experiments explore the behavior of ICS and its interest through an application to the multi-depot, periodic vehicle routing problem, for which ICS improves the results of the current state-of-the-art methods.
               
            

@&#INTRODUCTION@&#

Combinatorial optimization problems prominently appear in many theoretical and real-life settings. A large number of methodological developments targeted these problems proposing exact, heuristic, and meta-heuristic solution methods. Parallel computing enhanced these optimization methods providing the means to accelerate the resolution process and, for meta-heuristics, to obtain higher-quality solutions for a broad range of problems (Crainic & Toulouse, 2010).

Yet, although solution methods become more powerful, the combinatorial problems one faces grow continuously in size and difficulty, as defined by the number of interacting characteristics defining their feasibility structures and optimality criteria. Such increasingly larger sets of characteristics severely challenge our methodological capability to efficiently address the corresponding problem settings. Thus, the general approach when addressing such multi-attribute, also informally known as rich, problem settings is to either simplify them, or to sequentially solve a series of restricted problems where part of the overall setting is fixed or ignored. It is well-known, however, that such approaches lead to sub-optimal solutions. Moreover, one observes in many application settings, including vehicle routing, network design, and carrier service network design, the need to comprehensively address the associated combinatorial optimization formulations to simultaneously account for “all” relevant characteristics. The current literature does not offer a satisfactory answer to this challenge in terms of methods able to efficiently address multi-attribute problem settings and provide good solutions. The goal of this paper is to contribute toward addressing this challenge.

We focus on decision-based characteristics, called decision-set attributes in the following, i.e., the sets of decisions defining the particular problem setting, and introduce the Integrative Cooperative Search (ICS), a multi-thread cooperative search method. ICS musters the combined capabilities of a number of stand-alone solution methods, exact or meta-heuristic, some of which work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others integrate the resulting partial solutions into complete ones and, eventually, improve them. These methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm. We present and discuss the ICS concept, its structure, main building blocks, and operating principles, together with a proof-of-concept of its efficiency.

To illustrate the efficiency of ICS, one must identify a problem setting sufficiently rich to warrant the application of ICS, while also providing state-of-the-art results for valid comparisons. We selected the Multi-Depot Periodic VRP (MDPVRP), which encompasses decisions on 1) selecting a visit pattern for each customer, specifying the particular periods the customer is to be visited over the multi-period planning horizon, and 2) assigning each customer to a depot for each visit. This multi-attribute problem was considered until quite recently as difficult to address as a whole. New exact (Baldacci, Bartolini, Mingozzi, & Valletta, 2011; Baldacci & Mingozzi, 2009) and meta-heuristic (Vidal, Crainic, Gendreau, Lahrichi, & Rei, 2012) contributions have re-defined the state-of-the-art proposing valuable best-known solutions (BKS) to which the results of ICS are confronted.

The main contributions of this paper are to:

                        
                           1.
                           Introduce and formally describe a new meta-heuristic solution framework for multi-attribute combinatorial optimization problems; ICS is general, flexible, and scalable in the number of attributes defining the problem at hand;

Define and exploit a functional decomposition of such problems along decision-set attributes;

Illustrate ICS through an application to a well-known multi-attribute problem setting, the MDPVRP, for which ICS improves the results of the current state-of-the-art methods and discuss how to apply the methodology to other combinatorial optimization problem classes;

Show the interest of the proposed method by experimentally evaluating its components.

This paper is organized as follows. Section 2 discusses the motivation for our work and identifies the sources of inspiration for the methodology we propose. Section 3 introduces the fundamental concepts underlining the Integrative Cooperative Search methodology, particularly the decision-set attribute-based decomposition and the ICS algorithmic structure. We illustrate these concepts and methods through an application to the MDPVRP (Section 4.1), as well as an analysis on an extensive set of experiments (Section 4.2.) We finally conclude.

We aim to address extended versions of classical combinatorial-optimization problems, which are NP-hard in their basic forms. These versions generally aim to answer the requirements of real-world cases and involve several “new” characteristics that must be considered while searching for feasible solutions of high quality. The set of decisions to be considered is then much broader than for the basic problem settings, each new group of characteristics and decisions compounding the difficulty of the problem and complicating the solution process, particularly when one aims to address them simultaneously.

Two examples, selected from major operations research applications, illustrate this observation. Network design aims to select among a set of possible facilities on arcs, nodes, or both, such that the demand for using the resulting network is satisfied at the minimum total cost of selecting the facilities and using the network. Many particular design problem settings have been defined during the years, the vast majority focusing on the facility-selection and demand-flow decisions (Crainic, 2000; Drezner & Hamacher, 2002; Grötschel, Monma, & Stoer, 1995; Magnanti & Wong, 1984). Crainic, Chiara, Nonato, and Tarricone (2006a) describe a realistic setting of a wireless network design problem, where the decision set includes not only the selection of base stations to cover a given territory, but also the selection of the number of antennae for each base station, as well as their height, power, tilt, and orientation.

Vehicle routing offers the second example. An extensive literature addresses the Capacitated Vehicle Routing Problem (CVRP), which aims to construct cost-efficient routes to deliver the demand of a given set of customers with a fleet of vehicles of limited capacity operating out of a unique depot (Golden, Raghavan, & Wasil, 2008; Toth & Vigo, 2002), and its many extensions reflecting the variety of applications, e.g., multiple depots, customer requirements for multi-period visits, time windows on service at customers or activities at depots, route restrictions on total distance or time, etc. (Vidal, Crainic, Gendreau, & Prins, 2013). Yet, this proliferation of VRP variants is not sufficient to address many real-world settings (Golden, Assad, & Wasil, 2002), and one increasingly observes the enrichment (the “rich” qualification first appeared in the VRP literature; Hartl, Hasle, & Jansens, 2006) of the set of characteristics considered in routing formulations.

Adding characteristics to particular problem elements, e.g., timing concerns in VRPs given time-window customer requirements, makes problems more difficult to address, but may be handled within particular algorithmic components, e.g., route generation and sequencing. Such problem extensions might thus require a more involved algorithmic component (Vidal, Crainic, Gendreau, & Prins, 2015, 2014), but does not change fundamentally the nature of the problem. Adding more decision sets to the problem, on the other hand, makes it significantly harder to address and, thus, the general approach when addressing such multi-attribute problems is to either simplify them, or to sequentially solve a series of particular cases, where part of the overall problem is fixed or ignored, or both (e.g., Golden et al., 2002; Hadjiconstantinou & Baldacci, 1998; Hartl et al., 2006; Homberger & Gehring, 1999, 2005). It is well-known that this leads to sub-optimal solutions.

So, how to proceed to build a general, scalable, and efficient method to address multi-attribute combinatorial optimization problems in a comprehensive manner? We were inspired by two major methodological concepts: decomposition and cooperative search.

Decomposition is a fundamental technique in mathematical programming (Lasdon, 2002), e.g., the Dantzig–Wolfe decomposition with column generation (Dantzig & Wolfe, 1978), Bender’s decomposition (Benders, 1962), and Lagrangian-based mechanisms (Geoffrion, 1970; Guignard & Kim, 1987), as well as in parallel/distributed computing particularly for domain or low-level functional decomposition (Alba, 2005; Bertsekas & Tsitsiklis, 1989; Crainic, Cun, & Roucairol, 2006b; Crainic & Toulouse, 2010; Gendron & Crainic, 1994; Talbi, 2006). The main objective of all these strategies is to transform a difficult-to-address formulation into a number of “simpler” ones for which efficient solution methods are available. Simplification is thus part of decomposition, the challenge of defining “simpler” sub-problems resting with the search for the right equilibrium between an easy-to-address formulation and the usefulness of the corresponding results. The challenge is present for exact and heuristic decomposition methods alike. Thus, selecting the appropriate set of constraints to dualize in a Lagrangian-based strategy is highly influential of the form and difficulty of the resulting sub-problems (e.g., Crainic, Frangioni, & Gendron, 2001, for network design). In following this decomposition idea for multi-attribute combinatorial optimization problems, we propose a heuristic strategy (Section 3.1) that aims for opportunistic simplification in generating sub-problems for which efficient solution methods already exist or may be easily developed.

Decomposition-based methods encompass three main mechanisms. The first, decomposition, defines how the problem is transformed and sub-problems are derived. The second, integration, brings together the results obtained working on the sub-problems, creates complete solutions to the original problem and, eventually, continues the decomposition-based algorithm. The third specifies the information exchanged and defines how the complete method evolves. While the actual definition of a mathematical programming decomposition method embeds these mechanisms, they must be specifically defined for heuristic strategies. We turn to the cooperative-search paradigm to define the mechanisms for the Integrative Cooperative Search method we propose.

Cooperative search (Crainic, 2005; Crainic & Toulouse, 2008, 2010) has emerged as one of the most successful meta-heuristic methodologies to address hard optimization problems (see, e.g., the surveys of Crainic, 2008; Crainic & Hail, 2005 and the books of Alba, 2005; Talbi, 2006; Talukdar, Murthy, & Akkiraju, 2003). Cooperative search is based on harnessing the capabilities of several solution methods through cooperation mechanisms providing the means to asynchronously share information while addressing the same problem instance (and create new information out of the exchanged data in advanced settings). Cooperative-search strategies are mainly defined by (1) the solution methods engaged in cooperation (including the same method with different parameter settings or populations); (2) the nature of the information shared, e.g., the current best solution and contextual information about the status of the search; (3) how the sharing proceeds and how the global search is controlled: diffusion among “neighboring” solution methods arrayed in particular communication architectures, e.g., fine-grained, cellular GA (e.g., Cantú-Paz, 2005; Luque, Alba, & Dorronsoro, 2005) and multi-level cooperative search (Toulouse, Thulasiraman, & Glover, 1999); direct exchanges among processes, e.g., coarse-grain, island GA (Cantú-Paz, 2005; Luque et al., 2005), A-teams (Talukdar, Baerentzen, Gove, & de Souza, 1998; Talukdar et al., 2003), and Collegial Asynchronous strategies (Crainic, Toulouse, & Gendreau, 1996, 1997); indirect exchanges through a common data repository and management structure, e.g., adaptive (Badeau, Gendreau, Guertin, Potvin, & Taillard, 1997; Berger & Barkaoui, 2004; Rochat & Taillard, 1995) and central memory (Bouthillier, Crainic, & Kropf, 2005; Crainic et al., 2006a; Crainic et al., 1996, 1997; Jin, Crainic, & Løkketangen, 2014) strategies; (4) how the exchanged information is used globally (if it is used at all), and how each process uses the received information. ICS generalizes the adaptive/central-memory class of cooperative strategies (thereafter called central memory).

We now define the fundamental concepts and general framework of the proposed ICS methodology. The instantiation of this framework to particular applications is illustrated in Section 4.1.

ICS combines the ideas of opportunistic decomposition and cooperative search. The decomposition mechanism (Section 3.1) yields simpler but meaningful problem settings, in the sense that efficient algorithms, called hereafter solvers, can be “easily” obtained for these partial problems either by opportunistically using existing high-performing methods or by developing new ones. The cooperative-search framework addressing the complete formulation (Section 3.2) brings together the resulting partial problems and their associated solvers (Section 3.3), and the integration mechanisms reconstructing complete solutions (Section 3.4). The central-memory and search-guidance mechanisms are described in Section 3.5.

We aim for a decomposition mechanism that takes advantage of and preserves the structure of the problem at hand. We therefore propose a structural problem decomposition along sets of decisions variables.

Let 
                           
                              x
                              ∈
                              X
                           
                         be the set of decision variables of the problem at hand, and let δ be a set of indexes identifying a particular subset of x. The decision-set attribute decomposition identifies Δ sets of decision variables and defines a partial-problem formulation 
                           
                              
                                 Π
                                 δ
                              
                              
                                 (
                                 
                                    
                                       x
                                       δ
                                    
                                    ˜
                                 
                                 )
                              
                           
                         for each decision set xδ
                        , δ = 1
                           
                              ,
                              …
                              ,
                           
                         
                        Δ, by fixing the corresponding variables to suitably selected values 
                           
                              
                                 x
                                 δ
                              
                              ˜
                           
                         (and adjusting constraints, if needed). The sets 
                           
                              
                                 δ
                                 1
                              
                              ,
                              …
                              ,
                              
                                 δ
                                 Δ
                              
                           
                         are not required to induce a partition of the feasible domain. In mathematical-programming terms, the decision-set decomposition may be viewed as a multiple simultaneous restriction (Geoffrion, 1970), where the fixed variables are part of the solution to the restricted formulation. Notice that the proposed decomposition method does not discard variables and, thus, any solution to any partial problem constructed according to this definition may be considered for the complete formulation.

The selection of the decision-sets is specific to each application case, decision variables being clustered to yield known or identifiable optimization problem settings. Two examples to illustrate the application of the decision-set attribute decomposition. First, defining the Δ sets of decision variables according to the spatio-temporal characteristics of the problem elements, e.g., node coordinates in a space-time network representation, yields the well-known data-decomposition procedure (e.g., Taillard, 1993, for VRP). Second, fixing the customer-to-depot assignments in the MDPVRP illustration of Section 4.1 yields a periodic VRP, while fixing the patterns for all customers yields a multi-depot VRP.

ICS implements the decision-set attribute decomposition described above and takes the form of a self-adaptive cooperative meta-heuristic concurrently evolving and combining several populations, one corresponding to complete solutions to the initial problem, each one of the others addressing specific dimensions of the problem resulting from the decomposition. ICS integrates a purposeful-evolution mechanism geared to produce high-quality complete solutions.


                        Fig. 1
                         illustrates the structure and components of ICS, which are detailed in the following sub-sections. The decision-set decomposition of the original problem yields a number of partial problems. Each partial problem is addressed by a specific Partial Solver Group (PSG), which encompasses one or several solution methods. Two PSGs are illustrated in Fig. 1 schematically showing the respective partial solver sets, the central memories and their content, and the local search coordinators (the LSC hexagonal boxes).

Concurrently with PSG activities, integrators select partial solutions from PSGs (represented by full arrows in the figure), combine them to create complete ones and sent them (full arrow) to the Complete Solver Group (CSG). (All solutions are “complete” in ICS; we use the terms “partial” and “complete” only to indicate the solver group of origin.)

The Complete Solver Group may include solvers to enhance the complete solutions generated by the integrators, but its main task is to manage the pool of complete solutions and the context information received from the PSGs and to extract out of these the information required by the purposeful guidance of the partial and global searches performed by the Global Search Coordinator (GSC). Dashed-line arrows represent the exchange of information supporting the cooperation.

As already mentioned, ICS generalizes the central-memory cooperative search methodology (and includes data parallelism as a special case). ICS tackles the problem in hand through the combined work of several different solvers, which have each been assigned a particular role and which indirectly and asynchronously interact through a two-layer central-memory and guidance mechanism. The cooperation is built on these indirect exchanges through collections of elite solutions, communications being triggered either by the internal logic of each solver deciding when to send its updated information (e.g., new best solution) to the central memory or to request new solutions from it, or by a local or global search coordinator reacting to changes in the status of the memories and the search trajectory. Solvers thus never interact directly, which has been shown to induce very good performance in terms of solution quality, speed, and robustness in its “classical” central-memory applications (see the literature review of the previous section).

Cooperation is facilitated by the choice of a unique solution representation for all solvers and solver groups obtained by fixing rather than eliminating variables when defining partial problems, facilitates communications, information extraction and knowledge creation from exchanged solutions, as well as the development of generic solvers. We now examine each component in more details.

The number of Partial Solver Groups equals that of the partial problems obtained through the decision-set decomposition. Each PSG is thus dedicated to a specific partial problem and focuses on a particular subset of the original decision variables, the values of the other ones being fixed, directly or indirectly, through communications with the Global Search Coordinator. A PSG
                           i
                         is composed of a set of Partial Solvers
                        
                           
                              
                                 
                                    S
                                 
                                 i
                              
                              ,
                           
                         a central memory, and a Local Search Coordinator (LSC).

Partial Solvers may be any exact or heuristic solution method, but need to address efficiently the corresponding partial problem. They are thus application specific. ICS does not impose any limit on the number of solvers within a PSG, but the usual concerns related to an efficient implementation of parallel methods (e.g., computer architecture, communication protocol, programming language, etc.) also apply in this context.

Communications and exchanges among solvers within a PSG are performed through the central-memory mechanism, made up of the population of elite solutions 
                           
                              
                                 P
                              
                              i
                           
                         generated by the solvers, and the application-specific context information, under the supervision of the LSC. The solutions of the central memory may have different fixed-variables values. Communications are generally initiated by a solver desiring to deposit or requesting solutions and context information.

Guidance instructions are issued by the local or global search coordinators. The LSC functionality may include monitoring the performance of the Partial Solvers and acting when this performance becomes unsatisfactory (e.g., a given Partial Solver did not send any solution for a given time or all its latest contributions to the central memory are weak compared to the current best solution). The LSC could then, for example, force a Partial Solver to restart from a suitable solution in memory (e.g., changing the population of a genetic algorithm), modify the search parameters, or even change the solution method.

Similar behavior is also triggered by messages from the Global Search Coordinator (GSC). We discuss in more depth the role of the GSC later in this section, but want to emphasize that a thorough exploration of the solution space of the original problem generally requires the modification of the focus of particular Partial Solver Groups. The modification generally proceeds through changes to the 
                           
                              
                                 x
                                 δ
                              
                              ˜
                           
                         values defining the search space of given 
                           
                              
                                 Π
                                 δ
                              
                              
                                 (
                                 
                                    
                                       x
                                       δ
                                    
                                    ˜
                                 
                                 )
                              
                           
                         PSGs, but may also involve the definition of the Δ decomposition set. This modification is communicated to the corresponding LSC that, in turn, instructs Partial Solvers and adjusts (initialize or modify) parameter values.


                        Integrators play an essential role in the ICS methodology. While Partial Solvers address a single aspect of the original problem, with a number of attributes fixed, Integrators build complete solutions by mixing partial solutions with promising features from these various populations. Integrators select solutions in the populations of one or more PSGs, combine them to yield complete solutions, and transmit some or all of these new solutions to the Complete Solver Group.

Integration aims for solution quality, the transmission of critical features extracted from the partial solutions, and computational efficiency. Based on the largely acknowledged idea that population diversity contributes to the success of population-based meta-heuristics (e.g., Vidal et al., 2012), integration also aims to generate good but diverse solutions and, thus, increase the diversity of the population of complete solutions. Finally, integration should support the global computational efficiency of the method, by feeding new solutions to the CSG at a sustained pace to avoid unnecessary waiting and idling of the corresponding processes. This can be achieved by including several Integrators in an ICS implementation, as illustrated in Section 4.1.

The simplest and most general Integrator consists in selecting partial solutions to pass directly to the Complete Solver Group. It thus provides the means to efficiently add to the population of complete solutions individuals of high quality with respect to solution value or the inclusion of decision combinations frequently encountered in high-quality solutions. The latter characteristic is meaningful in terms of population diversity and the global guidance of the search (Section 3.5). Moreover, the speed of execution implies an almost continuous flow of new solutions toward the CSG, which makes such an integrator a recommended feature of an ICS implementation.

More advanced methods combine partial solutions. Population-based methods, genetic algorithms (e.g., Vidal et al., 2012, used in the illustrative application of Section 4.1) and path relinking (e.g., Vahed, Crainic, Gendreau, & Rei, 2013), in particular, have proved their flexibility and stability in combining solution characteristics to yield high-quality solutions. A different methodological approach to heuristic solution integration was recently introduced by Hachemi, Crainic, Lahrichi, Rei, and Vidal (2014). The authors start with a set of solutions, each characterized by a vector identifying the critical variables, i.e., those variables whose values in the respective solution represent desired attributes and propose a number of optimization problems to generate new solutions preserving critical variables. The models differ in the type of input they expect (critical variable-vectors that are disjoint or not) and the requirement to include all or part of the critical variables in their output. We use two of these integrators in the illustrative application of Section 4.1.

Integration, except for the simplest one described above, is application specific and so is the number of integrators to include in an ICS implementation. Given the objectives stated above, we suggest at least two: one transferring good partial solutions to the CSG and a second combining partial solutions into complete ones. This number could be slightly increased when several high-quality integrators, and the associated computing resources, are available. We have thus included four integrators on three processors in the application of Section 4.1.

The Complete Solver Group (CSG) component of ICS is organized similarly to the PSGs (the complete-solver set is optional, however) and plays an important double role. First, it receives complete solutions from integrators and, when solvers are included, it enhances them thus creating new ones. It is from the complete solution set P that the final solution to the initial problem is extracted once the stopping conditions are verified. We call Complete Solver Coordinator (CSC) the part of the CSG performing these tasks.

Second, the CSG includes the guidance mechanism composed of the Global Search Coordinator and the corresponding complete context information. The latter includes various measures characterizing complete solutions in P: the cost or fitness-type of value reflecting multiple solution characteristics, membership to a specific class of solutions (e.g., high, medium, poor quality) information on the solver or integrator that yielded it, etc. It may also include an image of the global search through statistical information (memories) on the evolution of solutions in the complete and partial populations, the contribution of solutions and their components (e.g., routes or arcs in VRP) to the evolution of the search, the relative performances of PSGs and Integrators, etc. Finally, the complete context information contains the complete or partial solutions, and associated measures, generated by the GSC and sent to PSGs and Integrators as part of the guidance process.

The Global Search Coordinator fulfills monitoring and guidance tasks. Monitoring is performed by following the evolution of the PSGs (through the information they transmit or by checking the evolution of their central memories—see Section 3.3) and that of the complete context information (built based on this information). Monitoring provides the means to detect undesired situations, e.g., loss of diversity in the partial or complete populations, stagnation in improving the quality of the current best solution, awareness that some zones of the solution space—defined by particular values for particular decision sets—have been scarcely explored, if at all, and that the search should be diversified in that direction, and so on.

Thresholds on such global performance measures trigger guidance operations, the GSC performs by sending “instructions” to Partial Solvers and Integrators. The particular type of guidance is application specific, but instructions may modify the values 
                           
                              
                                 x
                                 δ
                              
                              ˜
                           
                         of the fixed attributes for a specific Partial Solver to orient the search toward a different area, change the attribute subset under investigation (i.e., change the decomposition of the decision-set attributes), or modify/replace the solution method in a Partial Solver or Integrator. The last two types of instructions significantly modify the structure of the global search and should therefore be used rather infrequently to respond to a significant issue in the performance of the method, e.g., a solver is constantly under-performing compared to the others.

The first type of instructions, on the contrary, makes up the core guidance mechanism of the method and is implemented in the application discussed in Section 4.1. Such instructions must reflect the particular structure of the problem and solver at hand and it is therefore application specific. In general, they take the form of a particular solution or solution set being sent to re-initialize a given partial solution set (re-initialization may be complete or partial, retaining in the latter case a few very good and diverse solutions) and thus re-start the search of the respective PSG. Additional context information (e.g., the promising arc patterns of Bouthillier et al., 2005) may complete the guiding instructions, to further inflect the search trajectory toward regions that appear promising from the point of view of the global search.

The general ICS framework we introduced can be applied to any multi-attribute combinatorial problem class for which a decision set decomposition may be defined. The next section illustrates the application of the ICS methodology to such a problem class, which is then used to analyze the behavior and performance of the proposed method.

@&#EXPERIMENTS@&#

Our experimental work had a twofold objective. First, to perform a proof-of-concept of ICS through an application to a multi-attribute combinatorial optimization problem and, second, to evaluate the performance of the method. We selected the multi-depot periodic vehicle routing problem (MDPVRP), a known problem-setting context with well-acknowledged results and performance measures, which was also quite challenging until very recently. We start by detailing how to use ICS through the MDPVRP application (Section 4.1), and continue with the performance analysis of ICS (Section 4.2).

Briefly, the multi-depot periodic vehicle routing problem (Mingozzi, 2005; Vidal et al., 2012) is defined on a multi-period planning horizon, each customer requiring service several times during this planning horizon according to one of a particular set of pre-defined visit patterns (i.e., lists of periods when visits may occur). Service is provided out of a set of depots, operating in all periods, by a homogeneous fleet of limited-capacity vehicles. The distribution of the fleet among depots is known and the same for all periods. The MDPVRP aims to select a depot and a visit pattern for each customer, with services in different periods to the same customer being required to originate at the same depot, such that the total cost of distribution is minimized. The Annex displays a formulation for the MDPVRP inspired by Vidal et al. (2012).

The literature (see Vidal et al., 2012, for a detailed review) shows a richer set of contributions for two restrictions of the MDPVRP, the periodic VRP (PVRP) where service proceeds out of a single depot, and the multi-depot VRP (MDVRP) where the planning horizon has a single period only. Most contributions to the MDPVRP did not consider all attributes simultaneously, but rather applied a successive-optimization approach (e.g., Hadjiconstantinou & Baldacci, 1998; Kang, Lee, & Lee, 2005; Yang & Chu, 2000). Vidal et al. (2012) proposed a hybrid genetic methodology, the Hybrid Genetic Search with Adaptive Diversity Control (HGSADC), which addresses all attributes simultaneously and is the current state-of-the-art method for the MDPVRP, as well as for the PVRP and the MDVRP.

Summing up the presentation of Section 3, to apply ICS to any given problem, one has to specify (1) the decision-set attributes for the decomposition; (2) the state of the art algorithms making up the solvers addressing the resulting partial problems; (3) the organization of each Partial Solver Group including the Local Search Coordinators; (4) the integrators reconstructing complete solutions; and (5) the Complete Solver Group with the Global Search Coordinator mechanism. We follow this order in detailing the application.
                     

We are opportunistic in our implementation, aiming to take advantage of the quality of the solvers available in the literature for the PVRP and the MDVRP. We therefore decompose the MDPVRP along the depot and period decision sets to create two partial problems. The first is defined by fixing customer-to-depot assignments and is addressed within the PSG-fixDep Partial Solver Group. Notice that fixing customer-to-depot assignments allows us to separate the resulting problem into depot-specific periodic VRPs optimizing pattern assignments and routing decisions. Symmetrically, the second partial problem is defined by fixing pattern selections for customers and is addressed within the PSG-fixPat Partial Solver Group. The decomposition thus yields a multiple depot VRP optimizing depot assignment and routing decisions for each period. Notice that, fixing the customer pattern selections simplifies the problem but does not lead to a separable formulation as previously, since the depot assignment for each customer must be consistent among different periods.

Each PSG is made up of a number of solvers, a central memory where elite solutions are kept, and an LSC managing the central memory and interfacing with the Global Search Coordinator.

Two algorithms were used in the implementation as both complete or partial solvers, the HGSADC of Vidal et al. (2012) and GUTS, a generalized version of the Unified Tabu Search (UTS) of Cordeau, Laporte, and Mercier (2001). HGSADC combines the exploration capability of population-based evolutionary search, the aggressive-improvement strength of neighborhood-based local search to enhance solutions newly created by genetic operators, and a solution evaluation function driven by both solution quality and contribution to the population diversity, which contributes to progress toward diverse and good solutions. GUTS is a tabu search-based meta-heuristic implementing advanced insertion neighborhoods and allowing the exploration of unfeasible solutions by dynamically adjusting penalties on violations of vehicle capacity and route duration constraints. Both methods use relaxation of vehicle-capacity and route-duration constraints combined to penalization of infeasibilities in the evaluation function. They also use well-known VRP local neighborhoods based on pattern-change, depot-change, inter and intra-route movements.


                           Algorithm 1 schematically presents the current implementation of a solver within a PSG, using GUTS and HGSADC, respectively. The general procedure is the same, differences reflecting only from the nature of the two algorithms, neighborhood and population-based, respectively. It starts with a solution 
                              
                                 S
                                 
                                    i
                                    n
                                    i
                                 
                              
                            extracted from the central memory and proceeds with the current restrictions on pattern and depot assignments imposed by the definition of the PSG and the variable fixing. In the case of GUTS, 
                              
                                 S
                                 
                                    i
                                    n
                                    i
                                 
                              
                            is simply considered an initial solution to be enhanced by the algorithm. In the case of HGSADC, an initial population of individuals is generated as in Vidal et al. (2012) considering the allowed pattern and depot assignment alternatives. 
                              
                                 S
                                 
                                    i
                                    n
                                    i
                                 
                              
                            is then added to this population. Each algorithm is run until 
                              
                                 I
                                 
                                    t
                                    
                                       e
                                       n
                                       d
                                    
                                 
                                 =
                                 5000
                              
                            successive iterations (number of local-search moves for GUTS, number of generated individuals for HGSADC) have been performed without improvement of the best solution. When this threshold is reached, the solver restarts from a new solution from the elite set. Any improving solution is sent to the central memory if it remains the best for at least 
                              
                                 I
                                 
                                    t
                                    
                                       c
                                       o
                                       m
                                       m
                                    
                                 
                                 =
                                 200
                              
                            successive iterations, and thus the central memory receives only solutions known to require some effort for further improvement.

The LSC sends to the solver a new solution selected from the central memory after 
                              
                                 I
                                 
                                    t
                                    
                                       c
                                       o
                                       m
                                       m
                                    
                                 
                              
                            iterations. This solution becomes the new starting solution of GUTS and is included in the population of HGSADC, if it improves upon the current best solution of the solver. The solutions sent to the solvers are selected by binary tournament, using the evaluation function of Vidal et al. (2012). To avoid sending the same solution multiple times, any solution which a solver has worked on until the termination criteria is marked with a flag and cannot be received again by the same solver. A solution, which has been considered by all solvers without success, remains in the elite set for the purpose of integration, exchange with the GSC, and bookkeeping only. A Partial Solver Group may include any combination of a number of GUTS and HGSADC solvers, each combination yielding a different PSG instance. We investigate the impact of such combinations on ICS performance in Section 4.2.

When including population-based solvers in a PSG, one has to address the issue of how to define the corresponding populations with respect to the central memory. We consider two main cases. The first setting, which we name encapsulated, provides each population-based solver (HGSADC in our case) with a dedicated population, exchanges of improved solutions taking place through the central memory. The second is the sharing setting, where the central memory directly serves as population for all HGSADC solvers involved in the cooperation. In this case, flags are not used to mark solutions, and the role of the partial solver simply comes to iteratively receiving a pair of individuals, performing a crossover and a local search, and sending the resulting solution to the central memory (Line 2–4 in the HGSADC iteration of Algorithm 1). Notice that the two individuals selected for the crossover operation in the sharing version do not necessarily have the same depot or patterns associated with customers, and that the crossover operator will further modify these assignments.

Four Integrators operate in parallel in the current MDPVRP application. Each Integrator performs one specific integration task. The Integrators instantiate the concepts stated in Section 3.4, a simple one passing good solutions to the CSG, the other three starting from pairs of partial solutions 
                              
                                 S
                                 
                                    f
                                    i
                                    x
                                    D
                                    e
                                    p
                                 
                              
                            and 
                              
                                 S
                                 
                                    f
                                    i
                                    x
                                    P
                                    a
                                    t
                                 
                              
                            randomly selected among the best 25 percent of the PSG-fixDep and PSG-fixPat central memories, respectively. Algorithm 2
                            schematically presents the current implementation of the four Integrators:

                              
                                 
                                    
                                       
                                          I
                                          BEST
                                       
                                    
                                 
                                 Simple Integrator transmitting the newly improved best solution from of a PSG to the CSG. The best solutions of each PSG are thus rapidly made available for sharing with the other PSG and for extraction of relevant information for global guidance.

Applies the crossover operator of HGSADC Vidal et al. (2012) generating a new individual, which is then enhanced applying the education operator of HGSADC.

The integrator (Hachemi et al., 2014) aims to transmit the attributes for which there is “consensus” in the input solutions. It thus starts with the customer visit patterns of the 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             P
                                             a
                                             t
                                          
                                       
                                     solution and fixes those that are also selected in the 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             D
                                             e
                                             p
                                          
                                       
                                     solution. Similarly, it starts with the customer-to-depot assignments of 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             D
                                             e
                                             p
                                          
                                       
                                     and fixes those that also appear in 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             P
                                             a
                                             t
                                          
                                       
                                    . The resulting restricted formulation is then addressed by means of HGSADC.

Also introduced by Hachemi et al. (2014), it focuses on promoting the attributes of the input solutions, instead of forcing them as in the previous case. It proceeds by adding to the objective function of the MDPVRP a penalty term counting the number of occurrences of differences in customer visit patterns and customer-to-depot selections of the current solution with respect to the respective values in the 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             P
                                             a
                                             t
                                          
                                       
                                     and 
                                       
                                          S
                                          
                                             f
                                             i
                                             x
                                             D
                                             e
                                             p
                                          
                                       
                                     solutions.

The Complete Solver Group is made up of a central memory, which includes the complete-solution set, as well as the context information and the guiding solutions built by the GSC. As indicated in Section 3.5, the CSG may also include a number of solvers working on complete solutions, in which case, a Complete Solver Coordinator is present to manage exchanges between the solvers and the central memory. We investigated the performance of ICS with and without solvers in the CSG, the same two algorithms, GUTS and HGSADC, being used in the former case, and report the results in Section 4.2.

The Global Search Coordinator assumes the threefold role of 1) building the search contextual information, 2) building new guiding solutions to orient the search towards promising features, and 3) monitoring the status of the solver groups, sending guiding instructions when necessary. Algorithm 3
                            schematically presents the current implementation of these tasks.

The search context information is built by collecting statistical data on (customer, depot, pattern) triplets entering the complete solution set by computing the number of occurrences (frequency) of each triplet in the complete solution set and by recording the cost of the best solution containing the triplet.

The GSC guides the search trajectory of a particular PSG by sending instructions (Section 3.5) whenever monitoring shows that the search is not advancing properly within that solver group. Monitoring proceeds by interrogating the central memories of the PSGs to check whether more than five non-flagged individuals are available (GUTS and encapsulated-HGSADC implementations), and whether improving solutions have been received during the 
                              
                                 I
                                 
                                    t
                                    
                                       c
                                       o
                                       n
                                       t
                                       r
                                       o
                                       l
                                    
                                 
                                 =
                                 2000
                              
                            last solutions. Whenever one of these two criteria is not fulfilled, the GSC sends search trajectory-modifying instructions to the particular PSG.

Guiding instructions take the form of three solutions, which are randomly selected—with uniform probability—from either the complete solution set (with 50 percent probability), or from a set of guiding solutions maintained by the GSC (with 50 percent probability). The receiving PSG adds directly these solutions to its own central memory. Migration is preceded by a reset of the PSG population, all solutions being replaced by new randomly-generated ones.

The guiding solutions are continuously generated and stored in a particular pool, to reflect the current status and the history of the search represented by the context information. The GSC (see Algorithm 3) proceeds by selecting, with uniform probability for each customer, one promising triplet with respect to the search history, that is, a triplet that appears in at least one solution in P with a cost difference less than 3 percent relative to the current best solution in P. These promising triplets determine the customer assignments to patterns and depots in the new solution. The routes are then generated by the local search of HGSADC, and each solution is individually enhanced by a short execution of GUTS or HGSADC. The termination criterion for GUTS and HGSADC is set to 
                              
                                 I
                                 
                                    t
                                    
                                       e
                                       n
                                       d
                                    
                                    ′
                                 
                                 =
                                 2000
                              
                            successive iterations without improvement.

Extensive experimental analyses were conducted to 1) assess the performance of ICS when compared to state-of-the-art sequential methods and 2) investigate several implementation alternatives, including the potential inclusion of solvers in the complete solver group, and the choice of solver type (GUTS, HGSADC, or combinations of the two) and of cooperation strategy in the case of HGSADC (encapsulated or shared). We used the parameter settings of GUTS and HGSADC provided in their original papers to avoid any over-tuning effect. The stopping criterion was reduced to 
                           
                              I
                              
                                 t
                                 e
                              
                              n
                              d
                              =
                              5000
                           
                         to ensure a faster communication of solutions. The ICS method was implemented in C++. Experiments were run on an Altix 4700 server, using double Core processors Itanium 2 with 1.5 gigahertz cadence and a NUMAlink communication network.

Fourteen (14) processors were used for the MDPVRP experiments:

                           
                              •
                              Each PSG: 1 CPU for the central memory and the LSC, and 3 CPU for the partial solvers (2 only when solvers were included in the CSG);

The CSG: 1 CPU for the central memory and the CSC, and 2 CPU when solvers were included;

The GSC: 2 CPU, one for creating the guiding solutions (as this process is quite time consuming), and one fulfilling the remaining tasks;

Integrators: 3 CPU, I
                                 BEST and I
                                 CROSS being run on the same CPU.

This choice of task-to-CPU assignment is due to implementation simplicity and ready availability of processors. Computational experiments showed that, in practice, only 10 CPU out of 14 perform computationally-intensive tasks. The other four CPUs, dedicated to the management of the central memories and GSC monitoring, could be implemented on a single core in a more advanced implementation. We therefore consider in analyzing the results that the effective workload of ICS is approximately 10 times the load of a sequential method.

With respect to the PSG solvers, preliminary experiments showed that “pure” cooperation, involving only GUTS or HGSADC, outperforms “mixed” strategies. The main factor explaining this observation is the combination of the speed and quality of the evolution performed by HGSADC. We thus observed that, at any moment during the search, the partial solutions provided by GUTS within a mixed cooperation strategy were of less quality than the HGSADC ones and, thus, were rarely used to generate complete solutions. Consequently including an additional HGSADC solver within the cooperation was always more profitable than adding one additional GUTS. We thus investigated two classes of ICS variants:


                        Neighborhood-based solvers (GUTS) only in the solver groups. Two variants were tested in this class, ICS-GUTS and ICS-GUTS+, respectively, without and with the GUTS solvers in the CSG;


                        Hybrid genetic algorithm-based solvers (HGSADC) only in the solver groups. Four variants were tested in this class. ICS-GA1 and ICS-GA2 with the population-based HGSADC partial solvers in the sharing and encapsulated versions, respectively, and no solvers in the CSG. Their counterparts, ICS-GA1+ and ICS-GA2+ include the HGSADC solvers in the CSG.

Each variant was run ten times on each instance, recording the best solutions after 5, 10, 15, and 30  minutes of computation time. The ten MDPVRP instances pr01–pr10 of Vidal et al. (2012), derived from the Cordeau et al. (2001) data sets, were used for these tests. These instances present a uniform geographical distribution of customers coupled with a few customer clusters. The largest instances include up to 288 customers, 6 depots, 6 days, and a total of 864 deliveries. Detailed descriptions are provided in the Annex.


                        Table 1
                         sums up the performance comparison of the ICS variants and the two sequential solvers at different instances of computing time. Solution quality is reported as the average percentage of cost deviation (on all instances and all runs) with respect to the best known solutions in the MDPVRP literature, reported in Vidal et al. (2012). More detailed results are provided in Table 2
                         and the Annex.

The reported results underline the large contribution of the ICS methodological framework in enhancing neighborhood-based search such as GUTS. Thus, the solution quality improves from a 2.77  percent gap to a 0.52 percent gap when relying on the ICS cooperative framework. The improvement in the case of population-based search appears smaller but still significant, reducing the average gap from 0.42 percent  to 0.17 percent . This is impressive, given the smaller potential for improvement due to the high-quality solutions provided by HGSADC, the current state-of-the-art solution method for the MDPVRP. It should be noted that ICS also enables to obtain high-quality solutions in reduced time, the average solution quality being higher after 10 minutes of ICS than after 30 minutes of HGSADC.


                        Figs. 2
                         and 3
                         detail these results displaying comparative performance measures for the ICS variants using GUTS and HGSADC, respectively, after 5, 10, 15, and 30 minutes of CPU time. The measures are displayed as boxplots of the gaps relative to the BKS for each variant and computing time (computed considering the full set of 100 values for the 10 instances and 10 runs). The display is standard: the bottom and top of each box represent the first and third quartiles of the distribution of the corresponding set of gaps, respectively, the band inside standing for the median (the second quartile). The whiskers, vertical lines outside the boxes representing the variance of the distributions, are plotted at 1.5 times the inter-quartile space, outliers being plotted as disks.


                        Fig. 2 refers to GUTS and statistically illustrates the large enhancement to its performance brought by the ICS methodological framework. All ICS variants significantly outperform GUTS and the improvement is obtained much faster. The figure also illustrates the “convergence” of ICS-GUTS, that is, the rate of improvement in the best solution value. As already observed, the method achieves very good results fast but, increasing the search time yields improved results. The average gaps and the corresponding standard deviations decrease as is the number of outliers. Adding solvers to the CSG, the ICS-GUTS+ variant, enhances the performance of the method, but the enhancement does not appear significant for these variants.


                        Fig. 3 displays the results of the analysis for the ICS variants with HGSADC solvers, showing that the proposed method performs very well even when compared to the state-of-the art methodology. All ICS variants outperform the HGSADC meta-heuristic and better results are obtained faster. The figure shows that, similarly to the previous analysis, for these variants increasing the search time is also beneficial but, given the efficiency of the embedded solvers, the method achieves very good results much faster, particularly for the variants embedding solvers in the CSG.

A more detailed analysis of the four variants is performed further down this section, but the statistical values displayed in Fig. 3 indicate that ICS-GA2+, embedding HGSADC solvers in the CSG and encapsulated ones in the PSG, offers the highest performance. (During the complete experimentation process, this variant allowed us to find three new best solutions for the considered instance set: 5558.02 for pr05, 8254.73 for pr09, and 9776.28 for pr10; these solutions can be obtained from the authors). The first column of Table 2 specifies the instance, the next three columns report the average solution quality, the run time, and the best solution found by HGSADC, the two next groups of columns display the average and best results of ICS-GA2+ at different points in time, and the last column reports the previous BKS from the literature. For each line, the best solution is reported in boldface. New best known solutions are underlined.

Focusing on the best set of ICS variants, those including the HGSADC solvers, we now turn to two related issues: is the choice of method statistically significant on the one hand and, on the other hand, what is the impact of two particular ICS design features, the encapsulating or sharing of populations within PSGs, and the inclusion of general solvers in the CSG. We contrasted the gaps to the BKS obtained after 30  min of CPU time by the four ICS variants and HGSADC through a Friedman’s test, followed by one-on-one post-hoc comparisons using Wilcoxon tests with corrections for multiplicity. Fig. 4
                         displays the results of the experiments as a boxplot of the gaps to the BKS differences for all pairs, together with the corresponding post-hoc test results.

Friedman’s test shows that the choice of variant is significant. All ICS-GA variants are superior to HGSADC. Moreover, ICS-GA2+ is better that ICS-GA2 and ICS-GA1 indicating that using general solvers within the CSG yields an increase in solution quality. The results show (Figure 6 in the Annex) that, for short computation times (5 or 10  min), genetic algorithms that work directly on the central memories of the PSGs (sharing ICS) seem to conduct to higher-quality solutions. This observation relates to the fact that such a tight cooperation enables a fast exchange of solutions for an aggressive intensification. On longer runs, the encapsulated version of ICS, where each genetic solver operates its own population, seems to lead to better solutions, thanks to an increased diversity of the search trajectories.

Of particular importance is the fact that, when solvers are not used in the CSG, the ICS solution quality does only slightly decrease (a 0.08 percent difference in the worst case). This illustrates the remarkable ability of ICS to produce results of similar quality to those of the best methods addressing the complete problem, with only solvers that work on partial aspects of the problem. This observation is critical when dealing with multi-attribute, rich problem settings for which integrated solvers are either not available or not sufficiently efficient. ICS becomes the method of choice in these cases.

We complete the analysis by comparing the ICS variants and the sequential meta-heuristics from the point of view of the performance distribution with respect to the trade-off between solution quality (as relative gaps to the BKS) and overall CPU effort in minutes. Fig. 5
                         illustrates this analysis. It displays average solutions obtained after one run over all instances and best-solution results over 10 runs for all instances for ICS variants embedding GUTS and HGSADC solvers, as well as for the two sequential meta-heuristics. The displayed name of each method includes the type of result, best or average (avg), and, for the ICS variants, when the solution value was collected (5, 10, 15 or 30  min). The sequential meta-heuristics were run for 30  min. Relative gaps make up the horizontal axis. Notice the difference in the range of values emphasizing the importance of embedding good solvers into ICS. One observes clearly the superiority of ICS with HGSADC solvers over ICS with GUTS solvers, which reflects that of HGSADC over GUTS. The vertical axis displays the total computing effort required by the methods. Notice that, the results for the “best” versions have computing efforts 10 times higher than those of the “avg” ones to reflect the 10 runs. Similarly, the computing efforts of all ICS variants were multiplied by 10 to reflect the multiple processors used by the method.


                        Fig. 5 also shows that the exploration capabilities of the GUTS solvers are greatly enhanced by the cooperative framework, ICS-GUTS variants offering a variety of non-dominated (gap, CPU time) trade-offs. Regarding the ICS-GA variants, the Pareto frontier is made up of ICS-GA1+best30m and ICS-GA2+best30m (the difference is too small to be noticeable), HGSADC-best, ICS-GA2+avg10m, and HGSADC-avg. For an equal CPU effort, a 10-processor parallel independent multi-search with HGSADC (HGSADC-best), seems to produce solutions of slightly higher quality than ICS-GA2+ (deviation of 0.13 percent  versus 0.17 percent ). This is remarkable as HGSADC-best corresponds to selecting the best solution out of 10 independent runs of current state-of-the-art sequential method with practically all the computing effort dedicated to the search (no parallel overhead), while ICS-GA2+ pays the overhead implementing the ICS cooperation and dedicating only two processors to improving the complete solutions.

A twofold conclusion can be drawn from these experiments. First, not surprisingly, when an efficient solution exists for a given problem, there is no reason to look for more complex methodologies. Second, ICS performs excessively well compared to state-of-the-art methods, which emphasizes the excellent performance one may expect from ICS when such a method is not available for the problem at hand.

@&#CONCLUSIONS@&#

We introduced the Integrative Cooperative Search framework to efficiently address the challenges of rich, multi-attribute combinatorial optimization problems.

ICS decomposes such complex problems along decision-set attributes and musters, within a multi-thread cooperative search framework, the combined capabilities of a number of independent exact or meta-heuristic solution methods. A number of these methods work on sub-problems defined by suitably selected subsets of decision-set attributes of the problem, while others combine the resulting partial solutions into complete ones and, eventually, improve them. These methods cooperate through an adaptive search-guidance mechanism, using the central-memory cooperative search paradigm.

We illustrated the interest of the Integrative Cooperative Search methodology through an application to the multi-depot, periodic vehicle routing problem, for which ICS enhances the results of the current state-of-the-art methods.

To apply ICS to other combinatorial optimization problems, it is sufficient to identify decision-set attributes yielding suitable partial problems. Thus, for example, the recently proposed Unified Hybrid Genetic Search methodology (Vidal, Crainic, Gendreau, & Prins, 2014) offers the means to rapidly devise high-performing meta-heuristics for a wide gamut of vehicle routing problem settings. Similarly, multi-attribute design problems may be addressed through ICS integrating efficient tabu search and path relinking meta-heuristics (Crainic et al., 2006a). This emphasizes the generality and broad applicability of the proposed ICS methodology.

@&#ACKNOWLEDGMENTS@&#

While working on this project, T.G. Crainic was the NSERC Industrial Research Chair in Logistics Management, ESG UQAM, N. Lahrichi and G.C. Crişan were postdoctoral fellows with the Chair, M. Gendreau was the NSERC/Hydro-Québec Industrial Research Chair on the Stochastic Optimization of Electricity Generation, MAGI, École Polytechnique, and Thibaut Vidal was Ph.D. student, Département d’informatique et de recherche opérationnelle, Université de Montréal. Partial funding for this project has been provided by the Natural Sciences and Engineering Council of Canada (NSERC), through its Industrial Research Chair, Collaborative Research and Development, and Discovery Grant programs, by our partners CN, Rona, Alimentation Couche-Tard, la Fédération des producteurs de lait du Québec, and the Ministry of Transportation of Québec, and by the Fonds québécois de la recherche sur la nature et les technologies through its Team Research Project program. We also gratefully acknowledge the support of the Fonds de recherche du Québec through their infrastructure grants.

Supplementary material associated with this article can be found, in the online version, at 10.1016/j.ejor.2015.05.007.


                     
                        
                           
                        
                     
                  

@&#REFERENCES@&#


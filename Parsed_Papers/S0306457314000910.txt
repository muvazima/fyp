@&#MAIN-TITLE@&#A Spanish semantic orientation approach to domain adaptation for polarity classification

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A lexicon-based domain adaptation method is proposed.


                        
                        
                           
                           Several domain polar lexicons were compiled following a corpus-based approach.


                        
                        
                           
                           The new resources are assessed over a Spanish corpus.


                        
                        
                           
                           The promising results encourage us to follow improving this domain adaptation method.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Spanish opinion mining

Sentiment lexicon

Domain adaptation

@&#ABSTRACT@&#


               
               
                  One of the problems of opinion mining is the domain adaptation of the sentiment classifiers. There are several approaches to tackling this problem. One of these is the integration of a list of opinion bearing words for the specific domain. This paper presents the generation of several resources for domain adaptation to polarity detection. On the other hand, the lack of resources in languages different from English has orientated our work towards developing sentiment lexicons for polarity classifiers in Spanish. The results show the validity of the new sentiment lexicons, which can be used as part of a polarity classifier.
               
            

@&#INTRODUCTION@&#

Opinion Mining (OM) is defined as the computational treatment of opinion, sentiment, and subjectivity in text. This new area of research is becoming more and more important mainly due to the growth of social media where users con- tinually post contents on the web in the form of comments, opinions, emotions, etc. The OM discipline combines Natural Language Processing (NLP) with data mining techniques and includes a large number of tasks (Pang & Lee, 2008). One of the most widely studied tasks is the polarity classification of reviews. This task focuses on determining the overall sentiment-orientation (positive or negative) of the opinions contained within a given document.

Although different approaches have been applied to polarity classification, the mainstream basically consists of two major methodologies. On the one hand, the Machine Learning (ML) approach (also known as the supervised approach) is based on using a collection of data to train the classifiers (Pang, Lee, & Vaithyanathan, 2002). On the other hand, the approach based on Semantic Orientation (SO) does not need prior training, but takes into account the positive or negative orientation of words (Turney et al., 2002). This method, also known as the unsupervised approach, makes use of lexical resources like lists of opinion words, lexicons, dictionaries, etc. Both methodologies have their advantages and drawbacks. For example, the ML approach depends on the availability of labelled data sets (training data), which in many cases are impossible or difficult to achieve. On the contrary, the SO strategy requires a large amount of linguistic resources which generally depend on the language, and often this approach obtains lower recall because it depends on the presence of the words comprising the lexicon in the document in order to determine the orientation of opinion. In this paper we focus on the generation of linguistic resources to tackle the problem of polarity classification using an unsupervised approach.

While opinions and comments on the Internet are expressed in any language, most research in OM is focused on English texts. However, languages such as Chinese, Spanish or Arabic, are even more present on the web. Thus it is important to develop resources to help researchers to work with these languages. The work presented herein is mainly motivated by the need to develop polarity classification systems and resources in languages other than English. Specifically, in this paper we deal with Spanish reviews. We present an experimental study over the SFU Review Corpus
                        1
                        urlhttp://www.sfu.ca/œmtaboada/research/SFU_Review_Corpus.html.
                     
                     
                        1
                      (Brooke, Tofiloski, & Taboada, 2009), which is a comparable corpus that includes opinions of several topics in English and in Spanish in different domains.

One of the open problems in OM is that of domain adaptation. Although movie reviews have been the most studied domain in sentiment analysis, a wide range of areas are being investigated such as political debates, hotels or music. However, when we train a classifier using a specific domain we need to adapt it in order to apply it to another domain. For example, the sentence “Definitively, you should read the book” most likely refers to positive polarity for Book reviews but negative sentiment for Movie reviews.

Thus the problem of domain adaptation is attracting more and more attention in OM. In this paper we carry out an experimental study of domain adaptation of linguistic resources for Spanish reviews in different domains. We have used the Spanish version of SFU, which includes 400 reviews for 8 different domains. We have generated several lists of opinionated words integrating knowledge from the different domains and we have compared the results obtained. A corpus-based approach is followed with the aim of adapting a general-purpose sentiment lexicon to a specific domain by integrating lists of opinion bearing words. iSOL
                        2
                        The iSOL resource is freely available for research purpose at urlhttp://sinai.ujaen.es/?p=1202.
                     
                     
                        2
                      (Molina-González, Martínez-Cámara, Martín-Valdivia, & Perea-Ortega, 2013) is the general-purpose sentiment lexicon chosen. The Spanish version of the SFU corpus was the corpus selected for the adaptation process due mainly to the fact that it covers 8 different domains. Following different heuristics, which will be described later, the most frequent opinion bearing words are appended to iSOL. Several experiments were carried out with the goal of assessing the new domain-specific sentiment lexicons. The analysis of the results shows the validity of the new lists.

The paper is organised as follows: Section 2 briefly describes other papers that study non-English sentiment polarity classification and, specifically work related to Spanish OM. In addition, we include some papers studying the domain adaptation problem. In Section 3 we explain the different resources used. Sections 4 and 5 present the experiments carried out and discusses the main results obtained. Finally, we outline conclusions and further work.

@&#RELATED WORK@&#

In this study we focus on two open problems in opinion mining: non-English polarity classification and the domain adaptation problem. Next, we will comment on some papers that have inspired our work.

There are some interesting papers that have studied the problem using non-English collections. For example, Denecke (2008) worked on German comments collected from Amazon. These reviews were translated into English using standard machine translation software. Then the translated reviews were classified as positive or negative, using three different classifiers: LingPipe3, SentiWordNet (Esuli & Sebastiani, 2006) with classification rule, and SentiWordNet with machine learning. In (Zhang, Zeng, Li, Wang, & Zuo, 2009) Chinese sentiment analysis is applied on two datasets. In the first one euthanasia reviews were collected from different web sites, while the second dataset was about six product categories collected from Amazon (Chinese reviews). Ghorbel and Jacot (2011) used a corpus with movie reviews in French. They applied a supervised classification combined with SentiWordNet in order to determinate the polarity of the reviews. In (Agić, Ljubešić, & Tadić, 2010) a manually annotated corpus is presented with news on the financial market in Croatia. In (Rushdi-Saleh, Martín-Valdivia, Ureña López, & Perea-Ortega, 2011) a corpus of movies reviews in Arabic annotated with polarity was presented and several experiments using machine learning techniques were performed.

Regarding Spanish, there are also some interesting studies. For example, Banea, Mihalcea, Wiebe, and Hassan (2008) proposed several approaches to cross lingual subjectivity analysis by directly applying the translations of opinion corpus in English to training an opinion classifier in Romanian and Spanish. This study showed that automatic translation is a viable alternative for the construction of resources and tools for subjectivity analysis in a new target language. In (Brooke et al., 2009) several experiments dealing with Spanish and English resources are presented. They conclude that although the ML techniques can provide a good baseline performance, it is necessary to integrate language-specific knowledge and resources in order to achieve an improvement. They proposed three approaches: the first one uses Spanish resources generated manually and automatically. The second one applies ML to a Spanish corpus. The last one translates the Spanish corpus into English and then applies the SO-CAL (Semantic Orientation CALculator), a tool developed by themselves (Taboada, Brooke, Tofiloski, Voll, & Stede, 2011). Cruz, Troyano, Enriquez, and Ortega (2008) manually recollected the MuchoCine (MC) corpus in order to develop a sentiment polarity classifier based on semantic orientation. The corpus contains annotated Spanish movie reviews from the MuchoCine website.
                           3
                           urlhttp://www.muchocine.net/.
                        
                        
                           3
                         The MC corpus was also used in (Martínez-Cámara, Martín-Valdivia, & Ureña-López, 2011) to carry out several experiments with a supervised approach applying different ML algorithms (SVM, NB,BBR, KNN, C4.5). The results are much better than those obtained with the unsupervised approach proposed by Cruz et al. (2008).

One of the barriers in the study of how to resolve the problem of polarity classification on Spanish reviews is the lack of Spanish linguistic resources for opinion mining. However, some new sentiment linguistic resources, mainly lists of opinion bearing words, have been made available in the last years. Sidorov et al. (2013) provided the Spanish Emotion Lexicon (SEL). SEL is composed of 2,036 words that are associated with the measure of Probability Factor of Affective use (PFA) with respect to at least one basic emotion or category: joy, anger, fear, sadness, surprise, and disgust. Molina-González et al. (2013) describe a new Spanish sentiment lexicon. The authors translated the Bing Liu English Opinion Lexicon (Hu & Liu, 2004) into Spanish. Subsequently, the translated version was manually corrected and improved with Spanish opinion bearing words. The result is the lexicon iSOL, which is composed of 8135 words. iSOL has been also used in (Martínez-Cámara, Martín-Valdivia, & Molina-González, 2013) with promising results.

Different methods have been proposed for tackling the domain adaptation problem. One of the primary studies in sentiment analysis is (Blitzer, Dredze, & Pereira, 2007). They use Structural Correspondence Learning (SCL) to find correspondences between features from source and target domains through modelling their correlations with pivot features. The proposed approach was successfully tested on review data from 4 domains (DVDs, books, kitchen appliances and electronics). Following the same idea, Pan, Ni, Sun, Yang, and Chen (2010) present the Spectral Feature Alignment (SFA) that uses spectral clustering to align domain-specific and domain- independent words into a set of feature-clusters. The results obtained surpass the SCL. Jiang et al. (2007) describe two distinct needs. On the one hand, instance adaptation takes into account the change of instance probability, e.g., the change of vocabulary or the change of words frequency from one domain to another; On the other hand, labelling adaptation models the changes of the labelling function, since one feature that is positive in the source domain may express the opposite meaning in the target domain. Most studies tackle the instance adaptation problem, while Xia, Zong, Hu, and Cambria (2013) propose a combination taking into account both kinds of adaptation, obtaining good results. In Ponomareva et al. (2012) graph-based approaches are applied. They model the data as a graph of documents, taking into account not only the document content but also document connectivity, which is modelled as document sentiment similarity rather than content similarity.

Like some of the studies mentioned in the previous section, herein we propose a domain adaptation method for sentiment analysis. However, we focus our study on reviews written in Spanish. In addition, in contrast to the aforementioned methods which mainly focus on machine learning algorithms, we propose a lexicon-based approach to the domain adaptation problem. We follow a very simple strategy by generating lists of opinionated words for each domain in an automatic way. The Spanish version of Taboada corpus SFU is used in our experiments. Firstly we apply a general lexicon to the corpus, taking into account the different domains. Then, four different opinionated word lists are generated for each of the eight different domains and four different word lists for all domains of the corpus. Following a corpus based method, two heuristics are assessed with the aim of integrating into each list the most frequent words used for positive and negative reviews. A subset of the corpus is used to build the lists and the other part to test the new resources. The results obtained show an improvement over the experiments using the general lexicon.

In order to carry out the experiment we chose the Spanish part of the comparable SFU Review Corpus. The SFU Review Corpus is composed of reviews of products in English and Spanish. The English version (Taboada & Grieve, 2004) has 400 reviews (200 positive and 200 negative) of commercial products downloaded in 2004 from the Epinions
                           4
                           urlhttp://www.epinions.com.
                        
                        
                           4
                         web which are divided into eight categories. Each category includes 25 positive reviews and 25 negative reviews. Subsequently, the authors of the SFU Review Corpus have made available the Spanish version of the corpus
                           5
                           urlhttp://www.sfu.ca/mtaboada/download/downloadCorpusSpa.html.
                        
                        
                           5
                         with the aim of offering a comparable corpus for the research community. The Spanish reviews are divided into eight similar categories: books, cars, computers, washing machines, hotels, movies, music and phones. Each category also has 25 positive and 25 negative reviews, which are defined as positive or negative based on the number of stars given by the reviewer (1–2=negative; 4–5=positive; 3-star reviews are not included). In this case, the reviews are downloaded from the Ciao.es
                           6
                           urlhttp://www.ciao.es/.
                        
                        
                           6
                         website.

We followed a lexicon-based approach to tackle the problem. The iSOL lexicon (Molina-González et al., 2013) was selected to carry out the experiments. This resource was generated from the BLEL lexicon (Hu & Liu, 2004) by automatically translating it into Spanish and obtaining the SOL (Spanish Opinion Lexicon) resource. Then, this resource was manually reviewed in order to improve the final list of words obtaining iSOL (improved SOL). This resource has been successfully evaluated in (Molina-González et al., 2013) using a Spanish corpus of movie reviews called MuchoCine (Cruz et al., 2008). The results showed that the use of an improved list of sentiment words from the same language could be considered as a good strategy for unsupervised polarity classification. Moreover, another list was generated appending the positive and negative words of the MuchoCine corpus. In this way, domain knowledge was added in the lexicon. The result of the process was a new lexicon which is called eSOL (enriched SOL). The experiments with eSOL showed the advantages of using domain knowledge. Thus, the main motivation of this paper is the integration of knowledge from the domain in order to improve the final polarity classification system.

The improved Spanish Opinion Lexicon (iSOL) is composed of 2509 positive and 5626 negative words, thus in total the Spanish lexicon has 8135 opinion words.

As is well-known in the SA research community, the semantic orientation of a word is domain-dependent. Within the approaches followed by research into the compilation of a set of polar words, the most suitable for obtaining domain- dependent opinion words is that known as the corpus-based approach. Hatzivassiloglou et al. (1997) take some adjectives as seeds in order to find additional sentiment adjectives in the corpus. Their method takes advantage of a set of conventions on connectives with the aim of identifying more polar words and their orientation from a sentiment label corpus. On the other hand, Du, Tan, Cheng, and Yun (2010) follow a similar assumption, and they consider that a word should be positive (or negative) if it appears in many positive (or negative) documents.

We follow a more straightforward method which consists of enlarging iSOL with the most frequent words of a sample of the SFU Spanish Review Corpus. The key point of the method is to automatically find domain sentiment words in the different domains of the corpus with the goal of developing a domain specific sentiment lexicon for each domain covered by the SFU Spanish Review Corpus. Four different word lists for each domain of the corpus and four different word lists for the categories (positive and negative) of the corpus are generated. Then, the new resources are assessed over the reviews of the corpus which are not utilised for building the lists. To build the first four lists, we split the 50 reviews for each category into two random groups of 15 and 10 positive reviews and 15 and 10 negative reviews. We used the group of 15 reviews of both polarities (30 reviews in total) to seek the words and integrate them into the new resources. Then we used the group of 20 reviews (10 positive, 10 negative) to test the validity of the new domain specific lexicons.

Taking the general-purpose sentiment lexicon iSOL, we generated our first list of opinion words for each domain of the SFU Spanish Review Corpus. After removing the stop words from the documents, the selection of the polarity domain-dependent words consists of calculating the absolute frequency of each word per class (positive/negative), and then the most-used positive and negative words were appended to iSOL. The new list with domain information is called eSOLdomainLocal (enriched SOL Local) where domain =cars, hotels, washing machine, books, phones, music, computers, movies.

The second way to enrich the iSOL lexicon consists of adding not only the sentiment words but also the most frequently used domain-dependent words. Commercial names and proper nouns were discarded from this selection. Some examples of these discarded words were: Fagor, BMW, Almudena Grandes, Quijote, Siemens, Citroen, Acer, Nokia, Bon Jovi, AC/DC, Bosh, Hannibal Lecter, George Lucas, etc. The most frequent domain-dependent words are selected using the following formula:
                           
                              (1)
                              
                                 list
                                 (
                                 word
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   positive
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         -
                                                      
                                                   
                                                   =
                                                   0
                                                   ∧
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         +
                                                      
                                                   
                                                   ⩾
                                                   3
                                                   )
                                                   ∨
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        f
                                                                     
                                                                     
                                                                        +
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        f
                                                                     
                                                                     
                                                                        -
                                                                     
                                                                  
                                                               
                                                            
                                                            ⩾
                                                            3
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   negative
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         +
                                                      
                                                   
                                                   =
                                                   0
                                                   ∧
                                                   
                                                      
                                                         f
                                                      
                                                      
                                                         -
                                                      
                                                   
                                                   ⩾
                                                   3
                                                   )
                                                   ∨
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        f
                                                                     
                                                                     
                                                                        -
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        f
                                                                     
                                                                     
                                                                        +
                                                                     
                                                                  
                                                               
                                                            
                                                            ⩾
                                                            3
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    f
                                 
                                 
                                    +
                                 
                              
                           
                         is the frequency of the word in positive reviews and 
                           
                              
                                 
                                    f
                                 
                                 
                                    -
                                 
                              
                           
                         in negative reviews. Thus, those words that satisfy Eq. (1) are appended to the positive or negative list of eSOLdomainLocal. These new resources are called eSOLdomainLocal∗. Tables 1 and 2
                        
                         show some examples of domain-dependent words that have been appended to the lists.

The third and fourth lists generated are similar to the first and second ones. The difference is how to find the most used sentiment and domain-dependent words. In these lists, if one word is used one or more times in one positive or negative review we considered that its frequency is one. That is, although the word appears several times in a specific review, its frequency is one. Therefore in these lists, the highest possible frequency of a word is 15. The new resources are called eSOLdomainGlobal with only sentiment words and eSOLdomainGlobal∗ including the most frequently used sentiment words and domain-dependent words.

In order to generate the last four lists, we considered all the domains together. Again, we split the corpus into two groups, one for integrating opinion words into the lists and another one for testing the new resources. Thus, we used 120 positive reviews (the same 15 positive reviews per domain used before multiplied by 8 domains) and 120 negative reviews to generate new resources from eSOL, and we carried out the experiment with the rest of the corpus, that is 160 reviews, 80 positive (10 positive reviews for each 8 different domains) and 80 negative.

On the one hand, we generated the new eSOLLocal resource taking into account only the most frequent sentiment words. Then, we generated the new eSOLLocal∗ taking into account the sentiment words and also the most frequent domain words, which were obtained following the Eq. (1).

On the other hand, in the compilation of the latter two lists the difference is how to find the most used sentiment and domain-dependent words. If one word is used one or more times in one positive or negative review we have considered that its frequency is one. Therefore, in these lists the highest frequency is 120, and this only happens if the word is in all the reviews. The new resource, with only sentiment words added to iSOL, is called eSOLGlobal, and the resource with not only the sentiment words but also including the most frequent domain words is called eSOLGlobal∗.

Regarding the original lexicon iSOL, we increased the size of the generated eSOLdomainLocal and eSOLdomainLocal∗ lists for both negative and positive lists of words. Tables 3 and 4
                        
                         show the number of words added to iSOL in each resource respectively.

Concerning the eSOLdomainGlobal and eSOLdomainGlobal∗, we also increased the size of the original iSOL lexicon. Tables 5 and 6
                        
                         show the number of words added to iSOL and also the final size of each new list.

Regarding the eSOLLocal, eSOLLocal∗, eSOLGlobal and eSOLGlobal∗, the size also increased compared to the original iSOL lexicon, and the number of positive and negative words integrated in the new lists is shown in Table 7
                        .

@&#EXPERIMENTS AND RESULTS@&#

In order to evaluate the different approaches, we used the traditional measures employed in text classification: precision (P), recall (R), F1 and Accuracy:
                        
                           (2)
                           
                              P
                              =
                              
                                 
                                    TP
                                 
                                 
                                    TP
                                    +
                                    FP
                                 
                              
                           
                        
                     
                     
                        
                           (3)
                           
                              R
                              =
                              
                                 
                                    TP
                                 
                                 
                                    TP
                                    +
                                    FN
                                 
                              
                           
                        
                     
                     
                        
                           (4)
                           
                              F
                              1
                              =
                              
                                 
                                    2
                                    PR
                                 
                                 
                                    P
                                    +
                                    R
                                 
                              
                           
                        
                     
                     
                        
                           (5)
                           
                              Acc
                              .
                              =
                              
                                 
                                    TP
                                    +
                                    TN
                                 
                                 
                                    TP
                                    +
                                    TN
                                    +
                                    FP
                                    +
                                    FN
                                 
                              
                           
                        
                     where TP (True Positives) and TN (True Negatives) are those assessments where the system and a human expert agree on a label (in this case, TP and TN are those positive or negative reviews rightly classified), FP (False Positives) and FN (False Negatives) are those labels assigned by the system that do not agree with the expert assignment, in plain English, the positive and negatives reviews misclassified. F1 is a measure that combines both precision and recall, calculating the proportion of true results (both true positives and true negatives) Sebastiani (2002). Due to the fact that the system classifies two classes, the P, R and F1 of each class have been calculated. Then, the overall P, R and F1 of the system have been obtained following the macro-averaged evaluation measures. The macro-avergaed evaluation measures formulae for P, R and F1 are the following:
                        
                           (6)
                           
                              Macro-F1
                              =
                              
                                 
                                    2
                                    ∗
                                    Macro-Precision
                                    ∗
                                    Macro-Recall
                                 
                                 
                                    Macro-Precision
                                    +
                                    Macro-Recall
                                 
                              
                           
                        
                     Where Macro-Recall and Macro-Precision are obtained as follows:
                        
                           (7)
                           
                              Macro-Recall
                              =
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          c
                                       
                                    
                                    
                                       
                                          R
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    c
                                 
                              
                           
                        
                     
                     
                        
                           (8)
                           
                              Macro-Precision
                              =
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          c
                                       
                                    
                                    
                                       
                                          P
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                    c
                                 
                              
                           
                        
                     where c is the number of classes (c
                     =2).

Several experiments were carried out in order to verify the utility of the new resources generated for Spanish from iSOL: eSOLdomainLocal(∗), eSOLdomainGlobal(∗), eSOLLocal(∗) and eSOLGlobal(∗) where domain=cars, hotels, washing machine, books, phones, music, computers, movies. The general method consists of finding the presence in the reviews of opinion words which are included in a lexicon of opinion words. If a review has more positive words than negative ones, the document polarity is positive, otherwise negative (Eq. (9)).
                        
                           (9)
                           
                              p
                              (
                              r
                              )
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                if
                                                
                                                |
                                                positive
                                                |
                                                >
                                                |
                                                negative
                                                |
                                             
                                          
                                          
                                             
                                                -
                                                1
                                             
                                             
                                                if
                                                
                                                |
                                                positive
                                                |
                                                ⩽
                                                |
                                                negative
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where p(r) is the polarity of the review, 
                        
                           |
                        
                     positive
                        
                           |
                        
                      is the number of positive words and 
                        
                           |
                        
                     negative
                        
                           |
                        
                      is the number of negative words.

Before carrying out the experiments we performed a pre-processing step on the SFC corpus in order to apply the same criteria followed in the generation of the enriched iSOL lists. For example, we changed capital letters to non-capital ones, accented letters to non-accented ones and special characters were separated from words in the reviews. Moreover, the stop words were discarded.

For the baseline experiment we took the same 20 reviews used to test each domain separately and applied the iSOL lexicon. The results are presented in Table 8
                     .

The next experiments were carried out over the 160 reviews used for testing purposes (10 positive reviews and 10 negative reviews per domain chosen randomly and not used to generate the lexicons). Thus the results obtained with the eSOLdomainLocal are shown in Table 9
                     . This resource was built by adding the most used sentiment words in positive or negative reviews of each domain to iSOL. Table 8 also includes the percentage of improvement over the baseline experiment (Table 8) using the following equation:
                        
                           (10)
                           
                              Improvement
                              =
                              
                                 
                                    Macro-F1eSOLdomain[Local|Global]
                                    -
                                    MacroF
                                    1
                                    iSOLdomain
                                 
                                 
                                    MacroF
                                    1
                                    iSOLdomain
                                 
                              
                              ∗
                              100
                           
                        
                     
                  

The second eSOLdomainLocal∗ resource enriched the iSOL lexicon with sentiment words, but also the most frequent domain-dependent words (Eq. (1)). Table 10
                      shows the results obtained with this lexicon.

The next two experiments are similar to the two previous ones but using eSOLdomainGlobal and eSOLdomainGlobal∗. The difference between Local and Global is how to find the most used sentiment and domain-dependent words. If one word is used one or more times in a positive or negative review we considered that its frequency is one. Therefore, in this experiment the highest possible frequency of a word is 15. Tables 11 and 12
                     
                      show the results obtained using the eSOLdomainGlobal and eSOLdomainGlobal∗ resources respectively.

Taking as an example the cars domain to simplify, Table 13
                      shows how many new words were found in the reviews when we use the new lists generated. As we can see, in reviews “coches_no_2_12” and “coches_no_2_20” whose rank is −1, with iSOL the review is classified as Positive (FP), and with the new lists as Negative, which means an improvement of the system.

For the last experiments we did not take into account the different domains individually, and so we did not separate the domains of the SFU Reviews Corpus. Therefore, we have two new groups of reviews, one for generating the lists and another one for testing the new resources. The group for generating new resources eSOLLocal(∗) and eSOLGlobal(∗) includes a total of 240 documents: 120 positive reviews (15 positive reviews per domain multiplied by 8 domains) and 120 negative reviews. The group of reviews used for evaluating the generated lists is composed of 160 documents (10 positive and 10 negative reviews for each of the 8 domains). Thus, for the eSOLLocal we added only the most frequent sentiment words to iSOL lists and for the eSOLLocal∗ resource we also included the most frequent domain words if their frequency in positive (or negative) reviews was three or more times as much as negative (or positive) reviews. A similar process was followed to generate the eSOLGlobal and eSOLGlobal∗ resources. The difference is how to find the most used sentiment and domain words. If one word is used one or more times in one positive or negative review we considered that its frequency is one. Therefore, in this experiment the highest possible frequency of a word is 120. Table 14
                      shows the results obtained with these new resources, including the baseline experiment using the original iSOL list.

In Table 14 we can see that the results obtained are improved for all the cases when we integrate domain information without taking into account the domains individually but considering all them together.

As we can see by comparing the different tables of results, the baseline experiment is improved upon for five domains (Cars, Washing machines, Music and Mobile phones) when we apply domain sentiment lexicons. Nevertheless, the results obtained with the new resources over the domains Hotels, Books, Computers and Movies are worse or equal than the original iSOL list.

On the other hand, taking the means of the Macro-F1 and accuracy of results, we can see that the eSOLdomainGlobal and eSOLdomainGlobal∗ lists obtained results a little better than eSOLdomainLocal and eSOLdomainLocal∗ lexicons, respectively. This means that in order to generate domain adapted opinion bearing word lists it is advisable to measure the frequency of the words as the number of documents of the corpus where the word appears. So, if a word is in most of the documents of the corpus, it is more representative than the word which is repeated a lot of times in a single document but does not appear in the others. In our case, if a word is in most of the positive documents it is very likely that the word expresses a positive opinion or sentiment, but if that word is only repeated several times in a positive document it does not mean that it expresses a positive meaning.

However, the differences between the eSOLdomainGlobal lexicons and eSOLdomainGlobal∗ are not significant because they achieved very similar results, so we consider that the eSOLdomainGlobal resource has the most suitable list of opinion bearing words, because it adds less words than eSOLdomainGlobal∗. Although we should emphasise that the performance with the domains computers and movies is not good.

As we have said previously the domain adaptation process has not worked as we expected for some domains. One of the problematic domains is “Computers”. After reading some of the reviews we have noticed that in the some reviews the author expresses his disagreement and also advice the purchase of distinct computer. Thus in the same review there are positive and negative expressions that could have driven the domain adaptation method to introduce unsuitable words to the lists.

A deep analysis of the results shows that the number of FP is quite high. After reading some of the test reviews we can see that some possible causes of the misclassification are associated with the poor treatment of some issues in opinion mining: negation and irony. For example, some reviews that belong to the negative class use negative expressions with positive words to state a negative opinion. An example can be read in file “no_2_4.txt”(Fig. 1
                        ) of the Movies domain: no me ha gustado (I did not like it). The word gustado (liked) is in the positive lists of eSOLLocal and eSOLGlobal, so the system considers the word as positive, but it must be negative because the word no (not) changes the polarity of gustado (liked). Another example can be found in file “no_2_12.txt” (Fig. 2
                        ) of the Music domain. This file includes the sentence sin ideas geniales (without brilliant ideas). The word geniales is also in the positive lists of all resources, so the system considers it as positive. As in the previous example the word sin (without) changes the polarity of the word geniales (brilliant).

However, this kind of error could not be associated to the lexicon because the lexicon only includes bearing words. On the contrary, it is necessary to perform a deeper analysis of the content and develop strategies for dealing with negation.

On the other hand, one of the features of irony is the use of positive words to express a negative point of view about something or somebody. After reading some reviews of the corpus the use of irony is very common in some domains. The expression !una maravilla! (it is wonderful!) in the review “no_1_20.txt” (Fig. 3
                        ) of the Washing machines domain is a clear example.

These are the main reasons for the low performance in some domains, so the errors are not caused by a low quality of the lexicons. Thus the main problem is that the classifier built for domain lexicons assessment only takes into account the words that are on the lists and does not consider other issues of OM. The classifier does not consider negation or irony because the main goal of the paper is the description of the new domain specific sentiment lexicons.

To finish our analysis of results, we would like to evaluate the validity of the generated lexicons by comparing the system with other corpora. However, the availability of Spanish corpora is very sparse, so this evaluation is very difficult to carry out. Also, for a complete evaluation of all the lists we need eight different corpora, one per each domain. The only Spanish corpus available is a corpus of movie reviews. The corpus is called MuchoCine (Cruz et al., 2008). Thus, only the list that achieved better results in the Movie domain (eSOLMovieGlobal) has been evaluated with the corpus MuchoCine. The results achieved by iSOL and eSOLMovieGlobal are shown in Table 15
                        . The evaluation of eSOLMovieGlobal with the corpus MuchoCine has shown that the domain adaptation method presented in this paper is also valid for other corpus.

In this paper we study the integration of domain information for a Spanish polarity classification system. We have carried out several experiments in order to test the different resources generated from the original Spanish lexicon iSOL: a polarity classification of each domain using iSOL; a polarity classification with the sentiment lexicons eSOLdomainLocal and eSOLdomainLocal∗; the same ex- periment but with the lexicons eSOLdomainGlobal and eSOLdomainGlobal∗; and the last experiments with the lists iSOL, eSOLLocal, eSOLLocal∗, eSOLGlobal and eSOLGlobal∗. All these resources are freely available for research purposes.
                        7
                        urlhttp://sinai.ujaen.es/?p=1264.
                     
                     
                        7
                     
                  

The results obtained in the polarity classification of the entire corpus indepen- dently for the domain, the lexicons eSOLLocal, eSOLLocal∗, eSOLGlobal and eSOLGlobal∗ are very similar, although we highlight that eSOLLocal and eSOLGlobal achieve better results than eSOLLocal∗ and eSOLGlobal∗. The four lists surpass the results achieved by iSOL, but the differences between them are not significant.

However, according to the domain polarity classification the results over four domains surpass the baseline, while the other four domains seem to be harder to classify. An analysis of the errors shows that the possible cause of the misclassification could be the use of irony and negation in these reviews. Thus, our future work would be focused on the development of techniques for the treatment of negation in OM with the goal of improving the polarity classification systems. Another research line for the future is the analysis whether the application of a homogeneous factor for all the domains is a good strategy, because the analysis of the results shows up that it is very likely that each domain needs its own factor in Eq. (1).

@&#ACKNOWLEDGEMENTS@&#

This work has been partially supported by a grant from the Fondo Europeo de Desarrollo Regional (FEDER), ATTOS project (TIN2012-38536-C03-0) from the Spanish Government. The project AORESCU (P11-TIC-7684 MO) from the regional government of Junta de Andalucía partially supports this manuscript, and the project CEATIC-2013-01 from the University of Jaén.

@&#REFERENCES@&#


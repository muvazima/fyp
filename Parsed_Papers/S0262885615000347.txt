@&#MAIN-TITLE@&#A stereo matching approach based on particle filters and scattered control landmarks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A stereo matching approach motivated by the particle filter framework in robot localization.


                        
                        
                           
                           Highly accurate GCPs, acquired by the computation of multiple cost efficient disparity maps.


                        
                        
                           
                           A Markov chain model has been introduced in the process to reduce the computational complexity of particle filtering.


                        
                        
                           
                           Application of RANSAC algorithm along with a histogram technique to refine any outliers.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Stereo matching

Particle filters

Ground control points

Markov chains

Plane fitting

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

While common digital images provide sufficient 2D information of a scene, several applications including robotics, entertainment and other require full 3D information, such as depth information, which can be accomplished by stereo imaging. Stereo matching is the field of study that aims to determine correspondences in two or more images shot from different viewpoints for obtaining a depth map of the actual scene. This major field of computer vision has been reviewed and categorized accordingly in [1,2] and [3]. Stereo matching techniques can be explicitly classified into two major groups, global and local approaches. The common approach in local algorithms is that the disparity value of a given pixel is calculated only by intensities populating a certain region around that pixel, which is called support window. Several strategies have been introduced to optimize the results of local techniques such as adaptive-weight cost aggregation strategies aiming to reduce implicit assumptions [4]. In global approaches, algorithms determine the disparity values simultaneously based on smoothness assumptions and tend to be iterative for refining their results with energy minimization techniques. The general framework is that local techniques are less computationally expensive than the global techniques and, therefore, they are mostly real time/hardware applicable. Despite this fact, global algorithms can achieve higher accuracy if they deploy cost aggregation techniques in their process. Several applications of belief propagation [5], graph cuts [6] and segmentation combined with plane fitting [7] have been integrated in global and local approaches to boost their performance.

In this paper, we present an approach which tackles the stereo matching problem from a novel perspective compared to known techniques. Our inspiration has been derived from the problem of robot localization in a known environment. This problem can be solved accurately by particle filters, where each particle is a possible state of the robot and each state has its own probability of the robot's actual positioning [8]. The probability is calculated by means of linked series of geometrical and spatial information derived from known landmarks in the environment. We address the stereo matching problem with the same technique, where at first we acquire a set of ground control points (GCPs) [9] by computing multiple disparity maps and subsequently we label them as landmarks. Those features possess an extremely precise disparity value and we utilize them for applying the particle filtering context in a scan line for accurate estimation of disparity values. For improving the effectiveness of particle filtering, we first classify each landmark using a segmentation based technique in each of the paired images. Additionally, we introduce a Markov chain model to increase the accuracy and decrease the computational expensiveness of particle filtering. Finally, we refine our results by applying the RANSAC algorithm [10] combined with a histogram technique which, by drawing out the outliers, allows us to obtain high quality disparity maps.

@&#RELATED WORK@&#

The proposed stereo matching approach is based on particle filtering. Although recent work has introduced particle filtering in 3D optical flow [11], our framework of stereo matching is completely different in every aspect. Moreover, it tends to relate to a small portion of global and local approaches as referred in the stereo related literature.

Global algorithms have lately increased their accuracy due to segmentation-based techniques as introduced by [12,13]. These approaches rely on the assumption of homogeneous color segments which approximate non-overlapping regions in the reference image. Over-segmentation is preferred, since it helps to meet these assumptions in practice, where in every segment the disparity values vary smoothly on a planar surface [7]. Moreover, global approaches have employed belief propagation in their frameworks. Belief propagation was initially established and described in [14] and it has been a popular method for state of the art global algorithms as an energy minimization technique, which is usually constructed by Markov random fields [7,5]. Furthermore, various strategies of graph cuts have been implemented in global approaches to address the same problem of energy minimization [6].

On the contrary, local algorithms examine each pixel independently with the assistance of cost aggregation strategies. Cost aggregation approaches compose a broad chapter in stereo literature which has been evaluated and analyzed extensively in [15]. Several methods of cost aggregation strategies have been introduced over the years based on shiftable windows [16,17], adaptive weights [4], multiple windows [18], and segment based windows [19]. Traditional local algorithms produce less accurate results compared to global ones, but lately this gap has been reduced. A popular method in this category is based on adaptive weights proposed by Yoon and Kweon [4], inspired by the Gestalt principles based on spatial proximity and color similarity. Additional improvements to this method have been proposed by deploying a segmentation based support window [19].

Lastly, there is a category of stereo algorithms which takes advantage of global smoothness assumptions combined with several local constrains. These algorithms fall under the category of semi-global approaches where both global and local techniques are applied for the same correspondence purpose. One of the first semi-global approaches was proposed by Hirschmuller [20], where a different approach of energy minimization was utilized. Semi-global techniques aim at minimizing the global 2D energy function by applying several 1D minimization methods. Generally, semi-global matching algorithms take advantage of scan line energy minimization combined with dynamic programming from several 1D directions. Due to the computational efficiency of semi-global approaches, a wide range of techniques have been introduced to address the stereo correspondence problem, such as discontinuity preserving interpolation in structured environments [21] and segmentation based techniques combined with plane fitting [22].

The overall framework of our approach has been also motivated by recent global approaches which utilize ground control points. These points are described as high confidence matches and their first appearance was in the work of Bobick and Intille [9]. There are two well known methods that can obtain such high confident matches. The first method requires strong feature correspondences, for obtaining high confidence starting points in order to initiate the GCPs calculation [23]. The second technique for acquiring the GCPs relies on the computation of multiple disparity maps based on local approaches and winner-take-all (WTA) strategies as it has been presented in [24]. A similar technique has been presented in [25] where the GCPs are obtained from local matching by oriented spatial filters.

The proposed method has been motivated by the particle filter framework in robot localization. Early particle filter implementations in robot localization can be found in the literature, in which a robot's position has to be recovered from sensor data [8]. In all tracking problems it is essential to decompose the system into three basic models, the inference the state and the dynamics one. In the state model which describes the environment of a mobile robot, a state is usually measured by a two-dimensional Cartesian coordinate system and the orientation of heading. Additionally, in the inference model the sensor data provides the system with an estimation of its position in the environment combining spatial information from the surrounding objects. This spatial sensory information is often called a landmark. Finally, the dynamics model describes the evolution of the system states over time. When the system passes from a certain state x
                     
                        t
                      to the next x
                     
                        t
                        +1 in discrete time t, the sensors gather new spatial information from the environment. Furthermore, the current state is related to the previous state P(x
                     
                        t
                        +1|x
                     
                        t
                     ) by a Markov chain model. Each state in the Markov chain model is not observable, instead the only observable variable is the set of measurements Zt
                      acquired from the sensors leading to a stochastic prominence of the true state x
                     
                        t
                     .

More precisely, particle filters are approximate methods for the calculation of non-linear posterior probabilities in partially observable Markov chain models in discrete time, where an analytic solution to an integral equation is not feasible. In a typical non-linear Bayesian tracking model the list of total measurements up to t is denoted as Zt
                      and the feature measurements at time t is expressed as z
                     
                        t
                     , while the set of states over time is expressed as Xt
                     :
                        
                           
                              
                                 Z
                                 t
                              
                              =
                              
                                 
                                    
                                       z
                                       1
                                    
                                    ,
                                    ..
                                    .,
                                    
                                       z
                                       t
                                    
                                 
                              
                              ,
                              
                                 X
                                 t
                              
                              =
                              
                                 
                                    
                                       x
                                       1
                                    
                                    ,
                                    ..
                                    .,
                                    
                                       x
                                       t
                                    
                                 
                              
                              .
                           
                        
                     
                  

In order to calculate the posterior density probability P(x
                     
                        t
                     |Z
                     
                        t
                     ), conditioned over all given observations until time t, we utilize Bayes' formula:
                        
                           (1)
                           
                              P
                              
                                 
                                    
                                       x
                                       t
                                    
                                    |
                                    
                                       Z
                                       t
                                    
                                 
                              
                              =
                              
                                 
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                          
                                          |
                                          
                                             x
                                             t
                                          
                                          ,
                                          
                                             Z
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                       
                                    
                                    p
                                    
                                       
                                          
                                             x
                                             t
                                          
                                          |
                                          
                                             Z
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                                 
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                          
                                          |
                                          
                                             Z
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                              .
                           
                        
                     
                  

Furthermore, using the Chapman–Kolmogorov equation for joint probability distributions, and assuming there is independence between observations, Eq. (1) can be rewritten as:
                        
                           (2)
                           
                              P
                              
                                 
                                    
                                       x
                                       t
                                    
                                    |
                                    
                                       Z
                                       t
                                    
                                 
                              
                              =
                              
                                 
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                          
                                          |
                                          
                                             x
                                             t
                                          
                                       
                                    
                                    
                                       
                                          ∫
                                          
                                             
                                                x
                                                t
                                             
                                             −
                                             1
                                          
                                       
                                       
                                    
                                    p
                                    
                                       
                                          
                                             x
                                             t
                                          
                                          |
                                          
                                             x
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                       
                                    
                                    p
                                    
                                       
                                          
                                             x
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                          |
                                          
                                             Z
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                       
                                    
                                    d
                                    
                                       x
                                       
                                          t
                                          −
                                          1
                                       
                                    
                                 
                                 
                                    p
                                    
                                       
                                          z
                                          t
                                       
                                    
                                 
                              
                              .
                           
                        
                     
                  

This solution of the non-linear Bayesian tracking problem is a conceptual solution and it cannot be determined analytically. Several approximations have been proposed over the years in certain sets of cases. In the simplified case of Kalman filters [26] where the dynamics of the system and the observations are not linear, the measurement noise derived from observations forms a distinctive Gaussian distribution. In the case of non-linearities a considerable amount of techniques have been introduced to determine an approximate solution including Monte Carlo approximations [27]. Monte Carlo methods are simulation-based techniques for computing posterior distributions. Particle filters are sequential Monte Carlo models where each particle is a possible state scattered in the known environment as a three dimensional variable containing the orientation and the Cartesian coordinates. In every particle i, there is a certain associated weight w
                     
                        t
                     
                     (i), which is proportional to the prior probability of importance.

Given a certain amount of support points denoted as particles X
                     
                        t
                     
                     ={x
                     1,...,
                     x
                     
                        t
                     } up to time t let {X
                     
                        t
                     
                     (i),
                     w
                     
                        t
                     
                     (i)},
                     i
                     =1…
                     ν denote a random measure that characterizes the posterior density function P(X
                     
                        t
                     |Z
                     
                        t
                     ), where {w
                     
                        t
                     
                     (i),
                     i
                     =1,..,
                     ν} are the associated weights. The weights are normalized such that ∑
                        i
                     
                     w
                     
                        t
                     
                     (i)
                     =1. Then the posterior density at time t can be approximately expressed as:
                        
                           (3)
                           
                              P
                              
                                 
                                    
                                       x
                                       t
                                    
                                    |
                                    
                                       Z
                                       t
                                    
                                 
                              
                              ≈
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    ν
                                 
                                 
                              
                              
                                 w
                                 t
                                 
                                    i
                                 
                              
                              δ
                              
                                 
                                    
                                       x
                                       t
                                    
                                    −
                                    
                                       x
                                       t
                                       
                                          i
                                       
                                    
                                 
                              
                           
                        
                     where δ is the Dirac-delta function. This approximation describes the density probability as a discrete weighted function. The weights are chosen recursively using either the method of sequential importance sampling (SIS) or in our case the resampling method. In the case of SIS a degeneracy problem is observed between particles with negligible weights of insignificant importance. This leads to computational expensiveness due to the continuous update of negligible weights even thought their contribution to the approximate solution is unimportant. On the contrary, the resampling approach is capable of eliminating the degeneracy problem by excluding the particles with negligible weights from the update process. Thus, this approach focuses on the particles with important weights for the reducing of the computational complexity.

The proposed approach addresses the stereo correspondence from a different point of view by which we aim to estimate the best disparity value between a range of possible ones, by means of the particle filter framework. The proposed approach is applied to both stereo images combining different sets of characteristics from each one. In our case, the environment for particle filtering corresponds both to the target and the reference image and its possible states correspond to the disparity range of the stereo images. The inference model utilizes the GCPs acquired by the computation of multiple cost efficient disparity maps. Those features serve as landmarks taking advantage of the spatial inference from the global environment and utilize it for the estimation of the posterior probability P(x
                        
                           t
                        |Z
                        
                           t
                        ).

The state model can be divided into two categories, the reference state and the set of possible states. The reference state of the model by which we observe the true measurements and compare them to the ones of all possible states, corresponds to a specific pixel in the reference image IR
                            of size (m
                           ×
                           n) with Cartesian coordinates (xR
                           ,yR
                           ). The reference state at time t can be expressed as:
                              
                                 
                                    
                                       x
                                       t
                                       R
                                    
                                    =
                                    
                                       
                                          x
                                          t
                                          R
                                       
                                       
                                          y
                                          t
                                          R
                                       
                                    
                                    .
                                 
                              
                           
                        

Moreover, the set of possible states correspond to the target image 
                              I
                              T
                           . Due to the scan line framework our set of possible states exist in a certain scan line of states that can be determined by the y
                           
                              t
                           
                           
                              R
                            coordinate of the reference state x
                           
                              t
                           
                           
                              R
                            and is a subset of the target image:
                              
                                 
                                    
                                       I
                                       T
                                    
                                    
                                       
                                          
                                             
                                                x
                                                1
                                                T
                                             
                                             ,
                                             ..
                                             .,
                                             
                                                x
                                                n
                                                T
                                             
                                          
                                       
                                       
                                          y
                                          t
                                          R
                                       
                                    
                                    ⊂
                                    
                                       I
                                       T
                                    
                                    .
                                 
                              
                           
                        

The particle framework is not applied to the entire scan line but to a small subset defined by the disparity D
                           
                              r
                           
                           ∈ℤ+ range of the stereo images. More precisely, the set of possible states in the target image denote the possible disparity states given a certain reference state x
                           
                              t
                           
                           
                              R
                           :
                              
                                 
                                    
                                       I
                                       T
                                    
                                    
                                       
                                          
                                             
                                                x
                                                t
                                                R
                                             
                                             ,
                                             ..
                                             .,
                                             
                                                x
                                                t
                                                R
                                             
                                             +
                                             
                                                D
                                                r
                                             
                                          
                                       
                                       
                                          y
                                          t
                                          R
                                       
                                    
                                    ⊂
                                    
                                       I
                                       T
                                    
                                    
                                       
                                          
                                             
                                                x
                                                1
                                                T
                                             
                                             ,
                                             ..
                                             .,
                                             
                                                x
                                                n
                                                T
                                             
                                          
                                       
                                       
                                          y
                                          t
                                          R
                                       
                                    
                                    .
                                 
                              
                           
                        

The set of possible states x
                           
                              t
                           
                           (i) in the target image, at time t is defined as:
                              
                                 
                                    
                                       x
                                       t
                                       T
                                    
                                    =
                                    
                                       
                                          
                                             
                                                x
                                                t
                                                R
                                             
                                             ,
                                             ..
                                             .,
                                             
                                                x
                                                t
                                                R
                                             
                                             +
                                             
                                                D
                                                r
                                             
                                          
                                       
                                       
                                          y
                                          t
                                          R
                                       
                                    
                                    .
                                 
                              
                           
                        

The current state model has 2 degrees of freedom due to the discrete environment of images and the linear state model. The orientation of states is unnecessary given the fact that the simulated sequences of states are linear and the heading follows only one direction.

The dynamics model describes how the evolution of the system occurs over time in a discrete time-step model. In most cases of particle filter implementations the dynamics of the system has been derived from the system itself and the way the system interacts with the environment. Since we are dealing with rectified stereo image pairs, the dynamics model is forced to follow a scan-line structure. By integrating such model, the particles are propagated by increasing the x coordinate by one pixel per step, allowing us to infer a better converged disparity value for a given reference state. This is achieved by updating the weights according to the likelihood of the new observations. By introducing a hidden state x
                           
                              t
                            which belongs in the target image in the set of possible states without knowing its parameters the evolution of steps is described as follows:
                              
                                 
                                    
                                       x
                                       
                                          t
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          
                                             x
                                             t
                                          
                                          +
                                          1
                                          ,
                                          
                                             y
                                             t
                                             R
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

More precisely, the y coordinate of the system remains stationary in a fixed value of the respective scan line, whereas the x coordinate is increased by one pixel. The same dynamics has been applied in each particle in the state model of target image. This dynamics model can be applied only if the following target state of the model takes place under the same segment as the previews state.

The process is repeated over time in a step-wise form, where the weights of particles are updated recursively by the resampling method. In order to compute the disparity value 
                              
                                 d
                                 
                                    X
                                    t
                                    R
                                 
                              
                            for each reference state x
                           
                              t
                           
                           
                              R
                            in the reference image we only utilize the xt
                            coordinate (parameter) of the hidden state:
                              
                                 
                                    
                                       d
                                       
                                          X
                                          t
                                          R
                                       
                                    
                                    =
                                    
                                       
                                          
                                             x
                                             t
                                          
                                          −
                                          
                                             x
                                             R
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

After a sufficient amount of resampling periods when the posterior probability is obtained from the measurement model, all the parameters (coordinate xt
                           ) of the hidden state can be estimated by taking expectation of the state with respect to the posterior probability of particle filtering. Then the correct disparity value 
                              
                                 
                                    d
                                    ^
                                 
                                 
                                    X
                                    t
                                    R
                                 
                              
                            for each reference state can be computed by:
                              
                                 
                                    
                                       
                                          d
                                          ^
                                       
                                       
                                          X
                                          t
                                          R
                                       
                                    
                                    =
                                    
                                       
                                          E
                                          
                                             
                                                x
                                                t
                                             
                                          
                                          −
                                          
                                             x
                                             R
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Due to the small size of the disparity range the resampling period is decreased proportional to the state model, compared to other implementations of particle filters.

The inference model describes the statistical measurements adopted by the dynamics model to accurately compute the prior likelihood. Given a certain set of measurements in a precise state, the measurement model is denoted as P(z
                           
                              t
                           |x
                           
                              t
                           
                           (i)). In the examined case of stereo correspondence, the measurement model is constructed by the GCPs with known disparity values. The algorithm to obtain the GCPs is applied in both reference and target images and is described in Section 4.

Those GCPs are denoted as landmarks with known Cartesian coordinates in the image environment along with their precise disparity value. Each landmark in the reference image can be expressed as a vector:
                              
                                 
                                    
                                       l
                                       j
                                       R
                                    
                                    =
                                    
                                       
                                          x
                                          j
                                          R
                                       
                                       
                                          y
                                          j
                                          R
                                       
                                       
                                          d
                                          j
                                       
                                    
                                    .
                                 
                              
                           
                        

The respective landmark's j coordinates in the target image are acquired as follows:
                              
                                 
                                    
                                       l
                                       j
                                       T
                                    
                                    =
                                    
                                       
                                          
                                             x
                                             j
                                             R
                                          
                                          +
                                          
                                             d
                                             j
                                          
                                          ,
                                          
                                             y
                                             j
                                             R
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

We exploit those landmarks strictly as spatial observations by utilizing the Cartesian coordinates in the two dimensional image space. Since the distinctive set of landmarks possesses various disparity values, we group them under certain planar regions with homogeneous disparity values, in order to use the appropriate landmarks in the inference model under a certain region. The grouping has been achieved by over-segmentation and more precisely by Mean-Shift segmentation [28]. Assuming that the reference state is under a precise segment θ with a certain set of landmarks L
                           
                              θ
                           
                           
                              R
                           
                           ={l
                           1
                           
                              R
                           ,...,
                           l
                           
                              N
                           
                           
                              R
                           } the likelihood can be computed by the following procedure.

For each possible state we compute the Euclidean distance between the current state pixel and the landmark coordinates and compare them with the actual Euclidean distance of the reference state pixel and its respective landmark. We only consider landmarks for the computation of likelihood that are closer to the reference state. The number of those landmarks is truncated by a certain variable λ. If the number of landmarks N in a given segment θ is greater than the variable λ, then the closest λ number of landmarks are chosen for the computation of the likelihood:
                              
                                 
                                    
                                       l
                                       j
                                    
                                    =
                                    
                                       
                                          
                                             
                                                closest
                                                
                                                
                                                   l
                                                   λ
                                                
                                             
                                             
                                                
                                                if
                                                
                                                λ
                                                <
                                                N
                                             
                                          
                                          
                                             
                                                
                                                   l
                                                   N
                                                
                                             
                                             
                                                
                                                else
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

In order to compute the weights in each state, we employ the following equations, where at first we introduce for each landmark the measurement function:
                              
                                 
                                    
                                       z
                                       t
                                       
                                          j
                                       
                                    
                                    =
                                    
                                       D
                                       j
                                       R
                                    
                                    −
                                    
                                       D
                                       
                                          i
                                          ,
                                          j
                                          
                                             
                                                x
                                                t
                                                
                                                   i
                                                
                                             
                                          
                                       
                                       T
                                    
                                    +
                                    
                                       u
                                       t
                                       o
                                    
                                 
                              
                           where 
                              
                                 D
                                 
                                    i
                                    ,
                                    j
                                    
                                       
                                          x
                                          t
                                          
                                             i
                                          
                                       
                                    
                                 
                                 T
                              
                            is the Euclidean distance measured from the landmark l
                           
                              j
                           
                           
                              T
                            to a possible state x
                           
                              t
                           
                           (i) of the target image and D
                           
                              j
                           
                           
                              R
                            is the Euclidean distance measured from the reference state x
                           
                              t
                           
                           
                              R
                            to the respective landmark l
                           
                              j
                           
                           
                              R
                            in the reference image, as shown in Fig. 2
                           
                           . The parameter u
                           
                              t
                           
                           
                              o
                            is the zero mean Gaussian observation noise. Noisy measurements can be made by measuring the distance between a given pixel and a certain GCP in the image environment. Additionally, for the computation of individual likelihood we employ a conditional probability function based on the previews measurement function:
                              
                                 (4)
                                 
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                             
                                                j
                                             
                                          
                                          |
                                          
                                             x
                                             t
                                             
                                                i
                                             
                                          
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             2
                                             π
                                             
                                                σ
                                                2
                                             
                                          
                                       
                                    
                                    
                                       
                                          exp
                                          
                                             −
                                             
                                                
                                                   
                                                      
                                                         z
                                                         t
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                   2
                                                
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                   /
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Given that conditional independence exists between multiple landmarks, a combined likelihood is derived simply by multiplying all the individual likelihoods from the model:
                              
                                 (5)
                                 
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                          
                                          |
                                          
                                             x
                                             t
                                             
                                                i
                                             
                                          
                                       
                                    
                                    =
                                    
                                       
                                          ∏
                                          
                                             j
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                    
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                             
                                                j
                                             
                                          
                                          |
                                          
                                             x
                                             t
                                             
                                                i
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

In order to calculate the weight w
                           
                              t
                           
                           (i) for a given state x
                           
                              t
                           
                           (i) at time t in the target image, we utilize the following formula and we normalize it accordingly.
                              
                                 (6)
                                 
                                    
                                       
                                          w
                                          ^
                                       
                                       t
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       w
                                       
                                          t
                                          −
                                          1
                                       
                                       
                                          i
                                       
                                    
                                    p
                                    
                                       
                                          
                                             z
                                             t
                                          
                                          |
                                          
                                             x
                                             t
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 
                                    
                                       w
                                       t
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          
                                             w
                                             ^
                                          
                                          t
                                          
                                             i
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                i
                                             
                                             
                                          
                                          
                                             
                                                w
                                                ^
                                             
                                             t
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

The more similar these distances are, in a certain state, the bigger the weight of the particular particle is. Since we use the resampling method in our model, particles with bigger weights exhibit higher probability to survive during the resampling process.

Although this structure of inference model has been applied in the entire image, a few segments appear not to be able to support this model due to the lack of landmarks. These limited segments are very small to accommodate even one landmark and they tend to be uniform and not-textured regions. The pixel percentage in each image pair that cannot accommodate the particle filter framework can be seen in Table 1
                           . In some cases as the ‘Midd1’ stereo pair, large uniform segments appear (the background uniform segment) with a very little portion of landmarks. However the amount of those features is adequate for the application of particle filtering in those segments. Thus, in ‘Midd1’ stereo pair only the 0.91% of the image is computed solely by the cost aggregation method. Concretely, the pixel percentage that cannot accommodate the particle filter model is proportional not only to the size of the segments but also to the number of landmarks that reside in these segments.

However, in segments that do not accommodate even a single landmark, a typical model of cost aggregation strategy in a support window has been applied in a scan line framework. The method we utilized was the one of adaptive weights [4], which is based on spatial proximity and color similarity. Each pixel in the support window is weighted according to spatial proximity and color similarity in the CIELAB color space with regards to the central pixel of the window. Let pk
                            be a random pixel of the support window in reference image and pc
                            the central pixel, the respective weight can be defined as:
                              
                                 (7)
                                 
                                    
                                       w
                                       r
                                    
                                    
                                       
                                          p
                                          k
                                       
                                       
                                          p
                                          c
                                       
                                    
                                    =
                                    exp
                                    
                                       
                                          −
                                          
                                             
                                                
                                                   d
                                                   p
                                                
                                                
                                                   
                                                      p
                                                      k
                                                   
                                                   
                                                      p
                                                      c
                                                   
                                                
                                             
                                             
                                                γ
                                                p
                                             
                                          
                                          −
                                          
                                             
                                                
                                                   d
                                                   c
                                                
                                                
                                                   
                                                      
                                                         I
                                                         r
                                                      
                                                      
                                                         
                                                            p
                                                            k
                                                         
                                                      
                                                      ,
                                                      
                                                         I
                                                         r
                                                      
                                                      
                                                         
                                                            p
                                                            c
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                γ
                                                c
                                             
                                          
                                       
                                    
                                 
                              
                           where dp
                            and dc
                            are the Euclidean distance between coordinated pairs and the Euclidean distance in the CIELAB color space, respectively, according to the central pixel, with γp
                           ,γc
                            the proximity and color parameters. Similarly, we compute the weights w
                           
                              t
                           (q
                           
                              k
                           ,
                           q
                           
                              c
                           ) for the target image.

The total aggregation cost of correspondence (pc
                           ,qc
                           ) can be expressed as:
                              
                                 (8)
                                 
                                    C
                                    
                                       
                                          p
                                          c
                                       
                                       
                                          q
                                          c
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   
                                                      p
                                                      k
                                                   
                                                   ∈
                                                   
                                                      W
                                                      r
                                                   
                                                   ,
                                                   
                                                      q
                                                      k
                                                   
                                                   ∈
                                                   
                                                      W
                                                      t
                                                   
                                                
                                             
                                             
                                          
                                          
                                             w
                                             r
                                          
                                          
                                             
                                                p
                                                k
                                             
                                             
                                                p
                                                c
                                             
                                          
                                          
                                             w
                                             r
                                          
                                          
                                             
                                                q
                                                k
                                             
                                             
                                                q
                                                c
                                             
                                          
                                          TAD
                                          
                                             
                                                p
                                                k
                                             
                                             
                                                q
                                                k
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   
                                                      p
                                                      k
                                                   
                                                   ∈
                                                   
                                                      W
                                                      r
                                                   
                                                   ,
                                                   
                                                      q
                                                      k
                                                   
                                                   ∈
                                                   
                                                      W
                                                      t
                                                   
                                                
                                             
                                             
                                          
                                          
                                             w
                                             r
                                          
                                          
                                             
                                                p
                                                k
                                             
                                             
                                                p
                                                c
                                             
                                          
                                          
                                             w
                                             r
                                          
                                          
                                             
                                                q
                                                k
                                             
                                             
                                                q
                                                c
                                             
                                          
                                       
                                    
                                 
                              
                           where Wt
                           ,Wr
                            are respectively the target and the reference support windows of correspondence, while the point score in the support window is evaluated by the Truncated Absolute Difference (TAD).

Although we have embedded a belief propagation framework in our method we did not utilize our technique for energy minimization as previously proposed by other authors [7,5]. On the contrary, we use a Markov chain model in a scan line framework so as to reduce the computational complexity of the resampling part and assist the particle filtering structure to converge in the best possible state by adding a correlative weight in the process.

The state model in the Markov chain framework consists of the disparity levels {1,…,Dr
                        }. Each state Si
                         exhibits a certain probability of occurrence P(Si
                        )
                           t
                           −1 and a transition probability to any other state P(S
                        
                           j
                        |S
                        
                           i
                        )
                           t
                           −1 at time t
                        −1. In order to calculate these transition probabilities, the Markov chain structure requires a sufficient amount of past observations as linked occurrences. The linked observations in our approach are the past disparity values in the respective scan line structure of a certain segment. These observations can be considered satisfactory if and only if all the observations exist under the same segment as the reference state x
                        
                           t
                        
                        
                           R
                         of the particle filter model. Moreover, future probabilities P(Si
                        )
                           t
                         can be computed at time t by the sum of conditional probabilities:
                           
                              (9)
                              
                                 P
                                 
                                    
                                       
                                          S
                                          i
                                       
                                    
                                    t
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          D
                                          r
                                       
                                    
                                    
                                 
                                 P
                                 
                                    
                                       
                                          
                                             S
                                             i
                                          
                                          |
                                          
                                             S
                                             j
                                          
                                       
                                    
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 P
                                 
                                    
                                       
                                          S
                                          j
                                       
                                    
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 .
                              
                           
                        
                     

In order to avoid overfitting, we apply Laplace smoothing in all of the transition probabilities in our model as follows:
                           
                              (10)
                              
                                 P
                                 
                                    
                                       
                                          
                                             S
                                             i
                                          
                                          |
                                          
                                             S
                                             j
                                          
                                       
                                    
                                    
                                       t
                                       −
                                       1
                                    
                                    ′
                                 
                                 =
                                 
                                    
                                       P
                                       
                                          
                                             
                                                
                                                   S
                                                   i
                                                
                                                |
                                                
                                                   S
                                                   j
                                                
                                             
                                          
                                          
                                             t
                                             −
                                             1
                                          
                                       
                                       +
                                       α
                                    
                                    
                                       ω
                                       +
                                       α
                                       τ
                                    
                                 
                              
                           
                        where α
                        >0 is the smoothing parameter, ω is the number of trials and τ is the number of states in our model, which corresponds to Dr
                        . Smoothing prevents the assignment of zero probabilities to states that do not occur in a certain sample of past observations. In this way the probability distribution is smoothed across the entire state framework.

Assuming that the next disparity value will be Si
                         with probability P(Si
                        )
                           t
                         for a certain reference state x
                        
                           t
                        
                        
                           R
                         we can acquire the predicted target state in the target image. In order to incorporate the probability P(Si
                        )
                           t
                         in our framework an additive weight is assigned to the respective target state x
                        
                           t
                        
                        (i) of particle filter process. In order to avoid any errors in resampling caused by the Markov chain model, the additive weight is proportional to the original weight w
                        
                           t
                        
                        (i) of particle filtering in that exact state. The new weight w
                        
                           t
                        
                        (i)′ given the probability P(Si
                        )
                           t
                         can be described by the following equation:
                           
                              (11)
                              
                                 
                                    
                                       w
                                       t
                                       
                                          i
                                       
                                    
                                    ′
                                 
                                 =
                                 
                                    
                                       1
                                       +
                                       
                                          1
                                          
                                             
                                                D
                                                r
                                             
                                             
                                                
                                                   1
                                                   −
                                                   P
                                                   
                                                      
                                                         
                                                            S
                                                            i
                                                         
                                                      
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    w
                                    t
                                    
                                       i
                                    
                                 
                                 .
                              
                           
                        
                     

After the additional weight in the process of particle filtering, normalization is required. This approach of Markov chains reduces the resampling process in the particle filtering model resulting to faster convergence. The resulting weights encompass both the probability of the measurement framework of particle filtering P(x
                        
                           t
                        
                        (i)|x
                        
                           t
                           −1
                        (i),
                        z
                        
                           t
                        ) and the highest observation probability of the Markov chain structure P(Si
                        )
                           t
                        .

From the aspect of accuracy this model assists particle filter structure to converge, particularly in the case of a segmented region which appears to be a planar surface with multiple isometric disparity values. More precisely, by utilizing a separate Markov chain in the process we are able to introduce a smoothness technique in the scan-line framework of particle filtering inside a precise segment. Additionally, by exploiting the past disparity values of a certain scan-line we are able to assist the particle filtering model to converge to the right value of disparity even though some landmarks might not be accurate enough to take measurements from. Only a separate Markov chain that observes only the past disparity values as states and not the measurements from the particle filtering is able to provide us with that information. One disadvantage of that Markov chain model is that the model itself needs a certain amount of past observations in a certain scan-line inside a segment in order to begin its process. Compared to [29] which utilizes multiple neighbor states for the calculation of posterior probability we only utilize neighbor states that are in the respective scan-line of our particle filtering model and we exploit them through the separate Markov chain process.

This section describes how the disparity refinement method has been applied, along with a histogram technique for the optimization of the overall disparity map. The implementation of the refinement includes the RANSAC [10] plane fitting algorithm. The algorithm has been applied in every segment in order to fit a planar surface based on the disparity values in that segment. Plane fitting might, however, produce false results if the parameters of the algorithm are not properly chosen according to the disparity map structure.

Therefore, we apply a histogram technique to resolve this problem and we keep the same parameter values of the RANSAC algorithm in every stereo image pair utilized for this application. Then, each disparity value of the segment is compared with the disparity value before the plane fitting. The disparity error variance Ve
                         of all disparity values is computed for that particular pixel k with the assistance of the cost aggregation technique utilized in the particle filtering section. If the disparity error variance Vd
                         between the disparity value chosen from the plane fitting (d
                        
                           planefitting
                        ) and the disparity value created from the particle filtering framework (d
                        
                           original
                        ) is greater than the overall error variance Ve
                        , then the original disparity value is selected as the optimal one, as follows:
                           
                              
                                 
                                    d
                                    
                                       k
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                d
                                                planefitting
                                             
                                          
                                          
                                             
                                             if
                                             
                                             
                                                V
                                                d
                                             
                                             <
                                             
                                                V
                                                e
                                             
                                          
                                       
                                       
                                          
                                             
                                                d
                                                original
                                             
                                          
                                          
                                             
                                             else
                                          
                                       
                                    
                                 
                              
                           
                        
                     

@&#EXPERIMENTAL RESULTS@&#

The proposed method has been evaluated using the Middlebury benchmark [30]. The Middlebury data set include four stereo image pairs: ‘Tsukuba’, ‘Venus,’ ‘Teddy,’ and ‘Cones’, by which we are able to compare our algorithm with state of the art techniques in stereo vision and evaluate our approach.

Our algorithm utilized the same parameters during the entire process of the disparity computation in all benchmark stereo image pairs without making any adjustments. In the Mean-Shift segmentation part the constant parameter set is: σs
                     
                     =7 the spatial radius, σr
                     
                     =7 the range radius and Mr
                     
                     =35 the minimum region size. Moreover, in the inference model the standard deviation of the conditional probability function has been selected to be σ
                     =0.5. Additionally, the parameter set utilized for the cost aggregation strategy has the following values: γc
                     
                     =5 for the color similarity parameter and γp
                     
                     =17.5 for the spatial proximity parameter; the TAD parameter is T
                     =40 and the size of the support window is 35×35. After the appropriate evaluation of our framework in numerous images, the optimum λ variable in the measurement model was set to 30. Finally, the parameter of the Laplace smoothing equation was assigned to α
                     =1.


                     Fig. 3
                     , illustrates the estimated disparity maps computed by the proposed method, along with the ground truth maps and the error maps for each stereo pair. The disparity maps are evaluated according to the average percent of bad pixels (APBP) where the absolute disparity error is greater than one. Moreover, Fig. 4
                      shows additional estimated disparity maps along with the associated GCPs and ground truth maps for every image stereo pair.

In order to acquire the desired landmarks we implemented a voting strategy along with multiple cost efficient disparity maps. More precisely, we compute three disparity maps with winner-take-all strategy (WTA). Firstly, we compute a disparity map based on normalized cross correlation (NCC) [36] with 5×5 window size, followed by a disparity map resulted by the sum of humming distances (SHD) method with the same window size. Lastly, we obtain the third disparity map utilizing the adaptive weights (AW) method proposed by Yoon and Kweon [4] with 39×39 window size. To further reduce any outliers, we apply the same technique in both images and we compute the left-right consistency check [37]. A pixel is labeled as GCP if the disparity level in all of the three disparity maps is consistent and has survived the left–right consistency. Finally, the pixel should not be at the vicinity of an edge where vast disparity changes might take place and occlusions can be detected; computed by Canny edge detector [38]. The NCC and SHD methods are utilized in order to acquire a sparse set of GCPs whereas the AW method is utilized to choose the most accurate of those features. Additionally, the simplicity of SHD and NCC does not introduce huge computational expensiveness. The density and the accuracy of GCPs in each image pair can be seen in Table 1. The acquired GCPs for the ‘teddy’ stereo pair are shown in Fig. 1.

Additionally, Fig. 5
                      depicts the initial disparity maps after one iteration and the converged maps for each stereo pair without any refinement. The areas shown in black color in the initial disparity maps are the areas that have not converged yet. The convergence rate for each stereo pair is different and it depends on the disparity levels of each stereo pair, and on the uniformity of landmarks in each segment. Furthermore, each segment in the image has a different convergence rate and the overall rate is accounted when the last segment converges. The convergence rate for each stereo pair was: 10 for ‘Tsukuba’, 6 for ‘Venus’, 14 for ‘Teddy’, and 15 for ‘Cones’.

The evaluation of our method was compared to other similar techniques as shown in Table 2
                     , where APBAP has been divided according to Middlebury benchmark into 3 categories: The bad pixels in the non-occluded region (nonocc), all the pixels (all), and lastly, the pixels near the area of occluded pixels (disc). We compared our approach with similar local and semi global techniques utilizing belief propagation [35] and plane fitting [22], methods utilizing MSW descriptors [32] and cost aggregation strategies [4,33].

For the ‘Tsukuba’ stereo pair, our algorithm is currently ranked among the best disparity algorithms in the Middlebury benchmark with 0.98 nonocc error, 5.31 disc error and 1.53 all error. Relatively similar results appear also for the ‘Venus’ stereo pair. As far as the ‘Teddy’ and ‘Cones’ stereo pairs are concerned, the results are adequate even if the scattered landmarks are not equally scattered in the image environment. The pixel percentages in the ‘Teddy’ and ‘Cones’ synthetic images that do not accommodate any GCPs are 1.3% and 1.9%, respectively. In these relatively extended regions, cost aggregation method was applied instead of particle filtering, thus slightly deteriorated results were reported.

Various methods have been evaluated during our frameworks for the acquirement of landmark, such as feature matching with numerous descriptors. Firstly we implemented our method along with ORB features [39] for a real time applicable scenario. The main disadvantage of this descriptor was that the features were not equally scattered in the image environment and more precisely there were no strong features at all in the main questionable non-textured areas as shown in Fig. 6
                     . Additionally ORB strong features are frequently concatenated in corners and edges where the disparity level changes and occluded regions might appear. Moreover we assessed SIFT algorithm [40] as a feature matching descriptor. Alternative from ORB features the SIFT algorithm extracted more scattered keypoints. Conclusively SIFT algorithm was able to accommodate a few strong features in texture-less areas which they could be exploited as landmarks, as shown in Fig. 7
                     . Nevertheless the quantity of landmarks was considerably less compared to the GCPs in every stereo pair utilized for this research.

Although, we could easily increase the number of features in each stereo pair to overcome these drawbacks, the increment of landmarks does not necessarily imply better accuracy. More precisely this approach of feature matching relies on strong features and it is not possible to enhance the accuracy if we increase the number of landmarks since the additional landmarks would be less strong in terms of accuracy. Fig. 8
                     , depicts the tradeoff between the accuracy of the feature correspondence approach and the extracted number of utilized features.

In terms of accuracy between the two proposed methods we constructed the diagram shown in Fig. 9
                     , where the tradeoff between the disparity levels and the average percent of bad pixels is explained. As the disparity levels increase the accuracy decreases due to the mismatching pixels and the enlargement of ambiguous regions. However, the GCPs approach is always more accurate than the one utilizing the SIFT algorithm.

All the experiments, as well as the processing time measurements, were executed on a 2.4GHz Intel Core Duo processor. The overall processing time of our method was: 36.1s for ‘Tsukuba’, 69.04s for ‘Venus’, 101.3s for ‘Teddy’, and 107.2s for ‘Cones’. After the implementation of the Markov chain framework, which aimed at reducing the computational complexity of the resampling part in particle filtering, we observed that the overall time in every stereo pair was reduced approximately by 10% as shown in Fig. 10
                     .

Our method has been evaluated also by the large image data set KITTI [41]. Fig. 11
                      demonstrates the resulted disparity map for a specific image pair and Table 3
                      presents the respective results for that stereo pair.

Experimental results reveal that the proposed particle filter framework works better when being moved outside from the laboratory to the real world. The global reasoning of the method along with its local particle filtering provide slightly better results compared to local and semi-global state-of-the-art algorithms. This is mainly because of the fact that the proposed method does not rely on assumptions met in purely local methods, such as single or bi-labeled window assumption [42], or the fronto-parallel segment assumption [43], which are often violated in real world scenes.

@&#CONCLUSION@&#

In this paper, we presented a stereo matching approach motivated by the particle filter framework in robot localization. Strong scale invariant features have been applied in each stereo pair in order to create the inference structure for the particle filter framework. Furthermore, the particle filtering structure has been implemented for the first time to determine the best possible disparity value of each pixel in a stereo pair. Moreover, the Markov chain model has been introduced in the process to reduce the computational complexity of particle filtering, along with a histogram refinement method. The experimental results showed that our method is capable of producing high quality disparity maps by taking advantage of global spatial and geometrical inference from distinctive sets of landmarks.

@&#REFERENCES@&#


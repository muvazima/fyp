@&#MAIN-TITLE@&#R.A.P.I.D. (Root Aggregated Prioritized Information Display): A single screen display for efficient digital triaging of medical reports

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Invariant single screen EHR visual display.


                        
                        
                           
                           All data within data sets of all sizes represented on a single screen.


                        
                        
                           
                           Data physically partitioned-critical or non-critical for prompt response or work triage.


                        
                        
                           
                           One screen representation of all reports from all EHR systems with interface.


                        
                        
                           
                           Data mining enabled.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Data display

Patient safety

Intuitive design

Critical result sign-off

Work triage

Button array

@&#ABSTRACT@&#


               
               
                  Objective
                  The timely acknowledgement of critical patient clinical reports is vital for the delivery of safe patient care. With current EHR systems, critical reports reside on different screens. This leads to treatment delays and inefficient work flows. As a remedy, the R.A.P.I.D. (Root Aggregated Prioritized Information Display) system represents all data on a single screen, and its simple and intuitive “button” array structure allows triaged sign-off/sign-out of critical and non-critical reports.
               
               
                  Materials and methods
                  With 100 hematology and chemistry reports from each of two EHR systems Meditech (Westwood, MA) and Orchard Labs, Inc. (Carmel, IN), we generated files of the reports in their individual standard display formats (enhanced Meditech-EM and enhanced Orchard-EO). We also displayed the same 200 reports in the R.A.P.I.D. format. We then conducted a randomized trial to compare the time and accuracy of acknowledgement of critical and non-critical results.
               
               
                  Results
                  The sign-off times for reviewing the results for physician and non-physician providers, respectively, in seconds (with 95% confidence intervals) were for EM 1.78 (1.40–2.26) and 1.99 (1.72–2.30), for EO 2.69 (2.12–3.42) and 2.78 (2.40–3.21), and for R.A.P.I.D. 0.83 (0.70–0.98) and 1.58 (1.43–1.76). Non-physician providers reassigned system-defined non-critical results as critical with a frequency of 15.2% for EM, 18.4% for EO, and 7.83% for R.A.P.I.D., and critical results as non-critical with a frequency of 14.7%, 5.6%, and 5.8% respectively.
               
               
                  Discussion
                  The new display system was superior to two standard EHR systems that were significantly enhanced by first collecting the reports from their usual distributed locations and then by creating for each of the two standard EHRs a single file of reports for acknowledgement.
               
               
                  Conclusions
                  From a single screen display of all reports, the new display system enables timely acknowledgement of critical reports for patient safety and non-critical report triage for improved provider work flows.
               
            

@&#INTRODUCTION@&#

Many Electronic Health Records (EHR) systems have structures that require complex navigation and work flows. The inevitable consequence is that providers are now burdened in delivering timely patient care [1–4]. A $17billion British health-service information-technology upgrade was terminated after $9.9billion in expenditures, because the program was “not fit to provide the modern information-technology services” needed by the country’s healthcare system; the article further noted that information technology systems are sometimes designed without “enough input from doctors and nurses who [then] rebel against the product” [5].

Communication of what one provider considers important needs to be understood by other individuals involved in the care of mutual patients. Recent articles suggest that the EHR should improve communication between nurse practitioner and primary care physicians [6,7]. This problem of communication might be eased if the EHR display facilitated the digital triage of work flow, as in report sign-off/sign-out. By “signing off” we mean the acknowledgement of a result. By “signing out” we mean the transfer of the task of acknowledgement to someone else.

However, there are a number of barriers to improving EHR performance. Currently, fully deployed EHR systems are generally not compatible with each other. At present no standard mechanism exists to test the structural re-design of fully deployed EHR systems. The serious concerns about potential compromise to patient data confidentiality further burden any effort at EHR redesign.

We determined as practitioners (JF, EA) the aspect where current EHR performance most lagged our current EHR need. We chose the development of a single screen display that could show all the data from a medical practice and highlight the critical data. Vital to optimal care delivery is the prompt acknowledgement of and response to critical reports. The notion of critical reports is well established and is a feature of current EHR systems, including the EHR systems in this study [8–12]. If a display could be developed that physically separates reports with critical results from those with non-critical results, the display could become the basis for a rational scheme for work triage.

Also, we structured the investigation to test if the provider always agreed with the EHR system-defined critical/non-critical designations. If providers frequently reassign results that the EHR designated critical as non-critical, and non-critical as critical, then the display design should have the capability, beyond that of acknowledging system-defined critical results, to allow the provider to set critical ranges and mine the patient data.

We wanted to create a standalone display system that relies only on an interface, agnostic to software language of EHR of report origin, to work easily with all existing EHR systems.

Finally, we decided that an initial off-line test of such a display system would provide important answers as to whether the effort to conduct a full-scale implementation of the display system would be justified.

The goal of the present work is to improve the cognitive ergonomics for health care providers. The widespread adoption of EHRs presents the provider with an ever escalating cognitive load from the ever increasing volume of archived patient data. An improved EHR may help lighten this cognitive load. The starting point of this work was the observation that optimal data visualization compared to tabular displays improves access to data and improves patient care delivery [13,14].

Edward Tufte in his classic study of the history of graphic displays in print format stated that “graphical excellence is that which gives the viewer the greatest number of ideas in the shortest time with the least ink in the smallest space” [15]. With Tufte’s perspective as background there have been many visual display systems implemented, often in the monitoring of health care and often for use as heuristic tools. Scatter plots have been used in a visual display to monitor changes in multiple patients for a small number of characteristics over time [16]. With a hierarchical tree or tree map design a display has been used to monitor the quality of health care delivery [17,18]. Another data display system with tree map-based icons uses clustering to detect common features among a heterogeneous population to define more precisely different groups of patients [19]. Spider plots have been used with individual patient data in the ICU against the historical patient data of many patients and many parameters to predict outcome [20]. A bubble chart design has been used to follow the quality of care adherence for colorectal cancer patients [21]. One limitation of these designs for use by practitioners in health care delivery is that only a limited number of parameters can be tracked (e.g. x-axis, y-axis, bubble size, and colour of bubble). This limitation exists also for data displays using histograms and contour maps [22].

A recent comprehensive review of EHR data visualization identified several challenges to be overcome for optimal data visualization and health care delivery [23]. These challenges include: clutter-resulting from the size and complexity of the data, the difficulty of presenting a great deal of data on a single screen and compliance, the time it takes practitioners to learn to navigate a display system in an unfamiliar display format [23]. A successful display format for health care delivery must meet the twin challenges of embracing data complexity while resisting display complexity.

The design simplicity of the dashboard may allow for these twin challenges to be met. A clinical dashboard “enables easy access to multiple sources of data being captured locally, in a visual, concise and usable format” [24]. To this point most medical dashboards have been used much more in patient care monitoring rather than in the improvement of the real time delivery of patient care. A recent review of the use of dashboards to improve medical care found 543 citations [25]. Of these citations, only 11 full reports had data on the use of dashboards to improve medical care. Among the 11 reports only 1 report was assessed to be of high quality [26]. The high quality report used colour-coding to track level of compliance in real time with a patient management protocol.

For the present study the novel display design had to meet the requirement for the provider to handle correctly and in real time a huge volume of patient results. The display needed to provide the provider a “vectored alert” to the fraction of those results that are critical and require immediate provider acknowledgement.

New display design approaches may help providers manage the novel challenges in data acknowledgement posed by the computerized EHR. To that end Wickens et al. proposed thirteen principles of display design for best human–computer interaction [27]. These principles are: (1) legible displays, (2) avoid single variable (rather a dynamic range/analog display), (3) top down processing (familiar/constant format), (4) redundancy gain (present data more than once), (5) similarity causes confusion-use clearly distinct elements, (6) pictorial realism (make display look like variable that it represents), (7) principle of the moving part (moving design features should move as the measured element moves), (8) minimizing information access cost (convenient to use), (9) proximity compatibility principle (related items near each other but avoid clutter), (10) principle of multiple resources (different sensory input, as audio and visual), (11) replace memory with visual information: knowledge in the world (calibrate the need for background information on the basis of the user’s subject familiarity), (12) principle of predictive aiding (including information about possible implications of data), and (13) principle of consistency (invariant design).

Using the principles of Wickens et al., with the goal of improving patient care delivery as well as optimizing health care resource utilization, we created a novel data visualization dashboard design that “minimizes access cost” (principle 8) and minimizes the number of clicks. The design adheres to the principle of “multiple resources” (principle 10) in displaying reports from different EHR systems in their original format but representing them in the invariant novel display. Adhering to the principle of “predictive aiding” (principle 12) critical and non-critical reports are separate in the display. The novel display design is invariant and thus consistent with principle of consistency (principle 13).

As mentioned before, the current data visualization designs share a common feature. With increasing data these designs become increasingly complex. This aspect of these designs violates Wickens et al. principles (9) avoiding clutter and (13) having an invariant design. We chose, instead, a display of absolutely invariant design. An invariant design allows an unlimited number of reports to be queued or stacked and the “above” view can still be intelligible. To minimize the hierarchical character of the data structure and the resultant time required for data discovery, we attempted to maximize the “active” surface of the display as a fraction of the total text on the screen. All reports in the data set are enumerated in “buttons” by data category. This structure enables each click of any “button” to the display the first and then progressively all subsequent and underlying reports in the queue (or stack).

The current display partitions data into reports with non-critical reports represented on the circumference of the circle and reports with critical data partitioned and distributed around the outside of the circle. The display can be the basis for work triage. In the present case clinical reports with critical results that lie outside the circle are be dealt with immediately. The reports with non-critical results can be either dealt by the provider with at a later time or triaged to another member of the health care team. This display with its binary partition of reports is a model that can be applied in all other areas in health care where reports with critical results occur among a vast excess of reports with non-critical results. Areas such as compliance and accounting are examples.

At present, a major problem in EHRs is the lack of compatibility across different EHR systems. The novel design with its invariant display represents all reports both those with critical and those with non-critical results on a single screen. This structure enables the single screen display of all the reports from one or many EHR systems regardless of the primary EHR software. The requirement for a robust two way interface to the different EHR systems is the only modification needed for its deployment. The novel display design represents all reports but displays the actual report in the format of the original EHR system.

The current study is formative, and is limited to a test of laboratory data only. The value of the current display will be much clearer after it has undergone a real time test in a functioning EHR (see Section 5).

@&#METHODS@&#

R.A.P.I.D. (Root Aggregated Prioritized Information Display) [28] is a circular, single screen display that represents all data (Fig. 1
                     A). The data are parsed into discrete data categories at fixed locations around the circle designated by small circles lying on the circumference of the larger circle. The smaller circles are all actually “buttons” that display the top report in a stack when the cursor is above a smaller circle. When the mouse is then clicked, that report is acknowledged and the next report is displayed. The number in the each small circle represents the count of non-critical reports in that data category. Each critical report, as specified by the EHR and potentially by the provider, is represented by a number in the small red circle outside the larger circle connected by a line to the corresponding data category with non-critical reports.

With new display, the user has a top down view of the entire stack of patient data represented in a three-dimensional structure composed of two sets of small concentrically arrayed cylinders. The new display distributes all reports into the cylinder of the appropriate data category. Any report with a critical result is counted in the outer cylinder array. All non-critical reports are counted in the inner cylinder array. For both critical and non-critical reports, each cylinder is variably filled with reports.

This one-screen display instantly reveals the complete set of critical reports that require urgent review (Fig. 2
                     ) located in the outer cylinder array and highlighted in red. Rather than a multiple screen search, the critical reports can be acknowledged serially, and quickly, each with a single mouse click from a single screen (see the accompanying video [29]).

The new display system is a stand-alone software application coded in the Java computer programming language because of Java’s excellent graphic display characteristics. The new display uses the My SQL database to manage login IDs and passwords. As mentioned above, with an appropriate interface, the new display system can represent all data from multiple EHR systems on a single screen and thus enable timely practitioner response to the EHR system that originated the report.


                     Fig. 1A displays 200 R.A.P.I.D. reports that include both non-critical results (20 in Hematology, 157 in Chemistry, 7 in Coagulation, and 8 in Microbiology) and critical results (3 in Hematology and 5 in Chemistry). In the example in Fig. 1A, the displayed report includes a critically high WBC at 34.9. As the cursor is hovering over the circle designating the critical hematology report, the full report appears on the right side of the screen, and a smaller version of the original new display persists on the left side of the screen. Abnormal, but non-critical, results are highlighted in yellow. To acknowledge a result, the computer cursor is placed over the small circle corresponding to the data category of interest and clicked (or touched on a touch-screen). If the circle indicates more than one result, then a second mouse-click opens the second report in the stack, and so on. The individual reports are arranged in a queue with the most recent reports located at the bottom of the respective critical or non-critical category For the purpose of understanding the novel display, the reports can be thought of as being “stacked” in a virtual third dimension and quantified by the number in the relevant circle.

Meditech [Meditech Health Care Co., Westwood, MA 02090] EHR, as configured at the Mount Nittany Medical Center, displays reports in a tabular format and flags critical results in red and abnormal but not critical results in yellow (Fig. 1B). Orchard Laboratory [Orchard Laboratory Information System, Carmel, IN 46032] EHR, as configured at the Mount Nittany Medical Center, also displays reports in a tabular format and flags critical results in red (Fig. 1C).


                     Fig. 2 demonstrates across the top of the figure the invariant shape of R.A.P.I.D., regardless of the size of the data files. The “stack” height of the data files increases from that of 4 reports on the left, to 112 reports in the centre, to 12,979 reports on the right. As mentioned above, the actual data structure represented as a cylinder is actually a three-dimensional structure composed of two concentric arrays of cylinders. Each cylinder contains the reports of a different data category and contains a varying number of reports. Critical reports are represented in the outer cylindrical array in red and non-critical reports in the inner array. The increase in data density going from left to right in Fig. 2 is indicated by the corresponding increase in grey scale.

Critical data are signed off immediately by the appropriate healthcare provider for the single patient data (left column in Fig. 2); for the entire data set from the provider’s practice (centre column in Fig. 2); and for the entire data set of multiple provider practices (right column in Fig. 2). Beyond provider use, the multiple practice dataset in the new display format may also be useful elsewhere in health care delivery (see Section 5).


                     Fig. 3
                      shows how the new display, with the same data as in Fig. 2, can help to define workflow to improve practitioner efficiency, resource utilization, and patient safety. Providers sign off critical reports immediately. Non-critical reports can be signed off later by the provider or signed out to other members of the health-care team for sign off. The critical/non-critical data triage option is useful to any team or user of data in health care. An example includes an ICU nurse who monitors patient status with the novel display enabled triage of defined critical results to the responsible ICU physician for action. Another example is a nurse practitioner that uses the novel display to screen large patient populations for compliance with surveillance health screening.

With both adjustable time-windows and adjustable critical values the new display enables any user a one-screen representation of the entirety of the user’s universe with data defined as critical, in part, by the user on the fly.

From a data set of 30,797 de-identified, random laboratory results from the Meditech EHR we created a file or queue of 100 reports (designated enhanced Meditech or EM). From a similar data set of 9914 de-identified, random laboratory results from Orchard Laboratories we created a second file or queue of 100 reports (designated enhanced Orchard or EO). Each report remained in the format of the originating EHR system (Fig. 1). The same 200 reports were queued in a file and represented in the novel display format (Fig. 1) but displayed in the format of the original EHR (Meditech or Orchard). The report queues for acknowledgement in all three systems (EM, EO, and R.A.P.I.D.) had the same structure. The reports were placed in the appropriate categories, i.e. Hematology, Chemistry, Coagulation or Microbiology. The first click opened the first category (Hematology). That click also displayed the first report at the top of the queue for acknowledgement. The next click acknowledged the first report and also displayed the second report and so on. After the last report in a category was acknowledged, the next category was opened and so on until all, either 100 or 200 (in R.A.P.I.D.) reports, had been acknowledged (see Fig. 1). We included 12 physician providers and 30 non-physician providers who volunteered to measure the accuracy and speed in report sign-off. Study participants were asked to assign reports to the categories critical and non-critical (including both normal and abnormal but not critical). Each participant reviewed 100 reports in EM, 100 in EO, and 200 in R.A.P.I.D., on a common test computer in a timed manner, and the outcome was the average time in seconds required to sign off each report by a click in all cases. Accuracy was determined to be the compliance of the critical/non-critical assignment for a report by a study participant with the critical/non-critical assignment by the respective EHR system.

The data categories and data ranges that we use to designate a result as critical were those of the original EHR system that provided the report, as applied at the Mount Nittany Medical Center in State College, Pennsylvania.

The data were de-identified prior to distribution to the investigators and consisted of laboratory data only. The Mount Nittany Medical Center Institutional Review Board determined that the study of de-identified data did not require Institutional Review Board approval. Test subjects were selected and agreed to participate. Their survey responses were also de-identified as to test subject and are stored on two secure computers with no other dissemination.

Initially, a group of 12 physician providers signed off the three report groups. The physicians used the R.A.P.I.D. system that normally has only an acknowledgement function for review of reports. The error rate for the physician provider group with R.A.P.I.D. was therefore zero. Reports in R.A.P.I.D. with critical results are queued for review before reports containing only non-critical results. Both EM and EO systems were provided with a critical and a non-critical button so that the test participant could change the critical/non-critical designation of a report.

For the purposes of this study only, R.A.P.I.D. was then altered to allow a second group of study participants to reassign system designated critical/non-critical results. The new display acknowledgement function was therefore replaced with critical and non-critical buttons for sign-off. Then 30 nurses, nurse practitioners and physicians’ assistants (non-physician providers) with non-critical and critical buttons signed off the same set of reports in each of the three systems.

The order in which each subject reviewed the stack of reports was randomized, using a block randomization scheme to balance the order in which the systems were assigned. The order in which each subject was assigned to the EHR systems was randomized (Supplementary Materials Appendix Table 1 [30]). This constrained randomization scheme balances the cross-over design to ensure a fair comparison among the three methods, thus each method was used an equal number of times, as the first, second, and third system, by the test subject.

The analyses of the results of the 12 physician providers and 30 non-physician providers were conducted by fitting a three-way, mixed-effects, analysis-of-variance model which compared the mean time to review the laboratory data, measured in milliseconds. The fitted model was conducted on the logarithm of sign-off time with a model for the crossover experimental design using the rater (physician providers or non-physician providers) as a random effect, and which provided a test for a possible significant system and/or order effect.

To determine accuracy of the provider, the results for each test subject were scored for the frequency of reassignments of the EHR system defined non-critical to critical and of critical to non-critical for all three EHR formats separately. The frequency of reassignments among the three systems was compared using the Chi-square test for equal proportions.

@&#RESULTS@&#

The results, estimates, and confidence intervals are expressed in seconds. Fig. 4
                      shows the mean sign-off times for the three systems. Both physician provider and non-physician provider study subjects were timed, on a report-by-report basis, to sign off each result as either critical or non-critical. The analysis of variance mixed model showed significant differences among the three systems (p-value<0.001), and a significant (p-value<0.001) order effect, for both physician and non-physician providers. The results across systems for the physician provider and non-physician provider, respectively, per report acknowledgement in seconds (95% confidence intervals) were for EM 1.78 (1.40–2.26) and 1.99 (1.72–2.30), for EO 2.69 (2.12–3.42) and 2.78 (2.40–3.21), and for R.A.P.I.D. 0.83 (0.70–0.98) and 1.58 (1.43–1.76). The order effect showed a significant decreasing time from the first to the third system tested.

EM’s superiority relative to EO may relate to the assignment of a yellow colour to non-critical, but abnormal, results in EM. This feature might decrease the set of results that a subject would examine to partition between the critical and non-critical designations.

The improved sign-off times of the physician providers with the new display system compared to those of the non-physician providers is likely because the new display system, for the physician providers, had only a single acknowledgement button. However the significantly improved times for the non-physician providers using R.A.P.I.D. were based on identical acknowledgement protocols that differed only in the display.

The 30 non-physician providers frequently reassign with EM, and similarly with R.A.P.I.D., results as critical that the Meditech system designates as non-critical (Fig. 5
                     A). The reassignment as critical by each non-physician provider for each of the 95 non-critical results is indicated by a “tick”. The 30 non-physician providers also reassign with EM, and again similarly with R.A.P.I.D., results as non-critical that the Meditech system designates as critical. The assignment of non-critical by each of the 30 non-physician providers for each of the 5 critical results is indicated by a “tick” (Fig. 5B). Non-physician provider reassignment of the 97 results as critical that the Orchard system designates as non-critical is indicated in Fig. 5C. Non-physician providers reassign with EO the 3 results as non-critical that the Orchard System designates as critical. The reassignment pattern for these results is very much the same with R.A.P.I.D. (Fig. 5D).

The aggregate results of non-critical/critical reassignment reveal that among the 2850 results in EM that were designated non-critical by the system, 15.2% were reassigned as critical by the 30 non-physician providers. For EO, of the 2910 results that the system designated non-critical, 18.4% were reassigned as critical. For R.A.P.I.D., of the 5760 combined results that the respective systems designated as non-critical, 7.83% were reassigned as critical. These percentage differences are significant at p
                     <0.0005, and the reassignment rate for R.A.P.I.D. is significantly lower than for both EM and EO. For the 150 results designated critical in EM and the 90 critical results in EO the rate of reassignment was 14.7% for EM, 5.6% for EO and 5.8% for the 240 combined reports in R.A.P.I.D. (Fig. 5E). These reassignment rates are significantly different at p
                     =0.003, with R.A.P.I.D. at a significantly lower rate than EM at p
                     =0.02.

The concordance (“mirror image”) of reassignment by non-physician providers on a question-by-question basis was evident for both system-defined critical and non-critical results between both EM and R.A.P.I.D. as well as between EO and R.A.P.I.D. Such concordance is consistent with a highly non-random (i.e., decision-based) process.

@&#DISCUSSION@&#

With the new display system all reports are represented on a single screen with critical reports highlighted in red in the outer concentric array and non-critical results in the inner array. The new display system is a “button” array that with a cursor “hover and click” enables the direct display and progressive acknowledgement of represented reports from this simple, invariant format. The structure facilitates the triage of data review: critical results are signed off immediately by the provider and non-critical results can be signed off later by the provider or signed out to another member of that health-care team.

R.A.P.I.D. demonstrated superiority compared with the enhanced versions of two standard EHR systems, both in reducing review times and improving accuracy. Clinical report review with the new display is considerably faster than the test results demonstrate, because the reports for EM and EO were grouped in a single stack or file rather than separated from each other by multiple screens as is the usual case with Meditech and Orchard. This change allowed all reports in both Meditech and Orchard to be reviewed sequentially. Without this modification, and depending on the number of screens that would need to be searched to review all reports first on a patient-by-patient basis, then on a data category-by-category basis and finally on a report-by-report basis, the provider would need significant additional time to acknowledge a report in the standard Meditech and Orchard systems. By contrast, for the purposes of the survey the new display system, which normally has a single acknowledgement button, was fitted with a two-button critical/non-critical acknowledgement modification (and thus less efficient) to match the structure of EM and EO. Despite these modifications, the survey results show that R.A.P.I.D. is superior to EM and EO in report acknowledgement time and accuracy. The novel display system, with its simple, invariant button structure, also enables critical/non-critical reports of any number to be represented on a single screen for acknowledgement.

Non-physician providers frequently overrode both system-designated non-critical and critical reports. These reassignments are carried out in a highly non-random (i.e., decision-based) fashion and suggest that users now apply their own critical settings in their current practice of data review. The capability with R.A.P.I.D. for the user to adjust critical categories/values (Fig. 6
                     ) in addition to those defined by the EHR system as well as to set time windows of data reviewed will enable providers to improve patient care.

Additional features of the new display system for the user that were not part of the present study include the ability: (a) to toggle directly between displays of individual patient reports and those of larger groups of patients (Fig. 2), (b) to flag changes of critical magnitude (e.g., a hemoglobin drop of 20–30%) (Fig. 6), and (c) to conduct text-based document searches. These capabilities of the new display system, including reviews of text format reports, are demonstrated in the accompanying video [27].

In summary, the new display system is a stand-alone data structure and display format that can integrate data from multiple EHR systems onto a single screen representation. The new display system can be adapted for a hand-held device because the “stacking” feature generates a simple data display regardless of data complexity. It enhances patient safety through its simple contextual representation of all critical/non-critical data on a single screen that improves care provider communication.

Data displayed in this new display format would be ideal for use by administrators, compliance officers, researchers, the patients themselves, and in fact anyone with sanctioned access to patient data. On the basis of these results and to quantify the benefit of R.A.P.I.D., we now recommend that a real-time study with the use of complete patient data be conducted. Such a study would allow the full scope of the new display design benefit to be quantified. Further, this study would also enable the test of language-based critical/non-critical report assignment, such as those in the areas of radiology and pathology, as well as the display of critical/non-critical vital sign and drug interaction data.

Beyond its use by practitioners in optimizing patient care, the current display design will be useful within health care wherever critical data exists randomly within a huge volume of non-critical data. Examples include the use by nurses, in similar fashion to that we describe for practitioners, in monitoring the vital signs of all patients. Practice administrators can use the display design to monitor the compliance of a group of many practitioners with care guidelines. The billing office could monitor the payment histories of patients and their insurers.

The “button” array format presented here for review of patient data by health-care providers can also be used in many other contexts (academic, commercial, and military) where, on a single screen, a data set of virtually any data size can be categorized and represented around a circle at set locations and then partitioned into physically distinct non-critical and critical components.

Finally, this report shows that providers are already modifying critical ranges informally as part of their current due diligence to give optimal patient care. In addition to establishing default critical settings, EHR systems, generally, should enable user defined critical settings and time windows for data review.

This research received no specific grant from any funding agency in the public, commercial or not-for-profit sectors.

A U.S. patent has been issued for the design of R.A.P.I.D. and JPF and LYH are listed as inventors [26]. The remaining authors have no competing interests to declare.

All authors contributed to the writing and editing of the report. EA guided the approach to connecting to the clinical audience. DR and JLR designed the clinical trial and provided the supporting statistical analysis. LYH provided improvements to the R.A.P.I.D. design and created the enabling software for R.A.P.I.D. JPF designed the initial R.A.P.I.D. structure.

@&#ACKNOWLEDGMENT@&#

Craig Williamson of Williamson Adams, Walnut Creek, CA assisted with graphic design production.

@&#REFERENCES@&#


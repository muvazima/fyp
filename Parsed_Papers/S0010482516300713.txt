@&#MAIN-TITLE@&#Edge density based automatic detection of inflammation in colonoscopy videos

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A model based method for automatic inflammation detection in colonoscopy videos is introduced.


                        
                        
                           
                           The method relies on a high quality display provided by Olympus colonoscopy probe.


                        
                        
                           
                           The proposed method is suitable for parallel implementation and real-time processing of high-resolution colonoscopy videos.


                        
                        
                           
                           Real-time inflammation detection can provide the gastroenterologist with a useful tool to enable faster and more accurate diagnosis.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Colonoscopy

Inflammation

Texture

Automatic detection

@&#ABSTRACT@&#


               
               
                  Colon cancer is one of the deadliest diseases where early detection can prolong life and can increase the survival rates. The early stage disease is typically associated with polyps and mucosa inflammation. The often used diagnostic tools rely on high quality videos obtained from colonoscopy or capsule endoscope. The state-of-the-art image processing techniques of video analysis for automatic detection of anomalies use statistical and neural network methods. In this paper, we investigated a simple alternative model-based approach using texture analysis. The method can easily be implemented in parallel processing mode for real-time applications. A characteristic texture of inflamed tissue is used to distinguish between inflammatory and healthy tissues, where an appropriate filter kernel was proposed and implemented to efficiently detect this specific texture. The basic method is further improved to eliminate the effect of blood vessels present in the lower part of the descending colon. Both approaches of the proposed method were described in detail and tested in two different computer experiments. Our results show that the inflammatory region can be detected in real-time with an accuracy of over 84%. Furthermore, the experimental study showed that it is possible to detect certain segments of video frames containing inflammations with the detection accuracy above 90%.
               
            

@&#INTRODUCTION@&#

Colon cancer is recognized as one of the most common malignant diseases, thus regular examination of colon gains importance, especially for high risk populations [1]. Prevention of colon cancer is related to the detection of polyps, since untreated polyps can develop into cancer [2]. Inflammatory bowel diseases (most commonly Crohns disease and ulcerative colitis) are chronic diseases that include inflammation in the gastrointestinal tract. Early stage detection of inflammatory diseases is very important as it allows the patient to be provided with dietary advice and precaution. Polyps and inflammation can be detected during various medical procedures which include analysis of high-length videos, implying the necessity of computer-aided diagnostics of the gastrointestinal tract and its discussion within the scientific community.

The most effective colon screening method is colonoscopy, which is a bowel examination procedure that uses a camera and a flexible tube. Colonoscopy provides high resolution video, suitable for easy visual detection of pathological inflammation and colon diseases. Although colonoscopy can provide high quality videos and efficient ways to visually detect anomalies and ability to collect tissue samples in vivo, it is invasive and often uncomfortable [3] and gives view to colon only. One alternative medical approach for examination of the digestive tract is the so-called virtual colonoscopy, which includes the analysis of computer tomography (CT) scans. This method irradiates the patient. In the last decade, capsule endoscopy (CE) treatment has gained popularity. It is a minimally invasive screening approach which allows viewing the complete digestive tract without sedation, radiation or air-inflation. Capsule endoscopy uses a smart pill equipped with a camera and a radio transmitter that sends images to a recorder attached to the patient's waist. Smart pill can record over an eight hour long period, providing thousands of images. An overview and manual annotation of the complete dataset from one examination is time consuming. It would be helpful to automatically select images showing anomalies, such as internal bleeding, polyps and inflammation. If a physician is focused on images with higher priority, diagnosis requires less time. The main advantage of CE is the possibility of image acquisition throughout the whole digestive tract.

Even though physicians are able to observe live video during the colonoscopy examination, during which visual overview is usually sufficient to detect anomalies, additional real-time processing may be helpful for pinpointing the exact location of anomalies and faster visual detection. Another motivation for real-time processing of colonoscopy videos can be supported by the study showing that accuracy of real-time optical small polyp (less than 1cm) detection made by gastroenterologists, is approximately 76% [4]. Therefore, real-time processing of high definition video can be useful to provide the gastroenterologist with a decision making tool to improve the human performance. Nevertheless, it is hard to implement real-time processing, especially if complex algorithms need to be included. On the other hand, parallel implementation can provide fast processing and less time consumption.

Two main starting goals of this research were enabling fast video processing and achieving a high detection rate of inflammatory tissue. The algorithm proposed in this paper relies on neither computationally expensive feature extraction nor statistical learning. We took advantage of new technological developments in video acquisition, which can provide high quality video data. We used videos obtained by the Olympus probe [5] which delivers images with increased brightness and contrast, enabling close mucosal observation. The probe has an optical system with depth of field from 2 to 100mm. Observing from closer distance can reveal fine texture of mucous when it is either healthy or inflamed. The first contribution of this research is a proposal of a simple and fast texture analysis based on edge density estimation, which is used for automatic inflammation detection. The second contribution is the fact that parallel implementation of the proposed algorithm based on General Purpose computing on Graphics Processing Units (GPGPU) using OpenCL and C♯proved that colonoscopy videos can be automatically annotated in real time.

The rest of the paper is organized as follows. Section 2 gives a brief overview of the related literature, Section 3 describes the data used, while Section 4 describes the proposed algorithm in details. Section 5 describes the experimental setup and discusses the experimental results. Section 6 is a conclusion.

@&#RELATED WORK@&#

As it was briefly described in the previous section, recent technology improvements enabled acquisition of high resolution colonoscopy videos as well as large amounts of capsule endoscopy images. For automatic polyp detection in colonoscopy videos two major approaches are block-based classification and model-based detection. In [6] analysis of frames extracted from colonoscopy video footage is used for automatic polyp detection based on simple spatial-color features, Support Vector Machines (SVM) and previously manually labeled polyp regions. The authors divided every available frame into blocks of size 40×40 pixels. One specific block is considered to contain polyp only if a certain number of block's pixels overlap with manually labeled polyp mask. Ameling et al. used local texture features in [7] to automatically detect polyps in high resolution colonoscopy videos in a block-based approach similar to [6]. Häfner et al. in [8] used multi-scale local color patterns to automatically classify endoscopy images according to a pit pattern classification scheme. The authors used the local color vector pattern and k-Nearest Neighbors (kNN) classifier to classify 716 colonoscopy color images into pit pattern types. Although they emphasized on the speed and computational simplicity of multispectral image processing, they were able to achieve the classification accuracy over 85%. Bernal et al. in [9] proposed a model based polyp detection approach. In their research, a robust model of polyp appearance was developed to extract adaptive descriptors used for automatic detection of polyp regions in 380 colonoscopy images.

Li and Meng used local textural features for automatic detection of various bowel diseases in [10–13]. They reported the classification accuracy over 93% when features based upon wavelet transformation and local binary pattern were used in order to detect small bowel tumor [10,13] and the classification accuracy over 92% when feature based upon curvelet transformation and local binary pattern were used in order to detect ulcer [11]. They also suggested the usage of chromaticity moments for bleeding and ucelar detection [12]. Furthermore, various color and texture features were used for bleeding detection [14], informative frame detection [15] and analysis optimization [16]. In [17] a method based upon analysis of morphological and texture information of the colon wall, was used to detect polyps, while Tu et al. in [18] used a probabilistic model for object detection in order to detect polyps in CT scans. An improved model for polyp segmentation presented in [19] increased the accuracy of CT-based polyp detection. Authors reported the detection rate over 98% for polyps larger than 3mm. The overview of diagnostic methods, their properties and achieved accuracies is given in Table 1
                     .

Based on the literature review, we can notice that there are proposed and discussed algorithms for detection of various anomalies in the digestive tract. However, automatic inflammation detection remains undiscussed in the existing literature. To the best of our knowledge this is the first research on automatic inflammation detection within colonoscopy videos. Anomalies in images of the digestive tract are usually detected with a block-based approach, relying on the advantages of SVM or kNN classifier. Training of classifier is done offline, using a previously manually labeled dataset of CT scans, CE images or frames extracted from colonoscopy videos. In other words, no real-time processing was discussed in details. We concluded that a model-based approach is more suitable for real-time video annotation, compared to an approach based on statistical learning. Robust models could be developed for every targeted anomaly. Motivated by the research presented in [9] and the fact that various probes provide images with different details, magnification and colormap, we wanted to introduce a model-based approach for automatic inflammation detection suitable for Olympus probes.

We used three colonoscopy videos with different durations and with a frame resolution of 768×576 pixels and a frame rate of 25fps, all of which were obtained using the Olympus probe. This video footage contains segments showing pathological inflammation and segments with healthy tissue, including upper and lower part of the descending colon. All videos were examined and tagged by specialists so that we can differentiate between frames showing inflammatory and healthy tissue without ambiguities. The overview of the available videos with describing details is given in Table 2
                     .

Considering the fact that the aim is inflammation detection, after careful examination of all videos we concluded that exploiting the local texture of inflammatory tissue should be sufficient to differentiate between inflammatory and healthy regions. To enable a closer look at a fine structure of the colon lining that the Olympus probe can provide, we extracted example blocks from inflammatory and healthy regions. These blocks, shown in Fig. 1
                      , are used for demonstration purposes, only. The blocks given in Fig. 1a are extracted from the frames that show healthy tissue of the upper part of the descending colon. These blocks have small variations of light red color and lack noticeable edges. The blocks given in Fig. 1b are extracted from the frames that show healthy tissue of the lower part of the descending colon. In this case, submucosal blood vessels can clearly be seen. A shape of the blood vessels defines a characteristic texture with elongated edges. The blocks given in Fig. 1c are extracted from frames that show inflammation. Light red color of tissue and blood vessel structure is missing due to submucosal bleeding. The texture of the tissue has local variations of strong red color which define a characteristic pattern with irregular edge distribution. In the next section, we demonstrate that automatic detection of frame regions showing inflammation can be done based on the analysis of the described local features.

Since real-time processing of high-resolution colonoscopy video is the primary goal of the research, the detection algorithm must be optimized for fast execution. This implies simplicity in design which often implies a high error rate, or high degree of parallelism. Since processing is meant to be integrated with a portable device, the hardware could be constrained in terms of size and power usage which implies limited parallelism. A simplified parallel approach combining high performance and low error rate is proposed. The proposed algorithm is based on sequential convolutions and overlapping block analysis, highly suitable for GPGPU processing. The algorithm takes a grayscale image (one specific frame from colonoscopy video) and returns a fuzzy (grayscale) mask of detected inflamed regions of tissue, where mask pixel intensity values correspond to detection strength.

The proposed algorithm takes advantage of healthy colons surface smoothness and color uniformity properties. Any deviations from this pattern, such as subsurface blood accumulation, submucosal hemorrhage, tares, scarring or shriveling, result in a visible texture-like pattern on the surface of the colon detectable by a high-resolution probe. Even though the exact pathology cannot be determined with the probes recording, the area containing the anomalies can be marked as suspicious and flagged for further analysis. Three different regions which can be described with characteristic textures are considered: healthy tissue without blood vessels from the upper part of the descending colon, healthy tissue with blood vessels from the lower part of the descending colon and inflamed tissue in the descending colon. Since each of these regions consists of texture with different line distribution and edge orientation, the proposed approach contains following phases: (a) Kernel-based edge detection, (b) removal of overexposure effects, (c) (optional) sharp contours detection, (d) small block filtering, and (e) large block filtering. Pseudo code of the proposed algorithm is given in Algorithm 1.
                        Algorithm 1
                        The proposed algorithm.
                              
                                 
                                    
                                    
                                    
                                       
                                          1:
                                          Input: 
                                                
                                                   Image
                                                   (
                                                   I
                                                   )
                                                
                                             ,
                                       
                                       
                                          2:
                                          
                                             procedure 
                                             Edge detection (use: modified Sobel kernel K
                                             
                                                MS
                                             )
                                       
                                       
                                          3:
                                          
                                              Convert image to grayscale, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   G
                                                   ←
                                                   rgb
                                                   2
                                                   gray
                                                   (
                                                   I
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          4:
                                          
                                              Convolution, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   filteredG
                                                   ←
                                                   |
                                                   G
                                                   ⋆
                                                   
                                                      
                                                         K
                                                      
                                                      
                                                         MS
                                                      
                                                   
                                                   |
                                                   +
                                                   |
                                                   G
                                                   ⋆
                                                   
                                                      
                                                         K
                                                      
                                                      
                                                         MS
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                   |
                                                
                                             
                                          
                                       
                                       
                                          5:
                                          
                                             procedure 
                                             Overexposure effect removal (use: smallBlockSaturation)
                                       
                                       
                                          6:
                                          
                                             
                                             if 
                                             
                                                
                                                   filteredG
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   >
                                                   smallBlockSaturation
                                                
                                              
                                             then 
                                             
                                                
                                                   filteredG
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   ←
                                                   0
                                                
                                             
                                          
                                       
                                       
                                          7:
                                          
                                             procedure 
                                             (Optional) Blood vessel detection (use: Sobel kernel K
                                             
                                                S
                                             )
                                       
                                       
                                          8:
                                          
                                             Grayscale image downscale, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   S
                                                   ←
                                                   imResize
                                                   (
                                                   G
                                                   ,
                                                   0.25
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          9:
                                          
                                             Convolution, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   filteredM
                                                   ←
                                                   |
                                                   M
                                                   ⋆
                                                   
                                                      
                                                         K
                                                      
                                                      
                                                         S
                                                      
                                                   
                                                   |
                                                   +
                                                   |
                                                   M
                                                   ⋆
                                                   
                                                      
                                                         K
                                                      
                                                      
                                                         S
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                   |
                                                
                                             
                                          
                                       
                                       
                                          10:
                                          
                                             
                                             if 
                                             
                                                
                                                   filteredM
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   <
                                                   100
                                                
                                              
                                             then 
                                             
                                                
                                                   filteredM
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   ←
                                                   0
                                                
                                             
                                          
                                       
                                       
                                          11:
                                          
                                             Filtered image upscale, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   
                                                      
                                                         filteredM
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   ←
                                                   imResize
                                                   (
                                                   filteredM
                                                   ,
                                                   4
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          12:
                                          
                                             Filtered image blurring, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   
                                                      
                                                         filteredM
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   ←
                                                   blur
                                                   (
                                                   
                                                      
                                                         filteredM
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          13:
                                          
                                             Combination, 
                                                ▹
                                             
                                             
                                                
                                                   filteredG
                                                   ←
                                                   filteredG
                                                   −
                                                   2
                                                   ×
                                                   
                                                      
                                                         filteredM
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          14:
                                          
                                             
                                             if 
                                             
                                                
                                                   filteredG
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   <
                                                   0
                                                
                                              
                                             then 
                                             
                                                
                                                   filteredG
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   ←
                                                   0
                                                
                                             
                                          
                                       
                                       
                                          15:
                                          
                                             procedure 
                                             Small block filtering (use: smallBlockSize, smallBlockAverage, upA, upB, mask, step)
                                       
                                       
                                          16:
                                          
                                             
                                             while 
                                             
                                                
                                                   upA
                                                   <
                                                   a
                                                   ,
                                                   upB
                                                   <
                                                   b
                                                
                                              
                                             do
                                          
                                       
                                       
                                          17:
                                          
                                             
                                             
                                             
                                             if 
                                             
                                                
                                                   mean
                                                   (
                                                   smallBlock
                                                   )
                                                   >
                                                   smallBlockAverage
                                                
                                              
                                             then
                                          
                                       
                                       
                                          
                                          
                                             
                                             
                                             
                                             
                                             
                                                
                                                   mask
                                                   (
                                                   smallBlock
                                                   )
                                                   ←
                                                   mask
                                                   +
                                                   1
                                                
                                             ,
                                       
                                       
                                          18:
                                          
                                             
                                             
                                             
                                             
                                                
                                                   upA
                                                   ←
                                                   upA
                                                   +
                                                   step
                                                
                                             , 
                                                
                                                   upB
                                                   ←
                                                   upB
                                                   +
                                                   step
                                                
                                             ,
                                       
                                       
                                          19:
                                          
                                             procedure 
                                             Large block filtering (use: upA, upB, mask
                                             
                                                new
                                             , step, largeBlockSize, largeBlockThreshold)
                                       
                                       
                                          20:
                                          
                                             Initialization, 
                                             
                                                ▹
                                              
                                             
                                                
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   ←
                                                   mask
                                                
                                             
                                          
                                       
                                       
                                          21:
                                          
                                             
                                             while 
                                             
                                                
                                                   upA
                                                   <
                                                   a
                                                   ,
                                                   upB
                                                   <
                                                   b
                                                
                                              
                                             do
                                          
                                       
                                       
                                          22:
                                          
                                             
                                             
                                             
                                             if 
                                             
                                                
                                                   sum
                                                   (
                                                   largeBlock
                                                   )
                                                   >
                                                   largeBlockThreshold
                                                
                                              
                                             then
                                          
                                       
                                       
                                          
                                          
                                             
                                             
                                             
                                             
                                             
                                                
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   (
                                                   largeBlock
                                                   )
                                                   ←
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   +
                                                   1
                                                
                                             
                                          
                                       
                                       
                                          23:
                                          
                                             
                                             
                                             
                                             else
                                          
                                       
                                       
                                          24:
                                          
                                             
                                             
                                             
                                             
                                             
                                                
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   (
                                                   largeBlock
                                                   )
                                                   ←
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   −
                                                   1
                                                
                                             ,
                                       
                                       
                                          25:
                                          
                                             
                                             
                                             
                                             
                                                
                                                   upA
                                                   ←
                                                   upA
                                                   +
                                                   step
                                                
                                             , 
                                                
                                                   upB
                                                   ←
                                                   upB
                                                   +
                                                   step
                                                
                                             
                                          
                                       
                                       
                                          26:
                                          Clipping, 
                                             
                                                ▹
                                              
                                             if 
                                             
                                                
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   <
                                                   0
                                                
                                              then 
                                                
                                                   
                                                      
                                                         mask
                                                      
                                                      
                                                         new
                                                      
                                                   
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                   ←
                                                   0
                                                
                                             
                                          
                                       
                                       
                                          27:
                                          Output: mask
                                             
                                                new
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

The texture of inflammatory tissue has high color intensity variations and edge detection in a colonoscopy image yields feature-rich results. Edge detection can reveal line structure which is used to distinguish between healthy tissue without blood vessels (low edge density), healthy tissue with blood vessels (high density of elongated lines) and inflammatory tissue (high density of curved lines). In other words, edge detection can be used to estimate local edge density and it is used as a model for the proposed inflammation detection algorithm. In order to estimate local edge density, we propose a single kernel suitable for local line detection, which is a modification of the Sobel operator and it is given with the following matrix:
                           
                              (1)
                              
                                 
                                    
                                       
                                          K
                                       
                                       
                                          MS
                                       
                                    
                                    =
                                    [
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                −
                                                1
                                             
                                             
                                                −
                                                1
                                             
                                             
                                                1
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                −
                                                2
                                             
                                             
                                                −
                                                2
                                             
                                             
                                                2
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                −
                                                2
                                             
                                             
                                                −
                                                2
                                             
                                             
                                                2
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                −
                                                1
                                             
                                             
                                                −
                                                1
                                             
                                             
                                                1
                                             
                                          
                                       
                                    
                                    ]
                                 
                              
                           
                        This kernel and its transpose are used to detect horizontal and vertical edges. If we denote a single grayscale image as G, the convolution of kernel (1) and its transpose with the image, enable vertical and horizontal detection, 
                           
                              G
                              ⋆
                              
                                 
                                    K
                                 
                                 
                                    MS
                                 
                              
                           
                         and 
                           
                              G
                              ⋆
                              
                                 
                                    K
                                 
                                 
                                    MS
                                 
                                 
                                    T
                                 
                              
                           
                        , respectively. The output is obtained as a pixel based summation of absolute values:
                           
                              (2)
                              
                                 
                                    filteredG
                                    (
                                    i
                                    ,
                                    j
                                    )
                                    =
                                    |
                                    G
                                    (
                                    i
                                    ,
                                    j
                                    )
                                    ⋆
                                    
                                       
                                          K
                                       
                                       
                                          MS
                                       
                                    
                                    (
                                    i
                                    ,
                                    j
                                    )
                                    |
                                    +
                                    |
                                    G
                                    (
                                    i
                                    ,
                                    j
                                    )
                                    ⋆
                                    
                                       
                                          K
                                       
                                       
                                          MS
                                       
                                       
                                          T
                                       
                                    
                                    (
                                    i
                                    ,
                                    j
                                    )
                                    |
                                    ,
                                 
                              
                           
                        where 
                           
                              filteredG
                              (
                              i
                              ,
                              j
                              )
                           
                         is the gray level of pixel on position (i,j) within the filtered image. To demonstrate the efficiency of the proposed kernel, we filtered blocks given in Fig. 1, according to (1) and (2). The results are given in Fig. 2
                        . If we ignore the regions of overexposure, we can notice that the resulting blocks of inflammatory tissue have denser edges compared to the healthy tissue, especially in the upper colon. It is important to underline two problems with the proposed approach: (1) overexposure from light reflection (the result of the edge detection over these small regions can give high intensity gray levels in filtered image, increasing local edge density and possibly causing misclassification of these regions as an inflammation). (2) The presence of submucosal blood vessels in the frames showing the lower part of the descending colon (filtering regions containing these blood vessels can give regions with high edge density and cause similar false inflammatory detection).

Overexposure produces regions with very dense edges, i.e. false inflammatory regions. To circumvent this, we decided not to remove overexposure with additional preprocessing of images, but remove the mentioned effects, which is easier and less computationally expensive. After filtering the image with the proposed kernel (1), the resulting image is processed only to eliminate the effect of the pixels with very high gray levels. This is done with the simple comparison of pixel's gray level value from the filtered image and the predefined threshold value, which is denoted as smallBlockSaturation in Algorithm 1. Simply, if the pixel's values are higher than the value defined by smallBlockSaturation, it is set to zero. This step removes the effect of artifacts caused by light reflecting off the colon walls. The results of the proposed overexposure effects removal procedure applied to the filtered example blocks given in Fig. 2 are shown in Fig. 3
                        . As we can notice, the artifacts are removed.

A detailed analysis of the last step shows that the edge density of inflammatory tissue (Fig. 3c) is slightly higher compared to the lower colon healthy tissue (Fig. 3b) and much higher compared to the upper colon healthy tissue (Fig. 3a). It is noticeable that the edge density estimation works well when the probe is deeper in the colon, where there are no visible blood vessels. However, in the lower part of the colon, near the rectum, a high resolution probe is able to detect blood vessels as we can see on the sample frame given in Fig. 1b. We observed that the proposed edge detection approach can give similar edge densities for the region of healthy tissue with blood vessels as for the regions with inflammations. Therefore, it is reasonable to expect a higher rate of false inflammation detection. Hence, an additional phase for excluding the influence of the blood vessels is introduced.

Blood vessels have a contour-like shape and they can also contribute to the local edge density, so another kernel-based edge detection approach was implemented for their detection. Considering that blood vessels have a larger width than the aberrations resulting from inflammation, blood vessel contour detection was executed on downscaled images. Briefly explained, this phase includes image downscaling, edge detection using Sobel kernel, image upscaling and finding the difference between the original filtered image and the image with blood vessel detections. Blood vessels are detected by Sobel kernel and its transpose applied on downscaled images, after which absolute values of horizontal and vertical detections are summed in a pixel-wise manner, similar as in (2). After edge detection, the image is upscaled back to the original size and then additionally blurred. The result gives an approximate detection of the blood vessels and other sharp contours in the image. Finally, the resulting image is subtracted from the original filtered image, denoted as filteredG in Algorithm 1. This step is used to reduce the influence of the blood vessels and can be omitted in the case when the upper part of the colon is screened, for faster processing.

In this step the filtered image is split into overlapping blocks of fixed size. A detection mask is initialized as a grayscale image with pixel values set to zero with the size of the filtered image. For each block the average value of gray level within the block is calculated and compared with the predefined threshold. This predefined threshold is denoted as smallBlockAverage in Algorithm 1. If the average value of one specific small block is larger than smallBlockAverage, we conclude that the local edge density is high enough and all pixels at the corresponding positions in the mask are increased by one. The mask is updated by iterating through the filtered image and calculating the sum of values for all blocks overlapping at a given pixel. This results in the mask indicating potentially inflamed tissue.

An additional pass is applied to the mask obtained after small block filtering in order to remove floating elements on the mask. Floating elements are separated small regions labeled as inflammations due to the presence of various types of edges not coming from inflammatory tissue. In this step we divide the mask on larger overlapping blocks and compare the sum of the mask values within these blocks with the predefined value denoted as largeBlockThreshold. If the sum is larger than largeBlockThreshold all pixels within the block are incremented by one, otherwise they are decremented by one. Finally, if the specific gray level of the modified mask is less than zero, it is set to zero. The final mask is obtained after full iteration of large blocks, and is done throughout the whole mask obtained after small block filtering.

The results of inflammation detection, obtained with the described approach without optional blood vessel removal, for example frames shown in  
                        Fig. 4a, b and c, are given in Fig. 4d, e and f, respectively. The presence of the floating elements in the masks, coming from the regions with significant overexposure artifact on large regions, is noticeable. We see that a false detection for frame with healthy tissue of the upper part of the colon is present due to the noise and overexposed small region on the left. Also, blood vessels are contributing to the false detection. The results of inflammation detection in the case when additional sharp contours removal is applied is given in Fig. 4d, e and f, respectively. A large region of true positive detection is obtained for the inflammatory frame, while the false detection rate is significantly decreased in the other two examples.

The detection process is modular and thus it is possible to enable or disable specific phases of the algorithm, such as the removal of blood vessels in case of deep colonoscopy, or blurring in case of thin blood vessel structure. This allows for manual selection of algorithm's level of detail and manual tuning of performance-to-accuracy ratio. Furthermore, this approach allows customization of the algorithm for different hardware, so that less capable hardware can generate a highly accurate real-time approximation of the inflamed region mask.

Different phases of the proposed algorithm can be executed in parallel, allowing faster video processing. For example, edge density estimation is done as kernel based edge detection, which is fundamentally a convolution and as such is highly suitable for parallel processing. Generally, the implementation of the proposed algorithm can be efficiently parallelized on a GPGPU architecture. We have shown that our algorithm is capable of processing high resolution colonoscopy videos faster than real-time relying on a GPGPU implementation using OpenCL and C♯. Since the implementation is done in OpenCL, it is highly portable between different hardware configurations and even operating systems, given that Mono framework may be used. OpenCL kernels can easily be ported for a specialized CUDA implementation.

For GPGPU processing, we have written five OpenCL kernels, namely: edges, edgesModified, affected, erosion and convolution, to implement the corresponding procedures given in Algorithm 1. We instantiate two host threads for hybrid parallelization. The first host threads run resizing, standard edge detection and blur, while the second host thread runs modified edge detection. For blurring, the convolution kernel was used. The results are combined on the host using the same method as in Algorithm 1, parallelized on the CPU. Then the affected area is determined on the GPU by invoking the affected and erosion kernels.

Systems without a GPU can also benefit from the parallel implementation due to OpenCL's invariance with respect to hardware. This makes the algorithm suitable for embedded systems. Processing of multiple videos simultaneously can also be done with a significant performance gain. Since it is necessary to load frames from disk to memory during processing, the CPU utilization for processing a single video is not 100%. However, this allows processing of multiple videos concurrently. In any case, processing a single video stream can be done faster than real-time, given an adequate hardware configuration. For non real-time applications (video postprocessing), it is possible to process multiple frames simultaneously to provide faster overall video processing.

@&#EXPERIMENTS@&#

@&#METHODOLOGY@&#

We tested the proposed algorithm by two experiments using high resolution colonoscopy videos described in Section 3. The first experiment is designed to verify the ability to automatically detect inflammatory regions within one specific frame and the second experiment examines whether the proposed algorithm is able to differentiate between frames in which inflammation is shown and other frames. All experiments are executed using the parallelized implementation of the proposed algorithm, described in the previous section, on a computer with i7-4790K 4.00GHz CPU and NVidia GeForce 970 GTX graphics card.

Since our algorithm relies on block-processing and uses several thresholds, optimal block sizes and parameters used in the following experiments are obtained in a heuristic manner, considering the time consumption and accuracy. The values for smallBlockSize and largeBlockSize are chosen to ensure that every pixel is processed within a sufficient number of small blocks and large blocks. The value of step parameter should be chosen to enable overlapping between blocks and to avoid coarse division, but the number of blocks should be kept small for faster processing. Considering the fact that an image is scanned top-to-bottom and left-to-right in both small block and large block filtering, each pixel is examined 
                           
                              
                                 (
                                 smallBlockSize
                                 /
                                 step
                                 )
                              
                              
                                 2
                              
                           
                         and 
                           
                              
                                 (
                                 largeBlockSize
                                 /
                                 step
                                 )
                              
                              
                                 2
                              
                           
                         times during small block filtering and large block filtering, respectively. In our experiments, we concluded that values step = 8, smallBlockSize = 16 and largeBlockSize = 64, ensure sufficiently fast execution and adequate number of processing iterations for each pixel in both passes. The parameter smallBlockSaturation with values over 200 is found to have satisfactory effect of removing the overexposure effects. Based on the fine tuning, the value of 220 is chosen for smallBlockSaturation. Similarly, the value of parameter largeBlockTreshold is set to 1600, since experiments show that this value efficiently removed floating elements, as described in the previous section. The value of the parameter smallBlockAverage is found to have a larger impact on accuracy.

Since the optional phase for removal of the effect of blood vessels includes additional convolution for line detection and one more for blurring, we analyzed the Basic approach (without optional phase) and the Advanced approach (with optional phase), separately.

The proposed algorithm analyzes colonoscopy videos in a frame by frame manner, during which the output video with labeled regions is produced. To test if the proposed algorithm is capable of detecting the exact region in which inflammation is located, fifteen frames showing removal of an inflamed adenoma, during the examination, were processed. An adenoma is an inflammatory flat lesion polyp, which is characterized by a damaged mucosal layer and a high level of submucosal bleeding. Since the adenoma is an inflammatory region, it is suitable for detection using the proposed algorithm. For each frame, showing the adenoma, a ground truth reference mask is determined by an experienced expert physician. These masks show the exact areas on each frame, where the adenoma is located. Examples of frames and corresponding ground truth masks are given in  
                        Fig. 5.

Our algorithm returns a grayscale mask of detected regions. For the evaluation purpose, the binary mask is made from the grayscale mask so that the binary mask pixel is set to one only if the corresponding grayscale mask pixel is greater than the fixed value of 16. Considering the method, the final mask is obtained with the parameter values as previously described, meaning that one specific pixel is declared as part of the inflammation if at least two thirds of corresponding large blocks sums have greater value than largeBlockTreshold. For each of the selected frames, binary mask is compared with the reference mask in order to calculate true positive (TP), true negative (TN), false positive (FP) and false negative (FN) rate. Accuracy is calculated with the following formula:
                           
                              (3)
                              
                                 
                                    Accuracy
                                    =
                                    
                                       
                                          TP
                                          +
                                          TN
                                       
                                       
                                          TP
                                          +
                                          FP
                                          +
                                          TN
                                          +
                                          FN
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        In the case where the value of the parameter smallBlockAverage is set to 70, the rates and accuracy for each frame are given in  
                         
                        Figs. 6 and 7 for the Basic and the Advanced approach, respectively. Comparing the graphs, we noticed that adding the optional phase to remove the effect of the blood vessels actually increases true positive rate and decreases false negative rate, but also increases false positive rate. For given value of the parameter smallBlockAverage, the averaged accuracy is 79.4% for the Advanced approach and 82.4% for the Basic approach.

We investigated the influence of the parameter smallBlockAverage for both approaches. In this part of the experiment, we varied the value of the parameter starting from 40 with the increment 10, ending with 90. The accuracy rates are given in Table 3
                        , for both approaches. We can conclude that the two approaches have different optimal parameter values with which they reach approximately 85% of detection accuracy. It is important to emphasize that, although they have similar accuracy, the performance is different when other statistical results are taken into consideration. In other words, the choice between these two approaches according to the necessity for high true positive or low false positive rate can be made.

To demonstrate the efficiency the proposed algorithm, a single segment of a colonoscopy video showing both inflammation and healthy tissue is extracted and processed. The results of the automatic inflammation detection can be seen on the example video available at http://www.etfbl.net/~aleksej/example.mp4. Detected areas are colored in yellow.

The videos were manually annotated (Table 2) so that we could separate the frames which clearly show inflammatory tissue (inflammatory frames), from the frames which clearly show healthy tissue (healthy frames).This way the ground truth set of frames is extracted from the videos. It is of interest to evaluate the rate of the inflammatory frame detection. This experiment tests if it is possible to separate frames showing healthy tissues from frames showing inflammation. One frame per second of the video was extracted and processed to determine whether the inflammation was present or not. To avoid the influence of small regions, which are detected due to overexposure effect or some other kind of noise, the threshold of 10% of pixels is set. This means that the whole frame is labeled as inflammatory frame, if the corresponding binary mask contains more than 10% of the total number of pixels, in the detected inflammatory region. This way, we can estimate the percentage of accurate classification between frames showing healthy and inflammatory tissue. The goal is to recognize the frames in which the inflammation is shown.

Based on the annotation we extracted 50 inflammatory and 46 healthy frames from the Colon1.avi video, 79 healthy frames from the Colon2.avi video and 34 inflammatory and 22 healthy frames from the Colon3.avi video. Some frames from the Colon3.avi video are discarded, since a part of the video shows polyp removal procedure and it is not relevant for this experiment. Similar as in the first experiment, classification is made using the Basic and the Advanced approach. We used 84 inflammatory and 147 healthy frames. Classification results for both approaches are given in Table 4
                        . In this test, the value of the parameter smallBlockAverage is set to 70 for both approaches, in order to have a fair comparison.

Analyzing the results given in Table 4, we notice poor performance for both approaches in the Colon3.avi video. The reason for this can be found in the poor quality of video, in which most of the frames are highly damaged by blurring and motion noise. Nevertheless, the Advanced approach significantly improves accuracy, especially for the Colon2.avi video. This video shows the lower part of the descending colon with no inflammation, so blood vessels are clearly visible. Since the Advanced approach includes the additional computation for reducing the false detection rate caused by blood vessels, the improvement of classification accuracy was expected.

Overall, the Basic approach gives the classification accuracy of 42% but manages to detect the presence of inflammation, especially in the Colon1.avi. The Advanced approach significantly improves classification accuracy and, with the exception of the less-informative Colon3.avi video, it has accuracy over 90%.

Comparing with the Basic approach, the Advanced approach has an additional phase that includes two frame resize procedures and two convolutions. Since the analysis is done in a frame-by-frame manner, it is sufficient to analyze the processing time per frame in order to evaluate the total time consumption for video processing. Table 5
                         gives the average processing time per frame and estimated frames per second rate with which the specific approach can achieve real-time processing. We can notice that the Basic approach is capable of real-time processing of most common video footage encoded with 25 fps rate, while the Advanced approach can process every other frame in real-time manner.

@&#DISCUSSION@&#

A low complexity method for automatic detection of inflammation in high quality colonoscopy videos was introduced. This method includes edge density estimation, small and large block filtering and can be implemented in parallel, thus it is suitable for real-time inflammation detection. The advanced version of the method includes an additional phase to improve detection accuracy. In previous sections, a detailed analysis of both approaches, as well as their performance and time consumption, is given. According to the experimental results, we can notice the following:
                           
                              (a)
                              Overall execution time of the Basic approach is more than four times shorter compared to the Advanced approach.

The Basic approach is capable of processing video in real-time, while the Advanced approach can be used in real-time only if every second frame is analyzed.

In case when the exact region of inflammation needs to be detected:
                                    
                                       (1) Both the Basic and Advanced approach have similar accuracy.

(2) The Basic approach has higher true positive and false negative rate compared to the Advanced approach.

(3) The Advanced approach has smaller false positive rate compared to the Basic approach.

In case when inflammatory frames need to be detected:
                                    
                                       (1) Both the Basic and the Advanced have poor performance when video is corrupted with significant amount of noise.

(2) The Advanced approach significantly improves the detection accuracy compared to the Basic approach.

We conclude that the choice between the Basic and the Advanced approach can be made depending on available time resources and accuracy requirements. For example, if it is necessary to detect and mark the region with inflammation during the examination procedure, the Basic approach is recommended, since it can be executed in real-time. On the other hand, in case when the analysis is done off-line in order to detect video segments which can possibly contain the inflammation, the Advanced approach is more suitable, since it has a higher inflammatory frame detection accuracy. Also, the analysis using the Advanced approach can be executed in real-time, if every second frame is processed.

@&#CONCLUSION@&#

In this paper we proposed an algorithm suitable for parallel implementation and real-time processing with the aim to have a detection accuracy of inflammation in a video as high as possible. One specific characterization of inflammatory tissue, which is submucosal bleeding, is used to distinguish between inflamed and healthy tissue. The Basic approach can be tuned to achieve detection accuracy around 84% and can be executed in real-time, thus it can be used during the examination procedure to highlight the region with inflammation. The Advanced approach includes additional computation and gives more precise detection of video segments which contain the frames showing inflammation. In the case when video is not corrupted with motion blur, this approach can achieve detection accuracy over 90%. Since it is slower it is more suitable for off-line video analysis, although it is possible to achieve real-time processing if every second frame is skipped. The proposed algorithm is best suited for automatic colon inflammation detection in cases where inflammation texture has strong red spherical lesions, captured with high resolution probes. Further advances can be made in developing a suitable model for real-time detection for other anomalies, such as polyps, bleeding, etc.

This statement certifies that this article is Author's original work. We warrant that the paper has not received prior publication and is not under consideration for publication elsewhere. Financial and personal relationships of authors with other people or organizations that could inappropriately influence their work are not declared.

@&#ACKNOWLEDGMENTS@&#

Authors would like to thank the Lars Aabakken's gastro lab for providing the colonoscopy videos that were used in this research. The research was supported by NORBOTECH (NORwayBOsnia TECHnology Transfer) project for Programme in Higher Education, Research and Development by Norwegian Ministry of Foreign Affairs, and by the Ministry of Science and Technology of the Republic of Srpska under Contract 19/6-020/961-187/14, and by Bilateral Collaboration Project of Slovenian Research Agency (ARRS) and Ministry of Civil Affairs of Bosnia and Herzegovina, under Grants BI-BA/10-11-026 and BI-BA/14-15-035.

@&#REFERENCES@&#


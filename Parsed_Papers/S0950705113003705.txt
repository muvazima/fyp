@&#MAIN-TITLE@&#Automatic preference learning on numeric and multi-valued categorical attributes

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Learning preferences implicitly is a challenging task in the design of recommenders.


                        
                        
                           
                           Our approach infers preferences by analyzing choices without any explicit feedback.


                        
                        
                           
                           Choices considered are defined by numerical and multi-valued categorical criteria.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Recommender systems

Preference learning

Aggregation operators

Fuzzy sets

Ranking

@&#ABSTRACT@&#


               
               
                  One of the most challenging tasks in the development of recommender systems is the design of techniques that can infer the preferences of users through the observation of their actions. Those preferences are essential to obtain a satisfactory accuracy in the recommendations. Preference learning is especially difficult when attributes of different kinds (numeric or linguistic) intervene in the problem, and even more when they take multiple possible values. This paper presents an approach to learn user preferences over numeric and multi-valued linguistic attributes through the analysis of the user selections. The learning algorithm has been tested with real data on restaurants, showing a very good performance.
               
            

@&#INTRODUCTION@&#

Nowadays it is practically unconceivable to select our summer holiday destination or to choose which film to see in the cinema this weekend without consulting specialized sources of information in which, in some way or another, our preferences can be specified to aid the system to recommend us the best choices. That is because we live in an era where there are so many data easily available that it is impossible to manually filter every piece of information and evaluate it accurately. Recommender Systems (RS) have been designed to do this time-consuming task for us and, by feeding them with information about our interests, they are capable enough to tell us the best alternatives for us in a personalized way.

The preferences of the user are stored in a structure called user profile. In this work, as usual in the literature, it will be considered that each decision alternative is represented through a set of values assigned to a certain set of predetermined attributes or criteria. In these situations, the user profile must somehow represent the preference of the user with respect to each of the possible values of the attributes. With this information, the RS may rate and rank the corpus of available decision alternatives and show it to the user to help him/her to make the final choice. The representation of the preferences, the recommendation process and the automatic management of the dynamic evolution of the preferences are three of the most challenging issues in the development of this type of systems [24].

Concerning the latter problem (how to learn automatically the preferences of the users), the RS requires some kind of information from the users to guide the learning process. This feedback may be obtained implicitly, explicitly or combining both approaches. Explicit feedback forces users to evaluate items, indicating how relevant or interesting they are to them using some numeric or linguistic scale. These systems offer high performance and simplicity [25,26,29,33]. However, explicit feedback has some serious limitations: the user must spend some time and effort, the rating action distracts the attention of the user from his/her standard workflow, and a subjective numerical or linguistic scale is needed to rate each item [12]. Moreover, users are usually reluctant to spend time giving explicit feedback and some studies argue that only 15% of the users would supply it even if they were encouraged to do so [30].

On the other hand, implicit feedback is obtained by monitoring the actions of the users and automatically inferring their preferences. The amount of collected data is consequently very large, the computation needed to derive the profile adaptations is extensive, and the confidence in their suitability is likely to be relatively low. This approach has been less explored, although some existing methods have shown promising results (e.g. [3,9,24,32]). This paper discusses an unsupervised way to infer the user interests over numerical and multi-valued categorical attributes, which observes the user interaction and does not require any explicit information from him/her [17].

The basic idea of the preference learning framework proposed in this paper is shown in Fig. 1
                     . There is a set of alternatives that can be recommended to the user as solutions of a decision problem, represented with a set of predetermined criteria. These options are evaluated and ranked according to the current preferences of the user, stored in his/her profile. The user is shown the ranked list of alternatives, and his/her preferred option is selected. The preference learning algorithms analyze the option chosen by the user and the alternatives that were ranked above it in order to decide which changes must be made to the user profile so that it captures better the user preferences and the next recommendation is more accurate. It can be seen that the adaptation process is iterative and, the more choices are made by the user, the more information will the system have to find out his/her preferences. Therefore, this framework will be especially suitable in those cases in which the user is confronted with frequent decisional problems (e.g. which news to read every morning, which messages to read from a social network every day). Due to its progressive, continuous and dynamic nature, it will also be applicable in realistic settings in which the preferences of the user are not static but change dynamically over time [22,23].

The rest of the paper is organized as follows. Section 2 includes a brief description of the previous work of the authors in the area of preference learning over single-valued linguistic and numeric attributes, explaining how the interests of users over the values of these kinds of criteria are learned. Section 3 presents a new approach to learn preferences over the values of categorical attributes when the decision alternatives can take multiple linguistic values in a single attribute. Section 4 describes a novel expressive preference function on numeric attributes and how the parameters that define this function can be automatically learned. In Section 5 the case study where our approach has been tested (restaurant recommendation) is explained, describing the data set used and the results obtained. Section 6 gives an overview of related work on multi-criteria preference learning and analyses previous proposals. Finally, Section 7 outlines the main conclusions of the paper and identifies some lines of future research.

@&#BACKGROUND@&#

This section describes the previous work of the authors in the area of preference learning for single-valued numerical and categorical attributes, in order to set the background of the new results introduced in this paper. The first subsection explains how the information about the user preferences on the values of numerical and categorical attributes is represented in the user profile. After that, it is explained how this preference information is used to evaluate each of the alternatives of a decisional problem, so that the user may be given a ranked set of options before making a decision. Finally, the last subsection presents an overview of the basic techniques used to analyze the choices of the user and adapt dynamically the content of his/her profile. Fig. 1 represents the whole system architecture, where all the steps in the recommendation and learning processes are depicted.

The user profile contains information about the preferences of the user regarding the values that can be taken by numerical and categorical attributes. The preferences over these two kinds of criteria are represented in different ways. In a recent work [23] we proposed to represent the level of interest over each value in the domain of the categorical attributes by using a linguistic scale in which the semantics of preference labels is defined using fuzzy sets (see Fig. 2
                        a with an example with the labels “Very Low”, “Low”, “Medium”, “High” and “Very High”). This example shows a set of linguistic labels that are symmetrical and uniformly distributed. However, in some situations it can be more appropriate to represent the preferences using fuzzy sets that are not symmetrical or are not distributed uniformly through the domain, as shown in Fig. 2b with the label set (Very Low, Medium, Almost High, High, Perfect). As it will be explained later, the ULOWA aggregation operator [15] permits to aggregate preference information in both scenarios.

For the case of each numeric attribute, the profile contains a value, vpref
                        , that represents the preferred value of the user in the domain of the attribute. In order to evaluate the degree of preference of any value of the attribute, in our previous works it was assumed that each user has a preference function for each attribute, which has a triangular shape (see Fig. 3
                        ) and is defined as:
                           
                              (1)
                              
                                 
                                    
                                       p
                                    
                                    
                                       a
                                    
                                 
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   x
                                                   <
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         pref
                                                      
                                                   
                                                   -
                                                   Δ
                                                   )
                                                   )
                                                
                                             
                                             
                                                
                                                   1
                                                   -
                                                   
                                                      
                                                         |
                                                         x
                                                         -
                                                         
                                                            
                                                               v
                                                            
                                                            
                                                               pref
                                                            
                                                         
                                                         |
                                                      
                                                      
                                                         Δ
                                                      
                                                   
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         pref
                                                      
                                                   
                                                   -
                                                   Δ
                                                   )
                                                   ⩽
                                                   x
                                                   ⩽
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         pref
                                                      
                                                   
                                                   +
                                                   Δ
                                                   )
                                                   )
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   (
                                                   x
                                                   >
                                                   (
                                                   
                                                      
                                                         v
                                                      
                                                      
                                                         pref
                                                      
                                                   
                                                   +
                                                   Δ
                                                   )
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where pa
                        (x) is the preference of the value x of the attribute a and Δ is the width of the function, which we considered to be 10% of the attribute domain. Note that the only point with a preference 1 is precisely vpref
                        , and that any point below vpref
                        
                        −
                        Δ or above vpref
                           
                        +
                        Δ has preference 0.


                        Fig. 4
                         represents an example of a user profile which combines numerical (left side) and categorical (right side) attributes. The numerical preferences define the values of maximum preference of three attributes vpref
                        
                        1, vpref
                        
                        2 and vpref
                        
                        3 over the numerical attributes a
                        1, a
                        2 and a
                        3, respectively; those values belong to the particular domain of each variable. On the other hand, the right part contains the qualitative preferences over the possible values of the categorical attributes a
                        4 and a
                        5, represented with the linguistic labels depicted in Fig. 2a.

When evaluating an alternative, the objective is to aggregate all of the values of preference assigned to each of the values of its attributes into a single value. Since two kinds of attributes are being considered, a conversion to the same domain is made. In our approach, we chose to translate the numerical preferences into linguistic ones. The translation is done by, first, calculating the value of preference of every numeric attribute value by using Eq. (1). Then that value is mapped to the fuzzy linguistic label with a higher value in that point, rounding it up to the greater label in the cases where the values are exactly in the middle point between two labels. For the case of the values of the categorical attributes, they are translated directly into their associated linguistic preference values in the profile.

When all the attribute values have been assigned a value of preference using the same fuzzy linguistic scale, all the terms are aggregated using the ULOWA aggregation operator [15]. The final result of this aggregation is the value of preference assigned to the whole alternative, used to rank the alternatives.

The ULOWA aggregation operator is defined in Isern et al. [15] as follows:
                           
                              (2)
                              
                                 ULOWA
                                 (
                                 
                                    
                                       a
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       a
                                    
                                    
                                       n
                                    
                                 
                                 )
                                 =
                                 W
                                 ·
                                 
                                    
                                       B
                                    
                                    
                                       T
                                    
                                 
                                 =
                                 
                                    
                                       C
                                    
                                    
                                       n
                                    
                                 
                                 {
                                 
                                    
                                       w
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 
                                    
                                       b
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 k
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 n
                                 }
                                 =
                                 
                                    
                                       w
                                    
                                    
                                       1
                                    
                                 
                                 ⊗
                                 
                                    
                                       b
                                    
                                    
                                       1
                                    
                                 
                                 ⊕
                                 (
                                 1
                                 -
                                 
                                    
                                       w
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 ⊗
                                 
                                    
                                       C
                                    
                                    
                                       n
                                       -
                                       1
                                    
                                 
                                 {
                                 
                                    
                                       β
                                    
                                    
                                       h
                                    
                                 
                                 ,
                                 
                                    
                                       b
                                    
                                    
                                       h
                                    
                                 
                                 ,
                                 h
                                 =
                                 2
                                 ,
                                 …
                                 ,
                                 n
                                 }
                              
                           
                        In this expression W is the set of weights that describes the aggregation policy to be applied on labels from the set S, 
                           
                              β
                              =
                              
                                 
                                    w
                                 
                                 
                                    h
                                 
                              
                              /
                              
                                 
                                    ∑
                                 
                                 
                                    2
                                 
                                 
                                    n
                                 
                              
                              
                                 
                                    w
                                 
                                 
                                    h
                                 
                              
                           
                        , h
                        ={2,…,
                        n} and B
                        ={b
                        1,…,
                        bn
                        } is a permutation of the elements of A, such that B
                        =
                        σ(A)={aσ
                        
                        (1),…,
                        aσ
                        
                        (n)}, where aσ
                        
                        (
                        
                           j
                        
                        )
                        ⩽
                        aσ
                        
                        (
                        
                           i
                        
                        ), 
                           
                              ∀
                              j
                              ⩽
                              i
                           
                        . Cn
                         is the convex combination operator of n labels. If 
                           
                              ∃
                              j
                              ∈
                              1
                              ,
                              …
                              ,
                              n
                           
                        , wj
                           
                        =1 and 
                           
                              ∀
                              k
                              ∈
                              1
                              ,
                              …
                              ,
                              n
                           
                        , k
                        ≠
                        j, wk
                           
                        =0, then Cn
                        {wi
                        ,
                        bi
                        ,
                        i
                        =1,…,
                        n}=
                        bj
                        . When n
                        =2, with b
                        1
                        =
                        sj
                         and b
                        2
                        =
                        si
                        , sj
                        , si
                        
                        ∊
                        S (j
                        ⩾
                        i) then
                           
                              (3)
                              
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                                 {
                                 
                                    
                                       w
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       b
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 }
                                 =
                                 
                                    
                                       w
                                    
                                    
                                       1
                                    
                                 
                                 ⊗
                                 
                                    
                                       s
                                    
                                    
                                       j
                                    
                                 
                                 ⊕
                                 (
                                 1
                                 -
                                 
                                    
                                       w
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 ⊗
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       s
                                    
                                    
                                       k
                                    
                                 
                              
                           
                        such that k
                        =argmax
                           i⩽p⩽j
                        {Sim(sp
                        ,
                        δ)}, where δ is an intermediate crisp number between sj
                         and si
                         defined as δ
                        =(xk
                        ,
                        xk
                        ,
                        xk
                        ,
                        xk
                        ), with xk
                           
                        =
                        x
                        ∗
                        si
                           
                        +
                        w
                        1(x
                        ∗
                        sj
                        
                        −
                        x
                        ∗
                        si
                        ), x∗s being the x-component of the center of gravity of the label S.

The similarity between two fuzzy numbers (Sim(P,
                        Q)) is evaluated with Eq. (4) 
                        [8].
                           
                              (4)
                              
                                 Sim
                                 (
                                 P
                                 ,
                                 Q
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∏
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             4
                                          
                                       
                                       (
                                       2
                                       -
                                       |
                                       
                                          
                                             p
                                          
                                          
                                             i
                                          
                                       
                                       -
                                       
                                          
                                             q
                                          
                                          
                                             i
                                          
                                       
                                       |
                                       )
                                    
                                    
                                       4
                                    
                                 
                                 -
                                 1
                              
                           
                        Eq. (4) assumes that each fuzzy set (triangular or trapezoidal) is represented in the usual way by four numbers (P
                        =(p
                        1,
                        p
                        2,
                        p
                        3,
                        p
                        4), Q
                        =(q
                        1,
                        q
                        2,
                        q
                        3,
                        q
                        4)). When two fuzzy sets are identical, their similarity is 1.

The whole process of evaluation of an alternative is depicted in Fig. 5
                        , where an Asian restaurant is evaluated. It includes three categorical attributes (“Type of food”, “Atmosphere” and “Special characteristic”) and two numerical ones (“Average price” and “Distance to center”). The preference terms (taken from the set shown in Fig. 1a) for the first set of attributes are directly obtained from the user profile and they do not require any further interpretation. However, in the case of the values of the numerical attributes there is an intermediate step: first the numerical values are translated to a value of numerical preference using the attribute preference function (shown in Eq. (1)), and then that value is translated to a linguistic term of preference. At this moment, as shown at the bottom, we have a list of linguistic labels that represent the user’s qualitative preferences on all the values of the alternative that is being evaluated. The final overall evaluation of the alternative is obtained with the application of the ULOWA aggregation operator, resulting in the “High” label.

When the ranked alternatives are presented to the user, two things can happen: (a) the user selects the first ranked alternative or (b) the user selects any other alternative. The first case means that the recommendation process has worked accurately, since the system gave the first place to the selected alternative. However, in the second case, there were other alternatives (which we call over ranked) that were considered by the system as better than the one the user finally selected. Thus, that is probably indicating that the information in the user profile is not accurate enough and should be modified. In a nut shell, the main intuition behind the user profile change algorithm is that we should increase the preference on the attribute values present in the selected alternative and decrease the preference on the attribute values appearing in the over ranked alternatives.

The information required by the user profile adaptation algorithms is extracted from what is called “relevance feedback”, which, in this case, includes the over ranked alternatives and the selected one. Numerical and categorical attributes are managed in different ways, as described in the following subsections.

The main idea is to find attribute values repeated among the over ranked alternatives that do not appear on the selection, which will be the candidates for having his preference decreased. Similarly, the preference of the attribute values that appear on the selection and do not appear often on the over ranked alternatives is likely to be increased. The interested reader may find a more detailed explanation of the process of adaptation of linguistic preferences in Marin et al. [23].

The profile adaptation is conducted by two processes, depicted in Fig. 6
                           . The first one—called on-line adaptation—is executed every time the user asks the system for a recommendation. The main goals of this stage are to decrease the preference of the attribute values that are causing non-desired alternatives to be given high scores and to increase the preference of the attribute values that are important for the user but are not well judged on the basis of the current user profile. More concretely, for each recommendation made by the system, two sources of information are evaluated: the selected alternative, which is the choice made by the user, and the alternatives that were ranked above it. Values extracted from the over ranked alternatives have their level of preference decreased (changed to the previous label) whereas the ones extracted from the user’s final selection that do not appear in the set of over-ranked alternatives have their preference increased (moved to the following label).

The second one—called off-line adaptation—is triggered after the recommender system has been used a certain number of times. It considers the information given by the history of the previous rankings of alternatives and the selections made by the user in each case, but considers that information separately. When the system faces cases in which the number of over ranked alternatives is not large enough for reliable conclusions to be extracted, it stores the small number of over ranked alternatives in a temporary buffer. After several iterations in which the number of over ranked alternatives has been insufficient for evaluation, the system will have recorded enough alternatives to start evaluating them. When there are enough saved over-ranked alternatives, the values in their attributes will be analyzed and their preference decreased. In the other hand, user selections are stored after every interaction (rather than just in the cases where the on-line process did not apply) and, after a certain number of choices have been made, they are evaluated with the objective to increase the preference of the most repeated attribute values, since their repeated selection indicates that the user is really interested in them.

The numeric adaptation of the user profile is inspired by Coulomb’s Law: “the magnitude of the electrostatics force of interaction between two point charges is directly proportional to the scalar multiplication of the magnitudes of charges and inversely proportional to the square of the distances between them”. The main idea is to consider the value stored in the profile (current preference) as a charge with the same polarity as the values of the same criterion on the over ranked alternatives, and with opposite polarity to the value of that criterion in the selected alternative. Thus, the value of the profile is pushed away by the values in the over ranked alternatives and pulled back by the value in the selected alternative. As in the case of numerical attributes, two stages have been considered in the adaptation algorithm. The first one, called on-line adaptation process, is performed each time the user asks for a recommendation and there are enough over ranked alternatives. The other stage, called off-line process, is performed after a certain amount of interactions with the user.

For the on-line stage, the information available in each iteration is the user selection and the set of over ranked alternatives. In order to calculate the change of the value of preference in the user profile for each criterion it is necessary to study the attraction force done by the selected alternative and the repulsion forces done by the over ranked ones in each criterion, as represented in the example in Fig. 7
                           , in which the jth value of the five over ranked alternatives o
                           0, o
                           1, o
                           2, o
                           3, and o
                           4 causes a repulsion force 
                              
                                 
                                    
                                       F
                                    
                                    
                                       j
                                    
                                    
                                       o
                                    
                                 
                              
                           , and the value for the same criterion of the selected alternative, sj
                           , causes an attraction force 
                           
                              
                                 
                                    
                                       F
                                    
                                    
                                       j
                                    
                                    
                                       s
                                    
                                 
                              
                           . Both forces are applied on the jth value of the profile, Pj
                           .

The attraction force Fs
                            done by the selected alternative for each attribute j is defined as
                              
                                 (5)
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                    
                                    (
                                    P
                                    ,
                                    s
                                    ,
                                    j
                                    ,
                                    α
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            Δ
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     1
                                                                  
                                                                  
                                                                     |
                                                                     
                                                                        
                                                                           s
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                     -
                                                                     Pj
                                                                     
                                                                        
                                                                           |
                                                                        
                                                                        
                                                                           α
                                                                        
                                                                     
                                                                  
                                                               
                                                               ·
                                                               
                                                                  
                                                                     
                                                                        
                                                                           s
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                     -
                                                                     
                                                                        
                                                                           P
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                  
                                                                  
                                                                     |
                                                                     
                                                                        
                                                                           s
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                     -
                                                                     
                                                                        
                                                                           P
                                                                        
                                                                        
                                                                           j
                                                                        
                                                                     
                                                                     |
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      if
                                                      
                                                      
                                                         
                                                            s
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ≠
                                                      
                                                         
                                                            P
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      if
                                                      
                                                      
                                                         
                                                            s
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            P
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           In this equation, Δj
                            is the range of the criterion j, sj
                            is the value of the criterion j in the selected alternative and Pj
                            is the value of the same criterion in the stored profile P. The parameter α adjusts the strength of the force in order to have a balanced adaptation process. The repulsion force exerted by the over ranked alternatives for each criterion j is defined as a generalization of Eq. (5) as follows:
                              
                                 (6)
                                 
                                    
                                       
                                          F
                                       
                                       
                                          o
                                       
                                    
                                    
                                       
                                          
                                             P
                                             ,
                                             {
                                             
                                                
                                                   o
                                                
                                                
                                                   1
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   o
                                                
                                                
                                                   no
                                                
                                             
                                             }
                                             ,
                                             j
                                             ,
                                             α
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             no
                                          
                                       
                                    
                                    
                                       
                                          1
                                       
                                       
                                          |
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                          -
                                          
                                             
                                                o
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                          
                                             
                                                |
                                             
                                             
                                                α
                                             
                                          
                                       
                                    
                                    ·
                                    
                                       
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                          -
                                          
                                             
                                                o
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          |
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                          -
                                          
                                             
                                                o
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                          |
                                       
                                    
                                 
                              
                           In this expression oi
                            is the ith over-ranked alternative, 
                              
                                 
                                    
                                       o
                                    
                                    
                                       j
                                    
                                    
                                       i
                                    
                                 
                              
                            is the value of attribute j for oi
                           , and no is the number of over ranked alternatives. Finally, both forces are summed up and the resulting force is calculated.

The techniques designed for the on-line stage fail at detecting user trends over time since they only have information of a single selection. The off-line adaptation process gathers information from several user interactions. This technique allows considering changes in the profile that have a higher reliability than those proposed by the on-line adaptation process, because they are supported by a larger set of data.

The off-line adaptation process can be triggered in two ways: the first one evaluates the user choices, while the second one analyses the over ranked alternatives discarded by the user in several iterations. The possibility of running the off-line process (in any of its two possible forms) is checked after each recommendation. In the first case, the system has collected some alternatives selected by the user in several recommendation steps, and it calculates the attraction forces (
                              
                                 
                                    
                                       F
                                    
                                    
                                       s
                                    
                                    
                                       ′
                                    
                                 
                              
                           ) exerted by each of the stored selected alternatives over the values stored in the profile, using an adaptation of Eq. (6), that has as inputs the profile P, the past selections {s1
                           ,…,
                           srs
                           }, the criterion to evaluate j, and the strength-adjusting parameter α:
                              
                                 (7)
                                 
                                    
                                       
                                          F
                                       
                                       
                                          s
                                       
                                       
                                          ′
                                       
                                    
                                    
                                       
                                          
                                             P
                                             ,
                                             {
                                             
                                                
                                                   s
                                                
                                                
                                                   1
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   s
                                                
                                                
                                                   rs
                                                
                                             
                                             }
                                             ,
                                             j
                                             ,
                                             α
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             rs
                                          
                                       
                                    
                                    
                                       
                                          1
                                       
                                       
                                          |
                                          
                                             
                                                s
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                          
                                             
                                                |
                                             
                                             
                                                α
                                             
                                          
                                       
                                    
                                    ·
                                    
                                       
                                          
                                             
                                                s
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                       
                                       
                                          |
                                          
                                             
                                                s
                                             
                                             
                                                j
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                P
                                             
                                             
                                                j
                                             
                                          
                                          |
                                       
                                    
                                 
                              
                           The second kind of off-line adaptation process evaluates the set of over ranked alternatives that have been collected through several iterations and which were not used in the on-line adaptation process (because it did not have enough over ranked alternatives in a single iteration). When the stored over ranked alternatives reach a certain number, the off-line adaptation process calculates with Eq. (6) the repulsion forces over the profile values exerted by those alternatives (Fo
                           ).

As explained in Section 2, in our previous work we considered categorical attributes that could take only one linguistic value (e.g., a touristic destination could have a single value in the “Climate” attribute). However, there are cases in which it is interesting to consider multiple values. One example of that situation could be the attribute “Types of food” in a restaurant: a restaurant can have the values {“Asian”, “Seafood”, “Vegetarian”} while another can have only “Italian food”.

Extending our model so that it can manage lists of categorical values implies addressing two issues: how to represent and calculate the user preferences over the attribute taking into account all of the values and how to adapt dynamically those preferences after the user selection. These issues are discussed in the following sections.

When there is an attribute with multiple values a procedure should be defined to decide which single linguistic preference should be assigned to the whole set of linguistic values. Going back to the restaurant example, imagine that a restaurant offers the types of food “Japanese”, “Chinese” and “Thai”. In order to evaluate this option to decide if it should be recommended to the user, the system has to integrate the information about the preferences of the user for these three types of food. There could be trivial cases, for instance if the user has the preference “High” for the three options the evaluation of the restaurant for this attribute should clearly be “High”. However, in the general case the user will have different levels of preference for each attribute value (e.g. “VeryHigh” for “Japanese”, “High” for “Chinese” and “VeryLow” for “Thai”). We argue that a recommender framework should be general enough to allow for different ways of aggregating these preferences to obtain an overall linguistic score of the alternative for the attribute. For instance, it could be argued that if the restaurant offers any kind of food that the user likes, then the restaurant should be recommended (in this case, as the user likes very much Japanese food, this restaurant would be a good option to be recommended). It could also be said that it is preferable to give high preference values only to those cases in which the user likes all the kinds of food offered by the restaurant, as the user could then choose any of the foods in the menu. Another option would be to evaluate the attribute with some kind of “average” value of the preferences over each attribute value (in the example, a “Medium” value could be assigned to this restaurant). Other intermediate options could also be considered, like assigning a high score if the user has high preferences on most of the attribute values (so that a low preference in some attribute value does not penalize heavily the overall score).

All of the aggregation mechanisms commented in the previous paragraph may be implemented using different weighing policies in an aggregation operator. In particular, in our framework we propose the use of the ULOWA
                           1
                           Note that the ULOWA operator is used in two different situations: to aggregate the linguistic preferences on all the attributes of an alternative (see Fig.5) and to aggregate the linguistic preferences on the values of a multi-valued categorical attribute.
                        
                        
                           1
                         aggregation operator [19]. This operator has two positive properties that make it very suitable for our purposes. On the one hand, it permits to work with unbalanced linguistic labels, such as those shown in Fig. 2b, allowing a great degree of expressivity in the representation of preferences. On the other hand, it has as parameter a weighting vector that represents the policy to be applied in the aggregation process. It is very simple to implement policies that represent the situations mentioned above (take the best evaluation of the attribute values, make an average of the preferences of all values, give a high value if most of the preference values are high, etc.). Thus, depending on the particular application and the semantics of each attribute, a different aggregation scheme may be employed for each attribute.

The linguistic algorithm used to adapt categorical preferences explained in Section 2 needs some improvements to be able to manage lists of values. When single-valued attributes were considered, the user selection pointed directly towards the value the user liked for that attribute. Now, however, we cannot be sure which one/s of the values listed in the attribute is/are the one/s of interest for the user. That is the reason why it has been necessary to design a “relevance function” which indicates how relevant is a value found among the over ranked alternatives or in the selected alternative. The basic properties that the relevance function should satisfy are the following:
                           
                              •
                              The less values appear in a categorical attribute, the more relevant they are.

A value present in the selected alternative has a relevance that is inversely proportional to the number of over ranked alternatives in which it appears. Moreover, the shorter are the lists of categorical values in the over ranked alternatives, the less relevant will be the value in the selected alternative.

The relevance of a categorical value of an attribute will be stronger if the average number of values for that attribute is smaller than the average number of values for the other categorical attributes.

Relevance is measured in a [0,1] scale, with 1 meaning maximum relevance. To calculate how relevant a term t of the attribute j is among the over ranked alternatives the following expression is used (the relevance value is 0 if it does not appear in any of the over ranked alternatives):
                           
                              (8)
                              
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                    
                                       o
                                    
                                 
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       no
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          nt
                                       
                                    
                                 
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             nv
                                          
                                          
                                             j
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        Here, no represents the number of over ranked alternatives, nt the number of over ranked alternatives where t appears, and 
                           
                              
                                 
                                    nv
                                 
                                 
                                    j
                                 
                                 
                                    i
                                 
                              
                           
                         the number of values that appear for the attribute j in the alternative i. In this equation we consider that every linguistic term that appears in the over ranked alternatives has a relevance which is inversely proportional to the number of other values for the same attribute that appear among the over ranked alternatives that contain the term. Note that the maximum relevance among the over ranked alternatives is 1, in the case in which the term appears in all over ranked alternatives and it is the only value for the attribute in all of them. The minimum relevance is 0, when the term does not appear in the over ranked alternatives.

To calculate the relevance of a term in the selection the following formula is used (the relevance value is 0 if the term does not appear in the selection):
                           
                              (9)
                              
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   
                                                      nv
                                                   
                                                   
                                                      j
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             
                                                nl
                                             
                                             
                                                tv
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Here nvj
                         represents the number of values that appear for the attribute j in the selection, nl the total number of linguistic attributes, and tv the total number of linguistic values that appear in the selection. The relevance of a term in the selection is the mean of the inverses of the number of values of the attribute in the selected alternative and the average number of values of all the categorical attributes in the selection. Note that, in fact, this formula does not depend on the term t; therefore, all the terms in the selection have the same relevance. The maximum relevance is 1, if all the categorical attributes contain a single value in the selected alternative. The minimum relevance is 0, if the term does not appear in the selection.

Finally, after calculating both partial relevancies for all the terms, the overall relevance Rj(t) is calculated as: 
                           
                              (10)
                              
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 t
                                 )
                                 -
                                 
                                    
                                       R
                                    
                                    
                                       j
                                    
                                    
                                       o
                                    
                                 
                                 (
                                 t
                                 )
                              
                           
                        Note that this overall relevance gives a value between −1 and 1. Negative values are associated to situations in which the term appears often in the over ranked alternatives. Positive values indicate that the term is important in the selection (it is probably in a short list of values) and does not appear very much in the over ranked alternatives.

With this final evaluation it can be decided if the preference value on a certain categorical value has to be increased or decreased. Considering a threshold γ to avoid making low-relevance changes in the profile, it can be deduced that:
                           
                              •
                              If Rj
                                 (t)>
                                 γ, the preference over the term t for the attribute j should be increased (moved to the next linguistic label).

If Rj
                                 (t)<−γ, the preference over term t for the attribute j should be decreased (moved to the previous linguistic label).

The following example (see Fig. 8
                        ) illustrates the computation of the relevance of different terms in a situation in which there are three over ranked alternatives (o
                        1, o
                        2 and o
                        3) before the selection (s), each one formed by three categorical attributes (a
                        1, a
                        2 and a
                        3).

First, we will compare the relevance of terms A, B, C and F (values of attribute a
                        1 in the selection) among the over ranked alternatives, by applying Eq. (8):
                           
                              
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   °
                                                
                                             
                                             (
                                             A
                                             )
                                             =
                                             (
                                             1
                                             /
                                             3
                                             )
                                             *
                                             (
                                             1
                                             /
                                             4
                                             +
                                             1
                                             /
                                             3
                                             +
                                             1
                                             /
                                             1
                                             )
                                             =
                                             0.528
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   °
                                                
                                             
                                             (
                                             B
                                             )
                                             =
                                             (
                                             1
                                             /
                                             3
                                             )
                                             *
                                             (
                                             1
                                             /
                                             4
                                             +
                                             1
                                             /
                                             3
                                             )
                                             =
                                             0.194
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   °
                                                
                                             
                                             (
                                             C
                                             )
                                             =
                                             (
                                             1
                                             /
                                             3
                                             )
                                             *
                                             (
                                             1
                                             /
                                             4
                                             )
                                             =
                                             0.083
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   °
                                                
                                             
                                             (
                                             F
                                             )
                                             =
                                             (
                                             1
                                             /
                                             3
                                             )
                                             *
                                             (
                                             0
                                             )
                                             =
                                             0
                                          
                                       
                                    
                                 
                              
                           
                        It can be observed that terms A and B appear in the first two alternatives. However, in the third one A appears alone, increasing greatly its overall relevance. At the end, the relevance of A is more than twice the one of B. Then, it can be argued that it is likely that A is one the reasons that caused the user not to select any of the first three alternatives, so its level of preference may need to be readjusted negatively. Term C only appears in the first alternative and accompanied by many other terms, so its relevance on the over ranked set of alternatives is very low. Finally, term F does not appear in any over ranked alternative, so its relevance here is 0.

The next example consists in finding the overall relevance of a term. Let us evaluate the global relevance of the term H in the second attribute. To do this, it is necessary to calculate its relevance among the over ranked alternatives and in the selected alternative and then obtain the overall relevance using Eq. (10).
                           
                              
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   s
                                                
                                             
                                             (
                                             H
                                             )
                                             =
                                             (
                                             1
                                             /
                                             2
                                             )
                                             *
                                             (
                                             (
                                             1
                                             /
                                             1
                                             )
                                             +
                                             (
                                             3
                                             /
                                             6
                                             )
                                             )
                                             =
                                             0.75
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   j
                                                
                                                
                                                   °
                                                
                                             
                                             (
                                             H
                                             )
                                             =
                                             (
                                             1
                                             /
                                             3
                                             )
                                             *
                                             (
                                             1
                                             /
                                             5
                                             )
                                             =
                                             0.067
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             R
                                             (
                                             H
                                             )
                                             =
                                             0.75
                                             -
                                             0.067
                                             =
                                             0.683
                                          
                                       
                                    
                                 
                              
                           
                        A positive overall relevance means that the term is well considered by the user (it may be the reason why the user selected the alternative). On the other hand, a negative relevance of a term indicates that it may have been the reason why the user did not choose the alternatives in which it appears. In this example, the term H has a very low relevance in the set of over ranked alternatives (it just appears once and in an alternative where that attribute has a high number of values). However, it appears alone in the selected alternative. This fact produces a very positive final relevance, meaning that H has a good chance to be the reason why the user selected that alternative, so the preference learning system should readjust its preference positively.

Although the numeric preference learning approach described in Section 2 provided an adequate way of learning the ideal value of preference over a numeric attribute, it was unable to learn all of the parameters that model the preference function such as the slope or the width, which were fixed. The new learning method presented in this section relies on historic data about the user selections to approximate the preference function of the numeric attributes to the most adequate one. The whole process of learning the numerical preference function is performed after the system has stored at least ten interactions/selections of the user, since with fewer data the learned function would probably not be accurate enough. With this approach, we have a new definition of the function of preference which now has 5 parameters (left and right slope, left and right width, and value of maximum preference) instead of considering only the preferred value:
                        
                           (11)
                           
                              
                                 
                                    p
                                 
                                 
                                    a
                                 
                              
                              (
                              x
                              )
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                1
                                                -
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  |
                                                                  x
                                                                  -
                                                                  
                                                                     
                                                                        v
                                                                     
                                                                     
                                                                        pref
                                                                     
                                                                  
                                                                  |
                                                               
                                                               
                                                                  
                                                                     
                                                                        Δ
                                                                     
                                                                     
                                                                        l
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            m
                                                         
                                                         
                                                            l
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                if
                                                
                                                (
                                                x
                                                <
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      pref
                                                   
                                                
                                                )
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                if
                                                
                                                (
                                                x
                                                =
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      pref
                                                   
                                                
                                                )
                                             
                                          
                                          
                                             
                                                1
                                                -
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  |
                                                                  x
                                                                  -
                                                                  
                                                                     
                                                                        v
                                                                     
                                                                     
                                                                        pref
                                                                     
                                                                  
                                                                  |
                                                               
                                                               
                                                                  
                                                                     
                                                                        Δ
                                                                     
                                                                     
                                                                        r
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            m
                                                         
                                                         
                                                            r
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                if
                                                
                                                (
                                                x
                                                >
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      pref
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     In this expression pa
                     (x) is the preference of the value x of the attribute a, ml
                      and mr
                      are the slope values (for the left and right sides of the function, respectively) and Δl
                      and Δr
                      define the width of the function (also for the left and right sides, respectively). Fig. 9
                      shows an example of a preference function, where the left slope is a value under 1, the right slope is a value over 1, and the left width is greater than the right one.

The learning process of the numeric preference function is depicted in Fig. 10
                     .


                     Fig. 11
                      graphically represents the three main steps in the numeric preference function learning process. The first step filters the more reliable values from the historic set of selections by extracting a percentage of the values closer to the value of preference (trust interval), for instance 90%. This is a common way to get rid of outlier values that might disturb the learning process. Then a probability distribution function, represented with a histogram, is calculated with the remaining values, as depicted in Fig. 11a. The sample or discretization step is a parameter, for instance 10% of the domain range as used in the figure. Delta values are then calculated by observing the width of the probability distribution. For example, if the first domain value with a positive frequency in the histogram is 3, the last one is 56 and the value of higher preference (vpref
                     ) is 34, Δl
                      would be 31 and Δr
                      would be 22. Afterwards, the algorithm generates preference functions with different combinations of values for the slope values (m) (in the range from 0 to 5 in steps of 0.1), and compares the distance between each preference function and the probability distribution. The distance is calculated by discretizing both function domains in steps of 1% and summing the difference of the function values for those discretized points. The function with the lowest distance determines the best slope. In Fig. 11b many functions with different slopes are depicted for both the left and the right sides of the function, the best of them being the ones shown in bold line: m
                     =4 for the left side(ml
                     ) and m
                     =0.7 for the right side (mr
                     ). Finally, the new preference function is built with the new delta and slope values (Fig. 11c). The vpref
                      value is still learnt with the technique explained in Section 2.

In order to test our new approach to multi-valued attribute evaluation and numeric preference function learning, we have used data of the restaurants in Barcelona to implement a RS with the ability to learn the users’ interests from their selections. In the first part of this section a description of the data is given. Then, a detailed explanation of the whole recommender and learning algorithm is given, as well as the preferences setup. Finally, the results of the evaluation are provided.

The data used in this problem has been collected from the “BcnRestaurantes” web page
                           2
                           Website: http://www.bcnrestaurantes.com/. Last accessed November 23rd, 2012.
                        
                        
                           2
                        . The data set contains preprocessed information about 3000 restaurants of Barcelona evaluated by 5 attributes: 3 categorical (“Type of food” – 15 values, “Atmosphere” – 13 values, “Special characteristics” – 12 values) and 2 numerical (“Average price”, “Distance to city center”). Fig. 12
                         shows the complete list of possible values for each categorical attribute and the times each term appears in the whole set of alternatives. For the numerical attributes, their domain and units are shown. Moreover, in Figs. 13 and 14
                        
                        , the distribution of the values for the two numerical attributes is shown: Fig. 13 displays a histogram of the distribution of the values of the “Distance to city center” attribute in intervals of 0.2km from 0 to 10km, and Fig. 14 does the same with the attribute “Average price” but in the intervals “15–30€”, “30–45€”, “45–60€” and “More than 60€”. Some attributes and values from the original data were not considered due to their low relevance (number of appearances), and some of them were aggregated together to avoid considering similar values with different names. One example of register in the data file is “Fonda España; {National, Season cuisine, Traditional}; {Classic, For families}; {Round tables, In a hotel, With views}; 45; 0.979”, being “Fonda España” the restaurant name, “National”, “Season cuisine” and “Traditional” the types of food served, “Classic” and “For families” the restaurant atmosphere, “Round tables”, “In a hotel” and “With views” other important restaurant characteristics, 45€ the average menu price, and 0.979km the distance to the city center.

The set of 3000 restaurants has been randomly divided in blocks of 15 alternatives that are ranked independently, which gives out a total of 200 different recommendations. An ideal profile was manually defined and three initial profiles were created randomly. The goal is to learn the ideal profile starting from these three different points. In this evaluation the preferences over the categorical attributes are represented with labels from a term set of 7 values, shown in Fig. 15
                        , which are “Very Low” (VL), “Low” (L), “Almost Low” (AL), “Medium” (M), “Almost High” (AH), “High” (H) and “Very High” (VH). The values of the ideal profile and the initial values of the three testing profiles are represented in Fig. 16
                        .

The whole process (for each of the three profiles, repeated 200 times) consists in:
                           
                              (1)
                              Ranking a set of 15 alternatives according the current (initially random) profile.

Simulate the selection of the user by choosing the alternative that fits better with the ideal profile.

Extract relevance feedback from the selection (over ranked alternatives and the selection itself).

Decide which changes need to be made to the current profile and apply them.

Some information about the whole process is stored after each iteration, including the position of the selected alternative, the distance between the ideal and current profiles, and the preferences over linguistic and numeric values. The execution time of the whole automatic evaluation process (with the adaptation of the three initial profiles) has been of 18s with a computer equipped with an AMD Phenom 9550 Quad-Core processor (2.20GHz) and 4GB of RAM. Provided that this process consists in 600 (200 for each adapting profile) evaluations and ranking of alternatives and a similar number of executions of the adaptation processes, it can be said that the time the user has to wait for a single recommendation or adaptation is unnoticeable (about 30ms) and does not compromise the user experience in real time with the platform.

In order to evaluate the results of the new learning techniques, a distance function has been defined to calculate how different the profile we are learning is to an ideal profile which represents the exact preferences of the user. The first step is to calculate the distance for each attribute, taking into account if it is numeric or categorical. The distance between numeric attributes is calculated as:
                           
                              (12)
                              
                                 d
                                 (
                                 n
                                 ,
                                 c
                                 ,
                                 i
                                 )
                                 =
                                 1
                                 -
                                 
                                    
                                       p
                                    
                                    
                                       n
                                    
                                    
                                       c
                                    
                                 
                                 (
                                 
                                    
                                       v
                                    
                                    
                                       
                                          
                                             pref
                                          
                                          
                                             n
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 )
                              
                           
                        where n is the numerical attribute, c is the current profile (the one being learned), i is the ideal profile, and 
                           
                              
                                 
                                    p
                                 
                                 
                                    n
                                 
                                 
                                    c
                                 
                              
                              (
                              
                                 
                                    v
                                 
                                 
                                    
                                       
                                          pref
                                       
                                       
                                          n
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                              )
                           
                         is the value of preference of the vpref
                         value for the attribute n in i using the preference function of the same attribute in the profile c. A distance 0 means that the vpref
                         values in both profiles are equal.

The equation to calculate the distance between categorical attributes is
                           
                              (13)
                              
                                 d
                                 (
                                 l
                                 ,
                                 c
                                 ,
                                 i
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       card
                                       (
                                       l
                                       )
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          card
                                          (
                                          l
                                          )
                                       
                                    
                                 
                                 
                                    
                                       |
                                       CoG
                                       
                                          
                                             
                                                
                                                   
                                                      p
                                                   
                                                   
                                                      l
                                                   
                                                   
                                                      c
                                                   
                                                
                                                (
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                                )
                                             
                                          
                                       
                                       -
                                       CoG
                                       
                                          
                                             
                                                
                                                   
                                                      p
                                                   
                                                   
                                                      l
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                
                                                   
                                                      v
                                                   
                                                   
                                                      k
                                                   
                                                
                                                )
                                             
                                          
                                       
                                       |
                                    
                                    
                                       |
                                       CoG
                                       (
                                       
                                          
                                             s
                                          
                                          
                                             min
                                          
                                       
                                       )
                                       -
                                       CoG
                                       (
                                       
                                          
                                             s
                                          
                                          
                                             max
                                          
                                       
                                       )
                                       |
                                    
                                 
                              
                           
                        where l is the categorical attribute, card(l) is the cardinality of the attribute l (i.e., the number of different linguistic values it can take), and 
                           
                              CoG
                              (
                              
                                 
                                    p
                                 
                                 
                                    l
                                 
                                 
                                    c
                                 
                              
                              (
                              
                                 
                                    v
                                 
                                 
                                    k
                                 
                              
                              )
                              )
                           
                         and 
                           
                              CoG
                              (
                              
                                 
                                    p
                                 
                                 
                                    l
                                 
                                 
                                    i
                                 
                              
                              (
                              
                                 
                                    v
                                 
                                 
                                    k
                                 
                              
                              )
                              )
                           
                         are the x-coordinate of the centers of gravity of the fuzzy linguistic labels associated to the value of preference of vk
                         in the profiles c and i, respectively, and CoG(smin
                        ) and CoG(smax
                        ) are the centers of gravity of the minimum and maximum labels of the domain, respectively. Finally, the distance between two profiles is calculated as:
                           
                              (14)
                              
                                 D
                                 (
                                 c
                                 ,
                                 i
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       na
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          na
                                       
                                    
                                 
                                 d
                                 (
                                 k
                                 ,
                                 c
                                 ,
                                 i
                                 )
                              
                           
                        where na is the total number of attributes.

During the three tests (one for each initial random profile) the distance between the adapting and the ideal profile has been calculated in each iteration. Fig. 17
                         (continuous line) shows the average of the three distances. It can be seen that the initial average distance between the ideal and the adapting profiles is around 0.59. After 200 iterations it reaches a distance around 0.1. Although 200 iterations may seem a large number, it can also be observed that with only 50 iterations a very acceptable result of 0.2 is obtained.

To see to what extent the new approach to learn the numeric preference function explained in Section 4 has improved the result of our previous work (commented in Section 2), Fig. 17 also compares the results with and without (dashed line) that functionality. It can be seen how the improvement has been noticeable (distance improvement of about 0.07).

Additionally, we have also studied the behavior of the Normalized Discounted Cumulative Gain (NDGC) measure, that permits to analyze in more detail the order of the alternatives in each step of the learning process [16]. The premise of NDCG is that highly relevant objects appearing in low positions in a recommendation list should be penalized as the graded relevance value is reduced logarithmically with respect to the position of the object. According to that measure, it is possible to analyze if the system’s recommendations (rated and sorted using the current profile) are appropriately sorted through the successive iterations, by comparing their order with the perfect one provided by the ideal profile, which the system intends to learn.

The equation of the NDGCp
                         measure is
                           
                              (15)
                              
                                 
                                    
                                       NDCG
                                    
                                    
                                       p
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             DCG
                                          
                                          
                                             p
                                          
                                       
                                       -
                                       
                                          
                                             WDCG
                                          
                                          
                                             p
                                          
                                       
                                    
                                    
                                       
                                          
                                             IDCG
                                          
                                          
                                             p
                                          
                                       
                                       -
                                       
                                          
                                             WDCG
                                          
                                          
                                             p
                                          
                                       
                                    
                                 
                              
                           
                        where DCGp
                         is defined as:
                           
                              (16)
                              
                                 
                                    
                                       DCG
                                    
                                    
                                       p
                                    
                                 
                                 =
                                 
                                    
                                       rel
                                    
                                    
                                       1
                                    
                                 
                                 +
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          2
                                       
                                       
                                          p
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             rel
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             log
                                          
                                          
                                             2
                                          
                                       
                                       (
                                       i
                                       )
                                    
                                 
                              
                           
                        In this equation reli
                         is the graded relevance of the object at position i (i.e. the score of the alternative according to the ideal profile), and p is the number of alternatives taken into consideration in one iteration. Given a set of p alternatives analyzed in one iteration, we can obtain the rest of the measures used in Eq. (15). The IDCGp
                         (ideal DCGp
                        ) is the best DCGp
                         that we could obtain, which corresponds to the set of p alternatives ordered by their relevance in a descending way (i.e. the order induced by the ideal profile). In a similar way, the WDCGp
                         (worst DCGp
                        ) is the lowest DCGp
                         that we could obtain with the set of p alternatives (reverse order of IDCGp
                        ). The denominator in Eq. (15) is the normalization factor. A value of 1 in NDCGp
                         means that the order of the alternatives made by the RS coincides with the ideal one.

The relevance of one object is its linguistic preference value, which belongs to the domain S (i.e. the set depicted on Fig. 15). These preferences should be translated to the numerical domain by using their position (i.e., the VL label corresponds to 0, L would be translated to 1, and so on). Taking these values into consideration the DCG metric does not penalize for bad objects, and it is recommended that these evaluations should be balanced between positive and negative values. Thus, using the set of linguistic terms, the VL judgment is translated to −3, L to −2, AL is −1, M corresponds to 0, AH is 1, H is 2, and finally, VH corresponds a 3.

As a final remark before explaining the obtained results, note that in our case the learning procedure uses only the over ranked alternatives and the selected one. With this assumption, p corresponds in each iteration to the index of the selected alternative. When the user selects the first alternative, we take NCDG
                        1 to be 1 (the order of the list with a single alternative is perfect).


                        Fig. 18
                         shows the evolution of the NCDGp
                         (solid line) through the 200 iterations. Additionally, the average of the accumulated values is also shown through the iterations (dotted line). As the current profile and the ideal profile get more similar, NCDGp
                         increases (the system sorts better the set of alternatives in each iteration). As shown in Fig. 16, after the 50th iteration (approximately), the behavior in most of the cases is better than before this iteration (and notice also that the average is nearly 0.9 from this iteration until the end of the simulation).


                        Figs. 19 and 20
                        
                         and Fig. 20 represent the learning evolution of three attribute values for the categorical attributes “Type of foods”, “Atmosphere” and “Special characteristics”, respectively, and show how the ideal values indicated in the ideal profile are learned through iterations of the algorithm. This evolution, as the one of the numerical attributes shown later in this section, corresponds to the test with the initial profile P2 (see Fig. 16).


                        Fig. 19 shows how the preferences over the values “National”, “Asian” and “Rice dishes” of the attribute “Type of foods” are learned. “National” starts with a level of preference “Very Low” and stabilizes in the ideal value “High” (H). The value “Asian” starts with a “High” (H) level of preference and it is seen how it reaches the ideal value of “Medium” (M), although there are some changes between “Medium” (M) and “Almost Low” (AL). For the “Rice dishes” value, since the initial and the ideal value are the same, it can be seen how it does not change at all.


                        Fig. 20 shows the learning of the values “Informal”, “For families” and “Original” of the attribute “Atmosphere”. “Informal” has initially a “Very Low” (VL) level of preference but the system quickly learns that the true preference over that parameter is “High” (H); however, there are several changes to a “Very High” (VH) preference. The “For families” value starts with an “Almost Low” (AL) preference, which is very similar to the ideal “Low”, so there are not many changes here. “Original” stabilizes in the correct level of preference (“Almost High” (AL)) in less than 90 iterations, starting from “Low” (L).


                        Fig. 21
                         shows how the preferences over the values “With terrace”, “Suitable for celiacs” and “With video” of the attribute “Special characteristics” are learned. The value “With terrace” starts with a “High” (H) level of preference, which is very similar to the ideal “Very High”, and it is quickly learned with not many changes. The value “Suitable for celiacs” has an initial preference of “Medium” (M) that reaches the ideal “Almost Low” (AL) in less than 50 iterations. Finally, the value “With video”, which initially has a value of “Very Low” (VL) that is the opposite of the ideal one (“Very High” (VH)), is correctly learnt through the evaluation process.


                        Figs. 22 and 23
                        
                         represent the learning evolution of the preferred value for the numerical attributes “Average price” and “Distance to city center”, respectively, and show how the ideal value of preference of the numeric function indicated in the ideal profile is learned through the 200 iterations of the algorithm.

In the figure that represents the evolution of the value of maximum preference of the attribute “Average price” (see Fig. 22), it can be seen how the ideal one (15€) is correctly learned in less than 90 iterations and it remains stable from there. In the case of the value of maximum preference of the attribute “Distance to city center” (see Fig. 23), a value very close to the ideal one (0.3km) is learned in a similar number of iterations, and although it does not remain as static as in the previous example, the oscillations are not serious enough to compromise the recommendation process.


                        Fig. 24
                         shows the visual evolution of the numeric preference function of the attribute “Distance to city center”. The graphical representation of the function is shown before the start of the learning process (iteration 0), and then after the iterations 20, 50 and 100. In all pictures, the current learned function is compared with a dotted line representing the ideal preference function. The graph in Fig. 24a shows the value of the third initial profile shown in Fig. 16. After 20 iterations (Fig. 24b), the value of maximum preference has moved towards 3km, the slopes are 
                           
                              
                                 
                                    m
                                 
                                 
                                    l
                                 
                              
                              =
                              1.8
                           
                         and 
                           
                              
                                 
                                    m
                                 
                                 
                                    r
                                 
                              
                              =
                              0.6
                           
                         and the widths are Δl
                        
                        =0.3 and Δr
                        
                        =0.12. After iteration 50 (Fig. 24c), the 
                           
                              
                                 
                                    v
                                 
                                 
                                    pref
                                 
                              
                           
                         value is 1 Km, the slopes are 
                           
                              
                                 
                                    m
                                 
                                 
                                    l
                                 
                              
                              =
                              1.5
                           
                         and 
                           
                              
                                 
                                    m
                                 
                                 
                                    r
                                 
                              
                              =
                              0.6
                           
                         and the widths are Δl
                        
                        =0.2 and Δr
                        
                        =0.1. Finally, in Fig. 24d, it can be seen how after 100 iterations the numeric preference function learned (vpref
                        
                        =0.3,
                        ml
                        
                        =1.2,
                        mr
                        
                        =0.8,
                        Δl
                        
                        =0.15,
                        Δr
                        
                        =0.09) almost perfectly fits the ideal one. Although learning a function very similar to the ideal one required about 100 iterations, it is not necessary to obtain it to start giving adequate recommendations since, as the previous results have shown, very good results are obtained in less than half of that number of iterations.

To wrap up the results evaluation, Fig. 25
                         shows in what position the user selection is being ranked by the RS on each of the iterations in the first test (the three give similar results). This figure shows the results in a more intuitive way. Notice that the system is accurate if the selected alternative is in the first positions of the 15-items list in each iteration. Many factors can interfere in the process and make the learning of the exact ideal profile a very hard task, but if the user selection appears in the first positions, we can consider that the learning process is working properly. As it can be observed in Fig. 25, after about 50 iterations, the selected alternative is among the first three ones in 95% of the cases (and the first one in around 70% of the cases).

@&#RELATED WORK@&#

The main goal of the paper is to present an algorithm that automatically learns the user’s preferences over the values of numerical and multi-valued categorical attributes. In the literature, the reader can find numerous works to acquire and represent preferences, which usually depend on the objects to recommend. However, as will be argued in this subsection, there does not exist, as far as the authors know, any previous preference learning algorithm that manages implicit information and deals with these kinds of attributes.

User profiles normally contain two types of information: demographical and domain-dependent preferences [35]. The former include information such as age, sex, nationality, location, and career. that can be used to measure the similarity between users [27]. This information is usually applied to collaborative-based systems and it is not the focus of our work. In our case, we deal with characteristics of the objects to recommend and apply content-based recommendation mechanisms according to the individual preferences of a single user, so this paper focuses on the latter kind of data.

Information Retrieval techniques permit to automatically extract content available on electronic repositories (e.g. Web pages) and perform content-based recommendations; however, the management of this information and the evaluation of the similarities with the preferences of the user is still a challenging task. Additionally, current trends deal with tagged information sources [6,7,10]. These systems allow users to freely assign keywords (tags) to manage their own collections without the limitation of a preset vocabulary. Tags provide a rich source of information for recommendation purposes. With the tagging information, algorithms can be easily designed to calculate user similarity and object similarity by considering tag vectors in the user and object spaces, respectively. However, in our work we deal with the most general case, in which the objects to be recommended have not been previously tagged in any way. Thus, the proposal presented in this work can be directly applied in situations in which we only have an attribute-based description of the objects that can be recommended, without any additional information about them provided previously by the users.

There are several ways in which preferences may be represented in the user profile. A possible classification in four categories is the following: (i) user profiles that contain a vector of values in which the user is interested [31], (ii) user profiles that contain qualitative preferences represented with fuzzy terms [25,26,34], (iii) user profiles containing preferences on numerical criteria [19], and (iv) user profiles linked with ontology-based semantic information [2,27,29]. Note that most of these options focus on a single kind of preference values, which is either numeric (e.g. the user’s assessment of a particular object or the user’s level of interest in objects related to a certain class of the domain ontology) or linguistic (e.g. the user may be requested to fill a questionnaire describing his/her interests using some predefined linguistic labels, so that he/she is not forced to give a precise numerical value). The joint consideration of quantitative and qualitative preferences on numerical and multi-valued categorical attributes proposed in this paper is not directly addressed in this classification and provides an added value to the previous works in the field.

The information contained in those profiles is used to rank the set of elements to recommend according to the preferences of the user. This step is usually called preference rating. Several researchers have proposed different solutions to accomplish this task as the use of Machine Learning techniques [5,11,20] or multi-criteria decision aid–based approaches, which allow the combination of several criteria [1,2,4,36]. Our proposal fits in the latter kind of systems, as each of the items that can be recommended is described with a list of values associated to numeric or linguistic attributes. Our double use of the ULOWA aggregation operator introduces a high degree of flexibility and customization of the system to any domain, since the designer can decide how to put together the preferences on the individual values of categorical attributes (even having a different policy for each attribute) and also how to aggregate the linguistic preferences on all the values of all the criteria of a certain alternative. In the first case, which has been commented in section 3.1, the designer of the system can choose from a wide range of evaluation alternatives. In the most extreme case, he/she can decide that a list of categorical values contained in an attribute is interesting for the user only if he/she has a high preference value for all of those values; in the other extreme, it could be decided that it is only necessary for one of the categorical values to have a high associated preference for the list to be considered worth recommending to the user. The same flexibility exists in the second case, in which ULOWA is used to put together the linguistic evaluations of all the attributes of a given object. Again, in this step we could use from a very restrictive policy (an object will be recommended only if the user has a high preference on all the values of all the attributes) to a less demanding and more realistic setting (in which an object may be recommended to the user if some of its features seem to match with the user’s preferences, although there may be attributes in which the object has a value for which the user has a low preference).

Moscato et al. [28] propose an interesting hybrid recommender framework that combines implicit learning of preferences, explicit information collected from forms, and social information from other similar users. In this case, they use ontological information attached to the objects to calculate similarities between them. The final rate of an object combines three different elements: information about previous objects accessed by the user, influences from other users, and similarity with the user interests. The main shortcoming of this work is that they propose to rate objects taking into account only one criterion, in this case a multi-valued one picked from the domain ontology. However, the algorithms proposed in this paper may be used in much more complex multi-criteria scenarios, including different kinds of criteria.

There are few works that address multi-attribute preference learning. Adomavicius and YoungOk [1] propose two multi-criteria-based user profile adaptation algorithms. One of them employs collaborative filtering techniques. The other one suggests the following steps: to learn the rating prediction for each criterion individually, to learn an aggregation function that puts together the evaluation of each criterion to have a global assessment of an alternative, and finally to use the results of the previous steps to predict the overall rating of the option set. In the work presented in this paper each attribute is also considered individually and the evaluation of each attribute is aggregated to get the overall rate of an alternative. However, there are two basic differences in favor of the proposal presented in this paper. First, as commented previously, our proposal provides a great flexibility in the definition of the mechanism that aggregates the individual preferences of the attributes, permitting its use in very different settings. Moreover, unlike that proposal, we provide a complete and detailed algorithm for the adaptation of the user profile after the analysis of each selection of the user, which specifies precisely how the preferential information on the user profile changes depending on the object selected by the user after each recommendation step.

Another proposal that considers several criteria is made by Arias et al. [2]. In this case the aim is to filter the news that can be interesting for the user, taking into account the criteria of aboutness, coverage, novelty, reliability and timeliness. The user profile contains information on the preferences of the user in these aspects, and they are modified with the analysis of the news marked by the user as relevant. The authors define a very specific adaptation function for each of the considered criteria, whereas in our approach all the criteria are modified with the same process. This is the main difference of our work with respect to most of the previous works on preference learning, which are domain-dependent and rely heavily on the particular specificities of the domain in order to define the learning algorithm, making them hardly reusable in any other domain. Our proposal is fully domain independent and could be easily applied to any domain defined on numerical and categorical attributes, without having the need to study the concrete attributes of the domain and to define specific preference learning mechanisms adapted to their particularities. Our most restrictive requirement is that the user has to face the selection problem very often, so that his/her continuous selections provide the adaptation algorithms with the feedback they need to learn quickly and efficiently the user’s preferences. However, as argued in the initial section of the paper, nowadays users are constantly confronted with a high quantity of selection options and have to take decisions with dozens or hundreds of alternatives continuously, so it can be argued that the adaptation algorithms presented in this paper could indeed be useful in many daily decisional problems.

Finally, it could also be argued that this work fits into the “learning to rank” field of work, as the first module of the recommender processes the received alternatives and rates them according to the interests of the user; thus, at the end, the recommender system discretizes the n-dimensional space in 1 dimension – a linguistic label in our case. However, there are very important differences of our work with respect to the current approaches in the area (e.g. [13,14,18,21]) that highlight the novelty of our approach and make a direct comparison unfeasible. The main ones are the following:
                        
                           •
                           All of those methodologies are supervised, in the sense that all of them need a training set with a large number of ranked objects (for instance a set of 1.7million Web pages in Li et al. [21], 2.8million movie ratings in Freund et al. [13]). One specific goal of our work is to develop a non-supervised learning methodology that is domain-independent, flexible and does not require the construction of a training set.

All the mentioned methodologies have the goal of reaching a specific ideal ordering, which is supposed to be fixed. As our learning methodology is incremental, it permits the dynamic adaptation of the system to the preferences of the user, even if those preferences change dynamically over time. This methodology has already been introduced and tested using fuzzy linguistic values [23] and numerical values [22].

The base of our approach is the definition of each of the objects with respect to a relatively small set of attributes, using either numerical or multi-valued categorical attributes. Most learning-to-rank approaches ([13,18,21]) only deal with numerical values (considering usually a large number of attributes, e.g. 367–619 features in Li et al. [21], over 20,000 features in Joachims [18], 500–2000 features in Freund et al. [13]). Some works, like [14], do not even make an attribute-based definition of objects, but work directly on relative rankings of objects without considering any structure in them. Thus, none of those works are directly applicable in the multi-criteria decision support field in which our paper falls.

@&#CONCLUSIONS AND FUTURE WORK@&#

Two main contributions with respect to our previous work have been presented in this paper. The first one consists in managing multi-valued categorical attributes in the alternatives of a RS, allowing more expressivity in their representation. The system considers a single preference for each possible value and aggregates them to find out the preference over the whole attribute. The consideration of multi-valued attributes is mandatory when working with alternatives such as the ones presented in this paper (e.g. “Types of Food” in a restaurant).

The second contribution, which is learning the numeric preference function, allows shaping a more expressive and personalized representation of the user’s preferences over each numeric attribute, defining a preference function with 5 parameters. This additional expressivity helped to improve the profile learning process by reducing the learning error around 7%.

As future work, three interesting lines can be considered. As pointed out in Section 3, an aggregation policy can be considered in the aggregation of the preferences in a single categorical attribute, other than the use of the common “average” policy. Research can be made in this area in order to learn the aggregation policy that fits more with the user interests. Another interesting line to consider is to incorporate information about the five parameters that define the ideal numeric preference function in the distance measure used to evaluate the algorithm (Eq. (12)) since, currently, just the ideal value of preference is being considered. Finally, it would also be very interesting to build a mathematical model, based on the minimization of a loss function, that might permit a more rigorous and theoretical analysis of the performance of the proposed preference learning method.

@&#ACKNOWLEDGEMENTS@&#

This work has been supported by the Universitat Rovira i Virgili (a pre-doctoral grant of L. Marin) and the Spanish Ministry of Science and Innovation (DAMASK Project, Data mining algorithms with semantic knowledge, TIN2009-11005) and the Spanish Government (Plan E, Spanish Economy and Employment Stimulation Plan). The authors also acknowledge the insightful comments received from the reviewers.

@&#REFERENCES@&#


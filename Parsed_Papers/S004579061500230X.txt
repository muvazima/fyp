@&#MAIN-TITLE@&#Segmentation of cancerous regions in liver using an edge-based and phase congruent region enhancement method

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Novel level set method for segmenting low contrast cancerous regions is presented.


                        
                        
                           
                           Proposed method uses new stopping function based on edge and phase information.


                        
                        
                           
                           Result indicates the superiority of the proposed method in 2D and 3D CT images.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gradient

Leakage

Level sets

Liver cancer

Segmentation

Stopping function

@&#ABSTRACT@&#


               
               
                  Segmenting low-contrast cancerous regions from Computed Tomography (CT) images is an important task. Region and edge-based active contours fail to perform with such images. Thus, edge-based phase congruent region enhancement is proposed for detecting low-contrast boundaries using new stopping function. The stages of the proposed method are: region separation, region enhancement and Distance Regularised Level Set Evolution (DRLSE) with new stopping function. First, cancerous region is delineated by creating phase map and converting it into an edge map by thresholding. Second, the feature map is created by enhancing features at the boundaries of edge map. The feature map is combined with original image to generate final image. Finally, stopping function is constructed for DRLSE based on the gradient of final image. Experiments were performed on 20 two dimensional and 4 three dimensional CT scans. The proposed method was compared with two active contours. Results prove the superiority of proposed method.
               
            

@&#INTRODUCTION@&#

Cancer is one of the most lethal non-communicable diseases and contributes to 13% of total deaths worldwide [1]. It is curable if detected early and accurately. In addition, in the prognosis and diagnosis of cancer, it is necessary to know beforehand the size and area of spread of the cancer. In this regard, studies related to medical imaging play an important role in the early diagnosis of cancer. Medical imaging has emerged as a non-invasive tool for diagnosis of diseases. Many medical modalities related to imaging are used, such as X-rays, Ultrasound, Computed Tomography (CT) scanning and Magnetic Resonance Imaging (MRI). As the volume of digital imaging data is massively increasing, it is not possible for radiologists to diagnose diseases manually, and this may lead to misdiagnosis. Thus, computer-aided diagnosis systems have attracted a great deal of interest for the diagnosis of diseases as a method to improve the diagnosis accuracy and efficiency of radiologists [2]. The most important part of a computer-aided diagnosis system is image segmentation.

Image segmentation is the process of dividing an image into multiple regions. The segmented region is also known as the Region of Interest (ROI). These ROIs are used as informative inputs for image processing techniques, e.g., feature extraction, selection and, ultimately, classification of diseases. Thus, effective image segmentation is of utmost importance in medical image processing. In this paper, our main focus is on the segmentation of CT images of abdomen having an image of cancer with low contrast and weak boundaries (Fig. 1
                     ). An efficient and accurate image segmentation method is not only helpful in detecting the location of cancer in the liver but is equally important for determining the extent by which cancer has spread across the liver. In addition, it also provides information about the extent of damage to nearby organs or the liver. If image segmentation provides incorrect information about the extent of cancer by failing to detect the desired boundaries of the ROI, then a Computer-Aided Diagnostic (CAD) system may provide a false diagnostic report. Thus, segmentation methods need to be sensitive enough to detect the desired boundaries and area of cancer spread so that an accurate diagnosis can be achieved. Extensive studies have been performed in the past on medical image segmentation, and many methods have been proposed for the same. Sharma and Aggrawal [3] reviewed various methods of medical image segmentation and discussed the merits and demerits of segmentation methods. Ahmed et al. [4] surveyed semiautomatic and automatic medical image segmentation methods. Sridhar et al. [5] segmented abnormal masses from mammogram images using combination of watershed transform and Markov random fields. Linguraru et al. [6] used shape and physiological features along with probabilistic location information for segmenting the liver and analysed the proportion of the tumour in the liver. Hame and Pollari [7] proposed semi-automatic liver tumour segmentation method based on non-parametric intensity distribution estimation and hidden Markov model and attained high accuracy in segmenting desired ROI. Fang et al. [8] addressed the problem of low contrast boundaries and proposed new segmentation method based on optimal tree-metrics graph cuts on multi-phase contrast enhanced MRI images. Zhang et al. [9] proved that non-intensity based edge detection and subtraction method is an effective tool in segmentation of tumourous tissues in liver. Zhou et al. [10] presented a performance benchmarking study on liver tumour segmentation using region growing with knowledge-based constraints.

The deformable contour is one of the most reliable and extensively used techniques in medical image segmentation. The reason is its ability to handle complex structures [11]. Evgin et al. [12] proposed fully automated variational level set approach for liver segmentation. The evolution and termination of contour is controlled by region and edge bases special pressure force, thus does not rely on distance regularization term and conventional edge stopping functions [12]. The method is applied on ten data sets and results indicated that proposed method can accurately and efficiently segment liver images [12]. Linguraru et al. [13] used shape correction methods in geodesic active contours for accurate segmentation of tumour and liver. Patil et al. [14] designed semiautomatic segmentation method that employed multiple levels of thresholding for segmentation of tumour from liver. Smeets et al. [15] used semiautomatic level set technique for segmentation of liver tumours in CT images in which the statistical pixel classification algorithm is used for the evolution of level sets. Kadoury et al. [16] proposed method for liver tumour segmentation in which higher-order potentials ensure regional consistency. Peng et al. [17] presented semiautomatic level set based liver segmentation method that uses region and edge information for evolution. Results indicate that integrating region and edge information leads to the superior performance in delineating ambiguous liver edges.

Deformable contours, referred to as snakes, are used for detection of nearby edges. These snakes were represented by parametric curves, Lagrangian formulation and based on the principle of energy minimisation for the detection of nearby edges. Ersoy et al. [18] proposed edge guided level sets for analysis of spreading of cells. Evgin [19] in his thesis presented overview of liver segmentation methods and proposed level set method in which the evolution of contour using special signed pressure function based edge indicator is done without using any regularized term. Yang et al. [20] presented hybrid semiautomatic method that consists of fast marching and thresholding based level set approach for segmentation of liver from abdominal CT image. Li et al. [21] applied level set for segmentation of liver tumour in Two Dimensional (2D) and Three Dimensional (3D) CT images. Such contours use Euler formulation, and the evolution of contours is performed using the level set method.

The basic idea of the level set method is to represent a contour as the zero level set function of higher dimension called the level set function ϕ
                     0(x,
                     y) and thus formulate the motion of contour as the evolution of this level set function. The level set function ϕ
                     0(x,
                     y) defined using Eq. (1) is a signed distance function where the value of the function is zero on the boundary of the contour, negative inside the contour and positive outside the contour.
                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             ϕ
                                             0
                                          
                                          
                                             (
                                             x
                                             ,
                                             y
                                             )
                                          
                                          =
                                          
                                             {
                                             
                                                
                                                   
                                                      
                                                         
                                                            0
                                                            on
                                                            
                                                            boundary
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            +
                                                            ve
                                                            outside
                                                            
                                                            contour
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            −
                                                            ve
                                                            inside
                                                            
                                                            contour
                                                         
                                                      
                                                   
                                                
                                             
                                             }
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

The level set equation under the influence of Force ‘F’ is defined using Eq. (2) 
                     [22]:
                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             ϕ
                                             t
                                          
                                          +
                                          F
                                          
                                             |
                                             ∇
                                             ϕ
                                             |
                                          
                                          =
                                          0
                                       
                                    
                                 
                              
                           
                        
                     ‘F’ is function of various arguments, such as curvature, normal direction and gradient.

A further development of level sets for image segmentation is the geodesic active contour model, which uses gradient information to create an edge-based stopping function for contour to terminate at desired boundaries. It is necessary to maintain a stable level set function during evolution [23]. This is accomplished by a process called re-initialisation. Re-initialisation is meant to avoid numerical disorders during evolution, but it increases computational cost [23]. Li et al. [23] proposed edge-based DRLSE, in which re-initialisation is not required, thereby avoiding numerical errors. The problem of spreading of a contour out of the desired region of interest, commonly referred to as leakage, is often encountered in edge-based contours [24,25]. To overcome the problem of leakage, region-based contour was proposed by Vese and Chan [24]. Zhang et al. [25] proposed region-based Selective Binary and Gaussian Filtering Regularised Level Sets (SBGFRLS).

After an extensive literature survey on image segmentation, it has been observed that most of the methods that have been used in the past provide satisfactory results only if the boundaries of the desired ROI are distinct, i.e., the intensities of the infected and non-infected regions are not similar. The infected and non-infected regions are clearly demarcated by distinct boundaries. For distinct boundaries, the stopping function is equal to zero, which forces the contour to terminate at the desired boundaries. However, in CT images of liver cancer with low contrast and weak boundaries, the intensity of the infected region is almost the same as that of the non-infected region (Fig. 1). In these types of images, the gradient is not high at the desired boundaries. Thus, the stopping function (which is inversely proportional to gradient) can never be close to zero, which is required for the contour to terminate at the desired boundaries. Many studies [23–25] underlying the problem of leakage of contour at the location of the weak boundaries. The contour will extend beyond the correct boundaries of cancer (ROI), resulting in over segmentation. This may provide inaccurate information about the extent of spread of cancer across the liver. Thus, the main focus of this paper is to address the problem of stopping the contour at the desired boundaries, which are low in contrast and have weak intensity. The aim is to design new method of image segmentation that can delineate a liver cancerous region with low contrast and weak boundaries. Accordingly, a novel method, edge-based phase congruent region enhancement level set evolution, is proposed.

The main reason of leakage of the contour in conventional active contour models is lack of the gradient information near boundaries of ROI. This is because of similar texture within and outside ROI as shown in Fig. 1.The primary idea underlying the method is to create a gradient between the inner and outer region of the ROI using phase and region information to provide distinct boundaries. Phase information is used to extract ROI boundaries. After detecting the boundaries of ROI, region information is used to enhance the ROI boundaries. The gradient information created as a result of the enhancement is high enough to result in a stopping function close to zero near the desired boundaries. Lastly, the new stopping function is used in a level set framework to facilitate the contour stopping at the desired boundaries. The flow chart of the proposed method is shown in Fig. 2
                     .

The first stage of the proposed method is to separate the ROI (cancerous region) from the surrounding tissues within the CT image to use it for further processing. An approach called region separation has been proposed for this task. The purpose of separating the ROI from surrounding tissues is to detect the ROI boundaries, which earlier are not distinct and visible (Fig. 1). Given that, on the image, the liver cancer is low in contrast and has weak intensity boundaries (Fig. 1), the thresholding technique for separating the region does not always provide the desired results as it significantly distorts the ROI shape. Thus, as a first step of region separation, the phase information of an image is used for separating the ROI by applying a Fast Fourier transform (FFT) to the input image and searching for maximal phase congruency. Thus, the phase map is created by using local energy information. Secondly, the created phase map is transformed into an edge map by applying a conventional thresholding technique. By creating an edge map, the ROI (cancerous region) is separated from the surrounding tissues. Detecting the ROI boundaries alone is not sufficient for segmenting CT images with weak boundaries because the boundaries obtained by creating the edge map are broken. A broken boundary indicates that the periphery defining the ROI is neither continuous nor unified in nature. Because of these broken boundaries, the region within the ROI may merge with some similar unwanted region outside ROI. This leads to the wrong segmentation of ROI. In addition, for the broken boundaries, no credible information regarding the gradient near boundaries will be generated because the exact ROI boundary location is unclear. Thus, the boundaries of the edge map need to be defined clearly, uniform and continuous in nature to avoid any unwanted region being part of the ROI. In other words, empty spaces within boundaries that are broken need to be filled to ensure boundaries are continuous and unified. To accomplish this, a region enhancement scheme is proposed as a second stage. In region enhancement, the boundaries of the ROI obtained are made uniform and continuous by filling broken boundaries, and then pixels are enhanced by creating a feature map, resulting in enhanced boundary features. The feature map thus obtained is combined with the non-feature image (original CT image) to obtain a final image. The weak boundaries are now enhanced by combining the non-feature image with the ROI feature map. Enhancing features at boundaries improves the gradient information near the ROI boundaries. A new stopping function is created using the modified gradient information obtained from region enhancement used by the level sets to detect weak boundaries.

There are methods [26] that use phase information for the purpose of segmentation, but in these methods [26], only phase information is used to extract boundary features. In contrast, the proposed method extracts boundary features by integrating both phase as well as region information. Using region information along with phase information is a robust alternative to conventional phase based level set methods for segmenting CT images with weak boundaries. In the proposed method, additional information based on region is used, along with phase information, for detecting and enhancing features at the boundaries. Furthermore, in this paper, edge-based DRLSE [23] and region-based SBGFRLS [25] are implemented to prove the superiority of the proposed method. In this paper, the described experiments were performed on twenty 2D CT images and four 3D CT scans of liver cancer with low contrast and weak boundaries (confirmed by a group of specialists). First, the desired ROI, i.e., the cancerous region, was marked manually by specialists, and the result was compared with segmented ROIs created using proposed method. Four statistical parameters, (i) Boundary Displacement Error (BDE), (ii) Variation of Information (VOI), (iii) Global Consistency Error (GCE) and (iv) Rand Index (RI) were used to compare the performance of our proposed method with two other methods. The results we obtained are highly encouraging and indicate the promise of the proposed method. The outline of this paper is as follows. Section 2 consists of a review of edge-based and region-based active contour models. Section 3 provides the details of the proposed algorithm and its implementation. Section 4 includes experimental results and discussion. The last section concludes this paper.

Li proposed an edge-based DRLSE method for eliminating the need for re-initialisation [23]. Level set evolution is defined as a gradient flow that minimises energy function E(ϕ). The energy function E(ϕ) is the summation of the distance regularisation term Rp
                         and external energy Eext
                        . The Energy function E(ϕ) is defined using Eq. (3) 
                        [23].
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             E
                                             
                                                (
                                                ϕ
                                                )
                                             
                                             =
                                             μ
                                             
                                                R
                                                p
                                             
                                             
                                                (
                                                ϕ
                                                )
                                             
                                             +
                                             
                                                E
                                                ext
                                             
                                             
                                                (
                                                ϕ
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where Rp
                        (ϕ) is a distance regularisation term, and Eext
                        (ϕ) is external energy. The distance regularised term Rp
                         is defined using potential functions in such a way that it forces the gradient magnitude to be at minimum point, thereby maintaining the signed distance profile [23]. This is known as the distance regularisation effect. This effect eliminates the need for re-initialisation. The energy function can be minimised using Eq. (4) 
                        [23]:
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∂
                                                   ϕ
                                                
                                                
                                                   ∂
                                                   t
                                                
                                             
                                             
                                                =
                                                μ
                                                div
                                                (
                                             
                                             
                                                d
                                                p
                                             
                                             
                                                (
                                                |
                                                ∇
                                                ϕ
                                                |
                                                ∇
                                                ϕ
                                                )
                                             
                                             +
                                             λ
                                             δ
                                             
                                                (
                                                ϕ
                                                )
                                             
                                             div
                                             
                                                (
                                                g
                                                
                                                   
                                                      ∇
                                                      ϕ
                                                   
                                                   
                                                      |
                                                      ∇
                                                      ϕ
                                                      |
                                                   
                                                
                                                )
                                             
                                             +
                                             α
                                             g
                                             δ
                                             
                                                (
                                                ϕ
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        μ
                        >
0 is constant, and α and λ are coefficients of the energy function. The first term represents a distance regularisation term, and the second and third terms are related to external energy. This method works well for only distinct boundaries but does not provide satisfactory results in regard to low contrast images having weak boundaries because in weak boundaries, the gradient value is not high enough for a stopping function close to zero, which inhibits the termination of the contour at the desired boundaries.

SBGFRLS is a region-based active contour model [25]. It is based on the principle of energy minimisation and utilises the statistical information inside and outside the contour to control the evolution. For a given image I(x,
                        y), the Chan–Vese model is implemented by minimising the energy function using Eq. (5) 
                        [24,25]:


                        
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   E
                                                
                                                CV
                                             
                                             =
                                             
                                                λ
                                                1
                                             
                                             
                                                ∫
                                                INSIDE
                                             
                                             
                                                |
                                                I
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                −
                                                
                                                   c
                                                   1
                                                
                                                
                                                   
                                                      |
                                                   
                                                   2
                                                
                                                +
                                                
                                                   λ
                                                   2
                                                
                                                
                                                   ∫
                                                   OUTSIDE
                                                
                                                |
                                             
                                             I
                                             
                                                (
                                                x
                                                ,
                                                y
                                                )
                                             
                                             −
                                             
                                                c
                                                2
                                             
                                             
                                                
                                                   |
                                                
                                                2
                                             
                                             dx
                                          
                                       
                                    
                                 
                              
                           
                        where c
                        1 and c
                        2 are mean intensities inside and outside the contour, respectively. λ
                        1 and λ
                        2 are parameters having values greater than zero.

In region-based SBGFRLS, a special pressure force spf(I(x)) is used for automatically and efficiently stopping the contour at desired boundaries by considering the sign of pressure forces inside and outside the region for contraction or expansion using Eq. (6) 
                        [25]:
                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             spf
                                             
                                                (
                                                x
                                                )
                                             
                                             =
                                             
                                                
                                                   I
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   −
                                                   
                                                      
                                                         
                                                            c
                                                            1
                                                         
                                                         +
                                                         
                                                            c
                                                            2
                                                         
                                                      
                                                      2
                                                   
                                                
                                                
                                                   
                                                      max
                                                   
                                                   
                                                      (
                                                      
                                                         |
                                                         I
                                                         
                                                            (
                                                            x
                                                            )
                                                         
                                                         −
                                                      
                                                      
                                                         
                                                            
                                                               c
                                                               1
                                                            
                                                            +
                                                            
                                                               c
                                                               2
                                                            
                                                         
                                                         2
                                                      
                                                      
                                                         |
                                                      
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Level set formulation is performed using Eq. (7) 
                        [25]:
                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∂
                                                   ϕ
                                                
                                                
                                                   ∂
                                                   t
                                                
                                             
                                             =
                                             spf
                                             
                                                (
                                                I
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                )
                                             
                                             ·
                                             α
                                             
                                                |
                                                ∇
                                                ϕ
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where α is constant.

The novelty in this method is enhancing the features (pixel intensity) at the boundaries of the desired ROI by integrating phase and region information, thereby creating a new stopping function for level sets. This method is divided into three stages: (i) region separation, (ii) region enhancement and (iii) applying edge-based DRLSE with new stopping function.

In CT images, as depicted in Fig. 1, the grey level of the liver cancer tissue is very similar to that of the normal tissue (surrounding tissue). Therefore, using merely a thresholding technique for region separation will not separate the infected region from the normal one. It has been found that applying thresholding alone to CT images with very low-intensity variation distorts the ROI shape, which is cancer in this case. Thus, as the first step of region separation, and in an attempt to extract the cancerous region (ROI) of the liver from surrounding tissues, a phase map is created, and afterwards, thresholding is applied to convert this phase map to an edge map. We are concentrating on detecting boundaries of ROI by separating infected ROI (shown in Fig. 1 with arrow) from the surrounding tissues, so that separated ROI can be used for further processing. The steps in the region separation stage are (i) creation of phase map and (ii) thresholding: creation of an edge map.

In this work, the phase map is created by detecting edges based on a local energy model [27]. This model postulates that the features are perceived at a point in an image where Fourier components are maximal in phase using phase congruency. To detect the points having maximum phase congruency, it is easier to implement a local energy model than to directly calculate the phase congruency. Mathematically, the maximum phase points are calculated via the energy model using Eq. (8) 
                           [27]
                           
                              
                                 (8)
                                 
                                    
                                       
                                          
                                             
                                                PC
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   
                                                      |
                                                      E
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                      |
                                                   
                                                   
                                                      ∑
                                                      
                                                         A
                                                         n
                                                      
                                                      
                                                         (
                                                         x
                                                         ,
                                                         y
                                                         )
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where PC is Phase Congruency, and E(x,
                           y) is the energy function, which is the magnitude of a vector from origin to the end point, An
                           (x,
                           y), which is the sum of Fourier amplitudes.

The local energy function Ei
                           (x,
                           y) at any point x,
                           y and at any specific orientation i and specific scale n in the image is computed using Eq. (9) 
                           [27]:
                              
                                 (9)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   E
                                                   
                                                      i
                                                   
                                                   n
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   
                                                      
                                                         E
                                                         
                                                            x
                                                         
                                                         n
                                                      
                                                      
                                                         (
                                                         x
                                                         ,
                                                         y
                                                         )
                                                      
                                                      +
                                                      
                                                         E
                                                         
                                                            y
                                                         
                                                         n
                                                      
                                                      
                                                         (
                                                         x
                                                         ,
                                                         y
                                                         )
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where Ex
                           (x,
                           y) is the convolution of image with the even symmetric log-Gabor function at a specific scale n and orientation i, and Ey
                           (x,
                           y) is the convolution of an image with an odd symmetric log-Gabor function at specific scale n and orientation i. Ex
                           (x,
                           y) and Ey
                           (x,
                           y) are the Hilbert pairs of each other.

The total local energy Et
                           (x,
                           y) can be calculated as a summation of energies at different orientations and scales using Eq. (10) 
                           [27]
                           
                              
                                 (10)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   E
                                                   t
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                                =
                                                
                                                   ∑
                                                   
                                                      i
                                                      ,
                                                      n
                                                   
                                                
                                                
                                                   E
                                                   
                                                      i
                                                   
                                                   n
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   y
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where i is the orientation, and n is the scale.

When substituting the values of the local energy function, the phase map is created. The Gabor filter response can also be calculated in time domain, but we used FFT as all convolutions are performed in the frequency domain.

Once the phase map is created, a second step in region separation is to apply thresholding on the phase map and convert it into an edge map. Conversion of the phase map to edge map is shown in Fig. 3
                           . The optimal value of the threshold is required for faithful conversion of the phase map to edge map. Faithful conversion of phase map to edge map implies the preservation of ROI shape. Thus, threshold value for particular image is selected where the shape of ROI is preserved while converting phase map to edge map. Selection of threshold for particular image is shown in Fig. 3. It is amply clear from Fig. 3(f) that by selecting optimal threshold, the entire desired region within the phase map (Fig. 3(a)) is converted into an edge map and shape of the ROI is preserved. Otherwise, part of the desired region within the ROI becomes distorted as shown in Fig. 3(b)–(e), which ultimately affects the creation of the feature map. It is noted here that one needs to select a threshold value where the phase map is converted into an edge map with minimum distortion in terms of mapping of the regions of the edge map and phase map. Thus, optimal selection of threshold value is image specific and required to be selected where shape of ROI is preserved while converting phase map to edge map.

As shown in Fig. 3, the separated ROI in the form of the edge map has broken boundaries and is not continuous. Because of these broken boundaries, the desired region within the ROI may merge with the surrounding region outside the ROI leading to incorrect segmentation output. In addition, broken boundaries are unable to create credible and uniform gradient information near the boundaries, as the exact ROI is not clearly defined. Thus, the boundaries of the edge map need to be fixed by filling empty spaces within the boundaries and defined clearly by making them uniform and continuous in nature. In addition, the features at the boundaries need to be enhanced to create stopping function that can be zero near edges. This is accomplished with region enhancement. Region separation can be used for separating more than one infected region, but as per the requirement, we are applying region separation to the infected region only. Therefore, if there are more than one ROI, then the output is the union of all separated regions, having no commonality between two regions as in Eq. (11):
                              
                                 (11)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   R
                                                   T
                                                
                                                =
                                                
                                                   
                                                      ∪
                                                      S
                                                   
                                                   
                                                      l
                                                      =
                                                      1
                                                   
                                                
                                                
                                                   R
                                                   l
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    R
                                    l
                                 
                                 ∩
                                 
                                    R
                                    u
                                 
                                 =
                                 ϕ
                              
                           , l ≠ u, RT
                            is the total region of the image, Rl
                            the separated regions and S the total number of regions.

After the successful separation of the ROI from surrounding tissues, the next objective is to smooth the boundaries of the edge map, to unify the boundaries and enhance the features (pixel intensity) on the periphery of the separated ROI. Enhanced features are required to improve gradient information at the ROI periphery to generate stopping function that forces the contour to settle at the desired ROI boundaries. This aim has been achieved using region enhancement. The steps in the region enhancement stage are (i) creation of the feature map from the edge map, (ii) combining the original image with a feature map to create a final image and (iii) creation of the stopping function from the final image. These steps are detailed in the following sub-sections.

In the creation of the feature map, an enhanced feature image is initially generated. The idea, of generating an enhanced feature image, is to bridge and fill the empty spaces of the broken boundaries of the edge map so as to make the boundaries smooth, continuous and unified in nature by searching the pixels that are inside or on the periphery of ROI and then changing the intensities of those pixels which are inside ROI. The procedure for creating an enhanced feature image (Fig. 4
                           (b)) from edge map (Fig. 4(a)) is provided below:

                              
                                 
                                    
                                    
                                       
                                          (a) Set Pn
                                             
                                             =0; i (row number)=1, ii (column number)=1, Pth
                                             
                                             =Predefined pixel threshold value;
                                       
                                       
                                          
                                             
                                                
                                                   [
                                                   v
                                                   g
                                                   ]
                                                   =
                                                   size
                                                   (
                                                   input
                                                   _
                                                   image
                                                   )
                                                
                                             .
                                       
                                       
                                          (b) scan_pixel=input_image(i,
                                             ii).
                                       
                                       
                                          (c) while scan_pixel not equals to non-zero
                                       
                                       
                                          (d) ii
                                             =
                                             ii
                                             +1; end while
                                       
                                       
                                          (e) while Pn
                                             
                                             <=
                                             Pth
                                              or scan_pixel=next non zero pixel; Pn
                                             
                                             =
                                             Pn
                                             
                                             +1; ii
                                             =
                                             ii
                                             +1;means all scan_pixels are inside ROI.
                                       
                                       
                                          (f) end while
                                       
                                       
                                          (g) if scan_pixel=next non zero pixel
                                       
                                       
                                          (h) Change intensity of pixels, number of pixels whose intensity changes are equals to value of Pn
                                             ;
                                       
                                       
                                          (i) else: scan_pixels are outside ROI.
                                       
                                       
                                          (j) Make the intensity of scan_pixels as such.
                                       
                                       
                                          (k) Make Pn
                                             
                                             =0.
                                       
                                       
                                          (l) go to (d) in case ii
                                             <
                                             g
                                          
                                       
                                       
                                          End if
                                       
                                       
                                          (m) Make Pn
                                             
                                             =0; ii
                                             =1; repeat for all i; goto (b).
                                       
                                    
                                 
                              
                           
                           Pn
                            is counter for cumulative number of pixels and Pth
                            is the predefined number of pixels depending upon the ROI and threshold value T (value of Pth
                            ranges from 5 to 30 pixels).

As smoothing and filling needs to be performed for all pixels at the ROI periphery, this method is applicable to both the horizontal as well as vertical directions (for all rows and columns). The enhanced feature image created using the algorithm above is defined mathematically using Eq. (12):
                              
                                 (12)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   I
                                                   e
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   p
                                                   ,
                                                   q
                                                   )
                                                
                                                =
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                               −
                                                               
                                                                  c
                                                                  p
                                                               
                                                            
                                                            
                                                               
                                                                  r
                                                                  p
                                                               
                                                               −
                                                               
                                                                  c
                                                                  q
                                                               
                                                            
                                                         
                                                         
                                                            [
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  1
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  p
                                                               
                                                               )
                                                            
                                                            +
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  np
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  p
                                                               
                                                               )
                                                            
                                                            +
                                                            
                                                               ∑
                                                               
                                                                  i
                                                                  =
                                                                  2
                                                               
                                                               
                                                                  np
                                                                  −
                                                                  1
                                                               
                                                            
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  i
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  p
                                                               
                                                               )
                                                            
                                                            ]
                                                         
                                                      
                                                      ︸
                                                   
                                                   
                                                      Horizontal
                                                      
                                                      Direction
                                                      (
                                                      Row-wise
                                                      )
                                                   
                                                
                                                +
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                               −
                                                               
                                                                  r
                                                                  p
                                                               
                                                            
                                                            
                                                               
                                                                  c
                                                                  q
                                                               
                                                               −
                                                               
                                                                  r
                                                                  p
                                                               
                                                            
                                                         
                                                         
                                                            [
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  q
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  1
                                                               
                                                               )
                                                            
                                                            +
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  q
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  nq
                                                               
                                                               )
                                                            
                                                            +
                                                            
                                                               ∑
                                                               
                                                                  j
                                                                  =
                                                                  2
                                                               
                                                               
                                                                  nq
                                                                  −
                                                                  1
                                                               
                                                            
                                                            I
                                                            
                                                               (
                                                               
                                                                  x
                                                                  q
                                                               
                                                               ,
                                                               
                                                                  y
                                                                  j
                                                               
                                                               )
                                                            
                                                            ]
                                                         
                                                      
                                                      ︸
                                                   
                                                   
                                                      Vertical
                                                      
                                                      Direction
                                                      (
                                                      Column-wise
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           x
                           ∈{r
                           1,
                           r
                           2,
                           r
                           3
                           …, rM
                           ,
                           c
                           1,
                           c
                           2,
                           c
                           3
                           …
                           cN
                           }, where M and N are the number of rows and columns, respectively, rp
                            and cq
                            are the pth row and qth column, respectively, where p
                           ∈{1…, M}, q
                           ∈{1…
                           N}, and np,
                           nq are the number of pixels in the pth row and qth column, respectively. x and y pertains to the pixel position.

It is quite obvious in Fig. 4 that the boundaries of the enhanced feature image are much smoother and continuous than the boundaries of the edge map (Fig. 4(a)), and there is clear demarcation of boundaries between the inner and outer region of ROI, and no unwanted region outside the ROI is merged with the desired ROI (shown by an arrow in Fig. 4(b)). With enhanced image, although no immediate unwanted neighbour region is merged with the ROI, it is still difficult to differentiate the background of the ROI from other regions of the image having the same background. This is shown in Fig. 5
                           , where ROI marked as 1(desired ROI shown by arrow) is having same background as ROI marked as 2 (unwanted ROI). The objective is to segment only desired ROI from entire CT image without any unwanted ROI.

Thus, further processing is required to obtain the final segmented ROI. For this, the feature map is created using Eq. (13) by computing the gradient of the enhanced feature image Ie
                           . The gradient of Ie
                            is taken to capture the intensity difference created between the inner and outer region of the ROI.
                              
                                 (13)
                                 
                                    
                                       
                                          
                                             
                                                f
                                                =
                                                ∇
                                                
                                                   I
                                                   e
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   p
                                                   ,
                                                   q
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where f is the feature map representing the enhanced boundaries of the ROI. The feature map is shown in Fig. 6
                           .


                           Fig. 7
                           (b) and (d) shows the enhanced feature map for CT images having irregular shaped ROIs (shown by arrows in Fig. 7(a) and (c)). It is evident from Fig. 7 that proposed method able to create enhanced feature image (Fig. 7(b) and (d)) of irregular shaped ROIs with impeccable accuracy.

The feature map created using (13) is now multiplied with the non-feature original CT image to create the final image using Eq. (14). By combining the non-feature image with the feature map, the boundaries of desired ROI are now enhanced, which otherwise are not enhanced (weak boundaries and low in contrast).
                              
                                 (14)
                                 
                                    
                                       
                                          
                                             
                                                J
                                                (
                                                x
                                                ,
                                                y
                                                )
                                                =
                                                I
                                                (
                                                x
                                                ,
                                                y
                                                )
                                                ×
                                                
                                                f
                                             
                                          
                                       
                                    
                                 
                              
                           
                           J(x,
                           y) is final image, and I(x,
                           y) is the non-feature input image.

As a last step of region enhancement, a new stopping function is created using Eqs. (15) and (16) from final image J(x,
                           y) for terminating the contour at the desired boundary. It should be noted that the stopping function now uses modified gradient information.
                              
                                 (15)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   g
                                                   m
                                                
                                                =
                                                
                                                   1
                                                   
                                                      1
                                                      +
                                                      
                                                         
                                                            
                                                               |
                                                               ∇
                                                               G
                                                               ⊗
                                                               J
                                                               (
                                                               x
                                                               ,
                                                               y
                                                               )
                                                               |
                                                            
                                                         
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (16)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   g
                                                   m
                                                
                                                =
                                                
                                                   1
                                                   
                                                      1
                                                      +
                                                      
                                                         
                                                            
                                                               |
                                                               ∇
                                                               G
                                                               ⊗
                                                               (
                                                               I
                                                               (
                                                               x
                                                               ,
                                                               y
                                                               )
                                                               ×
                                                               
                                                               f
                                                               )
                                                               |
                                                            
                                                         
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           gm
                            is the new stopping function, G the Gaussian kernel and ⊗ a convolution operator and value of σ
                           =0.8.

As the last stage of the proposed method, edge-based DRLSE is applied to the final image J(x,
                        y) with the new stopping function created by the proposed method to terminate the contour at the desired edges using Eq. (17) 
                        [23]:
                           
                              (17)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∂
                                                   ϕ
                                                
                                                
                                                   ∂
                                                   t
                                                
                                             
                                             
                                                =
                                                μ
                                                div
                                                (
                                             
                                             
                                                d
                                                p
                                             
                                             
                                                (
                                                |
                                                ∇
                                                ϕ
                                                |
                                                )
                                                ∇
                                                ϕ
                                                )
                                             
                                             +
                                             λ
                                             
                                                δ
                                                
                                                   ɛ
                                                
                                             
                                             
                                                (
                                                ϕ
                                                )
                                             
                                             div
                                             
                                                (
                                                
                                                   g
                                                   m
                                                
                                                
                                                   
                                                      ∇
                                                      ϕ
                                                   
                                                   
                                                      |
                                                      ∇
                                                      ϕ
                                                      |
                                                   
                                                
                                                )
                                             
                                             +
                                             α
                                             
                                                g
                                                m
                                             
                                             
                                                δ
                                                
                                                   ɛ
                                                
                                             
                                             
                                                (
                                                ϕ
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where the first term is a distance regularised term; the second and third terms are energy terms; gm
                         is the new stopping function.


                        Fig. 8
                         demonstrates the implementation of the proposed method of image segmentation and comprises three stages, i.e., region separation, region enhancement and applying edge-based DRLSE with the new stopping function. The original CT image of the abdomen with the liver cancer having low contrast and weak boundaries is shown in Fig. 8(a). A manually demarcated ROI created by a group of specialists in which there is cancerous region is shown in Fig. 8(b). The phase map and edge map created by region separation are shown in Fig. 8(c) and (d). As shown in Fig. 8(c) the phase map is created where infected ROI (shown by arrow) is separated from the surrounding tissues. The edge map thus created is shown in Fig. 8(d). The feature map is constructed using region enhancement as shown in Fig. 8(e). It is quite clear from Fig. 8(e) that the features of the desired ROI at the periphery are enhanced but otherwise are quite vague in the original image, i.e., Fig. 8(a). The final image thus obtained after combining the feature map with the original image is shown in Fig. 8(f). Using this final image, a new stopping function is created. Finally, the edge-based distance regularised level set method is applied using this new stopping function as the last stage of the proposed method. The segmented image thus obtained after applying DRLSE with the new stopping function is shown in Fig. 8(g), and the final segmented ROI is shown in Fig. 8(h). It should be noted that the edge map is not considered as the final segmented output because the boundaries of the edge map ROI are broken and not unified in nature. In other words, if the boundaries of the edge map ROI are broken, it may merge with similar surroundings outside the ROI, which will result in the output of the ROI along with similar unwanted region outside the ROI (Fig. 5(b)). This provides a wrongly segmented ROI. In Fig. 5(b), the unwanted region (encircled) is merged with the ROI. The boundaries must be delineated to ensure unified output. This is accomplished using region enhancement. When creating the feature map by enhancing the features at the boundaries of the separated ROI using region enhancement, there is also a possibility of enhancement of false boundaries (Fig. 9
                        (c)). These false boundaries always exist outside the ROI, as shown in Fig. 9(c). The arrow in Fig. 9(c) indicates the false boundaries. These false boundaries will give rise to some unwanted regions as a part of the final segmented output. This can be avoided by using level sets with new modified stopping functions. By initialising the contour within the desired ROI only, all false regions are ignored. Similarly, problem mentioned in Fig. 5, where there are two regions of same background can also be solved by initializing active contour within desired ROI, thereby rejecting all other similar unwanted ROIs. For example in Fig. 5, if contour is initialized within desired ROI marked as 1, output only consist of desired ROI as shown in Fig. 9(d), thereby rejecting unwanted ROI. The final segmented output after the level sets is shown in Fig. 9(d). This final segmented output does not contain any false regions with similar background.

In this section, the results obtained after implementing three methods of image segmentation on 2D and 3D data sets of CT scans: (i) edge-based DRLSE, (ii) region-based SBGFRLS and (iii) the proposed method are provided and discussed. Data set consist of CT images of abdomen. These CT images were acquired from research and scanning centre, Punjab, India. CT images were acquired using SIEMENS six slice abdomen scanner having 40 slices per patient with slice width of 5mm. This work is implemented using Matlab 7.11.0 (R2010b).

The size of the images is 512×512. The results are presented in the form of comparative visual and quantitative analysis. To evaluate all these three methods and to prove the superiority of the proposed method, the experiments were performed on 20 two dimensional and 4 three dimensional CT images of the abdomen with a region of liver cancer that had been manually delineated by a group of specialists. For visual comparison, the results of only 5 CT images are shown, but for the objective evaluation, the results of all 20 images are taken into consideration. In order to analyse inter and intra observer variabilities the protocol mentioned in [26] is followed. The data set was manually segmented by two independent radiologists. Each radiologist segments each CT image five times. Thus, total of 200 manually segmented ROIs were available for inter and intra observer variabilities (manual segmentation) [26]. The intra-observer values are the mean values of Dice Similarity Coefficient (DSC) after comparing all manual segmentations of each specialist. The inter-observer values are the mean values of DSC of the comparisons performed by different specialist [26]. The results of inter and intra observability of five images are shown in Table 1
                     .

The results show that there is no significant difference between segmentations of different specialist and also no significant difference is found in segmentation of same specialist. On expected lines, intra-observer values come out to be greater than inter-observer values. The parameters for conventional DRLSE and SBGFRLS are selected strictly as mentioned in the respective literature [23,25] as follows: α ranges from −2.0 to −3.0, number of scales and orientations are 3 and 6, respectively, threshold parameter T varies with images, and Pth
                      ranges from 5 pixels to 30 pixels depending upon the threshold parameter and ROI. The controlling parameters like number of scales, orientations, α, T, Pth
                      and σ were adjusted for different experiments based on the nature of the CT image. The values of controlling parameters are selected in such a way so as to get the maximum accuracy. The effect of different parameters on the response of conventional DRLSE and SBGFRLS is shown is Fig. 10
                     . The desired ROI is shown in Fig. 10(a). The effect of variable α on the performance of DRLSE is shown in Fig. 10(b)–(g). As per [26], α is taken as negative to enable the contour to expand from inside the ROI to find the boundaries. Fig. 10(h)–(t) demonstrates the effect of α and σ on the performance of SBGFRLS. It is obvious from Fig. 10 that both methods, i.e., DRLSE and SBGFRLS, do not respond properly for the range of selected parameters. Both DRLSE and SBGFRLS either go beyond or are confined within the desired boundaries, leading to inaccurate image segmentation.

It is also imperative to assess the performance of proposed method on different initial conditions, especially location of initial contour and number of manually initialized contours. This is tested by initializing contours (black and white) at different locations as shown in Fig. 11
                     (a) and initializing more than one contours (four in number) shown in Fig. 12
                     (a). Figs. 11 and 12(b) and (c) show the proposed algorithm’s result. It is shown that final contours are very close to each other and proposed method able to produce same output even if contours are different in location and multiple in number. In order to quantitatively evaluate the effect of location and number of contours on final output, we compared the output of proposed method using multiple contours initialized at different locations with desired ROI. The DSC statistical metric is used to find the error between desired ROI and result of proposed method in case of using multiple contours initiated at different locations. The p-value is used to find the similarity of DSC values of desired ROIs and output of proposed method using multiple contours at different locations. The p-values are 0.9744 and 0.989 for contours initialized at different locations and for multiple contours respectively, which is greater than the prescribed value of p i.e., 0.05. This leads to the conclusion that there is no significant difference between the results produced by proposed method in case of multiple contours initialized at multiple locations.


                     Fig. 13
                      shows an illustrative comparison of the results of our proposed method with those of edge-based DRLSE and region-based SBGFRLS. The first row, Fig. 13(a), shows an original CT image with desired ROIs, which were marked manually by a group of specialists. The second row, Fig. 13(b), shows the results obtained after segmentation by the edge-based DRLSE method. For DRLSE, the parameter values are α
                     =−3.0, σ
                     =0.8 as the standard configuration for all slices used in the experiment shown in Fig. 13(b). The third row, Fig. 13(c) is the results obtained after segmentation by the region-based SBGFRLS method. The parameters used for SBGFRLS are α
                     =15, σ
                     =1.0 and Δ
                     =−5 and the fourth row, Fig. 13(d), are the results obtained after segmentation by our proposed method.

The controller parameters values used in proposed method for slices shown in Fig. 13(d) are α
                     =−2.0, σ
                     =0.8, Pth
                     
                     =5, number of scales and orientations are 5 and 2 respectively. But threshold values for Fig. 13(d) (images left to right) are 130, 80,140, 110 and 30 respectively.

In all three methods of segmentation used in this work, it is imperative that the contour should settle at the desired edges, i.e., manually marked boundary of the desired ROI as shown in Fig. 13(a). In other words, the segmented ROI must map with the desired ROI in terms of boundaries and area of spread. Visual analysis of the results in Fig. 13(b) shows that, after applying the DRLSE method, in all the CT images, the contour extends beyond the desired ROI instead of terminating at desired boundaries (desired ROI shown in Fig. 13(a)) as indicated by the white colour boundary. Thus, edge-based DRLSE, despite having the same experimental parameters as the proposed method (values of α is same for conventional DRLSE and proposed method), lacks the ability to identify boundaries because the stopping function used in this method does not reach zero value at weak boundaries, which leads to leakage of contour beyond the desired boundaries. The same problem is again prevalent in the results shown in Fig. 13(c), despite the fact that in the SBGFRLS method, a special pressure force is derived from the information inside and outside the contour to control evolution. Fig. 13(d) shows the results of our proposed method. The segmented ROIs in all the CT images obtained by our proposed method are much closer to the manually demarcated or desired ROI in comparison to the other two methods. Thus, in the proposed method, the final image, which is created by enhancing the features at boundaries, significantly improves the gradient information and ultimately creates a new stopping function that forces the contour to stop at the desired boundaries. This information is missing in the conventional edge-based DRLSE method and even the region-based SBGFRLS method. Thus, these two methods are not able to perform well in detecting the desired ROI in CT images of abdomens and liver cancer. Analysing the results shown in Fig. 13, the segmented ROI obtained using the proposed method does not exactly match the desired ROI, but it is very close and certainly better than the other two methods as applied to the detection of weak boundaries.

The performance of proposed method is evaluated by applying it on CT images having irregular, elongated shaped (Fig. 14
                     (a) and (e)) and non-homogenous intensity (Fig. 14(i)) ROIs. It is shown in Fig. 14(d), (h) and (l) the segmented ROIs using proposed method. These segmented ROIs are very close to manually segmented ROIs (Fig. 14(c), (g) and (k)). This validates the robustness of proposed method while handing ROIs with irregular shape and non homogenous intensity.

The comparative analysis of proposed method with edge based DRLSE and region based SBGFRLS is shown in Table 2
                     .

Segmentation is a tedious and very challenging task. The subjective visual evaluation of the results provides an indication of the fact that the segmentation method is able to locate the boundaries of desired ROI, but it inherently limits the depth of evaluation of segmentation method and fails to decipher the hidden dynamics of any segmentation method. In this regard, the objective performance measure plays a very crucial role in evaluating the performance of any segmentation method. Multiple metrics are necessary for evaluating any segmentation method. In this respect, four commonly used statistical parameters are (i) RI, (ii) VOI (iii), BDE, and (iv) GCE, have been calculated for further establishing the superiority of our proposed method. These methods are defined as follows:

The Rand Index is the measure of similarity [28] of data partitions using Eq. (18). One data set contains manually delineated ROIs (desired ROIs), and the second data set contains segmented ROIs.
                              
                                 
                                    
                                       R
                                       
                                          (
                                          W
                                          ,
                                          Z
                                          )
                                       
                                       =
                                       1
                                       −
                                       
                                          
                                             [
                                             
                                                1
                                                2
                                             
                                             
                                                (
                                                
                                                   ∑
                                                   u
                                                
                                                
                                                   n
                                                   
                                                      u
                                                      .
                                                   
                                                   2
                                                
                                                +
                                                
                                                   ∑
                                                   v
                                                
                                                
                                                   n
                                                   
                                                      v
                                                      .
                                                   
                                                   2
                                                
                                                )
                                             
                                             −
                                             
                                                ∑
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                             
                                             
                                                n
                                                
                                                   uv
                                                
                                                2
                                             
                                             ]
                                          
                                          
                                             B
                                             (
                                             B
                                             −
                                             1
                                             )
                                             /
                                             2
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (18)
                                 
                                    
                                       
                                          
                                             
                                                Where
                                                
                                                   n
                                                   
                                                      u
                                                      .
                                                   
                                                
                                                =
                                                
                                                   ∑
                                                   v
                                                
                                                
                                                   n
                                                   uv
                                                
                                                ,
                                                
                                                   n
                                                   
                                                      .
                                                      v
                                                   
                                                
                                                =
                                                
                                                   ∑
                                                   u
                                                
                                                
                                                   n
                                                   uv
                                                
                                                ,
                                                
                                                   ∑
                                                   u
                                                
                                                
                                                   n
                                                   
                                                      u
                                                      .
                                                   
                                                
                                                =
                                                
                                                   ∑
                                                   v
                                                
                                                
                                                   n
                                                   
                                                      .
                                                      v
                                                   
                                                
                                                =
                                                B
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Variation of information is the measure of information gain and loss when changing from one cluster to another [29] using Eq. (19)
                           
                              
                                 (19)
                                 
                                    
                                       
                                          
                                             
                                                VoI
                                                (
                                                W
                                                ;
                                                Z
                                                )
                                                =
                                                H
                                                (
                                                W
                                                )
                                                −
                                                2
                                                M
                                                (
                                                W
                                                ,
                                                Z
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           where H(W) is entropy. A lower VOI value indicates better segmentation.

The Boundary Displacement Error [29] measures the average displacement error of boundary pixels between two segmented images. The lower value of BDE indicates better segmentation.

Global consistency error is the measure of the extent to which one segmented region is a refinement of the other. GCE is calculated using Eq. (20) 
                           [29]:
                              
                                 (20)
                                 
                                    
                                       
                                          
                                             
                                                GCE
                                                
                                                   (
                                                   W
                                                   ,
                                                   Z
                                                   )
                                                
                                                =
                                                
                                                   1
                                                   B
                                                
                                                
                                                   min
                                                
                                                
                                                   {
                                                   
                                                      ∑
                                                      y
                                                   
                                                   LRE
                                                   
                                                      (
                                                      W
                                                      ,
                                                      Z
                                                      ,
                                                      
                                                         u
                                                         i
                                                      
                                                      )
                                                   
                                                   ,
                                                   
                                                      ∑
                                                      i
                                                   
                                                   LRE
                                                   
                                                      (
                                                      W
                                                      ,
                                                      Z
                                                      ,
                                                      
                                                         u
                                                         i
                                                      
                                                      )
                                                   
                                                   }
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where LRE is the local refinement error. LRE(W,
                           Z,
                           ui
                           )=
|C(W,ui
                           )â§¹C(Z,ui
                           )|/|C(W,ui
                           )|.

A higher Rand Index value indicates better segmentation.

A lower value of GCE indicates better segmentation. Fig. 15
                            provides the comparative performance analysis of three image segmentation methods using four evaluation parameters. The results indicate that the proposed method provides the overall best performance with the lowest values of VOI, BDE and GCE and highest RI score.

The box and whisker plots values for BDE, GCE and VOI metrics are shown in Fig. 15(a), (b) and (d), respectively. The values are skewed towards the lower values, indicating the superiority of the proposed method, whereas for RI in Fig. 15(c), the values for proposed method are higher, which again demonstrates the robustness of the proposed method. Therefore, these values indicate that the proposed method consistently performs better than edge-based DRLSE and region-based SBGFRLS with respect to visual and quantitative analysis. However, there are still many findings that remain to be explored regarding the application of our proposed method for detection of the boundaries and area of spread of liver cancer in abdomen CT images. Based on experimental results, our proposed method may prove to be useful in the clinical setting.

The performance of proposed method is also evaluated using 3D data set. Following volume based performance metrics are used for performance evaluation.

Volume of Error (VOE) is calculated using (21) 
                           [21]
                           
                              
                                 (21)
                                 
                                    
                                       
                                          
                                             
                                                VOE
                                                
                                                   (
                                                   %
                                                   )
                                                
                                                =
                                                
                                                   (
                                                   1
                                                   −
                                                   
                                                      
                                                         
                                                            V
                                                            S
                                                         
                                                         ∩
                                                         
                                                            V
                                                            D
                                                         
                                                      
                                                      
                                                         
                                                            V
                                                            S
                                                         
                                                         ∪
                                                         
                                                            V
                                                            D
                                                         
                                                      
                                                   
                                                   )
                                                
                                                ×
                                                
                                                100
                                             
                                          
                                       
                                    
                                 
                              
                           where VS
                            and VD
                            denote the volumes of segmentation using level sets and manually segmented desired ground truth. Lower VOE indicates better segmentation.

Average surface distance (ASD) is defined as the average of minimum distances of pixels lying on the surfaces of segmentation and desired ground truth. Lower value of ASD means better segmentation.

The box and whisker plots values for VOE and ASD metrics are shown in Fig. 16
                           (a) and (b) respectively. It is clearly evident that proposed method performs better than DRLSE and SBGFRLS in estimating liver abnormality like tumour in 3D data set.

@&#CONCLUSION@&#

The present paper places much emphasis on (i) algorithmic consideration of image segmentation methods, (ii) their methodological aspects related to image processing and (iii) their capabilities to detect low contrast, weak boundaries in CT images of abdomen having liver cancer. In this paper, an attempt has been made to propose a new method of image segmentation named edge based and phase congruent region enhancement method. The advantage of this method is the detection of desired ROIs having weak boundaries. The proposed method is based on creating a new gradient-based stopping function by enhancing the features at the periphery of the desired ROI. The gradient information is improved at the periphery of the ROI by enhancing features, thereby creating a new stopping function for level sets. The proposed method, when applied to numerous varieties of two dimensional and three dimensional CT images, was able to locate ROIs more accurately than the state-of-the-art DRLSE and SBGFRLS approaches. The performance of the proposed method was also evaluated using statistical indicators, i.e., BDE, GCE, VOI and RI. The quantitative comparison of results indicated that the proposed method provides more accurate idea of the desired boundaries. The results that are obtained using proposed method are not only desirable in basic studies related to medical image segmentation but may also be a pre-requisite for the wide spread utilisation of image segmentation methods in CT images in clinical settings, where simplicity and effectiveness are of prime importance. Further efforts are required to find the better method than conventional thresholding to create edge map, which in-turn improves the accuracy and reduces the manual intervention. It is intuitive that a segmented ROI is still not as good as a manual or desired ROI. Further investigations are needed to achieve impeccable similarity between segmented ROIs and manual ROIs.

@&#ACKNOWLEDGMENT@&#

We would like to thank team of doctors at Kapscan Imaging Centre, Jalandhar, Punjab, India for their help in this research work.

@&#REFERENCES@&#


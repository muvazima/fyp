@&#MAIN-TITLE@&#An empirical study based on semi-supervised hybrid self-organizing map for software fault prediction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We proposed a software fault detection model using semi-supervised hybrid self-organizing map (HySOM).


                        
                        
                           
                           The HySOM minimize the role of experts for identifying fault prone modules.


                        
                        
                           
                           The advantage of HySOM is the ability to predict the label of the modules in a semi-supervised manner.


                        
                        
                           
                           The experimental results show improvement in false negative rate and overall error rate in 80% and 60% with NASA data sets.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Artificial neural network

Clustering

Self-organizing maps

Semi-supervised

Software fault prediction

Threshold

@&#ABSTRACT@&#


               
               
                  Software testing is a crucial task during software development process with the potential to save time and budget by recognizing defects as early as possible and delivering a more defect-free product. To improve the testing process, fault prediction approaches identify parts of the system that are more defect prone. However, when the defect data or quality-based class labels are not identified or the company does not have similar or earlier versions of the software project, researchers cannot use supervised classification methods for defect detection. In order to detect defect proneness of modules in software projects with high accuracy and improve detection model generalization ability, we propose an automated software fault detection model using semi-supervised hybrid self-organizing map (HySOM). HySOM is a semi-supervised model based on self-organizing map and artificial neural network. The advantage of HySOM is the ability to predict the label of the modules in a semi-supervised manner using software measurement threshold values in the absence of quality data. In semi-supervised HySOM, the role of expert for identifying fault prone modules becomes less critical and more supportive. We have benchmarked the proposed model with eight industrial data sets from NASA and Turkish white-goods embedded controller software. The results show improvement in false negative rate and overall error rate in 80% and 60% of the cases respectively for NASA data sets. Moreover, we investigate the performance of the proposed model with other recent proposed methods. According to the results, our semi-supervised model can be used as an automated tool to guide testing effort by prioritizing the module’s defects improving the quality of software development and software testing in less time and budget.
               
            

@&#INTRODUCTION@&#

In today’s life, all work depends on software technologies. However, confidence about reliability of the software is considered as one of the crucial problems in software development as well as the software engineering process. In order to achieve the objectives of software quality assurance initiatives, software quality models and tools are used [1]. These quality models help project managers, developers, and testers to categorize the more defect prone program modules together. Thus, the inadequate resources assigned for any software quality inspection such as testing and reviewing software programs can be allocated to those affected program modules to achieve cost-effective resource utilization [2]. One of the software quality models is software fault prediction.
                        1
                        Fault prediction, fault detection, and defect detection can be used interchangeably throughout the paper.
                     
                     
                        1
                      Usually, software measurement data with defect (faulty/quality) data from previously developed release or similar project is needed [1] to build software fault prediction models, which is also known as supervised learning. Various statistical and machine learning algorithms such as genetic programming [3], decision trees [4], neural network [5], naïve Bayes [6], case-based reasoning [7], fuzzy logic [8] and artificial immune recognition system [9–11] are already used for software fault prediction based on the supervised learning process. Nevertheless, in software development practice, the availability of defect data is limited due to reasons such as high cost, lack of budget, time limitation, or even unavailability of experts [1,12,13]; therefore, in such cases, regular supervised techniques cannot be used for building software quality models.

To build software prediction models in the absence of defect data, unsupervised or semi-supervised approaches are used [1,13–20]. In unsupervised approaches, identifying faulty modules from non-faulty modules falls to software engineering experts [1,14,15,21,22]. In addition, labeling modules can also be done by using certain software measurement thresholds instead of software engineering experts [18,19,23]. On the other hand, semi-supervised approaches usually use small samples of software modules with known fault content which enhance the process of model training with modules for which the fault information is not available [16]. In semi-supervised approaches, sample labeled data are provided either by iterative semi-supervised techniques, or by software quality experts, or even data provided by the software company. In this paper, we proposed a semi-supervised fault detection model using hybrid self-organizing map clustering (HySOM) and artificial neural network classification with the help of available software measurement thresholds corresponding to certain module features extracted from the software program. The proposed method uses self-organizing maps (SOM) as the underlying clustering algorithm. After clustering process, neuron weights are labeled based on six available software measurement thresholds as faulty and non-faulty, which are then used as a sample data set to be trained with artificial neural network in order to perform the final prediction. The results have shown that the sample obtained from semi-supervised SOM clustering can exhibit relatively similar performance as the whole data set and can be used as a suitable labeled data set for further classification of unlabeled data set.

This work attempts to take advantage of artificial neural network (ANN) in training self-organizing maps (SOM) cluster weights, to amend the performance of the unsupervised fault prediction method. SOM is claimed to be able to cluster the multi-dimensional data on a smaller dimensional space. This type of artificial neural network model can provide two-dimensional map space from a multi-dimensional input space along with topology-preserving mapping [24]. Each neuron inside the SOM produces cluster areas based on approximation of data density connected to input vectors over iterations in unsupervised learning. According to [25], SOM shows more accuracy in classifying most of the objects to their cluster than other clustering algorithms such as k-means and expectation maximization (EM).

ANNs, on the other hand, is a good approach for modeling and detecting the relationship that may exist between software metrics and module labels. ANNs are able to investigate and learn the hidden knowledge inside input data while processing them. ANN is considered as a significant method in computational intelligence as it has solved many complex and nonlinear problems in the real world. Despite the popularity of ANNs, there are unfavourable choices due to lack of good performance in software quality and software fault prediction areas. In this study, we try to explore the possibility of using ANN for classification purpose to advance the generalization capability of SOM with the threshold during prediction by proposing a new hybrid model (HySOM) for predicting module labels from software measurement metrics using real industrial data.

The performance of HySOM with other methods has been investigated in related studies [19,23]. According to the results, classification of the modules by HySOM is better than other proposed models in most cases. To show the superiority of HySOM, model was also compared with three well-performed supervised learning approaches [26,27], which were naive Bayes, random forest, and artificial neural network.

Our proposed semi-supervised HySOM overcomes the problem of predicting fault prone modules in the absence of faulty data. The involvement of experts is more relaxed or provides more support now, and the performance compared with the unsupervised SOM is better in most of the data sets as shown in the experiment section. So far, SOM has not been used in this direction because of complexity of using it in semi-supervised ways. With this motivation, our model’s novelty is reflected by semi-supervised approach and proofs are provided according to the results. Furthermore, the knowledge learnt during semi-supervised approach yielded better classification of unlabeled modules as compared to both unsupervised clustering and supervised classification.

This paper is organized as follows: discussion on related work is presented in Section 2. The prerequisite tasks are described in Section 3. Section 4 presents the proposed semi-supervised hybrid model. Experimental description followed by experimental results is explored in Sections 5 and 6, respectively. Finally, the paper is summarized in Section 7.

@&#RELATED WORKS@&#

Different techniques have been used for software fault prediction [27–30]; however, many researchers were focused on supervised learning and only a few of them considered semi-supervised and unsupervised learning. Thus, in this section, we reviewed the selected studies on software fault prediction without prior quality-based class labels.

Zhong et al. [21,22] used clustering method with the expert-based approach to identify fault prone modules when quality data is absent. K-means and neural-gas algorithms are two clustering methods that were used in their experiments based on KC2 data sets from NASA. After clustering, an expert decided whether each cluster’s representative should be labeled as faulty or non-faulty based on some statistical data obtained from each cluster. Later, they repeated their experiments on another NASA data set with high population size namely JM1 [22]. Analyzed results of both studies affirmed that neural-gas performed slightly better for KC2 compared to JM1 than k-means in terms of overall error rate. Nevertheless, the proposed model is highly dependent on the availability of software engineering experts. In addition, the model cannot be automated, as it depends on experts for the prediction.

Seliya and Khoshgoftaar [1,32] proposed a semi-supervised learning model based on expectation maximization (EM). They considered the unlabeled modules as missing information and they used semi-supervised learning approach for solving the problem of completing the missing data. Their proposed model has outperformed the supervised learning method, which was based on C4.5. However, since C4.5 is not one of the best-performing classifiers in software fault prediction and software quality domain, their results were not sufficient as best practice for fault prediction [31].

Seliya and Khoshgoftaar [1,32] proposed a constraint-based semi-supervised clustering scheme. Here, clusters are iteratively labeled as faulty or not faulty with the help of software engineering expert’s domain knowledge in the absence of defect data. They investigated their proposed approach using six NASA data sets [33], which were JM1, CM1, KC1, KC2, PC1, and MW1. The software quality knowledge learned during the proposed semi-supervised clustering model using JM1 was then used to classify modules as fault prone and not fault prone in other remaining NASA data sets. They claimed that their approach could assist the expert in making more accurate prediction compared with unsupervised learning methods. Similar to their previous studies [21,22], they stated that half of the modules that remain unlabeled after their proposed approach, were probably noisy instances. According to these studies, large data set population increases the number of clusters as well as iterations. It also requires the experts to spend much more time labeling modules. Therefore, this model cannot be automated, as it depends on experts for the prediction.

Catal et al. [19] proposed the combination of clustering and metrics-thresholds to minimize the role of experts on deciding whether a module is faulty or non-faulty. They proposed two approaches namely one-stage and two-stage. In one-stage approach, no clustering methods were used, and they just compared selected module’s metrics against their corresponding threshold values whereas in two-stage approach, first k-means was used to cluster the data set and the metrics of each cluster representative was then compared with corresponding threshold values. If only one metric of the representative module exceeds the corresponding threshold vector, the selected cluster is considered as fault-prone. They stated that according to the obtained results, their approaches were effective. However, selecting the number of clusters in two-stage approach is more challenging than the one-stage approach. Later, Catal et al. [20] proposed another prediction model based on x-means clustering to overcome the problem of automatically identifying number of clusters. In their model, the mean vector of each cluster was compared with the corresponding metrics threshold vector. A fault-prone module is one that has at least one metric of the mean vector higher than the threshold vector for specific metrics. They used the same Turkish data sets for the experimental studies along with the same three performance metrics as their previous study [19], which were overall error rate, false positive rate and false negative rate. Although they came up with an automatic tool for predicting fault prone modules in the absence of defected data, the prediction accuracy is not validated.

Bishnu and Bhattacherjee [23] applied quad tree-based k-means (QDK) algorithm for identifying fault prone modules. They first wanted to find the initial cluster centres by applying quad trees as an input to the k-means, and prediction is then performed based on the quad tree-based algorithm. The dimension and metrics thresholds they used for data sets were the same as Catal et al. [19]. They evaluated their model by applying it on three data sets from Turkish white-goods manufacturer developing embedded controller software, with three performance metrics, which was overall error rate, false positive rate and false negative rate. They compared their model with the only existing study [19] as well as two supervised algorithm, which were naive Bayes and linear discriminate algorithm. According to their study, the clusters obtained by this algorithm have maximum gain values and are comparable with k-means algorithm. Further, they stated that the QDK model could be compared with other supervised learning methods such as naive Bayes and linear discriminate. QDK also performed better than one-stage and two-stage model proposed by Catal et al. [20] for all data sets. Although QDK performs better than Catal et al. [19] model, it has three limitations. First, this model depends on users in deciding the number of clusters. Second, QDK identifies K initial cluster centres, and simplified by changing the threshold values, which is also another factor showing user dependence on the model. Third, the model cannot be used as an automated tool because of the two problems mentioned. Finally, although the QDK outperformed the model by Catal et al. [20] and can be compared with other supervised models, its accuracy still needs to be improved.

Abaei et al. [21,22] proposed a prediction model by utilizing the self-organizing map (SOM) with the threshold to build a better prediction model when data is unlabeled. In this study, self-organizing map is used instead of k-means due to several drawbacks such as the problem of local minima and sensitivity to noisy data. The dimension and metrics thresholds they used for data sets were similar to Catal et al. [19] and Bishnu and Bhattacherjee. [23]. They evaluated their model by applying it on AR3, AR4, and AR5 from Turkish data sets with overall error rate, false positive rate, and false negative rate as performance evaluation metrics. They compared their model with Catal et al. [19] and Bishnu and Bhattacherjee [23]. The proposed model cannot be generalized to bigger data sets, as the performance was investigated based on three small data sets.

Based on the problems mentioned above, we proposed a semi-supervised hybrid prediction model in the absence of faulty data that does not rely strictly on the assistance of experts. Our proposed model outperformed other existing models on the same data set in many cases, and its performance is comparable with well-performed supervised algorithms.

According to Marinescu [34], there are three major approaches to determine the metrics threshold values. The first approach is based on experience and empirical studies that have been performed in the literature. Tuning machine is the second approach that uses the repository of the problematic items such as faulty modules and then chooses the threshold value based on the possibility of increasing the number of correctly predicted items. Finally, the last method examines various versions of the software program; this method does not parameterize an approach with multiple threshold values, but an important time standpoint is added to any suspicious entity.

We began this study by introducing method-level metrics thresholds values, that were determined from Predictive tool developed by Integrated Software Metrics, Inc. (ISM) for software fault prediction [35,36]. According to Menzies et al., method-level metrics are useful for software fault prediction [6] and knowledge about these metrics’ threshold are gained from both literature [37] and predictive tool’s documentation [35,36]. The dimensions and metrics used in our experiments are the same as [19,23] and are presented in Table 1
                        .

The concept of SOM was first introduced by Kohonen [39] in 1982. SOM is used for clustering data without knowing the class memberships of the input data. SOM provides a topology preserving mapping from the high dimensional space to map units and preserves the relative distance between the points, i.e., points that are near each other in the input space are grouped to nearby map units in the SOM output space, and vice versa [40]. In order to preserve properties of topological input space, this model uses a neighborhood function [41]. SOM has p input units as training vectors where each of the input vectors can have n features {xp
                        
                        ,1, xp
                        
                        ,2, ..., xp
                        
                        ,
                        
                           n
                        }. SOM output is a vector (y) with length of m that indicates the number of clusters {y
                        1, y
                        2, ..., ym
                        }. n and m can be equal or different. Weight vectors belonging to each output vector have the same dimensionality as input vectors. Any of the p vectors in the training data set is grouped in one of the m clusters. Each input unit p is connected to all output neurons through weights. In each iteration, the algorithm computes the distance of the random selected input nodes from the weight vector associated with each output node using the Euclidian distance formula. Every node is examined to calculate which node’s weights are most like the input vector. The output vector with minimum distance from the last step is selected, which is considered as a winning node commonly referred to as BMU (Best Matching Unit). After identifying the BMU, the winner node weight and nearby nodes are updated. Cells or neurons in map units identify similar groups of input data; therefore, since the similar software modules that have similar acts are grouped together, when the defect is found in one program module, other modules in the same group can be identified and debugged before failure occurs [42].

The SOM clustering process stops either by specifying the number of epoch before starting or when there is no significant amount of changes observed in the neuron’s weights. The SOM grid may have different topology, number of rows, and columns (neurons). For example, Fig. 1
                         presents a SOM structure with 3 rows and 5 columns.

Distances between each of the input vectors and all output neurons are computed using any of the Minkowski distance [43] formula (see Eq. (1)). The mentioned formula is recognized as Hamming and Euclidean distances by replacing p with values 1 and 2, respectively.
                           
                              (1)
                              
                                 
                                    
                                       ∀
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                                 ,
                                 distance
                                 (
                                 a
                                 ,
                                 b
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      t
                                                      =
                                                      1
                                                   
                                                   
                                                      n
                                                   
                                                
                                             
                                             |
                                             
                                                
                                                   a
                                                
                                                
                                                   t
                                                
                                             
                                             -
                                             
                                                
                                                   b
                                                
                                                
                                                   t
                                                
                                             
                                             
                                                
                                                   |
                                                
                                                
                                                   p
                                                
                                             
                                          
                                       
                                    
                                    
                                       1
                                       /
                                       p
                                    
                                 
                              
                           
                        
                     

In SOM calculation, a and b are replaced by input vector xi
                         and weighted vector wj
                         associated with each output node, respectively (refer to Eq. (2)).

Note that an initial weight is assigned to all connections as Wj
                         (0). There are two general initialization methods: random initialization and data analysis based initialization classes [44]. We used the random initialization, as it is easy to implement. Furthermore, Akinduko and Mirkes [45], performed an empirical study and compared the performance of SOM based on random initialization and principal component analysis initialization which is considered as one of the data analysis based initialization classes and observed that random initialization performed quite well for non-linear data sets.

After finding the winning neuron that is the nearest output vector to the input data xi
                        , weights are updated using Eq. (3). As mentioned earlier and shown in Eq. (2), weight vector belonging to each output’s vector have the same dimensionality (k) as input vector. Iterations are presented by t in the following equations.
                           
                              (2)
                              
                                 
                                    
                                       ∀
                                    
                                    
                                       i
                                       ,
                                       j
                                    
                                 
                                 ,
                                 
                                 dist
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          n
                                       
                                    
                                 
                                 
                                    
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             ik
                                          
                                       
                                       -
                                       
                                          
                                             w
                                          
                                          
                                             jk
                                          
                                       
                                       (
                                       t
                                       )
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 +
                                 1
                                 )
                                 =
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 +
                                 L
                                 (
                                 t
                                 )
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 )
                              
                           
                        where L is a small value which is called learning rate and which decreases over time (iterations). L is calculated using Eq. (4). L
                        0 is a learning rate at t
                        0 and 
                           
                              λ
                           
                         is a time constant.
                           
                              (4)
                              
                                 L
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       L
                                    
                                    
                                       0
                                    
                                 
                                 exp
                                 
                                    
                                       
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                λ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The learning rate decreases over time (iterations), and the effect of learning should be proportional to the distance of an output node from the BMU. Thus, Eq. (3) is converted to Eq. (5).
                           
                              (5)
                              
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 +
                                 1
                                 )
                                 =
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 +
                                 Φ
                                 (
                                 t
                                 )
                                 L
                                 (
                                 t
                                 )
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       w
                                    
                                    
                                       j
                                    
                                 
                                 (
                                 t
                                 )
                                 )
                              
                           
                        
                     

The winning neuron has influence on its neighbors. This influence is computed via neighbor function that is 
                           
                              Φ
                              (
                              t
                              )
                           
                        . 
                           
                              Φ
                              (
                              t
                              )
                           
                         is computed by Eq. (6)
                        
                           
                              (6)
                              
                                 Φ
                                 (
                                 t
                                 )
                                 =
                                 exp
                                 
                                    
                                       
                                          -
                                          
                                             
                                                
                                                   
                                                      dist
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                             
                                                2
                                                
                                                   
                                                      α
                                                   
                                                   
                                                      2
                                                   
                                                
                                                (
                                                t
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where dist is a distance of any output node from the BMU and width of neighborhood area is shown by α. The area of the neighborhood decreases over time (iterations) using exponential decay function. The width of the lattice at t
                        0 is presented by α
                        0 and 
                           
                              λ
                           
                         is a time constant and based on the iterations.
                           
                              (7)
                              
                                 α
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       α
                                    
                                    
                                       0
                                    
                                 
                                 exp
                                 
                                    
                                       
                                          -
                                          
                                             
                                                t
                                             
                                             
                                                λ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

In order to clarify why we used SOM clustering instead of k-means technique, a comparison table is given in Table 2
                         as follows.

An artificial neural network (ANN) is a collection of computational elements and connections that are weighted. The network keeps searching for the vector of connection weights, which could minimize the error in the training process. Each time the network runs through all training data set is called an epoch. Each instance is prepared as two vectors, input vector and output vector. One epoch is considered to be completed only when the neural network runs the entire set of instances. Thus, the neural network establishes mapping mechanism between inputs and outputs and is expected to work accurately when new set of data are fed as inputs. Changing the number of neurons in the hidden layers along with varying learning rate is a technique leading to best network structure.

Two main factors that show the superiority of the neural network in terms of computation ability are: its parallel-distributed structure and its potential to extrapolate the learned information to get desired outputs from the inputs, not seen during training stage. Data mining, pattern recognition, and function approximation are examples employed by neural networks [48]. Local minimum is a major problem that occurs during the training of the network. One solution to solve this problem is re-training the network with a distinct set of initial weights [49]. The graphical schema of the neural network is given in Fig. 2
                        , where n is the total number of clusters obtained after SOM clustering. Each one of these clusters (Wj
                        ) has the representative weights that consist of six features (Wj
                        
                        1, Wj
                        
                        2, ..., Wj
                        
                        6). Note that w (in small letter) refers to synoptic weights, which are needed for neural network training, and W (in capital letter) refers to representative weights belonging to each cluster after SOM clustering process.

In order to simplify the proposed model, all steps are illustrated in Fig. 3
                        , in three different phases. Phase 1 shows the steps during SOM clustering and phase 2 demonstrates how neurons not winning during competing for input vectors are removed from the SOM map. Finally, in phase 3, the steps related to label the weights based on the software measurement thresholds are explained. Outputs from phase 3 are fed to ANN for the training process.

In phase 1, SOM clustering is performed as explained in Section 3.2. In phase 2, we calculate the possibility of winning for each neuron and call it the number of hits (NOH) based on algorithm 1 presented in Fig. 4
                        . Some of the trained neurons are considered dead because of the fact that the NOH is zero or less than the threshold. In other words, dead neurons are the output vectors (clusters) that are never activated and no input vector is mapped to them. Therefore, we eliminate the dead neurons for achieving better error rate and accuracy. In this paper, we used zero as a threshold value to identify and remove dead neuron to obtain final weights. Dead neurons help their neighbors perform better in training process; however, they are no longer needed when the training task is finished. Note that, in Fig. 4, wj
                         is shown as wj
                        
                        ,
                        
                           i
                         to emphasize that the dimension of each of these output neurons is the same as input neurons, in order to compute the distance between input vectors and output neurons in SOM map.


                        Neuron is the term that is used to represent each output vector after clustering resulted from phase 1, and it has two components. Neuron.NOH denotes the number of input vectors that are grouped in to a certain cluster (output vector). For example, Neuron.NOH (1)=10 means, 10 input vectors are clustered in output neuron 1 or Neuron.NOH (10)=0 means, no input vector is clustered in output neuron 2. Moreover, Neuron.Weight stores the final weights (W) corresponding to each output vector if the corresponding NOH is more than zero and that specific neuron is not considered as the dead neuron. For example, W(1) contains the weight values belonging to output vector or cluster 1, and if it remains after the dead neuron elimination process, it shows that, there are some input vectors mapped to this cluster, and the NOH value for this cluster or output vector is 1.

In phase 3, we applied the software measurement threshold values on the final weights (W) obtained from phase 2 instead of applying them on raw input vectors. This is because geometrically, the weight vectors of the modified neurons tend to be as similar as input pattern and as a result, input pattern and the weight vectors are getting closer to each other. According to phase 3, a neuron weight is considered fault prone if three or more metrics of the representative neuron weight were higher than the specified threshold value of that metric. We selected three as the threshold level as a decision factor about a module’s faultiness because we have done many trial-and-error experiments based on different selection of threshold values ranging from one to five and based on the results, three delivered the best performance. The output from phase 3 would be a set of labeled weights that are used as a sample data set for the semi-supervised learning and to be trained with ANN.

The proposed hybrid model has two sections, which are SOM and ANN. Input data is divided into training and testing sets using the stratify method [50]. A stratified sampling technique guarantees that the same pattern as the original data is used. The training set (66%) is used to build the model (internal validation) while the testing set (33%) is used to evaluate the predictive capability of the model (external validation or cross validation criterion). The module’s labels are deleted, and the training set is passed to the SOM. The capability of SOM has been shown in several works such as in [41,46] and this has been confirmed in this work as well.

As the neuron’s weight vectors are moving toward the input pattern, they become more similar to each other, which is why we applied the threshold on the final weights obtained from clustering phase instead of applying them on raw input vectors. After the modules are clustered, and the representative weights are labeled based on the threshold’s values, the new generated labeled data set is given to the ANN as a representative of the inputs to be trained. Fig. 5
                         shows the steps during the training stage of the proposed hybrid HySOM system. Phases 1 through 3, which are shown in Fig. 4, are marked in Fig. 5 for more readability.

Suppose we are given a set of input–output data pairs as illustrated in Eq. (8).
                           
                              (8)
                              
                                 S
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                x
                                             
                                             
                                                ij
                                             
                                          
                                          |
                                          x
                                          ∈
                                          X
                                          ,
                                          
                                          i
                                          =
                                          1
                                          
                                          to
                                          
                                          n
                                          ,
                                          
                                          j
                                          =
                                          1
                                          
                                          to
                                          
                                          m
                                          ,
                                          
                                          
                                             
                                                x
                                             
                                             
                                                im
                                             
                                          
                                          =
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where xij
                         denotes ith data object that could have jth features (measurements metrics), and yi
                         is a class label corresponding to the ith data object which is either zero or one.

In order to run our experiment, we first remove the class labels corresponding to each input data xij
                        , so S(x)=
                        S(x)−
                        y. Then, we divide the input data into training S(xtrain
                        ) and testing sets S(xtest
                        ) using the stratify sampling approach [50] where S(xtrain
                        )∩
                        S(xtest
                        )=∅. In this step, the available data is passed to SOM system for clustering as the first component of the hybrid scheme. The weight vectors of the adapted neurons in each cluster are moved and updated gradually toward the input pattern using Eq. (4) or Eq. (6). Possibility of winning for each neuron is computed and stored as NOH using Algorithm 1 and dead neurons that are less than the threshold are removed as shown in Fig. 3. Based on the metrics thresholds, final weights are labeled. The outputs from this step, which are the labeled weights from SOM clustering process W(d), are then passed to the ANN for classification. Note that d refers to the output neuron (cluster number), for example, W(1) refers to output neuron or cluster 1.

Let us consider 
                           
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    
                                       
                                          y
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                         as actual and predicted ANN outputs respectively. In order to accept or reject the ANN model, error has been calculated using Eq. (9) for each fold cross validations. If 
                           
                              Error
                              
                                 
                                    
                                       y
                                       ,
                                       
                                          
                                             y
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                 
                              
                           
                        
                        <ɛ , the model is accepted and the final HySOM is being tested using unseen data (S(xtest
                        )).
                           
                              (9)
                              
                                 Error
                                 
                                    
                                       
                                          y
                                          ,
                                          
                                             
                                                y
                                             
                                             
                                                ˆ
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             (
                                             
                                                
                                                   y
                                                
                                                
                                                   i
                                                
                                             
                                             -
                                             
                                                
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         ˆ
                                                      
                                                   
                                                
                                                
                                                   i
                                                
                                             
                                             )
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                     

After building the prediction model, any module from the test data set is labeled based on the developed HySOM model and fault prone modules can be identified and reported to the project managers, developers, and testers to help them focus their attention and allocate the resources on those modules that are already predicted as fault prone.

In total, eight data sets are used for investigating the performance of the proposed method. In the first experiment, three data sets namely AR3, AR4, and AR5 [51] from a Turkish white-goods manufacturer developing embedded controller software are used. They are all coded in C programming language. AR3 has 63 modules and 13% of it is faulty; AR4 is a larger data set with 107 rows and 19% faulty modules. AR5 is a smallest data set with only 36 modules and 22% of them are faulty. From now on, we refer to these set of data sets as Turkish set.

In this study, five data sets from the repository of NASA [51] are also selected to show the performance of the proposed model through larger data sets as well. The CM1 was written in C code and has 498 modules with 10% fault prone modules; this data belongs to the project related to spacecraft instrument. The second data set, PC1 is flight software for earth orbiting satellite, which is also written in C language; it has 1109 numbers of rows and 7% of the data are defected. Third data set is KC1 with 2107 models, written in C++ code and 15% of it is defected with one or more faults. KC1 belongs to storage management project, which received and processed ground data. KC2 is the software that controls the process of receiving and delivering ground data. It contains 522 modules, of which 20% of them are defected. KC2 was coded in C++. Finally, the fifth data set is MW1, which is the software application from zero-gravity-combustion experiment. It is written in C code, and it contains 403 modules. 8% of the data is faulty. For the sake of simplicity, we refer to these data sets as NASA sets.

A total of 29 and 21 software measurement metrics are available for Turkish and NASA set, respectively; however, only six of them have been selected for modeling as only their threshold values were available.

In order to evaluate the proposed model, we used three different evaluation metrics. As shown in Table 3
                        , the confusion matrix has been calculated after specifying each module’s label after training and testing phase.

If a module’s label is predicted as non-faulty but the actual label is faulty, we get the condition of false negative (FN). In contrast, if the non-faulty module is labeled as faulty, it is called false positive (FP). If the faulty module is predicted as faulty and non-faulty module is predicted as non-faulty, we have the condition of true positive (TP) and true negative (TN), respectively. FNR (false negative rate) is the percentage of modules that are actually faulty but predicted as non-faulty. In contrast, FPR (false positive rate) is the percentage of modules that are actually non-faulty but predicted as faulty. FNR, FPR and errors need to be as small as possible in all the experiments. The following equations are used to calculate FNR, FPR, and overall error rate.
                           
                              (10)
                              
                                 Overall
                                 
                                 Error
                                 
                                 Rate
                                 =
                                 
                                    
                                       FN
                                       +
                                       FP
                                    
                                    
                                       TP
                                       +
                                       FN
                                       +
                                       FP
                                       +
                                       TN
                                    
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 FPR
                                 =
                                 
                                    
                                       FP
                                    
                                    
                                       FP
                                       +
                                       TN
                                    
                                 
                              
                           
                        
                        
                           
                              (12)
                              
                                 FNR
                                 =
                                 
                                    
                                       FN
                                    
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                     

Deciding on the number of clusters is an important decision. In this paper, selecting SOM size should also be done such that the best number of clusters is assigned for clustering process. Some researchers such as Vesanto [52] used Eq. (13), where n is the product of row (number of inputs) and columns (number of features). In fact, the optimal size of the SOM minimizes the chance of creating SOM map with too many empty cells (we referred to them as dead neurons) after clustering process; this size could be varied between 64 and 1024 cells [53].
                           
                              (13)
                              
                                 SOMsize
                                 =
                                 5
                                 ×
                                 
                                    
                                       n
                                    
                                 
                              
                           
                        
                     

In this paper, we analyzed and observed the relationship between the number of rows, columns (features), SOM size, and final classification outputs. Based on different analysis and large numerical calculation on data sets, we concluded that the SOM size can be computed using Eq. (14).
                           
                              (14)
                              
                                 SOMsize
                                 =
                                 
                                    
                                       
                                          
                                             Round
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        n
                                                                     
                                                                     
                                                                        row
                                                                     
                                                                  
                                                                  ∗
                                                                  
                                                                     
                                                                        n
                                                                     
                                                                     
                                                                        col
                                                                     
                                                                  
                                                               
                                                               
                                                                  5
                                                                  ∗
                                                                  (
                                                                  
                                                                     
                                                                        n
                                                                     
                                                                     
                                                                        col
                                                                     
                                                                  
                                                                  -
                                                                  1
                                                                  )
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                     

For example, if the total number of rows and columns are 63 and 6, respectively, for AR3, SOM size will be calculated as follows:
                           
                              
                                 SOMsize
                                 =
                                 
                                    
                                       
                                          
                                             Round
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  63
                                                                  ∗
                                                                  6
                                                               
                                                               
                                                                  5
                                                                  ∗
                                                                  (
                                                                  6
                                                                  -
                                                                  1
                                                                  )
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             Round
                                             
                                                
                                                   
                                                      
                                                         
                                                            15.12
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       (
                                       Round
                                       (
                                       3.89
                                       )
                                       )
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 4
                                 ∗
                                 4
                              
                           
                        
                     

The SOM-map size calculated for each data set based on Eq. (14) is presented in Table 4
                        .

Two sets of experiment have been performed based on the type of data set. The first experiment investigated the performance of the proposed HySOM model employing Turkish set and the second experiment was conducted on NASA set. Table 5
                      presents the prediction error analysis on Turkish set for the semi-supervised HySOM approach as compared with other approaches, namely, unsupervised standalone SOM approach (SSOM) [21,22], unsupervised two-stage approach (CT) [19], unsupervised one-stage approach (CO) [19], unsupervised quad tree-based k-means approach (QDK) [23], unsupervised two-stage x-mean approach (CX) [20], supervised naive Bayes (NB), supervised random forest (RF), and supervised artificial neural network (ANN).

The FNR values for HySOM model are better than SSOM, QDK, CO, CT, and CX for AR3 and AR5 data sets, the same as CO and CT and better than QDK for AR4. The FPR values for HySOM are better than QDK, CO, CT, and CX for AR3 and better than CO, CT, and CX for AR4 and AR5. The HySOM error rates are also better than QDK, CO, CT, and CX for AR3, and better than CO, CT for AR4, and almost same as CX for AR5. The HySOM error rate performances are close to QDK error rate for AR4 and AR5. As can be seen in Table 4, SSOM outperformed HySOM in terms of FPR and overall error rate for AR3 and AR4. Moreover, considering all data sets, our approach is comparable with supervised learning NB, RF, and ANN. In addition, HySOM outperformed other supervised methods in terms of FNR. The overall error rate for AR3 is also best (0.1481) for HySOM compared with ANN (0.1851). On the other hand, the overall error rate for AR4 is also best (0.1250) for HySOM compared with NB (0.1495), RF (0.1682), and ANN (0.1354). The HySOM overall error for AR5 is 0.1667 that is better than RF and ANN.

To show the performance comparison among all models in an easier and visual manner, differences between computed error values (FPR, FNR, and overall error rate) resulted from HySOM model and any other presented models are calculated and presented in Tables 6-8
                     
                     
                     , and Figs. 6-8
                     
                     
                      for each of the Turkish data set. A positive number means that the corresponding error value belonging to HySOM is worse compared with other selected methods, and a negative number indicates the opposite. According to the tables and figures, it was observed that HySOM has performed best in 20 and 18 out of 24 cases for FNR and overall error rate, respectively. However, it only outperformed 10 cases in terms of FPR.

In order to investigate whether semi-supervised HySOM can outperform other models specially unsupervised SSOM using bigger data sets, we analyzed the model performance on NASA set as well. Unfortunately, we did not have access to the details of the model proposed by Bishnu and Bhattacherjee [23] to observe the performance on NASA data; however, we carefully followed all steps reported in paper [19,21,22] to reconstruct their model and tested it on NASA data set as well. We compared the semi-supervised HySOM results with other approaches, namely, unsupervised standalone SOM approach (SSOM) [21,22], unsupervised two-stage approach (CT) [19], unsupervised one-stage approach (CO) [19], supervised naive Bayes (NB), supervised random forest (RF), and supervised artificial neural network (ANN).

According to the results presented in Table 9
                     , the FNR values for HySOM model are better than SSOM, CO and CT for KC2 and MW1 data sets, and are better than CO for CM1 and PC1. The FPR values for HySOM are better than SSOM for all data sets and better than CO and CT for CM1, KC1, and MW1, and better than CT for PC1. The HySOM error rates are also better than SSOM for all data sets and better than CO and CT for CM1, MW1, and PC1 and near to CO and CT for KC2. All performance metrics are the best for HySOM for MW1. Furthermore, in all data sets, our approach is comparable with supervised learning NB and RF. According to the results, ANN did not perform accurately as it cannot predict any faulty modules.

Again to show the model performance in an easier and visual manner, differences between computed (FPR, FNR, and Overall error rate) values resulted from HySOM model and other presented models are calculated and presented in Tables 10–12
                     
                     
                     , and Figs. 9-11
                     
                     
                      for each of the NASA set. A positive number means that the corresponding error value belonging to HySOM is worse compared with other selected methods, and a negative number indicates the opposite. According to the tables and figures, it was observed that HySOM performed better in 24 and 18 out of 30 cases for FNR and overall error rate, respectively; however, it only outperformed 11 cases in terms of FPR.

According to the empirical study, HySOM could not perform better than SSOM for Turkish set; however, it outperformed SSOM in terms of FPR and overall error rate for all NASA sets. Based on the results, the reason why HySOM performs better on NASA sets is that, when the size of the data set is small, the size of the representative clusters that is needed for neural network training is not big enough. Therefore, it is not suitable to be used as a sample data as part of the semi-supervised approach; however, in big data sets the number of sample clusters which is representative of the inputs is relatively big enough and can depict the overall characteristics of the input data.

@&#CONCLUSION@&#

Software fault detection is one of the important software quality practices during software development and software testing. However, building detecting model with no prior faulty data from previous or similar projects is a very difficult task. This paper presented a semi-supervised hybrid approach to software fault prediction when the labels of data are not identified.

Semi-supervised HySOM, which is the appropriate combination of SOM and ANN, have been analyzed and developed as an alternative prediction solution for module labels in unlabeled data sets. Our method does not need historical data and can achieve improved prediction performance by learning from sampled modules obtained from SOM clustering and using software measurement threshold values. Furthermore, the strong need for software quality experts who are needed in unsupervised approaches is also reduced. Eight industrial data sets are used for the validation of the proposed model. The obtained results have established the superiority of the proposed HySOM model over the other proposed methods in most of the cases in terms of FNR and overall error rate for NASA set; however, it could not outperform SSOM in small data sets belonging to Turkish set. The overall error rate of HySOM is found to be comparable with other existing unsupervised algorithms as well as supervised learning approaches, naive Bayes, random forest, and artificial neural network for both NASA and Turkish Data set.

Since SOM map size can be identified with our proposed SOM-Size formula, HySOM method can be used as an automated tool which can enable project managers, software developers, and testers to concentrate more on those program modules that are identified as more defect prone especially when the project is behind schedule and over budget.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank Zahra Rezaei dan M. Reza Mashinchi from Software Engineering Research Group, Universiti Teknologi Malaysia (UTM) for providing some comments in improving the manuscript. Moreover, this work is supported by the Research Management Centre (RMC) at the Universiti Teknologi Malaysia under Research University Grant (Vot 01G72) and the Ministry of Science, Technology & Innovations Malaysia under Science Fund (Vot 4S062).

@&#REFERENCES@&#


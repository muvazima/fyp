@&#MAIN-TITLE@&#Can user privacy and recommendation performance be preserved simultaneously?

@&#HIGHLIGHTS@&#


               Highlight
               
                  
                     
                        
                           
                           Preserve privacy without loss of recommendation accuracy.


                        
                        
                           
                           Add factitious ratings to blur the privacy but intensify interests.


                        
                        
                           
                           Propose a new similarity metric of ratings.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Privacy protection

Balance precision

Similarity metric

Recommendation

@&#ABSTRACT@&#


               
               
                  In online systems of videos, music or books, users’ behaviors are disclosed to the recommender systems to learn their interests. Such a disclosure raises a serious concern in the public for the leak of users’ privacy. Meanwhile, some algorithms are proposed to obfuscate users’ historical behavior records to protect users’ privacy, at the cost of degradation of recommendation accuracy. It is a common belief that such tradeoff is inevitable. In this paper, however, we break this pessimistic belief based on the fact that people's interests are not necessarily limited to items which are geared to a certain gender, age, or profession. Based on this idea, we propose a recommendation-friendly privacy-preserving framework by introducing a privacy-preserving module between a recommender system and user side. For instance, to obfuscate a female user's gender information, the privacy-preserving module adds a set of extra factitious ratings of movies not watched by the given user. These added movies are selected to be those mostly watched by male viewers but interesting the given female user. Extensive experiments show that our algorithm obfuscates users’ privacy information, e.g., gender, efficiently, but also maintains or even improves recommendation accuracy.
               
            

@&#INTRODUCTION@&#

Recommendation service plays an important role in online video systems, but the possible disclosure of users’ privacy via recommendation raises serious concern in the public. The accurate recommendation is of cardinal significance for both the service providers and users. It helps users get satisfying products with ease and in turn increase the revenue for the providers [1]. Hence Netflix ever set $1 M Prize for 10% improvement of recommendation accuracy [2]. However, since a recommender system (RS) makes recommendations via mining user historical behavior to find their interests, it has been found that user personal information such as gender and age can be inferred as well. For instance, one's gender can be inferred from his or her records of watching videos [3,4], and one's age can be inferred from his or her web browsing history [5]. It worries some users that leak of personal information may lead to malicious attacks, e.g., prank calls, annoying advertisement. As a result, some users are even disgusted with personalized recommendation [6]. It is a burning issue of finding a solution to the dilemma of efficient recommendation and the protection of user identity information [7].

Many existing schemes have protected user privacy successfully during the recommendation processes. And they commonly solve this problem via sacrificing the recommendation accuracy [3,6,8]. In contrast, in this paper, we set up a simple and effective framework to protect user privacy information from being inferred, and retain the recommendation accuracy without degradation meanwhile. The key to the success of this framework is a privacy-preserving (PP) module that makes the user privacy information blurred but the interest pattern undistorted and even more distinct towards RS. Since both the advertisers and malicious attackers can divide users into two groups, i.e., target group and non-target group, we exam PP module via binary classification of user privacy in detail.

We illustrate its functionality with a simple example. In an online book system, to avoid old people being troubled with too many elderly-oriented advertisements, the PP module will add a set of extra factitious ratings of unread books which satisfy the following conditions: (1) their readers are mostly youth; (2) they are similar to the books that the user is interested in. Then, we set the ratings of selected books equal to the average ratings given by the youth. With the help of PP module, we can not only protect old people's age from being inferred but also provide them with accurate recommendations simultaneously. In Section 5, we introduce the work steps of PP module in detail.

We take gender preservation as an instance to elaborate our algorithm as does the existing work on privacy preservation in RS [3]. Gender is one of the most basic personal information cared by not only users themselves but also advertisers or other third parties who want to make their commercials more targeted. We evaluate our framework on the MovieLens and Flixster datasets, which are commonly used in studies on RSs and privacy information obfuscation algorithms [3,9–12]. In particular, we use balanced precision [4] as the metric to evaluate the accuracy of gender inference to handle the serious imbalance between different user groups in this dataset, e.g., the number of male users is much greater than that of female ones. Such an imbalance is common in real systems [5]. And we also make a complexity analysis of our method in Section 6. The main contributions of this paper are as follows.

                        
                           •
                           We treat the recommendation-friendly privacy protection (RFPP) problem as a multi-objective optimization problem and propose an efficient heuristic algorithm to solve it. As a result, we can preserve privacy without loss of recommendation accuracy simultaneously.

We introduce a PP module, which serves between users and RSs to disguise user ratings before they are disclosed to the RS and the privacy inferrer (PI). With this module, the privacy information is blurred but the interest preference of user keeps undistorted.

We propose a new similarity metric of movies based on the average difference of ratings and the number of users. Evaluation results show that our metric outperforms the existing ones.

We add factitious ratings based on her/his interests and the average ratings from the opposite privacy group. Our scheme performs better both in the recommendation accuracy and the user privacy protection than the existing works.

The rest of this paper is organized as follows. The related work is presented in Section 2. In Section 3, we describe the RFPP problem, and in Section 4, we give out the prerequisite knowledge. Section 5 introduces the algorithm framework, and Section 6 shows our experiment analysis. Finally, we make a conclusion in Section 7.

@&#RELATED WORK@&#

There are mainly three aspects of related work about RS and user privacy.


                     Recommendation enhancement with extra information. The social relationship or other related information of users increasingly received research interests to be used to improve recommendation accuracy [12–14]. For example, Yang et al. studied Top-k recommendation problem using social network data from Epinions and Flixster [12]. Observing that users may have different opinions on their shared interests, Gurini et al. presented a sentiment-based approach to Twitter user recommendation [15]. For comparison, they all utilize extra data resources to improve RSs’ performance. However our method does not need extra data like social relationship and sentiment information.


                     Protection of data privacy. How to protect user's privacy, especially in personalized services becomes a research focus in recent years. To decrease users’ psychological burden, the work of privacy-preserving collaborative filtering (PPCF) begins with Canny's paper [16], and many related works based on PPCF have been proposed, such as [17]. Moreover, some works utilized randomized perturbation techniques (RPT) to realize PPCF and make data private or avoid greatly exposing users’ privacy [18–21]. Others make use of the clustering-based PPCF [22] or the semi-trusted third party [23,24]. Furthermore, since anonymity is generally conceived to be an integral part of user's right to privacy, Kambourakis contributes to acquiring a comprehensive view of the anonymity research via examining how anonymity is put to work in practice [25]. These works mainly focus on protection of individual user's interests pattern, and in this paper, we consider the protection of demographic information of individual users.


                     Protection of demographic information. Although different users may have different privacy concerns, personal demographic information is most private. Hence it is taken into consideration in research of privacy protection. Berkovsky et al. described a privacy-enhanced collaborative filtering by distributing the stored profiles to several repositories [6]. They also proposed an algorithm, which blocks the properties of a single user, but not the aggregated preferences of a large group of users, to be inferred. This algorithm achieved this at the cost of some loss of recommendation accuracy [8]. It brings about a concern that when most of the users in a group have the same demographics like gender, once some users have their gender disclosed, the whole group may suffer the risk of disclosure. Besides, Weinsberg et al. blur user gender via adding extra factitious ratings to users’ existing records but also with some loss of recommendation accuracy [3]. To our knowledge, none of these schemes can improve the recommendation accuracy when protect user demographic information. And our early work only protects user gender information for video systems [26]. The recommendation-friendly obfuscation method proposed in this paper is the first general one to solve this dilemma by only obscuring users’ privacy information but not their interest information via adding factitious data for a number of scenarios.

Is it possible to preserve privacy without degrading recommendation quality? We regard this problem as RFPP problem, and first give the definition of it. In this section, we also make an analysis of the RFPP problem.

The problem studied in this paper is how to design a PP module to minimize the loss of recommendation accuracy and privacy disclosure risk for users, given user behavior records. Specifically, the PP module functions as a filter between user side and RS and the possible PI, as shown in Fig. 1
                        . A transformation is applied to the user behavior data feeding into the PP module, which obfuscates the demographic information without distorting the user's interest information. RS and PI both work on the data outgoing from PP module. In the reverse direction, recommendation to the users from the RS is rectified in PP module.

The original PI is chosen according to the type of the protecting privacy. It can be trained as a multi-classifier or a linear classifier for the demographic information like race or age. Since almost all advertisers and malicious have a defined target user group, we take the binary classifier as PI to divide users into target group and non-target group. Since the gender prediction is typical binary classification problem, we take gender as the protection privacy to introduce the function of PP module in the following subsections.

Moreover, the framework can be applied in a number of scenarios. Though we take movie systems to exam the function of our method, and the related systems with items like music, CDs, and books also fit the framework in Fig. 1. Once they have recommendation requirement, they need to improve recommendation and protecting user privacy simultaneously. Moreover, browsing, listening, watching, rating, etc. such behavior records can be utilized as same as watching records. Thus, the generality of our method is obvious, and we take the movie systems to show the effectiveness of our framework in this paper.

Denote the loss function of RFPP problem, where R denotes the loss of recommendation accuracy, and P denotes the degree of privacy leakage L(R, P) is a two-dimensional evaluation metric. To minimize L(R, P) is equivalent to improve the recommendation accuracy and protect user privacy information simultaneously. Rather than putting forward a compromise method, we intend to design the PP module to solve this problem effectively and efficiently via adding factitious ratings according to the input data, i.e., users’ existing ratings.

So far it is believed that obfuscating the demographic information will decrease the accuracy of recommendation, since there is a dependency between user interests and demographic types. However, the relationship between them is not always absolute due to the complexity of the personality [27]. For example, a female may be also interested in some movies mainly favored by males, if we can estimate her ratings on such movies that she has not watched, and add such estimations to her existing behavior records in PP module, then her gender can be blurred but her interests will not be distorted. It is vice versa for a male.

To evaluate the effect of the PP module, we further develop L(R, P) as (1).

                           
                              (1)
                              
                                 
                                    
                                       L
                                       →
                                    
                                    
                                    =
                                    
                                    
                                       (
                                       
                                          R
                                          M
                                          S
                                          E
                                          (
                                          
                                             B
                                             ˜
                                          
                                          )
                                          ,
                                       
                                       
                                          
                                             |
                                          
                                          
                                             P
                                             r
                                             e
                                             
                                                (
                                                
                                                   A
                                                   ˜
                                                
                                                )
                                             
                                             −
                                             P
                                             r
                                             
                                                e
                                                0
                                             
                                          
                                          
                                             |
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where 
                           
                              B
                              ˜
                           
                         is the recommendation matrix of user ratings, and 
                           
                              A
                              ˜
                           
                         is the obscured rating matrix. 
                           
                              P
                              r
                              e
                              (
                              
                                 A
                                 ˜
                              
                              )
                           
                         indicates the accuracy of privacy inference and Pre
                        0 is the ideal accuracy aiming at the privacy protection.

For the recommendation part, we take root-mean-square error (RMSE) to measure the differences between values predicted by the scheme in this paper and the values actually observed. The value of RMSE is explicitly the smaller the better. Since our main purpose is to obfuscate users’ privacy, the accuracy of gender inference is most concerned. In [3] it is taken for granted that lower accuracy is better for the sense of gender protection, which is not true in some cases, especially when partial knowledge of user privacy is disclosed. Supposing that the gender obfuscation achieves a very low accuracy, says 0.1, if some users’ actual gender were disclosed, other users’ gender information would be inferred directly with the inverse of the original output by the gender inferrer. The accuracy would be 0.9 exactly. Hence, we argue that for the proper gender obfuscation, the optimal targeted accuracy of gender inference should be 0.5, i.e., the average accuracy of the wild-guesses. As a result, we update (1) to get the final loss function as (2).

                           
                              (2)
                              
                                 
                                    
                                       L
                                       →
                                    
                                    =
                                    
                                       (
                                       
                                          R
                                          M
                                          S
                                          E
                                          (
                                          
                                             B
                                             ˜
                                          
                                          )
                                          ,
                                       
                                       
                                          
                                             |
                                          
                                          
                                             B
                                             P
                                             r
                                             e
                                             (
                                             
                                                A
                                                ˜
                                             
                                             )
                                             −
                                             0.5
                                          
                                          
                                             |
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where 
                           
                              B
                              P
                              r
                              e
                              (
                              
                                 A
                                 ˜
                              
                              )
                           
                         indicates the balance precision of the user privacy inference and 0.5 is the average accuracy of the wild-guesses.

Moreover, for the privacy obfuscation part, we take the balanced precision [4] as a metric to evaluate the efficiency of our obfuscation algorithm as shown above. For an imbalance system, e.g., the number of males is much larger than that of females, most users’ gender can be disclosed easily just by inferring all users’ gender to the gender of the majority group. Since the commonly used metric is unfair to the minority for the gender inferrer, we take the balanced precision as accuracy, which we first proposed in [4] to evaluate the effect of gender prediction. To deal with the significant shortcomings of accuracy in the imbalance system such as MovieLens, some balanced measures have been proposed [28,29]. And Brodersen et al. proposed a definition as the weighted sum of precision for each class, i.e., 
                           
                              
                                 ρ
                                 ˜
                              
                              =
                              c
                              
                                 ρ
                                 P
                              
                              +
                              
                                 (
                                 
                                    1
                                    −
                                    c
                                 
                                 )
                              
                              
                                 ρ
                                 N
                              
                           
                         
                        [30], where ρP
                         and ρN
                         indicate the precision of the positive and negative group, respectively, parameter c ∈ (0, 1) is the cost associated with the misclassification of a case. To strengthen the protection to the minority user, we determine the cost parameter c in analog with the information conveyed in a communication system, based on the information theory [31]. We propose to take the normalized information as the cost with a misclassification as follows.

                           
                              (3)
                              
                                 
                                    c
                                    =
                                    
                                       
                                          −
                                          
                                             log
                                             2
                                          
                                          p
                                       
                                       
                                          −
                                          
                                             log
                                             2
                                          
                                          p
                                          −
                                          
                                             log
                                             2
                                          
                                          
                                             (
                                             
                                                1
                                                −
                                                p
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        where p ∈ (0, 1) is a prior probability of a sample to be positive.

In this section, we show the basic recommendation mechanism, the gender inference module and the basic gender protecting method. To make our algorithm general, we take the commonly used obfuscating method.

To setup recommendation mechanism, we utilize the matrix factorization technique, which becomes the first choice for implementing collaborative filtering, thanks to its attractive accuracy and scalability. We make use of the simple matrix factorization SVD module as Kantor et al. introduced in [1] and predict the users’ ratings by minimizing the regularized squared error as (4).

                           
                              (4)
                              
                                 
                                    
                                       
                                       
                                       
                                          
                                             min
                                             
                                                ∑
                                                
                                                   
                                                      b
                                                      *
                                                   
                                                   ,
                                                   
                                                      q
                                                      *
                                                   
                                                   ,
                                                   
                                                      p
                                                      *
                                                   
                                                   
                                                      (
                                                      u
                                                      ,
                                                      i
                                                      )
                                                   
                                                   ∈
                                                   κ
                                                
                                             
                                             
                                                
                                                   (
                                                   
                                                      r
                                                      
                                                         u
                                                         i
                                                      
                                                   
                                                   −
                                                   μ
                                                   −
                                                   
                                                      b
                                                      i
                                                   
                                                   −
                                                   
                                                      b
                                                      u
                                                   
                                                   −
                                                   
                                                      q
                                                      i
                                                      T
                                                   
                                                   
                                                      p
                                                      u
                                                   
                                                   )
                                                
                                                2
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             
                                             +
                                             
                                             λ
                                             (
                                             
                                                b
                                                i
                                                2
                                             
                                             +
                                             
                                                b
                                                u
                                                2
                                             
                                             +
                                             
                                                
                                                   
                                                      ∥
                                                      
                                                         q
                                                         i
                                                      
                                                      ∥
                                                   
                                                
                                                2
                                             
                                             +
                                             
                                                
                                                   
                                                      ∥
                                                      
                                                         p
                                                         u
                                                      
                                                      ∥
                                                   
                                                
                                                2
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        where rui
                         is the predicted rating of movie i rated by user u. μ is the average rating of the whole dataset. bi
                         and bu
                         are the rating differences of movie i and user u, respectively. And 
                           
                              
                                 q
                                 i
                                 T
                              
                              
                                 p
                                 u
                              
                           
                         captures the implicit feedback between movie i and user u. We compute bi, bu, qi, pu
                         by minimizing the RMSE using the gradient descent method.

The gender inference problem is, in essence, a classifying problem that users are assigned into positive group or negative group according to their rating behaviors. Commonly used logistic regression model is applied to train the classifier. Besides, we denote the female and male users by 0 and 1, respectively. Furthermore, the coefficient 
                           
                              ω
                              i
                              0
                           
                         (
                           
                              ω
                              i
                              1
                           
                        ) learned from this module, which indicates the strength of movie i correlated with the female users or male users, will be used in our PP module in the recommendation framework. And the ratio between training dataset and test dataset is 8:2.

Since deleting movie watching records is almost impractical in most situations and changing ratings is more suspicious, we obfuscate user gender information and strengthen the user interests via the commonly used method, i.e., adding extra data to the original data in the user side as (5).

                           
                              (5)
                              
                                 
                                    
                                       A
                                       ˜
                                    
                                    =
                                    A
                                    +
                                    
                                       A
                                       ′
                                    
                                 
                              
                           
                        where 
                           
                              A
                              ∈
                              
                                 Z
                                 
                                    U
                                    ×
                                    I
                                 
                              
                           
                         is the training matrix built with the behavior records selected randomly, and aui
                         denotes the rating of movie 
                           
                              i
                              ∈
                              [
                              1
                              ,
                              …
                              ,
                              I
                              ]
                           
                         rated by user 
                           
                              u
                              ∈
                              [
                              1
                              ,
                              …
                              ,
                              U
                              ]
                           
                        . 
                           
                              
                                 A
                                 ′
                              
                              ∈
                              
                                 Z
                                 
                                    U
                                    ×
                                    I
                                 
                              
                           
                         is the factitious adding data chosen by PP module. 
                           
                              
                                 A
                                 ˜
                              
                              ∈
                              
                                 Z
                                 
                                    U
                                    ×
                                    I
                                 
                              
                           
                         is the obfuscation matrix, and will replace the original behavior matrix A to train the RS to avoid the leakage of user demographic privacy e.g., the RS or advertiser can learn users’ gender information from the data used to recommendation. How to design the obscure matrix 
                           
                              
                                 A
                                 ˜
                              
                              ∈
                              
                                 Z
                                 
                                    U
                                    ×
                                    I
                                 
                              
                           
                         is the most difference between our works and the existing ones, and we will introduce how to get the obscure matrix 
                           
                              A
                              ˜
                           
                         specifically in the next section.

The algorithm designed for the PP module consists of two operators, i.e., the forward operator and the reverse operator. The former obfuscates user data before it is collected by RS and PI, and the latter makes the modifier of RS recommendation before it is delivered to the user side. Moreover, we introduce the following algorithm based on MovieLens dataset.

In this section, the forward operator is described in detail. We introduce how to choose the movies in PP module, how to compute the similarities between a pair of movies, and how to get the extra factitious ratings. We also illustrate the mechanism of the forward module targeting gender protection specifically.

By the name of PP module, we intend to show that it lets through user interest information but little of gender information. For example, for a woman, this module will choose a set of extra movies that she probably likes, and estimate the ratings that she would give to each movie in this set. Moreover, considering gender protection, for a female user, the added movies should be associated with the males. Firstly, we show the rules and process of movie selection as follows. And then we compare our similarity metric with the existing ones. Finally, the value estimation method of adding ratings is given.

In order to obfuscate a user's gender information but not her/his interests, we suggest the following 3 rules.


                           Rule 1. Movies dominant by the opposite gender group. Gender protection is primary target in the design of this module. A dominant user group can be associated to a movie in terms of the female (male) dominancy. The female (male) dominancy of a movie can be obtained with the Logistic regression model learned from the training dataset. For a female user, the extra movies should be selected from the male dominant movies, and vice versa.


                           Rule 2. Movies interesting to the given user. Good recommendation is the secondary target in the design of the obfuscation mechanism. In order to minimize the RMSE of the obscure matrix 
                              
                                 A
                                 ˜
                              
                           , i.e., 
                              
                                 R
                                 M
                                 S
                                 E
                                 
                                 (
                                 
                                    A
                                    ˜
                                 
                                 )
                              
                            described in Section 6.2, the PP module should emphasize users’ personal interests by adding extra movies that are interesting to the given users. It is commonly assumed that a movie similar to the movies that a user likes will be interesting to the user as well.


                           Rule 3. Movies more popular than others. It is commonly accepted that the preference to popular items benefits the grand performance of a recommendation system. Hence selecting extra movies of higher popularity is the third rule.

We take female as positive group, and male as negative group. The process of movie selection is as follows:

                              
                                 (i)
                                 First of all, following Rule 1, the top-k positive-dominant movie list and the negative-dominant list are built respectively. In this paper, we choose k = 1000.

Next, for a user u belonging to the positive group, the PP module prepares the set of extra movies to be added according to Rule 2 and Rule 3.

After that, the PP module controls the number of added movies with their popularity. The more popular movies will be selected.

There are two points to be noticed during the selection process of the extra movies.

                              
                                 (i)
                                 For each movie i in user u’s existing records, the PP module traverses the opposite movies’ list, and picks up movies which are similar to movie i with a similarity more than β. We adjust β large enough to ensure that the added movies are interesting to user u. By contrast, if a movie whose similarity values are less than β is added, it will weaken u’s personal interests, and seem like noise. Via the experiment of MovieLens and Flixster datasets, we find that for a movie system, the similarity threshold value 
                                       
                                          β
                                          
                                          =
                                          
                                          0.95
                                       
                                     has good performance towards gender protection.

The more popular the added movies are, the better the recommendation accuracy is.

In addition, in our experiment, 80% of records from MovieLens are selected randomly as the training dataset, and the other records are regarded as user behavior in the future. All evaluation results are averaged across 10-fold cross-validation in this paper.

As common recognition, users usually give similar ratings to movies that are similar to the movies they are interested in. Since movie similarity metric is relevant to the accuracy of recommendation, a suitable similarity metric can help PP module pick the similar movies to be added for each user. The existing metrics, such as Pearson correlation, cosine similarity, and adjusted cosine similarity, mainly measure the rating correlation of two movies, and Jaccard index considers the coincidence of users instead of the ratings for two movies, which is somewhat related to the movie popularity. Since for a pair of movies the existing algorithms cannot consider the ratings similarities and the number of their identical users simultaneously, we propose a new calculation method of similarity as follow.

                              
                                 (6)
                                 
                                    
                                       sim
                                       =
                                       1
                                       −
                                       
                                          
                                             
                                                ∑
                                                
                                                   u
                                                   ∈
                                                   
                                                      S
                                                      
                                                         i
                                                         j
                                                      
                                                   
                                                
                                             
                                             
                                                |
                                                
                                                   
                                                      r
                                                      
                                                         u
                                                         i
                                                      
                                                   
                                                   −
                                                   
                                                      r
                                                      
                                                         u
                                                         j
                                                      
                                                   
                                                
                                                |
                                             
                                          
                                          
                                             N
                                             
                                                i
                                                j
                                             
                                          
                                       
                                       
                                          e
                                          
                                             −
                                             
                                                N
                                                
                                                   i
                                                   j
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           where Sij
                            is a collection of users who watches both movie i and movie j, 
                              
                                 
                                    N
                                    
                                       i
                                       j
                                    
                                 
                                 
                                 =
                                 
                                 
                                    |
                                    
                                       S
                                       
                                          i
                                          j
                                       
                                    
                                    |
                                 
                              
                            is the number of users in Sij. rui, ruj
                            are the ratings of movie i and movie j, given by user u. The similarity contains two sides, i.e., movies’ ratings and popularities. 
                              
                                 
                                    ∑
                                    
                                       u
                                       ∈
                                       
                                          S
                                          
                                             i
                                             j
                                          
                                       
                                    
                                 
                                 
                                    
                                       |
                                    
                                    
                                       
                                          r
                                          
                                             u
                                             i
                                          
                                       
                                       −
                                       
                                          r
                                          
                                             u
                                             j
                                          
                                       
                                    
                                    
                                       |
                                    
                                 
                                 /
                                 
                                    N
                                    
                                       i
                                       j
                                    
                                 
                              
                            is the average difference of ratings between movie i and movie j. 
                              
                                 e
                                 
                                    −
                                    
                                       N
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                            is an adjusted quotient (AQ) to control the effect of the movie popularity. For example, when two pairs of movies have the same value of rating side 
                              
                                 
                                    ∑
                                    
                                       u
                                       ∈
                                       
                                          S
                                          
                                             i
                                             j
                                          
                                       
                                    
                                 
                                 
                                    
                                       |
                                    
                                    
                                       
                                          r
                                          
                                             u
                                             i
                                          
                                       
                                       −
                                       
                                          r
                                          
                                             u
                                             j
                                          
                                       
                                    
                                    
                                       |
                                       /
                                    
                                    
                                       N
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                           , the pair attracting more users will have a larger compound similarity value caused by a smaller 
                              
                                 e
                                 
                                    −
                                    
                                       N
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                           .

To keep the users’ interests undistorted, we compare our calculation with several existing similarities on the MovieLens dataset in Table 1
                            based on the loss function 
                              
                                 L
                                 →
                              
                           , and define the change of RMSE of recommendation as ΔR, and the balanced precision of gender inference as BPre. In addition the loss function 
                              
                                 L
                                 →
                              
                           , RMSE, and 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                              
                            are described specifically in Section 6.2.

As Table 1 lists, the PP module can minimize the metric BPre close to the average accuracy of wild-guesses based on any kind of similarity. It means our method can obviously protect users’ privacy. Comparing with the existing similarities, only our calculation method of similarity can improve the recommendation with 0.002086 decrease of RMSE. Moreover, to build the recommendation-friendly obfuscation algorithm, we should choose a most advantage similarity metric to the RS with an acceptable demographic inference result. Hence, the compound similarity is the best and we find that in choosing the extra movie set a user might be interested, the movie popularity and the rating should be covered together, and our method has done.

To further verify that our calculation method of similarity is reasonable, we compare various forms of adjusted quotients as listed in Table 2
                           . Obviously, 
                              
                                 e
                                 
                                    −
                                    
                                       N
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                            is the optimal adjusted quotient. 
                              
                                 e
                                 
                                    −
                                    
                                       N
                                       
                                          i
                                          j
                                       
                                    
                                 
                              
                            not only improves the recommendation performance most, but also has a BPre mostly close to the average accuracy of the wild-guesses, i.e., 0.5.

It is not occasional or intuitive to take the average rating associated with the opposite gender as the extra factitious rating. For the extra movie j selected for user u, several estimations of rating ruj
                            are compared, including the average rating of the same gender raters, average rating of the opposite gender raters and average rating of all raters.

As Table 3
                            lists, the opposite gender rating performs best in terms of ΔR RMSE and 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                              
                            both. For a female user u, according to the Rule 1, the extra movie j is male dominant, hence the most appropriate estimating for the rating of user u for movie j, is the average rating given by the male raters. And the average rating given by all raters comes second. Besides, even the average rating given by female raters only brings an insignificant increase of RMSE.

On the reverse direction, the reverse operator will rectify the recommendation output of the RS input into the PP module before it is delivered to the user side. Since the RS considers the nonzero elements in A' as users’ history, it will not recommend the corresponding items to the associated users. To do this, we get the final recommendation matrix based on A', which is reserved by the PP module, as (7).

                           
                              (7)
                              
                                 
                                    
                                       B
                                       ˜
                                    
                                    =
                                    P
                                    
                                       (
                                       B
                                       )
                                    
                                 
                              
                           
                        where 
                           
                              B
                              ∈
                              
                                 Z
                                 
                                    U
                                    ×
                                    I
                                 
                              
                           
                         indicates the original recommendation matrix, bui
                         denotes the predicted value of item 
                           
                              i
                              ∈
                              [
                              1
                              ,
                              …
                              ,
                              I
                              ]
                           
                         for the user 
                           
                              u
                              ∈
                              [
                              1
                              ,
                              …
                              ,
                              U
                              ]
                           
                         by RS. 
                           
                              B
                              ˜
                           
                         is the final recommendation matrix, and 
                           
                              
                                 b
                                 ˜
                              
                              
                                 u
                                 i
                              
                           
                         is the final modified value given to the associated user by PP module via 
                           
                              P
                              (
                              ⋅
                              )
                           
                         function that appends the records of A' to B. In addition, the recommendation accuracy is tested with the users’ future behavior, herein the test dataset. And the protection of user demographic is tested based on the obscured rating matrix 
                           
                              A
                              ˜
                           
                        .

In this section, we introduce the datasets firstly. And then the experiment process will be described in detail. Finally, we evaluate the experiment based on a proper range of extra factitious ratings from three respects, respectively, i.e., privacy performance, recommendation performance and complexity analysis. In addition, we denote p
                     0 the percentage of added ratings relative to total number of records in the training dataset.

We describe the MovieLens and Flixster datasets in this subsection, and also give the basic statistical analysis of both two datasets.

MovieLens is the frequently used RS, which recommends films for its users to watch, based on their film preferences. It is also a virtual community website, which dataset is from a project of GroupLens [32] Research about personalized RSs. This dataset contains 1,000,209 anonymous ratings of approximately 3900 movies given by 6040 users who joined MovieLens in 2000. MovieLens is a gender imbalance system. Only 28.29% of its users are female, and 71.71% of its users are male.

Although according to the World Health Organization standard users of MovieLens system can be divided into three intervals according to their ages (18–44), i.e. Teenage (<18), Youth (18–35), Middle aged and elderly people (>35), we divided users into two groups with the view of economic benefit to test the generality of PP module. Since the youth is always with widest interests in the varied kinds of movies as well as the fashionable products displayed by advertisement to cater for any age interval, both the RSs and the commercial advertisers would like most to know and attract them. Thus, the age of the youth is emergent to be protected. Therefore, we take two age groups, i.e. the youth group and the old and kid group. Obviously, the final distribution of age groups is disproportion. The youth group occupies 72.71% of the total users, and the old and kid group only accounts for 27.29% of the total users.

Flixster is an American social movie site for discovering new movies, learning about movies, and meeting others with similar tastes in movies. For further comparison, we choose users with valid gender information, landing between Oct. 1 and Dec. 31, 2009, and their corresponding records of viewer id, video rating during this period. The final dataset contains 994,448 anonymous ratings of 3796 movies given by 6843 users, each movie with at least five viewers to decrease the sparseness of rating matrix. In addition, 54.95% of the total users are female, and 45.05% of the total users are male.

We show the experiment process of our method in this subsection specifically according to the framework represented in Fig. 1.
                     

We imply experiments based on gender and age privacy information, respectively. To test the effects of adding ratings, we choose different number of added records based on the popularity rank of videos. The experiment involves the following steps.

                           
                              (i)
                              Select 80% of user behavior records as training dataset, and obscure user data with selected records as Section 5.1 described. Specifically, for each user, we traverse the opposite-dominant movies’ list, and picks up movies which are similar to her/his existing records with a similarity more than β and also in top-k popularity movie set of training dataset. After that, we add factitious ratings of selected movies for this user. Hence, we call the total adding records as rank-k video ratings for simplicity.

Test the recommendation result based on obscuring data with the rest of original user behavior records.

Test the privacy protection result based on the obscuring data with the PI training on the original user behavior records.

We show the performance of privacy preservation and that of recommendation with adding factitious rank-k video ratings preferred by the opposite gender (age) class.

To evaluate the performance of PP module, we analyze the results with respect to privacy performance, recommendation performance and computing complexity. Fig. 2 shows the evaluation results based on MovieLens and Flixster datasets. In Fig. 2 (a–c), the green square dotted line indicts the value of 
                           
                              |
                              B
                              P
                              r
                              e
                              −
                              0.5
                              |
                           
                        , and the blue circular dotted line indicts the value of ΔR. The red line is the reference line of 
                           
                              Δ
                              R
                              =
                              0
                           
                        , representing no loss of recommendation accuracy. The left and right vertical axis corresponds to ΔR and 
                           
                              |
                              B
                              P
                              r
                              e
                              −
                              0.5
                              |
                           
                         respectively. In Fig. 2 (d), the lavender (turquoise) diamond dotted line indicts the distribution of p
                        0 based on rank-k video ratings with gender information in MovieLens (Flixster) dataset. And the lavender triangle dotted line represents the distribution of p
                        0 with age information in MovieLens dataset.

In this subsection, we show the privacy performance of PP module respectively for gender and age preservation. And we also compare our method with existing similar work. Results verify that PP module can preserve user privacy information successfully.

For gender preservation, we show the results with MovieLens and Flixster datasets, respectively. As shown in Fig. 2 (a), in MovieLens dataset, when 2 ≤ k ≤ 10, 3.89% ≤ p
                           0 ≤ 8.82%, 
                              
                                 0.013
                                 ≤
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 <
                                 0.05
                              
                            corresponds to the average accuracy of the wild-guesses. And as shown in Fig. 2 (b), in Flixster dataset, via adding ratings, 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                              
                            decreases more or less obviously. Most importantly, Weinsberg et al. use 10% extra factitious ratings of MovieLens dataset to obscure user ratings based on their proposed method, and make 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 ≈
                                 0.145
                              
                           , and ΔR is 0.058, While we only add 8.12% (
                              
                                 k
                                 =
                                 8
                              
                           ) extra records and make 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 ≈
                                 0.003
                              
                           , and ΔR is only 0.012. It is evident that PP module can make BPre greatly close to the average accuracy of the wild-guesses to protect user gender information effectively.

For age preservation, we apply the heuristic algorithm on the MovieLens dataset. And we show the results based on the loss function 
                              
                                 L
                                 →
                              
                            in Fig. 2 (c) and Table 4
                           , respectively. Although 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 ≈
                                 0.1
                              
                            is not so perfect, the value nearly reduces three times comparing with no adding. Thus, according the analysis above, PP module can preserve privacy information obviously.

In this subsection, we show the recommendation performance of PP module, and also compare our method with the realistic values and existing similar work. It has been proved that PP module can preserve accuracy of recommendation effectively.

For gender information, although a small number of extra factitious ratings have very little effect on recommendation accuracy, we can decrease RMSE of commendation practically. As Fig. 2 (a and d) shown, in MovieLens dataset, when 
                              
                                 k
                                 =
                                 2
                                 ,
                                 
                                    p
                                    0
                                 
                                 ≈
                                 0.04
                                 %
                              
                           , RMSE has the largest decrease. Most importantly, Weinsberg et al. use 10% extra factitious ratings of MovieLens dataset to make ΔR equal to 0.058, 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 ≈
                                 0.145
                              
                           . While we only add 3.89% (
                              
                                 k
                                 =
                                 2
                              
                           ) extra records and make ΔR equal to −0.002, 
                              
                                 |
                                 B
                                 P
                                 r
                                 e
                                 −
                                 0.5
                                 |
                                 ≈
                                 0.05
                              
                           . Furthermore, we have an interesting finding that PP module performs better than works of giving added movie a realistic rating known from the test dataset. In detail, for user u of MovieLens dataset, if movie j to be added belongs to u’s records in the test dataset of RS, we add the realistic rating to u's existing records, and find ΔR is −0.001 (ours is −0.002). Besides, in Flixster dataset, only adding 0.87% (
                              
                                 k
                                 =
                                 1
                              
                           ) ratings of existing records can make RMSE absolutely decreases 0.001.

For age information, adding a very limited number of fictitious ratings brings a rapid decline in the two dimensions of 
                              
                                 L
                                 →
                              
                            as shown in Fig. 2 (c) and Table 4. It means that no more than 0.2% extra ratings can satisfy the users. Thus, PP module can preserve RS's performance simultaneously.

For the feasibility of implementation in reality, the PP module should obscure user behavior data with ease and bring limit extra fictitious records to RS. We make the complexity analysis of our method as follow.

Actually, online video systems devote to protect privacy of loyal users, who are active and register with personal privacy information. Furthermore thousands of popular videos can cover the most of these users. For Flixster system, the precision difference of gender inference trained on 5000 viewers and 25,000 viewers is only 0.02, and the former result is nearly 0.74 [3]. For MovieLens dataset, top-500 popular videos can cover all viewers. Thus, PP module can utilize a small dataset to finish most of works offline with ease, such as building top-k videos’ lists, computing the similarity of videos, and learning the relationship between p
                           0 and RMSE (|BPre −0.5 |).

Besides, PP module can preserve user privacy information and improve the recommendation quality in an efficient way via adding a quite small amount of extra fictitious records to users’ existing behavior records. For RS, as the cost of computing the recommendation list depends on the number of non-zeros (nnz) in SVD module, it requires our method satisfy the following constraint:

                              
                                 (8)
                                 
                                    
                                       n
                                       n
                                       z
                                       
                                          (
                                          A
                                          )
                                       
                                       +
                                       n
                                       n
                                       z
                                       
                                          (
                                          
                                             A
                                             ′
                                          
                                          )
                                       
                                       ≈
                                       n
                                       n
                                       z
                                       
                                          (
                                          A
                                          )
                                       
                                    
                                 
                              
                           where 
                              
                                 A
                                 ∈
                                 
                                    Z
                                    
                                       U
                                       ×
                                       I
                                    
                                 
                              
                            is the training matrix, and 
                              
                                 
                                    A
                                    ′
                                 
                                 ∈
                                 
                                    Z
                                    
                                       U
                                       ×
                                       I
                                    
                                 
                              
                            is the factitious adding data chosen by PP module. Since the value of nnz(A) is as thousands times as that of nnz(A'), nnz(A') can be ignored generally. Thus, the PP module does not increase the complexity of RS significantly in deed.

In addition, for online video systems targeting new videos like movies and TV series which release slowly, PP module can update the work process offline each week. In real applications, PP module can adjust update time to make a tradeoff between accuracy and timeliness of recommendations to cater the demand of various RSs.

@&#CONCLUSION@&#

In this paper, we proposed a general and effective framework to overcome the dilemma between protecting users’ privacy and improving recommendation accuracy simultaneously. For the sense of gender protection, we define a perfect protection of gender is a prediction accuracy close to the average accuracy of the wild-guesses, i.e., 0.5. We propose a recommendation-friendly user privacy obfuscation algorithm evaluated by the loss function L(R, P) which considers two metrics, i.e., RMSE and balanced precision, and the experiment results show that we can achieve a small decrease of RMSE of recommendation, and make the gender results close to wild-guess. Above all, we design the selection strategy of choosing extra movies and the method of estimating the factitious ratings, and we propose a new similarity metric. Finally, we make experiment analysis of our algorithm and prove that our algorithm can achieve accurate recommendation and protect users’ gender and age at the same time.

Since our algorithm is simple and effective, more research about other privacy information will be considered in the further work via different privacy prediction methods. And we want to experiment on user objective online history like shopping records as well.

@&#ACKNOWLEDGMENTS@&#

This work was supported in part by the National Science Foundation of China under grant nos. 61271199, 61301082 and the Fundamental Research Funds for the Central Universities under grant no. W14JB00500.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An effective hybrid teaching–learning-based optimization algorithm for permutation flow shop scheduling problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A teaching–learning-based optimization is proposed for flow shop problem.


                        
                        
                           
                           A variable neighborhood search is proposed for fast solution improvement.


                        
                        
                           
                           A simulated annealing is adopted as the local search method of VNS.


                        
                        
                           
                           For the DMU problems, some new upper bounds have been obtained.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Permutation flow shop scheduling problem

Teaching-learning-based optimization algorithm

Variable neighborhood search

Simulated annealing

Makespan

Maximum lateness

@&#ABSTRACT@&#


               
               
                  Permutation flow shop scheduling (PFSP) is among the most studied scheduling settings. In this paper, a hybrid Teaching–Learning-Based Optimization algorithm (HTLBO), which combines a novel teaching–learning-based optimization algorithm for solution evolution and a variable neighborhood search (VNS) for fast solution improvement, is proposed for PFSP to determine the job sequence with minimization of makespan criterion and minimization of maximum lateness criterion, respectively. To convert the individual to the job permutation, a largest order value (LOV) rule is utilized. Furthermore, a simulated annealing (SA) is adopted as the local search method of VNS after the shaking procedure. Experimental comparisons over public PFSP test instances with other competitive algorithms show the effectiveness of the proposed algorithm. For the DMU problems, 19 new upper bounds are obtained for the instances with makespan criterion and 88 new upper bounds are obtained for the instances with maximum lateness criterion.
               
            

@&#INTRODUCTION@&#

In permutation flow shop scheduling problems, n jobs N
                     =
                     N
                     1, N
                     2,…,
                     Nn
                      have to be processed on a set of m machines M
                     =
                     M
                     1, M
                     2,…,
                     Mm
                      sequentially. Therefore, each job consists of a set of m operations Oj
                     
                     ={Oj
                     
                     1,…,
                     Ojm
                     }. Each operation has a given processing time denoted by Pi,j
                      (i
                     =1, 2,…,
                     m, j
                     =1, 2,…,
                     n). At any time, each machine can process at most one job and each job can be processed by at most one machine. Once the processing of a job on a machine has started, it must be completed without interruption. The sequence in which the jobs to be processed are identical for each machine. Thus there is n! possible processing sequences for the problem. The minimum completion time, which is known as makespan or C
                     max, is the most commonly studied objective of PFSP [1]. Recently, PFSP with other objectives such as those involving due dates have drawn significant attention [2–4]. Demirkol et al. [5] presented extensive sets of randomly generated test problems for the problems of minimizing makespan (C
                     max) and maximum lateness (L
                     max) in flow shops, generally referred to DMU problems. PFSP with the makespan criterion can be denoted as Fm
                     |prmu|Cmax
                      and has been proved NP-complete [6]. PFSP with the criterion of maximum lateness can be denoted as Fm
                     |prmu|L
                     max, where Lj
                     
                     =max{Cj
                     
                     −
                     dj
                     , 0} is the lateness of job j, being dj
                      its due date and Cj
                      its completion time at the last machine of the shop. Lenstra et al. [7] proved that the two-machine flow shop with maximum lateness is NP-complete.

Approaches for PFSP can be divided into three categories: exact algorithms, heuristics and meta-heuristics. Exact algorithms, such as branch-and-bound method, dynamic programming and mathematical programming, have been successfully applied in solving small instances [8–10]. However, they could not obtain promising results in a reasonable time for medium or large instances. As for the heuristics, a feasible solution is generally built based on some constructive operations with a fast process, while the solution is quite not satisfactory [11]. More recently, the meta-heuristic algorithms, such as genetic algorithm (GA), simulated annealing (SA), tabu search (TS), have been given special emphasis for they could provide high-quality solutions with reasonable computing times. In recent decade, an increasing number of research papers focusing on meta-heuristics for PFSP have been published.

Teaching–Learning-Based Optimization (TLBO) proposed by Rao et al. [12] is a novel efficient optimization method. The main idea behind TLBO is the simulation of a classical school learning process. The advantages of TLBO algorithm such as ease of implementation, immediately accessible for practical applications, speed to get the solutions and robustness are shown in the literature [12,13]. TLBO seems to be a rising star from amongst a number of meta-heuristics with relatively competitive performances. Empirical tests show that TLBO could outperforms the other well-known meta-heuristics regarding constrained benchmark functions, constrained mechanical design, and continuous non-linear numerical optimization problems [13]. However, applications of TLBO for discrete combinatorial optimization problems are still limited.

In this paper, a novel hybrid Teaching–Learning-Based Optimization algorithm (HTLBO) is proposed for PFSP to optimize two objectives: the makespan and maximum lateness of jobs. The paper is organized as follows: Section 2 presents the literature review about PFSP problem; Section 3 provides the description of the PFSP; Section 4 describes implementation details of the HTLBO for PFSP; Section 5 shows the computational results and comparisons with other competitive algorithms; and Section 6 concludes the paper.

@&#LITERATURE REVIEW@&#

The makespan criterion for flow shop scheduling is still a hot topic of research as shown in the recent review by Gupta and Stafford Jr. [14]. Tseng et al. [15] introduced that the exact algorithms are sensible to the number of machines. As a result, a wealth of literature on heuristic and meta-heuristic methods for the PFSP problem and makespan criterion was published. Heuristics for the makespan minimization problem have been proposed by Palmer [16], Campbell et al. [17], Dannenbring [18], Nawaz et al. [19], Taillard [20], Framinan and Leisten [21] and Framinan et al. [22], Li et al. [23], Laha and Chakraborty [24]. Among these existing heuristics, the Nawaz–Enscore–Ham (NEH) heuristic has been proved one of the most successful constructive heuristics which can obtain comparable results against some modern constructive methods according to the results of the computational evaluation given by Ruiz and Maroto [25]. The meta-heuristics include simulated annealing [26,27], tabu search [28–31], genetic algorithms [32,33], ant colony optimization [34], iterated local search [35], iterated greedy methods [36,37], particle swarm optimization [38–40], differential evolution algorithm [41] and so on. Based on these meta-heuristics, some hybrid algorithms were proposed, which had been demonstrated effective according to the computational results on some well-known benchmark problems. Chang et al. [42] proposed a hybrid genetic-immune algorithm, in which the regular genetic algorithm is applied in the first stage to rapidly evolve and when the processes are converged up to a pre-defined iteration then artificial immune system is introduced to hybridize GA in the second stage. Among hybrid algorithms, the most popular strategy is to hybridize a meta-heuristic with a local search method. Murata et al. [43] showed two hybrid algorithms: genetic local search and genetic simulated annealing. Nearchou [44] designed a hybrid simulated annealing algorithm for solving the flow shop scheduling problem. In this algorithm, an iterated hill climbing procedure is applied on the population of schedules during the annealing process. Pan et al. [41] introduced a new and novel referenced local search procedure hybridized with both discrete differential evolution algorithm and iterated greedy algorithm to further improve the solution quality. Ahmadizar [45] developed a new ant colony optimization algorithm for makespan minimization in permutation flow shops. In this algorithm, novel mechanism is employed in initialization the pheromone trails based on an initial sequence. Tzeng et al. [46] proposed a hybrid estimation of distribution algorithm (EDA) with ant colony system (ACS). Their algorithm, in each iteration, applies a new filter strategy and a local search method to update the local best solution and, based on the local best solution, generates pheromone trails using a new pheromone-generating rule and applies a solution construction method of ACS to generate members for the next iteration.

For the maximum lateness criterion, within our knowledge, only a few of researchers adopted this criterion as the performance measure of proposed algorithms. Some researchers studied on the two-machine flow shop scheduling with maximum lateness criterion [47]. Tasgetiren et al. [38] first introduced a particle swarm optimization for maximum lateness minimization in permutation flow shop scheduling problem based on the DMU benchmark problems. Since then, some novel meta-heuristics have been proposed to deal with the objective of maximum lateness. Zheng and Yamashiro [11] designed a new quantum differential evolutionary algorithm, this algorithm based on the basic quantum-inspired evolutionary algorithm (QEA). Li and Yin [48] suggested an opposition-based differential evolution algorithm to solve PFSP with the criteria of makespan and maximum lateness.

Schedule π is a permutation of the n jobs, which can be denoted as {π
                     1, π
                     2,…,
                     πn
                     }, in which πi
                     
                     ∊
                     Ω is the ith (i
                     =1, 2,…,
                     n) job in π. Π is the set of all the permutations of the n jobs. Let 
                        
                           
                              
                                 p
                              
                              
                                 
                                    
                                       π
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 j
                              
                           
                        
                      represents the processing time of job πi
                      on machine j and C(πi
                     ,
                     m) represents the completion time of job πi
                      on machine m. Then the completion time for the n-job, m-machine problem can be calculated as follows:
                        
                           (1)
                           
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    1
                                 
                              
                              ,
                              1
                              )
                              =
                              
                                 
                                    p
                                 
                                 
                                    
                                       
                                          π
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              ,
                              1
                           
                        
                     
                     
                        
                           (2)
                           
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              ,
                              1
                              )
                              =
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                    -
                                    1
                                 
                              
                              ,
                              1
                              )
                              +
                              
                                 
                                    p
                                 
                                 
                                    
                                       
                                          π
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    1
                                 
                              
                              ,
                              
                              i
                              =
                              2
                              ,
                              …
                              ,
                              n
                           
                        
                     
                     
                        
                           (3)
                           
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    1
                                 
                              
                              ,
                              j
                              )
                              =
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    1
                                 
                              
                              ,
                              j
                              -
                              1
                              )
                              +
                              
                                 
                                    p
                                 
                                 
                                    
                                       
                                          π
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    j
                                 
                              
                              ,
                              
                              j
                              =
                              2
                              ,
                              …
                              ,
                              m
                           
                        
                     
                     
                        
                           (4)
                           
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              ,
                              j
                              )
                              =
                              
                                 max
                              
                              (
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                    -
                                    1
                                 
                              
                              ,
                              j
                              )
                              ,
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              ,
                              j
                              -
                              1
                              )
                              )
                              +
                              
                                 
                                    p
                                 
                                 
                                    
                                       
                                          π
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    j
                                 
                              
                              ,
                              
                              i
                              =
                              2
                              ,
                              …
                              ,
                              n
                              ,
                              
                              j
                              =
                              2
                              ,
                              …
                              ,
                              m
                           
                        
                     
                  

The makespan of a permutation π can be formally defined as the completion time πn
                      of the last job on the last machine m, so the makespan is defined as:
                        
                           (5)
                           
                              
                                 
                                    C
                                 
                                 
                                    max
                                 
                              
                              (
                              π
                              )
                              =
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    n
                                 
                              
                              ,
                              m
                              )
                           
                        
                     
                  

The PFSP with the makespan criterion is to find the optimal permutation π
                     * in the set of all permutation:
                        
                           (6)
                           
                              
                                 
                                    C
                                 
                                 
                                    max
                                 
                              
                              (
                              
                                 
                                    π
                                 
                                 
                                    ∗
                                 
                              
                              )
                              ≤
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    n
                                 
                              
                              ,
                              m
                              )
                              ,
                              
                              ∀
                              π
                              ∈
                              Π
                           
                        
                     
                  

As for the flow shop scheduling with the due date constraint, let L(πi
                     ) denoted the lateness of jobs πi
                      and can be defined as:
                        
                           (7)
                           
                              L
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              )
                              =
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              ,
                              m
                              )
                              -
                              d
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              )
                           
                        
                     
                  

Maximum lateness L
                     max(π) of a permutation can be defined as:
                        
                           (8)
                           
                              
                                 
                                    L
                                 
                                 
                                    max
                                 
                              
                              (
                              π
                              )
                              =
                              
                                 max
                              
                              (
                              C
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              ,
                              m
                              )
                              -
                              d
                              (
                              
                                 
                                    π
                                 
                                 
                                    i
                                 
                              
                              )
                              )
                           
                        
                     where d(πi
                     ) is the due date of jobs πi
                     . The optimal solution π
                     * should satisfy the following criterion:
                        
                           (9)
                           
                              
                                 
                                    L
                                 
                                 
                                    max
                                 
                              
                              (
                              
                                 
                                    π
                                 
                                 
                                    ∗
                                 
                              
                              )
                              ≤
                              
                                 
                                    L
                                 
                                 
                                    max
                                 
                              
                              (
                              π
                              )
                              ,
                              
                              ∀
                              π
                              ∈
                              Π
                           
                        
                     
                  

Teaching–Learning-Based Optimization (TLBO) is a population-based method inspired by the effect of the influence of a teacher on the output of learners in a class and has been applied to cluster data [49], design of planar steel frames [50], optimization of two stage thermoelectric cooler [51], job shop scheduling [52] and so on. Like other nature-inspired algorithms, TLBO uses a population of solutions to proceed to the global solution. In TLBO, the best individual is regarded as the teacher, and the rest individuals are regarded as students. The process of TLBO is divided into two parts: teacher phase and learner phase.

During the teacher phase, a teacher wants to bring his or her learners up to his or her level in terms of knowledge, but the level the class can reach depends on the capability of the class. In other words, the improvement of students is influenced by the difference between the teacher’s knowledge and the qualities of all students. Thus the individuals are modified with the following expression:
                           
                              (10)
                              
                                 
                                    
                                       X
                                    
                                    
                                       new,
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       X
                                    
                                    
                                       old,
                                       i
                                    
                                 
                                 +
                                 r
                                 ·
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       teacher
                                    
                                 
                                 -
                                 (
                                 
                                    
                                       T
                                    
                                    
                                       F
                                    
                                 
                                 ·
                                 
                                    
                                       X
                                    
                                    
                                       mean
                                    
                                 
                                 )
                                 )
                              
                           
                        where X
                        teacher is the best individual in the population, TF
                         is a teaching factor, which can be either 1 or 2, X
                        mean is the current mean value of the individuals, r is a uniform random number between 0 and 1.

During the learner phase, learners increase their knowledge by interaction between themselves. A random individual Xii
                         is selected for an individual Xi
                         to learn from. Two situations are considered. If Xii
                         is better than Xi
                        , the individual is modified with the following expression:
                           
                              (11)
                              
                                 
                                    
                                       X
                                    
                                    
                                       new,
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       X
                                    
                                    
                                       i
                                    
                                 
                                 +
                                 r
                                 ·
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       ii
                                    
                                 
                                 -
                                 
                                    
                                       X
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           
                        
                     

Otherwise, the individual is modified with the following expression:
                           
                              (12)
                              
                                 
                                    
                                       X
                                    
                                    
                                       new,
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       X
                                    
                                    
                                       i
                                    
                                 
                                 +
                                 r
                                 ·
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       X
                                    
                                    
                                       ii
                                    
                                 
                                 )
                              
                           
                        
                     

Procedures of TLBO are described as follows and shown in Fig. 1
                        :
                           
                              Step 1: Initialization.

Step 2: If the termination criterion is not met, repeat the following steps.

Step 3: Teacher phase.

Step 4: Learner phase.

TLBO was initially designed to solve continuous optimization problems. Hence, the standard TLBO could not be used to solve PFSP directly. In order to apply general TLBO to PFSP, the key issue is to find a suitable mapping between the job permutation and the vector of individuals. Bean et al. presented a robust representation called random keys [53]. Then inspired by this method, a smallest position value (SPV) rule based on random keys is proposed by Tasgetiren et al. [38] to convert individual Xi
                        
                        =[xi
                        
                        ,1,
                        xi
                        
                        ,2,…,
                        xi
                        
                        ,
                        
                           n
                        ] to the job permutation πi
                        
                        =[πi
                        
                        ,1,
                        πi
                        
                        ,2,…,
                        πi
                        
                        ,
                        
                           n
                        ]. Qian et al. [54] introduced a largest order value (LOV) rule based on random key representation. Li and Yin [48] proposed a largest position value (LPV) rule. In this work, the LOV rule is adopted for TLBO. A simple example is presented in Table 1
                         to illustrate the LOV rule.

According to LOV rule, all elements of Xi
                        
                        =[xi
                        
                        ,1,
                        xi
                        
                        ,2,…,
                        xi
                        
                        ,
                        
                           n
                        ] are firstly ranked by descending order to get a sequence ϕi
                        
                        =[ϕi
                        
                        ,1,
                        ϕi
                        
                        ,2,…,
                        ϕi
                        
                        ,
                        
                           n
                        ]. Then the job permutation πi
                         is calculated by the following formula:
                           
                              (13)
                              
                                 
                                    
                                       π
                                    
                                    
                                       i
                                       ,
                                       
                                          
                                             ϕ
                                          
                                          
                                             i
                                             ,
                                             l
                                          
                                       
                                    
                                 
                                 =
                                 l
                              
                           
                        where the dimension l varies from 1 to n. In Table 1, the LOV is illustrated with a simple instance (n
                        =5), where individual is Xi
                        
                        =[0.05, 0.35, −0.67, 0.21, −0.72]. Because xi
                        
                        ,2 is the largest value of Xi
                        . So xi
                        
                        ,2 is selected first and assigned the rank value 1. Then xi
                        
                        ,4 is selected secondly and assigned rank value 2. In the same way, xi
                        
                        ,1, xi
                        
                        ,3, xi
                        
                        ,5 are assigned the value 3, 4 and 5, respectively. Thus, the sequence is ϕi
                        
                        =[3,1,4,2,5]. According to (13), if l
                        =1, then ϕi
                        
                        ,1
                        =3 and 
                           
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    
                                       
                                          ϕ
                                       
                                       
                                          i
                                          ,
                                          1
                                       
                                    
                                 
                              
                              =
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    3
                                 
                              
                              =
                              1
                           
                        ; if l
                        =2, then 
                           
                              
                                 
                                    ϕ
                                 
                                 
                                    i
                                    ,
                                    2
                                 
                              
                              =
                              1
                           
                         and 
                           
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    
                                       
                                          ϕ
                                       
                                       
                                          i
                                          ,
                                          2
                                       
                                    
                                 
                              
                              =
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    1
                                 
                              
                              =
                              2
                           
                        ; if l
                        =3, then 
                           
                              
                                 
                                    ϕ
                                 
                                 
                                    i
                                    ,
                                    3
                                 
                              
                              =
                              4
                           
                         and 
                           
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    
                                       
                                          ϕ
                                       
                                       
                                          i
                                          ,
                                          3
                                       
                                    
                                 
                              
                              =
                              
                                 
                                    π
                                 
                                 
                                    i
                                    ,
                                    4
                                 
                              
                              =
                              3
                           
                        ; and so on. Thus, we obtain the job permutation πi
                        
                        =[2, 4, 1, 3, 5]. As we can see, LOV rule provides a simple conversion to makes TLBO applicable to solve PFSP.

The initial population is generated randomly and uniformly. A vector Xi
                        
                        ={xi
                        
                        1,
                        xi
                        
                        2,…,
                        xin
                        } is randomly produced according to the following formula:
                           
                              (14)
                              
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 
                                    
                                       x
                                    
                                    
                                       min
                                    
                                 
                                 +
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       max
                                    
                                 
                                 -
                                 
                                    
                                       x
                                    
                                    
                                       min
                                    
                                 
                                 )
                                 *
                                 rand,
                                 
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 …
                                 ,
                                 NP
                                 ,
                                 
                                 j
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 …
                                 ,
                                 n
                              
                           
                        where x
                        min
                        =−1.0, x
                        max
                        =1.0 and rand is an uniform random number between 0 and 1.

Crossover is a typical operator in genetic algorithm. To enforce the performance of the global search, we apply crossover operator after the general TLBO tenure. To create new individuals, two types of crossover operators are selected: TP (two-point order crossover) operator by Murata et al. [43] and PMX (partially mapped crossover) operator by Glodberg [55]. Readers can refer to the literature we have mentioned for the details of the crossover operators. Generally, a new pair will be generated after crossover between an existing pair. However, in our HTLBO, crossover is taken between an individual and his/her previous individual in the population to generate a new pair of individuals. Especially, the first individual is manipulated with the last individual. Each individual create a new pair of individuals. If the better individual between the new pair is also better than the original individual, the original individual will be replaced by the better individual.

The procedure of crossover operator can be summarized as follows:
                           
                              Step 1: Apply the LOV rule to convert the individual Xi
                                  to the job permutation πi
                                 .

Step 2: Choose one type of crossover operators randomly.

Step 3: Generate a pair of new individuals by crossover and find the better individual between the new pair.

Step 4: If the better individual is better than the original individual, then the original individual is replaced by the better individual.

Variable neighborhood search is an efficient method for solving combinatorial and global optimization problems whose basic idea is a systematic change of neighborhood both within a descent phase to find a local optimum and in a perturbation phase to get out of the corresponding valley [56].

In a VNS algorithm, a set of neighborhood structures Nk
                        (x), k
                        =1, 2, …, k
                        max in which Nk
                        (x) is the kth neighborhood, is first defined. Then, an initial solution x is found and a stopping criterion is determined. Given the initial solution x, a random point 
                           
                              
                                 
                                    x
                                 
                                 
                                    ′
                                 
                              
                           
                         in Nk
                        (x) is generated. Starting from 
                           
                              
                                 
                                    x
                                 
                                 
                                    ′
                                 
                              
                           
                        , a local search is then performed to generate 
                           
                              
                                 
                                    x
                                 
                                 
                                    ″
                                 
                              
                           
                        . If 
                           
                              
                                 
                                    x
                                 
                                 
                                    ″
                                 
                              
                           
                         is better than the incumbent best solution x, then 
                           
                              x
                              =
                              
                                 
                                    x
                                 
                                 
                                    ″
                                 
                              
                           
                        , and the search returns to N
                        1(x). Otherwise, the search explores the next neighborhood N
                        2(x). This is repeated until k
                        =
                        k
                        max.

The procedure of the basic VNS is described as follows:
                           
                              (1)
                              Generate an initial solution.

Select the set of neighborhood structures Nk
                                 (x), k
                                 =1, 2, …, k
                                 max, that will be used in the search.

Repeat the following until the stopping criterion is met:
                                    
                                       (1)
                                       Set k
                                          ←1;

Until k
                                          =
                                          k
                                          max, repeat the following steps:
                                             
                                                (a)
                                                
                                                   Shaking: Generate a point 
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ′
                                                            
                                                         
                                                      
                                                    at random form the kth neighborhood of 
                                                      
                                                         x
                                                         (
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ′
                                                            
                                                         
                                                         ∈
                                                         
                                                            
                                                               N
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                         (
                                                         x
                                                         )
                                                         )
                                                      
                                                   .


                                                   Local search: Apply some local search method with 
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ′
                                                            
                                                         
                                                      
                                                    as initial solution; denote with 
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ″
                                                            
                                                         
                                                      
                                                    the so obtained local optimum.


                                                   Move or not: If this local optimum is better than the incumbent, move there 
                                                      
                                                         (
                                                         x
                                                         ←
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ″
                                                            
                                                         
                                                         )
                                                      
                                                   , and continue the search with N
                                                   1(x); otherwise, set k
                                                   ←
                                                   k
                                                   +1.

The VNS procedure can be coupled with other procedures in many different ways to improve the performance. In this paper, we adopted a SA as the local search method after shaking procedure to enhance the search capability of VNS. The performance of SA depends on several control parameters: the initial temperature T
                        0, the cooling rate Cr
                         and the final temperature Tf
                         
                        [57]. A standard SA procedure offers the possibility of accepting worse neighbor solutions in a controlled manner in order to escape from local minima. However, worse neighbor solutions are not accepted in our algorithm because we focus on the local search capability of SA. The pseudo-code of VNS in this paper is shown in Fig. 2
                        .

Five kinds of neighborhood structures are selected. These operators are written as Swap, Forward-insert, Backward-insert, Inverse and Adjacent-swap and shown in Fig. 3
                        . The details of these neighborhood structures are as follows:


                        Swap: Choose two different positions from a job permutation randomly and swap them.


                        Forward-insert: Choose two different positions from a job permutation randomly and insert the back one before the front.


                        Backward-insert: Choose two different positions from a job permutation randomly and insert the front one before the back.


                        Inverse: Inverse the subsequence between two different random positions of a job permutation.


                        Adjacent-swap: Choose one position from a job permutation randomly and swap it with the next position of the job permutation. Especially, if the chosen position is the last position of the job permutation, swap it with the first position of the job permutation.

When the algorithm is trapped in local optimum, it is time-consuming to step out of the region. To escape from this situation, we design a re-initialization mechanism. If the best individual of the population is not improved after searching successive 50 generations, we reinitialize the population. The re-initialization strategy is designed as follows: half of the individuals are replaced by the best individual generated in the previous process, and another half are constructed randomly.

The hybrid algorithm must attain a balance between exploration and exploitation. In HTLBO, the main role of TLBO is to explore the searching space, and the general TLBO is modified by introducing the LOV rule to convert the individual to the job permutation. The main role of VNS is to exploit the individual obtained by the global TLBO, and five kinds of neighborhood structures are presented to obtain promising results. The re-initialization mechanism is applied to increase the probability of escaping from the local optimum.

Notations are given before the proposed HTLBO description:
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          NP
                                       
                                       population size
                                    
                                    
                                       
                                          Maxiter
                                       
                                       maximum number of iteration
                                    
                                    
                                       
                                          maxT
                                       
                                       maximum CPU time
                                    
                                    
                                       
                                          CT
                                       
                                       limitation of consecutive generations for solution not improved
                                    
                                    
                                       
                                          count
                                       
                                       record of consecutive generations for solution not improved
                                    
                                    
                                       
                                          Fi
                                          
                                       
                                       the fitness of the ith individual
                                    
                                    
                                       
                                          bestvalue[i]
                                       
                                       the objective function value of the ith generation
                                    
                                 
                              
                           
                        
                     

The pseudo-code of the HTLBO algorithm is shown in Fig. 4
                        .

In this section, parameters of HTLBO are determined by experiments. Performance of HTLBO is evaluated by comparing it with other existing good algorithms for the considered problem.

The parameters of the HTLBO include the size of population NP, the teaching factor TF, the initial temperature T
                        0, the cooling rate Cr
                         and the final temperature Tf
                        . The effect of population size is considerable. The large value of NP would improve the solution quality but increase the CPU time that is not desirable. Initial temperature, final temperatures and cooling rate play important roles in SA algorithm. High initial temperature can extend search scope in initial steps. However, when the final temperature is fixed, the increase of initial temperature will increase the running time of the algorithm. Low final temperature causes the algorithm to make narrow its search scope and find an acceptable solution. As for the cooling scheme, the most commonly used temperature reducing function is i.e. Ti
                        
                        =
                        CrTi
                        
                        −1 in which Cr
                         is a constant. We also adopt this reducing function. Typically, Cr
                         is set between 0.75 and 0.95. The increase of cooling rate can improve the solution quality since more neighborhood solutions have been exploited. At the same time, it is more time-consuming. In this present study, an attempt has been made by considering values both 1 and 2, but no significant difference in the results has been observed. Hence, in order to simplify the algorithm, we take the teaching factor with the value 1 in our HTLBO algorithm.

In this paper, the famous Design of Experiments (DoE) approach is adopted to investigate the best parameter setting for the proposal. The value domains of these parameters are set as: NP∊{20,40,60}, T
                        0∊{1000,5000,10,000}, Cr
                        ∊{0.80,0.85,0.90}, TF
                        ∊{1,2}, Tf
                           
                        =1, respectively. So, there are 2×33
                        =54 combinations totally, all of which are tested. Teaching factor TF
                         is the only parameter in TLBO. TF
                         is generated randomly during the algorithm and can be either 1 or 2, in which 1 corresponds to no increase in the knowledge level and 2 corresponds to complete transfer of knowledge.

HTLBO is implemented in C++ and tested on a PC with Intel Core2 Duo 2.0GHz CPU & 2GB memory. Car1, car2 through to car8 benchmark problems designed by Carlier [58] and Rec01, Rec03 through to Rec41 designed by Reeves and Yamada [33] are considered. Average percentage relative difference (ARPD) is adopted to evaluate the performance.
                           
                              (15)
                              
                                 APRD
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          R
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         (
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               i
                                                            
                                                         
                                                         -
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               best
                                                            
                                                         
                                                         )
                                                         ×
                                                         100
                                                      
                                                      
                                                         
                                                            
                                                               S
                                                            
                                                            
                                                               best
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 R
                              
                           
                        
                     

In Eq. (15), for each instance, Si
                         denotes the solution generated by a given algorithm, R is the number of replications and S
                        best represents the best known solution for the instance. The lower APRD is, the higher the performance is. In the experiment, R
                        =10 and the termination criterion is set as 0.3×
                        m
                        ×
                        n seconds maximum computation time. The experiment results are analyzed by the multi-factor analysis of variance (ANOVA) method. In the experiment, the three main hypotheses (normality, homoscedasticity and independence of the residuals) are checked and accepted. The p-values in the experiment are all close to zero, so analyzing the p-values is useless. Instead, we focus on the F-ratio, which is the ratio between variance explained by a factor and the unexplained variance. The greater the F-ratio is, the more effect the factor has on the response variable. Note that the interactions among more than two factors are not considered, since their F-ratio are quite small. The factor with the greatest F-ratio is first analyzed, followed by the second one, and so on.

The greatest F-ratio corresponds to the factor T
                        0, and the means plot with the Least Significant Difference (LSD) interval (at the 95% confidence level) is given in Fig. 5
                        . Fig. 5 illustrates that HTLBO with T
                        0
                        
                        =
                        10,000 obtains the significantly best performance, while that with T
                        0
                        
                        =
                        100 yields the worst effectiveness.

The factor Cr
                         has the second greatest F-ratio, and the means plot with LSD intervals (at the 95% confidence level) is given in Fig. 6
                        . As we can see from Fig. 6, HTLBO with Cr
                        
                        =0.85 obtains the significantly best performance. HTLBO with a small Cr
                         value generates the worst effectiveness, and the reason lies in that few neighbors are searched.

The third greatest F-ratio corresponds to the factor NP. The means plot with LSD intervals (at the 95% confidence level) is given in Fig. 7
                        . In Fig. 7, it can be seen that HTLBO with NP
                        =40 obtains the significantly best performance. NP
                        =20 yields the worst effectiveness and the reason is that diversity of population is insufficient. If we look closely at the plotted means, we find that the differences in the response variable different NP are low, which supports that our proposed algorithm is robust.

The last factor is TF
                        , and the means plot with LSD intervals (at the 95% confidence level) is given in Fig. 8
                        . As we can see from Fig. 8, there is a clear statistically significant difference between TF
                           
                        =1 and TF
                           
                        =2 schemes and the former results in a better performing HTLBO.

According to the above analysis, all the parameters are selected as follows: NP
                        
                        =
                        40, T
                        0
                        =10,000, Cr
                        
                        =0.85, TF
                        
                        =1, Tf
                        
                        =1.

In this section, we compare TLBO (without local search method), VNS and HTLBO for the PFSP with makespan criterion. For the evaluation, Carlier’s benchmark set [58] and Reeves and Yamada’s benchmark set [33] are used. The computational results and comparisons of TLBO (without local search method), VNS and HTLBO are shown in Table 2
                           . In Table 2, C
                           * denotes the optimal solution of the instances. BPRD denotes the best percentage relative difference. SD denotes the standard deviation.

It is clear from Table 2 that the HTLBO algorithm is the winner, since it finds the best BPRD and APRD values for all of the 29 problems, whereas the TLBO algorithm only generates 8 best BPRD values and 7 best APRD values, and the VNS algorithm yields 18 best BPRD values and 17 best APRD values. The overall mean APRD values yielded by TLBO, VNS and HTLBO algorithms are equal to 2.173%, 0.465% and 0.206%. HTLBO achieves the best performance, which demonstratestheeffectivenessof hybridization. The SD obtained by HTLBO is also lower than the TLBO and VNS algorithms, which justify the robustness of the HTLBO algorithm.

The performance of HTLBO is also compared with other three state-to-art algorithms, i.e. PSOVNS by Tasgetiren et al. [40], QDEA by Zheng and Yamashiro [11]and ODDE by Li and Yin [48]. PSOVNS is a algorithm which hybridize PSO and VNS. QDEA is based on the basic quantum-inspired evolutionary algorithm (QEA) and adopts the differential evolution to perform the updating of quantum gate and variable neighborhood search (VNS) to raise the performance of the local search. ODDE is a hybrid algorithm that combines DE and opposition-based search, the fast local search and pairwise based local search.

The computational results are shown in Table 3
                           . As we can see from Table 3, the BPRD values obtained by HTLBO are better than PSOVNS, QDEA and ODDE for most instances except Rec27, Rec39 and Rec41. The APRD values of HTLBO are also better than PSOVNS, QDEA and ODDE for most instances except Rec39. The overall APRD values yielded by HTLBO is 0.206%, compared to the corresponding values of 1.442%, 0.428% and 0.325% obtained by PSOVNS, ODDE and QDEA, respectively. From the above observations, we can conclude that our HTLBO algorithm is more effective and efficient than PSOVNS, QDEA and ODDE algorithms. In addition, Table 3 shows that the mean SD values resulting from the HTLBO algorithm is smaller than PSOVNS, QDEA and ODDE algorithms, which demonstrate the robustness of the HTLBO algorithm.


                           Table 4
                            reports the two-side Wilcoxon rank sum tests of HTLBO, TLBO, VNS, RSA, QDEA and ODDE algorithms with significance level equal to 5%. In the table, there are two values, i.e., p value and h value. p is the probability of observing the given result by chance if the null hypothesis is true. When h equals 1, it indicates that the results obtained by the two compared algorithms are obviously different. When h equals to 0, it denotes that the difference between the two algorithms is not significant at 5% significant level. From Table 4, we can see that the proposed HTLBO algorithm is significantly different from the other compared algorithms.

To further show the effectiveness of HTLBO, we compare HTLBO with those of the following algorithms over the DMU benchmark sets [5]: RSA proposed by Low et al. [59] and aforementioned ODDE. RSA is a robust simulated annealing algorithm. In RSA, a mechanism that records the good solution’s characteristics is designed and introduced into simulated annealing to make the searching procedure more robust.


                           Table 5
                            shows the computational results and comparisons of the HTLBO with RSA and ODDE in various testing problem size based on DMU problems. The lower bounds and upper bounds for these instances are also provided.

As we can see from Table 5, all of the upper bounds reported by Demirkol et al. [5] are improved. 19 out of the 40 best known solutions provided by RSA and ODDE are further improved by the proposed HTLBO algorithm. Furthermore, the RSA and ODDE algorithms found only 14 (14/40=35%) and 18 (18/40=45%) best known solutions, respectively, while HTLBO obtained 36 (36/40=90%) best known solutions. These results show that the proposed HTLBO algorithm yields better solutions than all of the compared algorithms.


                           Table 6
                            summarizes the average percent relative deviation (APRD) and standard deviation (SD) obtained by RSA, ODDE and HTLBO. The overall APRD values yielded by HTLBO is 0.315%, compared to the corresponding values of 0.827% and 0.698% obtained by RSA and ODDE, respectively. In addition, the mean SD values resulting from the HTLBO algorithm is also smaller than RSA and ODDE algorithms. From the above observations, we can conclude that our HTLBO algorithm outperforms RSA and ODDE algorithms for solving the DMU instances with makespan criterion.


                           Table 7
                            reports the two-side Wilcoxon rank sum tests of HTLBO, RSA and ODDE algorithms with significance level equal to 5%. The computational results show that the proposed HTLBO algorithm is significantly different from RSA and ODDE algorithms.

For the maximum lateness criterion in PFSP, we compared our algorithm with aforementioned ODDE and QDEA. The computational results and comparisons of HTLBO with QDEA and ODDE are listed in Table 8
                           . As shown in Table 8, 88 out of the 120 best known solutions provided by QDEA and ODDE are further improved by the proposed HTLBO algorithm. Furthermore, the QDEA and ODDE algorithms found only and 18 (18/160=11.25%) and 72 (72/160=45%) best known solutions, respectively, while HTLBO obtained 159 (159/160=99.375%) best known solutions.


                           Table 9
                            summarizes the average percent relative deviation (APRD) and standard deviation (SD) obtained by QDEA, ODDE and HTLBO. The overall APRD values yielded by HTLBO is 0.315%, compared to the corresponding values of 0.827% and 0.698% obtained by QDEA and ODDE, respectively. In addition, the mean SD values resulting from the HTLBO algorithm is also smaller than QDEA and ODDE algorithms. These results show that the proposed HTLBO algorithm outperforms all of the compared algorithms when they are applied to solve PFSP with maximum lateness criterion.


                           Table 10
                            reports the two-side Wilcoxon rank sum tests of HTLBO, QDEA and ODDE algorithms with significance level equal to 5%. The computational results show that the proposed HTLBO algorithm is significantly different from QDEA and ODDE algorithms.

This paper proposes a novel hybrid Teaching–Learning-Based Optimization (HTLBO) algorithm to address the permutation flow shop scheduling problem (PFSP) with the makespan and maximum lateness criterion. In order to employ general TLBO to solve PFSP successfully, a LOV rule is used to convert the individual to the job permutation. VNS is combined with TLBO to achieve the balance of diversification and intensification. Furthermore, five kinds of neighborhood structures are introduced in VNS to obtain promising results, and a re-initialization mechanism is designed to increase the probability of escaping from the local optimum.

The computational results and comparisons based on Carlier’s benchmark set and Reeves and Yamada’s benchmark set show the effectiveness of the proposed algorithm. HTLBO is also applied to solve the well-known DMU problems, and compare with the algorithms of the recent literature. For makespan criterion, the HTLBO algorithm has been tested against the other 5 well performing algorithms from the recent literature. For maximum lateness criterion, the HTLBO algorithm has been tested against 2 recent algorithms. The experimental results show that the proposed HTLBO method performs well and is an effective approach for the PFSP with the makespan and maximum lateness criterion. Our algorithm improves the best known solutions for 19 instances with makespan criterion and 88 instances with maximum lateness criterion from the well-known DMU benchmark. The future research directions involve the consideration of multi-objective flow shop and hybrid flow shop scheduling problems.

@&#ACKNOWLEDGMENTS@&#

This research is supported by the State Key Program of National Natural Science of China (Grant No. 51035001), National Science Foundation of China (Grant No. 51275190) and National High Technology Research and Development Program of 863 projects (Grant No. 2012AA040909).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Computational methods for the image segmentation of pigmented skin lesions: A review

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The clinical requirement for the early diagnosis of malignant skin lesions from images is introduced and justified.


                        
                        
                           
                           An up-to-date review about the proposed techniques for the image segmentation of pigmented skin lesions is presented.


                        
                        
                           
                           Additionally, the tasks related to image acquisition and pre-processing are also taken into account.


                        
                        
                           
                           The techniques are introduced, classified, and some examples of their results, are illustrated and discussed.


                        
                        
                           
                           This review is of interest both for researchers and for health professionals.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image acquisition

Image pre-processing

Image segmentation

Pigmented skin lesion images

@&#ABSTRACT@&#


               
               
                  Background and objectives
                  Because skin cancer affects millions of people worldwide, computational methods for the segmentation of pigmented skin lesions in images have been developed in order to assist dermatologists in their diagnosis. This paper aims to present a review of the current methods, and outline a comparative analysis with regards to several of the fundamental steps of image processing, such as image acquisition, pre-processing and segmentation.
               
               
                  Methods
                  Techniques that have been proposed to achieve these tasks were identified and reviewed. As to the image segmentation task, the techniques were classified according to their principle.
               
               
                  Results
                  The techniques employed in each step are explained, and their strengths and weaknesses are identified. In addition, several of the reviewed techniques are applied to macroscopic and dermoscopy images in order to exemplify their results.
               
               
                  Conclusions
                  The image segmentation of skin lesions has been addressed successfully in many studies; however, there is a demand for new methodologies in order to improve the efficiency.
               
            

@&#INTRODUCTION@&#

Pigmented skin lesions, which may be classified as benign or malignant, are mainly caused by an abnormal production of a group of cells in some specific regions. Benign lesions have a more organized behaviour than malignant lesions, since the former do not proliferate into other tissues. Nevus, such as melanocytic, blue, halo, sptiz and dysplastic (Fig. 1a
                     ), and seborrheic keratosis (Fig. 1b), are examples of benign lesions. In the case of malignant lesions, i.e., skin cancer, the cells split quickly, and may invade other parts of the body. Indeed, these cells do not die as generally occurs with normal cells. Skin cancer may be divided into two categories: melanoma (Fig. 1c) and non-melanoma (Fig. 1d). Basal cell carcinoma and squamous cell carcinoma are two examples of non-melanoma skin cancer (NMSC) and are the most common of all skin cancers. Moreover, these types of cancer have a higher chance of cure than melanoma, since they have a reduced capacity to spread (metastasis) to other parts of the body. Melanoma is the most aggressive form of skin cancer and the one with the highest mortality rate due to its high levels of metastasis [2].

Melanoma was the 19th most common cancer worldwide in 2008, with an approximate estimation of 200,000 new cases, and with the highest incidence rate in Australia/New Zealand, Northern America and Northern Europe, and the lowest in South-Central Asia [3]. Table 1
                      presents recent data regarding skin cancer in the United States of America (USA), the United Kingdom (UK) and Brazil, according to gender. In the USA, 76,100 new cases of melanoma were estimated to be diagnosed in 2014 [4]. This estimate does not include NMSC, since this form of skin cancer is not required to be reported to cancer registries. For the same year, 9710 deaths from melanoma were estimated. Another interesting point concerns melanoma incidence rates, which have increased during the last 30 years; for example, the incidence rates from 2006 to 2010 have increased by 2.7% per year. In the UK, melanoma was the 15th most common cancer in 2010, with approximately 12,800 new cases of this disease [3]. As a result, melanoma was the 18th most common cause of death from cancer in the UK. In 2011, there were 2209 deaths from melanoma, and 590 deaths from NMSC in the UK. Of these deaths from melanoma, 59% of the deaths were male patients, and 41% of the deaths were female patients. In Brazil, NMSC will be the most common form of cancer, since approximately 182,000 new cases are estimated in 2014 and 2015 [5]. Although NMSC has a lower mortality rate, it has a higher incidence than melanoma.

Recently, there has been a great interest in the development of computer-aided diagnosis (CAD) systems for the detection and analysis of pigmented skin lesions from images [6–9], which can assist the dermatologist in preventing the development of malignant lesions. Particularly, CAD systems may be used to monitor benign skin lesions, in order to prevent the development of malignancy. Moreover, malignant lesions may be diagnosed at an early stage, during which the patient has a higher probability of cure, and more favourable conditions for being properly treated.

On the other hand, there is also a great interest concerning the image segmentation step of the CAD systems. This step allows for a better representation of the lesion under study, and extraction of its features. Image segmentation has, therefore, a critical role in the effectiveness of the CAD systems. Previous studies [10–15] have shown that computational methods for image segmentation may provide suitable results for the identification of skin lesions in images. Frequently, the images under analysis are pre-processed for image enhancement and artefact removal, so that more robust segmentations may be achieved [16,17]. An overview of lesion border detection methods, which addresses the pre-processing, segmentation and post-processing steps, is presented in Celebi et al. [18]. In addition, the authors also discuss performance evaluation issues and propose guidelines for future studies. However, they primarily focus on dermoscopy images of pigmented skin lesions, and the segmentation methods were classified according to the images to be segmented. In this review, we introduce some of the most relevant solutions that have been developed to assist the diagnosis of skin lesions from images, including those concerning the steps of image acquisition, pre-processing and segmentation. In particular, we comprehensively review the computational techniques that have been suggested for the image segmentation of pigmented skin lesions. In the following sections, these techniques are classified into five classes according to their segmentation principle, specifically, based on edges, thresholding, regions, artificial intelligence techniques, and the ones based on active contours. In addition, several of the reviewed techniques are applied to macroscopic and dermoscopy images, in order to exemplify and discuss their applications.

The paper is organized as follows: in Section 2, a review of the current state-of-the-art concerning the image segmentation of pigmented skin lesions is provided. In addition, smoothing and segmentation results by using several methods are presented. In Section 3, the properties of some of the reviewed computational methods are discussed, and their advantages/disadvantages are identified. Finally, in Section 4, the conclusions of the review and future trends are outlined.

Different non-invasive imaging techniques have been employed to assist dermatologists in the diagnosis of skin lesions. Dermoscopy, photography, confocal scanning laser microscopy (CSLM), optical coherence tomography (OCT), ultrasound, magnetic resonance imaging (MRI), and spectroscopic imaging are examples of these techniques [19–21]. Macroscopic images, commonly known as clinical images [13,22,23], and images acquired by epiluminescence microscopy (ELM), also called dermoscopy or dermatoscopy images [12,14,15,24–27], are normally used in the computational analysis of skin lesions. Fig. 2
                         presents examples of dermoscopy and macroscopic images.

Clinical images are usually obtained using common digital video or image cameras. However, the imaging conditions are frequently inconsistent; for example, images are acquired from variable distances or/and under different illumination conditions. Furthermore, the images may have poor resolution, which may cause complications when the size of the lesion is small. An additional problem with clinical images is related to the presence of artefacts, such as hair, reflections, shadows and skin lines, which may hinder the adequate analysis of the imaged skin lesions.

Essentially, ELM is a non-invasive technique for image acquisition, where the lesion is immersed in oil, and subsequently a dermatoscope device (which includes a specific camera) acquires the images. This technique allows a better visualization of the pigmentation pattern on the skin surface. Besides the non-polarised imaging modality due to the oil immersion, there are two other modalities of ELM that may be used: cross-polarization and transillumination, also called side or epi-transillumination. In these modalities, the images are acquired via a nevoscope device, which allows the acquisition of images with a variable amount of transillumination or cross-polarized surface light. Both modalities highlight the surface pigmentation, but the transillumination modality has the advantage of highlighting the subsurface vasculature and blood flow. However, hairs and air bubbles must be subsequently removed from the images, to allow for a better recognition of the skin lesions.

The image pre-processing step is an important aspect for the effective identification and analysis of pigmented skin lesions in images. As mentioned earlier, the images under analysis may contain several artefacts, such as hairs, reflections, shadows, skin lines and air bubbles, which may affect the accuracy of the image segmentation step. Effective methods based on colour space transformation [28–30], illumination correction [31,32], contrast enhancement [28,29,33,34] and artefact removal [28,35] as a pre-processing step have been proposed in order to improve the segmentation accuracy.

In order to pre-process both macroscopy and dermoscopy images, the original RGB (red, green, blue) colour image may be used. The application may adopt scalar (single channel) or vector (multichannel) processing. In scalar processing, the colour image is converted into a scalar image such as, for example, a grey-level image, or only the blue channel is retained, since the lesions are often more evident in this channel [18]. In vector processing, the original RGB image may be used directly or after conversion to other colour spaces, such as the CIE L*a*b* [29], CIE L*u*v* [6], and HSV (hue, saturation, value) spaces [31]. These colour spaces are commonly used in literature to enhance colour images, since they augment the approximate perceptual uniformity of the image colours. Several pre-processing methods were originally designed for scalar images. However, these methods may also be applied to colour images, for example, by applying the scalar method separately to each colour channel of a given colour space, and then combining the results [36], or adopting methods that deal with vector data [37].

Artefacts due to illumination variation, such as shadows and reflections, may significantly affect the skin lesion segmentation results, specifically in macroscopic images. For shading effect attenuation in macroscopic images, Cavalcanti et al. [31] proposed a method for illumination variation modelling with a quadratic function. This method converts the original RGB image to the HSV colour space, and retains the V channel in order to obtain a higher visibility of the shading effects. The normalized image is obtained by applying, on the HSV image, an estimate of the quadratic function computed from the local illumination intensity in V channel. Afterwards, the normalized image is converted from the HSV colour space back to the RGB colour space, but now with the shading effects significantly attenuated. Colour image segmentation is then performed on this illumination-corrected image, by using the Otsu's thresholding segmentation approach [38]. Recently, Glaister et al. [32] proposed a new multistep illumination modelling method to correct the illumination variation in macroscopic images. This method first determines a nonparametric model of the illumination by using a Monte Carlo sampling method. Then, a parametric quadratic surface model is used to determine the final illumination estimation. Finally, the illumination-corrected image is obtained by using the reflectance component computed from the final estimated illumination.

Another factor that complicates the segmentation of skin lesions, in both macroscopic and dermoscopy images, is the low contrast of the lesions. Celebi et al. [34] presented a method to enhance the contrast in dermoscopy images. The method searches for the optimal weights to convert an original RGB image to the corresponding grey-level image, by maximizing an Otsu's histogram bimodality measure. Recently, Barata et al. [36] used a shades-of-grey method for colour compensation in dermoscopy images. This method only uses image information to estimate the colour of the light source. Morphological filtering [39], which is based on set theory, may also be used to enhance skin lesions in images [40]. For example, one may refer to the work of Beuren et al. [40], where colour morphological filtering is used to enhance the regions of the lesions. Moreover, morphological filtering has been applied in order to include areas with low contrast borders in the detected lesion regions [26,41], and to remove image noise [12,41].

Algorithms for hair removal, in both macroscopic and dermoscopy images, are commonly used in pre-processing steps, since this artefact may considerably affect the detection of the lesion borders. Lee et al. [42] proposed a solution for hair removal, especially thick dark hairs, which is based on one of the first widely adopted methods for hair removal in dermoscopy images, and consists of three main steps: 1) identify the hair location by applying a grey-level morphological operation to the three colour channels of the original RGB image separately, and build the binary hair mask image by using thresholding to divide the image into hair and non-hair regions; 2) replace the values of the detected hair pixels in the original image by the values of the corresponding nearby non-hair pixels; and 3) apply a binary morphological operation and median filter to smooth the thin lines. This method has influenced several other methods for hair detection and removal [43–46].

The presence of hairs in images may also be reduced by the application of image smoothing methods, such as the median and anisotropic diffusion filters, without losing relevant information about the lesions, and, therefore improving the accuracy of the segmentation process. The median filter [47], which is a non-linear image filtering method, has been commonly applied on noisy images showing successful results. Unlike linear filters, such as the average filter [47], this type of filter allows the smoothing of the original image without blurring edges and thin details. The median filter has been often applied to smooth images of skin lesions, as well as to remove artefacts, maintaining the edges of the lesions, which is imperative for an adequate segmentation [6,12,48,49]. To establish the best median filtering mask for the smoothing of skin lesion images, Celebi et al. [48] established a theory, which considers that, for an effective smoothing, the size of the filtering mask should be proportional to the size of the input image. Anisotropic diffusion [50] has also been used for smoothing skin lesion images [17]. This filter is applied iteratively, such that the number of iterations is determined according to the amount of noise presented in the input image. However, relevant edges may be removed when the number of iterations is too large. Improvements have been proposed, in order to enhance the results of the anisotropic diffusion filter. For example, Barcelos et al. [51] proposed an enhancement of the anisotropic diffusion algorithm, originally suggested by Perona and Malik [50]. The improved algorithm not only aims at smoothing very noisy images without removing relevant edges, but also considers the improvements proposed by Alvarez et al. [52] and Nordström [53] to enhance the edges.

The results of the application of the median [47], average [47] and anisotropic diffusion [50] filters to an 256 × 256 pixel image are shown in Fig. 3
                        . A 9 × 9 convolution mask was used in the median and average filtering, since other masks did not lead to a successfully smoothed image with a reduced noise level. Regarding the anisotropic diffusion filter, the smoothing was halted after 150 iterations.

Unlike most methods proposed in literature for reducing the influence of hairs on images of skin lesions, Abbas et al. [16] suggested an effective pre-processing method for the reduction of different artefacts, in both dermoscopy and macroscopic images, and, consequently, a better detection of lesion borders. Essentially, this method consists of three steps: 1) specular reflection reduction by applying homomorphic filtering [54], Fast Fourier Transform (FFT) and high pass filtering, in order to modify the illumination and reflectance, and obtaining, therefore, high contrast skin lesions; 2) the reduction of dermoscopic-gel or air bubble artefacts, based on an adaptive and recursive weighted median filter; and 3) hair, blood vessel and skin line detection and reduction, using a line detection procedure, based on the two-dimensional (2D) derivatives of Gaussian (DOG) [55] and the exemplar-based inpainting technique [56].

Segmentation allows the extraction of the region of interest (ROI) of an image. Bearing in mind that the skin lesion is the ROI in the image under analysis, the segmentation process should not cease until the lesion is fully detached from the image background, or until some other outcome is reached. Some artefacts, such as hairs, reflections, shadows, skin lines and bubbles, may influence the result of the segmentation process, making it a complex computational task. Nonetheless, as mentioned previously, pre-processing techniques may be applied to the original images, with the purpose of facilitating the segmentation process and improving the resultant accuracy.

In general, the segmentation process is based on the discontinuity and similarity of some properties of the ROIs to be segmented [57]. The segmentation methods may be edge-based, i.e., the methods are based on information about the image edges, more specifically, they search for abrupt changes, i.e., discontinuities, in the intensity of the image pixels relative to their neighbours. Edge detectors are the most common examples of such methods. In addition, the segmentation process may depend on similarity criteria, such as similar grey-levels, colours or textures. Thresholding- and region-based segmentation are some examples of methods that use similarity criteria to identify skin lesions in images. Many segmentation methods are originally designed for scalar images. Therefore, several applications are available to convert the original colour image to scalar data [58], for example, grey-level images, pursuing the computational simplicity and convenience of scalar processing. However, in order obtain better segmentation results by using the information contained in all the colour channels of the original images, segmentation methods dedicated to process vector images have been developed [59]. However, this vector image processing is usually more computationally demanding and requires appropriate colour spaces.

In the following sections, we discuss the applicability of some methods commonly used in literature for the segmentation of pigmented skin lesions in images, such as the edge-, thresholding- and region-based methods, and methods based on artificial intelligence (AI) and active contours. Other methods are discussed in Section 3. The reviewed research is summarized in Table 2
                        . Research that combines different methods [10,14,67,71], and that compares segmentation methods [12], is also included in Table 2.

The changes in intensity of the pixels in an image to be segmented may be determined based on the magnitude of the gradient used to detect the edges of the ROI [57]. The Prewitt, Sobel, Roberts, Laplacian [57] and Canny [76] operators are common examples of edge detectors that lead to image segmentation based on edges. According to Sonka et al. [39], edge detectors may only achieve partial image segmentation. Therefore, the application of another segmentation method is needed to improve the final segmentation result. In particular, edge detectors present the following problems [39]: 1) the detection of an edge where no real border exists; 2) the non-detection of an edge where a real border exists; 3) the possibility of generating double edges; and 4) the large sensitivity to image noise.

The edge detector developed by Canny [76] has been applied to skin lesion images [17,60] due to its advantages compared with other edge detectors: 1) it provides good edge detection with a low error probability; 2) it allows a good location of the edge pixels; and 3) it avoids the detection of double edges. First, Canny's algorithm smooths the input image 
                              
                                 f
                                 
                                    (
                                    
                                       x
                                       ,
                                        
                                       y
                                    
                                    )
                                 
                              
                           , performing a convolution with a Gaussian function 
                              
                                 G
                                 
                                    (
                                    
                                       x
                                       ,
                                        
                                       y
                                    
                                    )
                                 
                              
                           :
                              
                                 (1)
                                 
                                    
                                       g
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       =
                                       f
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       ∗
                                       G
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where:
                              
                                 (2)
                                 
                                    
                                       G
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          1
                                          
                                             2
                                             π
                                             
                                                σ
                                                2
                                             
                                          
                                       
                                       
                                          e
                                          
                                             −
                                             
                                                
                                                   
                                                      x
                                                      2
                                                   
                                                   +
                                                   
                                                      y
                                                      2
                                                   
                                                
                                                
                                                   2
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                       ​
                                       ,
                                    
                                 
                              
                           and where 
                              σ
                            is the Gaussian function standard deviation. Then, the gradient magnitude 
                              
                                 M
                                 
                                    (
                                    
                                       x
                                       ,
                                        
                                       y
                                    
                                    )
                                 
                              
                           , and the direction 
                              
                                 α
                                 
                                    (
                                    
                                       x
                                       ,
                                        
                                       y
                                    
                                    )
                                 
                              
                           , at each pixel in the smoothed image 
                              
                                 g
                                 
                                    (
                                    
                                       x
                                       ,
                                        
                                       y
                                    
                                    )
                                 
                              
                           , are computed:
                              
                                 (3)
                                 
                                    
                                       M
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       =
                                       
                                          
                                             
                                                g
                                                x
                                                2
                                             
                                             +
                                             
                                                g
                                                y
                                                2
                                             
                                          
                                       
                                       ,
                                        
                                       and
                                    
                                 
                              
                           
                           
                              
                                 (4)
                                 
                                    
                                       α
                                       
                                          (
                                          
                                             x
                                             ,
                                              
                                             y
                                          
                                          )
                                       
                                       =
                                       t
                                       a
                                       
                                          n
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             
                                                g
                                                x
                                             
                                          
                                          
                                             
                                                g
                                                y
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Subsequently, the non-maximum suppression technique is used to preserve all pixels with local maximum in the gradient image. Afterwards, double thresholding 
                              
                                 
                                    (
                                    
                                       
                                          T
                                          1
                                       
                                       ​
                                       ,
                                        
                                       
                                          T
                                          2
                                       
                                    
                                    )
                                 
                              
                            is established to remove the weak edges. The pixels with a gradient magnitude below the 
                              
                                 
                                    T
                                    1
                                 
                              
                            are considered as weak edges, and the pixels with a gradient magnitude above 
                              
                                 
                                    T
                                    2
                                 
                              
                            are considered as strong edges. Finally, the final edges are defined by all the pixels considered as strong edges or also by the weak pixels that can be connected to any strong pixels.


                           Fig. 4
                            illustrates the segmentation results from application of Canny's edge detector to two skin lesion images [76]. Usually, a median filter [47] is applied before the edge detector in order to smooth the original image and reduce the noise. However, the edges generated by Canny's edge detector are usually not satisfactory. Although the lesions are identified by the detector, the generated edges are discontinuous; thus, the boundaries of the lesions are not fully detected. In addition, there is a large sensitivity to the noise, which generates boundaries that are not part of the lesions.

Barcelos and Pires [17] employed Canny's edge detector after the application of an anisotropic diffusion smoothing filter [51], and the results demonstrated that the unwanted edges were removed. However, some regions of the skin lesions were not included in the detected edge map, and the edges were not completely closed.

The thresholding technique has been commonly used in several skin lesion segmentation methods proposed in literature. This technique is based on the histogram of the input image, which represents the distribution of the image pixels, 
                              
                                 
                                    P
                                    i
                                 
                                 =
                                 
                                    
                                       
                                          n
                                          i
                                       
                                    
                                    /
                                    N
                                 
                              
                           , in terms of each possible intensity level, 
                              
                                 i
                                 =
                                 
                                    [
                                    
                                       1
                                       ,
                                        
                                       2
                                       ,
                                        
                                       …
                                        
                                       ,
                                        
                                        
                                       L
                                    
                                    ]
                                 
                              
                           , where 
                              
                                 
                                    n
                                    i
                                 
                              
                            is the number of pixels for a particular intensity level 
                              i
                           , 
                              N
                            is the total number of pixels of the image, and L is the number of intensity levels. Thus, the thresholding technique entails the selection of one or multiple threshold values to separate the ROIs in the input images.

Among the various techniques proposed in literature to define the threshold value(s), we may cite Otsu's method [38], which has many applications in image segmentation of skin lesion [6,26,29,41,49,61,65]. This method is based on a normalized histogram, built in order to set the optimal threshold value 
                              k
                           , which separates the pixels of the input image into two homogeneous classes 
                              
                                 
                                    (
                                    
                                       
                                          C
                                          0
                                       
                                       ​
                                       ,
                                        
                                       
                                          C
                                          1
                                       
                                    
                                    )
                                 
                              
                           , with minimal variance (
                              
                                 
                                    σ
                                    B
                                    2
                                 
                              
                           ): one class for the ROI, 
                              
                                 
                                    C
                                    0
                                 
                                 =
                                 
                                    [
                                    
                                       1
                                       ,
                                        
                                       2
                                       ,
                                        
                                       …
                                        
                                       ,
                                        
                                       k
                                    
                                    ]
                                 
                              
                           , and the other class for the image background, 
                              
                                 
                                    C
                                    1
                                 
                                 =
                                 
                                    [
                                    
                                       k
                                       +
                                       1
                                       ,
                                        
                                       k
                                       +
                                       2
                                       ,
                                        
                                       …
                                        
                                       ,
                                        
                                       L
                                    
                                    ]
                                 
                              
                           :
                              
                                 (5)
                                 
                                    
                                       
                                          σ
                                          B
                                          2
                                       
                                       =
                                       
                                          ω
                                          0
                                       
                                        
                                       
                                          
                                             
                                                (
                                                
                                                   
                                                      μ
                                                      0
                                                   
                                                   −
                                                   
                                                      μ
                                                      T
                                                   
                                                
                                                )
                                             
                                          
                                          2
                                       
                                       +
                                       
                                          ω
                                          1
                                       
                                        
                                       
                                          
                                             
                                                (
                                                
                                                   
                                                      μ
                                                      1
                                                   
                                                   −
                                                   
                                                      μ
                                                      T
                                                   
                                                
                                                )
                                             
                                          
                                          2
                                       
                                       ​
                                       ,
                                    
                                 
                              
                           
                           
                              
                                 (6)
                                 
                                    
                                       
                                          ω
                                          0
                                       
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             k
                                          
                                          
                                             
                                                P
                                                i
                                             
                                          
                                       
                                       ​
                                       ,
                                        
                                       
                                          ω
                                          1
                                       
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                k
                                                +
                                                1
                                             
                                             L
                                          
                                          
                                             
                                                P
                                                i
                                             
                                          
                                       
                                       ​
                                       ,
                                    
                                 
                              
                           
                           
                              
                                 (7)
                                 
                                    
                                       
                                          μ
                                          0
                                       
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             k
                                          
                                          
                                             
                                                
                                                   i
                                                   
                                                      P
                                                      i
                                                   
                                                
                                                
                                                   
                                                      ω
                                                      0
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                        
                                       
                                          μ
                                          1
                                       
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                k
                                                +
                                                1
                                             
                                             k
                                          
                                          
                                             
                                                
                                                   i
                                                   
                                                      P
                                                      i
                                                   
                                                
                                                
                                                   
                                                      ω
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                        
                                       and
                                    
                                 
                              
                           
                           
                              
                                 (8)
                                 
                                    
                                       
                                          μ
                                          T
                                       
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                k
                                                +
                                                1
                                             
                                             k
                                          
                                          
                                             i
                                             
                                                P
                                                i
                                             
                                          
                                       
                                       ​
                                       ,
                                    
                                 
                              
                           where 
                              
                                 
                                    ω
                                    0
                                 
                              
                            and 
                              
                                 
                                    ω
                                    1
                                 
                              
                            are the probabilities, and 
                              
                                 
                                    μ
                                    0
                                 
                              
                            and 
                              
                                 
                                    μ
                                    1
                                 
                              
                            the means of the classes 
                              
                                 
                                    C
                                    0
                                 
                              
                            and 
                              
                                 
                                    C
                                    1
                                 
                              
                           , respectively. Thus, 
                              
                                 
                                    μ
                                    T
                                 
                              
                            is the total mean of the intensities of the input image. Fig. 5
                            presents the segmentation results after the application of Otsu's method [38] to dermoscopy and a macroscopic images. A median filter [47] was employed before the segmentation step, to reduce the noise in the original images. Although several lesion boundaries are correctly detected, several other regions, such as edges with low contrast, are not identified as part of the lesions. Furthermore, this edge detector is very sensitive to artefacts and, therefore, because of reflections, some interior regions of the lesions are wrongly identified as belonging to the lesions.

Otsu's method has revealed some problems, such as: (1) the segmented lesions tend to be smaller than they are in reality; and (2) it may lead to very irregular lesion edges. Yuksel and Borlu [14] proposed a method using the type-2 fuzzy logic technique [77] to solve such problems, which automatically determines the threshold value to segment dermoscopy images. This technique exhibits good performance in dealing with fuzzy values, by determining whether a specific image intensity level belongs to lesion regions or belongs to the background skin. Alcón et al. [23] proposed an improved thresholding technique to overcome some issues of Otsu's method. In the proposed algorithm, the threshold is defined by finding the average value between the means of both background and lesion probability distributions. Cavalcanti et al. [31] and Gómez et al. [72] suggested building projections of the original RGB colour space, where they were able to properly apply Otsu's method. A thresholding method based on the Renyi's entropy [78] has also been applied to define the desired threshold value, leading to segmentations that preserve the geometry and shape of the lesions [40]. Another technique to define the threshold value is indicated by Xu et al. [69], which considers the average intensity of the strongest gradient pixels in the input image. Threshold selection by an iterative [33,67,68] or an adaptive [12,66] process has also been adopted to segment skin lesions in images. The fusion of the results provided by the ensemble of thresholding methods results in another segmentation technique based on thresholding [24].

The region growing algorithm [79], splitting and merging operations [80], and the Mumford–Shah method [81] are examples of region-based techniques that have been used to segment skin lesion images. The region growing algorithm consists in grouping similar neighbouring pixels, or in grouping sub-regions, into larger homogeneous regions according to a growing criterion. For example, in a given region of an image, pixels with similar properties, such as grey-level, colour or texture, are grouped together [6,7]. The splitting and merging operations are region-based techniques applied to group similar regions [10,12]. Thus, the same intensity is attributed to all input pixels that have similar intensity, in agreement with the grouping criterion. On the other hand, the Mumford–Shah method divides the original image into several regions 
                              
                                 
                                    Ω
                                    i
                                 
                                 =
                                 
                                    Ω
                                    1
                                 
                                 ∪
                                 
                                    Ω
                                    2
                                 
                                 ∪
                                 …
                                 ∪
                                 
                                    Ω
                                    n
                                 
                                 ∪
                                 k
                              
                           , where 
                              k
                            is the boundary between them, merging the close regions by analysing their pixel intensities. This technique is based on an energy functional 
                              
                                 E
                                 
                                    (
                                    k
                                    )
                                 
                              
                           , calculated as:
                              
                                 (9)
                                 
                                    
                                       E
                                       
                                          (
                                          k
                                          )
                                       
                                       =
                                       
                                          
                                             ∑
                                             i
                                          
                                          
                                             
                                                
                                                   
                                                      ∬
                                                      
                                                         
                                                            Ω
                                                            i
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               |
                                                               
                                                                  
                                                                     |
                                                                     
                                                                        u
                                                                        −
                                                                        
                                                                           c
                                                                           i
                                                                        
                                                                     
                                                                     |
                                                                  
                                                               
                                                               |
                                                            
                                                         
                                                         2
                                                      
                                                      d
                                                      x
                                                       
                                                      d
                                                      y
                                                   
                                                
                                             
                                          
                                       
                                       +
                                       ⋋
                                       l
                                       
                                          (
                                          k
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where 
                              u
                            is a constant function into each image region 
                              
                                 
                                    Ω
                                    i
                                 
                              
                           , 
                              
                                 
                                    c
                                    i
                                 
                                 =
                                 mean
                                 
                                    (
                                    u
                                    )
                                 
                              
                           , 
                              
                                 d
                                 x
                              
                            and 
                              
                                 d
                                 y
                              
                            are the differentials of 
                              x
                            and 
                              y
                           , 
                              ⋋
                            is a parameter that is incremented at each iteration, and 
                              
                                 l
                                 
                                    (
                                    k
                                    )
                                 
                              
                            is the total length of the regions at each iteration.

The active contour model without edges [82] is based on the Mumford–Shah method and has been used in the image segmentation of skin lesions [12,16]. Examples of the results obtained by the Mumford–Shah method applied to skin lesion images are presented in Fig. 6
                           . The method was employed on two images that were previously smoothed using the median filter [47]. Observation of the resultant images shows that the lesions are completed identified, including the lesion regions with considerable colour variation. However, some regions are erroneously identified as belonging to the lesions due to image artefacts.

Castillejos et al. [70], Celebi et al. [48] and Ganzeli et al. [60] employed the statistical region merging (SRM) algorithm [83] to detect the edges in images of skin lesions. This algorithm is a technique developed to segment colour images based on region growing and merging. Simplicity, computational efficiency and excellent performance are the main advantages reported for the SRM algorithm. Image quantization and colour space transformation steps that are commonly applied to the original images before their segmentation are unnecessary when this algorithm is used to segment skin lesion images.

A method to segment skin lesion images through iterative stochastic region merging has been proposed by Wong et al. [13] based on the SRM algorithm [83]: each image pixel is assigned to a single region, which is subsequently merged with other regions in a stochastic way, based on a probability function of region fusion. This process is characterized by a multi-path refining of the results in order to achieve the best final segmentation. This method has been shown to be robust to image artefacts and to perform successfully in cases where several skin lesions, structural lesion variations, varying illuminations and colour variations are present in the input images. In addition, it achieves successful segmentation in cases where there is low contrast between the lesion and the skin background near the lesion boundaries.

Techniques based on artificial intelligence (AI) have also been proposed for the image segmentation of skin lesions, in which the image pixels are classified as belonging to the ROIs or to the background of the images. Neural networks, evolutionary computation and fuzzy logic are some examples of these techniques, which aim at performing similar tasks to humans, based on learning, natural evolution and human reasoning. These techniques may be combined among themselves, or with other traditional image processing techniques, in order to improve segmentation performance.

Artificial neural networks (ANNs) [84], which are parallel distributed systems composed of simple processing units with the purpose of obtaining similar results to the human brain, have been applied to segment images with skin lesions [33,68]. The segmentation performance of ANNs may be improved through the application of Genetic Algorithms (GAs) [85], which are computational techniques for searching and optimization. GAs are based on natural evolution and biological genetics, with the aim of finding the best solution for a given problem; for example, GAs may be employed to optimize ANN parameters.

Roberts and Claridge [11] presented a method to segment skin lesion images through Genetic Programming (GP) [86], which is a technique based on natural evolution to solveproblems following the concepts of genetic algorithms. The proposed method consists in creating a random population of programmes from the function and terminal sets. The function set is built from the image processing operations, such as image thresholding, morphological operations, edge detection and merging. The terminal set is built from information in the input image, such as the intensity and coordinate values of the pixels. This method showed good generalization with a very small set of training samples. Furthermore, the system learns by example, thus increasing the amount of problems in which it is applicable. However, this method has some disadvantages regarding the complexity of its implementation, and the presence of unnecessary steps, which is computationally demanding.

Fuzzy logic deals with uncertain and imprecise values. Many algorithms based on fuzzy logic have been proposed to segment skin lesions in images [10,12,14,27,67,71]. This method allows the representation of intermediate values within an interval; in other words, the input data is qualitatively analysed (linguistic values). Frequently, the fuzzy method is applied together with other segmentation techniques. In Maeda et al. [10] and Silveira et al. [12], the fuzzy method, combined with both splitting and merging techniques, was used to segment dermoscopy images. This combination, originally proposed by Maeda et al. [87,88], generates an algorithm for the unsupervised perceptual segmentation of natural colour images using a fuzzy-based homogeneity measure, which performs the fusion of colour and texture features. The algorithm includes four steps: simple splitting, local merging, global merging and boundary refinement.

The fuzzy method was also used to define a threshold value from fuzzy intensity, by applying the type-2 fuzzy logic technique [77]; the idea was to determine whether a specific intensity belongs to the ROI or to the image background [14]. Another method, named neuro-fuzzy approach [71], combines fuzzy logic with neural networks to segment dermatological images. In addition, fuzzy logic, combined with clustering techniques, has been employed in the image segmentation of skin lesions, e.g., the fuzzy c-means (FCM) algorithm [27,67,70]. The basic idea behind the FCM algorithm is to find the centre of each cluster, similarly to the traditional k-means algorithm. Nevertheless, this process is more flexible, since partial membership may be introduced in the clusters. For each iteration of FCM, the minimization of the objective function 
                              F
                            is computed as:
                              
                                 (10)
                                 
                                    
                                       F
                                       =
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   C
                                                
                                                
                                                   
                                                      μ
                                                      
                                                         i
                                                         j
                                                      
                                                      k
                                                   
                                                   
                                                      
                                                         
                                                            ‖
                                                            
                                                               
                                                                  x
                                                                  i
                                                               
                                                               −
                                                               
                                                                  c
                                                                  j
                                                               
                                                            
                                                            ‖
                                                         
                                                      
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                       ​
                                       ,
                                    
                                 
                              
                           
                           
                              
                                 (11)
                                 
                                    
                                       
                                          μ
                                          
                                             i
                                             j
                                          
                                       
                                       =
                                       
                                          1
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      m
                                                      =
                                                      1
                                                   
                                                   C
                                                
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            
                                                               
                                                                  ‖
                                                                  
                                                                     
                                                                        x
                                                                        i
                                                                     
                                                                     −
                                                                     
                                                                        c
                                                                        j
                                                                     
                                                                  
                                                                  ‖
                                                               
                                                            
                                                            
                                                               
                                                                  
                                                                     
                                                                        ‖
                                                                        
                                                                           
                                                                              x
                                                                              i
                                                                           
                                                                           −
                                                                           
                                                                              c
                                                                              m
                                                                           
                                                                        
                                                                        ‖
                                                                     
                                                                  
                                                                  
                                                                     
                                                                        2
                                                                        /
                                                                        
                                                                           
                                                                              (
                                                                              
                                                                                 k
                                                                                 −
                                                                                 1
                                                                              
                                                                              )
                                                                           
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                        
                                       and
                                    
                                 
                              
                           
                           
                              
                                 (12)
                                 
                                    
                                       
                                          c
                                          j
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   
                                                      μ
                                                      
                                                         i
                                                         j
                                                      
                                                      k
                                                   
                                                   
                                                      x
                                                      i
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   
                                                      μ
                                                      
                                                         i
                                                         j
                                                      
                                                      k
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           where 
                              N
                            is the number of pixels in the input image, 
                              C
                            is the number of defined clusters, 
                              
                                 
                                    c
                                    j
                                 
                              
                            is the centre of each cluster 
                              j
                           , 
                              
                                 
                                    μ
                                    
                                       i
                                       j
                                    
                                 
                              
                            is the degree of membership for the pixels 
                              
                                 
                                    x
                                    i
                                 
                              
                            in cluster 
                              j
                           , and 
                              k
                            is a coefficient that defines the fuzziness of the resulting clusters. The term 
                              
                                 
                                    ‖
                                    
                                       
                                          x
                                          i
                                       
                                       −
                                       
                                          c
                                          j
                                       
                                    
                                    ‖
                                 
                              
                            is used to measure the similarity of the pixels to the centre 
                              
                                 
                                    c
                                    j
                                 
                              
                            of a given cluster 
                              j
                           .


                           Fig. 7
                            presents the segmentation results obtained by applying the fuzzy c-means method to two images, which have been previously smoothed by applying the median filter [47]. Two clusters were defined with the initial mean intensities of 8 and 250. Using these parameters, the resultant images demonstrate that the lesions are successfully segmented. However, some lesion pixels with low contrast are not clustered into the lesion groups.

Zhou et al. [27] proposed a new mean shift approach, based on the FCM algorithm, called the anisotropic mean shift algorithm (AMSFCM), to segment dermoscopic images. The AMSFCM algorithm [89] is more effective than the FCM algorithm, and requires less computational time than the traditional mean shift technique. Furthermore, it provides superior segmentation results. Mean shift-based techniques [90] allow the estimation of local density gradients of similar pixels by using radially symmetric kernels. However, these kernels may not adequately deal with the presence of irregular structures and noise in the input image. On the other hand, the AMSFCM algorithm provides improved performance in these cases, since it uses an anisotropic kernel. Castillejos et al. [70] proposed a cluster pre-selection algorithm based on the FCM algorithm (CPSFCM) in order to use fuzzy logic to automatically determine the optimal number of clusters based on the input image data such as the intensity values.

Algorithms based on active contours have been used for segmenting skin lesion images [12,15,16,28,64]. In these algorithms, the initial curves move towards the boundaries of the objects of interest through appropriate deformation. A deformable model may be classified as parametric [91–93] or geometric [59,82,94–96], according to the technique used to track the curve movement.

Parametric models include the traditional active contour models, namely, snake models [92]. Typically, in these models, the curve deformation is guided by energy forces, in which an internal energy determines the smoothness level by the definition of the curve's elasticity and rigidity; in other words, it controls the degree of shrinkage or expansion of the model curve in order to avoid over-deformations. An external energy is also included in the models, which has the function of driving the curve to the desired boundary. This energy may be defined by the user or through an automatic process. Image-based energies may also be defined which drive the curve towards interesting image features, such as those based on image intensity, gradient, line segments and corners. However, these models have some limitations [82,93]: 1) the curve initialization must be near the object's boundary; 2) the models have difficulty in dealing with boundaries with large curvatures; 3) the stop criterion of the curve deformation usually depends on the image gradient, which may cause bad edge localization when the gradient value is not high enough; and 4) these models have difficulty in dealing with topological changes during the curve evolution.

The gradient vector flow (GVF) [93] is another parametric model that has been used in the segmentation of skin lesions [12,15,63]. Xu and Prince [93] proposed a new external energy for the active contour models, which is computed by a linear partial differential equation, and extends the gradient vectors at the image edges to the whole image. The goal of the new model was to overcome some of the main problems of the traditional snake model, in particular, the curve initialization and the convergence onto boundary regions with large curvature. On the other hand, Zhou et al. [15], Zhou et al. [74] and Zhou et al. [73] proposed a new type of dynamic energy for the segmentation of skin lesions that combines the classical GVF model [93] and the mean shift algorithm [97]. This algorithm was designed to find the most similar edges to the true boundaries by calculating the distance between the centroid of the curve and the true boundary of the object of interest. Thus, the curve evolution towards the ROI is generated by the gradient vector flow as well as by the mean shift of the pixels contained within the curve. This combination makes the model versatile, because the successful calculation of the image-based energies is guaranteed, even in very noisy images.

Geometric models are characterized by the topological changes that the curve may experience during the segmentation process, and are less dependent on the initial curve conditions. Level set method [94] and active contour model without edges, known as Chan–Vese's model [82], are such examples of geometric models. The level set method was originally proposed by Osher and Sethian [94] to handle topological changes during the curve evolution, which is one of the limitations of the traditional parametric models. The curve evolution is implicitly tracked by a level set function, which allows the easy identification of a pixel: whether an image pixel is located inside, outside or on the curve. The geometric properties of the curve may be easily computed by the level set function.

The active contour model without edges proposed by Chan and Vese [82] is based on the average of the intensities of the image pixels, and not on the image gradient. Therefore, the model uses the concepts of the Mumford–Shah [81] and Level Set [94] segmentation techniques. Essentially, Chan–Vese's model considers a “fitting” term 
                              F
                            for the energy minimization, which is calculated by means of an energy functional based on the level set function, 
                              ϕ
                           , to identify whether the object of interest is inside or outside the curve, 
                              C
                           . The minimization of the energy function 
                              
                                 F
                                 
                                    (
                                    
                                       
                                          c
                                          1
                                       
                                       ​
                                       ,
                                        
                                       
                                          c
                                          2
                                       
                                       ​
                                       ,
                                        
                                       ϕ
                                    
                                    )
                                 
                              
                            allows the deformation of the curve towards the boundary of the object, where the inside and outside intensities are constant and similar:
                              
                                 (13)
                                 
                                    
                                       
                                          
                                             
                                             F
                                             
                                                (
                                                
                                                   
                                                      c
                                                      1
                                                   
                                                   ​
                                                   ,
                                                    
                                                   
                                                      c
                                                      2
                                                   
                                                   ​
                                                   ,
                                                    
                                                   ϕ
                                                
                                                )
                                             
                                             =
                                             
                                             μ
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      δ
                                                      
                                                         (
                                                         
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      
                                                         |
                                                         
                                                            ∇
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         |
                                                      
                                                      d
                                                      x
                                                       
                                                      d
                                                      y
                                                   
                                                
                                             
                                             +
                                             ν
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      H
                                                      
                                                         (
                                                         
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      d
                                                      x
                                                       
                                                      d
                                                      y
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                              
                                             +
                                              
                                             
                                                ⋋
                                                1
                                             
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               |
                                                               
                                                                  
                                                                     u
                                                                     0
                                                                  
                                                                   
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        ,
                                                                         
                                                                        y
                                                                     
                                                                     )
                                                                  
                                                                  −
                                                                  
                                                                     c
                                                                     1
                                                                  
                                                               
                                                               |
                                                            
                                                         
                                                         2
                                                      
                                                      H
                                                      
                                                         (
                                                         
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      d
                                                      x
                                                       
                                                      d
                                                      y
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                              
                                             +
                                              
                                             
                                                ⋋
                                                2
                                             
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               |
                                                               
                                                                  
                                                                     u
                                                                     0
                                                                  
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        ,
                                                                         
                                                                        y
                                                                     
                                                                     )
                                                                  
                                                                  −
                                                                  
                                                                     c
                                                                     2
                                                                  
                                                               
                                                               |
                                                            
                                                         
                                                         2
                                                      
                                                       
                                                      
                                                         (
                                                         
                                                            1
                                                            −
                                                            H
                                                            
                                                               (
                                                               
                                                                  ϕ
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        ,
                                                                         
                                                                        y
                                                                     
                                                                     )
                                                                  
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      d
                                                      x
                                                       
                                                      d
                                                      y
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    u
                                    0
                                 
                              
                            is a pre-processed image, as a bounded function on 
                              
                                 Ω
                                 ¯
                              
                            and with real values. The fixed parameters 
                              μ
                           , 
                              
                                 ν
                                 ≥
                                 0
                              
                           , 
                              
                                 
                                    ⋋
                                    1
                                 
                              
                            and 
                              
                                 
                                    ⋋
                                    2
                                 
                                 >
                                 0
                              
                            are weights for the fitting term. The terms 
                              H
                            and 
                              δ
                            are the Heaviside and Dirac delta functions, respectively. The constants 
                              
                                 
                                    c
                                    1
                                 
                              
                            and 
                              
                                 
                                    c
                                    2
                                 
                              
                           , which are based on Mumford–Shah's segmentation model, are the average image 
                              
                                 
                                    u
                                    0
                                 
                              
                            inside and outside the curve 
                              C
                           , respectively, and given by:
                              
                                 (14)
                                 
                                    
                                       
                                          c
                                          1
                                       
                                        
                                       
                                          (
                                          ϕ
                                          )
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      
                                                         u
                                                         0
                                                      
                                                       
                                                      
                                                         (
                                                         
                                                            x
                                                            ,
                                                             
                                                            y
                                                         
                                                         )
                                                      
                                                      H
                                                      
                                                         (
                                                         
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      dxdy
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      H
                                                      
                                                         (
                                                         
                                                            ϕ
                                                            
                                                               (
                                                               
                                                                  x
                                                                  ,
                                                                   
                                                                  y
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      dxdy
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                        
                                       and
                                    
                                 
                              
                           
                           
                              
                                 (15)
                                 
                                    
                                       
                                          c
                                          2
                                       
                                        
                                       
                                          (
                                          ϕ
                                          )
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      
                                                         u
                                                         0
                                                      
                                                       
                                                      
                                                         (
                                                         
                                                            x
                                                            ,
                                                             
                                                            y
                                                         
                                                         )
                                                      
                                                      
                                                         (
                                                         
                                                            1
                                                            −
                                                            H
                                                            
                                                               (
                                                               
                                                                  ϕ
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        ,
                                                                         
                                                                        y
                                                                     
                                                                     )
                                                                  
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      dxdy
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∫
                                                      Ω
                                                   
                                                   
                                                      
                                                         (
                                                         
                                                            1
                                                            −
                                                            H
                                                            
                                                               (
                                                               
                                                                  ϕ
                                                                  
                                                                     (
                                                                     
                                                                        x
                                                                        ,
                                                                         
                                                                        y
                                                                     
                                                                     )
                                                                  
                                                               
                                                               )
                                                            
                                                         
                                                         )
                                                      
                                                      dxdy
                                                   
                                                
                                             
                                          
                                       
                                        
                                       .
                                    
                                 
                              
                           
                        

Chan–Vese's model has been used in the segmentation of skin lesions in images [12,16,65] due to its advantages when compared with other segmentation techniques based on the active contour model [82], such as: 1) the initial curve may be defined more freely in the image; 2) the inner contours are automatically detected without the need to introduce a second curve in the image; 3) the object detection is carried out even in the presence of varying intensities, very smooth boundaries and where the boundaries may not be successfully defined by the gradient, a situation which is not effectively handled by the traditional active contour model; and 4) it provides effective detection of object boundaries even on noisy images, without the necessity to previously smooth the original images.


                           Fig. 8
                            presents the segmentation results obtained by applying the traditional Chan–Vese's model [82] to two images, which were previously smoothed using a median filter [47]. The segmentation process was halted when the edges were on the lesion boundaries, or when the maximum number of iterations was reached. From the resultant images, one may confirm that this model has provided good segmentation results, having identified low contrast boundaries and overcome the image noise.

Abbas et al. [28] proposed an improved, perceptually-oriented region-based active contour (RAC) scheme [98], where the segmentation concept is based on Chan–Vese's model [82] to determine the edges of the lesion to be segmented. The authors suggested this model due to its ability to simultaneously define multiple regions, separate heterogeneous objects, successfully deal with image noise, and because of the automatic convergence of the modelled curve.

@&#DISCUSSION@&#

In general, the segmentation results are post-processed in order to improve the accuracy of the obtained lesion edges. In many cases, morphological filters are used to smooth the edges, to remove the isolated regions and/or even to fill the interior of the segmented lesion regions [12,26,27,41,48,67]. The final contours obtained for the lesions may be compared with ground truths defined by one or more specialists. Additionally, the accuracy of the edge detection results may be measured using statistical metrics in order to estimate the associated precision and recall, sensitivity and specificity, error probability and operation exclusive disjunction (XOR) [29,49,99]. The accuracy of the segmentation depends on the model and techniques used to solve the problem. Fig. 9
                      illustrates the distribution of the methods reviewed in this article, according to the applied principle, which have been developed to segment pigmented skin lesions in images.

Threshold-based techniques have been widely used, mainly because of their simplicity, computational efficiency and good performance. The wide use of techniques based on AI is justified by the advantages it offers, such as the possibility of learning from sample cases provided by the ANNs, the search and optimization for the best segmentation results provided by algorithms based on GAs, and the capability to deal with imprecise values that are provided by fuzzy logic. Algorithms based on the active contour model have also been frequently proposed for the segmentation of skin lesions. Nevertheless, parametric models have difficulty in dealing with topological changes and large curvatures. On the other hand, geometric models do not present such problems, but their computational complexity may be prohibitive. Region-based methods have also been used, since such methods have shown successful performance even in the presence of several obstacles, such as illumination and colour variation. Usually, edge-based segmentation techniques are not applied independently, since these techniques may not completely identify the edges of the lesions, which is imperative in the analysis of skin lesions in images.

Clustering algorithms have also been applied to segment skin lesion images [44,70,72]. For example, the k-means clustering algorithm is used by Castillejos et al. [70]. The authors present a novel approach to segment the images based on the wavelet transform for k-means, FCM and CPSFCM algorithms. The proposed methods achieved superior results when compared with techniques that did not apply the wavelet transform. The hill-climbing algorithm (HCA) is a technique based on the clustering of points on an image, which is also applied to detect the ROIs of skin lesion images [29]. This algorithm takes an image and the number of histogram bins in each dimension as input parameters, and returns a labelled image, whereas in the traditional k-means algorithm, the numbers of clusters (k) are specified manually by the users. Image segmentation based on such a technique relies on a simple, fast and non-parametric algorithm. In Abbas et al. [58] and Abbas et al. [75], a new segmentation method based on dynamic programming was proposed in order to overcome the limitation of thresholding, region-growing and clustering, as well as level set-based segmentation methods. This method is a general optimization solution, with good edge-based segmentation capabilities, its ability to solve for local minima or overlapping problems, its computational efficiency, and its excellent performance in detecting lesion borders in dermoscopy images. The combination of different methods have also been adopted to improve the final result of the image segmentation process, such as finding the approximate location of lesion, and automatically defining the initial contours, mainly to be used with the active contour model [7,63,68].


                     Table 3
                      allows the performance comparison of the methods reviewed to segment both macroscopic and dermoscopy images of skin lesions, which are mostly performed automatically. The segmentation results are compared against the ground-truth defined by one or more specialists, or their quality has been visually assessed. The table indicates the number and type of image used, the colour spaces and channels employed in the pre-processing and segmentation steps, and the values of the evaluation measures.

In order to obtain enhanced segmentation results, both from dermoscopy and macroscopic images, pre-processing methods, such as colour space transformation, illumination correction, contrast enhancement and artefact removal, have been used. The median filter [47] and anisotropic diffusion filter [51] are usually applied to smooth images in order to reduce the noise. Nonetheless, these filters cannot deal with some obstacles, such as illumination variation and very thick dark hair. Algorithms based on hair detection and repair, for example, based on inpainting techniques, have been used for hair removal [43].These enhance the lesions, which can lead to important improvements, and, therefore, favourably affect the diagnosis.

With regards to the segmentation step, edge-based techniques are not suggested for segment skin lesions, since these techniques may produce segmentations with edges that are not completely closed. On the other hand, thresholding-, region-, and AI-based segmentation techniques may completely identify the lesions in the images. However, lesion boundaries with low contrast are generally not detected by such techniques. Moreover, these techniques are susceptible to image artefacts. Other techniques based on entropy or fuzzy logic [14,40], to define the threshold value, may sometimes achieve superior segmentation results. The region-based approach proposed by Wong et al. [13] has a better segmentation performance even in the presence of boundaries with low contrast. In addition, such a method can tackle structural variations, varying illumination and colour variations. Other techniques have also been suggested to convert the FCM segmentation method into a more effective approach for segmenting skin lesions in images [27]. Using these methods, better segmentation results may be achieved even in the presence of irregular lesions and image noise. Active contour models [82] are a good option for the segmentation of skin lesions, since these models can adequately deal with varying intensities, low contrast boundaries and noisy images. Nevertheless, these models also have disadvantages; for example, the segmentation result depends on the suitability of the initial curve.

@&#CONCLUSIONS@&#

Image segmentation is an important step for the effective computational diagnosis of pigmented skin lesions in images. Skin lesion diagnosis is an area of increased interest due both to the importance of prevention and to early diagnosis of skin cancer. Although the image segmentation of skin lesions has been addressed in several studies and successful applications, there is the potential to develop new methodologies and to improve the performance of existing methods. Here, we have presented a review about current methods that have been proposed to segment skin lesions. Additionally, we have introduced techniques used to acquire and pre-process images, with a focus on their subsequent segmentation.

From the presented review, one may conclude that dermoscopy images should be more commonly used in the computational diagnosis of skin lesions, since these images present less artefacts and more detailed features, which may lead to more adequate lesion segmentation and analysis. Nevertheless, techniques to remove or reduce the artefacts are usually necessary to obtain robust segmentation results.

The reviewed segmentation techniques were classified into: edge-, thresholding-, region-, AI- and active contour-based and other categories. We have presented and discussed results obtained with some of these techniques applied to dermoscopy and macroscopic images of skin lesions. Active contour models can provide good results on images with colour variation and low contrast of the lesion boundaries. Therefore, such models are a good option for the segmentation of skin lesions. However, other methods with improvements, or in combination with other techniques, may also provide good lesion detections.

In conclusion, the future trends regarding the image segmentation of skin lesions are to search for superior accuracy in terms of the detection of the lesion edges, as well as to take into account other issues in the development of computational solutions, such as computational performance, automaticity level, image noise smoothing and removal, and image enhancement.

@&#ACKNOWLEDGEMENTS@&#

The first author would like to thank the “Conselho Nacional de Desenvolvimento Científico e Tecnológico” (CNPq), in Brazil, for her PhD grant. This work is funded by the European Regional Development Funds (ERDF) through the Operational Programme “Thematic Factors of Competitiveness” (COMPETE) and Portuguese Funds through the “Fundação para a Ciência e a Tecnologia” (FCT), under the project: FCOMP-01-0124-FEDER 028160/PTDC/BBB- BMD/3088/2012.

@&#REFERENCES@&#


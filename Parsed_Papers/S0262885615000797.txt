@&#MAIN-TITLE@&#RSILC: Rotation- and Scale-Invariant, Line-based Color-aware descriptor

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new rotation- and scale-invariant line-based color-aware descriptor is introduced.


                        
                        
                           
                           The descriptor captures both local (texture, color) and global (inter-line spatial) information.


                        
                        
                           
                           Experiments show that proposed descriptor is robust to rotation, scale, and illumination.


                        
                        
                           
                           The descriptor is compared to the well-known descriptors.


                        
                        
                           
                           The proposed descriptor is more accurate on matching line-rich objects such as faces.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image descriptor

Local features

Spatial features

Rotation invariance

Scale invariance

Color aware

@&#ABSTRACT@&#


               
               
                  Modern appearance-based object recognition systems typically involve feature/descriptor extraction and matching stages. The extracted descriptors are expected to be robust to illumination changes and to reasonable (rigid or affine) image/object transformations. Some descriptors work well for general object matching, but gray-scale key-point-based methods may be suboptimal for matching line-rich color scenes/objects such as cars, buildings, and faces. We present a Rotation- and Scale-Invariant, Line-based Color-aware descriptor (RSILC), which allows matching of objects/scenes in terms of their key-lines, line-region properties, and line spatial arrangements. An important special application is face matching, since face characteristics are best captured by lines/curves. We tested RSILC performance on publicly available datasets and compared it with other descriptors. Our experiments show that RSILC is more accurate in line-rich object description than other well-known generic object descriptors.
               
            

@&#INTRODUCTION@&#

Feature matching is an essential component of many modern computer vision applications, including near-duplicate detection [1], stereo correspondence [2], 3D modeling [3], image stitching [4], as well as face alignment and matching [5–7]. Scene and object matching methods in digital images can be roughly divided in the following major groups by the density of the image features they extract and use:
                        dense
                        
                           descriptor methods [8–10] tend to use all image information and often assume that all pixels in the image are equally important. Hence, they may be computationally expensive and require a high degree of correlation between the probe and gallery images. Typically, such methods are not very accurate given large variations in object pose, scale, and illumination.

descriptor methods use non-dense image features (e.g., edges [11]) and/or various key-spots [12–14]. They are relatively robust to variations in pose, size, orientation, and lighting of the query image with respect to the objects in the gallery. They provide a sparse representation for objects and high-speed matching on the key locations that need to be automatically determined, which calls for some sort of a saliency map [15].

This implicit methodology division prompted some well-performing hybrid techniques that include features from both categories and typically fuse them in a weighted features ensemble [16–18], optimized for a particular application [19].

In content-based image retrieval, object detection, and face recognition (FR) in an unconstrained environment (typically outside of the studio), sparse descriptors are generally preferred because they are often more robust to deformations and lighting variations than dense feature methods. Key-spot-based matching involves detecting the key-spots, building local descriptors for each key-spot, and finding an aggregate distance of best matches. For pose- and lighting-robust matching, the descriptors should be robust to geometrical variations such as translation, rotation, scaling (and if possible to affine/projective transformations and photometric variations such as illumination direction, intensity, colors, and highlights. The selection of a robust key-spot (e.g., a point, a line, or a corner) depends on the image collection and the application.

In generic object matching, the coarse features from key-points may be adequate to find suitable matches. However, in line-rich scenes, some dominant lines on objects may provide more stable and discriminative features than key-points. Such line-rich scenes and objects are omnipresent and can be natural (e.g., landscapes, plants, animals, humans) or artificial (e.g., cities, cars, house exteriors and interiors, office spaces). Stable (but not necessarily rigid) characteristic lines in them can be used as good key-spot candidates, promising a more stable object matching ability than key-points can.

Human face matching/recognition (FM/FR) is an important special case of object matching that has been an active research and development area in academia and industry because of the wide variety of real-world applications, such as surveillance, visual authentication, human–machine interface, criminal identification, and commercial applications. It identifies individuals from face images or video sequences using computer vision and machine learning algorithms. The general procedure for the appearance-based face image retrieval (FIR) systems consists of detecting the faces, extracting the facial information, and comparing a query face descriptor with those in a database [7,20–24].

To deal with the variation in face appearance (e.g., unknown head poses, unexpected facial expressions, and unpredictable lighting), the extracted features are expected to be robust to illumination changes, distortion, and scaling. One can certainly use key-point-based descriptors (e.g., SIFT [12], SURF [13], ORB [14], but because faces are line-rich objects, it may be beneficial to introduce the notion of key-lines and their descriptors for better matching.

According to psychophysics and neuroscience studies, line-rich features, such as face outline, eyes, mouth, and hair, are most important for perceiving and remembering faces [25] by humans. Another study has investigated the importance of facial features for automatic face recognition [26] by extracting facial landmarks. Experimental results indicate that these facial features are indeed important for face identification. Several other studies [6,11,27] showed that the most informative face characteristics appear to come from the face lines that can model face features in a very intuitive, human-perceptible form.

Consider the face images shown in Fig. 1
                     .a–b. The prominent characteristic parts are marked by lines/curves, whose local regions and their spatial arrangements on a face can be used for robust matching. The human-perceptible important face lines overlap very well with the machine-computed edge maps of the faces on the CalTech set [28], whose cumulative distribution is also shown. The lines are mostly located on the prominent face characteristics (landmarks such as eye, mouth, nose, and face shape), which are the discriminative locations of a face (Fig. 1.c.). All these studies and illustrations indicate that lines with their descriptors can provide more stable recognition features for face matching.

We propose a general-purpose key-line descriptor that is color aware, invariant to rotation/scale, and is robust to illumination changes. To increase the discriminative power of the descriptor, we combined color/texture information of the local regions and added the relational information of the other key-lines. We tested our descriptor matching power on publicly available datasets containing unconstrained images of faces and general objects. We compared the new descriptor to well-known descriptors (in the same test-bed system), and our experimental results show that the RSILC descriptor is robust to rotation, scale, reflection and illumination and produces more accurate matches in face and object retrieval applications.

Many different techniques for modeling local image regions have been developed. Scale-Invariant Feature Transform (SIFT) [12,29] is one of the most robust key-point descriptors among the local feature descriptors with respect to different geometrical changes [30]. It detects notable and stable key-points for images at different resolutions and produces scale- and rotation-invariant descriptors for robust matching. Several papers have been published on SIFT-based face recognition [31–33]. Although SIFT originally was designed for gray-scale images, there are several extensions to make use of the color information in the descriptors [34–36]. One of the successful attempts is colored SIFT (CSIFT) [36] which embeds the color information through the gradient of color invariants instead of using gray-scale gradients as in conventional SIFT. Defining the descriptor in color space makes the descriptor more robust with respect to color variations.

Another well-known key-point descriptor is Speeded Up Robust Features (SURF), which provides a quicker way to detect key-points and compute descriptors that are rotation and scale invariant as well as robust to illumination changes [37]. SURF is less accurate than SIFT, but it has been successfully used in many practical applications, including face/components matching [38,39].

The mentioned key-point descriptors (e.g. SIFT and SURF), being robust to various affine transformations and lighting, are widely used for object detection and recognition. However, they typically contain information that is local to their key-points, which prompts some false-positive correspondences when performing many-to-many matches. This problem could be remedied by considering key-point spatial relationships, (e.g., having each descriptor record other key-points' azimuth angles much like shape context [40]), hence capturing not only local context of each key-spot but also their global spatial relationships. Knowing the usefulness of spatial relations in image understanding [41,42], several state-of-the-art methods have been reported together with the use of application-dependent local features. For example, the authors in [43,44] integrate spatial distribution of key-points by using shape context with texture features for food classification. In a similar fashion, spatial relations between the visual primitives (such as circles and corners) are integrated with statistical shape features for graphics recognition [45].

The Pyramid of Histograms of Orientation Gradients (PHOG) descriptor represents an image by its local shape and the spatial layout of shape information [46]. The local shape is modeled by a histogram of edge orientations. The spatial layout is represented by tiling the image into the regions at multiple resolutions. The final descriptor vector is the concatenation of histograms at each resolution. The descriptor is robust to scaling as long as the object position and orientation remain the same, but it is rotation dependent and color-blind.

As an alternative to key-points, another important set of features for object matching can be collected from edges, which provide the advantages of a lesser demand on the storage space and a lower sensitivity to illumination changes. Gao and Leung [11] describe a face recognition method using line edge maps (LEMs). The system extracts the lines from the edge map of face images and compares their similarity using the Hausdorff distance. LEM produces fast and reliable matching on aligned faces but does not use the region around the lines, which contains intensity information that helps to discriminate the lines and reduce mismatches. Gao and Qi [47] extend the LEM approach by considering corner points along the edge lines and show their method's robustness to scale as well as the superior one-image-per-person retrieval capability compared to the eigenfaces [48]. Deboeverie et al. [6] combined the curve edge map with the relative positions and intensity information around the curves. This system uses the orientation of the main axis of the curve segments for the first match. Then, it considers the histograms of inner and outer sides of the curve and relative positions of curve segments to refine the matching stage. However, this method lacks color information for the local regions.

Liu et al. [16] propose SIFT flow to align an image to its nearest neighbors in a photo gallery. This hybrid method matches densely sampled, pixel-wise SIFT features between two images while preserving (sparse) spatial discontinuities, matching a query object located at different parts of the scene. Experiments show that the proposed approach robustly aligns complex scene pairs containing significant spatial differences. The applications include single image motion field prediction/synthesis via object transfer, satellite image registration, and face recognition.

Motivated by the discriminative ability of (sparse) shape information and (dense) local patterns in object recognition, Nguyen et al. [17] propose a window-based (hybrid) object descriptor that integrates both cues: contour templates representing object shape are used to derive a set of key-points at which local appearance features are extracted. The key-points are located via template matching that uses both spatial and orientation information. An object descriptor is formed by concatenating the non-redundant local binary pattern (NR-LBP) features from all key-points to encode the shape as well as the appearance of the object. The experimental results suggest that the proposed descriptor can effectively describe non-rigid articulated objects and improve the detection rate compared to other state-of-the-art object descriptors.

Satpathy et al. [18] propose two sets of edge-texture features for object recognition: Discriminative Robust Local Binary Pattern (DRLBP) and Ternary Pattern (DRLTP). These hybrid features fuse edge (sparse) and texture (dense) information in a single representation, and they appear to be robust to image variations caused by intensity inversion and discriminative to the image structures within the histogram block, as demonstrated by experiments on seven datasets.

Some recent papers present an interesting approach to line-rich scene matching [49,50]. This approach works with gray-scale images and uses rotation- and scale-invariant key-lines and log-polar descriptors. The authors described their promising methodology, giving a few examples with line-rich scenes but showing no large-scale experiments. The approach is quite similar to ours. Therefore, we highlight the major differences, as RSILC: 1) uses color information in the chroma bands of YCbCr
                      color space, 2) uses local gradients histogram from the equalized intensity band, and 3) uses spatial information across all key-lines to make descriptor matching more accurate.

Computing our key-line descriptor involves: 1) extracting key-lines by applying oriented line filters to the image edge maps, and 2) sampling the line direction oriented circular histograms around each key-line, including both local (texture, color) and global (inter-line spatial) information.

To extract key-lines from the studied image, we use convolution of line filters with an edge image, as reported in [49,50]. Formally, the whole process is composed of constructing line filters in different orientations and their convolution with an edge image. A set of line filters in a normal Gaussian 1D distribution are defined, which are oriented in different directions in the range [0, π). In generic form, we can express such a set as 
                           F
                           =
                           
                              
                                 F
                                 θ
                              
                           
                           ,
                           
                           
                              θ
                              k
                           
                           =
                           
                              
                                 k
                                 π
                              
                              6
                           
                           
                           and
                           
                           k
                           =
                           0
                           ,
                           
                           1
                           ,
                           …
                           ,
                           5
                        , where θ
                        
                           k
                         represents an orientation value associated with a specific filter F. In Fig. 2
                        , line filters that are oriented in six different directions are shown. These line filters F
                        
                           θ
                         are then convolved with an edge image I
                        
                           E
                         obtained via Canny edge detector [51]. The convolution results in a set of key-lines from each line filter. Considering a set 
                           F
                         of line filters, the complete set 
                           L
                         of extracted key-lines can be expressed as
                           
                              (1)
                              
                                 L
                                 =
                                 
                                    F
                                    θ
                                 
                                 *
                                 
                                    I
                                    E
                                 
                                 
                                 ∀
                                 θ
                                 ∈
                                 [
                                 0
                                 ,
                                 
                                 π
                                 )
                                 =
                                 
                                    
                                       
                                          <
                                          l
                                          i
                                          n
                                          
                                             e
                                             
                                                θ
                                                ,
                                                l
                                             
                                          
                                          >
                                       
                                    
                                    
                                       l
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       L
                                    
                                 
                                 ,
                              
                           
                        where each extracted key-line carries its orientation value θ (that is associated with its line filter) and the total number of key-lines L that varies from one image to another. Note that small lines can be considered as noise and omitted. Fig. 3
                         shows key-lines that are extracted from a face image.

In this section, we describe how key-line features are computed to include both local and relational features. Local features are computed independently while relational features take other key-lines into account. We model each key-line with a circle of radius r. Fig. 4
                         shows the circles corresponding to key-lines from face images with different poses. Because the size of the radius uses the length of the key-line, circle sizes vary. Given a complete circle, we sub-divide it into equal sectors 
                           
                              s
                              i
                           
                           ∈
                           S
                        . For each sector, local and relational features are computed and concatenated to build a key-line descriptor.

Each key-line is represented by gradient and color features that characterize the local texture and intensity distribution in every sector of the associated circle. For intensity information, YCbCr
                            color space is used, which is robust to illumination changes and perceptually uniform compared to other color spaces [52]. The normalized Y-band is used to compute the gradient direction and gradient magnitude at each pixel. The color information is calculated from each color band (CB) separately. For each sector si
                           , feature histograms are computed as follows,
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                h
                                                
                                                   s
                                                   i
                                                
                                                
                                                   
                                                      ∇
                                                      I
                                                   
                                                
                                             
                                             
                                             =
                                             
                                             hist
                                             
                                                
                                                   |
                                                   ∇
                                                   I
                                                   |
                                                   
                                                      
                                                      
                                                         s
                                                         i
                                                      
                                                      p
                                                   
                                                
                                             
                                             ,
                                             
                                             ∀
                                             
                                             p
                                             ∈
                                             
                                                s
                                                i
                                             
                                             ,
                                          
                                       
                                       
                                          
                                             
                                                h
                                                
                                                   s
                                                   i
                                                
                                                
                                                   ψ
                                                   
                                                      
                                                         ∇
                                                         I
                                                      
                                                   
                                                
                                             
                                             
                                             =
                                             
                                             hist
                                             
                                                
                                                   ψ
                                                   
                                                      
                                                         
                                                            ∇
                                                            I
                                                         
                                                      
                                                      
                                                         s
                                                         i
                                                      
                                                      p
                                                   
                                                
                                             
                                             ,
                                             
                                             ∀
                                             
                                             p
                                             ∈
                                             
                                                s
                                                i
                                             
                                             ,
                                          
                                       
                                       
                                          
                                             
                                                h
                                                
                                                   s
                                                   i
                                                
                                                
                                                   C
                                                   B
                                                
                                             
                                             
                                             =
                                             
                                             hist
                                             
                                                
                                                   I
                                                   
                                                      p
                                                   
                                                
                                             
                                             ,
                                             
                                             ∀
                                             
                                             p
                                             ∈
                                             
                                                s
                                                i
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           where hist(★) is the histogram function and populates the values ★ into bins; 
                              
                                 
                                    
                                       ∇
                                       I
                                    
                                 
                                 
                                    s
                                    i
                                 
                                 p
                              
                              
                              =
                              
                              
                                 
                                    
                                       
                                          
                                             
                                                ∂
                                                I
                                                
                                                   p
                                                
                                             
                                             
                                                ∂
                                                x
                                             
                                          
                                       
                                       2
                                    
                                    +
                                    
                                       
                                          
                                             
                                                ∂
                                                I
                                                
                                                   p
                                                
                                             
                                             
                                                ∂
                                                y
                                             
                                          
                                       
                                       2
                                    
                                 
                              
                            is the gradient magnitude; 
                              ψ
                              
                                 
                                    
                                       ∇
                                       I
                                    
                                 
                                 
                                    s
                                    i
                                 
                                 p
                              
                              =
                              atan
                              
                                 
                                    
                                       
                                          ∂
                                          I
                                          
                                             p
                                          
                                       
                                       
                                          ∂
                                          y
                                       
                                    
                                    /
                                    
                                       
                                          ∂
                                          I
                                          
                                             p
                                          
                                       
                                       
                                          ∂
                                          x
                                       
                                    
                                 
                              
                            is the gradient direction; 
                              
                                 
                                    ∂
                                    I
                                    
                                       p
                                    
                                 
                                 
                                    ∂
                                    ★
                                 
                              
                            is the gradient component in ★ direction; and p
                           ={x,
                           y} is the image pixel. To maintain the rotation invariance of 
                              
                                 h
                                 
                                    s
                                    i
                                 
                                 
                                    ψ
                                    
                                       
                                          ∇
                                          I
                                       
                                    
                                 
                              
                           , the gradient angles are normalized with respect to the key-line orientation before the histogram computation. With the three separate histograms for color bands viz. Y, Cb
                           , and Cr
                           , the complete feature histogram in any particular sector can be expressed by concatenating them, 
                              
                                 H
                                 
                                    l
                                    o
                                    
                                       c
                                       
                                          s
                                          i
                                       
                                    
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          h
                                          
                                             s
                                             i
                                          
                                          
                                             
                                                ∇
                                                I
                                             
                                          
                                       
                                    
                                    
                                       
                                          h
                                          
                                             s
                                             i
                                          
                                          
                                             ψ
                                             
                                                
                                                   ∇
                                                   I
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          h
                                          
                                             s
                                             i
                                          
                                          Y
                                       
                                    
                                    
                                       
                                          h
                                          
                                             s
                                             i
                                          
                                          
                                             C
                                             b
                                          
                                       
                                    
                                    
                                       h
                                       
                                          s
                                          i
                                       
                                       
                                          C
                                          r
                                       
                                    
                                 
                              
                           . Considering all sectors in the specified circle for any key-line l, the complete local feature histogram can be expressed by concatenating them,
                              
                                 (3)
                                 
                                    
                                       F
                                       
                                          l
                                          o
                                          c
                                       
                                       l
                                    
                                    
                                    =
                                    
                                    
                                       
                                          
                                             
                                                H
                                                
                                                   l
                                                   o
                                                   
                                                      c
                                                      
                                                         s
                                                         1
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                H
                                                
                                                   l
                                                   o
                                                   
                                                      c
                                                      
                                                         s
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             …
                                          
                                          
                                             H
                                             
                                                l
                                                o
                                                
                                                   c
                                                   
                                                      s
                                                      N
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Such a concatenation of local feature histograms is more discriminant than the feature histogram computed from the whole circle at once [49,50].

To satisfy the rotation-invariant property, we follow counterclockwise histogram concatenation, which starts from the reference key-line orientation defined in Eq. (1). Fig. 5
                            shows a graphical illustration of rotation-invariance property of the descriptor. In this example, we have eight sectors where concatenation starts from the orientation angle of that particular reference key-line. Starting from the orientation angle of the key-line provides dynamic change in the sector indexing. As a consequence, the feature vector after concatenation remains the same for all key-lines in Fig. 5.a. In Section 3.3, real-world examples are considered to confirm the rotation-invariant property.

Alone, local features for each key-line do not offer information about spatial organization of the remaining key-lines. This may cause some false matches. As an example, a key-line associated with the right eye of the query image could be matched with the key-line associated with the left eye of the database image. Therefore, relational information is incorporated to the local feature histograms in each sector. Consider a sector s of a reference key-line l. We define two features to compute the relationships between the key-lines: orientation angle differences between l and the other key-lines l′∈
                           s
                           
                              i
                           , and the presence of key-lines in that sector s
                           
                              i
                            with respect to l.

The orientation angle difference Δθ between l and l′ can be computed as Δθ
                           =|θ
                           −
                           θ′|∀
                           l′∈
                           s. Based on this, a histogram can be computed as
                              
                                 (4)
                                 
                                    
                                       h
                                       
                                          s
                                          i
                                       
                                       
                                          Δ
                                          θ
                                       
                                    
                                    =
                                    hist
                                    
                                       
                                          
                                             θ
                                             −
                                             
                                                θ
                                                ′
                                             
                                          
                                       
                                    
                                    )
                                    .
                                 
                              
                           where hist(★) is the histogram function and populates the values ★ into bins; the number of bins is defined as 
                              
                                 
                                    k
                                    π
                                 
                                 6
                              
                            and k
                           =[0,…,5].

Additionally, the presence of key-lines is computed by taking the proportion of key-lines l′ that are visible from l in s
                           
                              i
                           . To make the descriptor more discriminant, we further sub-divide s
                           
                              i
                            into annular sectors a
                           ∈
                           s
                           
                              i
                            and compute the histogram,
                              
                                 (5)
                                 
                                    
                                       h
                                       
                                          s
                                          i
                                       
                                       
                                          #
                                          
                                             l
                                             ′
                                          
                                       
                                    
                                    =
                                    hist
                                    
                                       
                                          #
                                          
                                             l
                                             ′
                                          
                                       
                                    
                                    )
                                    ∀
                                    
                                    
                                       l
                                       ′
                                    
                                    ∈
                                    
                                       s
                                       i
                                    
                                    ,
                                 
                              
                           where hist(★) is the histogram function and populates the values ★ into bins; the number of bins is {a
                           
                              j
                           }
                              j
                              =1,…,4 and the size of the annular sector depends on the radius r of the circle belonging to the reference key-line.

In both relational features, histograms are normalized by using the total number of key-lines that appear in that sector. To graphically illustrate the relational feature histograms, we refer to Fig. 6
                           . In one particular sector s
                           
                              i
                           , both histograms are concatenated to build the relational histogram 
                              
                                 H
                                 
                                    r
                                    e
                                    
                                       l
                                       
                                          s
                                          i
                                       
                                    
                                 
                              
                              =
                              
                              
                                 
                                    
                                       h
                                       
                                          s
                                          i
                                       
                                       
                                          Δ
                                          θ
                                       
                                    
                                    
                                       
                                          h
                                          
                                             s
                                             i
                                          
                                          
                                             #
                                             
                                                l
                                                ′
                                             
                                          
                                       
                                    
                                 
                              
                           . Considering all sectors for a single key-line l, the complete relational feature can be computed by concatenating all histograms,
                              
                                 (6)
                                 
                                    
                                       F
                                       
                                          r
                                          e
                                          l
                                       
                                       l
                                    
                                    =
                                    
                                       
                                          
                                             
                                                H
                                                
                                                   r
                                                   e
                                                   
                                                      l
                                                      
                                                         s
                                                         1
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                                H
                                                
                                                   r
                                                   e
                                                   
                                                      l
                                                      
                                                         s
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             …
                                          
                                          
                                             H
                                             
                                                r
                                                e
                                                
                                                   l
                                                   
                                                      s
                                                      N
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Like the local histograms, to satisfy the property of rotation invariance, concatenation follows exactly similar sector indexing.

RSILC descriptor is designed to be rotation and scale invariant. To show these properties, we take example images as shown in Fig. 7
                        . Example key-line locations are shown on straight, rotated, and re-scaled faces. For illustration purposes, we use a single key-line to build an RSILC descriptor (cf. Section 3.2). Histograms (both local and relational) from all sectors inside the circle are concatenated in a counterclockwise fashion, where the starting point is indexed by the reference key-line orientation angle. To maintain the scale invariance property, the reference key-line is modeled with a circle (cf. Fig. 5). The radius of circle is computed by using key-line length that varies with image size. Fig. 8
                         shows the corresponding 1D feature vector of example images. The overlapping of feature vectors (histogram distributions) from the mouth regions of up-right and rotated faces as well as from the eye regions of up-right and scaled faces show that RSILC is rotation and scale invariant.

Following our feature description in Sections 3.2.1 and 3.2.2, a line-rich image I can be described with a descriptor of line features
                        
                           (7)
                           
                              d
                              s
                              c
                              =
                              
                                 
                                    
                                       F
                                       l
                                    
                                 
                                 
                                    l
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    L
                                 
                              
                           
                        
                     where F
                     
                        l
                     
                     =[F
                     
                        loc
                     
                     
                        l
                     ,
                     F
                     
                        rel
                     
                     
                        l
                     ], as in Eqs. (3) and (6), and L is the number of key-lines in the descriptor. To match descriptors from two different images dsc
                     1 and dsc
                     2, a symmetric distance function is defined as the average norm of left and right best match scores vectors (BMSV) mij
                     
                     
                        
                           (8)
                           
                              dist
                              
                                 
                                    d
                                    s
                                    
                                       c
                                       1
                                    
                                    ,
                                    
                                    d
                                    s
                                    
                                       c
                                       2
                                    
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             m
                                             12
                                          
                                          |
                                          |
                                          +
                                          |
                                          |
                                          
                                             m
                                             21
                                          
                                       
                                    
                                 
                              
                              /
                              2
                           
                        
                     
                     
                        
                           (9)
                           
                              
                                 m
                                 
                                    i
                                    j
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          min
                                          
                                             l
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             
                                                L
                                                j
                                             
                                          
                                       
                                       diff
                                       
                                          
                                             
                                                F
                                                i
                                                k
                                             
                                             ,
                                             
                                             
                                                F
                                                j
                                                l
                                             
                                          
                                       
                                    
                                 
                                 
                                    k
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    
                                       L
                                       i
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (10)
                           
                              diff
                              
                                 
                                    
                                       F
                                       i
                                       k
                                    
                                    ,
                                    
                                    
                                       F
                                       j
                                       l
                                    
                                 
                              
                              =
                              
                              |
                              |
                              
                                 F
                                 i
                                 k
                              
                              −
                              
                                 F
                                 j
                                 l
                              
                              |
                              |
                           
                        
                     where i,
                     j
                     ∈{1,2}, m
                     
                        ij
                      are the BMSV and L
                     
                        i
                        =1,2 is the number of individual line features in each descriptor. Note that one has to compute two BMSV (left and right) to satisfy the distance symmetry requirement. In our experiments, we found that in some applications (e.g., matching faces), it may be sufficient to compute just one half of the match (e.g., left BMSV) without much loss in the accuracy. This makes our distance non-symmetric but cuts matching time by approximately half. These time savings can be used for ensuring RSILC invariance to image reflection (a feature that most key-point descriptors lack, e.g., SIFT and SURF) by redefining
                        
                           (11)
                           
                              diff
                              
                                 
                                    
                                       F
                                       1
                                       k
                                    
                                    ,
                                    
                                    
                                       F
                                       2
                                       l
                                    
                                 
                              
                              =
                              min
                              
                                 
                                    
                                       
                                          
                                             F
                                             1
                                             k
                                          
                                          −
                                          
                                             F
                                             2
                                             l
                                          
                                          |
                                          |
                                          ,
                                          |
                                          |
                                          
                                             F
                                             1
                                             k
                                          
                                          −
                                          
                                             
                                                F
                                                ^
                                             
                                             2
                                             l
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (12)
                           
                              
                                 F
                                 ^
                              
                              =
                              
                                 
                                    
                                       F
                                       
                                          i
                                          =
                                          
                                             
                                                
                                                   n
                                                   2
                                                
                                                +
                                                1
                                             
                                          
                                          ,
                                          …
                                          ,
                                          n
                                       
                                    
                                    ,
                                    
                                    
                                       F
                                       
                                          j
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          
                                             n
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           F
                           ^
                        
                      is a half-swapped feature vector (of even length n) computed to ensure the mirror flip matching invariance of the key-line descriptor; this effectively rotates the histogram sectors by the angle of π about the center of the key-line. One can skip the extra half-swap histogram match if the key-line orientation span is extended to the [0,2π] range (e.g., by computing the major intensity gradient direction at the line center), then diff can again be computed as in Eq. (10).

Although there certainly may be other descriptor matching methods, ours is consistent with most matching methods in the literature. Given a relatively small number of key-lines (compared to number of key-points) in a typical image and a good discriminative power of RSILC, we did not need to remove any outliers or perform descriptors cross-check.

@&#EXPERIMENTS@&#

We design a set of experiments to evaluate the proposed descriptor. We first measure the retrieval performance of the descriptor on several face and generic datasets. We compare its performance with several other well-known descriptors on the same test-bed system. We also measure the performance change of descriptors to illumination variations and geometric transformations.

We test the performance of the descriptors on a test-bed system that extracts the descriptor of the query image and compares it with the descriptors of database images. For this task, we follow a leave-one-out approach by selecting one face as a query image and comparing it with the remaining images. According to the similarity measure, the top-k most similar images are listed as candidate matches. A hit-match is counted if the candidate object belongs to the same class of the query image. We define the hit rate for the top-k matches as
                           
                              (13)
                              
                                 HitRate
                                 
                                    k
                                 
                                 =
                                 
                                    
                                       HitCount
                                       
                                          
                                             k
                                             ,
                                             
                                             Q
                                          
                                       
                                    
                                    
                                       Q
                                    
                                 
                                 ,
                              
                           
                        where 
                           Q
                         represents a set of query image, HitCount(,) is a function that counts the successful top-k matches using the query set of size 
                           |
                           Q
                           |
                        .

Descriptor performances are measured using the following public datasets. Fig. 9
                         shows examples from these datasets.
                           
                              The CalTech Faces set [28] consists of 450 frontal views of 29 people which are taken under varying lighting, expressions and complex background conditions.

The Indian Faces set [53] consists of frontal and left/right profile faces with varying facial expressions of 61 individuals under varying lighting conditions.

The ColorFERET set [54] consists of 2,413 facial images from 856 individuals with frontal and left/right profile faces, with/without glasses and with various facial expressions. In our experiment, a subset of the ColorFERET dataset is created with 500 images from 101 individuals.

The Labeled Faces in Wild (LFW) set [55] consists of celebrity faces collected from the Internet. The faces are captured in completely uncontrolled environments. Therefore, faces have large pose, illumination, expression, and facial hair variations. Some of them contain partial occlusions by glasses, mustaches, or hats.

The Amsterdam Library of Object Images (ALOI) set [56] is a generic object set that contains a large number of objects under different illumination directions and different viewpoints.

Before measuring the retrieval performance of the descriptor, we investigate the effects of descriptor parameters to the matching performance. Our goal is to select parameters that yield optimal performances for both hit rate and execution time. We vary the parameters and conduct the matching experiments on the CalTech and Indian faces datasets.

The line filters are convolved with edge image to extract the key-lines (cf. Section 3.1). Increasing the filter size increases the computation time of the key-line extraction stage because of the convolution operation. To measure the performance of the descriptor with different line filter sizes, we set the size as k×k where k
                           =9, 11, 13, 15. We found that larger filters do not have a significant impact on hit rate. Therefore, in the experiments, we use 9×9 filters, which is also adequate to model all key-line orientations.

Each key-line is modeled with a circle of radius r (cf. Section 3.2). We set the radius as r
                           =
                           k
                           ×
                           L, where k
                           =1/2, 2/3, 3/4, 1, and L is the length of the key-line. We found that r
                           =2
                           L/3 is adequate to characterize the local texture and intensity information around the key-line.

To model the spatial information, we sub-divide the key-line circle into equal sectors and build the descriptor by concatenating the histograms of each sector. The number of sectors inside the circle is set to s, where s
                           =4, 8, 12, 16. We found that s
                           =8 is adequate to model the spatial layout for the reported size of image.

In Eq. (2), the values inside the key-line circle are populated into bins. To observe the effect of the number of bins to descriptor discriminability, we set the bin size as b
                           =4, 8, 12, 16 and repeat the matching test. We found that b
                           =8 is best for the CalTech set, because retrieval performance decreases with a higher number of bins. However, for the Indian set (slightly larger images), we observed a higher hit rate with b
                           =16.

The graphs in Fig. 10
                            show the hit rates with respect to different parameter values. The parameter values used in the experiments are summarized in Table 1
                           . Some of these parameters (e.g., Gaussian filter σ for Canny edge detection) vary with image size. Therefore, we also reported the average size of the test images.

One of the important stability measurements for a descriptor is its repeatability in terms of detected key-spot locations. To measure the repeatability, we follow similar test manner as in [29]. Each test image is (i) rotated in the range [π/6) in π/6 intervals; (ii) re-scaled 1/2, 3/2, and 2 times the original size; and (iii) flipped in mirror-side or upside-down. Then, we extract the key-lines on the test image and on the transformed image. We expect that the key-lines are located at similar positions in the transformed image. Therefore, we compute where each key-line in the test image should appear in the transformed image by applying the same transformation to the key-lines in the test image. If the transformed key-line on the test image is LT
                         and the extracted key-line on the transformed image is LE
                        , then the location accuracy of key-lines is computed with the Euclidean distance of the center coordinates of each LT
                         and LE
                         with the following equation:
                           
                              (14)
                              
                                 
                                    
                                       d
                                       =
                                       
                                    
                                 
                                 
                                    
                                       
                                          C
                                          
                                             L
                                             E
                                          
                                       
                                       −
                                       
                                          C
                                          
                                             L
                                             T
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              C
                              
                                 L
                                 E
                              
                           
                         is the center coordinates of LE
                         and 
                           
                              C
                              
                                 L
                                 T
                              
                           
                         is the center coordinates of LT
                        . d
                        <∈ means that LE
                         and LT
                         are ∈-close, and their regions overlap. The repeatability is the percentage of overlapped key-lines. We measure the repeatability on the CalTech set with several different transformations. The graphs in Fig. 11
                         show the repeatability of the key-line locations. Each point in the graph corresponds to repeatability score of one image. The color of the points indicates the applied transformation. The x-axis is the image number on the CalTech set in which there are 450 face images. The y-axis shows the repeatability score. The median repeatability levels for the CalTech set are shown as color-coded solid lines. Experiment results show that RSILC is most invariant to mirror flip transformation, followed by rotation and scale transformation.

We compare the proposed descriptor with well-known baseline descriptors. We measure the performance of all descriptors with their best parameters on the same dataset and test-bed system (cf. Section 5.1). The baseline descriptors we compare ours to are as follows:
                           
                              SIFT [12,29] is a well-known key-point descriptor that extracts the key-point in scale-space and models the region around the key-point with the statistics of gradient information. It is invariant to scale and rotation transformations and partially robust to illumination. The conventional SIFT descriptor does not use color information.

SURF [37], similar to SIFT, uses the distribution of gradient information for each key-point. The descriptor has smaller dimensions than SIFT, therefore, has relatively faster computation. It is invariant to scale and rotation and robust to lighting variations. It does not contain color information.

CSIFT [36] embeds the color information in conventional SIFT descriptor [29] through the gradient of color invariants instead of gray-scale gradients. Our experiments indicate that CSIFT is more successful than other descriptors at matching due to addition of color information.

PHOG [46] descriptor represents the image by its local and the spatial layout of the shape information. The local shape is represented by histogram of edge orientations; and spatial layout is represented by tiling the image into regions at multiple resolutions. The final descriptor vector is concatenation of histograms at each resolution. It is robust to scaling as long as the object position and orientation remain the same. However, it is not rotation invariant and does not use color information.

LEM [11] is the only key-line descriptor among the comparison descriptors. Modeling with lines reduces the storage requirement and sensitivity to illumination change. However, ignoring the texture information of objects could decrease the matching performance. In the experiments, we use face matching system with LEMs [11], which extract the lines from the edge map of faces and compare the lines using Hausdorff distance. This basic system performs as well as more advanced face matching techniques, but it is not designed for geometric transformation variances.

@&#RESULTS@&#

The bar graphs in Fig. 12
                            summarize the hit rate (%) of each descriptor on the test datasets. We found that the retrieval performance of RSILC is either the first or the second among the other descriptors for all test datasets. CSIFT is one of the best descriptors except on the Indian dataset. This descriptor uses color information, therefore it has better results compared to color-blind descriptors. LEM performance is higher than the other descriptors on the CalTech set, in which all images are frontal faces. However, LEM is not designed to deal with geometric transformations. Therefore, its matching accuracy decreases on a dataset with large pose variations (e.g., Indian Faces and ColorFERET) and performance is drastically lower if the query image is rotated and re-scaled (cf. Fig. 15 and Section 5.6.3). The PHOG descriptor produces comparable results on the face datasets and highest scores on the generic set but is color-blind and rotation variant. Therefore, in transformation experiments, this descriptor failed to perform accurate matching (cf. Section 5.6.3). Conventional SIFT and SURF have lower performance on both the face and generic sets compared to other descriptors.

In a controlled environment, all descriptors perform well, even with a basic test-bed system as in our case. However, the matching results on the LFW dataset show that a simple test-bed system is insufficient for face recognition in an unconstrained environment. It would be unfair to compare our scores with full face identification systems, which often have additional stages, such as the incorporation of age, gender, or facial expression information to improve matching accuracy. Because we propose a generic descriptor, we compare it with the other generic descriptors in the same test-bed system.

All of the face datasets that we used in our experiments have illumination variances including other variances, such as view and facial expression. However, in the ALOI set, the illumination direction is systematically varied for each object in 24 configurations and all other parameters are held constant. Therefore, we found that this database is suitable to test the robustness of the descriptor to large illumination variance. As mentioned in Section 3.2.1, our descriptor uses YCbCr
                            color space, which is more robust to illumination changes compared to other color spaces. Fig. 13
                            shows two example objects with different illumination directions. The RSILC descriptor computes the key-lines from the edge map of the objects and the edge boundary is computed from the Y-band of YCbCr
                            color space. The visibility of objects is affected by high illumination variance in RGB space. On the other hand, the illumination variance seems to be reduced in YCbCr
                            space. Therefore, the edge maps extracted from the Y-band are less affected by illumination variance. The other line-based descriptor, LEM, extracts the edges from the RGB space. Although it is claimed that the LEM is robust to illumination changes because it only uses edge information, the edge maps in Fig. 13.e and the poor retrieval performance on the ALOI illumination set indicate that edges are affected by the high illumination variance. The retrieval accuracy of the conventional SIFT and SURF on this dataset are also lower (Fig. 12). It can be interpreted as, these descriptors are less robust to illumination variance compared to CSIFT, PHOG, and RSILC, which perform well in this set with a retrieval score (hit rate) higher than 90%.

We investigate the retrieval performance of the descriptors to the following transformations: rotation, scaling, and mirror-flipping. We run experiments on the CalTech set. The query image is rotated by π/6, rescaled to 50% of its original size, mirror-flipped, and matched with straight images in the dataset. Fig. 14
                            shows examples from the experiment. We report the hit rates of descriptors as bar graphs in Fig. 15
                           . According to the scoring, RSILC matching performance is not affected by rotation, scaling, or flip transformation, but SIFT, SURF, PHOG, and LEM performance suffered a significant drop when images were transformed. LEM and PHOG are not designed to cope with rotation transformation. Thus, their matching performance in the rotation case was less than 50%.

To quantify the degradation of retrieval performance with image transformation, we compare retrieval performance of RSILC on transformed images with the retrieval performance on non-transformed images. Table 2
                            lists the hit rates of the system on the CalTech set. There is a slight drop due to transformation at the top-1 hit rate. However, at top-3 and top-5, the hit rate is equal to that obtained with non-transformed query images.

We have successfully integrated RSILC in the face matching module (FaceMatch) [19] of the People Locator (PL) [57] service developed by NLM to help families reunite in disaster situations. PL photo collection is dynamic and large, containing hundreds of thousands of images. It typically has only one (seldom two) picture per person; therefore, FaceMatch cannot train any sophisticated person-specific model and is required to provide single-shot-based face matching capability while working with fairly low-quality images. Our experiments indicate that overall, RSILC provides a better top-1 hit rate face image retrieval accuracy (HitRate.RSILC=0.96) than any other individual descriptor, including the rotation- and scale-invariant SIFT (0.94) and SURF (0.92), on the CalTech Faces, yielding only to the ensemble (an optimally weighted combination) of descriptors (SIFT, SURF, ORB, LBPH, HAAR) (HitRate.COMBO=0.98), thus prompting a safe replacement of some of them with itself without any expected accuracy loss.

@&#CONCLUSIONS@&#

We introduced a new Rotation- and Scale-Invariant Line-based Color-aware descriptor (RSILC), which detects image key-lines and their circular regions, combining both local (intensity, color, gradient histograms) and global (line inter-positioning) information. It models the line-rich objects in a more intuitive and economical way than the popular key-point descriptors do. Moreover, RSILC has a better matching efficiency, since it produces more discriminative candidates to match in line-rich regions of interest. Aside from the mentioned features, RSILC is also mirror-flip invariant via symmetric key-line descriptor matching, something that other key-spot descriptors we tested cannot claim.

We performed a thorough investigation of the descriptor matching performance by conducting the following image and face retrieval experiments involving (i) generic line-rich objects and faces (an important special case of line-rich objects), (ii) controlled illumination variation using several direct lights, (iii) geometric transformation, including rotation, scale, and mirror-flip transformations. We compared our descriptor matching performance with well-known descriptors in the same test-bed system. The results indicated that overall RSILC is more accurate for line-rich object matching than the key-point descriptors. We successfully integrated RSILC in the real-world face image retrieval system FaceMatch (FM) and observed that RSILC is more accurate than any of the FM individual descriptors.

Our future work includes experiments with alternative edge detection methods (e.g., key-line filtering directly after the Sobel operator), various optimizations to RSILC computation and matching (e.g., reducing the individual descriptor size) utilizing multiple processing cores, and pushing batch matching to GPU. RSILC can be further expanded to piece-wise polynomial and curve-based region matching, which should expand the possible image matching application pool. Although RSILC produced good results in our out-of-plane rotation experiments, it was not designed to be invariant to affine or projective transforms, hence a natural extension would involve the study and introduction of such an invariance.

@&#ACKNOWLEDGMENTS@&#

This research was supported by the Intramural Research Program of the National Institutes of Health, National Library of Medicine and Lister Hill National Center for Biomedical Communications. We would like to acknowledge the editorial assistance of the NIH Fellows Editorial board.

@&#REFERENCES@&#


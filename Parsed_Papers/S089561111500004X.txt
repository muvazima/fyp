@&#MAIN-TITLE@&#Estimating the size of polyps during actual endoscopy procedures using a spatio-temporal characterization

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The approach segments a polyp by propagating an initial manual delineation.


                        
                        
                           
                           Polyp segmentation is performed by a combination of motion and appearance features.


                        
                        
                           
                           A defocus strategy estimates the camera distance and the actual polyp size.


                        
                        
                           
                           Four experts and the method did not show significant differences in endoscopy.


                        
                        
                           
                           The approach is robust to different types of noise and can be used in real scenarios.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

@&#ABSTRACT@&#


               
               
                  Colorectal cancer usually appears in polyps developed from the mucosa. Carcinoma is frequently found in those polyps larger than 10mm and therefore only this kind of polyps is sent for pathology examination. In consequence, accurate estimation of a polyp size determines the surveillance interval after polypectomy. The follow up consists in a periodic colonoscopy whose frequency depends on the estimation of the size polyp. Typically, this polyp measure is achieved by examining the lesion with a calibrated endoscopy tool. However, measurement is very challenging because it must be performed during a procedure subjected to a complex mix of noise sources, namely anatomical variability, drastic illumination changes and abrupt camera movements. This work introduces a semi-automatic method that estimates a polyp size by propagating an initial manual delineation in a single frame to the whole video sequence using a spatio-temporal characterization of the lesion, during a routine endoscopic examination. The proposed approach achieved a Dice Score of 0.7 in real endoscopy video-sequences, when comparing with an expert. In addition, the method obtained a root mean square error (RMSE) of 0.87mm in videos artificially captured in a cylindric structure with spheres of known size that simulated the polyps. Finally, in real endoscopy sequences, the diameter estimation was compared with measures obtained by a group of four experts with similar experience, obtaining a RMSE of 4.7mm for a set of polyps measuring from 5 to 20mm. An ANOVA test performed for the five groups of measurements (four experts and the method) showed no significant differences (p
                     <0.01).
               
            

@&#INTRODUCTION@&#

Colorectal cancer is the seventh most likely cause of death worldwide [1] and frequently asymptomatic illness characterized by a set of malign polyps along the digestive tract [2,3]. Typically, this disease is discovered during an endoscopy procedure, in which case the polyp size is used as the main endoscopic sign that supports the decision of an immediate resection, i.e., if the polyp is smaller than 10mm [4,5], it is removed, otherwise a sample is sent to pathology and the procedure is re-programmed for an extirpation [2,3,5]. Usually, the polyp size is estimated by measuring the lesion with a linear colonoscopy probe or by using the aperture of the endoscopy forceps as a repair for comparison [6]. This estimation is a very difficult task, highly subjective and dependent on the expert training [7]. In addition, several technical problems may arise during the procedure, such as: (1) optical distortion (Barrel's effect), (2) difficult handling of the endoscope because of the bowel tone and (3) exacerbated physiological conditions like increased motility or secretion [7]. Current advances on video processing [8–10] open up actual possibility of identifying polyps during endoscopy, with some potential advantages, namely: (1) real time estimation, (2) less-invasiveness, i.e., no additional tool is needed, (3) low cost procedure, and (4) a lesion characterization that might be used as support to the diagnosis. However, developing automatic approaches for estimation of polyp size is challenging because of the high variability of both the endoscopy procedure and the polyp shape [11,12], interference light patterns due to the bowel motion and blurred captures because of the varying illumination conditions [7].

Current approaches far proposed for segmenting and estimating the polyp size, use features derived from their geometry, appearance and size but difficulties in estimating these parameters limit the accuracy of these methods [13]. Aiming to delineate the polyp, Liu et al. [8] simulate a geometrical 3D intestinal tract, computed from a flow deformation map that matches a set of salient points from consecutive frames. Such method results computationally expensive and prone to errors because the salient points are hardly correlated. This strategy only predicts the presence/absence of the polyp, requiring an initial manual intervention. In [9], a per-frame polyp shape is estimated by using a set of classical geometrical and color descriptors, a strategy that fails under non controlled illumination conditions. In contrast, Bernal et al. [10] approximate the polyp shape by using per-frame static features that must follow a polyp appearance model. This characterization may fail if the polyp is blurred in the endoscopy video, as usually observed in real scenarios. For estimating the polyp size, Chadebecq et al. [7] introduced a prior RoI bounding the polyp and tracked the lesion using a temporal rigid transformation. Afterward, an infocus blur allowed a RoI size estimation. However, in real conditions the camera movements may be so rapid that the RoI easily losses the polyp.

Recent strategies involve the fusion of video-endoscopy with ultrasound images.

Nevertheless, such echo-endoscopy device is mainly indicated in case of extramural polyps, i.e., it makes possible to measure advanced stages of the polyp and its use is highly expert dependent [5]. Other strategies include the virtual endoscopy from CT images [14–16], a 3D reconstruction that requires long exposition to ionizing radiation, report low sensitivity rates [15–17] and is purely diagnostic and polyps finally must be removed during an endoscopy procedure.

The main contribution of this work is a semi-automatic method that delineates the polyp and estimates its size in a video sequence, using a local spatio-temporal characterization and an automatic defocus strategy. In this approach, an initial manual delineation in a single frame is propagated using a per-pixel motion descriptor built while the camera is moving, assuming only a statistical dependence with the precedent frame. An additional Bayes strategy couples the per-pixel motion descriptor with prior motion information, approximating the shape during occlusion phases. The polyp size is then estimated from the resulting polyp delineation, using a focused estimation of the whole sequence with a calibrated camera model. This paper is organized as follows. In Section 2 describe the proposed strategy, in Section 3 present the evaluation and result of method, in Section 4 is the discussion of proposed approach and in Section 5 the conclusions and the future work.

The present strategy segments, tracks and measures polyps during an endoscopy procedure. An initial manual polyp delineation in the first frame captures the main features to be used. This characterization and the motion history endoscopy coarsely follow the polyp in the sequence. Afterwards, a classical second order Kalman filter, a Bayesian tracking strategy, is used to refine the polyp segmentation, obtained from the spatio-temporal characterization. Once a polyp is identified and segmented, the polyp size is computed using an offline depth defocus strategy. The pipeline of the proposed approach is illustrated in Fig. 1
                      and further described in the following subsections.

In general, radial endoscopy distortion produces non-linear incremental deformations from the optical center to the outer regions, affecting the object relative size and position [18,19]. The wide-angle lens distortion (barrel's effect) was corrected by estimating the camera parameters using a bank of artificial images (see Fig. 1c). Assuming an orthogonal coordinate system, every point in the image space 
                           x
                         is related to the real world 
                           
                              
                                 x
                              
                              ˜
                           
                         by a pinhole model defined as 
                           
                              
                                 x
                              
                              =
                              
                                 
                                    
                                       f
                                       /
                                       z
                                    
                                 
                              
                              
                                 
                                    x
                                 
                                 ˜
                              
                           
                        , where f is the focal length and z the distance from the object to the camera lens. This model estimates the focus camera length, the scale factor, the distortion coefficient and the optical center point. This nonlinear distortion was approximated by power series and corrected as 
                           
                              
                                 r
                                 n
                              
                              =
                              
                                 r
                                 d
                              
                              
                                 
                                    1
                                    +
                                    k
                                    ×
                                    
                                       r
                                       d
                                       2
                                    
                                 
                              
                           
                        , being k the radial distortion coefficient and r
                        
                           d
                         the image with the corrected distortion.

A polyp is an intestinal protuberance whose appearance may be easily confounded with the surrounding tissues, leading most segmentation procedures to fail. The proposed approach starts by an expert delineation of the polyp contour in the first frame to capture specific polyp features. The polyp contour 
                           X
                        
                        
                           t
                         is represented as a parametric curve defined as: 
                           
                              
                                 
                                    X
                                 
                                 t
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                   t
                                                
                                             
                                          
                                       
                                       
                                          i
                                          =
                                          0
                                       
                                       n
                                    
                                    ,
                                    (
                                    
                                       x
                                       ¯
                                    
                                    ,
                                    
                                       y
                                       ¯
                                    
                                    )
                                 
                              
                           
                        , where 
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                x
                                             
                                             t
                                          
                                       
                                    
                                 
                                 
                                    i
                                    =
                                    0
                                 
                                 n
                              
                           
                         is a set of n points contouring the polyp with its centroid defined in 
                           
                              (
                              
                                 x
                                 ¯
                              
                              ,
                              
                                 y
                                 ¯
                              
                              )
                           
                        . Such delineation defines a neighbour RoI around the lesion, the RoI
                           t
                         with size {RoI
                        
                           t
                        
                        =
                        X
                        
                           t
                        
                        +
                        ξ}, being ξ a tolerance value. Afterwards, the histogram of the whole sequence was equalized and a Gaussian filter, with σ
                        =0.7, was applied to remove the granular noise.

During an endoscopy navigation, the expert always tries to track the polyp with translational movements, attempting to generate a depth perception by amplifying the motion of nearby structures
                           1
                        
                        
                           1
                           Classically known as motion parallax (right-left movements) [20] and kinetic depth perception (rear-front movements) [21].
                        . Using a background subtraction strategy, the proposed approach estimates the region with more motion, within which the polyp shape is approximated by those pixels with the largest temporal variance [22]. For doing so, a per pixel history motion M
                        
                           t
                        (x, y) (reference model), storing those pixels that are relatively motionless and correspond to the background, is first calculated as:
                           
                              (1)
                              
                                 
                                    
                                       M
                                       t
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    =
                                    
                                       M
                                       
                                          t
                                          −
                                          1
                                       
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    +
                                    sign
                                       
                                    
                                       
                                          
                                             I
                                             t
                                          
                                          
                                             
                                                x
                                                ,
                                                y
                                             
                                          
                                          −
                                          
                                             M
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                          
                                             
                                                x
                                                ,
                                                y
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        
                     

where I
                        
                           t
                         is a particular frame at time t. A likelihood function Δ
                        
                           t
                        (x, y) measures the instantaneous pixel motion at time t w.r.t. the background history motion, being:
                           
                              (2)
                              
                                 
                                    
                                       Δ
                                       t
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    =
                                    
                                       
                                          
                                             M
                                             t
                                          
                                          
                                             
                                                x
                                                ,
                                                y
                                             
                                          
                                          −
                                          
                                             I
                                             t
                                          
                                          (
                                          x
                                          ,
                                          y
                                          )
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

The lesion is then the set of pixels with a relevant motion defined by the bidirectionally likelihood function, i.e., in the forward and backward temporal directions of the whole video-sequence (causal and anti-causal analysis). The bidirectional computation of the motion pixels recovers the lesion at each time as:
                           
                              (3)
                              
                                 
                                    
                                       
                                          Δ
                                       
                                       t
                                    
                                    
                                       
                                          
                                             x
                                          
                                          ,
                                          
                                             y
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             a
                                             t
                                          
                                       
                                    
                                    
                                       Δ
                                       t
                                       
                                          forward
                                       
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    −
                                    
                                       
                                          1
                                          −
                                          
                                             a
                                             t
                                          
                                       
                                    
                                    
                                       Δ
                                       t
                                       
                                          backward
                                       
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              α
                              =
                              
                                 t
                                 /
                                 N
                              
                           
                         is a temporal weight parameter. Finally, moving pixels that better represent the polyp shape are selected by simple thresholding the estimation 
                           
                              
                                 
                                    Δ
                                 
                                 t
                              
                              
                                 
                                    
                                       x
                                    
                                    ,
                                    
                                       y
                                    
                                 
                              
                           
                         with a learned scalar parameter τ yielding the motion segmentation as:
                           
                              (4)
                              
                                 
                                    S
                                    
                                       b
                                       t
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    =
                                    
                                       
                                          Δ
                                       
                                       t
                                    
                                    
                                       
                                          
                                             x
                                          
                                          ,
                                          
                                             y
                                          
                                       
                                    
                                    ≥
                                    τ
                                 
                              
                           
                        
                     

The initial position of the RoI
                           t
                         that bounds the polyp delineation is then propagated to the rest of the image space and motion history sequences. For doing so, the motion history is correlated for every pair of consecutive frames [23], as:
                           
                              (5)
                              
                                 
                                    
                                       RoI
                                       t
                                    
                                    
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    =
                                    arg
                                    
                                       
                                          max
                                       
                                       
                                          R
                                          o
                                          
                                             I
                                             t
                                          
                                       
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          0
                                       
                                       
                                          (
                                          n
                                          −
                                          1
                                          )
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             j
                                             =
                                             0
                                          
                                          
                                             (
                                             m
                                             −
                                             1
                                             )
                                          
                                       
                                       
                                          
                                             
                                                Δ
                                             
                                             t
                                          
                                          
                                             
                                                
                                                   i
                                                
                                                ,
                                                
                                                   j
                                                
                                             
                                          
                                          ×
                                          
                                             RoI
                                             
                                                t
                                                −
                                                1
                                             
                                          
                                          
                                             
                                                x
                                                −
                                                i
                                                ,
                                                y
                                                −
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where RoI
                           t
                        (x, y) is an estimation of the polyp location that corresponds then to that maximally correlated RoI.

Such RoI in the motion history space is mapped to the image space, where a minimal per-pixel Euclidean distance w.r.t. the precedent RoI
                           t−1, allows to obtain an additional polyp segmentation Si
                        
                           t
                        (x, y), the intensity segmentation.

Then, an improved segmentation is obtained by fusing the two mentioned segmentations as the intersection of the intensity Si
                        
                           t
                        (x, y) and motion Sb
                        
                           t
                        (x, y) (defined in the previous subsection):
                           
                              (6)
                              
                                 
                                    
                                       Z
                                       t
                                    
                                    =
                                    
                                       
                                          S
                                          
                                             i
                                             t
                                          
                                          
                                             
                                                x
                                                ,
                                                y
                                             
                                          
                                          ⊕
                                          S
                                          
                                             b
                                             t
                                          
                                          
                                             
                                                x
                                                ,
                                                y
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Additionally, a classical morphological operator removes the remaining noise, basically groups of isolated polyp regions. Finally, the obtained segmentation is transformed to a polar space, where a simple smoothing preserves the global shape.

During an actual endoscopy procedure, a polyp may be missed because of some abrupt camera motions or presence of some digestive fluid that might partially occlude the intestinal tract. With a proper frame-rate capture, it is reasonable to assume a relatively smooth polyp motion, even when the polyp is partially occluded.

A Bayesian strategy estimates and tracks the polyp, modeling the probability 
                           
                              p
                              (
                              
                                 
                                    
                                       X
                                    
                                    ˆ
                                 
                                 t
                              
                              |
                              
                                 Z
                                 t
                              
                              )
                           
                         of the state of the polyp delination 
                           
                              
                                 
                                    
                                       X
                                    
                                    ˆ
                                 
                                 t
                              
                           
                         at time t, given the spatio-temporal observations 
                           
                              
                                 
                                    Z
                                 
                                 t
                              
                              =
                              
                                 
                                    
                                       Z
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       Z
                                       N
                                    
                                 
                              
                           
                        . This model is assumed markovian, i.e., the current state of the system stores the relevant information. Such Bayesian strategy requires a model of the dynamics p(X
                        
                           t
                        |X
                        
                           t−1) and a likelihood function p(Z
                        
                           t
                        |X
                        
                           t
                        ) that maps the estimated polyp to the spatio-temporal space. Once this information is available, the polyp delineation at a particular state, is calculated in two steps:
                           
                              -
                              Prediction: A particular state X
                                 
                                    t
                                  is computed by updating the previous belief 
                                    
                                       
                                          
                                             
                                                X
                                             
                                             ˆ
                                          
                                          
                                             
                                                t
                                             
                                             −
                                             1
                                          
                                       
                                    
                                 , after a prediction given by the Chapman–Kolmogorov equation:
                                    
                                       (7)
                                       
                                          
                                             
                                                
                                                   X
                                                   ˆ
                                                
                                                t
                                             
                                             =
                                             ∫
                                             
                                                p
                                                
                                                   
                                                      
                                                         X
                                                         t
                                                      
                                                      |
                                                      
                                                         X
                                                         
                                                            t
                                                            −
                                                            1
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      X
                                                      ˆ
                                                   
                                                   
                                                      t
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   d
                                                   
                                                      
                                                         X
                                                         
                                                            t
                                                            −
                                                            1
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Update: The predicted belief X
                                 
                                    t
                                  is adjusted after observations:
                                    
                                       (8)
                                       
                                          
                                             
                                                X
                                                t
                                             
                                             ∝
                                             
                                                
                                                   X
                                                   ˆ
                                                
                                                t
                                             
                                             p
                                             
                                                
                                                   
                                                      Z
                                                      t
                                                   
                                                   |
                                                   
                                                      X
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

For the sake of computational efficiency, a second order Kalman filter models the polyp delineation 
                           
                              
                                 
                                    
                                       X
                                    
                                    ˆ
                                 
                                 t
                              
                           
                         by using the first and second statistical moments as 
                           
                              
                                 
                                    X
                                 
                                 t
                              
                              ∼
                              N
                              
                                 
                                    
                                       μ
                                       t
                                    
                                    ,
                                    
                                       Σ
                                       t
                                       2
                                    
                                 
                              
                           
                        , where μ
                        
                           t
                         is the mean distribution and 
                           
                              
                                 Σ
                                 t
                                 2
                              
                           
                         is the covariance matrix of the state t. This Kalman estimator is computationally optimal because it linearizes the system with a first order Taylor series expansion.

A polyp size is estimated from the obtained temporal segmentation at a fixed depth position of the camera, as a function of the focused image
                           2
                        
                        
                           2
                           A well-known psychophysical theory states that the distance to the camera is a function of the image blur [24].
                         and the pinhole camera parameters (see in Section 2.1).

The depth was herein estimated by a defocus strategy [7] that assumes each frame is contaminated with an unknown Gaussian blur with standard deviation σ
                        
                           o
                        , proportional to the object distance to the camera. This unknown Gaussian blur is estimated by convolving the image with a known Gaussian blur and computing the difference between gradients of the original (unknown blur) and blurred (known blur) images. This gradient ratio R
                        
                           t
                         is proportional to the unknown standard deviation as 
                           
                              
                                 σ
                                 t
                                 o
                              
                              =
                              
                                 1
                                 /
                                 
                                    
                                       
                                          
                                             
                                                
                                                   R
                                                   2
                                                
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                              
                                 σ
                                 t
                                 b
                              
                           
                        , where σ
                        
                           b
                         is a known standard deviation of a blurred Gaussian.

In an off-line posterior training step, the blur coefficients, a set of correspondences between the blur levels of a phantom image
                           3
                        
                        
                           3
                           An artificial grid phantom was adapted for this task.
                         and actual camera depths (see in Fig. 2(a)), are computed. A single blur coefficient is then associated to the infocus breakpoint image IB
                        of-line (the clearer cut-frame) and serves as a reference depth since this is the minimum estimated blurring with a unique depth correspondence. Such relationship – the blur coefficients – was herein used within the endoscopic RoI
                           t
                         to estimate the unblurred polyp by computing the corresponding infocus RoI breakpoint. The unblurred polyp size (ϕ) is then estimated from the segmentation previously obtained.

The dataset herein used is composed of a set of 16 endoscopy video-sequences captured using an Olympus EVIS EXERA (GIF-1TQ160) gastrovideoscope device, provided with a field of view of 140° and a focal length of (357.3, 325.5). Each sequence was recorded in color, with a spatial resolution of 720 per 480 pixels and a temporal resolution of 30 frames per second. Two different groups of videos were captured for training and evaluation. The first dataset is composed of 6 video-sequences that were captured under controlled conditions using an artificial phantom grid superimposed to a set of images captured at different angles, estimating thereby the intrinsic and extrinsic camera parameters. The depth function was trained with captures of the artificial phantom grid, as illustrated in Fig. 1(c). The grid is placed at different depth distances, using a custom platform that is displaced in steps of 1mm, with a maximum distance of 30mm. Additionally, as shown in Fig. 3
                        , a tubular structure emulated the digestive tract while a set of spheres of known size, the polyps. Four navigations within this structure were recorded to test the proposed approach in controlled conditions. The second dataset included real endoscopic procedures and presence of polyp lesions. A total of 10 video-sequences were captured and four gastroenterologists annotated the videos, segmenting the polyps and estimating their size.

The performance of the proposed approach was assessed in two different tasks: segmentation and estimation of the polyp size. Four expert gastroenterologists delineated and estimated the polyp size in phantom and real endoscopy sequences.


                        Fig. 4
                         illustrates the segmentation results in actual endoscopic videos. The yellow contour stands for the ground truth delineation. In the second row, the red polyp delineation is computed using an alternative tracking strategy introduced as a baseline, the classical exponentially weighted moving average EWMA [25], for which an actual polyp delineation is propagated along the sequence using the Bhattacharyya coefficient and a set of exponentially decreasing weights obtained from previous frames. Despite this strategy takes into account the motion history, and the polyp is relatively well localized within the analysis RoI, the method misses polyp changes resulting from abrupt camera movement, leading to a wrong segmentation. In contrast, in the third row, the blue delineation is obtained with the proposed approach, showing a reliable overlap during those periods with a relatively slow motion. When the camera abruptly moves, the polyp appearance and size result modified, but the proposed approach follows the lesion more accurately than the tracking observed with the EWMA.

Two quantitative metrics were used for assessing the segmentation task: the Dice coefficient (DSC) and the Hausdorff distance (HD). The DSC(A, b) is 
                           
                              
                                 
                                    2
                                    (
                                    A
                                    ∩
                                    B
                                    )
                                 
                                 /
                                 
                                    
                                       
                                          A
                                          +
                                          B
                                       
                                    
                                 
                              
                           
                         
                        [26], where A and B represent the obtained polyp area and the expert ground truth delineation, respectively. The Hausdorff measure H(A, B) [27] computes the maximum distance between two sets of points as max(h(A, B), h(B, A)) and 
                           
                              h
                              
                                 
                                    A
                                    ,
                                    B
                                 
                              
                              =
                              
                                 
                                    max
                                 
                                 
                                    a
                                    ∈
                                    A
                                 
                              
                              
                                 
                                    min
                                 
                                 
                                    b
                                    ∈
                                    B
                                 
                              
                              a
                              −
                              
                                 b
                                 2
                                 2
                              
                           
                        . In this case, each set of points represents the polyp delineation at each frame. This measure allows to indirectly assessing the compactness of the segmentation since outliers are penalized. In videos captured within the artificial tubular structure (see in Fig. 3) a DSC of 0.96 was obtained when the phantom polyps were segmented, under controlled illumination conditions. Table 1
                         shows the performance obtained by the proposed approach and the EWMA tracking when segmenting 1040 frames.

An additional comparison with the Hausdorff Distance allows the compactness of the polyp delineation to be assessed, since this measure penalizes those pixels far from the ground truth, reporting in such a case a small value. Overall, the proposed approach outperforms the baseline in terms of overlapping and compactness (small Hausdorff distance). Some segmentation errors may be caused a certain polyp occlusion is present or in cases in which abrupt motions may change the appearance, size and shape of the polyp.

Estimation of polyp size is a challenging task and high intra and inter expert variability has been reported in previous work. The variance of 12 expert measuring 240 gastric lesions was reported [28], obtaining a mean difference of 11±17mm. Additionally, a kappa coefficient of 0.4 and an agreement of only a 50.0% in series with three gastroenterologists were also reported [4]. In consequence, a second experiment aimed to evaluate the accuracy of the estimated polyp size. This task is much more challenging because of the multiple sources of distortion, but also more useful from a clinical standpoint since the gastroenterologist usually has no reference to establish an actual polyp size. Results are shown in Fig. 5
                        , the blue lower and upper boxes stand for the spread of the estimated sizes reported by four experts (interquartile range), while the maximum and minimum values are shown as the vertical dotted lines. A total of four endoscopy phantom sequences, with 4 spheres whose size varied between 5 and 15mm, were evaluated. A part of the experiment required the gastroenterologist to simulate a procedure with similar gestures to an actual endoscopy, the camera moved abruptly and the navigation patterns were complex. In spite of the controlled conditions, experts showed a large variability in their estimation, as illustrated in Fig. 5, where yellow diamonds correspond to the ground truth measure per video. Interestingly, results evidence a very large variability of the obtained measures with respect to the reference. In average, the standard deviation was about ±5.4mm, confirming the high inter expert variability. In contrast, the proposed method (green circles) systematically achieved estimations much closer to the actual value. In this case, the method accomplished an accurate segmentation of the phantom polyps and also a proper estimation of the break focus frame.

Overall, it has been traditionally acknowledged that the expert estimation is the most reliable information source in real endoscopy procedures and therefore the ground truth reference. Fig. 6
                         shows the obtained estimations by the proposed approach (green circles) and the gastroenterologists (interquartile range). In average, the gastroenterologists showed a variance of ±3.63mm with respect to polyps that varied between 5 and 20mm. In case of real endoscopies, the mean expert estimation – the red line – amounts to the ground truth. As illustrated in Fig. 6, the estimated size of the proposed approach is within the range of variability observed for the group gastroenterologists and no significant differences were found when statistically evaluated (ANOVA test with p
                        <0.01).

The quality and fidelity of measurements obtained for any method is always affected by a noise. The quality of the estimation was herein weighted by the noise as the SNR-like measurement, using a logarithmic scale and measuring the difference between the expected control data and the predicted values. This SNR-like measurement was defined as 
                           
                              SNR
                              ­
                              like
                              =
                              10
                               
                              
                                 
                                    log
                                 
                                 
                                    10
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             σ
                                             2
                                          
                                       
                                       /
                                       
                                          RMSE
                                       
                                    
                                 
                              
                              ,
                           
                         where σ
                        2 is the largest delineation variance among the group of experts and RMSE is the root mean squared error, the computed error of the proposed approach w.r.t. the ground truth estimation. Table 2
                         shows the results obtained by the proposed approach in terms of this SNR-like and RMSE measures. In summary, the proposed approach achieves a gain of 37.48dB, indicating that the proposed approach estimates the polyp, with a high degree of confidence, within the interval defined by the estimations of the experts. Table 2 also reports the mean and the standard deviation of the error (RMSE), indicating a high accuracy of the estimation in artificial videos and size estimation within the interval defined by expert variability, in real videos.

@&#DISCUSSION@&#

This work introduces a novel approach that segments polyps and estimates their sizes during video-endoscopy procedures. The method starts with an initial expert delineation that is warped along the sequence by using information obtained from both a motion and an appearance per-frame analysis. The resultant coarse shape is then refined by a second order Kalman filter, a Bayesian strategy that uses the motion history as observation. From such segmentation, the maximum polyp size in pixels is computed and then transformed to real-world coordinates by a combination of camera parameters and computation of an optimal depth distance.

Every polyp, found during a colonoscopic procedure, must be extirpated, but those polyps whose size exceeds the 10mm are sent for further pathological examination [2,5,29]. In spite of the demonstrated importance of quantifying the polyp size, the colonoscopic measure so far consists in comparing the observed lesion with micro-scales introduced within the endoscopy tube, a very highly expert-dependent procedure. Hence, reliable, efficient and reproducible measurements that estimate the polyp size are required. As mentioned before, this problem is particularly challenging since the procedure is by nature the result of abrupt motions, the exploration is carried out under uncontrolled illumination conditions and the complex anatomy introduces a huge variability of the polyp appearance and shape. Several computational strategies have been proposed to cope with identification, characterization and measure of polyps. Regarding polyp delineation, Ganz et al. [30] used a multispectral endoscopic imaging to highlight the region that bounded the polyp, according to certain expected histological properties. Then, the boundary is detected using a prior shape term as regularizer. In terms of overlapping, this automatic strategy achieved an average Jaccard index of 0.52 for the segmentation task, without any manual intervention. This method requires a special device to characterize the polyp (a 2d narrow band imaging), that is to say, to define the set of histological characteristics that might be associated to the lesion. Hence, this approach results dependent on a very large database that stores the high shape variability. In contrast, the presented approach characterizes the polyp in standard endoscopic sequences, without whatsoever external prior shape, learned from other video-sequences. The proposed approach achieves an overlapping score of 0.71 over 1040 frames in 10 videos by propagating an initial manual delineation using spatio-temporal descriptor. On the other hand, for estimating the polyp size, Chadebecq et al. [31] proposed a semi-automatic method that started by manually placing a bounding box surrounding the polyp with a tolerance windows size of ±3 pixels, followed by a conventional affine registration that propagates such initial guess to the whole sequence and estimates the best focused region by a depth learning procedure. In this approach, a 7% average error was estimated for the bounding box size estimating task. Unlike our approach, this break focus is determined on the entire bounding box, with the consequent error coming from calculating the polyp distance as a linear function of the estimated depth within the box. Likewise, the noise obtained by the rigid registration is very limited to follow abrupt changes of the camera view. In average, the herein proposed approach achieves a RMSE error of 0.89±0.56 and 4.7±3.2mm for artificial and real sequences over a range of polyp sizes among 5 to 20mm.

The proposed approach has presented a framework that performs polyp segmentation and size estimation, during colonoscopy procedures. One of the main advantages of the proposed approach is the adaptability to different polyp shapes, with different appearances, depending only of the required initial characterization. Additionally, the deep estimation was computed only within the polyp regions, obtaining more accurate approximations. The proposed approach was evaluated on phantom and real endoscopy videos, showing in general an appropriate performance in both tasks, polyp segmentation and size estimation, i.e., an overlapping average of 0.82±0.09 for segmentation and a RMSE of 0.89±0.56mm in phantom polyps varying from 5 to 20mm and a RMSE of 4.7±3.2mm in real sequences, when estimating sizes. In summary, the proposed approach shows adequate sensitivity and reproducibility so that it may potentially be useful in clinical applications as a tool to support the diagnosis.

The average time spent by the proposed approach in a test set of 15 sequences at 30 frames per second was 21.2s, discriminated as follows: (1) the pre-processing step 4.1s, (2) the expert delineation 7.2s, (3) the polyp shape estimation 5.7s and (4) the polyp size estimation 4.2s.

This work has introduced a novel approach to segment and estimate the polyp size in colonoscopy video sequences. The proposed method uses a combination of local motion information and the appearance of polyp features. The results show a reliable segmentation and tracking of the polyp throughout the video sequence. The approach also is capable of dealing with video artifacts and the high degree of variability in appearance. Additionally, the real polyp size estimation was obtained in millimeters and results demonstrated these measurements were comparable to those obtained by experts. In a future work, a strategy to automatically initialize the segmentation will be integrated, based on machine learning strategies while the segmentation will be refined with alternative polyp appearance descriptors.

@&#REFERENCES@&#


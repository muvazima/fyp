@&#MAIN-TITLE@&#Multi-view facial landmark detector learned by the Structured Output SVM

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Real-time multi-view landmark detector independent on initialization


                        
                        
                           
                           Detector composed of a mixture of tree based Deformable Part Models


                        
                        
                           
                           Landmark detector learned by the Structured Output Support Vector Machines


                        
                        
                           
                           Coarse-to-fine strategy to speed up inference based on dynamic programming


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Deformable Part Models

Structured output SVM

Facial landmarks detection

@&#ABSTRACT@&#


               
               
                  We propose a real-time multi-view landmark detector based on Deformable Part Models (DPM). The detector is composed of a mixture of tree based DPMs, each component describing landmark configurations in a specific range of viewing angles. The usage of view specific DPMs allows to capture a large range of poses and to deal with the problem of self-occlusions. Parameters of the detector are learned from annotated examples by the Structured Output Support Vector Machines algorithm. The learning objective is directly related to the performance measure used for detector evaluation. The tree based DPM allows to find a globally optimal landmark configuration by the dynamic programming. We propose a coarse-to-fine search strategy which allows real-time processing by the dynamic programming also on high resolution images. Empirical evaluation on “in the wild” images shows that the proposed detector is competitive with the state-of-the-art methods in terms of speed and accuracy yet it keeps the guarantee of finding a globally optimal estimate in contrast to other methods.
               
            

@&#INTRODUCTION@&#

The detection of facial landmarks in images is a crucial step in many computer vision applications involving faces. For example, the landmark positions are used for alignment and normalization of face having substantial impact on the overall accuracy of face recognition systems estimating e.g. age, gender or identity (for example [1,2]).

In this paper, we propose a real-time multi-view landmark detector based on Deformable Part Models (DPM) [3,4]. An exemplary output of the proposed detector is shown in Fig. 1
                     . The detector is composed of a mixture of tree based DPM, each component describing landmark configurations in a specific range of viewing angles. The usage of view specific DPM allows to capture a large range of poses and to deal with the problem of self-occlusions. The estimation of the viewing angle and the landmark position is done simultaneously by a structured output classifier. The inference problem can be solved globally by the dynamic programming, hence the detector's output is independent on an initial estimate in contrast to majority of other methods. Parameters of the DPM based structured classifiers are learned from annotated examples by the Structured Output SVM algorithm [5]. The objective function of the learning algorithm is directly related to the performance measure used for detector evaluation. In order to obtain a real-time detector, we use several speedups. First, we use tree based shape model defined by separable pair-wise potential functions which allows to decrease the computational complexity of the dynamic programming procedure from quadratic to linear in terms of the number of landmark positions via employing the distance transform [6]. Second, we propose to use the MIPMAP technique [7] for fast computation of features used by the local landmark classifiers. Third, we propose a coarse-to-fine strategy in order to reduce the size of the search space on higher resolution images. Evaluation on the challenging “Annotated Faces in the Wild” (AFLW) database [8] and 300-W dataset shows, that the proposed detector achieves competitive localization error compared to the current state-of-the-art detectors [9–13], yet it keeps the guarantee of finding a globally optimal estimate.

The proposed detector significantly outperforms the detector of [9], on which we build our approach. The authors of [9] propose a multi-view tree based DPM detector, which simultaneously estimates face locations, landmark positions and viewing angles. The conceptual difference to our method is the objective function optimized by the learning algorithm. Their learning algorithm is a variant of a two-class Support Vector Machines [14] which, in this application, optimizes the detection rate of resulting face detector while the landmark positions serve only as latent variables not appearing in the loss function. In contrast, our method based on the Structured Output SVMs optimizes directly the average landmark localization error, being the evaluation metric of landmark detectors. Using the proper learning objective function leads to a significant improvement in the localization accuracy, as we demonstrate empirically.

The contributions of this paper are as follows:
                        
                           •
                           We treat the multi-view landmark detection as an instance of the structured output classification problem. The parameters of the detector are learned from examples by the Structured Output SVM algorithm [5]. Unlike the existing related method [9], the objective function of the learning algorithm is directly related to the performance measure commonly used for evaluation of landmark detectors.

We implemented a coarse-to-fine strategy to decrease the computational complexity of the inference procedure based on the dynamic programing. The proposed strategy allows to keep a real-time performance of the proposed detector when it estimates a dense set of landmarks (for example 68 landmarks on the 300-W benchmark) on high resolution images.

We propose to speed up the evaluation of a dense local feature descriptor via representing the base features (in our case Local Binary Patterns [15]) computed in multiple scales in the form of MIPMAP [7]. The MIPMAP representation avoids repetitive evaluation of the base features which significantly decreases the evaluation time without increasing the localization error.

We experimentally show that a well tuned tree based DPM landmark detector with the guarantee to find globally optimal estimate is comparable in speed and accuracy to other methods using more complex shape models and local optimization strategies like [10–13].

This paper combines the results of our previously published conference paper [16] and a workshop paper [17]. In addition, this paper proposes a coarse-to-fine search strategy which is necessary for the estimation of a dense landmark sets in higher resolution images, such as images appearing in the 300-W competition.

The paper is organized as follows. Related work is discussed in Section 2. The proposed detector and its learning is described in Section 3. The coarse-to-fine strategy is outlined in Section 4. The experimental evaluation is given in Section 5. Finally, Section 6 concludes the paper.

@&#RELATED WORK@&#

The generative methods build a holistic parametric model of the face appearance. The shape and the texture are both represented by linear models learned from a set of aligned faces by the Principal Component Analysis. Fitting the generative model amounts to minimizing the error between the input image and the closest synthetic image generated by the model. Although the shape and the texture are described by linear models, the error function is highly non-linear with respect to the unknown poses and shape parameters. The resulting non-linear minimization problem is solved by iterative descent methods, finding a local optimum quality of which highly depends on an initial estimate. Among the most popular generative methods applied to facial landmark detection belong the Active Appearance Models (AAMs) [18,19] and the Morphable Models [2].

The discriminative methods learn predictors directly estimating pose, shape or the landmark positions from features computed on the input image. The advantages of the discriminative methods are their conceptual simplicity and a low test time. Nowadays, the most popular discriminative approach is a cascade of regressors, that were considered for example in [12,20,21]. Starting from an initial estimate, each regressor refines prediction of the previous one. The prediction in each stage is based on simple features extracted from patches located at positions determined by the output of the previous stage. Besides 2D landmark positions, [11] shows that the cascade of regressors can also accurately estimate pose and shape of a 3D face model. [22,23] proposed to use regression to estimate parameters of the AAMs. Regression methods combined with probabilistic graphical models were proposed in [24,25]. The graphical model is used to aggregate estimates of stochastically sampled local regressors into a single robust prediction.

The Deformable Part Models perform alignment by searching the most likely configuration of local parts. The objective is to maximize the correlation of local parts with the image, simultaneously with the plausibility of their joint geometrical configuration. Instances of the DPM differ in shape model and optimization method used for fitting the model parameters. The Constrained Local Models (CLM) [13,26–29] employ the holistic PCA shape model like the AAMs. While [26] uses a generic optimization method, the works [13,27–29] propose optimization strategies tailored for specific models, which the methods use. For example, [29] proposed a non-parametric representation of the likelihood of landmark configurations and an optimization method resembling the mean-shift algorithm. Unlike the CLM, the Active Shape Models (ASMs) [30] separate the correlation of the local parts with the image and the regularization via a global PCA shape model into separate processes.

A specific category addressed in this paper are the DPM using a tree based graphical model to encode the shape prior [3,4]. The tree based DPM use relatively weak shape prior which can possibly result to anthropologically implausible landmark configurations. On the other hand, the weak shape prior requires less shape variation in the training examples and, most importantly, it allows to find the globally optimal landmark configuration by dynamic programming. The global optimization makes the method independent of an initial estimate which is the biggest advantage over other approaches. In addition, a mixture of DPM allows to model a large range of view angles in a principled way. A notable disadvantage is the high computational demand connected with the search for a globally optimal solution. The model parameters are typically trained from annotated examples by discriminative approaches [9,16], however generative methods can be used as well [31].

The tree based DPM approach [3,4,9,32] translates the estimation of landmark positions into an energy minimization problem. We follow this scheme by introducing a scoring function which is to be maximized w.r.t. the landmark positions and the viewing angle. The shape model is represented by an undirected graph G
                     =(V,
                     E), where V is a finite set of vertices representing the landmarks and 
                        E
                        ⊂
                        
                           
                              
                                 
                                    V
                                 
                              
                              
                                 
                                    2
                                 
                              
                           
                        
                      is a set of edges between pairs of landmarks, whose positions are related.
                        1
                     
                     
                        1
                        The notation 
                              
                                 
                                    
                                       
                                          V
                                       
                                    
                                    
                                       
                                          2
                                       
                                    
                                 
                              
                            means a set of edges of a fully connected graph with nodes V.
                      Examples of particular graphs used in the proposed detector are shown in Figs. 6 and 11.

Let I
                     ∈
                     
                        I
                     
                     
                        H
                        ×
                        W
                      be a fixed-size image (denoted as the normalized frame in the sequel), let ϕ
                     ∈Φ be a discretized yaw angle corresponding to a particular view, let 
                        s
                     
                     =(
                        s
                     
                     1,…,
                     
                        s
                     
                     |
                           V
                        |-1)∈(H
                     ×
                     W)|
                           V
                        | be a configuration of landmark locations and, finally, let 
                        w
                      denote the vector of parameters composed of parameters 
                        
                           w
                           i
                           ϕq
                        
                        ∈
                        
                           R
                           
                              n
                              i
                              ϕq
                           
                        
                      and 
                        
                           w
                           ij
                           ϕg
                        
                        ∈
                        
                           R
                           
                              n
                              ij
                              ϕg
                           
                        
                      (n
                     
                        i
                     
                     
                        ϕq
                      and n
                     
                        ij
                     
                     
                        ϕg
                      denote the number of parameters) associated with the unary and pair-wise potentials, respectively. Then, the scoring function and the proposed detector h
                     :
                     I
                     
                        H
                        ×
                        W
                     
                     →Φ×
                     
                        S
                     , are defined as follows:
                        
                           
                              f
                              
                                 I
                                 ϕ
                                 s
                                 w
                              
                              =
                              
                                 ∑
                                 
                                    i
                                    ∈
                                    V
                                 
                              
                              ‍
                              
                                 q
                                 i
                                 ϕ
                              
                              
                                 
                                    s
                                    i
                                 
                                 I
                                 
                                    w
                                    i
                                    ϕq
                                 
                              
                              +
                              
                                 ∑
                                 
                                    
                                       i
                                       j
                                    
                                    ∈
                                    E
                                 
                              
                              ‍
                              
                                 g
                                 ij
                                 ϕ
                              
                              
                                 
                                    s
                                    i
                                 
                                 
                                    s
                                    j
                                 
                                 
                                    w
                                    ij
                                    ϕg
                                 
                              
                           
                        
                     
                     
                        
                           (1)
                           
                              h
                              
                                 I
                                 w
                              
                              =
                              arg
                              
                                 max
                                 
                                    ϕ
                                    ∈
                                    Φ
                                    ,
                                    s
                                    ∈
                                    S
                                 
                              
                              f
                              
                                 I
                                 ϕ
                                 s
                                 w
                              
                              .
                           
                        
                     
                  

The first part of the scoring function, denoted as the appearance model, is composed of unary potentials q
                     
                        i
                     
                     
                        ϕ
                     (
                        s
                     
                     
                        i
                     ,
                     I;
                     
                        w
                     
                     
                        i
                     
                     
                        ϕq
                     ) measuring the quality of the fit of individual landmark positions 
                        s
                     
                     
                        i
                     , i
                     ∈
                     V, to the image I. The second part, denoted as the deformation cost, is composed of pair-wise potentials g
                     
                        ij
                     
                     
                        ϕ
                     (
                        s
                     
                     
                        i
                     ,
                     
                        s
                     
                     
                        j
                     ;
                     
                        w
                     
                     
                        ij
                     
                     
                        ϕg
                     ) measuring the likelihood of the mutual position of the connected pairs of landmarks.

The normalized frame, serving as an input of the detector, is constructed from a response of a face detector. The face detector provides an estimate of the position, the scale and the in-plane rotation of the face. In order to compensate the imprecision of the face detector, we extend the face box by a multiple of its size. Finally, we apply a similarity transformation to obtain the normalized frame of a fixed size. The process of preparing the normalized frame is illustrated in Fig. 2
                     .
                     
                     
                     
                     
                     
                     
                     
                     
                     
                  

The landmark configuration 
                        s
                      is restricted to be from a predefined area, 
                        s
                        ∈
                        S
                        =
                        
                           S
                           0
                        
                        ×
                        …
                        ×
                        
                           S
                           
                              |
                              V
                              -
                              1
                              |
                           
                        
                     , where 
                        
                           S
                           i
                        
                        ⊂
                        
                           1
                           …
                           H
                        
                        ×
                        
                           1
                           …
                           W
                        
                      denotes the search space of the i-th landmark serving as a hard constraint on the landmark location.

The appearance model is a linearly parameterized function
                              
                                 (2)
                                 
                                    
                                       q
                                       i
                                       ϕ
                                    
                                    
                                       
                                          s
                                          i
                                       
                                       I
                                       
                                          w
                                          i
                                          ϕq
                                       
                                    
                                    =
                                    
                                       
                                          w
                                          i
                                          ϕq
                                       
                                       
                                          
                                             Ψ
                                             i
                                             ϕq
                                          
                                          
                                             I
                                             
                                                s
                                                i
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where 
                              
                                 Ψ
                                 i
                                 ϕq
                              
                              
                                 I
                                 
                                    s
                                    i
                                 
                              
                              :
                              I
                              ×
                              
                                 S
                                 i
                              
                              →
                              
                                 ℝ
                                 
                                    n
                                    i
                                    ϕq
                                 
                              
                            denotes a feature descriptor of a patch cropped from the image I around the position 
                              s
                           
                           
                              i
                           . Our approach allows to use an arbitrary feature descriptor. We have experimented with several descriptors including normalized intensity values, their derivatives and HOGs [33]. In the experiments, we use the multi-scale pyramid of Sparse Local Binary Patterns (S-LBP) [34,16], mainly because of a favorable trade-off between the speed and the resulting localization accuracy. The weight vectors 
                              
                                 w
                                 i
                                 ϕq
                              
                              ∈
                              
                                 R
                                 
                                    n
                                    i
                                    ϕq
                                 
                              
                           , i
                           ∈
                           V, are learned from examples.

The S-LBP descriptor evaluates standard 3×3 Local Binary Pattern (LBP) [15] in each position of the original patch. Each 8bit LBP code is represented by a binary vector composed of all zeros and a single one, whose position is determined by the LBP code. Then the patch is downscaled by a factor of two and the LBPs are computed again in all positions. This process is repeated until the resolution of the downscaled patch is below 3×3 pixels. The resulting sequence of binary vectors is concatenated to a column vector forming the final descriptor. The resulting sparse high-dimensional S-LBP descriptor can be best represented by indices of its components equal to one. To give an example of its dimensionality, let us consider a patch of size 15×15pixels. The number of all 3×3pixels sub-windows in all levels of the scale pyramid is 13×13+5×5+1×1=195. Since each LBP is represented by a 256-dimensional binary vector, the resulting descriptor has n
                           
                              i
                           
                           
                              ϕq
                           
                           =195⋅256=49,920 components.

Finding the optimal landmark location requires computation of the S-LBP features in patches centered in all searched positions. A naïve implementation results in a large number of repetitive evaluations of the base LPB feature descriptor since the search patches are highly overlapped. We propose to pre-compute the base LBP in all scales of the entire normalized frames. The resulting LBP codes are represented in the form of MIPMAP [7], which allows efficient indexing of corresponding features in different scales. The final S-LBP descriptor is then compiled from the MIPMAP on the fly (See Fig. 3
                           .). This approach makes the feature computation independent of the number of sought landmarks (assuming that the computational demand of feature compilation can be neglected), leading to about 40% speedup compared to the naïve implementation. More importantly, this approach allows us to share the pre-computed features among different views making the final structured classifier only sub-linearly slower compared to the naïve strategy evaluating individual DPM detector from a scratch. Note that the feature descriptor evaluated via the MIPMAP representation is not exactly the same as the original S-LBP descriptor. Using the MIPMAP representation leads to skipping some base LBP features computed in lower scales, however, we found that it has no impact on the detectors accuracy.

The deformation cost is also a linearly parametrized function
                              
                                 (3)
                                 
                                    
                                       g
                                       ij
                                       ϕ
                                    
                                    
                                       
                                          s
                                          i
                                       
                                       
                                          s
                                          j
                                       
                                       
                                          w
                                          ij
                                          ϕg
                                       
                                    
                                    =
                                    
                                       
                                          w
                                          ij
                                          ϕg
                                       
                                       
                                          
                                             Ψ
                                             ij
                                             ϕg
                                          
                                          
                                             
                                                s
                                                i
                                             
                                             
                                                s
                                                j
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where 
                              
                                 Ψ
                                 ij
                                 ϕg
                              
                              
                                 
                                    s
                                    i
                                 
                                 
                                    s
                                    j
                                 
                              
                              :
                              
                                 S
                                 i
                              
                              ×
                              
                                 S
                                 j
                              
                              →
                              
                                 R
                                 
                                    n
                                    ij
                                    ϕg
                                 
                              
                           , which similar to [4], is defined as a quadratic function of the displacement vector, namely,
                              
                                 (4)
                                 
                                    
                                       Ψ
                                       ij
                                       ϕg
                                    
                                    
                                       
                                          s
                                          i
                                       
                                       
                                          s
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                δx
                                             
                                          
                                          
                                             
                                                δy
                                             
                                          
                                          
                                             
                                                δ
                                                
                                                   x
                                                   2
                                                
                                             
                                          
                                          
                                             
                                                δ
                                                
                                                   y
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    ,
                                    
                                    where
                                    
                                    
                                    
                                       
                                          
                                             
                                                δx
                                             
                                          
                                          
                                             
                                                δy
                                             
                                          
                                       
                                    
                                    =
                                    
                                       s
                                       i
                                    
                                    −
                                    
                                       s
                                       j
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                   i
                                                
                                                −
                                                
                                                   y
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   x
                                                   j
                                                
                                                −
                                                
                                                   y
                                                   j
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

The n
                           
                              ij
                           
                           
                              ϕg
                           
                           =4-dimensional parameter vectors 
                              
                                 w
                                 ij
                                 ϕg
                              
                              ∈
                              
                                 R
                                 
                                    n
                                    ij
                                    ϕg
                                 
                              
                           , (i,
                           j)∈
                           E, are learned from examples.

The main advantage of having the deformation cost in the form of a separable quadratic function is the possibility to use the distance transform [6] to solve the max-sum problem (1) in time depending linearly on the number of searched positions. The only requirement for application of the distance transform is the concavity of the functions g
                           
                              ij
                           
                           
                              ϕ
                           . By examining the principal minors of the matrix form of g
                           
                              ij
                           
                           
                              ϕ
                           , we see that this can be enforced by linear constraints involving 
                              w
                           
                           
                              ij
                           
                           
                              ϕg
                           . In particular, we need to keep the 3rd and the 4th components of all 4-dimensional vectors 
                              w
                           
                           
                              ij
                           
                           
                              ϕg
                           , (i,
                           j)∈
                           E, negative. We denote the corresponding set of indices of the 3rd and the 4th components of 
                              w
                           
                           
                              ij
                           
                           
                              ϕg
                           , (i,
                           j)∈
                           E, within the joint parameter vector 
                              w
                            by symbol 
                              
                                 J
                                 -
                              
                           .

Thanks to the used parameterization of the unary and pair-wise potentials, the proposed DPM detector (1) is an instance of a linear classifier. Therefore we can learn the parameters by the SO-SVM framework [5]. The joint parameter vector 
                        
                           w
                         to be learned is given by a concatenation of parameter vectors of individual appearance models 
                           w
                        
                        
                           i
                        
                        
                           ϕq
                        , i
                        ∈
                        V, as well as parameter vectors of all deformation costs 
                           w
                        
                        
                           ij
                        
                        
                           ϕg
                        , (i,
                        j)∈
                        E. We define a joint feature map Ψ(I,
                        ϕ,
                        
                           s
                        ) as a concatenation of the feature maps Ψ
                        
                           i
                        
                        
                           ϕq
                        (I,
                        
                           s
                        
                        
                           i
                        ), i
                        ∈
                        V, and Ψ
                        
                           ij
                        
                        
                           ϕg
                        (
                           s
                        
                        
                           i
                        ,
                        
                           s
                        
                        
                           j
                        ), (i,
                        j)∈
                        E. It is seen that with these definitions, the scoring function of the detector (1) can be written as a dot product of the joint parameter vector and the joint feature map, such that f(I,
                        ϕ,
                        
                           s
                        ;
                        
                           w
                        )=〈
                           w
                        ,
                        Ψ(I,
                        ϕ,
                        
                           s
                        )〉.

The SO-SVM algorithm translates the learning of the parameter vector of a linear structured classifier into the following convex program
                           
                              (5)
                              
                                 
                                    w
                                    *
                                 
                                 =
                                 arg
                                 
                                    min
                                    
                                       w
                                       ∈
                                       
                                          ℝ
                                          n
                                       
                                    
                                 
                                 F
                                 
                                    w
                                 
                                 :
                                 =
                                 
                                    
                                       
                                          λ
                                          2
                                       
                                       
                                          
                                             w
                                          
                                          2
                                       
                                       +
                                       
                                          1
                                          m
                                       
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             m
                                          
                                          
                                             r
                                             i
                                          
                                          
                                             w
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 s
                                 .
                                 t
                                 .
                                 
                                    w
                                    i
                                 
                                 ≤
                                 
                                    c
                                    -
                                 
                                 ,
                                 i
                                 ∈
                                 
                                    J
                                    -
                                 
                                 .
                              
                           
                        where r
                        
                           i
                        (
                           w
                        ) is a loss incurred by the classifier on the i-th training example (I
                        
                           i
                        ,
                        ϕ
                        
                           i
                        ,
                        
                           s
                        
                        
                           i
                        ) and 
                           
                              λ
                              2
                           
                           ∥
                           w
                           
                              ∥
                              2
                           
                         is a quadratic regularizer introduced to prevent over-fitting. The optimal setting of the regularization constant λ
                        >0 is tuned on a validation set. Recall, that the inequality constrains are used to ensure the concavity of functions g
                        
                           ij
                        
                        
                           ϕ
                        . To this end, we set 
                           
                              c
                              -
                           
                         to a small negative constant. The loss r
                        
                           i
                        (
                           w
                        ) is the margin-rescaling convex proxy (c.f. [5]) of the true loss Δ
                           ϕ
                           ,
                           
                              s
                           
                        (ϕ,
                        
                           s
                        ,
                        ϕ',
                        
                           s
                        ') and it reads
                           
                              (6)
                              
                                 
                                    r
                                    i
                                 
                                 
                                    w
                                 
                                 =
                                 
                                    max
                                    
                                       ϕ
                                       ∈
                                       Φ
                                       ,
                                       s
                                       ∈
                                       S
                                    
                                 
                                 
                                    
                                       
                                          Δ
                                          
                                             ϕ
                                             ,
                                             s
                                          
                                       
                                       
                                          ϕ
                                          s
                                          
                                             ϕ
                                             ′
                                          
                                          
                                             s
                                             ′
                                          
                                       
                                       +
                                       
                                          w
                                          
                                             Ψ
                                             
                                                
                                                   I
                                                   i
                                                
                                                ϕ
                                                s
                                             
                                          
                                       
                                       −
                                       
                                          w
                                          
                                             Ψ
                                             
                                                
                                                   I
                                                   i
                                                
                                                
                                                   ϕ
                                                   i
                                                
                                                
                                                   s
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

The form of the true loss Δ
                           ϕ
                           ,
                           
                              s
                           
                        (ϕ,
                        
                           s
                        ,
                        ϕ',
                        
                           s
                        ') is discussed later in Section 3.1.1. Evaluation of the proxy loss r
                        
                           i
                        (
                           w
                        ) amounts to running the classifier with the scoring function augmented by the true loss Δ
                           ϕ
                           ,
                           
                              s
                           
                        (ϕ,
                        
                           s
                        ,
                        ϕ',
                        
                           s
                        ').

We solve the problem (5) approximately by the Bundle Methods for Regularized Risk Minimization (BMRM) algorithm [35], which we have slightly modified to accept the inequality constraints on 
                           w
                        . The BMRM algorithm is outlined in Algorithm 1. The core idea is to approximate the original hard problem (5) by a reduced problem
                           
                              (7)
                              
                                 
                                    w
                                    *
                                 
                                 =
                                 arg
                                 
                                    min
                                    
                                       w
                                       ∈
                                       
                                          R
                                          n
                                       
                                    
                                 
                                 
                                    F
                                    t
                                 
                                 
                                    w
                                 
                                 :
                                 =
                                 
                                    
                                       
                                          λ
                                          2
                                       
                                       ∥
                                       w
                                       
                                          ∥
                                          2
                                       
                                       +
                                       
                                          r
                                          t
                                       
                                       
                                          w
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 s
                                 .
                                 t
                                 .
                                 
                                    w
                                    i
                                 
                                 ≤
                                 
                                    c
                                    -
                                 
                                 ,
                                 i
                                 ∈
                                 
                                    J
                                    -
                                 
                                 ,
                              
                           
                        whose objective function F
                        
                           t
                        (
                           w
                        ) is obtained by replacing the risk term 
                           r
                           
                              w
                           
                           =
                           
                              1
                              m
                           
                           
                              ∑
                              
                                 i
                                 =
                                 1
                              
                              m
                           
                           ‍
                           
                              r
                              i
                           
                           
                              w
                           
                         by its cutting plane model
                           
                              (8)
                              
                                 
                                    r
                                    t
                                 
                                 
                                    w
                                 
                                 =
                                 
                                    max
                                    
                                       i
                                       =
                                       0
                                       ,
                                       1
                                       ,
                                       …
                                       ,
                                       t
                                       -
                                       1
                                    
                                 
                                 
                                    
                                       r
                                       
                                          
                                             w
                                             i
                                          
                                       
                                       +
                                       
                                          
                                             r
                                             '
                                             
                                                
                                                   w
                                                   i
                                                
                                             
                                          
                                          
                                             w
                                             -
                                             
                                                w
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           r
                           '
                           
                              
                                 w
                                 i
                              
                           
                           ∈
                           
                              R
                              n
                           
                         denotes a sub-gradient of r(
                           w
                        ) evaluated at 
                           
                              w
                              i
                           
                           ∈
                           
                              R
                              n
                           
                        . Starting from an initial guess 
                           w
                        
                        0
                        =0, the BMRM algorithm computes a new iterate 
                           w
                        
                        
                           t
                         by solving the reduced problem (7). In each iteration t, the cutting plane model (8) is updated by a new cutting plane computed at the intermediate solution 
                           w
                        
                        
                           t
                         leading to a progressively tighter approximation of F(
                           w
                        ). It was proved, that the BMRM converges to an ϵ-precise solution satisfying F(
                           w
                        
                        
                           t
                        )≤
                        F(
                           w
                        
                        ⁎)+
                        ε in 
                           O
                           
                              
                                 1
                                 ϵ
                              
                           
                         iterations for arbitrary ϵ
                        >0. The BMRM accesses the objective via the first order oracle, which for a given query 
                           w
                        
                        
                           t
                         evaluates r(
                           w
                        
                        
                           t
                        ) and the sub-gradient 
                           r
                        
                        '(
                           w
                        
                        
                           t
                        ). Components of the sub-gradient 
                           r
                           '
                           
                              
                                 w
                                 t
                              
                           
                           =
                           
                              1
                              m
                           
                           
                              ∑
                              
                                 i
                                 =
                                 1
                              
                              m
                           
                           ‍
                           
                              
                                 r
                                 '
                              
                              i
                           
                           
                              
                                 w
                                 t
                              
                           
                         can be computed by the Danskin's theorem (see e.g. [36]) as follows:
                           
                              
                                 
                                    
                                       r
                                       '
                                    
                                    i
                                 
                                 
                                    
                                       w
                                       t
                                    
                                 
                                 =
                                 Ψ
                                 
                                    
                                       I
                                       i
                                    
                                    
                                       ϕ
                                       ˆ
                                    
                                    
                                       s
                                       ˆ
                                    
                                 
                                 -
                                 Ψ
                                 
                                    
                                       I
                                       i
                                    
                                    
                                       ϕ
                                       i
                                    
                                    
                                       s
                                       i
                                    
                                 
                                 ,
                              
                           
                        where
                           
                              
                                 
                                    
                                       ϕ
                                       ˆ
                                    
                                    
                                       s
                                       ˆ
                                    
                                 
                                 =
                                 arg
                                 
                                    max
                                    
                                       ϕ
                                       ∈
                                       Φ
                                       ,
                                       s
                                       ∈
                                       S
                                    
                                 
                                 
                                    
                                       
                                          Δ
                                          
                                             ϕ
                                             ,
                                             s
                                          
                                       
                                       
                                          ϕ
                                          s
                                          
                                             ϕ
                                             '
                                          
                                          
                                             s
                                             '
                                          
                                       
                                       +
                                       
                                          w
                                          
                                             Ψ
                                             
                                                
                                                   I
                                                   i
                                                
                                                ϕ
                                                s
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

The BMRM translates the original problem (5) to a sequence of reduced problems (7). The reduced problem can be expressed as an equivalent convex quadratic program, the dual form of which has only t variables. Hence the reduced problem is amenable by off-the-shelf QP solvers. The computational bottleneck is the evaluation of risk r(
                           w
                        ) and its sub-gradient 
                           r
                        
                        '(
                           w
                        ). Fortunately, both quantities are sums of simpler terms, hence their evaluation can be efficiently parallelized.
                           Algorithm 1
                           BMRM algorithm.
                                 
                                 Image 1
                              
                           

The learning algorithm (5) optimizes a convex surrogate of the true loss Δ
                              ϕ
                              ,
                              
                                 s
                              
                           (ϕ,
                           
                              s
                           ,
                           ϕ',
                           
                              s
                           '). The loss Δ
                              ϕ
                              ,
                              
                                 s
                              
                           (ϕ,
                           
                              s
                           ,
                           ϕ',
                           
                              s
                           ') is designed to measure a discrepancy between the true and the estimated landmark positions on a given training example. We define the loss function as follows
                              
                                 (9)
                                 
                                    
                                       Δ
                                       
                                          ϕ
                                          ,
                                          s
                                       
                                    
                                    
                                       ϕ
                                       s
                                       
                                          ϕ
                                          '
                                       
                                       
                                          s
                                          '
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                κ
                                                
                                                   s
                                                
                                                
                                                   1
                                                   
                                                      V
                                                   
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         j
                                                         =
                                                         1
                                                      
                                                      
                                                         V
                                                      
                                                   
                                                   ∥
                                                   
                                                      s
                                                      j
                                                   
                                                   −
                                                   s
                                                   
                                                      '
                                                      j
                                                   
                                                   ∥
                                                   ,
                                                
                                             
                                             
                                                if
                                                
                                                ϕ
                                                =
                                                ϕ
                                                '
                                             
                                          
                                          
                                             
                                                
                                                1
                                                ,
                                             
                                             
                                                
                                                otherwise
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where the normalization constant κ(
                              s
                           ) is a reciprocal to the inter-ocular distance or the distance between the root of the nose and the chin. The inter-ocular distance is a common normalization suitable for near-frontal faces. For large yaw angles the inter-ocular distance goes to zero in which case the root of the nose to chin distance, independent to yaw angle, seems to be a better choice. We use both mentioned normalization constants in experiments. For details see Sections 5.1.1 and 5.3.1.

The penalty for confusing the viewing angle is set to 1, which is much larger value than an acceptable localization error. In turn, the loss function penalizes mistakes in the viewing angle more than the landmark misplacement. Note also that the loss Δ
                              ϕ
                              ,
                              
                                 s
                              
                           (ϕ,
                           
                              s
                           ,
                           ϕ',
                           
                              s
                           ') is non-negative and 0 iff (ϕ,
                           
                              s
                           )=(ϕ',
                           
                              s
                           ') as commonly required by the SO-SVM framework.

Evaluation of the detector (1) amounts to solving an instance of the max-sum problem for each view ϕ separately and then taking the landmark configuration with the overall highest score. A tractability of the max-sum problem depends on the graph G. While our framework does not limit the graph structure, for the sake of speed we set the graph G to be a tree. In this case the global solution can be found in polynomial time by the dynamic programing. For a general graph the max-sum problem is known to be NP-hard. The dynamic programing solver proceeds as follows. The graph is topologically sorted so that the root landmark is evaluated last. Then the leafs are evaluated (that is, the maximizing label is found for each possible label in the adjacent node) and cut away from the graph. The same evaluation procedure propagates till the root landmark is solved. The evaluation in the root landmark provides the optimal value and the optimal landmark position at the root. The remaining landmark positions are obtained by backtracking. For more details see e.g. [37].

The computational time required by a plain dynamic programming scales quadratically with the number of searched landmark positions (given by 
                           
                              S
                              0
                           
                           ×
                           ⋯
                           ×
                           
                              S
                              
                                 
                                    V
                                    −
                                    1
                                 
                              
                           
                        ) and linearly with the number of landmarks. This starts to be impractical for high resolution normalized frames and a dense set of landmarks, which is the case of the 300-W challenge. To alleviate the problem, we use the generalized distance transform (DT) [6], whose computational time scales only linearly with the number of landmark positions. The DT exploits the fact that the pair-wise potentials are concave separable functions of the x and y coordinates. This allows to perform the maximization over a grid search space by effectively maximizing over x and y coordinates separately. For more details on the distance transform we refer to [6].

The DT can be also used in evaluation of the loss r
                        
                           i
                        (
                           w
                        ) and its sub-gradient 
                           r
                        '
                           i
                        (
                           w
                        ), which is the computational bottle-neck of the BMRM. Note that the BMRM maintains the non-negativity constraints necessary for the application of the DT during the whole course of the algorithm. The usage of DT leads to a substantial speed-up of the learning procedure. Detailed experimental evaluation of speed-ups due to the usage of DT is discussed in Section 5.2.

A practical limitation of the DPM detectors is their computational cost scaling with the size of the search spaces of the individual landmark positions, 
                        
                           S
                           i
                        
                     , i
                     ∈
                     V. The size of the search space is a function of the resolution of the normalized frame and the a priori knowledge of the landmark's position. The a priori landmark position depends on the accuracy and robustness of the used face detector. That is, an imprecise localization provided by the face detector has to be compensated by a large search space, in order not to miss the correct landmark position. The search is done in the normalized frame and the found landmark location is projected into the original image. Therefore the resolution of the normalized frame lower bounds the accuracy of the landmark localization. In turn, improving localization accuracy increases the search time.

To alleviate the problem, we propose a coarse-to-fine strategy (denoted also as C2F-DPM) with two stages. In the first stage, we use a DPM detector, denoted as C-DPM, which operates in a low-resolution normalized frame. The output of the C-DPM detector is used to compute a better estimate of the face location than the one provided by the face detector. Hence, the C-DPM detector serves as a precise face detector. In the second stage we apply a DPM detector, denoted as F-DPM, which searches for the landmarks in a high resolution normalized frame. The initial estimate by the C-DPM allows to set much smaller search spaces in the high resolution normalized frame of the F-DPM detector without a danger of overlooking the landmarks. The scheme of the proposed coarse-to-fine strategy is outlined in Fig. 4.

The precise face box used to initialize F-DPM is constructed from the response of the C-DPM detector as follows. The center of the precise face box is computed as the mean of the estimated landmarks. Then the centers of both eyes 
                        C
                     
                     
                        l
                     
                     ,
                     
                        C
                     
                     
                        r
                      are computed (again as the mean position of the corresponding estimated landmarks). The size of the precise face box is defined as 2.7⋅∥
                     
                        C
                     
                     
                        l
                     
                     -
                     
                        C
                     
                     
                        r
                     
                     ∥2. Finally, the in-plane rotation of the precise face box is computed as the deviation of the (least squares optimal) line l fitted to the eyes landmarks and the x-axis. A few examples of the corrected face box are depicted in Fig. 5.

@&#EXPERIMENTS@&#

We split the experiments into two parts. In the first part, Section 5.1, we evaluate the proposed multi-view landmark detector on the AFLW [8] and Multi-PIE [38] datasets. These experiments demonstrate the ability to estimate landmarks robustly in a large range of viewing angles. The measured timing statistics are summarized in Section 5.2. In the second part, Section 5.3, we evaluate the detector on the public part of the 300-W [39,40] datasets and we also present results on the non-public test set obtained from the organizers of the 300-W competition. The experiments in the second part evaluate the ability of the detector to estimate a dense set of landmarks from near-frontal faces in high resolution images.

We discretize the viewing (yaw) angle as follows Φ={-profile, -half-profile, frontal, half-profile, profile}. For each view we detect a different number of landmarks visible from the given range of yaw angles. The particular ranges of the yaw angles and the corresponding number of estimated landmarks are listed in Table 1
                           . The underlying graphs G
                           
                              ϕ
                           
                           =(V,
                           E) of the DPM for individual views are depicted in Fig. 6.

The size of the normalized frame is set to 60×60pixels, which provides sufficient localization accuracy for the AFLW dataset. Since the normalized frame has a relatively small resolution, we do not use the coarse-to-fine strategy in this experiment. A face box found by the face detector is enlarged by a factor of 1.5 and the enlarged box is affinely transformed into the normalized frame. In particular, we use a commercial implementation
                              2
                           
                           
                              2
                              Courtesy of Eyedea Recognition Ltd., http://www.eyedea.cz/.
                            of the Wald-Boost face detector proposed in [41]. In the case when the face detector fails to find a face, the detector returns empty set symbols (
                              s
                           
                           =∅,
                           ϕ
                           =∅) to denote the failure (c.f. definitions of the evaluation metrics in Section 5.1.2). We use the S-LBP features computed by the MIPMAP for the appearance models (2). Each landmark's descriptor was computed from a patch of size 9×9pixels except for the root landmark, the tip of the nose, which used a bigger patch of 15×15pixels. As the deformation cost (3) we use a separable quadratic function of the displacement vector as defined in Eq. (4). This leads to the overall dimensionality of the joint parameter vector 
                              w
                              ∈
                              
                                 R
                                 n
                              
                            equal to n
                           =1,335,360. As the normalization factor κ(
                              s
                           ), present in the true loss (9), we use the face size computed as the distance between the root of the nose and the chin (namely, the distance ∥
                              
                                 s
                           
                           09
                           -
                           
                              s
                           
                           21
                           ∥ using the notation from Fig. 6).

The entire learning procedure composed of tuning the regularization constant λ took around 5days on a machine with a 12 cores CPU.

We use the AFLW [8] database for both training and evaluation and the Multi-PIE [38] database just for the evaluation. Both datasets come with annotation of 21 facial landmarks (see Fig. 6(a)). We used a subset of 12,525 images from the Multi-PIE for which we have precise ground truth annotation. The original AFLW database consists of 24,686 images, however, the annotation of a large number of images is either inconsistent (confused landmarks) or imprecise. In order to correct the annotation, we fitted a 3D face model proposed in [42] to the manually annotated landmarks. The projected landmarks of the 3D model were then manually inspected and corrected when necessary. The process reduced the number of images to 21,688 (mainly due to failures of the face detector involved in the semi-automatic annotation procedure), but it significantly improved the quality of ground truth annotation.

We randomly selected ≈25% of images for training, ≈10% for validation and ≈65% for testing. The number of training examples is relatively small taking into account the number of model parameters, which is dim(
                              w
                           )=1,335,360. Surprisingly, the test accuracy of the learned detector is quite high, which we attribute to the generalization ability of the SO-SVM algorithm.

Once the joint parameter vector 
                              w
                            is learned, we evaluate the detector on the hold out test examples. For the evaluation we use three metrics, namely, the average localization error E
                           loc (sometimes also called point-to-point error), the yaw misclassification rate E
                           yaw and the face detector error E
                           fd defined as follows
                              
                                 (10)
                                 
                                    
                                       E
                                       loc
                                    
                                    
                                       ϕ
                                       s
                                       
                                          ϕ
                                          *
                                       
                                       
                                          s
                                          *
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                
                                                   
                                                      κ
                                                      
                                                         s
                                                      
                                                   
                                                   
                                                      |
                                                      V
                                                      |
                                                   
                                                
                                                
                                                   ∑
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   
                                                      |
                                                      V
                                                      |
                                                   
                                                
                                                ‍
                                                ∥
                                                
                                                   s
                                                   j
                                                
                                                -
                                                
                                                   s
                                                   j
                                                   *
                                                
                                                ∥
                                                ,
                                             
                                             
                                                
                                                if
                                                
                                                ϕ
                                                =
                                                
                                                   ϕ
                                                   *
                                                
                                                
                                             
                                          
                                          
                                             
                                                ∞
                                                ,
                                                if
                                                
                                                s
                                                =
                                                ∅
                                                or
                                             
                                             
                                                ϕ
                                                ≠
                                                
                                                   ϕ
                                                   *
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (11)
                                 
                                    
                                       E
                                       yaw
                                    
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             i
                                          
                                          m
                                       
                                       
                                          
                                             
                                                ϕ
                                                i
                                             
                                             ≠
                                             
                                                ϕ
                                                i
                                                *
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (12)
                                 
                                    
                                       E
                                       fd
                                    
                                    =
                                    
                                       1
                                       m
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             i
                                          
                                          m
                                       
                                       
                                          
                                             
                                                ϕ
                                                i
                                             
                                             =
                                             ∅
                                          
                                       
                                    
                                    ,
                                 
                              
                           where the brackets 〚⋅〛 denote the Kronecker delta, (ϕ
                           
                              i
                           ,
                           
                              s
                           
                           
                              i
                           ) is the detector response on the i-th test image and (ϕ
                           
                              i
                           
                           ⁎,
                           
                              s
                           
                           
                              i
                           
                           ⁎) denotes the ground truth annotation. We report the cumulative histogram of the average localization error E
                           loc and the single number statistics E
                           yaw, E
                           fd. Since most of the competing detectors come with their own integrated face detectors, we cannot separate contributions of the face detector failure from the definition of the evaluation metrics. That is, a face detector failure incurs maximal localization error E
                           loc as well as the yaw misclassification error E
                           yaw.

To avoid a possible confusion of the reader and to make the evaluation comparable with previous works, we also introduce the view insensitive average localization error E
                           loc2 defined as
                              
                                 (13)
                                 
                                    
                                       E
                                       
                                          loc
                                          2
                                       
                                    
                                    
                                       s
                                       
                                          s
                                          *
                                       
                                    
                                    =
                                    
                                       
                                          κ
                                          
                                             s
                                          
                                       
                                       
                                          D
                                       
                                    
                                    
                                       
                                          ∑
                                          j
                                          
                                             D
                                          
                                       
                                    
                                    ∥
                                    
                                       s
                                       j
                                    
                                    −
                                    
                                       s
                                       j
                                       *
                                    
                                    ∥
                                    .
                                 
                              
                           
                        

In contrast to (10), E
                           loc2(
                              s
                           ,
                           
                              s
                           
                           ⁎) does not penalize the misclassification of the viewing angle and it computes the point-to-point error only for the set of detected landmarks (denoted as D). The error E
                           loc2(
                              s
                           ,
                           
                              s
                           
                           ⁎) has been the standard evaluation metric used so far, however, it is not suitable for evaluation of truly multi-view detectors which may return different sets of landmarks depending on the viewing angle like the proposed one (e.g. more landmarks are visible for frontal view than for the profiles).

Since we consider the speed of the detector as its important aspect, we measure timings for all stages of the proposed detector and provide a comparison to other methods.

In this section we describe a list of existing methods against which we compare the proposed detector. Namely, we compare to the tree based DPM detector of Zhu & Ramanan [9], which is the most related to our work. Despite a relatively low localization accuracy, it is up to our best knowledge the only publicly available detector working in the full range of the yaw angle. We also compare against the IntraFace [10] detector, considered to be the current state-of-the-art in both precision and speed, the detector of Kazemi & Sullivan [12], Gauss-Newton Deformable Part Models (GN-DPM) [13], and Chehra [11]. In addition, we evaluate a baseline tree based DPM detector composed of a set of independent view-specific detectors in order to demonstrate the advantage of the proposed structured output model.

To have a fair comparison with the competing methods, we crop the test images around the face box enlarged by 30%. This should minimize the dependency on a specific face detector used by the competing approaches. We also consider only a subset of landmarks common to all methods. In particular, the common subset contains 18 landmarks for the frontal view, leaving out the landmarks representing ears and chin (see Fig. 6a). Not all of the competing methods are capable of estimating the viewing angle. In such case, we use the head pose estimator based on fitting a 3D model to the estimated landmarks [43]. The estimated yaw is then rounded to the intervals defined in Table 1.

To show the benefits of the proposed multi-view detector simultaneously estimating the view angle and the landmark locations, we use the following baseline approach. We learn a set of independent single-view DPM detectors, each for a different view ϕ
                              ∈Φ. The particular single-view detector is then selected based on the response of the face detector providing a rough estimate of the yaw ϕ. The individual single-view detectors have exactly the same structure and use the same features as the proposed multi-view detector.

We use the code provided by the authors with the fully shared model “p99”. This detector simultaneously works as the face detector and detector of facial landmarks. The detector returns 68 or 39 landmarks for the near-frontal or profile views, respectively. The Zhu & Ramanan detector uses a part of the Multi-PIE database for training, which is not consistent with our split. Hence the corresponding results on the Multi-PIE dataset can be positively biased.

We use the implementation of the recently published facial landmark detector provided by the authors. The detector uses a cascade of discriminatively trained regressors estimating the pose and shape parameters of a 3D face model. The detector was trained on the 300-W dataset [40]. The detector returns 49 landmarks.

We use the code kindly provided by the authors. This detector uses supervised descent method (SDM) learning a descent direction from the training data in order to minimize an objective function formulated as a non-linear least squares matching of the face model to the image. It detects 49 landmarks. The detector comes with an estimator of the yaw angle. The detector was learned on a subset of Multi-PIE and LFW [44] datasets. Hence the results on the Multi-PIE dataset can be positively biased, since we use a different split.

We use a code provided by the authors. This detector is an instance of a generative DPM, where the optimization of the appearance and global shape model is done simultaneously by the Gauss–Newton algorithm. It detects 49 landmarks. The detector is initialized from a response of the Zhu & Ramanan detector (using the p204-
                              Wild model). The detector was trained on the LFPW [45] dataset being a part of the 300-W benchmark.

We used the implementation from the “dlib C++” library. This detector is based on a gradient boosting of ensemble of regression trees. It detects 68 landmarks. The detector is trained on the iBUG dataset which overlaps with testing part of the 300-W benchmark. Hence we compare this method only on the AFLW and Multi-PIE datasets.

@&#RESULTS@&#

This section summarizes the comparison of the proposed landmark detector with competing methods on the AFLW and Multi-PIE datasets. In Figs. 7 and 9, we show the cumulative histograms of the mean localization error E
                           loc evaluated on the test images of the AFLW and the Multi-PIE dataset, respectively. Besides statistics computed on all test images, we also evaluate the detectors on subsets of test images with a specified range of the ground truth yaw angle:
                              
                                 •
                                 
                                    near-frontal images with ϕ
                                    ∈(-15∘,15∘)


                                    non-profile images with ϕ
                                    ∈(-60∘,60∘)


                                    profile images with ϕ
                                    ∈(-110∘,-60∘)∪(60∘,110∘)

Most of the detectors are not trained or designed for the full range of yaw angle and thus they fail on the profile images. For this reason, we show results on the profile subset only for the proposed detector, the baseline independent DPM detector and the detector of [9], all operating in the full range of yaw angle. In Table 2
                           , we also show the yaw misclassification error E
                           yaw and the face detector error E
                           fd on the non-profile images.

The results demonstrate that the proposed detector has consistently good localization accuracy in all views. For near-frontal and non-profile faces, the proposed detector does not provide the smallest localization error (E
                           loc
                           <0.075) with the highest frequency but it dominates the other methods in the regime with a tolerable error (E
                           loc
                           >0.075). This behavior is consistent over the AFLW and the Multi-PIE dataset. On profile images, the proposed detector significantly outperforms the only full multi-view competitor [9]. The proposed detector is also consistently better than the baseline composed of independent DPM detectors which demonstrates the benefits of using the structured classifier over the independent estimate of the view and the landmark locations.

The presented comparisons has the following limitations. The main drawback is that the evaluation criteria E
                           loc combines the landmark localization error with the face detector error E
                           fd which, as can be seen from Table 2, is non-negligible. Moreover, on the AFLW dataset our face detector has 0% error because the same detector was involved in the semi-automatic annotation procedure and hence the results of our method are positively biased. This is not the case on the Multi-PIE where, however, our face detector has also significantly lower error. On the other hand, our method and the detector of [9], unlike other competitors returning a single landmark set for all views, are additionally penalized for the incorrect yaw estimates which also contributes to the overall localization error E
                           loc (c.f. Eq. (10)). Another drawback is an inconsistent training set used by different method. The mentioned deficiencies are mitigated by using the 300-W benchmark as described in Section 5.3.

In order to make our evaluation compatible with previous works, we also evaluate the methods using the view insensitive localization error E
                           loc2. The cumulative histograms of E
                           loc2 obtained on the near-frontal examples of the testing subset of both AFLW and Multi-PIE are shown in Fig. 10. It is seen that if the set of landmarks to be estimated is known a priori, the performance of all methods improves significantly. The best performing method is the IntraFace on both datasets. The results of the proposed DPM based detector remain competitive. For completeness, Table 3
                            summarizes the count of intrinsic face detector failures for each method, obtained on the near-frontal examples of the testing subset of both AFLW and Multi-PIE. Note that our commercial face detector is significantly outperforming all competitors, especially on the AFLW database.


                           Fig. 8 shows exemplary outputs of the proposed detector on a sample of test images from the AFLW dataset. We show both examples with small localization error, E
                           loc
                           ≈5%, and the highest error, E
                           loc
                           =∞, that is, images on which the yaw estimate failed.


                        Table 4
                         presents average times required by competing methods to process a single image. The time is measured on the cropped images containing only the face in order to decrease time spent in the face detector which is an integral part of the methods [10,9,12]. We do not count initialization time and, if possible, we subtract the face detector time [12].

The fastest among the compared methods is the independent DPM detector using an external method for the yaw estimate. Otherwise, the proposed DPM detector is consistently significantly faster (by an order of magnitude at least) than the other methods on both AFLW and Multi-PIE datasets.

The processing time required by individual stages of the proposed detector is detailed in Table 5
                        . It is seen that the computations are dominated by the feature evaluation, which depends on the resolution of the normalized frame and the size of the search space. On the other hand, the MAX-SUM inference takes, thanks to the distance transform, less than 20% of the overall time. To demonstrate the benefit of the distance transform, we also show the time required by the MAX-SUM inference when solved by a plain dynamic programming.

@&#IMPLEMENTATION DETAILS@&#

The 300-W dataset contains near-frontal images with all 68 landmarks considered to be always visible. Therefore in this experiment we consider only the single-view variant of the DPM detector. On the other hand, in contrast to the experiments on AFLW and Multi-PIE, we estimate a dense set of 68 landmarks in images with considerably higher resolution. The graph with landmark configuration is depicted in Fig. 11. In order to keep the processing time of the detector reasonably low, we use the proposed coarse-to-fine search strategy, denoted as C2F-DPM detector, with the following settings.

The size of normalized frame of the C-DPM detector is set to 80×80pixels. The normalized frame is obtained by affinely transforming an image cropped around the face box enlarged by a factor of 1.5. The patches used to compute features for the appearance model are set to 13×13pixels for all landmarks except of the root landmark (
                                 s
                              
                              31), whose patch size is 21×21pixels. The C-DPM detector has dim(
                                 w
                              )=2,478,348 parameters in total, which are learned from examples.

The size of normalized frame of the F-DPM detector is set to 160×160pixels. The face box is extended by factor of 1.25. The patches of the appearance model are 15×15 pixels for non-root landmarks and 21×21pixels for the root landmark. The overall dimensionality of the parameter vector 
                                 w
                               is dim(
                                 w
                              )=3,456,012.

We use the public part of the 300-W dataset [39] for training and evaluation of the proposed methods. The public part contains 6,193 images in total. We use the original split of the images to the training and the test part. Since our learning algorithm requires a validation set for tuning the regularization constant, we further split the original training set into training and validation part. This results in 3 subsets: 518 images for testing, 551 for validation (tuning the reg. parameter λ) and 5,124 for training the weights 
                              w
                           . We use the average localization error normalized by the interocular distance. The face detector failures are penalized by ∞. That is, we use the evaluation metric entirely consistent with the 300-W challenge.

Since the available implementations of most of the competing methods do not detect all 68 landmarks we use a subset of 49 landmarks (without the landmarks on the cheek contour) common to all compared detectors. The two missing landmarks from the 51 landmark set are the inner corners of the mouth.


                           Fig. 12(a) shows the cumulative histograms of the average localization error for all compared methods evaluated on the public test set part of the 300-W dataset. The best method appears to be the IntraFace detector [10] closely followed by the proposed C2F-DPM detector. Only marginally worse results are obtained for the Chehra [11] and the GN-DPM detector [13]. The only full multi-view competitor [9] provides reasonable localization error yet significantly worse than the other compared methods.

In Fig. 12(b), we show the localization error of the fine, second stage, F-DPM detector initialized by different methods. Namely, we consider initialization from an uncorrected face detector's bounding box and also from an ideal bounding box computed from the ground truth annotation. It is seen that the proposed initialization from the coarse C-DPM detector (whose error is also shown) yields the best results closely matching the initialization from the ideal bounding box.

The rightmost column of Table 4 reports an average time required by the compared methods to process as a single image of the 300-W dataset. The fastest methods are the IntraFace [10] (which detects 49 landmarks) and the proposed C2F-DPM detector (detecting 68 landmarks). The slowest method is the Zhu & Ramanan [9] which employs the DPM simultaneously for the face localization and the landmark localization unlike the other methods using much faster sliding window face detectors.

The results of the proposed C2F-DPM detector on the non-public test images provided by the organizers of the 300-W competition are summarized in Fig. 13. In Fig. 13(a) we compare localization accuracy of the proposed detector on all four benchmark datasets. First, we include results on a subset of non-profile facial images (and thus comparable with 300-W dataset) from the AFLW and the Multi-PIE dataset processed by the multi-view DPM detector estimating 21 landmarks. Second, we include results obtained by the C2F-DPM detector on the public and the non-public test images of the 300-W estimating 51 landmarks. It is seen that estimation of landmark location jointly with the viewing angle in “multi-view” images from AFLW and Multi-PIE constitutes (not surprisingly) significantly harder problem. Furthermore, we observe that the results on the non-public test images of 300-W are much less optimistic compared to the public ones.

The face detector error E
                           fd on the non-public part was 1.33%.


                           Fig. 13(b) shows the difference in localization accuracy when evaluated on the full set of 68 landmarks and a subset of 51 landmarks not containing the cheek contour landmarks.

@&#CONCLUSIONS@&#

We have proposed a real-time, full multi-view landmark detector based on the Deformable Part Models. The detector uses a mixture of tree based graphical models to capture landmark configurations in a full range of yaw angle. The landmark positions and the viewing angle are estimated simultaneously by a global optimization method based on the dynamic programming. The objective function of the learning algorithm is tightly related to the evaluation metric. The benefits of using a proper objective function are demonstrated by empirical comparison with the Zhu & Ramanan detector [9], which has similar structure, but uses simpler two-class SVM algorithm for learning. To achieve a real-time performance we have implemented several speedups. First, we proposed a coarse-to-fine search strategy using an output of a fast low-resolution DPM detector to shrink a search space of the consequent precise DPM detector operating on a high resolution image. Second, we sped up the computation of LBP based dense feature descriptor by pre-computing base LBP features in multiple scales and representing them as a MIPMAP. Third, we use a DPM with decomposable pair-wise potentials, which allow to reduce the inference time by the distance transform. Experiments on public benchmarks with “in the wild” images show that the proposed detector is comparable in accuracy and speed with other approaches using more complicated shape models and local optimization methods for inference.

An open-source implementation of the proposed detector together with learned models can be downloaded from http://cmp.felk.cvut.cz/~uricamic/clandmark.

@&#ACKNOWLEDGMENTS@&#

MU was supported by The Grant Agency of the CTU in Prague project SGS15/201/OHK3/3T/13. VF was supported by the Ministry of Education, Youth and Sports under project ERC-CZ LL1303. VH was supported by The Technology Agency of the Czech Republic under Project TE01020197 Center Applied Cybernetics.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Supporting the human life-raft in confronting the juggernaut of technology: Jens Rasmussen, 1961–1986

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Thematic survey of Jens Rasmussen's papers (and Risø work reports) from 1961 to 1986.


                        
                        
                           
                           Theme 1: Rasmussen's engineering epistemology.


                        
                        
                           
                           Theme 2: Rasmussen's approach of conceptualizing the problem of technical reliability as a systems problem.


                        
                        
                           
                           Theme 3: Rasmussen's conceptualization of the operator in technical contexts.


                        
                        
                           
                           Theme 4: Supporting the operator's everyday knowing and acting for correct functioning of the system.


                        
                        
                           
                           Theme 5: Emphasis on a generalized qualitative and categorical approach for systems design.


                        
                        
                           
                           Theme 6: Relation between operator and designer in systems design.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Jens Rasmussen

Engineering epistemology

@&#ABSTRACT@&#


               
               
                  Jens Rasmussen's contribution to the field of human factors and ergonomics has had a lasting impact. Six prominent interrelated themes can be extracted from his research between 1961 and 1986. These themes form the basis of an engineering epistemology which is best manifested by his abstraction hierarchy. Further, Rasmussen reformulated technical reliability using systems language to enable a proper human-machine fit. To understand the concept of human-machine fit, he included the operator as a central component in the system to enhance system safety. This change resulted in the application of a qualitative and categorical approach for human-machine interaction design. Finally, Rasmussen's insistence on a working philosophy of systems design as being a joint responsibility of operators and designers provided the basis for averting errors and ensuring safe and correct system functioning.
               
            


                  
                     “It is probably not far from the truth to say that it will always be so - matters relating to an optimal incorporation of humans into systems can be likened to a little life-raft struggling to keep afloat in the wake of the juggernaut of technology - but never catching up. Therefore, any attempts to at least minimize the effects of this unfortunate state of affairs must be based on generalizable concepts and theories which can readily be adapted to a changing world” (Goodstein and Rasmussen, 1980d, p. 41)
                  
               

@&#INTRODUCTION@&#

Jens Rasmussen is an innovator in the fields of Safety Science and Human Factors and Ergonomics (HFE). His groundbreaking theoretical approach asserts a lasting impact on fundamental issues related to the above two fields. During the years 1961–1986, Rasmussen provided a fundamental understanding for cognitive modeling and interface design for human-machine interaction. This paper presents a thematic survey of his English language papers (and Risø work reports) between 1961 and 1986, with a special emphasis on the dimension of engineering epistemology in his approach. The themes that Rasmussen addressed are still pertinent to the field of HFE and can be used to provide novel extensions. For example, the themes identified in this article have been used to extend Cognitive Work Analysis (CWA, Vicente, 1999). Based on these themes, CWA was extended at a fundamental level in terms of accounting for the body and socio-cultural dimension of human knowing and acting for gathering requirements for interface design (see Kant, 2015; Chs. 2, 4, 5 for details).

Returning to Rasmussen's original ideas also allows the modern engineer to grasp the manner in which he formulated the problem and devised a solution in an intellectually singular manner. Especially noteworthy is that he produced an engineering solution to the problem of technical systems reliability. Even though he addressed issues related to human knowing and acting, in his papers he repeatedly emphasized that his approach is not an application of psychological science but is an engineering approach (c.f. Woods and Roth, 1988; Wilson et al., 2013). This aspect of Rasmussen's approach is crucial as it allows for a different way of thinking about cognitive engineering and related engineering fundamentals (see Vicente, 1998 for Risø genotype). In this paper, Rasmussen's approach as a contribution to engineering epistemology has been briefly addressed and can be found in a detailed discussion and chronological survey in Kant, 2015 (Appendix A, also see Kant, 2015; Ch. 3 for a discussion of engineering epistemology).

During the years 1961–1986 six main interrelated themes are salient in Rasmussen's approach. First, Rasmussen presents an engineering knowledge structure that is not a mere application of knowledge gained from psychological science (cognitive science). Treatment of the problem in engineering terms involves not only considering design but also verification and evaluation from a conceptual, qualitative perspective. Second, Rasmussen treats the problem as a holistic systems design problem rather than a divide-and-conquer reductive approach. Therefore, the proposed knowledge framework has elements that fit seamlessly together and have a common underlying understanding of the human and the work environment. Third, he addresses the human as a part of the system and provides a conceptualization of the human in the language of engineering. In doing so, he does not reduce the human to a mechanism, but forms a conceptualization that takes into account the various dimensions required for understanding the human in the overall system functioning. Fourth, Rasmussen emphasizes the need to design for and support the everyday knowing and acting of the operator. This includes understanding the human's (operator's) viewpoint and subjectivity; supporting their common sense reasoning; as well as acknowledging and designing for their tacit knowing and “process feel”. As a result, the emphasis is on a qualitative and categorical mode of enquiry. Finally, an important theme in Rasmussen is the intertwined roles of the operator and designer for successful systems design. The designer and operator are together involved in the design of the control system based on a working philosophy of shared responsibility.

The current article is divided into four main sections. Section 2 provides a background of the past historical research conducted on Rasmussen's approach. Section 3 provides the details of the methodology adopted in this paper and delineates the scope of this article. Section 4 presents the results in the form of six major themes found in Rasmussen's approach. Finally, the article concludes with directions for further research (Section 5 and 6). The references (Section 8.0) are divided into two parts for clarity. References I (Section 8.1) consists of a list of Rasmussen's papers and References II (Section 8.2) presents a list of the other documents cited in this paper.

The ideas proposed by Rasmussen have been addressed historically by three researchers: Jean-Christophe Le Coze (2015), Penelope Sanderson (Sanderson and Harwood, 1988) and Kim Vicente (Vicente, 1997, 1998, 1999, 2001; Vicente and Sanderson, 1992). Sanderson and Harwood (1988) have developed an account explicating the growth of the Skills, Rules, Knowledge (SRK) taxonomy between the years 1969–1981. Whereas Vicente and Sanderson (1992) is a short note delineating the earliest use of the terms in the SRK framework and identifying the timeline in which it was framed. As opposed to the above two papers, Vicente (2001) has developed “a history of the context of justification” of research at Risø Laboratories for the years 1962–1979 (Vicente, 2001, 1998, p. 5; alsobib_Vicente_1998), whereas Vicente (1999, p. 361–365) features a short historical addendum outlining the human factors research program at Risø. In a recent review of Rasmussen's approach, Le Coze (2015) has emphasized the major themes throughout Rasmussen's career with a special emphasis towards safety science and macro issues related to risk and accidents. The current paper adds to the above list by presenting the major themes in Rasmussen's papers with special emphasis on the engineering dimension of his approach. This current article should be considered along with the ones presented by the above researchers for an overall understanding of Rasmussen's approach.

The focus of the present article is on an internalist approach towards the growth of ideas. It consists of all of Rasmussen's English language papers beginning from his earliest papers in 1961 up till 1986, when he published his book on cognitive engineering (see References I
                        2
                     
                     
                        2
                        While all documents have been studied and used for writing this thesis, they have not all been cited in the paper. Nevertheless they are important to the study and therefore have been presented in the reference section. A list of non-cited works that have been helpful in comprehending Rasmussen's approach have been placed at the end of this article. For a chronological summary of all the papers, see Kant, 2015, Appendix A.
                     for details). These documents include sole-authored and co-authored published articles, as well as work reports from Risø Laboratories, Denmark. Rasmussen's 1986 book outlined a major advancement for cognitive engineering and presented, in a consolidated manner, Rasmussen's viewpoint on man-machine systems design that was developed in the previous decades (Rasmussen, 1986). 1986 saw a shift in Rasmussen's focus, thus making it a natural endpoint. Le Coze (2015, p.130) notes that from 1987 onwards there was a clear shift towards the macro issues of accidents and safety in Rasmussen's approach.

I would like to emphasize that the current article is a historical paper addressing Rasmussen's approach. It is an essential task of the historian to bring to light the manner in which the historical actors themselves conceptualized and approached the problems they faced. This is the direction I have taken in the current manuscript based on the reading of Rasmussen papers as well as the supplementary background reading from the citations in his papers. The paper that I have written is a historical paper and brings to light the logic behind Rasmussen's work from 1961 to 1986 and the aspects that I am addressing are the ones that he has raised.

In this study, a few sources were consulted for a detailed analysis of Rasmussen's papers. First, a list of Rasmussen's papers was found in the appendix of the book Tasks, Errors and Mental Models (Goodstein et al., 1988, p. 335). Further, the Risø Laboratories research reports appearing in this list were cross-checked with the library catalogue of the Technical University of Denmark.
                        3
                     
                     
                        3
                        Risø Laboratories became a part of Denmark Technical University (http://www.risoecampus.dtu.dk/?sc_lang=en). The library catalog can be found at http://orbit.dtu.dk/en/.
                      This step was taken in order to ensure that the list of documented papers was complete. For example, Rasmussen's paper “On the Communication between Operators and Instrumentation in Automatic Process Plants” initially appeared as a report (Risø-M-686) in 1968 (in this article, Rasmussen, 1968c) and was later published as a book chapter in 1974 (in this article, Rasmussen, 1974a). However, in the appendix of the book Tasks, Errors and Mental Models, this paper does not appear in 1968 as a work report, but does appear in 1974 as a published source. A third source of Rasmussen's papers was found in the collection of the Advanced Interface Design Lab (AIDL), University of Waterloo, Canada. This source also contained work reports and working papers that were not included in the appendix of the book Tasks, Errors and Mental Models. For example, Rasmussen's 1978 report “Operator/technician errors in calibration, setting, and testing nuclear power plant equipment” (N-17-78, May, 1978; in this paper Rasmussen, 1978d) does not appear as a work report for the year 1978 in the appendix of the book Tasks, Errors and Mental Models. However, in developing accounts of Rasmussen's research, others have referenced this paper (e.g., see Vicente, 1999, 2001). The list from AIDL includes these missing work reports and working papers. Therefore, the list of references (References I) used in this case study is an amalgamation of these three sources.

@&#RESULTS@&#

Rasmussen's intellectual career spans over four decades and presents fundamental contributions to the study of human errors and reliability, as well as modeling of human behavior for systems design. In developing the framework, Rasmussen with his sensibilities of an engineer used an entirely new formulation suited to the purpose of systems design. Even though his framework reflects an understanding from fields such as philosophy, psychology, and linguistics, among others, it is not an application of these fields. In other words, even though Rasmussen deals with human cognition, his approach and related framework of 1986 is not an application of cognitive science — it is an engineering knowledge approach.

In his 1986 book on the cognitive engineering framework for systems design, Rasmussen (1986, p. 1) highlights two major technological trends in the previous decades that influenced the development of the framework. First, there was a growth of complex systems with centralized control. Second, the advent of digital computers and industrial automation changed the manner in which operators conducted work. Due to these changes, work in industrial process plants tended towards supervisory control involving a concomitant focus on operators. Subsequently, a new approach was required for the design of interfaces for process control systems. Rasmussen addressed this challenge by devising a conceptual framework. Rasmussen's 1986 framework consists of four major elements: a “decision ladder” (DL) for studying the diagnostic task; “abstraction hierarchy” (AH) for representing the technical context in which the decision is made; strategies employed for conducting a particular task; along with the “skills, rules and knowledge (SRK) taxonomy” for modeling performance. The importance of this framework is that it provides a systematic method of connecting the higher level goals of the system to the information processing aspects of the human operator, in terms of structural categories. Thus, allowing for a common systems framework to support the thought process of operators in industrial process control. Rasmussen's interpretive study of the operator's knowing and acting led him to formulate generalized knowledge structures. Therefore, a broader theoretical significance of this study is the focus on operators and their ways of knowing and acting in order to sustain correct functioning of technical systems. While acknowledging the different viewpoints of the operators and designers, Rasmussen encourages the designer to share the operator's viewpoint via an interpretive understanding. This interpretive understanding can be gained by a “philosophy of shared responsibility” for systems design. Rasmussen emphasizes the need for considering the operator's “process feel” as well as their traditional ways of knowing and acting.

As Rasmussen's ideas develop, a continuity can be found amongst his papers. The problem that started with a technical outlook related to reliability led to the consideration of the human as a part of the system. In fact, Rasmussen's framework can be best understood as the devising of a systems language to address the human as a part of the complete technical system. In devising the systems language, Rasmussen adopts a multifaceted view that takes into account not only the concept of system reliability, but also a revised view of “human errors”. In this revised view, errors are treated as social concepts — they are labels that are typically attached in retrospect. To substantiate, at the moment in which the act is committed, given the circumstances, the act appears as reasonable to the operator. Due to the system functioning not being transparent to the operator, certain acts are committed that lead to problems later; thus, being labeled as errors in hindsight. By this revised view of errors, Rasmussen emphasizes a deeper qualitative understanding of the concept of “errors” and its treatment for systems design.

An important notion in Rasmussen's framework is the emphasis on the nature of designed systems. Rasmussen notes that engineered systems are different because they incorporate the central ideas of correct functioning and malfunction. Correct functioning is a necessary concept for considering technical systems; i.e., technical systems are devised for performing in a particular manner — a correct manner. It is also to be noted that the idea of correct functioning is an engineering concept and not a scientific concept (see Kant, 2015; Ch. 3 for a discussion of engineering epistemology). Using the distinction between reasons and causes, as presented by the philosopher Michael Polanyi (1964), Rasmussen accounts for correct functioning and malfunction. Along with reasons and causes, the representation of the technical environment (abstraction hierarchy) ranges from the categories relating to function at one end to physical form at the other. The function-form linkage is a hallmark of designed systems and hence, engineering epistemology (Kroes, 2012). These two aspects will be discussed further in theme 1 (Section 4.2.1). Keeping the view in mind that the framework is an engineering knowledge structure allows us to consider Rasmussen's approach as a unified whole, in terms of design, evaluation, operation and verification. Rasmussen also uses the results of human error reports. In doing this he exemplifies the very notion of engineering and correct functioning; studies of failure are common fare in engineering. Therefore, by studying failure reports, he identifies how a framework can be devised to consider operator functioning in situations that led to failure. Finally, the germ of the ideas developed in between these years led Rasmussen to consider more broader issues of risk management in society and technology in his later years (for e.g., Rasmussen, 1997; Rasmussen and Svedung, 2000; also see Le Coze, 2015).

To understand the engineering dimension of Rasmussen's approach, two main aspects of engineering knowledge need to be highlighted (see Kant, 2015, Ch. 3 for a detailed discussion of engineering epistemology). First, engineering knowledge is not an application of scientific knowledge. Engineers use science, however, engineering knowledge cannot be reduced to the label of application of scientific knowledge. Second, design is an integral aspect of engineering. Consequently, designed systems embody a function-structure linkage; i.e., they link the purpose to the form of the artifact (for e.g. Kroes, 2012; Ullman, 2010). Further, these technical artifacts and systems are designed to function correctly and also take into account malfunctions. These notions exemplifying engineering epistemology are also found in Rasmussen's framework (Fig. 1
                        ).

Beginning from the early 1960s, a crucial aspect of Rasmussen's papers is that his modus operandi is an engineering approach and not an application of science. Even though Rasmussen derives ideas from scientists (psychologists, physiologists, among others), his approach is not a direct application of any scientific theory. For example, in devising models for the operator, Rasmussen repeatedly emphasized that his approach was not an application of the then prevalent psychological science:
                           “The model is not intended to be a psychological model of the mental processes of an operator in a basic task, but a functional model to illustrate general aspects of operator's situation at a higher level as seen by the systems designer” (Rasmussen, 1969, no pagination in original, Section 3 – operator model, paragraph after the fourth condition, emphasis added)
                        
                     

Another example of the emphasis on engineering can be observed in Rasmussen's 1974 paper (Rasmussen, 1974b) on the human as a system component. In this paper, he provides the difference between his approach and that of the standard information processing psychology. In the 1970s, information processing theory had a stronghold on psychology. The concepts of information processing theory were derived from communications theory along with the use of concepts such as information and data capacity, among others. According to the information processing view in psychology, since a man has low data processing capacity, redundancy in information processing would ideally have to be reduced. However, Rasmussen notes that this reduction of information will be not amenable from an engineering standpoint. Rather, in engineering, the information would not have to be reduced but presented meaningfully. Thus, Rasmussen conceptualizes the challenges from an engineering viewpoint (Rasmussen, 1974b, p. 10–11; also see figure related to different approaches for channel in information theory and man-machine systems on p. 11):
                           “Primitive use of communication theory generally leads to a statement of the need to reduce the amount of information presented to the man to avoid saturation of his data capacity. Normally this is due to use of the simple analogy of a transmission channel – depicting something like the transatlantic telegraph cable. In our context, however, the principal problem is not the information transmission, but the capacity and reliability of information processing.”
                        
                     

The conceptual differences between scientific knowledge from psychology and requirements for engineering design are also observed in the tools employed by Rasmussen in understanding operator activity. For example, Rasmussen recognized that the operator's mental activity did not follow linear chains of reasoning. There were often jumps between processing steps during moments of insights. To accommodate these leaps of insights, Rasmussen used the standard information processing steps (from psychological science) and turned them into a decision ladder (Vicente, 2001). The operator's insights could be accounted by direct linkages between the information processing steps. Thus even though Rasmussen's approach draws from psychological science, it is not a direct application of scientific knowledge.

Another manner in which Rasmussen's approach can be characterized as engineering knowledge is the accommodation of concepts such as correct functioning and malfunction. Since Rasmussen was addressing nuclear power plant reliability, a crucial requirement was that these systems should function correctly; malfunctions of the power plant were to be strictly avoided. Therefore, in studies of diagnosis of faults, Rasmussen and colleagues (Rasmussen, 1971; Rasmussen and Goodstein, 1972; Rasmussen and Jensen, 1973b, 1974c; Goodstein et al., 1974d) noted the ways in which the troubleshooters used the notion of correct functioning of the device as a reference point.

These studies with the troubleshooters and operators later led to the formulation of the abstraction hierarchy (AH). The AH was a representation of the technical context of the operator (Fig. 1). In the studies with operators and troubleshooters, Rasmussen found that these people used various mental models while diagnosing the problems. These models ranged from those related to physical form to those of functional purpose. Rasmussen consolidated these models based on varying degrees of abstraction. Further, Rasmussen also took into account the notions of correct functioning and malfunctions; thus, emphasizing the designed dimension of technical systems. Here the case of the AH will be discussed in a little more detail to emphasize the engineering approach espoused by Rasmussen.

In his paper outlining the AH, Rasmussen (1979a) begins with providing a taxonomy of categories of mental models that have been extracted from verbal protocols. According to Rasmussen, “The categories of models stratify the span between the physical world on the one side, and human purposes, i.e., the reason for the existence of the physical systems on the other” (Rasmussen, 1979a, p.10). The AH has five levels ranging from physical form to functional purpose (Fig. 1). These categories have been selected to account for various levels of abstraction and concreteness that the operators and troubleshooters required while conducting their activities. It is to be noted that these operators and troubleshooters were working with technical systems (or designed systems) that were expected to function correctly. Therefore, it is not surprising that the categories correspond to a function-structure linkage. Function-structure (physical form) linkage and emphasis on correct functioning is one of the hallmarks of designed systems (see Kroes, 2002, 2012, on dual nature of designed systems, i.e. function structure linkage). In order to address the engineered dimension of the system, Rasmussen incorporates the philosopher Michael Polanyi's “logic of contrivance” to structure the AH.

The philosopher Michael Polanyi in his book “Personal Knowledge: Towards a Post-Critical Philosophy”, addresses the “logic of contrivance” (Polanyi, 1964, Ch. 11). Polanyi claims that even though the “logic of deductive reasoning” and the “logic of empirical inference” has been present in philosophy, the “logic of contrivance” has yet to make inroads. The “logic of contrivance” refers to the logic by which a tool or machine operates. Any machine is built by embodying operational principles that account for the machine correctly: “rules of rightness”.

In contrast to the “rules of rightness” that is required by contrivances, such as machines, technical equipment and the like, the pure sciences do not take these operational principles into account. As a result, the pure sciences treat contrivances as “an altogether chaotic ensemble” (Polanyi, 1964, p.329). Polanyi continues, “In other words, the class of things defined by a common operational principle cannot be even approximately specified in terms of physics and chemistry” (Polanyi, 1964, pg.329, emphasis in original). The challenge then occurs for properly accounting for malfunctions. To answer this question Polanyi underscores the difference between a scientific and technical point-of-view. A technical point-of-view takes into account operational principles of a machine; whereas, a scientific point-of-view missing these principles fails to recognize an object as a technical contrivance:
                              “The first thing to realize is that a knowledge of physics and chemistry would in itself not enable us to recognize a machine. Suppose you are faced with a problematic object and try to explore its nature by a meticulous physical or chemical analysis of all its parts. You may thus obtain a complete physico-chemical map of it. At what point would you discover that it is a machine (if it is one), and if so, how it operates? Never. For you cannot even put this question, let alone answer it, though you have all physics and chemistry at your finger-tips, unless you already know how machines work. [ … ] The physico-chemical topography of the object may in some cases serve as a clue to its technical interpretation, but by itself it would leave us completely in the dark in this respect.” (Polanyi, 1964, pg. 330)
                           
                        

Polanyi ruminates on the two kinds of knowledge — scientific and technical. He mentions that these two kinds of knowledge pursue alternative routes and are asymmetrical in relation to each other. Viewing a machine from a technical perspective reveals true knowledge of its essential character; however, when viewed from a scientific perspective, even when a thorough and detailed examination is provided, it will not provide an insight into the logic of the machine. The challenge, as Polanyi presents, is to account for correct functioning as well as malfunction. In order to account for these two concepts, Polanyi turns to the distinction between reasons and causes. Polanyi notes that correct functioning of the system is provided by “reasons” that account for why the system was devised in a particular manner.

Further, Polanyi elucidates the relation of the physico-chemical nature of the machine with its overall function. Polanyi notes that this physico-chemical makeup contributes to understanding the “causes” of malfunction:
                              “Since rules of rightness cannot account for failures, and reasons for doing something can only be given within the context of rules of rightness, it follows that there can be no reasons (in this sense) for a failure. It is best, therefore, to avoid the use of the word ‘reason’ in this context and to describe the origins of failures invariably as their causes. [ … ] If a stratagem succeeds, it does so in accordance with its own premeditated internal reasons; if it fails, this is due to unforeseen external causes. (Polanyi, 1964, pg. 332, emphasis in original)
                           
                        

The distinction between reasons and causes is central for Rasmussen's approach for structuring the AH; in other words, without reasons and causes, the structural integrity of the AH is lost. In the AH, reasons for correct functioning act top-down, beginning from the level of purpose to the level of physical form. In contrast, the causes of malfunction propagate in the opposite direction. While reasons and causes (and hence the emphasis on the engineering viewpoint) have remained central to Rasmussen's approach, the link to engineering epistemology has not been adequately emphasized by latter-day researchers deriving from Rasmussen's approach (a notable exception highlighting the difference briefly is Le Coze, 2015, p. 128, Section 4.1).

To summarize, the above examples highlight that Rasmussen's approach can be best characterized as lying under the purview of engineering epistemology. The differentiation of an engineering viewpoint from that of a scientific approach is present throughout Rasmussen's career and is discernible in the various knowledge structures, such as the AH. Rasmussen's depiction of the technical context in terms of the AH takes into account the function-structure linkage, correct functioning and malfunction (reasons and causes). Thus, this situates Rasmussen's modus operandi as an engineering knowledge approach.

Along with emphasizing an engineering approach, a central insight that Rasmussen brought to nuclear power plant reliability was the treatment of the problem in terms of a systems viewpoint. In hindsight, this particular theme may seem obvious, but at the time Rasmussen was addressing this problem of reliability, conceptualizing the problem as a systems problem was a conceptual leap (Fig. 2
                        ).

In the early years of 1960 Rasmussen addressed the problem of reliability of electronic equipment and related systems (for e.g., Rasmussen and Timmermann, 1962a, 1962b). The research resulted in a recognition that failure was related to many factors ranging from component quality to maintenance (Jensen et al., 1963). Further, in the late 1960s there was a growing recognition that to address the reliability of nuclear power plants, it was necessary to understand the role of the operators (Rasmussen, 1968a, 1968b, 1969). The operators were considered a part of the system and nuclear power plants had to be optimized together with the operators for the correct functioning of the whole system.

A system is often conceptualized as an entity that has parts that interact in such a way as to provide functional (at times, structural) coherence to each other, as well as to the whole system. As a result, changes in one part of the system are reflected in other parts as well as the overall system. These tenets of the systems approach are also evident in Rasmussen's approach. For example, in addressing the overall system, the operator was highlighted as a system component and the technical system as the operator's environment. Both were taken together in finding the solution to nuclear power plant reliability. Further, there was a necessity for a fit between both the operator and his technical environment. In understanding the operator as a systems component, Rasmussen (1974b) provided a conceptualization which later served as the basis for subsequent formulations (for e.g. Rasmussen, 1976a, 1979a, 1979b, 1980b; Pedersen and Rasmussen, 1980). The treatment of the human was further developed in terms of the skills, rules and knowledge categories involved in human performance (Rasmussen, 1983d). Along with the human, Rasmussen (1979a; Rasmussen and Lind, 1981c) also accounted for the technical environment of the operator by developing consolidated models in the form of abstraction hierarchy (AH). Finally, in the framework of 1986, Rasmussen's (1986) approach to systems design took into account the whole system comprising of the operator, the technical environment and the associated activities. Therefore, the problem which started initially as a technical problem of reliability of nuclear power plants was morphed into a systems problem which took into account the operator and his context in ensuring reliable and safe functioning.

The systems approach is also evident in Rasmussen's treatment of errors (Rasmussen, 1978b, 1978c, 1978d, 1979e, 1980c). In understanding how errors occur, Rasmussen avoids the view in which operators are blamed for errors. Instead, Rasmussen adopts a view in which errors are treated as a social construct, as well as a systemic concept. Rasmussen and colleagues (Pedersen and Rasmussen, 1980; also see Rasmussen and Pedersen, 1980f) identified the multiple factors associated with errors. The notion of the errors could be addressed by removing those pertinent pitfalls rather than either blaming the operators or providing further training in order to avoid errors. Rasmussen's approach to avoiding errors is to provide better support to the operators in terms of information displays, as well as to take into account the performance characteristics of the operators. Along with Rasmussen's solution to building error-tolerant systems, the important aspect to be highlighted in this discussion is that the systemic approach is a key aspect in Rasmussen's papers.

In theme 2 (Section 4.3), it was highlighted that Rasmussen conceived the technical problem of reliability as a systemic problem taking into account the human as a crucial part of the system: the “operator was a system component” and the “system was the operator's environment”. Thus, the essential task was to ensure that a proper fit between the operator and his technical environment is maintained. In the solution to this problem, Rasmussen developed a conceptualization of the operator that served as the basis for his ultimate framework. Beginning in the end of the 1960s, Rasmussen searched for a way to characterize the operator in the nuclear plant.

In 1969, Rasmussen (1969) provided a schematic model of the operator's performance. This model was not a psychological model gained from the application of basic science; rather, it was a functional model devised from systems design (theme 1, Section 4.2). The model of the human in Rasmussen's, 1969 paper consisted of four separate categories accounting for both normal (routine) and abnormal (non-routine) situations. In everyday routine situations, the operator does not delve into the diagnosis of the problem too deeply. In contrast, if unusual patterns of information are encountered by the operator, then he delves into the problem more deeply in order to find an optimal solution. Further, in the case of extremely unfamiliar situations (completely novel problems), the operator makes decisions based on fundamental education and reasoning based on possibilities provided by the situation. Thus, Rasmussen's model of the human operator was based on a variety of situations in which the operator would find himself.


                        Rasmussen (1974b) extended the formulation of the human operator as a system component in 1974. In this paper, the human operator was conceptualized as a creative improviser, symbolic manipulator, versatile, adaptable and context-oriented in nature. Thus, to accommodate these notions of the operator, Rasmussen presented an engineering based functional model of the operator. While Rasmussen draws from a variety of sources, not limited to philosophers, psychologists and physiologists, the model is conceptualized taking into account his past research and an engineering outlook. The various viewpoints were molded into Rasmussen's approach for systems design. Rasmussen's model emphasizes engineering needs and goals:
                           “Man is far more than a mechanistic data processor, but in man-machine systems the designer has to consider him as a versatile but predictable data processor, and the designer has to plan the data processing allocated to the man and to the instrumentation system as one integrated system. The man-machine interface has to be based upon compatible models of the data processing in man and in instruments, and a model of man drawing heavily upon engineering analogies may be fruitful in this respect.” (Rasmussen, 1974b, p.5)
                        
                     

Even though Rasmussen's approach was engineering oriented, it was not reductionist in nature; rather, he attempted to provide a holistic understanding of the operator. Rasmussen's (1974b) model of the human processor had two subcomponents – conscious and subconscious. Both these components comprised a duo; i.e., they supported each other in a reciprocal manner. While the conscious processor was involved in perception, detection and reasoning, among other tasks, the subconscious processor was involved in handling the motor tasks, sub-level processes of perception such as feature integration, among others. Thus, the sub-conscious processor was working in the background while the conscious processor was involved in processes that required careful reasoning and problem-solving activities. The reciprocal nature of the processors also highlights the fact that Rasmussen treats human knowing and acting as intertwined processes.

A salient aspect of Rasmussen's model was that “man is quite simple – but in a complex way” (Rasmussen, 1974b, p.1). The outlook of simplicity of behavior is supported by complex processes proceeding in the background. To characterize the simple outlook as well as the intricate performance in situations, Rasmussen used the human processor to serve as the basis for subsequent formulations (for e.g. Rasmussen, 1976a, 1979b, 1980b; Pedersen and Rasmussen, 1980). This concept of the human as a system component began in the late 1960s and remained a major theme all throughout the 1970s and 1980s (Rasmussen, 1969, 1974b, 1976a, 1983d, 1986; Goodstein and Rasmussen, 1980d). The conception of the human in terms of an engineered functional component of the system remained a key idea in Rasmussen's approach.

In the previous three themes, it was highlighted that Rasmussen's engineering approach conceptualized the operator as a system component and the system as man's technical context. While being a system component, the human operator approaches the task from an everyday experiential viewpoint. In this everyday approach, the designer should not assume that the operator always works on the basis of formal and rational principles. Unlike the scientist or the designer, the operator was not involved in explaining the working of equipment; rather, their goal was to diagnose the fault and remedy it. Therefore, in actual practice the operator's mode of functioning was different from the standard view of how operators comprehend and diagnose the problems. In the standard view, authors of textbooks often describe the detailed anatomy of the equipment assuming that the operators always return to the detailed anatomical understanding for fault diagnosis. However, based on multiple studies (Rasmussen, 1971; Rasmussen and Goodstein, 1972; Rasmussen and Jensen, 1973b, 1974c; Goodstein et al., 1974d), Rasmussen and colleagues highlighted that operators work on the basis of everyday practical reasoning.
                           “a major experience from our work has been the great discrepancy which is often found between the procedures used to handle technical systems in real-life conditions and the imaginations of engineers at their design desks, and we want to stress the importance of more research in real life conditions in industrial environments to permit full advantage to be taken of the flexibility of modern display equipment”. (Rasmussen, 1971, p.276)
                        
                     

Over a period of time while working in the technical contexts, operators acquire a “process feel” (Rasmussen, 1969, 1974b). This process feel is a holistic kind of understanding which forms the basis of knowing and acting in technical contexts. In this holistic mode, the operator behaves in a functional manner to handle the tasks based on the information received and the possible choices in a given situation. In other words, operators act in situations based on the meanings they have for their technical environments. Further, the technical context of the operator is a symbolic world with which the operator interacts both consciously and subconsciously (Rasmussen, 1974b). Therefore, Rasmussen notes that the primary task of the designer is to design displays that support the operator by providing information about the ongoing situation. In other words, designers should support the operator's situated activity (Rasmussen, 1978d, 1979b, 1980b; Rasmussen and Taylor, 1976c).

Immersed in his everyday technical context, the operator becomes adapted to it and develops shortcuts and tricks to handle routine situations. However, in non-routine situations, these shortcuts may prove unfruitful or even hazardous. Based on the findings from error reports and accident analysis reports, Rasmussen (1979e, 1980c; also see Pedersen and Rasmussen, 1980; Rasmussen and Pedersen, 1980f) found that many errors were caused due to the operator being adapted to the technical context. To substantiate, in many cases, the operators missed a certain step or completed steps in manner that was not conducive to the situation at hand. Therefore, in order to avert such errors, Rasmussen highlights that the adaptation of the operator must be supported (Rasmussen, 1969, 1980c).

The emphasis on supporting the operator's knowing and acting in everyday situations is a key aspect of Rasmussen's approach (Fig. 2, also see Rasmussen, 1980b). Based on studies of operators and troubleshooters, Rasmussen (1974b) formulated the decision ladder to support operators' shifts in reasoning and their shortcuts in information processing activities. In 1979, Rasmussen (1979a) provided the abstraction hierarchy to understand the various models that the operator uses during diagnosis of problems. Further, in order to understand the operator's performance in a detailed manner, Rasmussen (1978a) highlighted the need for studying the various strategies employed by the operator as well as the operator's performance in terms of skills, rules, knowledge taxonomy (Rasmussen, 1983d).

In supporting the operator's knowing and acting, a central aspect which comes to the forefront is Rasmussen's insistence on a generalized qualitative and categorical approach (Fig. 1). This emphasis had been present in Rasmussen's approach from the beginning, but became more pronounced in the later years when the AH and SRK were devised.

In understanding operator activity, Rasmussen realized that for systems design, there is a need to move away from analysis of specific instances and understand activity from a broader vantage point. The emphasis for systems design is to understand “what” went wrong instead of “why” (e.g., Rasmussen, 1983c). In any given design problem, there are a multitude of relations between the purposes, functions, equipment. Therefore, to devise a conceptual framework would require a careful understanding of the “what” from a generalized perspective (for e.g., Rasmussen, 1980b); i.e., there is need to comprehend the possibilities for failure to ensure correct function of the technology.

Along with the need for a generalized perspective for systems design, another requirement is the need for handling the inherent variability of the human operator. In everyday tasks the operator is flexible; there are many different ways in which he can achieve a goal (Rasmussen, 1974b). The aim of the designer should be to handle the inherent variability of the operator. Thus, there is a necessity for understanding behavior in terms of generic categories rather than specific instances. To understand the necessity of generic categories, Rasmussen quotes the anthropologist and cybernetician, Gregory Bateson (1979). Bateson used the philosophers Bertrand Russell and Alfred Whitehead's concept of “logic types” (Rasmussen, 1982c). The philosophers Russell and Whitehead note that the generic is often more comprehensible than the specifics. This generic approach maps onto a qualitative understanding. Using generic qualitative concepts to build a framework allows for understanding possibilities of occurrences not completely captured by simply modeling the situations already present.

The generalized and categorical approaches are evident in the elements of Rasmussen's framework such as AH (Rasmussen, 1979a), SRK taxonomy (Rasmussen, 1983d) and the error taxonomy (Rasmussen, 1981e; also see Rasmussen, 1978b; Rasmussen and Pedersen, 1980f; Pedersen and Rasmussen, 1980). All these knowledge structures involve treatment of the subject matter in terms of generic categories. However, since they have been formed on the basis of specific studies (verbal protocol studies, accident reports, error reports and the like), Rasmussen's knowledge structures show an emphasized methodological trait of building theories based on the actual knowing and acting of operators in their everyday practice.

A final major theme in Rasmussen's approach is the discussion of the relation between the operator and the designer. Beginning in the 1960s (see Rasmussen, 1968b, 1968c/1974a, 1969), a question arose about the technical considerations of the control system. The designer had to consider the manner in which the control system ought to be designed to ensure the overall reliability of the nuclear plant. For example, it was infeasible to design the control system to include all unanticipated situations. Also, it is to be noted that normal situations constitute the majority in power plant operation; however, abnormal situations even though rare can prove hazardous. Therefore, the challenge for a designer was to allocate the tasks between the operator and control system. Rasmussen envisioned the task of supervisory control of the nuclear power plant as a joint endeavor between the operator and the control system, in a manner that ensures safe and optimal functioning. He promulgated a “joint responsibility” between the operator and the designer for the design of the control system (e.g. Rasmussen, 1968b, 1968c/1974a, 1978c, 1981b). Under this joint responsibility the task of the designer was to design the control system so as to support the operator's everyday knowing and acting (Theme 4, Section 4.5). Also, the design of the control system should be such that it provides the operator with a holistic understanding of the situation, as well as provide detailed information for diagnosing specific instances. In the long run, proper display of information will avert errors and thus ensure reliability. Rasmussen thus promulgates a “working philosophy” for averting errors, as well as correct and safe system functioning (e.g., see Rasmussen, 1974b).

In theme 4 (Section 4.5), it was highlighted that the designers should support the operator's everyday knowing and acting. This can be done if the designer understands the operator's viewpoint. In order to accomplish this, the designer has to adopt an interpretive understanding of the operator's world; i.e., the designer has to view the everyday tasks and context of the operator as the operator views them. For example, Rasmussen conducted verbal protocol studies to understand how troubleshooters diagnose technical problems. In these studies, he emphasized the necessity for the designer to adopt an interpretive understanding of the operator's viewpoint,
                           “It is important that analysts have a background in engineering for them to imagine themselves in the task situation and have a clear understanding of the meaning of the manipulations and measurements. They can formulate what the man is doing, and thus find the structure in the information handling”. (Rasmussen and Jensen, 1974c, p.296)
                        
                     

Based on the viewpoints of the operators and troubleshooters, the concept of AH was later formulated. Therefore, all throughout the duration of his career discussed here (especially the 1970s and 1980s), the interpretive understanding between the designer and the operator remained a corner stone in Rasmussen's approach (e.g. Rasmussen, 1971, 1976a, 1976e, 1979a, 1979b, 1981b, 1984a; Rasmussen and Jensen, 1973b, 1974c; Rasmussen and Lind, 1981c).

Along with the interpretive understanding, as emphasized in Theme 4 (Section 4.5), Rasmussen highlighted that the designer ought to treat the operator as a system component to ensure overall systems reliability (theme 3; Section 4.4). In this relation, the designer draws on the capabilities of the operator and situates the operator in relation to the overall technical context (Fig. 2). Thus, for a designer two main aspects have to be considered — the operator's viewpoint in the negotiation of the everyday technical context, as well as the operator as a part of the entire system. Thus, as highlighted before, for a designer two reciprocal entities were under consideration, “man as systems component” and “systems as man's work environment”. These two ways in which designer interacts with the operator is also a core theme in Rasmussen's approach.

Based on the summary of Rasmussen's approach, two main directions for future research can be identified—technical and historical. In terms of the technical direction, Rasmussen's papers provide a direction for new tools and methodologies for design related to engineered systems. One direction for future research is in terms of the categories of models that make up the AH (see Rasmussen, 1979a for details on the models). These categories of models can be developed further and interconnected with other theoretical approaches and frameworks in HFE. Further, a key aspect highlighted by Rasmussen is the social dimension of the concept of errors. Even though this aspect has not been developed in detail in this paper, it remains a key concept that emerged in the latter half of his career and has been recently revisited by Le Coze (2015). The views on errors and accidents are still active areas of research and revisiting Rasmussen's ideas will allow for a more detailed scrutiny of basic issues.

From the historical perspective, one direction for further research is a contextual study of Rasmussen's approach from a broader viewpoint. For example, Rasmussen's framework can be approached from the background of the large-scale movement of the alignment of the field of electronics, computers and nuclear power. The nuclear power plant industry was aligned to the growing field of electronics in the middle of the twentieth century (Mcmahon, 1984). As nuclear power engineering was growing as a source of potential power in the 1940–1950s, the growing field of electronics provided the impetus whereby electrical engineers along with mechanical and chemical engineers were involved in the devising of control systems and instrumentation for the functioning of nuclear power plants (Mcmahon, 1984, Ch. 7). Further, over the course of his career, Rasmussen was also a part of the Committee on Safety of Nuclear Installation (CSNI) group of experts involved in researching human factors in nuclear power plants (Nuclear Energy Agency, 1977, p. 165), as well as with other agencies such as the North Atlantic Treaty Organization (NATO). A number of papers filed as work reports and conferences attended were for the purposes of these groups. Therefore, there is a further impetus for studying Rasmussen's papers from the currents of the relationship between human factors, electronics and nuclear power in the international arena for a more detailed understanding of his perspective.

Alternatively, Rasmussen's framework can be approached from a broader perspective of the establishment of nuclear power in Denmark and the growth of Danish technology, infrastructure and knowledge structures. For example, Nielsen and colleagues have provided an account of the Risø Laboratory and its attempts at establishing safe nuclear power in Denmark (Nielsen et al., 1999). Therefore, Rasmussen's approach (as well as other members at Risø) can be understood from a contextual viewpoint of the growth of Risø Laboratories and energy in Denmark.

@&#CONCLUSION@&#

Jens Rasmussen's approach has provided fundamental contributions to safety science and HFE. Six primary themes were identified ranging from his emphasis on a generalized qualitative and categorical approach to discussions of the operator's everyday knowing and acting. Among these themes, the engineering dimensions of Rasmussen's approach were emphasized and the technical constitution of the AH was highlighted. The themes identified in this historical study were used to extend CWA fundamentally (see Kant, 2015). Specifically, revisiting basic viewpoints in Rasmussen's approach allowed for extending CWA for embodiment and socio-cultural dimension of human activity in order to gather information requirements for interface design. Therefore, this extension shows that along with the original framework, Rasmussen's theoretical insights and approach are also valuable for future discussions. Along with the technical dimension a historical viewpoint can be used to situate Rasmussen's approach in the broader currents of technology and society, as well as provide directions for future research.

@&#ACKNOWLEDGMENTS@&#

I would like to dedicate this paper to my teacher and mentor, Scott Campbell, for introducing me to the intricacies of addressing history. I would like to thank Alexander Demos for providing valuable comments on the structure of this paper and Janice Arnott for proof reading this document. Many thanks to Jean Christophe Le Coze for his encouragement for contributing to this special issue. Part of the research for this paper was supported by The Natural Sciences and Engineering Research Council of Canada (NSERC) Discovery grant # 132995 awarded to Catherine Burns. The views addressed in this paper belong to the author and do not represent the views of NSERC or the awardee. I thank NSERC and Catherine Burns for their support.

@&#REFERENCES@&#


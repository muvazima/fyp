@&#MAIN-TITLE@&#Visualization of boundaries in volumetric data sets through a what material you pick is what boundary you see approach

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Human-centric boundary extraction criteria and new boundary model.


                        
                        
                           
                           A novel boundary visualization method though a what material you pick is what boundary you see approach.


                        
                        
                           
                           Point-to-material distance measure.


                        
                        
                           
                           A complete application.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Direct volume rendering

Transfer function

Boundary visualization

3-D edge detection

@&#ABSTRACT@&#


               
               
                  Transfer function design is a key issue in direct volume rendering. Many sophisticated transfer functions have been proposed to visualize boundaries in volumetric data sets such as computed tomography and magnetic resonance imaging. However, it is still conventionally challenging to reliably detect boundaries. Meanwhile, the interactive strategy is complicated for new users or even experts. In this paper, we first propose the human-centric boundary extraction criteria and our boundary model. Based on the model we present a boundary visualization method through a what material you pick is what boundary you see approach. Users can pick out the material of interest to directly convey semantics. In addition, the 3-D canny edge detection is utilized to ensure the good localization of boundaries. Furthermore, we establish a point-to-material distance measure to guarantee the accuracy and integrity of boundaries. The proposed boundary visualization is intuitive and flexible for the exploration of volumetric data.
               
            

@&#INTRODUCTION@&#

Direct volume rendering (DVR) is a widely used visualization technique to demonstrate the internal structures of volumetric data [1,2]. The applications of DVR range from medical visualizations to atmospheric simulations. However, designing an appropriate transfer function (TF) is still particularly challenging which limits the application of DVR. TFs [3] are designed to map data properties (e.g. scalar value, gradient) to optical properties (e.g. color, opacity). Color is used to generate a visual distinction between different data properties [4]. Opacity determines the visual degree of each voxel in volumetric data sets.

The visualization of the boundaries of three-dimensional (3-D) computed tomography (CT) and magnetic resource imaging (MRI) volumetric data has a wide range of applications and great significance for disease diagnosis and screening [5]. In order to highlight boundaries, gradient magnitude (∇f) has often been employed as a data property [3,6]. The most common TFs designed to visualize boundaries are multi-dimensional, such as intensity-gradient (f
                     −|∇f|) histogram [7] and LH histogram [8]. The user interfaces of these sophisticated TF designs provide various widgets to help users to extract regions from the histograms. However, there exist two major obstacles in designing TFs for boundaries. First, the precise localization and detection of the boundaries is difficult. TFs are designed by assigning color and opacity to the extracted regions with the help of the widgets. Sometimes, the regions representing different boundaries are connected due to noise. Therefore, misclassification among different boundaries may occur while extracting regions. When the interference reaches a certain level, it is impossible for users to pick out the boundaries with high quality. Second, semantics is difficult to be integrated into boundary TF design. Multi-dimensional TFs concentrate on data properties which are difficult to be understood by non-experts, such as physicians and radiologists. They have to first translate their domain knowledge into the form of computer graphics. Sometimes a slight change of the translation may lead to a dramatic difference in the final rendering result. It is a tedious task to fine tune the widgets to generate high-quality TFs by non-experts via trial-and-error process.

In this paper, we first propose three boundary visualization criteria and our boundary model. Compared with the classic two-material boundary model which is employed by LH histogram, our model only focuses on one material to achieve the human-centric interaction and introduce edge points for the precise localization of boundaries. Based on this boundary model we propose a what material you pick is what boundary you see boundary visualization that accepts direct manipulations on the original volumetric data, which enables the integration of semantics. Users can directly pick out the material of interest in the 2-D sequential images to transmit semantics. In addition, we utilize 3-D canny edge detection to ensure the good detection and localization of boundaries. Furthermore, we establish a point-to-material distance measure to guarantee the accuracy and integrity of boundaries. Without the tedious region extraction in a newly defined multi-dimensional TF domain and concerning about the quality of the TF design, users can focus on the exploration of the volumetric data intuitively.

This paper is organized as follows: In Section 2, we discuss relevant methods in literature. In Section 3, we describe the general notion of boundary extraction criteria and our boundary model. In Section 4, we present our boundary extraction method based on our boundary model. In Section 5, we establish the TF to visualize boundaries. In Section 6, we use several concrete examples to demonstrate the advantage of our proposed method. In Section 7, we provide the limitations, followed by the conclusion in Section 8.

@&#BACKGROUND@&#

Transfer function design is of essential importance to direct volume rendering. According to whether focusing on the original volumetric data or direct volume rendering images (DVRIs), TFs can be roughly divided into data-centric and image-centric [7].

Data-centric TFs mainly employ inherent data features, such as intensity and derivative magnitude, as the input data properties. In order to aid the design, these features are often organized in the form of histograms.

1-D histogram with the intensity value as x-axis is the most widely used. To highlight boundaries, gradient is introduced to the TF design. Levoy et al. [3] and Drebin et al. [6] put forward a 1-D TF to display different boundaries using gradient magnitude. To reduce the overlapping, Kindlmann et al. [7] proposed a 2-D histogram (f
                           −|∇f|) with the horizontal axis representing intensity value and the vertical axis representing gradient magnitude. Arches in the histogram represent boundaries between different materials. Second derivative [9] and curvature information [10] were integrated into the f
                           −|∇f| histogram to get further improved rendering results.

Unlike the aforementioned histograms using inherent features directly, LH histogram is based on the boundary model proposed by Nickoloff and Riley [11] and treats the boundary as the transition of two idealized homogeneous regions. Lum et al. [12] proposed the early concept of LH. LH means the high intensity and low intensity of the homogeneous regions connected by the boundary. Arches in f
                           −|∇f| histogram are transferred to straight lines in LH histogram for an easy recognition. Sereda [8] compacted the arches to points and lines in LH histogram for a convenient extraction of the boundaries. Serlie [13] derived the relationship between f
                           −|∇f| and LH histogram in a strict mathematic form based on the boundary model. Praßni et al. [14] proposed a new way to efficiently construct LH histogram. Region selecting is the key issue for LH histogram. Sereda et al.[15] used hierarchical clustering to automatically divide LH histogram into independent regions. Nguyen et al. [16] applied mean shift clustering to LH histogram and then used hierarchical clustering to group similar voxels.

Unlike data-centric TFs, image-centric TFs focus on direct volume render images. He et al. [17] and Marks et al. [18] explored the TF space by searching DVRI galleries. As users are the direct receivers, Wu et al. [19] proposed a system to maximize the similarity between the DVRIs and the images given by users. Wu et al. [20] extended the system by introducing four quantitative measures of DVRIs based on the intuitiveness and efficiency of users. To search the appropriate TFs, image-centric TF designs often construct a feedback process of users’ inputs in the form of minimizing information entropy, which can be come down to optimization problems [17,18,20].

Almost each TF design tends to provide a user-friendly interface for a convenient interaction. The data-driven TF designs provide various widgets to users [21,22,9]. These widgets concentrate on the data properties of volumetric data. Although sophisticated widgets [23] have been designed, it is still a tedious task for non-experts to design TFs with little domain knowledge. A few methods such as TFs with semantics [24,25] and sketch-based user interface [26–28] have been proposed to integrate intuitions into the TF design. TFs with semantics introduce an additional level of semantics, which allow experts to design high-level TFs and non-expert users to use intuitively. Sketch-based TFs allow users to directly manipulate data. It is more than just a TF deign interface rather an integrated method of visualization, TF design, human image understanding and special knowledge.

In addition to TF design, other techniques such as isosurface extraction [29–31] can also extract boundaries in volumetric data sets. Isosurface extraction can extract high-quality isosurfaces by the marching-cube algorithm. However, the results are not satisfactory when the isosurface extraction is applied to real-world data sets, because the scalar value of boundaries varies when contaminated by noise.

Our proposed method employs both data-centric TF design and sketch-based user interface design. On one hand, users can directly manipulate the original sequential images to convey semantics. On the other hand, 3-D canny edge detection is utilized to ensure the precise localization of edge points. We combine the high-level of sematic with the low level of edge detection in our boundary model.

The classic two-material boundary (f) [13] is modeled by a scaled step function (u) convolved with 1-D Gaussian edge-spread-function (g) shown in Fig. 1
                        . L and H represent the scalar values of the corresponding materials.
                           
                              (1)
                              
                                 
                                    f
                                    (
                                    x
                                    ,
                                    L
                                    ,
                                    H
                                    ,
                                    σ
                                    )
                                    =
                                    u
                                    (
                                    x
                                    ,
                                    L
                                    ,
                                    H
                                    )
                                    *
                                    g
                                    (
                                    x
                                    ,
                                    σ
                                    )
                                 
                                 
                                    =
                                    L
                                    +
                                    (
                                    H
                                    −
                                    L
                                    )
                                    ×
                                    
                                       1
                                       
                                          σ
                                          
                                             
                                                2
                                                π
                                             
                                          
                                       
                                    
                                    
                                       ∫
                                       
                                          −
                                          ∞
                                       
                                       x
                                    
                                    
                                       exp
                                       
                                          
                                             
                                                
                                                   
                                                      −
                                                      
                                                         
                                                            η
                                                            2
                                                         
                                                      
                                                   
                                                   
                                                      2
                                                      
                                                         σ
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                    
                                 d
                                 η
                                 
                                    =
                                    L
                                    +
                                    (
                                    H
                                    −
                                    L
                                    )
                                    ×
                                    
                                       
                                          
                                             
                                                1
                                                2
                                             
                                             +
                                             
                                                1
                                                2
                                             
                                             erf
                                             
                                                
                                                   
                                                      
                                                         x
                                                         
                                                            σ
                                                            
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        with:
                           
                              (2)
                              
                                 u
                                 (
                                 x
                                 ,
                                 L
                                 ,
                                 H
                                 )
                                 =
                                 L
                                 +
                                 (
                                 H
                                 −
                                 L
                                 )
                                 ×
                                 u
                                 (
                                 x
                                 )
                              
                           
                        
                        
                           
                              (3)
                              
                                 u
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      x
                                                      <
                                                      0
                                                   
                                                
                                             
                                             
                                                
                                                   1
                                                
                                                
                                                   
                                                      x
                                                      ≥
                                                      0
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 g
                                 (
                                 x
                                 ,
                                 σ
                                 )
                                 =
                                 
                                    1
                                    
                                       σ
                                       
                                          
                                             2
                                             π
                                          
                                       
                                    
                                 
                                 exp
                                 
                                    
                                       
                                          
                                             
                                                −
                                                
                                                   
                                                      x
                                                      2
                                                   
                                                
                                             
                                             
                                                2
                                                
                                                   σ
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (5)
                              
                                 erf
                                 (
                                 x
                                 )
                                 =
                                 
                                    2
                                    
                                       
                                          π
                                       
                                    
                                 
                                 
                                    ∫
                                    0
                                    x
                                 
                                 
                                    exp
                                    (
                                    −
                                    
                                       
                                          η
                                          2
                                       
                                    
                                    )
                                 
                                 d
                                 η
                              
                           
                        
                     

Data properties such as gradient and scalar value are introduced to describe the boundary. In general, global histograms, such as intensity-gradient histogram and LH histogram, are established to classify and extract boundaries. There exist two main difficulties in precisely extracting boundaries based on the histograms. One is the difficulty of interaction, users cannot intuitively extract the expected boundary from these data-centric histograms. The other is the absence of noise, it is difficult to motivate for noisy real-world data in general. The precise localization and integrity of the boundary cannot be guaranteed.

To summarize the previous work of the boundary visualization, we propose three performance criteria as follows:
                           
                              •
                              Human-centric interaction. Users can directly operate on the volumetric data.

Good detection. There should be a low probability of misclassification of boundary voxels.

Integrity. The extracted boundary should form an integral surface as much as possible.

Our boundary model is shown in Fig. 2
                        . We only focus on the boundary of one material to achieve an easy implementation of the human-centric interaction. We model the one-material boundary by the boundary function Eq. (1) connecting the material and the edge point. Compared with the classic boundary model, we introduce the edge point since it can be precisely detected by 3-D edge detection.

As it is difficult to implement the flexible human-centric interaction and the precise edge detection simultaneously, the boundary extraction based on our model can be naturally divided into three levels corresponding to the three performance criteria. (1) High level. The human-centric interaction method is introduced to extract the material. (2) Low level. The 3-D canny edge detection is adopted to extract the edge point. The low and high levels are independent of each other. (3) Middle level. This level extracts the boundary connecting the material of the high level to the edge points of the low level based on our boundary model. This level includes two aspects: One is to extract the corresponding edge points of the material, the other is to ensure the integrity of the boundary.

Let the whole volume be V(x), a given boundary be f(L, H), the edge point be p. An obvious relationship between the edge point and the material is shown as follows:
                           
                              (6)
                              
                                 H
                                 −
                                 L
                                 =
                                 2
                                 *
                                 (
                                 H
                                 −
                                 V
                                 (
                                 p
                                 )
                                 )
                                 =
                                 2
                                 *
                                 (
                                 V
                                 (
                                 p
                                 )
                                 −
                                 L
                                 )
                              
                           
                        
                     

In clinical, physicians often view volumetric medical data sets such as CT and MRI in the way of directly scanning each slice of the tomographic images [32]. The location of the material of interest can be precisely picked out in the process of the scanning even if the material is with a small size. Furthermore, the scalar value of the same material is within a small range, which physicians are proficient with. Kniss et al. [9] proposed the notion of the probing widget which helped users to extract points in the volume and visualize them in the transfer function domain. With this extensive interface concept, we design a user interface (Fig. 3
                        (a)) where users can directly observe the scalar value while scanning the sequential 2-D images. Based on the aforementioned bases, after the location of the material of interest is picked out, the material of interest can be extracted by region growing.

Let the volume data be V(x, y, z), where x, y, z are the indexes of the width, height, depth respectively. The material extraction algorithm is described in Algorithm 1.


                        
                           Algorithm 1
                           Human-centric material extraction. 
                                 
                                    
                                       
                                       
                                          
                                             1. Scan the sequential images to obtain the location (x1, y1, z1) of a voxel of the material of interest.
                                          
                                          
                                             2. Set the range (B) of the material of interest.
                                          
                                          
                                             3. Based on the point (x1, y1, z1) and the range B, do region growing to extract the volume of the material of interest.
                                          
                                       
                                    
                                 
                              
                           

Edge detection is a fundamental tool in image processing and computer vision. Among many edge detection methods [33,34], canny edge detection algorithm is one of the most strictly defined methods which provide good and reliable detection. Canny edge detector [35] is an edge detection operator that uses a multi-stage algorithm to detect a wide range of edges in images. Moreover, John F. Canny developed the computational theory of edge detection to explain how this technology works in 1986. As 3-D canny edge detector is a natural extension of the 2-D one, the process of 3-D canny edge detection algorithm can be roughly divided to 5 different steps:
                           
                              1.
                              Apply Gaussian filter;

Calculate the gradient;

Apply non-maximum suppression;

Apply double threshold to get potential edge points;

Track edge by hysteresis.

In this paper, we apply the 3-D canny edge detection to the whole volume data. Considering our boundary model is local and the 3-D canny edge detection is applied to the whole volumetric data, we add two requirements to ensure the edge detection meaningful. First, the size of the Gaussian filter should be small to guarantee the edge points of the material with a small size. Second, the threshold should be small enough to retain the edge points with a small gradient. The user interface of the edge detection (Fig. 3(b)) is the same with that of the material extraction (Fig. 3(a)) so that users can determine the parameters of the edge detection by the results and the original images.

For a given boundary f(x, L, H, σ), we can get the gradient magnitude (|∇f|) of the boundary:
                           
                              (7)
                              
                                 |
                                 ∇
                                 f
                                 |
                                 =
                                 
                                    1
                                    
                                       σ
                                       
                                          
                                             2
                                             π
                                          
                                       
                                    
                                 
                                 (
                                 H
                                 −
                                 L
                                 )
                                 exp
                                 
                                    
                                       
                                          
                                             
                                                −
                                                
                                                   
                                                      x
                                                      2
                                                   
                                                
                                             
                                             
                                                2
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Let the edge point be p. The gradient magnitude of the edge point can be gotten at x
                        =0:
                           
                              (8)
                              
                                 |
                                 ∇
                                 
                                    
                                       f
                                       p
                                    
                                 
                                 |
                                 =
                                 
                                    1
                                    
                                       σ
                                       
                                          
                                             2
                                             π
                                          
                                       
                                    
                                 
                                 (
                                 H
                                 −
                                 L
                                 )
                              
                           
                        
                     

We have extracted the material of interest and the whole edge points respectively. As the material is local while the edge points are global, we extract the edge points connecting to the material of interest based on our boundary model. The boundary between the edge points and the material is a monotonous function defined in Eq. (1), thus the scalar values of the material of interest can be regarded as local maxima/minima along the boundary profile. We use line search to extract the edge points connecting to the material of interest.

Line search aims at finding local maxima/minima and is the backbone of many optimizations, defined as:
                              
                                 (9)
                                 
                                    
                                       
                                          
                                             Min
                                          
                                          
                                             
                                                f
                                                (
                                                
                                                   
                                                      x
                                                      k
                                                   
                                                
                                                +
                                                λ
                                                
                                                   
                                                      d
                                                      k
                                                   
                                                
                                                )
                                             
                                          
                                       
                                       
                                          
                                             
                                                s
                                                .
                                                t
                                                .
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        x
                                                                        
                                                                           k
                                                                           +
                                                                           1
                                                                        
                                                                     
                                                                  
                                                                  =
                                                                  
                                                                     
                                                                        x
                                                                        k
                                                                     
                                                                  
                                                                  +
                                                                  λ
                                                                  
                                                                     
                                                                        d
                                                                        k
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  λ
                                                                  ∈
                                                                  [
                                                                  0
                                                                  ,
                                                                  +
                                                                  ∞
                                                                  )
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           The goal is to find the appropriate λ to satisfy Eq. (9). In our boundary model, the scalar values of the material can be regarded as the local maxima/minima along the boundary profile. Thus line search with the first-order derivative [36] is adopted to find the edge points connecting to the material. Line search stops at x, where ∇f(x
                           −
                           ɛd)*∇
                           f(x
                           +
                           ɛd)≤0, where ɛ is a small real number. Fig. 4
                           (a) shows the schematic diagram of line search applied to our boundary model. The edge point extraction can be described as follows:


                           
                              Algorithm 2
                              Edge point extraction. 
                                    
                                       
                                          
                                          
                                             
                                                Let the volume of the material of interest be V
                                                   
                                                      m
                                                   , the set of the edge points be S.
                                             
                                             
                                                1. Get an element p from S.
                                             
                                             
                                                2. Do line search to find the local maximum and maximum and the locations of the maximum (p
                                                   
                                                      max
                                                   ) and maximum (p
                                                   
                                                      min
                                                   ) for p.
                                             
                                             
                                                3. Check whether p
                                                   
                                                      max
                                                    or p
                                                   
                                                      min
                                                    is in V
                                                   
                                                      m
                                                   . If yes, p is the edge point connecting to the material.
                                             
                                             
                                                4. If S is not empty, go to 1.
                                             
                                          
                                       
                                    
                                 
                              

For a given boundary f(x, L, H, σ), the gradient magnitude (|∇f|) is a scaled Gaussian function shown in Fig. 4(b). Since the whole integration of Gaussian function is 1 and the integration in the range of [−3σ, 3σ] is 0.954, it means the gradient magnitude at x
                           =−3σ and x
                           =3σ approximately equals to 0. As line search stops at x where ∇f(x
                           −
                           ɛd)*∇
                           f(x
                           +
                           ɛd)≤0, we can conclude that after applying line search to our boundary model (Fig. 4(a)), the distance between the edge point (p) and its corresponding extremum (p
                           
                              e
                           ) is as follows:
                              
                                 (10)
                                 
                                    3
                                    σ
                                    −
                                    ξ
                                    ≤
                                    |
                                    p
                                    −
                                    
                                       
                                          p
                                          e
                                       
                                    
                                    |
                                    ≤
                                    3
                                    σ
                                    +
                                    ξ
                                 
                              
                           where ξ is a small real number.

Considering the extraction of the edge points is not robust under the situation that two boundaries are close and noise exists in the volume shown in Fig. 5
                           , we introduce a distance metric to measure the reliability of the extracted edge points.

Let a given boundary be f(x, L, H, σ) (Eq. (1)), the location of the edge point be p, the location of its corresponding local extremum be p
                           
                              e
                           , the whole volume be V(x). We define |p
                           −
                           p
                           
                              e
                           | as the point-to-material distance which establishes the contact between the corresponding edge point and the material of interest. In our boundary model, the gradient magnitude of the edge point can be calculated using Eq. (8). σ can be calculated as follows:
                              
                                 (11)
                                 
                                    σ
                                    =
                                    
                                       
                                          H
                                          −
                                          L
                                       
                                       
                                          |
                                          ∇
                                          
                                             
                                                f
                                                p
                                             
                                          
                                          |
                                          
                                             
                                                2
                                                π
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Without loss of generality, we assume the scalar value of the material is L, adding Eqs. (6)–(11):
                              
                                 (12)
                                 
                                    σ
                                    =
                                    
                                       
                                          2
                                          *
                                          (
                                          V
                                          (
                                          p
                                          )
                                          −
                                          L
                                          )
                                       
                                       
                                          |
                                          ∇
                                          
                                             
                                                f
                                                p
                                             
                                          
                                          |
                                          
                                             
                                                2
                                                π
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

In addition, |p
                           −
                           p
                           
                              e
                           | can be measured by Eq. (10). We can get:
                              
                                 (13)
                                 
                                    3
                                    *
                                    
                                       
                                          2
                                          (
                                          V
                                          (
                                          p
                                          )
                                          −
                                          L
                                          )
                                       
                                       
                                          |
                                          ∇
                                          
                                             
                                                f
                                                p
                                             
                                          
                                          |
                                          
                                             
                                                2
                                                π
                                             
                                          
                                       
                                    
                                    −
                                    ξ
                                    ≤
                                    |
                                    p
                                    −
                                    p
                                    
                                       
                                       e
                                    
                                    |
                                    ≤
                                    3
                                    *
                                    
                                       
                                          2
                                          (
                                          V
                                          (
                                          p
                                          )
                                          −
                                          L
                                          )
                                       
                                       
                                          |
                                          ∇
                                          
                                             
                                                f
                                                p
                                             
                                          
                                          |
                                          
                                             
                                                2
                                                π
                                             
                                          
                                       
                                    
                                    +
                                    ξ
                                 
                              
                           where ξ is a small real number.

There are two advantages to use Eq. (13) as the criterion for the extraction of edge points. One is the universality, each edge point connecting to the material of interest has its own discrimination value. The other is the briefness: On one hand, the uncertain parameter σ is evaded. On the other hand, compared with other complicated classification methods, we only use Eq. (13) which exploits the inherent properties of the edge point and the material of interest. Fig. 6
                            shows the result that the point-to-material distance metric is adopted. The misclassification shown in Fig. 5(d) is almost eliminated by the measure in Eq. (13).

After the edge points connecting to the material have been extracted, the boundary extraction is a process of completely fulfilling the isosurface composed of the edge points with a certain thickness. In general, the process of fulfilling the isosurface is accomplished by region growing on the conjugate direction of the edge points around their local neighborhoods [8]. In this paper, we divide the region growing into two parts: One is region growing along the boundary profile, the other is region growing along the boundary surface. In our boundary model, the scalar value of the material is a local extremum along the boundary profile, therefore, for each voxel around the edge points, we can use line search (Section 4.3.1) not only to determine whether it is a boundary element but also to get its point-to-material distance. In addition, the concept of the neighborhood is based on distance metrics, such as cross, block and sphere. In this paper, we have proposed the point-to-material distance which can be regarded as a measure along the surface. The proposed two region growing are independent of each other, because the region growing directions are perpendicular.

The region growing based on line search starts from the extracted edge points. The whole process is shown in Algorithm 3 which is similar with Algorithm 2.


                        
                           Algorithm 3
                           Region growing based on line search. 
                                 
                                    
                                       
                                       
                                          
                                             Let the volume of the material of interest be V
                                                
                                                   m
                                                , the set of the extracted edge points be S
                                                
                                                   e
                                                .
                                          
                                          
                                             1. Get an unvisited element p from S
                                                
                                                   e
                                                .
                                          
                                          
                                             2. Get the neighborhood (F) on the conjugate direction of p.
                                          
                                          
                                             3. Do line search to find the local extremum and the location of the extremum (p
                                                
                                                   e
                                                ) for each voxel in F.
                                          
                                          
                                             4. Check whether p
                                                
                                                   e
                                                 is in V
                                                
                                                   m
                                                . If yes, the voxel is a boundary element and added to S
                                                
                                                   e
                                                .
                                          
                                          
                                             5. While there exists an element which is not visited in S
                                                
                                                   e
                                                , go to 1.
                                          
                                       
                                    
                                 
                              
                           


                        Fig. 7
                         gives an example of the region growing based on line search for Fig. 6. Most of the boundary elements of the larger circle are extracted while there exist some holes because of Gaussian noise. The aim of the region growing based on the point-to-material distance is to ensure the integrity of the boundary and at the same time to ensure the region growing takes place on the right boundary (Fig. 8
                        ). The algorithm of region growing based on the point-to-material distance is described in Algorithm 4.


                        
                           Algorithm 4
                           Region growing based on the point-to-material distance. 
                                 
                                    
                                       
                                       
                                          
                                             Let the volume of the material of interest be V
                                                
                                                   m
                                                , the set of the extracted boundary elements be S
                                                
                                                   b
                                                .
                                          
                                          
                                             1. Get an unvisited element b from S
                                                
                                                   b
                                                , the location of the extremum (b
                                                
                                                   e
                                                ) of b, the distance D between b
                                                
                                                   e
                                                 and b.
                                          
                                          
                                             2. Get a voexl (p
                                                
                                                   s
                                                ) in the neighborhood (F) on the conjugate direction of b.
                                          
                                          
                                             3. Check whether the distance between p
                                                
                                                   s
                                                 and b
                                                
                                                   e
                                                 is in the range of [γD, D], where γ is a real number near to 1. If yes, do region growing on this voxel and then add the voxel to S
                                                
                                                   b
                                                .
                                          
                                          
                                             4. While there exists an element which is not visited in S
                                                
                                                   b
                                                , go to 1.
                                          
                                       
                                    
                                 
                              
                           

We can establish a TF based on the extracted boundaries by assigning their color and opacity. Color is used for the visual grouping. Users can interactively assign the same color to an extracted boundary by their intuitive feelings. Since non-experts may be unfamiliar with the TF of opacity, we design the mathematical expression (Eq. (14)) with a parameter adjusted by users. As the gradient magnitude of the edge point is a local maximum in our boundary model, the TF is designed to emphasize the voxels close to the edge point (Fig. 9
                     ).
                        
                           (14)
                           
                              TF
                              (
                              α
                              )
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                |
                                                ∇
                                                f
                                                |
                                             
                                             
                                                |
                                                ∇
                                                f
                                                
                                                   
                                                      |
                                                      max
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 λ
                              
                              
                              λ
                              ≥
                              1
                           
                        
                     where TF(α) is the TF for opacity, |∇f| is the gradient magnitude of an extracted boundary element, |∇f|max is the maximum gradient magnitude of the extracted boundary. λ is a parameter adjusted by the users emphasizing the voxels close to the edge point.

@&#RESULTS@&#

We demonstrate our method with medical volume data sets acquired by different equipments such as CT, MRI and DIT. The data sets are obtained from the volume library http://schorsch.efi.fh-nuernberg.de/data/volume/. Detailed information can be found on the web site. As the TF design of boundaries is a dynamic process, we record the entire process of the boundary extraction as videos. The videos can be watched at http://home.ustc.edu.cn/%7Elilu630/WMYPIWBYS.


                        Fig. 10
                         shows the user interface of our boundary extraction method. The left of the interface shows the original sequential 2-D images and the results after 3-D canny edge detection. It is convenient to pick out the material of interest and determine the parameters of the edge detection with the widgets discussed in Sections 4.1 and 4.2. The middle of the interface shows the result of direct volume rendering. As the result of the material extraction and the rendering of the boundary are mutual processes temporally, we use the same widget to visualize them. The right of the interface is the control panel which is divided into three parts: The parameters of the 3-D edge detection, the material and boundary extraction and the TF of opacity. Our interface is human-centric that combines the higher level of human image understanding with the lower level of 3-D canny edge detection. It reaches the aim of what material you pick is what boundary you see. It is convenient to visualize the boundaries of interest even for non-experts. The software package can be obtained by contacting Mr. Lu Li at lilu630@mail.ustc.edu.cn.


                        Fig. 11
                         illustrates the final rendering results of the boundaries in the data set of the CT head sized with 256*256*256. The volume data contains many materials with rich semantics, such as skin, skull and lung. Domain knowledge can be directly integrated into the process of material extraction. Users can quickly identify the meaningful materials and then pick them out. In addition, the point-to-material distance measure ensures the good localization and the integrity of the boundaries.

We compare our boundary visualization method with f
                        −|∇f| and LH histogram in two aspects: One is the interactive method, the other is the rendering quality.

Boundaries are represented as arches in f
                        −|∇f| histogram and points/regions in LH histogram under the assumption that little noise is added to the volume data. In general, the assumption is difficult to be satisfied. Fig. 12
                        (a) and (c) shows the f
                        −|∇f| histogram and LH histogram of the volume data of the CT head respectively. In the f
                        −|∇f| histogram, we can pick out two main arches while other arches are hidden by them. Users need to carefully choose regions to pick out each boundary and avoid misclassification simultaneously with the help of the widget. If the rendering result is unsatisfactory, users have to deal with the histogram via trial-and-error process. In the LH histogram, the regions are connecting together so that it is difficult to extract boundaries from the histogram even with the widget. The boundary extraction methods using f
                        −|∇f| and LH histogram are data-centric, the histograms transfer the boundaries into newly defined data domains and assign the TF design tasks as picking out regions via trial-and-error process. While our method is a human-centric boundary extraction, we combine the high level of semantics with the low level of edge detection. Users can concentrate on the semantics of the original sequential images without concerning the direct manipulation of data. It is more intuitive, especially for non-experts.

The rendering results using f
                        −|∇f| histogram and LH histogram are shown in Fig. 12(b) and (d) respectively. In Fig. 12(b) the shapes of the boundaries are complete, but there are misclassification regions. For example, the skin is rendered in blue and green. In Fig. 12(d) there are few misclassification regions, but the shapes are not complete, especially the blue skin. The quality of the boundary visualization using f
                        −|∇f| histogram and LH histogram is mainly determined by the regions extracted by the users. If we want to visualize a material with a small size, as the histograms are global, the boundary information may be hidden in the histogram. It is a difficult task to pick the boundary out precisely via trail-and-error process even with a well-defined widget. In addition, the quality of the boundary visualization varies widely, experts can achieve a high-quality rendering with their domain knowledge, while non-experts may get a poor-quality rendering using the same widget. Our method separates the high level of semantics from the low level of precise edge detection. The two independent parts are connected by the point-to-material distance measure. This boundary extraction strategy not only takes advantage of the intuition but also the precision of the 3-D canny edge detection. Compared with the rendering results using f
                        −|∇f| and LH histogram, our results are more straightforward to be understood. Non-experts can also get rendering results with high quality.


                        Fig. 13
                         presents the rendering results of the MRI head sized with 181*217*181. The volume data is a simulated brain data set using proton-density-weighted. Domain knowledge can be directly integrated into the boundary extraction process via the local material extraction. Users can quickly identify meaningful materials and our method can automatically extract the boundary of the material of interest. Compared with the CT head data, the distances between different boundaries are smaller and the shapes of the boundaries are more complicated. With the help of the precise canny edge detection and the point-to-material distance measure, the boundaries are integrated with little misclassification.


                        Fig. 14
                         shows the rendering result of the DIT head sized with 128*128*58. DIT is an MRI method that produces in vivo magnetic resonance images of biological tissues sensitized with the local characteristics of molecular diffusion. Compared with MRI images, the contrast of the DIT image is lower. Hence, users should carefully pick out the material of interest with their domain knowledge.

@&#SUMMARY@&#

We have shown three examples using our system. For new users, there exist a few matters needing attention. Firstly, the range of the material needs carefully setting, a small change of the range may lead to a dramatic effect on the material extraction. Secondly, the threshold for the canny edge detection should be small to guarantee that the boundary with small gradient can be detected. Thirdly, if the material of interest is difficult to be extracted, users can focus on the adjacent materials. For example, the skin is a thin material whose intensity range varies greatly, while the intensity of the air changes little. Thus, we choose the air as the material of interest and extract the boundary of the skin in an indirect way.

@&#LIMITATIONS@&#

There exist a few limitations in our proposed boundary visualization method.

First, we use region growing to extract the material of interest under the assumption that the variation of the scalar values of the material is in a small range. The assumption may not be satisfied when a strong bias occurs in the data set. Thus, it is a challenge to pick out the material of interest with high quality. In addition, region growing can only pick out the material in a simply connected region. If the material of interest consists of a few simply connected regions, users have to pick each region out. It is a tedious task when the number of the regions is large.

Second, we use the queue as the data structure in the implementation of the region growing based on line search and the point-to-material distance. We utilize standard C++ library running on CPU without a parallel acceleration. Our implementation cannot achieve real-time interaction (see videos).

In this paper, we propose three criteria and the boundary model for the extraction of boundaries. Based on these foundations we provide a novel what material you pick is what boundary you see boundary visualization method that accepts a direct manipulation on the original sequential images. Users can pick out the material of interest directly to convey semantics. In addition, the 3-D canny edge detection is utilized to ensure the good localization of the boundary. Furthermore, we establish a point-to-material measure to guarantee the accuracy and integrity of the boundary. The proposed boundary visualization method is intuitive and flexible for the exploration of medical volumetric data.

There exist a few extensions that can be developed to improve the quality of the visualization of boundaries.

In this paper, we do not provide a strategy to extract all the boundaries in a volume. As an isolated boundary does not provide much meaningful information, we may establish a frame including a sufficient number of boundaries as a reference before the extraction of the boundary by non-experts. The multi-resolution pyramid may be a solution. We can build the main frame in a large scale, then users can extract the boundary of the material of interest guided by the frame.

The local statistical properties employed in this work are scalar value and gradient. There are other properties such as curvature, texture, etc. How to select and combine these features is worth a further investigation. Recently, the deep learning method brings a new understanding of these features. Farabet [38] employed ConvNets to extract the features and label scene for a 2-D image. This inspired us to employ deep learning method in the visualization of the 3-D data set in our future work.

@&#ACKNOWLEDGEMENT@&#

This project was supported by National Natural Science Foundation of China (Grant Nos. 61172037, 60871087, 81571760, 61501164 and 61401138).

@&#REFERENCES@&#


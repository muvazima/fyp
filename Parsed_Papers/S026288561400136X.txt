@&#MAIN-TITLE@&#Half-sweep imaging for depth from defocus

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a novel imaging approach, “Half-sweep imaging”, for depth from defocus.


                        
                        
                           
                           Novel PSF engineering by focus changes during each exposure time.


                        
                        
                           
                           Complementary responses of the PSFs help image restoration and depth estimation.


                        
                        
                           
                           Increasing the quantity of the incident light affects the quality of DFD estimation.


                        
                        
                           
                           We built the prototype camera and confirmed the effectiveness of our approach.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Computational photography

Depth from defocus

Image deblurring

@&#ABSTRACT@&#


               
               
                  Depth from defocus (DFD) is a technique that restores scene depth based on the amount of defocus blur in the images. DFD usually captures two differently focused images, one near-focused and the other far-focused, and calculates the size of the defocus blur in these images. However, DFD using a regular circular aperture is not sensitive to depth, since the point spread function (PSF) is symmetric and only the radius changes with the depth. In recent years, the coded aperture technique, which uses a special pattern for the aperture to engineer the PSF, has been used to improve the accuracy of DFD estimation. The technique is often used to restore an all-in-focus image and estimate depth in DFD applications. Use of a coded aperture has a disadvantage in terms of image deblurring, since deblurring requires a higher signal-to-noise ratio (SNR) of the captured images. The aperture attenuates incoming light in controlling the PSF and, as a result, decreases the input image SNR. In this paper, we propose a new computational imaging approach for DFD estimation using focus changes during image integration to engineer the PSF. We capture input images with a higher SNR since we can control the PSF with a wide aperture setting unlike with a coded aperture. We confirm the effectiveness of the method through experimental comparisons with conventional DFD and the coded aperture approach.
               
            

@&#INTRODUCTION@&#

There are many methods, referred to as depth from defocus (DFD) techniques [1,2], for estimating scene depth using a single camera. The methods use defocus blur (i.e., blurring that depends on the scene depth) present in the captured images. DFD usually employs a pair of images, one near-focused and the other far-focused, to determine differences in the size of defocus blur resulting from depth differences in the scene. However, the circular shape of the aperture of a regular camera is not beneficial for DFD estimation, since the blurred pattern is not unique for different depths. For more robust DFD estimation, many researchers have investigated coded aperture techniques [3–6], which use special patterns for the camera aperture to control the shape of the point spread function (PSF). Additionally, it is well known that the shape of the PSF directly affects the frequency response of an imaging system, which is described by the optical transfer function in the field of optics. We can select aperture patterns that drastically change the PSF shape in the image domain or its frequency response in the Fourier domain according to scale changes in the PSF due to object depth differences, thereby achieving more accurate DFD estimation in discriminating scene depths. However, the use of a coded aperture attenuates the intensity of captured images, since incident light from the scene is blocked in engineering the PSFs. The attenuation decreases the signal-to-noise ratio (SNR) of the images and limits improvement in DFD estimation.

On the other hand, wavefront coding [7] and a lattice focus lens [8] have been proposed so that incident light is not attenuated. In these cases, special optical elements, called phase plates or lattice lenses, are inserted at the position of the camera aperture to alter the PSFs. Although these methods have an advantage in terms of the image SNR over using a coded aperture, they require specially crafted and expensive optical elements. They are not adaptive to captured scene depths or contexts, since the property of the PSF is fixed and must be predefined before using the camera. It is also difficult to achieve compatibility with regular imaging using a normal circular aperture.

In this paper, we propose a new imaging operation, called half-sweep imaging, for DFD estimation. DFD sometimes ignores the quality of the restored image. We focus on achieving high quality all-in-focus image restoration as well as robust DFD estimation in order to consider visualization of computational photography. The technique, inspired by focus sweeping [9,10], is extended to DFD applications. Half-sweep imaging obtains two images by sweeping the focus during the image exposure time. It has the advantage of a higher SNR for captured images, since we can engineer the image PSFs even if the camera aperture is open. The operation requires continuous changing of the lens focus or sweeping of an image sensor, which is easy to implement since we can utilize the auto-focusing mechanism or an actuator for image stabilization, which current commercial cameras already possess. Moreover, the method is completely compatible with regular imaging and adaptive to scene depth when we stop the sweeping motion or freely adjust the sweeping length and position. Employing the proposed method, we integrate multiple PSFs with different focus settings obtained by focal sweeping to control the frequency responses of imaging PSFs. We split a sweep into half regions to capture images. Thus, two images are obtained for the same scene, but with different PSFs (i.e., transfer functions of imaging). As a result, one of the PSFs and captured images has zero-crossings in its frequency response, which help with depth estimation, while the sum of the PSFs has a broadband spectrum, which allows restoration of a better all-in-focus image. This paper is an extended version of the paper [11], which appeared in PSIVT2011.

@&#RELATED WORK@&#

Many researchers have proposed PSF engineering methods to improve DFD estimation. Surya et al. [12] proposed and implemented a DFD system using two images taken with different circular aperture diameters. Rajagopalan et al. [13] investigated the optimal value of the diameter of a circular aperture for effective DFD. However, the performance of DFD using a circular aperture is unstable owing to its simple symmetric pattern; a special coded pattern must be used for the aperture to improve estimation.

As an early work on coded apertures, Hiura and Matsuyama [3] used three or four pin holes as the apertures of a multiple-focus camera. Three differently focused images captured by the camera were then used to realize robust depth estimation. However, this aperture coding was far from optimal.

Levin et al. [4] proposed using an aperture with a pattern more distinguishable than that of a conventional circular aperture. They defined K–L divergence as a metric for the PSF scale difference due to depth difference and found an optimal pattern for DFD estimation by maximizing the metric. The Fourier spectrum of the pattern contains many zero-crossings, and their positions are displaced when the blur size changes as a result of the depth difference. If we use a different size of PSF for deconvolution, the restored image has severe artifacts due to disagreement with the true PSF spectrum. The artifacts increase the penalty for misrecognizing the depth and improve the stability of DFD estimation. As a result, they allow DFD estimation from a single image, while most commonly used DFD methods require at least two differently focused images to solve ambiguity in the blurred image due to texture. However, the aperture is not suited to restoring an all-in-focus image through deconvolution, since the frequency response of a zero-crossing point is such that we have zero information at that frequency.

Zhou et al. [5,6] proposed a coded aperture pair to restore a high-quality focused image and estimate depth. It is well known that a broadband PSF in the Fourier domain is favorable for blurred-image restoration through deconvolution, since it provides image information for the entire frequency range even though the captured image is blurred [14,15]. However, as mentioned by Levin et al. [4], zero-crossings are favorable for depth estimation. These properties are not compatible with each other when using only a single aperture pattern. A dilemma arises in practical DFD applications in that it is necessary to restore the true texture for accurate depth estimation; however, restoring the texture requires knowledge of the correct depth information. Therefore, Zhou et al. [5,6] proposed the use of a pair of coded apertures that optimize image restoration and depth estimation simultaneously. In the case of their proposed aperture pair, the frequency response of a single PSF has zero-crossings, but the sum of PSFs has a broad band since the PSFs have complementary responses. Nevertheless, the need to replace two lenses with a coded aperture pair remains a difficult problem in image capture. Levin [16] theoretically analyzed the pair of coded aperture patterns for DFD and concluded that Zhou's pair is optimum for DFD and deblurring as well.

A programmable-aperture camera that can quickly switch aperture patterns has been developed [17]. Green et al. [18] proposed a multi-aperture camera that uses special made mirrors. There are examples of implementations that have realized easy capture and increased flexibility for multiple coded apertures. However, PSF engineering using a coded aperture has an intuitive problem: the SNR of the image is lower than that of conventional DFD measurement, since the aperture blocks incident light in controlling the PSF shape. Therefore, there is the limitation that noise in the image destabilizes depth estimation and contaminates the restored image.

Wavefront coding engineers the PSF without blocking incident light unlike in a coded aperture. To apply this method, a special optical element called a phase plate is placed at the position of the camera aperture. The phase plate controls the wavefront of rays according to the positions in the aperture. Dowski et al. [7] proposed a phase plate for DFD estimation whose PSF spectrum has many zero-crossings as in Levin's coded aperture [4]. Levin et al. [8] theoretically analyzed the upper bound of the PSF response for image deblurring and designed an optic, called a lattice focus lens, to realize the PSF. The lens can be used to estimate scene depth and achieve optimal defocus deblurring, since the PSF of the lattice focus lens is depth-variant. Wavefront coding engineers the PSF with an open aperture and realizes image acquisition with a higher SNR. However, the cost of the phase plate is expensive and its property is not adaptive to a scene.

Nagahara et al. [9,10] proposed focus sweep imaging, which moves the focus points during image integration to capture a single image. This method integrates different scales of PSFs to realize PSFs with a broadband frequency response and invariant shapes across the entire scene depth. The authors proposed applying this imaging operation to an extended depth of field by deblurring without any depth estimation or knowledge. The advantages of focal sweep are a higher SNR, compatibility, and flexibility. We can obtain a captured image with a higher SNR since focus sweeping engineers the PSF with an open aperture. Focus sweeping is realized by changing the imager position or using an auto-focus mechanism. We can adaptively change a sweeping region according to the target depth range of the scene. If we terminate the sweeping, a regular image is obtained. However, the PSFs are almost depth invariant and are not applicable to depth estimation. Hasinoff et al. [19] discussed the optimal number of focal stack images across a scene depth for various imaging systems. They applied focal sweep imaging to acquire focal stack (multiple) images, thereby obtaining the best all-in-focus image. Although this has been verified through simulation, the authors did not compare DFD accuracy in their paper.

In this paper, we confirm the effectiveness of our focal sweep approach compared with the conventional method, which uses two images captured with different focal planes, and the coded aperture pairs method [5,6] in terms of the restored all-in-focus image and the accuracy of depth estimation. In all our experiments and analyses, we assumed the target scene to be a static scene, because it is necessary to capture two images of the same target in our method. The static scene assumption is often held in most of the above-mentioned DFD works that use multiple, at least, two input images. The comparative methods used in our analyses, namely, the conventional and coded aperture pair methods, also require two images as input and make the same static scene assumption. Our main contribution in this paper is to reveal how to control and engineer better PSFs to realize robust depth estimation and all-in-focus image restoration.

Focus sweep imaging [9,10] sweeps the focal plane across a scene during the image exposure time. It is achieved by moving the lens or image sensor position along the optical axis. We can manipulate the PSF by controlling the range or speed of the sweep. In this paper, we propose an extension of focal sweep imaging called half-sweep imaging for DFD application. Full-sweep imaging [9,10] sweeps the focal plane across the entire depth of the target scene during the exposure time to realize an extended depth of field. Our half-sweep imaging splits the sweep range into two regions and captures two images corresponding to the front and back halves of the sweeping regions. Consequently, we capture two images with depth-variant blur (PSFs) for DFD estimation, while the original full sweep obtains depth-invariant blur for restoration. In this section, we present the properties and advantages of PSFs in half-sweep imaging.


                     Fig. 1
                      shows the projective geometry where the image sensor is at a distance p from a lens with focal length f, and the aperture diameter is a. Incident rays from a scene point M at a distance u converge at the focus point m at a distance v from the lens. The relation between u and v is given by the Gaussian lens law:
                        
                           (1)
                           
                              
                                 1
                                 f
                              
                              =
                              
                                 1
                                 u
                              
                              +
                              
                                 1
                                 v
                              
                              .
                           
                        
                     
                  

As shown in the figure, if an image sensor is placed at a distance p from the lens, M is imaged to m′ with blur on the sensor. The diameter of the blurred circle b is given by
                        
                           (2)
                           
                              b
                              
                                 p
                              
                              =
                              
                                 a
                                 v
                              
                              
                                 
                                    
                                       v
                                       −
                                       p
                                    
                                 
                              
                              .
                           
                        
                     
                  

The PSF is a function of the distribution of light energy within the blurred circle. Here we consider r to be the distance of an image point from the center m′ of the blurred circle, and the PSF is denoted by P(r,
                     u,
                     p). The PSF is often modeled as a pillbox function:
                        
                           (3)
                           
                              P
                              
                                 r
                                 u
                                 p
                              
                              =
                              
                                 4
                                 
                                    π
                                    
                                       b
                                       2
                                    
                                 
                              
                              
                                 ∏
                                 
                                    
                                       
                                          r
                                          b
                                       
                                    
                                    ,
                                 
                              
                           
                        
                     where ∏(x) is the rectangle function, which has a value 1 if |x|<1/2 and 0 otherwise. This is the PSF function of an object placed at u when the sensor position is fixed at p as in regular imaging with a common camera.

In half-sweep imaging, the sensor moves from p
                     0 to p
                     2 along the optical axis of the camera as shown in Fig. 2(a). We assume that focus points of all objects in a scene lie between p
                     0 and p
                     2. The half-sweep imaging captures two images, f
                     1 and f
                     2, with exposures e
                     1 and e
                     2, respectively, as shown in Fig. 2(b). The sensor motion is modeled as a function of time, p(t)=
                     st
                     +
                     p
                     0, if the sensor moves with constant speed s. The relation between sensor motion and exposure time is shown in Fig. 2(b). This figure shows that exposures e
                     1 and e
                     2 for capturing images f
                     1 and f
                     2 correspond with sweep regions from p
                     0 to p
                     1 and from p
                     1 to p
                     2, respectively. Hence, we obtain two images with different integrations of different blurred images focusing at positions between p
                     0 and p
                     1 or p
                     1 and p
                     2. It is easy to realize half sweeping by simply changing the shutter timings and exposure time from those for full sweeping. An imaging process can be modeled by convolution of the PSF function:
                        
                           (4)
                           
                              
                                 f
                                 i
                              
                              =
                              
                                 k
                                 i
                              
                              ⊗
                              
                                 f
                                 0
                              
                              +
                              ξ
                              ,
                              
                              i
                              =
                              1
                              ,
                              2
                              ,
                           
                        
                     where f
                     
                        i
                      is the observed image, k
                     
                        i
                      is the PSF kernel, f
                     0 is the latent in-focus image, and ξ is image noise, assumed to be Gaussian white noise N(0,
                     σ
                     2). Normally, the shape of a PSF is determined by the aperture size and object depth as defined by Eq. (3). Meanwhile, the half-sweep PSF h
                     
                        i
                      is modeled by integration of PSFs at multiple sensor positions p throughout the sweeping regions during the exposure time. This is denoted by
                        
                           (5)
                           
                              
                                 h
                                 i
                              
                              
                                 r
                                 u
                              
                              =
                              
                                 
                                    ∫
                                    
                                       p
                                       
                                          i
                                          −
                                          1
                                       
                                    
                                    
                                       p
                                       i
                                    
                                 
                                 
                                    P
                                    
                                       r
                                       u
                                       p
                                    
                                    dp
                                    ,
                                    
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                 
                              
                           
                        
                     where p
                     
                        i
                      (i
                     =0,1,2) is the position of the image sensor. The sensor moves from p
                     
                        i
                        −1 to p
                     
                        i
                      during the exposure time e
                     
                        i
                     . If we assume that the integrated blur model is a pillbox function as described in Eq. (3), the half-sweep PSF is modeled as
                        
                           (6)
                           
                              
                                 h
                                 i
                              
                              
                                 r
                                 u
                              
                              =
                              
                                 uf
                                 
                                    
                                       
                                          u
                                          −
                                          f
                                       
                                    
                                    πas
                                    
                                       p
                                       i
                                    
                                 
                              
                              
                                 
                                    
                                       
                                          
                                             λ
                                             
                                                p
                                                
                                                   i
                                                   −
                                                   1
                                                
                                             
                                          
                                          +
                                          
                                             λ
                                             
                                                p
                                                i
                                             
                                          
                                       
                                       r
                                    
                                    −
                                    
                                       
                                          2
                                          
                                             λ
                                             
                                                p
                                                
                                                   i
                                                   −
                                                   1
                                                
                                             
                                          
                                       
                                       
                                          b
                                          
                                             
                                                p
                                                
                                                   i
                                                   −
                                                   1
                                                
                                             
                                          
                                       
                                    
                                    −
                                    
                                       
                                          2
                                          
                                             λ
                                             
                                                p
                                                i
                                             
                                          
                                       
                                       
                                          b
                                          
                                             
                                                p
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                              ,
                              
                              i
                              =
                              1
                              ,
                              2
                              ,
                           
                        
                     where b(p) is the diameter of the blurred circle at position p, and λ
                     
                        p
                     
                     =1 if b(p)≥2r and 0 otherwise.


                     Fig. 3(a) shows simulated half-sweep PSFs, h
                     1 and h
                     2 modeled by Eq. (6) and their average PSF h
                     
                        all
                      at four different scene depths. The four different depth positions u are determined by the relation of the lens law so that the corresponding focal positions v are at constant intervals on the sensor side. The average PSF h
                     
                        all
                      is simply derived from h
                     
                        all
                     
                     =(h
                     1
                     +
                     h
                     2)/2. Therefore, we consider h
                     
                        all
                      to be the same as the fullsweep PSF [9,10], since the sum of h
                     1 and h
                     2 is an integration of different focal images across the entire swept region. The figure shows that PSF shapes h
                     1 and h
                     2 change according to depth differences, while the shape of the average PSF h
                     
                        all
                      does not vary visually. Fig. 3(b) shows the logarithms of the power spectrums of the three PSFs with different scene depths in the frequency domain, where H
                     1, H
                     2, and H
                     
                        all
                      are the discrete Fourier transforms of h
                     1,
                     h
                     2, and h
                     
                        all
                     , respectively. This plot corresponds to Fig. 3(a). The spectrums of H
                     1 and H
                     2 change according to depth. We also see zero-crossings in one of the spectrums. On the other hand, H
                     
                        all
                      has a broadband spectrum. Levin et al. [4] and Zhou et al. [5,6] claimed that PSFs with zero-crossings are a useful property of the DFD measurement and improve depth discrimination. Additionally, it is well known that broadband PSFs are beneficial for defocus deblurring [5,6,9,10,14,15] and allow the generation of good quality all-in-focus images in DFD applications.

In this section, we theoretically evaluate some PSFs to confirm the effectiveness of our half-sweep PSF. We use modified versions of the metric proposed by Hasinoff et al. [19] to evaluate the quality of image restoration and accuracy of depth estimation.

The metric modeled the peak signal-to-noise ratio (PSNR) as the image quality. Hence, the image quality metric is defined as a function of PSF kernels, k
                     1 and k
                     2, and is given by:
                        
                           (7)
                           
                              IQM
                              
                                 
                                    k
                                    1
                                 
                                 
                                    k
                                    2
                                 
                              
                              =
                              
                                 
                                    P
                                    ⋅
                                    
                                       
                                          
                                             f
                                             max
                                          
                                          2
                                       
                                    
                                 
                                 
                                    
                                       
                                          max
                                          d
                                       
                                    
                                    E
                                    
                                       
                                          
                                             
                                                
                                                   f
                                                   0
                                                   
                                                      d
                                                   
                                                
                                                −
                                                
                                                   
                                                      f
                                                      ^
                                                   
                                                   0
                                                
                                             
                                          
                                          2
                                       
                                    
                                 
                              
                              ,
                           
                        
                     where P is the number of pixels per image and f
                     
                        max
                      is the maximum possible value of pixel intensity. Furthermore, f
                     0
                     (d) is a scene image at depth d and 
                        
                           
                              
                                 f
                                 ^
                              
                              0
                           
                        
                      is the restored all-in-focus image of this scene. The quality metric is calculated by an expected restoration error, 
                        E
                        
                           
                              
                                 
                                    
                                       f
                                       0
                                       
                                          d
                                       
                                    
                                    −
                                    
                                       
                                          
                                             f
                                             ^
                                          
                                          0
                                       
                                    
                                 
                              
                              2
                           
                        
                     , which is defined as:
                        
                           (8)
                           
                              E
                              
                                 
                                    
                                       
                                          
                                             f
                                             0
                                             
                                                d
                                             
                                          
                                          −
                                          
                                             
                                                
                                                   f
                                                   ^
                                                
                                                0
                                             
                                          
                                       
                                    
                                    2
                                 
                              
                              =
                              
                                 
                                    ∑
                                    ω
                                 
                                 
                                    
                                       
                                          ∫
                                          
                                             d
                                             ^
                                          
                                       
                                       
                                          Pr
                                          
                                             
                                                
                                                   d
                                                   ^
                                                
                                                |
                                                d
                                             
                                          
                                          E
                                          
                                             
                                                
                                                   
                                                      
                                                         F
                                                         0
                                                      
                                                      −
                                                      
                                                         
                                                            
                                                               F
                                                               ^
                                                            
                                                            0
                                                            
                                                               
                                                                  d
                                                                  ^
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                2
                                             
                                          
                                          d
                                          
                                             d
                                             ^
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where F
                     0 is the Fourier transform of the scene image and 
                        
                           
                              
                                 F
                                 ^
                              
                              0
                              
                                 d
                              
                           
                        
                      is the Fourier transform of the restored all-in-focus image. Eq. (8) consists of two parts; 
                        Pr
                        
                           
                              
                                 d
                                 ^
                              
                              |
                              d
                           
                        
                      and 
                        E
                        
                           
                              
                                 
                                    
                                       F
                                       0
                                    
                                    −
                                    
                                       
                                          
                                             F
                                             ^
                                          
                                          0
                                          
                                             
                                                d
                                                ^
                                             
                                          
                                       
                                    
                                 
                              
                              2
                           
                        
                     , indicating the probability of depth selection as an estimated depth and the expected restoration error of the estimated depth in the frequency domain, respectively. The metric, IQM(k
                     1,
                     k
                     2) shows the PSNR of the restoration image for the worst case depth. Thus, as the value increases, the PSFs, k
                     1 and k
                     2, achieve better performance for image restoration.

We also modeled a metric for evaluating the accuracy of depth estimation, which is defined as:
                        
                           (9)
                           
                              DEM
                              
                                 
                                    k
                                    1
                                 
                                 
                                    k
                                    2
                                 
                              
                              =
                              
                                 
                                    max
                                    d
                                 
                              
                              E
                              
                                 
                                    
                                       
                                          d
                                          −
                                          
                                             d
                                             ^
                                          
                                       
                                    
                                    2
                                 
                              
                              ,
                           
                        
                     where the expected depth error is given by:
                        
                           (10)
                           
                              E
                              
                                 
                                    
                                       
                                          d
                                          −
                                          
                                             d
                                             ^
                                          
                                       
                                    
                                    2
                                 
                              
                              =
                              
                                 
                                    ∑
                                    ω
                                 
                                 
                                    
                                       
                                          ∫
                                          
                                             d
                                             ^
                                          
                                       
                                       
                                          Pr
                                          
                                             
                                                
                                                   d
                                                   ^
                                                
                                                |
                                                d
                                             
                                          
                                          
                                             
                                                
                                                   d
                                                   −
                                                   
                                                      d
                                                      ^
                                                   
                                                
                                             
                                             2
                                          
                                          d
                                          
                                             d
                                             ^
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     in a similar manner to Eq. (8). In Eq. (10), 
                        Pr
                        
                           
                              
                                 d
                                 ^
                              
                              |
                              d
                           
                        
                      also indicates the probability of depth selection, while 
                        
                           
                              
                                 d
                                 −
                                 
                                    d
                                    ^
                                 
                              
                           
                           2
                        
                      obviously shows the L2 distance between the estimated depth and actual depth. This metric gives the expected error of depth estimation for the worst-case depth. As the value decreases, the PSFs, k
                     1 and k
                     2, achieve better performance for depth estimation.

We are supposed to estimate the restored all-in-focus image 
                        
                           
                              
                                 F
                                 ^
                              
                              0
                              
                                 d
                              
                           
                        
                      using the maximum a posteriori (MAP) estimation, as the peak of:
                        
                           (11)
                           
                              Pr
                              
                                 
                                    
                                       F
                                       0
                                    
                                    |
                                    F
                                    ,
                                    d
                                 
                              
                              =
                              N
                              
                                 
                                    
                                       1
                                       
                                          σ
                                          2
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   K
                                                   ¯
                                                
                                                
                                                   
                                                      d
                                                   
                                                   T
                                                
                                             
                                          
                                          F
                                       
                                    
                                    
                                       V
                                       
                                          d
                                       
                                    
                                    ,
                                    
                                       V
                                       
                                          d
                                       
                                    
                                 
                              
                              ,
                           
                        
                     where vector 
                        F
                     
                     =[F
                     1 
                     F
                     2]
                        T
                      collects the frequency transform of two captured images, f
                     1 and f
                     2, vector 
                        K
                     
                     (d)
                     =[K
                     1
                     (d) 
                     K
                     2
                     (d)]
                        T
                      collects the frequency transform of the PSF coefficients k
                     1
                     (d) and k
                     2
                     (d) for the input images, σ is the read noise level, and 
                        K
                     
                     (d) indicates a complex conjugate of 
                        K
                     
                     (d). V
                     (d) in Eq. (11) indicates the variance in the MAP estimate, that is:
                        
                           (12)
                           
                              
                                 V
                                 
                                    d
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          1
                                          
                                             σ
                                             2
                                          
                                       
                                       
                                          
                                             
                                                K
                                                
                                                   d
                                                
                                             
                                          
                                          2
                                       
                                       +
                                       
                                          1
                                          S
                                       
                                    
                                 
                                 
                                    −
                                    1
                                 
                              
                              .
                           
                        
                     
                  


                     S is the per frequency prior texture variance, the distribution of which is assumed to be Gaussian.

Under these conditions, we expect the error of MAP restoration 
                        E
                        
                           
                              
                                 
                                    
                                       F
                                       0
                                    
                                    −
                                    
                                       
                                          
                                             F
                                             ^
                                          
                                          0
                                          
                                             d
                                          
                                       
                                    
                                 
                              
                              2
                           
                        
                      in Eq. (8) using an estimated depth 
                        
                           d
                           ^
                        
                     , to be:
                        
                           (13)
                           
                              E
                              
                                 
                                    
                                       
                                          
                                             F
                                             0
                                          
                                          −
                                          
                                             
                                                
                                                   F
                                                   ^
                                                
                                                0
                                                
                                                   
                                                      d
                                                      ^
                                                   
                                                
                                             
                                          
                                       
                                    
                                    2
                                 
                              
                              =
                              
                                 
                                    
                                       S
                                       
                                          σ
                                          2
                                       
                                    
                                    
                                       
                                          Δ
                                       
                                       2
                                    
                                    −
                                    
                                       
                                          Δ
                                          +
                                          
                                             
                                                
                                                   Δ
                                                   ¯
                                                
                                                T
                                             
                                          
                                       
                                    
                                 
                              
                              
                                 1
                                 
                                    σ
                                    2
                                 
                              
                              
                                 
                                    
                                       V
                                       
                                          
                                             d
                                             ^
                                          
                                       
                                    
                                    2
                                 
                              
                              +
                              
                                 V
                                 
                                    
                                       d
                                       ^
                                    
                                 
                              
                              ,
                           
                        
                     where the scalar 
                        Δ
                        =
                        
                           
                              
                                 K
                                 ¯
                              
                              
                                 
                                    
                                       d
                                       ^
                                    
                                 
                                 T
                              
                           
                        
                        
                           
                              
                                 K
                                 
                                    d
                                 
                              
                              −
                              
                                 K
                                 
                                    
                                       d
                                       ^
                                    
                                 
                              
                           
                        
                      measures the discrepancy between the true and estimated PSFs (i.e., the Δ would be zero if both PSFs have the same property). Eq. (13) can calculate the expected error independently of the scene texture.

In addition, 
                        Pr
                        
                           
                              
                                 d
                                 ^
                              
                              |
                              d
                           
                        
                      in Eq. (8) is computed from the probability of obtaining different depth estimates 
                        
                           d
                           ^
                        
                      over a set of sampled observed images of a scene at depth d by using:
                        
                           (14)
                           
                              
                                 
                                    
                                       
                                       logPr
                                       
                                          
                                             
                                                d
                                                ^
                                             
                                             |
                                             d
                                          
                                       
                                       
                                       =
                                       const
                                       −
                                       
                                          1
                                          2
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                   ,
                                                   2
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            f
                                                            i
                                                         
                                                         −
                                                         
                                                            k
                                                            i
                                                            
                                                               d
                                                            
                                                         
                                                         ⊗
                                                         
                                                            
                                                               
                                                                  f
                                                                  ^
                                                               
                                                               0
                                                               
                                                                  d
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                       
                                       
                                          
                                             +
                                             α
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     f
                                                                     ^
                                                                  
                                                                  0
                                                                  
                                                                     d
                                                                  
                                                               
                                                            
                                                            ⊗
                                                            
                                                               g
                                                               x
                                                            
                                                         
                                                      
                                                      2
                                                   
                                                   +
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     f
                                                                     ^
                                                                  
                                                                  0
                                                                  
                                                                     d
                                                                  
                                                               
                                                            
                                                            ⊗
                                                            
                                                               g
                                                               y
                                                            
                                                         
                                                      
                                                      2
                                                   
                                                
                                             
                                             +
                                             
                                                1
                                                P
                                             
                                             
                                                
                                                   ∑
                                                   ω
                                                
                                                
                                                   log
                                                   
                                                      
                                                         
                                                            σ
                                                            2
                                                         
                                                         S
                                                         
                                                            
                                                               
                                                                  V
                                                                  
                                                                     d
                                                                  
                                                               
                                                               
                                                                  −
                                                                  1
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           
                        
                     where α is the fitting parameter of the natural image and g
                     
                        x
                     ,
                     g
                     
                        y
                      are gradient filters for the x,
                     y spatial dimensions. Detailed derivations of these equations can be found in [19].

We compared three types of PSFs, namely, half-sweep, conventional DFD, and coded aperture, using Eqs. (8) and (10) to evaluate the performance of restoration and depth estimation. The coded aperture pair uses two images with special patterned apertures proposed by Zhou et al. [5,6], while the conventional DFD method discussed in this paper makes use of near-focused and far-focused images as input. We also simulated these PSFs to obtain a theoretical evaluation and comparison with previous methods.

In this evaluation, we assume that the PSF has 20 depths. We used σ
                     =0.003 as a baseline of the noise level from preliminary analysis similar to the performance analysis described in Section 7.


                     Table 1
                      shows the evaluation results of various PSFs for the conventional, coded aperture pair, and proposed half-sweep methods. In terms of the quality of the restoration image, the half-sweep imaging method is better than the other methods. The difference between the conventional method and coded aperture pair is small, whereas that between half-sweep imaging and the other methods is large. In terms of the depth error, we also confirm that half-sweep PSF outperformed the others. The coded aperture method showed the worst performance, despite the restoration error being similar to that of the conventional method, since the changes in defocus blur due to aperture differences are smaller than those due to focus differences. We confirmed that our proposed half-sweep method has the best performance for restoration and depth estimation.

In this section, we propose a method for estimating a depth map and an all-in-focus image from two images captured by half-sweep imaging. Half-sweep imaging is given by Eq. (4), which can be expressed in the Fourier domain as
                        
                           (15)
                           
                              
                                 F
                                 i
                                 
                                    d
                                 
                              
                              =
                              
                                 F
                                 0
                              
                              ⋅
                              
                                 K
                                 i
                                 
                                    d
                                 
                              
                              +
                              N
                              ,
                              
                              i
                              =
                              1
                              ,
                              2
                              ,
                           
                        
                     where F
                     
                        i
                     
                     (d) is the Fourier transform of the captured images (i
                     =1,2) at depth d, F
                     0 is the Fourier transform of a latent all-in-focus image, K
                     
                        i
                     
                     (d) (i
                     =1,2) is the Fourier transform of a PSF kernel at depth d, and N is the Fourier transform of noise. Here we consider the problem of estimating the all-in-focus image F
                     0 and unknown scene depth d from Eq. (15). Generally, image F
                     0 is given by deconvolution; here we use the Wiener deconvolution:
                        
                           (16)
                           
                              
                                 
                                    F
                                    ^
                                 
                                 0
                              
                              =
                              
                                 
                                    F
                                    ⋅
                                    
                                       K
                                       ¯
                                    
                                 
                                 
                                    
                                       
                                          K
                                       
                                       2
                                    
                                    +
                                    
                                       
                                          C
                                       
                                       2
                                    
                                 
                              
                              ,
                           
                        
                     where 
                        |
                        K
                        |
                        
                           
                           2
                        
                        =
                        K
                        ⋅
                        
                           K
                           ¯
                        
                     . C represents 
                        σ
                        /
                        
                           A
                           
                              
                                 1
                                 2
                              
                           
                        
                     , with A defined over the power distribution of natural images according to the 1/f law. The original Wiener deconvolution was designed to deblur one blurred image, and we propose using an extended method in our half-sweep imaging. As shown in Section 3, h
                     
                        all
                     , which is the average of half-sweep PSF kernels h
                     1 and h
                     2, has a broadband frequency response for each depth. Additionally, f
                     
                        all
                     , which is the average image of f
                     1 and f
                     2, has broadband image information, since we can assume that image f
                     
                        all
                      is captured by the h
                     
                        all
                      kernel. The property of addition is maintained over the Fourier transform. Hence, we obtain the Fourier transforms of the average kernel and the image as
                        
                           (17)
                           
                              
                                 F
                                 all
                              
                              =
                              
                                 
                                    
                                       F
                                       1
                                    
                                    +
                                    
                                       F
                                       2
                                    
                                 
                                 2
                              
                              ,
                              
                              
                                 
                                    
                                       H
                                       ¯
                                    
                                    all
                                    
                                       d
                                    
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             H
                                             ¯
                                          
                                          1
                                          
                                             d
                                          
                                       
                                    
                                    +
                                    
                                       
                                          
                                             H
                                             ¯
                                          
                                          2
                                          
                                             d
                                          
                                       
                                    
                                 
                                 2
                              
                              .
                           
                        
                     
                  

We can extend Wiener deconvolution to half-sweep imaging by substituting Eq. (17) into Eq. (16):
                        
                           (18)
                           
                              
                                 
                                    
                                       
                                          F
                                          ^
                                       
                                       0
                                    
                                    
                                       d
                                    
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             F
                                             1
                                          
                                          +
                                          
                                             F
                                             2
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                H
                                                1
                                                
                                                   d
                                                
                                             
                                             +
                                             
                                                H
                                                2
                                                
                                                   d
                                                
                                             
                                          
                                       
                                       ¯
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                H
                                                1
                                                
                                                   d
                                                
                                             
                                             +
                                             
                                                H
                                                2
                                                
                                                   d
                                                
                                             
                                          
                                       
                                       2
                                    
                                    +
                                    4
                                    
                                       
                                          C
                                       
                                       2
                                    
                                 
                              
                              .
                           
                        
                     
                  

We assume that the error between the observed and estimated images must be minimal when the estimated depth d is correct. Therefore, we define a cost function to estimate depth d, as
                        
                           (19)
                           
                              
                                 W
                                 
                                    d
                                 
                              
                              =
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                       ,
                                       2
                                    
                                 
                                 
                                    
                                       
                                          IFFT
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            F
                                                            ^
                                                         
                                                         0
                                                      
                                                      
                                                         d
                                                      
                                                   
                                                
                                                ⋅
                                                
                                                   H
                                                   i
                                                   
                                                      d
                                                   
                                                
                                                −
                                                
                                                   F
                                                   i
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        
                     where IFFT is the 2D inverse Fourier transform and 
                        
                           
                              
                                 F
                                 ^
                              
                              0
                           
                        
                      is derived from Eq. (18). The cost function W
                     (d) represents the error between the reconstructed and captured images. Thus, W
                     (d) is a measure of how close d is to the actual scene depth d
                     ∗. We estimate depths to find the minimum W
                     (d) for each pixel (x,
                     y) using
                        
                           (20)
                           
                              U
                              
                                 x
                                 y
                              
                              =
                              arg
                              
                                 min
                                 
                                    d
                                    ∈
                                    D
                                 
                              
                              
                                 W
                                 
                                    d
                                 
                              
                              
                                 x
                                 y
                              
                              .
                           
                        
                     
                  

We also obtain an all-in-focus image I from the estimated depth map U as
                        
                           (21)
                           
                              I
                              
                                 x
                                 y
                              
                              =
                              
                                 
                                    
                                       F
                                       0
                                    
                                    
                                       
                                          U
                                          
                                             x
                                             y
                                          
                                       
                                    
                                 
                              
                              
                                 x
                                 y
                              
                              .
                           
                        
                     
                  

We carried out simulation experiments to evaluate the performance of our half-sweep imaging. In this section, we denote the object position by u, focal point by v, and sensor position by p, as illustrated in Fig. 1. We assume that the scene is a synthetic staircase scene as shown in Fig. 4(a). These depth maps have false-color representation with red indicating locations far (step 1) from the camera and blue denoting locations close (step 20)to the camera. The scene has two textures, one with strong and dense patterns and the other comprising natural wood with weak texture as illustrated in Fig. 5(a). The physical object depth u is between 2034 and 83.6mm from the camera lens, while the corresponding focal point v varies from 9.04 to 10.085mm behind the lens according to the lens law given in Eq. (1).

We divided the possible range of the focal position v into 20 uniform steps (Δv
                     =0.055mm) so that the defocus blur changes by an equal ratio (0.5pixels for each step) in an image. Table 2
                      gives the relation between step number and the corresponding object depth u and focal position v for ease of understanding. The focal length and F-number of the lens are taken as f
                     =9mm and f/1.4 in this study. With these settings, we simulated captured images through convolution with theoretical PSFs modeled by the pillbox function defined in Eq. (6). We set the integration intervals to half by half of the target depth range for half-sweep DFD. Thus, with a depth range of 20 steps, the intervals are 1 to 10 and 11 to 20 steps. The corresponding sensor positions are p
                     0
                     =9.04mm, p
                     1
                     =9.945mm, and p
                     2
                     =10.085mm for Eq. (5). Conventional DFD uses far-focused (step 20, p
                     =9.04mm) and near-focused (step 1, p
                     =10.085mm) images with an open circular aperture. The coded aperture method uses two far-focused (step 20, p
                     =9.04mm) images captured by an aperture pair [5,6] (i.e., where the aperture difference is the depth key). Note that our setting for the simulation differs from that in [5,6]. Zhou et al. set the focus point of the lens as the center of the service depth range, whereas in our paper, we set it as the farthest distance, since we would like to compare whether the largest PSF has the same size in the service depth range.

We estimated scene depth maps and all-in-focus images using the proposed DFD algorithm as mentioned in Section 5. For the conventional and coded-aperture DFD estimation, we used Zhou's DFD algorithm [5,6] for comparison. For this simulation, we assumed the noise level to be σ
                     =0.003.


                     Fig. 4 shows the depth estimation results. The figure shows the depth maps for (a) the ground truth, (b) the conventional DFD method, (c) Zhou's coded aperture pair, and (d) our proposed method capturing half-sweep imaging. We see that the strong texture on the left side of the scene does not differ greatly among the methods. However, there are large differences in the weak texture on the right side, with our proposed half-sweep imaging achieving the best performance. The result of conventional DFD estimation in Fig. 4(b) shows a large error around the central depth, while Fig. 4(c), the result of coded-aperture-pair DFD estimation, shows errors across the entire depth range. On the other hand, the result of the proposed method in Fig. 4(d) shows greater robustness, although the scene has weak texture. Fig. 5(b, c, d) shows the differences between the estimated images and the true texture shown in Fig. 5(a), since it is difficult to recognize errors in the estimated images. The figures are shown using a false color representation with the color bar indicating the normalized intensity of the errors (i.e., the maximum intensity is 1.0). Fig. 5(b) shows large restoration errors in the center of the image, since the captured images have much blur and high-frequency information is lost in the center of the image using conventional DFD estimation. Fig. 5(c) shows that the restoration errors increase with greater object depth. It is difficult to distinguish between the coded aperture pair where the size of blur is small or in focus, since the method using the coded aperture pair employs shape differences between the apertures as the depth key. Fig. 5(d) shows that the proposed restoration method produces errors that are smaller and more uniform.

We also compared various numerical qualities of these methods. Table 3
                      shows the root-mean-square (RMS) errors of the depth estimations and the peak signal-to-noise ratios (PSNRs) of the restored image qualities. The RMS errors of depth indicate average errors between the estimated and ground truth depths in the depth steps. The PSNR is often used as a metric for image quality, where a larger value indicates better quality. The table shows that the proposed method achieves the best performance in terms of both depth estimation and restored image quality.

Thus, we can confirm that the proposed method for half-sweep imaging has the best performance in terms of estimating the scene depth and restoring an all-in-focus image. This is due to one of the proposed half-sweep imaging PSFs having zero-crossings and their sum having a broadband spectrum in the Fourier domain.

In this section, we analyze the performance of each method in terms of scene range and noise level. To achieve a more general evaluation, we used 30 arbitrary images downloaded from flickr as scene textures for generating simulated images.

In this experiment, we used a similar setting to that in Fig. 4 (i.e., with noise level σ
                        =0.003), but changed the object depth range (the number of stairs) from 2 to 40 steps. Table 2 shows the conversion of the object depth.


                        Fig. 6(a, b) shows the RMS errors of the estimated depth errors and the PSNRs of the restored images against the scene range. In these figures, line plots indicate the average values of the RMS error or PSNR, while the error bars indicate the standard deviations of 30 variations of textures. The standard deviation confirms that each result deviates according to the texture difference. Fig. 6(a) shows that the performance of each of the methods deteriorates as the depth range increases, since larger blur must be used to estimate a greater depth range and it is difficult to estimate the blur size when it is larger. Half-sweep DFD achieves better performance in estimating the depth than the other methods. Fig. 6(b) shows similar results for PSNR; that is, for all methods, the PSNR deteriorates as the depth range increases. Nevertheless, it is obvious that the PSNR of the proposed method is far better than that of the others. We can also see that the standard deviation of the proposed method is smaller than that of the others. This means that half-sweep DFD is more robust in restoring the images independently of variations in the scene texture. These figures once again confirm that the proposed method outperforms the others in both depth estimation and restored image quality.

In this experiment, we used a similar setting to that in Fig. 4 (i.e., with a depth range of 20 steps), but we varied the noise level from σ
                        =0.001 to σ
                        =0.05 in intervals of 0.001.


                        Fig. 7
                         shows the changes in the PSNRs of the restored images against the noise levels. In this figure, line plots indicate the average values of the PSNR, while the error bars indicate the standard deviations for 30 variations of textures. For a low noise level, the results are similar to those in Table 3. The PSNR of half-sweep imaging is higher than that of the coded aperture method, which in turn is higher than that of the conventional method. However, the performance of the coded aperture and conventional methods is reversed as the noise level increases. Thus, we can say that the coded aperture method is sensitive to noise. On the other hand, our half-sweep method achieves the best performance of all the methods at each noise level. In addition, the standard deviation of the proposed method is smaller than those of the other methods. We can thus confirm that the proposed method outperforms the other methods regardless of noise or texture.

We also evaluated our half-sweep imaging method using real images captured by a prototype camera. Fig. 8
                      shows the prototype camera for realizing half-sweep imaging. The camera consists of a 1/3″ Sony CCD (with 1032×776 pixels) mounted on a Physik Instrument P-628.1CL translation stage. This stage is driven by a piezoelectric actuator with a range of translation of 800 microns. We attached a Tokina 12.5mm lens and set the F-number to f/1.4 for this experiment. The shutter of the CCD and the actuator were controlled by signals generated by a PC. These signals were completely synchronized to realize half-sweep imaging.

In the real experiments, we captured two scenes. To create the first scene, animal toys were placed at different depths in front of a scenic backdrop as shown in Figs. 9 and 10
                     
                     . The range of scene depth varied from 340 to 750mm from the camera lens. The actuator needed to translate 225 microns from the start to end positions to cover the entire scene depth. Fig. 10(a) shows the images captured using the prototype camera with half-sweep imaging. Images f
                     1 and f
                     2 were captured, respectively, by the front half and back half of the sensor sweeping. Likewise, Fig. 9(a) shows images captured using the prototype camera, but with near-focus and far-focus positions (instead of sweeping) for conventional DFD. We captured measured PSFs for both the half-sweep imaging and conventional DFD estimation at ten depths using a point light source before the experiments. We estimated the object depths and restored all-in-focus images using the input images and measured PSFs. Fig. 10(b, c) shows the results of the restored all-in-focus images and the depth map of the scene, respectively. We employed the proposed DFD method as mentioned in Section 5. For comparison, Fig. 9(b, c) shows the results of the conventional DFD estimation.

Comparing Figs. 9(b) and 10(b), we can see that both depth maps show the depth differences among the objects. White dotted circles in these two figures show the outstanding differences in depth estimation accuracy. These results show that a leaf in the circle was mistaken in estimating the depth, since in the conventional DFD approach it is difficult to estimate the correct depth where an object has weak texture, as discussed in Section 6. In contrast, our half-sweep DFD approach estimates the depth accurately.

Comparing Figs. 9(c) and 10(c), we see that the restored focused images have large differences. The image obtained by conventional DFD estimation has many artifacts such as enhanced noise and ringing artifacts. Wealso see that some portion of the texture is still blurred even after deconvolution because of depth estimation errors. Fig. 11
                      clearly shows the differences for several magnified portions of the images. Fig. 11(c) depicts the ground truth textures captured for the same scene with a small aperture setting of f/16. Although the proposed method does not provide an image that is identical to the ground truth, it achieves far better performance than the conventional DFD approach.

The second scene is illustrated in Figs. 12 and 13
                     
                     . We captured a town diorama using the same settings as for the sweeping in the first scene. All objects were placed between 340 and 750mm from the camera lens. Figs. 13(a) and 12(a) show the images captured using the prototype camera with each of the two methods, while Figs. 12(b) and 13(b) show the results of the depth map of the scene using each method. Finally, Figs. 12(c) and 13(c) show the results of the restored all-in-focus images using each method. In obtaining these results, we estimated the object depths and restored all-in-focus images in the same way as for the first scene.

Comparing Figs. 12(b) and 13(b), we can see large differences in the white dotted circles. The circle contains a ground plane with continuous depth differences. In Fig. 12(b), the depth map has large errors on the ground plane because the conventional DFD approach cannot accurately estimate the depth of a weak texture. Fig. 10(b) shows that the proposed half-sweep method estimates correct smooth depth changes for portions of the image. We can thus confirm that our approach estimates the depth map accurately and smoothly regardless of the texture strength.

Comparing Figs. 12(c) and 13(c), we see that the restored focus images have large differences. The result of conventional DFD estimation has many artifacts and some blurred areas similar to the scene with animal toys. Fig. 14
                      clearly shows the differences for zoomed-in portions of the images, while Fig. 14(c) shows the ground truth textures captured for the same scene with a small aperture setting of f/16. From the above results, it is clear that the proposed method also achieves better performance than the conventional DFD approach in the second scene.

These experiments targeting two different scenes show the stability of our depth estimation and image restoration regardless of the type of scene. The experiments confirm that our proposed method has an advantage over conventional DFD and works in real implementations.

@&#CONCLUSION@&#

In this paper we proposed a new computational imaging technique called half-sweep imaging and a processing method for DFD estimation. The sensor sweeps during the exposure time to capture two images. We showed that the PSFs of the proposed half-sweep imaging simultaneously have zero-crossings and broadband properties in the Fourier domain. We also showed that robust depth estimation and high-quality image restoration can be realized from the contribution of the PSF properties. We further confirmed the advantage of our half-sweep imaging over previous methods in theoretical PSF evaluation, as well as simulations and real experiments. We implemented a prototype camera that incorporates a piezoelectric actuator to sweep an image sensor in real experiments. However, the sweeping operation can be more easily implemented in commercial cameras, e.g., utilizing the auto-focusing mechanism. Half-sweep imaging has the advantages of achieving a higher SNR for images, having flexibility such that it can adapt to the scene depth, and being completely compatible with regular imaging. Hence, it is applicable for use in a wide range of products such as digital still cameras.

@&#REFERENCES@&#


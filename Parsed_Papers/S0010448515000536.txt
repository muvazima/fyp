@&#MAIN-TITLE@&#Next viewing directions for the scanning of dental impressions

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Dental impression scanning with the minimum number of scanning operations.


                        
                        
                           
                           Graphics board utilization to accelerate the evaluation of visibility.


                        
                        
                           
                           Missing area identification from range images.


                        
                        
                           
                           Next viewing directions from the visibility of missing areas.


                        
                        
                           
                           Proposed procedure is more than twice faster compared to conventional method.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Structured light system

Dental impression

Ceramic restorations

Global interference

Range image

Graphics board

@&#ABSTRACT@&#


               
               
                  This paper proposes a scanning procedure for a structured light system (SLS) to measure dental impressions. Although increasing the number of scanning orientations may improve the quality of a scanned model, it is desirable to minimize the number of scanning operations to time and data storage. We attempt to reduce the number of scanning operations to the least number that will still acquire a complete model. The proposed procedure must resolve two sub-problems: (1) identification of missing areas from given range images, and (2) determination of the next viewing directions to fill those missing areas. If we consider range images as triangular meshes, the sub-problems can be solved by using well-known geometric algorithms. The triangular meshes, however, may consist of tens of millions of triangles, which require an unacceptably long time to compute. To cope with this problem, we propose two key ideas: (1) utilizing an inherent attribute of a range image, the map structure; (2) utilizing a graphics board to accelerate the evaluation of visibility. Our demonstration proves that the proposed approach improves the quality of scanned models and reduces the number of scanning operations.
               
            

@&#INTRODUCTION@&#

Nowadays, all-ceramic restorations for missing tooth structures are becoming popular because of their translucency, which minimizes gingival shadowing and maximizes the appearance of health  [1]. Because all-ceramic restorations require different manufacturing processes relative to those used with traditional metal restorations, many researchers have attempted to develop new manufacturing processes involving CAD/CAM (computer-aided design/manufacturing) technologies  [2]. These CAD/CAM-based manufacturing procedures involve the machining of ceramics that are partially sintered. After machining, the ceramic restorations are fired again to form a hard ceramic. The ceramic materials include glass-boned porcelain and phase-stabilized zirconia.


                     Fig. 1
                      shows the manufacturing procedure for all-ceramic restorations. The process consists of four steps: (1) preparation of a dental impression, which is usually carried out by dentists; (2) scanning the dental impression to create a proper CAD model (i.e., a triangular mesh model); (3) machining all-ceramic materials to create the restoration; (4) sintering the machined restoration to form a hard ceramic. Because the final product of the manufacturing procedure is intended to replace a person’s missing tooth structure, the required accuracy (
                        50
                        
                        
                           μ
                        
                        
                           m
                        
                     ) should be ensured throughout all steps of manufacturing.

This paper focuses primarily on the second of the four steps shown in Fig. 1 (scanning a dental impression), because it is crucial for the accuracy of restoration. For scanning dental impressions, it is necessary to use optical measurements based on machine vision cameras. Structured light systems (SLS) are currently popular for use in dental CAD/CAM due to their fast measuring speed, simple optical arrangement, non-contact arrangement, moderate accuracy, low cost, and ability to function under varying ambient light conditions. Three-dimensional range images consist of spatial coordinates for the surface points of an object  [3]. They are useful for 3D object matching, object recognition, and dimensional measurement. An SLS provides a general method for acquiring the surface range data from a scene.


                     Fig. 2
                      shows the typical configuration of an SLS that consists of a projector and a camera. In an SLS, an object is illuminated from a structured light source (i.e., a projector) and the scene is captured by a camera. The angle between the projector and the camera is known as an optical triangulation angle. Because the optical triangulation angle does not change during scanning, the camera and projector orientations are restricted by the scanning orientation. An SLS can measure only the area visible from a specific scanning orientation; however, the geometry of a dental impression is usually complicated. Therefore, a typical SLS has mobile axes (a swing axis and a rotation axis) to enable multiple scan operations from different directions.

As shown in Fig. 3
                     , we may improve the quality of a scanned model by increasing the number of scanning orientations. Using many scanning operations, however, requires an excessive amount of scanning time and computer memory. As long as a complete model can be acquired, it is desirable to minimize the number of scanning operations in order to save time and memory. Scanning of a dental impression is currently performed in three steps: (1) multiple range images are acquired with initial scanning orientations; 40–60 orientations are used, depending on the complexity of the impression (Fig. 4
                     -(a)), (2) a human operator conducts manual scanning operations to fill missing areas (Fig. 4-(b)); (3) all range images are merged to generate a complete mesh model (Fig. 4-(c)). In the case of the second step, the additional scanning orientations should be determined by skilled workers, and large amounts of time and effort are required. This paper focuses on minimizing the number of scanning operations in the second step. The objective of this paper is to develop a new procedure to determine the next viewing directions by analyzing the range images obtained at the first step.

To find the next proper viewing directions, it is necessary to evaluate the visibility of missing areas from images of a given range. The visibility evaluation for a given geometric model has various applications, including computer graphics  [4–6], multiaxis machining  [7–10], orientation of parts on a CMM (coordinate measuring machine)  [11,12], parting line determination for castings  [13–15], and optical scanning for object reconstruction   [16–20]. Therefore, the visibility problem has long been studied by many researchers. Mehra et al.  [4] presented an algorithm for estimating visibility from a given viewpoint for a point set. They computed the visibility based on a construction involving the convex hull in a dual space instead of performing an explicit surface reconstruction for the points set. Wang et al.  [6] proposed an adaptive visibility sampling algorithm for the all-frequency rendering of dynamic scenes, which comprises two steps: adaptive visibility sampling and hemispherical distance transformation. Park  [10] presented a procedure to compute pencil curves from a given triangular mesh model. For the computation of visible pencil curves, he used a graphics board to accelerate the computation. Kang and Suh  [8] proposed a method for calculating the setup orientations for five-axis machining that is implemented by numerical simulation. Kweon and Medeiros  [11] presented a method to determine part orientations on a CMM that utilizes the visibility map to represent accessible directions. Spyridi and Requicha  [12] suggested an algorithm that calculates the accessibility of a CMM probe based on the concept of an accessibility cone. They divided an accessibility cone into local and global accessibility cones to determine the bound of the possible probe orientations. Singh and Madan  [13] suggested a procedure to determine the parting line for die-cast parts. Their procedure applies die-casting process requirements along with geometrical reasoning to determine the parting line of the die-cast parts. Lee and Park  [17] suggested a measuring procedure of parts based on a laser scanning mechanism. Their procedure uses the concept of local accessible directions (LADs) and assumes that a CAD model is available for the part; it determines the scanning directions that cover the surface of the part by performing Boolean intersection operations among LADs. Although there have been many previous results, they cannot be applied directly to the problem of scanning dental impressions. Most of them evaluate the visibility for a complete model, whether it is a CAD model or a point cloud model. Because a dental impression represents the tooth structure of a human, we cannot have a complete CAD model prior to finishing the scanning operation.

In the area of optical scanning, Scott and Roth  [18] surveys and compares view planning techniques for automated 3D object reconstruction and inspection by means of active, triangulation-based range sensors. They classify existing non-model based view planning methods into three categories: (1) volumetric, (2) surface-based, and (3) global. Once again, the surface-based methods are separated into three approaches: (1) occlusion edge, (2) contour following, and (3) parametric surface representation. Among these, occlusion edge method  [19,20] is the most commonly used traditional method, and it is based on the premise that occlusion edges internal to the image indicate surface areas not yet sampled (missing areas). Maver and Bajcsy  [19] selected a viewing direction by reasoning about the angular arc through which occluded areas of the object surface can be viewed, based on assumptions about the unseen topography. Garcia et al.  [20] also utilized an occlusion edge method, and their method is based on a voting scheme that takes into account the orientation of occlusion edges.

Although, the proposed approach in this paper belongs to the occlusion edge category, the existing occlusion edge methods are not suitable for the scanning problem of dental impressions. Since conventional occlusion methods evaluate the visibility of a missing area for a general geometric model, they are not efficient enough to be applied to the scanning of a dental impression which may require tens of millions of triangles. To cope with the problem, our approach makes use of the inherent attribute of range images as well as a graphics board.

Several years ago, the authors of this paper proposed a scanning procedure for dental impressions utilizing the visibility map  [21]. Although the proposed approach enables the automatic scanning of a dental impression, there are two serious problems: (1) there was no consideration of the global interference problem, which can occur with a complicated dental impression; and (2) the computation time should be reduced to satisfy current time requirements. The previously proposed procedure finds missing areas from a merged triangular mesh, which requires a computationally expensive merge operation to be carried out upon range images for every scanning cycle. Consequently, the methodology requires an excessive scanning time; over 10 min for an average model. To avoid the frequent merge operations, it is necessary to identify missing areas directly from range images instead of from a merged triangular mesh model.

Our objective is to acquire a scanned model in less than 4 min. Because reduction of scanning time entails better production of dental restorations, it is a very important issue. The proposed procedure consists of two steps: (1) identify the missing areas directly from the range images; and (2) determine the next viewing directions by considering the visibility of the missing areas. The remainder of this paper is organized as follows. Section  2 addresses the proposed approach for finding the next viewing directions for given range images. Section  3 describes the details of the core algorithms of the proposed procedure. Finally, concluding remarks are given in Section  4.

As shown in Fig. 5
                     , the proposed algorithm considers range images of a dental impression, and gives the next viewing directions to fill the missing areas of the given range images. The problem can be split into two sub-problems: (1) identifying the missing area from given range images, and (2) determining the next viewing direction by calculating the visibility of missing areas.

It is necessary to analyze range images to determine missing areas. Because one scanning operation generates one range image, the number of range images is equal to the number of previous scanning operations. Fig. 6
                      shows an example of a range image, and presents the map structure, which is a 2D-array of real numbers in which the 
                        Z
                     -values (depth values) of the shape, sampled at regular grid-points, are stored. The number of points in a range image depends on the resolution of the camera. The range image shown in Fig. 6 was captured by a camera with a 1.2 megapixel (1280 × 960) resolution and contains 810,000 points. Owing to the simplicity of the map structure, a range image can be intuitively converted into a triangular mesh  [3].


                     Fig. 7
                      shows the concept behind finding areas missing from multiple range images. Because a range image can be considered as a triangular mesh, the problem can be considered in terms of identifying the area missing from multiple triangular meshes. As shown in Fig. 7, missing areas can be limited by the boundary curves of triangular meshes. It is necessary to observe that the missing area “A” in Fig. 7 is defined by three different segments of boundary curves. To extract such segments defining a missing area, we need to extract the segments of boundary curves that do not lie on other triangular meshes. In other words, we need to perform the overlapping test between triangular meshes. The overlapping test requires an expensive function; computing the distance between a triangular mesh and a point  [22]. Considering that the triangular meshes can number in the tens of millions, the overlapping test may require an excessive time to compute, at least couple of minutes. To overcome this difficulty, we propose a different approach utilizing an inherent attribute of range images, the map structure. As shown in Fig. 6, the map structure of a range image is a 2D-array of real numbers in which the depth values of the shape are stored. The proposed approach uses the attributes of the map structure of a range image, and the computation time is very fast. Details of the algorithm will be presented in the next section.

Once missing areas are identified, it is necessary to compute the next viewing directions to fill the missing areas. Because a missing area is defined by boundary curves of existing range images, the boundary of a missing area can be considered as a set of points. For the set of points bounding a missing area, it is possible to compute a least-squares fit plane, as shown in Fig. 8
                     . For a plane, the optimal scanning direction is the normal vector of the plane, because the scanning direction perpendicular to an object gives the most reliable measuring results. Considering that, we use the normal vector of the least-squares fit plane as the next viewing direction for the corresponding missing area. The problem with this simple method is that the normal vector of the least-squares fit plane does not guarantee that it will avoid global interference, as shown in Fig. 8. To avoid global interference, we propose a more sophisticated approach to determine the next viewing direction for a given missing area. Details of the method will be presented in the next section.

As mentioned above, the proposed procedure consists of two core algorithms: (1) identifying the area missing from range images; (2) determining the next viewing direction while avoiding global interference. Because the number of triangles can be tens of millions, it is necessary to accurately design the core algorithms so that they can handle such a large number of triangles in a reasonable amount of time. Although range images can be considered as triangular meshes, it is not desirable to design algorithms that operate on triangular meshes because it is impossible to operate on tens of millions of triangles in the desired time frame.


                     Fig. 9
                      shows the missing area for three given range images. The missing area is bounded by the segments of boundary curves. Therefore, we need to identify only the boundary points defining the missing area rather than the exact geometry of the missing area. As shown in Fig. 9, we need to extract boundary points that do not overlap other range images. The missing area, shown in Fig. 9, consists of nine boundary points (nine solid circles). Although the hollow circles overlap with other range images, the nine solid circles do not. To identify such boundary points, it is necessary to perform the overlapping test between all boundary points and the given range images. The overlapping test of a boundary point for a range image can be considered as a distance computing problem between a point and a triangular mesh. Although the distance computation between a point and a triangular mesh can be performed using a simple logic, the computation cost would be prohibitively high because of the large number of triangles. To cope with the problem, we propose a new algorithm to identify the boundary points of missing areas by making use of an inherent attribute of a range image; the map structure shown in Fig. 6.


                     Fig. 10
                      illustrates the concept of the proposed algorithm performing the overlapping test between a point and a range image. As mentioned earlier, a range image can be considered as a 2D-array (
                        
                           Z
                        
                        
                           [
                           i
                           ,
                           j
                           ]
                        
                      of Fig. 10) of real numbers in which the 
                        Z
                     -values of the shape are sampled at regular grid-points. Each point can be indexed by two subscripts, one for the column and one for the row. For example, the vertices 
                        
                           K
                        
                      and 
                        
                           A
                        
                      of Fig. 10 can be indexed by   [1,3,2,3], respectively. In this manner, each grid point can be addressed by index 
                        
                           [
                           i
                           ,
                           j
                           ]
                        
                      in 2D, and each vertex has coordinates (
                        i
                        ∗
                        d
                        x
                        ,
                        j
                        ∗
                        d
                        y
                        ,
                        Z
                        
                           [
                           i
                           ,
                           j
                           ]
                        
                     ) for real numbers 
                        d
                        x
                      and 
                        d
                        y
                      representing the grid spacing. By using this attribute of a range image, the overlapping test of a given point can be efficiently completed. For a given point 
                        P
                        
                           (
                           x
                           ,
                           y
                           ,
                           z
                           )
                        
                     , we can convert the point into the index domain 
                        
                           [
                           i
                           ,
                           j
                           ]
                        
                      of a range image. As shown in Fig. 10, it is possible to identify neighboring grid points (A, B, C, and D) of a range image for the given point P. Once the neighboring grid points are identified, we can easily perform the overlapping test by computing the distance between 
                        P
                      and the neighboring grid points. The algorithm can be described as follows:


                     
                        
                           
                              
                              
                                 
                                    
                                       Algorithm for overlapping test of a point against a range image:
                                 
                                 
                                    // Input:
                                 
                                 
                                    // 
                                          P
                                          
                                             (
                                             x
                                             ,
                                             y
                                             ,
                                             z
                                             )
                                          
                                       : a point belonging to a boundary curve,
                                 
                                 
                                    // Z[i][j], x0, y0, dx, dy: a range image stored in a map structure,
                                 
                                 
                                    // 
                                          ε
                                       : given tolerance (
                                          20
                                          
                                          
                                             μ
                                          
                                          
                                             m
                                          
                                       : 2/5th of required accuracy of dental restorations (
                                          50
                                          
                                          
                                             μ
                                          
                                          
                                             m
                                          
                                       ))
                                 
                                 
                                    // Output:
                                 
                                 
                                    // True: if P lies on the range image within 
                                          ε
                                       
                                    
                                 
                                 
                                    // False: if P does not lie on the range image
                                 
                                 
                                    // Main Variables:
                                 
                                 
                                    // A, B, C, D: Four points bounding P on the XY plane
                                 
                                 
                                    Step 1. Finding the index I & J
                                 
                                 
                                    
                                        I  =  floor (x/dx); // floor (v): returns value of v rounded downward
                                 
                                 
                                    
                                        II  =  I+1;
                                 
                                 
                                    
                                        J  =  floor (y/dy);
                                 
                                 
                                    
                                        JJ  =  J+1;
                                 
                                 
                                    Step 2. Checking the distance between P & the four points A, B, C, and D
                                 
                                 
                                    
                                        A  =  (x0+I*dx, y0+JJ*dy, Z[I][JJ]);
                                 
                                 
                                    
                                        If (distance between P and 
                                          
                                             A
                                          
                                          <
                                          ε
                                       )
                                 
                                 
                                    
                                        Return True;
                                 
                                 
                                    
                                        B  =  (x0+I*dx, y0+J*dy, Z[I][J]);
                                 
                                 
                                    
                                        If (distance between P and 
                                          
                                             B
                                          
                                          <
                                          ε
                                       )
                                 
                                 
                                    
                                        Return True;
                                 
                                 
                                    
                                        C  =  (x0+II*dx, y0+J*dy, Z[II][J]);
                                 
                                 
                                    
                                        If (distance between P and 
                                          
                                             C
                                          
                                          <
                                          ε
                                       )
                                 
                                 
                                    
                                        Return True;
                                 
                                 
                                    
                                        D  =  (x0+II*dx, y0+JJ*dy, Z[II][JJ]);
                                 
                                 
                                    
                                        If (distance between P and 
                                          
                                             D
                                          
                                          <
                                          ε
                                       )
                                 
                                 
                                    
                                        Return True;
                                 
                                 
                                    
                                        Return False;
                                 
                              
                           
                        
                     
                  

Thereby, we can identify all of the missing areas directly from the given range images. At this time, it is necessary to remove the most-outer peripheral boundary from the missing areas. As shown in Fig. 9, we can simply identify the most-outer peripheral boundary by selecting a missing area including the largest number of boundary points. After removing the most-outer peripheral boundary, we need to determine the scanning direction for each missing area. Once the boundary points of a missing area have been identified, we compute a least-squares fit plane for the boundary points. As mentioned earlier, the normal vector of the least-squares fit plane can be the ideal next scanning orientation as long as there are no global interference problems. We can assume that an SLS has two axes upon which to change scanning direction; a swing axis and a rotation axis. Fig. 11
                      shows the two axes, and the solution space for viewing directions. If the initial solution (the normal vector of the least-squares fit plane) causes a global interference problem, then it is necessary to search for other solutions near the initial solution. As shown in Fig. 11, we evaluate four scanning directions as alternatives. Among the alternatives, we deem the best viewing direction as that which gives the most stable visibility of the missing area; this makes it essential to have an efficient method to check the global interference for a given scanning direction.

To check the global interference, it is necessary to evaluate the visibility of the boundary points of a missing area. Theoretically, the visibility of a specific point can be evaluated by checking the interference of a viewing vector and acquired range images consisting of tens of millions of triangles. Checking the interference between triangular meshes and a vector is conceptually simple, but it would consume inordinate computation time. To cope with the computational difficulty, we employ a graphics board that performs hidden surface removal on up to one million polygons per second. We shall assume that we have range images with identified boundary points defining a missing area; the triangles can then be classified into two categories: (1) “boundary triangles”, including any of the identified boundary points; (2) the rest of the “regular triangles”. For the two categories of triangles, we can assign different colors; red for boundary triangles and gray for regular triangles. We can then draw the range images on a pixel map (graphics board) with a given scanning direction. By counting the number of red pixels, it is possible to evaluate the visibility of the boundary triangles around a missing area. The proposed approach deems the best viewing direction as that which gives the largest number of red pixels. In the case of the example shown in Fig. 12
                     , we can intuitively choose N4 as the best viewing direction.

Conceptually, the visibility of each candidate direction can be classified as full visibility, partial visibility, and no visibility, as shown in Fig. 12. At this time, we need to observe the worst case scenario, a dental impression consisting of extremely complex geometric features. In such a case, it might be impossible to find a proper scanning direction avoiding the global interference. If all the candidates fall into the no visibility category, we consider the missing area as a scanning impossible area. As shown in Fig. 4-(d), even range images from 100 directions still include small missing areas which are the scanning impossible areas.

The proposed algorithm was implemented in 
                        
                           C
                        
                        +
                        +
                      language and test runs were made on a personal computer with an i5-2500 processor with 4 GB memory and a Windows 7 operating system. For the experimentation we used a commercial scanner, IDENTICA®  developed by Medit. The execution times were collected for the examples shown in Figs. 13 and 14
                     
                     , and the results are shown in Table 1
                     . Although, the execution times in Table 1 may have been affected by many practical factors (code optimization, data structure, CPU performance, etc.), they are sufficient to show that the execution of the proposed approach can be completed within reasonable time.

To compute a next viewing direction, it is necessary to go through two steps, the identification of missing areas and the avoidance of global interference. If we use existing algorithms working on triangular meshes consisting of tens of millions of triangles, it may take at least couple of minutes to compute a next viewing direction. As shown in Table 1, the average computation time to find a next viewing direction is less than 1 s (0.4 s for Fig. 13, and 0.5 s for Fig. 14), because the proposed approach makes use of the inherent attribute of range images as well as the graphics board. In the case of our previous algorithm  [21], the computation time to find a next viewing direction is more than 60 s for the same examples (67 s for Fig. 13, and 75 s for Fig. 14), because the previous algorithm works on a merged triangular mesh consisting of tens of millions of triangles.

Examples shown in Figs. 13 and 14 can be considered as dental impressions with high complexity requiring more than 20 million triangles. Example A of Fig. 13 deals with the same dental impression with Fig. 4. In the cause of Fig. 4, the manual scanning has been done by a skilled operator with more than 5 years of experience. Whereas the manual procedure, shown in Fig. 4, takes almost 13 min (764 s), the proposed approach takes less than 4 min (204 s). By reducing the number of scanning operations, we also can also conserve computer memory as well as scanning time.

@&#SUMMARY@&#

In this paper, we proposed a procedure for scanning dental impressions with the least possible number of scanning operations. The proposed procedure overcomes two sub-problems: (1) identifying missing areas directly from range images; (2) selecting the next viewing directions by determining the visibility of the missing areas. If we consider range images as triangular meshes, the problems can be solved by using well-known geometric algorithms. The triangular meshes, however, may consist of tens of millions of triangles, which require an unacceptably long time to compute. To cope with the problem, we develop new algorithms for the two sub-problems. Because the scanning time of a dental impression directly affects the production of dental restorations, it is important to carefully design the new algorithms so that an average model can be scanned in less than 4 min without manual operations.

For the first sub-problem, we used an inherent attribute of a range image; the map structure, a 2D-array of real numbers in which the 
                        Z
                     -values of the shape are sampled at regular grid-points. By making use of the map structure, the proposed algorithm identifies missing areas directly from range images instead of triangular meshes. As a result, missing areas for an average model were extracted in a reasonable amount of time. For the second sub-problem, it is necessary to evaluate the visibility of the boundary points of a missing area. To accelerate the evaluation, we employed a graphics board that performs hidden surface removal on up to one million polygons per second. By drawing boundary points and range images on a pixel map, we efficiently evaluated the visibility of a missing area for a given scanning direction. The proposed procedure has been implemented, and the demonstration proves that the proposed approach improves the quality of scanned models and reduces the number of scanning operations.

@&#ACKNOWLEDGMENTS@&#

This work was partially supported by the Defense Acquisition Program Administration and the Agency for Defense Development (UD110006MD & UD140066CD). Also, the research was supported by Korea University (special research funds), and the National Research Foundation grant (2010-0021040) funded by the Ministry of Education, Science and Technology, Korea.

@&#REFERENCES@&#


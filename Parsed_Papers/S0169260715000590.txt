@&#MAIN-TITLE@&#Acrosome integrity assessment of boar spermatozoa images using an early fusion of texture and contour descriptors

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A new early fusion approach for acrosome integrity classification is proposed.


                        
                        
                           
                           Specific segmentation based on shape priors was carried out.


                        
                        
                           
                           The biggest acrosome intact-damaged dataset ever created was created and published.


                        
                        
                           
                           Acrosome contour is important for improving description and classification.


                        
                        
                           
                           The best result up to date combining shape and texture features has been obtained.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Acrosome integrity

Texture description

Contour description

Early fusion

SVM

@&#ABSTRACT@&#


               
               
                  The assessment of the state of the acrosome is a priority in artificial insemination centres since it is one of the main causes of function loss. In this work, boar spermatozoa present in gray scale images acquired with a phase-contrast microscope have been classified as acrosome-intact or acrosome-damaged, after using fluorescent images for creating the ground truth. Based on shape prior criteria combined with Otsu's thresholding, regional minima and watershed transform, the spermatozoa heads were segmented and registered. One of the main novelties of this proposal is that, unlike what previous works stated, the obtained results show that the contour information of the spermatozoon head is important for improving description and classification. Other of this work novelties is that it confirms that combining different texture descriptors and contour descriptors yield the best classification rates for this problem up to date. The classification was performed with a Support Vector Machine backed by a Least Squares training algorithm and a linear kernel. Using the biggest acrosome intact-damaged dataset ever created, the early fusion approach followed provides a 0.9913 F-Score, outperforming all previous related works.
               
            

@&#INTRODUCTION@&#

Herd fertility is critical to the prosperity of any breeding animal company. Artificial insemination is both a fertility treatment for humans and a typical method in breeding of pigs or dairy cattle, dominating the reproductive process of many farms. It brings superior species, mainly for human consumption, requiring that mating is performed using viable sperm.

Computer Assisted Semen Analysis (CASA) systems are more and more present in sperm analysis centres [1]. CASA system is used to assess the semen quality of many species such as bulls [2], pigeons [3] or cats [4], not only humans. It is an automatic or semi-automatic and standardised equipment which allows to assess sperm concentration [5], motility [6] or morphology [7] in a semen sample [8]. However, the major cause of function loss is damage of acrosome due to the leakage of cellular components and inactivation of crucial proteins [9]. Up to our knowledge, the only way of automatically measuring the state and vitality of a sperm sample is using fluorescence images in combination with Cell Counters or fluorescence microscopy which is a very expensive device. Otherwise, the stained samples have to be manually assessed which requires the use of veterinary experts and specialised equipments leading to an expensive and non-objective task. This work deals with the automatic and reliable assessment of the state of the boar acrosome using phase contrast images, so just a phase contrast microscope, a high-featured digital camera and a computer are needed.

There are few works related with this topic and in most of them the texture description makes up the basic operation. González et al. [10] proved that the texture features derived from the Discrete Wavelet Transform (DWT) allow to classify the acrosome integrity with an accuracy of 92.09%. Following this idea, Alegre et al. [11] used the first order statistics derived from the co-occurrence matrix of the image, both computed from the original image and from the coefficients yielded by the DWT. They affirm that this approach outperforms moments-based descriptors (Hu [12], Zernike [13,14] and Legendre [15]) in terms of the classification accuracy they provide yielding the 94.93% which suggests that the edge and some shape features are not enough to describe the state of the acrosome. Besides texture and moments, the gradient magnitude along the contour of the sperm head has been used to describe the acrosome integrity. Learning Vector Quantification (LVQ) has been applied in 2007 with only three prototypes and a hit rate of 83.5% [16] and more recently in 2012 [17] with four prototypes reaching a hit rate of 93.2%. Alegre et al. in 2013 [18] improved this approach by using 7 inner contours and computing a local texture descriptor for each point of the seven contours and classifying with Relevance LVQ, obtaining the best result so far with a hit rate of 99%. As we can see, global and local texture description of the head of the spermatozoa and contour description of the shape of the acrosome have been considered in previous works. Here we present a comparison and combination of the three approaches with different methods applied in a bigger dataset.

Not only the description of the cells is important but the segmentation of the heads, if any, and the classification step can be critical. González-Castro et al. [19] proposed a novel and intelligent segmentation method based on a changing threshold and on a Watershed with which 90.96% of 763 spermatozoa images have been correctly segmented. Bijar et al. [20] segmented the acrosome of human spermatozoa through a method based on a Bayesian classifier which utilizes the adaptive mixtures method (AMM) and Markov random field (MRF) model to obtain and upgrade the class conditional probability density function (CCPDF) and the a priori probability of each class. As regard to the classification, unsupervised classification methods proved to have better performance than supervised ones [21]. However besides this experiments, it is very important to yield an accurate classification. [22] and [23] estimate the true and unknown proportion of damaged cells in a sample with help of the Hellinger distance by quantifying the unknown a priori probabilities of test sets.

The assessment of the vitality of a spermatozoon is a close related topic which has also been studied recently. Most of the works are also based on texture description. Sánchez et al. [24] used the intensity distribution of the cytoplasm densities of the cells whereas [25] adds standard deviation information to the Local Binary Pattern (LBP) descriptor, [26] presents a new textural descriptor called NCSR and [27] shows the performance of LTP texture descriptor.

The rest of the paper is organized as follows: Section 2 describes the methodology used to determine the spermatozoa description. The dataset, experimental setup and experimental results are presented in Section 3. Finally, Section 4 shows our conclusions.

@&#METHODOLOGY@&#

In this work, we have assessed boar sperm integrity by describing images that contain spermatozoa heads. In particular, global and local texture and the contour of spermatozoa heads have been chosen to describe and classify them as acrosome-intact or acrosome-damaged. For obtaining the global texture, 13 Haralick features computed on the GLCMs of the original image and on the images obtained in the first Haar DWT decomposition were used. Regarding contour, Fourier Shape Descriptors were calculated whereas rotation invariant uniform LBPs were obtained in order to describe the local texture of the heads. Moreover, some different early fusion approaches of the aforementioned descriptors have been evaluated to thoroughly describe the heads. Here we propose the use of WFLP (Wavelet Fourier Local Pattern) as we have named the new descriptor obtained with the specific combination of the three previous approaches that yielded the better performance. A general diagram of the steps followed can be viewed in Fig. 1
                     .

Previously to carry out the description of the spermatozoa it is necessary to segment the spermatozoa heads so that the computed descriptors for texture and contour correspond only to the region of interest. We used the ideas presented in the González-Castro et al. [19] work, where images of alive and dead spermatozoa in positive phase contrast are segmented. We have followed the same steps but modifying the validation criteria in such a way it works when the purpose is to segment acrosome-intact and acrosome damaged spermatozoa heads. The González-Castro et al. [19] method combines a first segmentation step, where some morphological operations and Otsu's thresholding is carried out, with a second segmentation using a Watershed transform, in cascade. After the first step, the images that do not fulfil the validation criteria explained below are segmented again and, if they do not accomplish them again, they are rejected.

The criteria for rejecting a wrongly segmented image are based on specific values that have been obtained experimentally and that are the following ones:
                           
                              1.
                              The area, measured in pixels, of the obtained head can not be smaller than the 75% of the average area of the whole dataset. This average area was computed using a ground truth where the heads were segmented manually. As long as the camera resolution, and the magnification of the image (microscope and optics used) remain constant, this value is constant.

The ratio between the major and minor axes of the ellipse that has the same normalized second central moment as the considered head, must belong to the interval [1.5, 2.4]. These values were also obtained empirically using the same ground truth dataset.

The first segmentation was carried out preprocessing the images, thresholding them and applying several morphological operations. In the preprocessing, images are converted to grayscale and image contrast is increased with a histogram slicing. Later, a binary image is obtained with a threshold calculated using Otsu's method [28], the negative image is computed, the white regions are dilated using a disk-shaped structuring element and all the objects smaller than the biggest one are removed. Finally, the spermatozoa tail is separated using an opening and later removed in such a way that only the white region corresponding to the spermatozoon's head remains, region that will be used to mask the grayscale level image if the validation criteria are accomplished (regions properties like eccentricity or area).

When an image does not pass the segmentation test, the previously segmented region of interest, that did not accomplish the validation criteria, is used as the foreground marker for the Watershed transform. The markers are necessary to avoid the typical over-segmentation due to the fact that the gradient of the image is very sensitive to noise. In the non frequent cases when the previous segmentation do not yield any region, a box placed on the center of the image, with an area of the 25% of the image size, is used as the foreground marker. The background markers are obtained by computing the watershed transform of the distance image of the foreground marker to each one of the corners of the image. After performing the watershed segmentation, the regional minima of the gradient image is computed and the area of the foreground marker obtained with the watershed transformation is smoothed using an opening with a disk-shaped structuring element.

Finally, the validation criteria is checked out again, If the segmented image passes the criteria the grayscale image is masked with the binary image and, otherwise, the image is discarded and labelled as wrongly segmented.

Using this method, approximately 10% of the original images are non well segmented and rejected before the description. The good thing about this method, that also was the main reason for using it, is that non even one image wrongly segmented pass to the description step, as was checked by a visual validation of the whole segmented set. In this way, we are rejecting some rightly segmented images but with this approach we do guarantee that the posterior description is accomplished only on rightly segmented images. By the other hand, to discard some spermatozoa is not important in a CASA (Computer-Aided Sperm Analysis) system because usually, depending on the conditions on the sample (dilution, centrifugation, etc.), it is frequent to find overlapping spermatozoa, particles and other circumstances that recommends that the number of the spermatozoa that are present in a sample be much higher than the number of spermatozoa needed to assess this sample.

For texture description purposes, the head of each spermatozoon is automatically registered locating the tail part in the bottom of the image, using the same procedure as the one explained in [29]. This is doing before to remove the tail in the segmentation step.

We have used the Discrete Wavelet Transform (DWT) due to its proven efficiency when describing texture patterns. In a simple way, a wavelet transform decomposes an image into the sum of a coarse image plus a detailed image. The DWT of an image I is calculated by applying some low and high pass filters g as in Eq. (1).


                        
                           
                              (1)
                              
                                 y
                                 [
                                 n
                                 ]
                                 =
                                 
                                    
                                       
                                          I
                                          *
                                          g
                                       
                                    
                                 
                                 [
                                 n
                                 ]
                                 =
                                 
                                    ∑
                                    
                                       −
                                       ∞
                                    
                                    ∞
                                 
                                 x
                                 [
                                 k
                                 ]
                                 g
                                 [
                                 n
                                 −
                                 k
                                 ]
                              
                           
                        When the image is passed through a low pass filter, resulting in the lineal convolution between the image and the filter, only the coarse information of the image is preserved. On the other hand, when the image is convolved with a high pass filter, the fine details of the image are kept. This is called level 1 of decomposition. Nevertheless, each course approximation can be filtered, and therefore decomposed, again into a new level of decomposition. After filtering the image, a down-sampling by a factor of 2 is performed, which means that the even elements of the filtered image are preserved while the odd elements are omitted.A diagram together with a simple one dimension example of this approach can be seen in Fig. 2
                        .

In order to obtain DWT from an image, two dimension DWT has to be considered, leading to a decomposition into four sub-bands in each level of decomposition. These four sub-bands arise from applying horizontal and vertical filters one after the other and they are usually labelled as LL1, LH1, HL1 and HH1 in the first level. The letters refer to the kind of filter applied, L stands for low and H for high, and the number concerns the level of decomposition. For example to compute LH1, first a one dimension low pass filter is applied to each row of the image followed by a down-sampling of 2, leading to an image with half number of rows and the same number of columns. Next, the image is filtered with a one dimension high pass filter and down-sampled with a factor of 2, ending up in an image with both half number of rows and columns as shown in Fig. 3
                        (a). The four sub-bands are usually schematised as in Fig. 3(b) resulting in an image with the original size. In this way, LL1 represents the course information of the image and it is used to obtain the next levels of wavelet coefficients, while LH1, HL1 and HH1 conform the detail images.

We have chosen to use Haar wavelets in the computation of the DWT. The Haar wavelet, introduced by Alfréd Haar in 1910 [30], is the simplest possible wavelet. These set of square-shape functions can be described by its mother wavelet function 
                           ψ
                           
                              
                                 t
                              
                           
                         as


                        
                           
                              (2)
                              
                                 ψ
                                 
                                    
                                       t
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   0
                                                   ⩽
                                                   t
                                                   <
                                                   1
                                                   /
                                                   2
                                                
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   1
                                                   /
                                                   2
                                                   ⩽
                                                   t
                                                   <
                                                   1
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

with scaling function 
                           ϕ
                           
                              
                                 t
                              
                           
                        :


                        
                           
                              (3)
                              
                                 ϕ
                                 
                                    
                                       t
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   0
                                                   ⩽
                                                   t
                                                   <
                                                   1
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

In order to obtain the feature descriptor, some metrics are computed from the GLCM (Gray Level Co-occurrence Matrix) of the original image and the four sub-images of first level of decomposition with the Haar DWT similarly to [31].

GLCM is a second order texture statistic that represents how often different combinations of gray levels occur between two pixels of the neighbourhood at a given offset. Formally, if i and j are the image intensity values of the image, p and q are the spatial positions in the nxm image I and the offset (Δx, Δy) dependent on the direction and the distance at which the matrix is computed, the GLCM is obtained following Eq. (4).


                        
                           
                              (4)
                              
                                 
                                    GLCM
                                    
                                       Δ
                                       x
                                       ,
                                       Δ
                                       y
                                    
                                 
                                 (
                                 i
                                 ,
                                 j
                                 )
                                 =
                                 
                                    ∑
                                    
                                       p
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    ∑
                                    
                                       q
                                       =
                                       1
                                    
                                    m
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   I
                                                   (
                                                   p
                                                   ,
                                                   q
                                                   )
                                                   =
                                                   i
                                                   
                                                   and
                                                   
                                                   I
                                                   (
                                                   p
                                                   +
                                                   Δ
                                                   x
                                                   ,
                                                   q
                                                   +
                                                   Δ
                                                   y
                                                   )
                                                   =
                                                   j
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Some measurements can be computed from the GLCM to characterize an image. Haralick in [32] proposed 14 features. In this work, 13 out of those 14 features have been computed, leaving out the Maximal Correlation Coefficient. As mentioned previously, these features are computed on the GLCM of the original image and on the GLCMs of the four sub-bands of the first split of the Haar DWT, leading to a descriptor composed by 65 features which is called WCF13.

Contours are common occurrences in the fields of pattern recognition and image analysis as a way to describe objects. Fourier shape descriptors (FSD) provide the means to characterize those contours by capturing either the global features or the finer details of the object's shape. They were first introduced as tools for describing objects in biological samples by Holmquist et al.[33] and have become popular due to the fact that they are powerful descriptors that are relatively insensitive to noise and easy to normalize [34].


                        Fig. 4
                         shows a L-point digital boundary in the xy-plane. By traversing the boundary from an arbitrary starting point (x(0), y(0)) and storing coordinate pairs 
                           
                              
                                 x
                                 (
                                 t
                                 )
                                 ,
                                 y
                                 (
                                 t
                                 )
                                 ,
                                 t
                                 =
                                 0
                                 ,
                                 1
                                 ,
                                 …
                                 ,
                                 L
                                 −
                                 1
                              
                           
                         the boundary can be represented as a sequence of coordinates 
                           z
                           (
                           t
                           )
                           =
                           
                              
                                 
                                    x
                                    (
                                    t
                                    )
                                    ,
                                    y
                                    (
                                    t
                                    )
                                 
                              
                           
                        . Each coordinate pair can also be treated as a complex number so that
                           
                              (5)
                              
                                 z
                                 (
                                 t
                                 )
                                 =
                                 x
                                 (
                                 t
                                 )
                                 +
                                 iy
                                 (
                                 t
                                 )
                                 .
                              
                           
                        
                     

This action has the great benefit that it reduces a 2D problem to a 1D one. At this stage we can choose to eliminate the effect of translation bias by using a shifted coordinate function


                        
                           
                              (6)
                              
                                 z
                                 (
                                 t
                                 )
                                 =
                                 
                                    
                                       
                                          x
                                          (
                                          t
                                          )
                                          −
                                          
                                             x
                                             c
                                          
                                       
                                    
                                 
                                 +
                                 i
                                 
                                    
                                       
                                          y
                                          (
                                          t
                                          )
                                          −
                                          
                                             y
                                             c
                                          
                                       
                                    
                                 
                              
                           
                        where (x
                        
                           c
                        , y
                        
                           c
                        ) are the centroid coordinates of the object.

For object matching purposes it can be beneficial to sample objects at a fixed number of points rather than using every pixel in the boundary. Using a number of sample points that is lower than the number of pixels in the boundary also smooths the shape, removing noise. There exists different methods for performing the boundary sampling [34]. For the purposes of this paper the equal arc length sampling method has been chosen. The equal arc length method selects sampling points spaced at equal arclength along the shape boundary. Assuming K sample points the space between two consecutive sample points is given by P/K where P is the shape perimeter.

For a given shape signature, z(t), the discrete Fourier transform (DFT) is written as


                        
                           
                              (7)
                              
                                 u
                                 (
                                 n
                                 )
                                 =
                                 
                                    1
                                    L
                                 
                                 
                                    ∑
                                    
                                       t
                                       =
                                       0
                                    
                                    
                                       L
                                       −
                                       1
                                    
                                 
                                 z
                                 (
                                 t
                                 )
                                 
                                    e
                                    
                                       −
                                       i
                                       2
                                       π
                                       nt
                                       /
                                       L
                                    
                                 
                              
                           
                        where n
                        =0, 1, …, L
                        −1. The complex coefficients u(n) are called the FSD of the boundary. Fourier shape descriptors are especially good from the point of shape invariants. We are already using a shifted coordinate function (Eq. (6)) giving us translational invariance. Rotational invariance can be achieved by ignoring the phase information in u, taking only the magnitude values of the FSD. Finally, we can achieve scale normalization by dividing the magnitude values of all descriptors by the value of the second descriptor. An invariant Fourier descriptor vector, 
                           
                              d
                              ¯
                           
                        , can thus be written as


                        
                           
                              (8)
                              
                                 
                                    
                                       d
                                       ¯
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             d
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             d
                                             
                                                L
                                                −
                                                1
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   1
                                                   )
                                                
                                                |
                                             
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   1
                                                   )
                                                
                                                |
                                             
                                          
                                          ,
                                          
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   2
                                                   )
                                                
                                                |
                                             
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   1
                                                   )
                                                
                                                |
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   L
                                                   −
                                                   1
                                                   )
                                                
                                                |
                                             
                                             
                                                |
                                                
                                                   u
                                                   (
                                                   1
                                                   )
                                                
                                                |
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

From 
                           
                              d
                              ¯
                           
                         we can calculate the eccentricity, ecc, of the object as


                        
                           
                              (9)
                              
                                 ecc
                                 =
                                 
                                    
                                       
                                          d
                                          1
                                       
                                       −
                                       
                                          d
                                          
                                             L
                                             −
                                             1
                                          
                                       
                                    
                                    
                                       
                                          d
                                          1
                                       
                                       +
                                       
                                          d
                                          
                                             L
                                             −
                                             1
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

This constitutes a very rough description of the object shape. To obtain more detailed shape descriptors, it is necessary to locate which intervals of 
                           
                              d
                              ¯
                           
                         contain interesting information [35].

We define a lower and an upper limit, [A, B], B
                        >
                        A, that will capture the low-, freq
                        
                           low
                        , and the high-, freq
                        
                           high
                        , frequency shape energy for the object (Fig. 5
                        ). These energy scores are then calculated as


                        
                           
                              (10)
                              
                                 
                                    
                                       
                                          
                                             freq
                                             low
                                          
                                       
                                       
                                          =
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             A
                                          
                                          
                                             d
                                             i
                                          
                                          +
                                          
                                             ∑
                                             
                                                i
                                                =
                                                L
                                                −
                                                (
                                                A
                                                +
                                                1
                                                )
                                             
                                             
                                                L
                                                −
                                                1
                                             
                                          
                                          
                                             d
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             freq
                                             high
                                          
                                       
                                       
                                          =
                                          
                                             ∑
                                             
                                                i
                                                =
                                                A
                                                +
                                                1
                                             
                                             B
                                          
                                          
                                             d
                                             i
                                          
                                          +
                                          
                                             ∑
                                             
                                                i
                                                =
                                                L
                                                −
                                                (
                                                B
                                                +
                                                A
                                                +
                                                1
                                                )
                                             
                                             
                                                L
                                                −
                                                (
                                                A
                                                +
                                                2
                                                )
                                             
                                          
                                          
                                             d
                                             i
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     

In Fig. 6
                        , the difference in energy values for different intervals depending on boundary shape is illustrated.

Local Binary Pattern (LBP) [36] is a gray-scale texture operator that extracts pixel-wise information of an image. The relationships between a pixel and its neighbourhood pixels are described in a way that all neighbours that have values higher than or equal to the value of the central pixel are multiplied by 1, and all the rest are multiply by 0. After that, the LBP for that pixel is extracted by summing up all those values. Eq. (11) express this concept mathematically and Fig. 7
                         shows the extraction of one pattern for one pixel.


                        
                           
                              (11)
                              
                                 
                                    LBP
                                    
                                       P
                                       ,
                                       R
                                    
                                 
                                 =
                                 
                                    ∑
                                    
                                       p
                                       =
                                       0
                                    
                                    
                                       P
                                       −
                                       1
                                    
                                 
                                 s
                                 (
                                 
                                    g
                                    p
                                 
                                 −
                                 
                                    g
                                    c
                                 
                                 )
                                 
                                    2
                                    p
                                 
                                 ,
                                 s
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                
                                                
                                                   if
                                                   
                                                   x
                                                   ≥
                                                   0
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   x
                                                   <
                                                   0
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where g
                        
                           c
                         are the value of central pixel, g
                        
                           p
                         the value of its neighbour p, P the number of neighbours and R the radius of the neighbourhood.

Despite LBP is gray scale invariant, rotating a binary pattern results in a different LBP value. In order to achieve invariance to rotation by assigning a unique identifier to each rotated LBP the following equation was defined by Ojala et al. in [37]:


                        
                           
                              (12)
                              
                                 
                                    LBP
                                    
                                       P
                                       ,
                                       R
                                    
                                    ri
                                 
                                 =
                                 min
                                 
                                    
                                       
                                          ROR
                                          (
                                          
                                             LBP
                                             
                                                P
                                                ,
                                                R
                                             
                                          
                                          ,
                                          i
                                          )
                                          ∣
                                          i
                                          =
                                          0
                                          ,
                                          1
                                          ,
                                          .
                                          .
                                          .
                                          ,
                                          P
                                          −
                                          1
                                       
                                    
                                 
                              
                           
                        where ROR(x, i) performs a circular bit-wise right shift on the P-bit number x i times. In this way for example the patterns 01001111 and 00111101 will lead to the same output value.

As mentioned by Ojala et al. in the same work [37], some LBP appear to be fundamental properties of local textures and they are called “uniform” patterns since they contain very few spatial transitions. Formally, U(“pattern”) is a uniformity measure which is equal to the number of bitwise transitions from 0 to 1 or from 1 to 0 taking into account also the possible transition between the last and first bits of the pattern. An LBP is considered uniform if U(“pattern”) is at most 2. Examples of uniform patterns are 00000000 (0 transitions), 00000001 (2 transitions), 00111000 (2 transitions) whereas 01011000 (4 transitions) or 00101011 (6 transitions) are examples of non-uniform patterns. The following operator apart from being gray scale and rotation invariant gather non-uniform patterns in the same group:


                        
                           
                              (13)
                              
                                 
                                    LBP
                                    
                                       P
                                       ,
                                       R
                                    
                                    
                                       riu
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         p
                                                         =
                                                         0
                                                      
                                                      
                                                         P
                                                         −
                                                         1
                                                      
                                                   
                                                   s
                                                   (
                                                   
                                                      g
                                                      p
                                                   
                                                   −
                                                   
                                                      g
                                                      c
                                                   
                                                   )
                                                
                                                
                                                   if
                                                   
                                                   
                                                   U
                                                   (
                                                   
                                                      LBP
                                                      
                                                         P
                                                         ,
                                                         R
                                                      
                                                   
                                                   )
                                                   ≤
                                                   2
                                                
                                             
                                             
                                                
                                                   P
                                                   +
                                                   1
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where


                        
                           
                              (14)
                              
                                 U
                                 (
                                 
                                    LBP
                                    
                                       P
                                       ,
                                       R
                                    
                                 
                                 )
                                 =
                                 |
                                 
                                    s
                                    (
                                    
                                       g
                                       
                                          P
                                          −
                                          1
                                       
                                    
                                    −
                                    
                                       g
                                       c
                                    
                                    )
                                    −
                                    s
                                    (
                                    
                                       g
                                       0
                                    
                                    −
                                    
                                       g
                                       c
                                    
                                    )
                                 
                                 |
                                 +
                                 
                                    ∑
                                    
                                       p
                                       =
                                       1
                                    
                                    
                                       P
                                       −
                                       1
                                    
                                 
                                 |
                                 
                                    s
                                    (
                                    
                                       g
                                       p
                                    
                                    −
                                    
                                       g
                                       c
                                    
                                    )
                                    −
                                    s
                                    (
                                    
                                       g
                                       
                                          p
                                          −
                                          1
                                       
                                    
                                    −
                                    
                                       g
                                       c
                                    
                                    )
                                 
                                 |
                              
                           
                        
                     

There are only P
                        +1 uniform patterns in a neighbour of P pixels. Each of these will have a label from 0 to P, according to equation 13, which corresponds to the number of bits equal to 1 in the pattern. On the other hand, all non-uniform patterns will be labelled as P+1. See Fig. 8
                        . Therefore, in total 
                           
                              LBP
                              
                                 P
                                 ,
                                 R
                              
                              
                                 riu
                                 2
                              
                           
                         produces P
                        +2 output values. Finally, a histogram of P
                        +2 bins is built in order to describe the whole image by computing 
                           
                              LBP
                              
                                 P
                                 ,
                                 R
                              
                              
                                 riu
                                 2
                              
                           
                         for each pixel of the image, yielding the feature vector of the image.

In this work, we have used 
                           
                              LBP
                              
                                 P
                                 ,
                                 R
                              
                              
                                 riu
                                 2
                              
                           
                         but for simplicity it will be called LBP henceforth.

In this work, we propose an early fusion strategy to describe the intact and damaged-acrosome spermatozoa using the information provided by the three descriptors detailed in previous subsections. Having into account the results obtained, we considered that this is an example where combining the information before the classification step produce a good description of the object of interest, the two kind of spermatozoa heads. Even so, in a future work we consider to explore the effects of a later fusion in the classification performance.

Therefore, our proposal in this work is to obtain a new descriptor, named WFLP (Wavelet Fourier Local Pattern), defined as the concatenation of the WCF13, FSD and LBP descriptors detailed before. In this way, each spermatozoa head is describe in terms of global (WCF) and local (LBP) texture in conjunction with the information of its shape based on the contour (FSD).

Given a head image, the WCF13 (
                           
                              fv
                              1
                           
                           =
                           [
                           
                              w
                              1
                           
                           ,
                           
                              w
                              2
                           
                           ,
                           .
                           .
                           .
                           ,
                           
                              w
                              65
                           
                           ]
                        ), the FSD (fv
                        2
                        =
                        f
                        1, f
                        2, f
                        3) and the LBP (fv
                        3
                        =
                        l
                        1, l
                        2, ..., l
                        
                           P+2), the WFLP is created by concatenating the features as:


                        
                           
                              (15)
                              
                                 
                                    fv
                                    new
                                 
                                 =
                                 [
                                 
                                    fv
                                    1
                                 
                                 ,
                                 
                                    fv
                                    2
                                 
                                 ,
                                 
                                    fv
                                    3
                                 
                                 ]
                                 =
                                 [
                                 
                                    w
                                    1
                                 
                                 ,
                                 
                                    w
                                    2
                                 
                                 ,
                                 .
                                 .
                                 .
                                 ,
                                 
                                    w
                                    65
                                 
                                 ,
                                 
                                    f
                                    1
                                 
                                 ,
                                 
                                    f
                                    2
                                 
                                 ,
                                 
                                    f
                                    3
                                 
                                 ,
                                 
                                    l
                                    1
                                 
                                 ,
                                 
                                    l
                                    2
                                 
                                 ,
                                 .
                                 .
                                 .
                                 ,
                                 
                                    l
                                    
                                       P
                                       +
                                       2
                                    
                                 
                                 ]
                              
                           
                        where fv
                        
                           new
                         is the WFLP descriptor.

Hence, the fusion increases the dimension of the feature vector but also improves the description of the image. For the LBP P
                        =8 and P
                        =16 were evaluated, which means that the total length of the WFLP descriptor is either 65+3+8+2=78 features or 65+3+16+2=86 features. In the next section we will present and discuss the results obtained with the most outstanding fusion approaches evaluated. LBP will be shown with radius equal to 1 and 8 neighbours and with radius 2 and 16 neighbours whereas WCF13 will be presented with distances at which the GLCM matrix is computed from 1 to 10.

@&#EXPERIMENTS@&#

Due to the lack of datasets for the purpose of this paper, we have collected and labelled a boar sperm dataset available at our website.
                           1
                        
                        
                           1
                           
                              http://pitia.unileon.es/VARP/datasets.
                         The images have been captured at CENTROTEC research centre working together with a group of medical veterinarians. Furthermore, in order to make the dataset valid for a wider variety of boars, sperm samples have been obtained from three races which are Piyorker, Large White and Landrace.

First of all, we have taken an aliquot with 500μl of diluted sperm. Afterwards, 5μl of formaldehyde (<0.3%), 25μl of FITC-PNA lectin, and the aliquot were mixed. The formaldehyde paralyses the movement of the spermatozoa in order to make possible a better capture of the images.

The images were acquired using a Basler Scout scA780-54fc camera, with 780×580 pixels of spatial resolution, controlled by a computer in order to adjust its parameters and to store the images. Besides the camera, an epifluorescent microscope Nikon E-600 configured with a 100× magnification allowed to capture and to observe a sample under a positive phase contrast and under a fluorescent illumination.

Using this microscope it was possible to create the ground truth dataset where each head in grayscale is labelled as acrosome-intact or acrosome-damaged in base of the color information obtained from its fluorescent paired image. This was possible because when the acquisition had place, two images, one in positive phase contrast and the other one with fluorescent illumination where captured for the same sample. Therefore, for each sample two snapshots were taken and stored, one in positive phase contrast with a conventional light diaphragm and the other one in real color with fluorescence illumination. The positive phase contrast image is a gray level image that was the one used in the image processing, namely the segmentation and description of the spermatozoa heads. On the contrary, the fluorescent illumination snapshot was only used to manually label each sperm head as acrosome-intact or acrosome-damaged in order to create the reliable ground truth. Overlapped heads cannot be analysed, so they are discarded from the set of images.

First row of Fig. 9
                         presents several examples of the positive phase contrast images whilst in second row fluorescent images are shown. The samples were stained with hypogaea (peanut) agglutinin (PNA) that is a labelling method where the labelling is restricted to the acrosome and is not influenced by the fixation procedure. As it is known [38], the FITC-PNA binding site is mainly limited to the outer acrosomal membrane of boar sperm, therefore it is an accurate test for studying boar sperm acrosome reaction.

After this labelling, the dataset used was meaningful for classification with supervised learning techniques. More details about the sample preparation can be found in [39].

Each of the spermatozoa has been cropped to obtain only one spermatozoon per image following the method described in 2.1.

Finally, the dataset is composed by a total of 1851 images with 905 intact and 946 damaged acrosomes. This dataset is the biggest one up to date, compared with most of the papers published on this topic. In 2013 in [18] only 360 acrosomes were used (210 intact and 150 damaged) whereas Alegre et al. [17] in 2012 used a total of 800 sperm heads, 400 intact and 400 damaged. On that account, more reliable results are expected with this bigger dataset. Examples of intact and damaged spermatozoa heads can be found in the Figs. 10
                         and 11
                        .

Several configurations of the classifier have been tested in order that our statistical analysis is able to generalize to an independent data set. A cross validation algorithm has been implemented to deal with this model selection problem. Therefore, the parameters of the classifier will be chosen testing the cross validation set and once the best parameters are selected the results will arise using the test set. To that end, a random subset of 20% of the images are kept to use as test set. Since this is a dichotomous classification, the splits of our dataset will be done in a way that each subset contains roughly the same proportions of the two classes, intact and damaged. Then, a 10-fold cross validation algorithm is applied to chose the best parameters and solve the problem of the model selection. The classification was performed with a Support Vector Machine (SVM) backed by a Least Squares (LS) training algorithm and a linear kernel. Experiments with Gaussian kernel obtained worst results. This process is completely explained in the Algorithm 1 and a schema is shown in Fig. 12
                        .


                        
                           Algorithm 1
                           Cross validation algorithm and experimental setup. 
                                 
                                    
                                       
                                       
                                          
                                             
                                                Require: Cropped heads.
                                          
                                          
                                             
                                                Ensure: Precision, recall, F-Score and accuracy of the method.
                                          
                                          
                                             1.  Select randomly 20% of the images as test set (20% of the intact images and 20% of the damaged images).
                                          
                                          
                                             2.  Split the rest of the images (80%) in 10 subsets with equally intact and damaged heads proportions.
                                          
                                          
                                             3.  for each parameter configuration do
                                             
                                          
                                          
                                             4.
                                                for i=1:10 do
                                             
                                          
                                          
                                             5.   Take the ith subset as cross validation set.
                                          
                                          
                                             6.   Take the rest as training set.
                                          
                                          
                                             7.  Perform SVM with LS training.
                                          
                                          
                                             8.  Compute and store F-Score and accuracy.
                                          
                                          
                                             9.
                                                end for
                                             
                                          
                                          
                                             10. Compute and store mean F-Score and accuracy on the ten subsets.
                                          
                                          
                                             11.   end for
                                             
                                          
                                          
                                             12.  Select the SVM model with the highest F-Score and accuracy.
                                          
                                          
                                             13.  Evaluate test set using the selected SVM.
                                          
                                          
                                             14.  Compute precision, recall, F-Score and accuracy.
                                          
                                          
                                             
                                          
                                       
                                    
                                 
                              
                           

Precision, recall, F-Score and accuracy are the measurements used to assess the response of our method. The main reason is because they are well known and widely employed for the pattern recognition community. Besides, this metrics were used in previous works therefore it is easier to compare the results obtained in this work with the state of the art. We defined the damaged heads as the positive class and the intact one as the negative class. Then, a True Positive (TP) is a damaged head classified as damaged; a True Negative (TN) is an intact head recognized as intact; a False Positive (FP) is an intact head classified as damaged; and a False Negative (FN) is a damaged head recognized as intact. Thereafter, precision, recall, F-Score and accuracy are defined in Eqs. (16)–(19), respectively. Note that F-Score vary in the range [0,1] being 1 the best score and 0 the worst one.


                        
                           
                              (16)
                              
                                 Precision
                                 =
                                 
                                    TP
                                    
                                       TP
                                       +
                                       FP
                                    
                                 
                              
                           
                        
                        
                           
                              (17)
                              
                                 Recall
                                 =
                                 
                                    TP
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (18)
                              
                                 F
                                 −
                                 Score
                                 =
                                 2
                                 ·
                                 
                                 
                                    
                                       Precision
                                       ·
                                       Recall
                                    
                                    
                                       Precision
                                       +
                                       Recall
                                    
                                 
                              
                           
                        
                        
                           
                              (19)
                              
                                 Accuracy
                                 =
                                 
                                    
                                       TP
                                       +
                                       TN
                                    
                                    
                                       TP
                                       +
                                       FP
                                       +
                                       TN
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                     

In Fig. 13
                        , the results for each evaluated descriptor are presented. As mentioned, the WCF13 (W) is evaluated for distances of the GLCM from 1 to 10 whereas the LBP approach is shown both for radius 1 and 8 neighbours (L8) and for radius 2 and 16 neighbours (L16). Fourier contour descriptor will be shorten as F. The considered descriptors are: the basic approach of only considering WCF13 descriptor, the combination of WCF13 either with Fourier (WF) or with LBP (WL8 and WL16) and, finally, the fusion of the three methods (WFLP8 and WFLP16).

It is possible to notice that using only the global descriptor, WCF13, W in Fig. 13(f), the best recall, and at the same time the worst precision, is obtained at distance 7. It means that almost all the damaged are classified rightly but also a not small number of intact ones have been considered as damaged. With this descriptor, the most balanced point is with distance 2, where the FScore is the better because there are less intact spermatozoa classified as damaged. Therefore, this global descriptor works better when considering the information that is at short distance, classify well the damaged ones, the 99%, but also miss-classify 4 intact heads out of 100. Hence, global descriptors give us a high recall.

When adding local information, coming from LBP, subfigures (e) and (d) results change slightly. The information of the 8 neighbourhoods combined with wavelet (subfigure (e)) makes differences between precision and recall much smaller in general, increasing the FScore when GLCM is computed with a distance of 2 pixels. It is clear that the local information of LBP8, WL8 in subfigure (e), gives more precision to the classification so, in this case, the description is more reliable and when it classifies a head as acrosome-damaged, it is true in almost the 99% of the cases. When the neighbourhood is bigger, WL16, results get worse. It is the best until the moment but the difference between precision and recall is big, saying us that some of the damaged ones are considered as intact. Hence, adding local information we obtain more precision but losing a little bit of recall.

If we consider now subfigure (c), we will see that adding information of the contour, the Fourier descriptors, to the global descriptor yields a higher precision than before. Of course, depending on the distance the recall drops and again the differences between precision and recall grow. It is clear that information of the contour helps a lot for detecting the acrosome-damaged heads. Looking at Figs. 11 and 10 it is noticeable that the borders of the apical area are much more smooth in the intact than in the damaged ones and the Fourier descriptor is having advantage of this property for detecting in a very precise way to all the acrosome-damaged heads. Therefore, adding contour information increases more the precision.

Finally, in the subfigures (a) and (b) it is possible to see the combination of the three different kind of descriptors: global (WCF13), local LBP and contour (FSD). Something remarkable is that with WFLP16 a 100% of precision is reached for distances 7 and 10. The problem with this approach is that when precision is so high, recall drops significantly. By the contrary, the same combination but using LBP with a small neighbourhood, WFLP8, yields a more balanced response, with very high Fscore at distance 3, and the highest, above 99% with distance 6. In this case, the high precision produced by the Fourier descriptors is combined with the good recall yield by LBP8 and, in general with the not bad behaviour of the wavelet descriptors. For this reason, this will be our final proposal.

In order to better understand these results, Figs. 14
                         and 15
                         and Table 1
                         summarize comparatively the values obtained with the distances of the GLCM that perform better for the four more representative methods.

As we saw above, it is possible to notice in Fig. 14 that the wavelet descriptor has almost the highest recall. This means that by using global information most of damaged heads are recognized but but paying the price of detecting wrong some intact heads as damaged.

Adding Fourier contour information to the basic WCF13 descriptor (F-Score equals 0.9897 and accuracy of 98.92%) outperforms the combination of WCF13 with LBP (0.9795 F-Score and 97.84% accuracy). However both approaches perform better than the basic WCF13 (0.9718 F-Score and 97.30% accuracy). Moreover, it is interesting to notice that using global descriptors (WCF13) leads to higher recall than precision but when it is combined with local information such as LBP or Fourier the precision increases while the recall remains or even decreases. While local description can better describe the heterogeneous texture of a damage acrosome with black spots, global information captures better the homogeneous and smooth texture of the intact heads. Therefore the combination of both local and global methods in the description of acrosomes is a nice solution, achieving a good performance both in terms of precision and recall.

The ROC curve raises quickly towards high True Positive Rates which indicates good classification results (see Fig. 15). The best F-Score (0.9912) and accuracy (99.19%) are achieved with the concatenation of the three methods with radius 1 and 8 neighbours in the LBP and WCF13 with distance 6. Therefore, our proposed approach provides a very reliable method for classifying boar spermatozoa as acrosome-intact or acrosome-damaged.

Another important thing to highlight is that our proposal improves all previous methods in the literature dealing with the same purpose as it can be seen in Table 2
                        . In the most recent one, Alegre et al. [18] achieved a hit rate of 99% but using a very small dataset of 360 heads, 210 intact and 150 damaged. Here we have not only increased the performance but also results are more reliable since the dataset used is bigger with 1851 images (905 intact and 946 damaged) (Table 3
                        ).

@&#CONCLUSIONS@&#

This paper deals with the classification of the boar acrosome integrity as intact or damaged using gray scale digital images. With this purpose, three descriptors have been considered, compared and combined. We have computed 13 Haralick features on the GLCM of the original image and the four sub-bands of the first split of the Haar DWT, making up a global texture descriptor of the head of the spermatozoon. Besides, a local texture description is obtained by computing a rotation invariant and uniform LBP. Finally, the shape is described through FSD giving an idea of the contour of the spermatozoon head. We use a early fusion approach, concatenating the three selected descriptors before the classifier since each one provides new descriptive information. A k-fold cross validation analysis has been implemented to make the results independent from the classification parameters selection. The classification has been carried out with a SVM backed by a LS algorithm and four metrics have been computed in order to measure the performance of our proposal: precision, recall, F-Score and accuracy. Results have shown that the best performance is achieved by the combination of the three selected descriptors (WFLP8) with a distance of 6 pixels in the GLCM matrix and a radius 1 and 8 neighbours in the LBP. The 99.19% of accuracy and 0.9913 of F-Score makes this approach the best to this date [11,17,18] and very advantageous for the veterinary community. Furthermore, the dataset is much bigger than in previous works with a total of 1851 heads, making the results more reliable.

@&#ACKNOWLEDGEMENTS@&#

This work has been supported by DPI2012-36166 grant and the pre-doctoral FPU fellowship program supported by the Spanish Government (AP2010-0947).

@&#REFERENCES@&#


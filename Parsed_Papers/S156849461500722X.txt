@&#MAIN-TITLE@&#Optimal design of a 3D-printed scaffold using intelligent evolutionary algorithms

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The aggregated artificial neural network was used to investigate the simultaneous effects of printing parameters on the compressive strength and porosity of scaffolds.


                        
                        
                           
                           Particle swarm optimization algorithm was implemented to obtain the optimum topology of the AANN. Pareto front optimization was used to determine the optimal setting parameters.


                        
                        
                           
                           The presented results and discussion can give informative information to practitioners who want to design a porous structure, and need to know the impact of influential design parameters.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Scaffolds

3D printer

Aggregated artificial neural network (AANN)

Particle swarm optimization (PSO)

Porous structure

Mechanical strength

@&#ABSTRACT@&#


               
               
                  Fabrication of three-dimensional structures has gained increasing importance in the bone tissue engineering (BTE) field. Mechanical properties and permeability are two important requirement for BTE scaffolds. The mechanical properties of the scaffolds are highly dependent on the processing parameters. Layer thickness, delay time between spreading each powder layer, and printing orientation are the major factors that determine the porosity and compression strength of the 3D printed scaffold.
                  In this study, the aggregated artificial neural network (AANN) was used to investigate the simultaneous effects of layer thickness, delay time between spreading each layer, and print orientation of porous structures on the compressive strength and porosity of scaffolds. Two optimization methods were applied to obtain the optimal 3D parameter settings for printing tiny porous structures as a real BTE problem. First, particle swarm optimization algorithm was implemented to obtain the optimum topology of the AANN. Then, Pareto front optimization was used to determine the optimal setting parameters for the fabrication of the scaffolds with required compressive strength and porosity. The results indicate the acceptable potential of the evolutionary strategies for the controlling and optimization of the 3DP process as a complicated engineering problem.
               
            

@&#INTRODUCTION@&#

Additive manufacturing (AM) is a layer-over-layer manufacturing technique. In most cases, enables complex components to be manufactured that are difficult to fabricate or cannot be made using conventional methods. Among AM practices, powder-based three-dimensional printing (3DP) is the most capable technique for bone tissue engineering (BTE) applications [1–6].

Seeding and cultivating scaffolds with bone cells is the standard method in BTE. Scaffolds are highly porous 3D structures that aim to imitate the natural extracellular matrix (ECM) of bone on a temporary basis. From a technical point of view, scaffold engineering sets high demands on design and materials. In addition to chemistry, interconnected porosity, permeability, and mechanical strength are critical parameters that define the performance of a scaffold. These factors cannot be controlled precisely through conventional fabrication processes [7–9].

The immense potential for fabrication of scaffolds due to its maximum control over porosity and its ability to reproduce the customized anatomical design with great fidelity to the 3D medical pictures are the main advantages of the powder-based 3DP [10–12].


                     Fig. 1
                      shows a schematic illustration of the 3DP process. First, the chosen physical object is modeled on a computer-aided design (CAD) system. Then, the CAD model is converted to the stereolithography (STL) file format. A software program analyzes the STL file and mathematically slices the model into cross sections based on the selected layer thickness. The cross sections are recreated using the reaction of the powder and the binder. This process is repeated layer by layer until a 3D object similar to the design is formed. During the fabrication process, the printer head jets a liquid into thin layers of powder according to the object profile created by the software. Subsequently, a build chamber (build-bed) containing the powder bed is lowered to enable the spreading of the next powder layer. Following the consecutive application of layers, the unbound powder is removed, and the 3D part is produced [13–17]. Setting the 3DP process parameters is a complex and time-consuming task, as there are many variables that influence the printed part quality for particular applications. In many cases, these variables conflict with each other. In recent years, many reports have been made on the 3DP fabrication of BTE scaffolds, and its critical process factors and parameters [18–22]. Many studies have focused on improving the dimensional accuracy (DA) and mechanical properties of 3D-printed objects and have shown sensitive process parameters that can be tuned to improve the desired attributes. These characteristics are related to the process parameters and can be improved with proper adjustment [4,19,20,23–25].

Although a number of successful production experiments have been conducted, the quality assessment of fabricated parts remains to be one of the main challenges. Factors influencing quality have been studied through diverse indicators. However, a significant amount of work has not focused on mechanical properties and porosity together for the fabrication of tiny pores on scaffolds in the application of BTE. The cost of the end products of the process is high. Therefore, from a technological and economic point of view, selecting the process parameters for the optimization of manufactured parts is highly essential. In the context of the 3DP process optimization for improving the performance of the prototype, the soft computing method is a promising approach to monitor and model the process based on physical understanding and experimental data [26].

Achieving the optimal process parameters for fabricating 3D parts using the experimental tests is a time-consuming and costly approach. Numerical models of the process can be effective tools in finding the appropriate process parameters according to the demanded characteristics. From the physical modeling point of view, the 3DP process is complex. Many physical phenomena (e.g., powder and binder reaction and removing unbound powder) affect product quality. Based on the author's experiments and analysis, it has been observed that the relation between the porosity and compression strength of the porous structures and the influential parameters are nonlinear and uncertain. On the other hand, it is a very formidable task to provide an authentic and exact physics-based mathematical formulation, which can effectively represent the effect of layer thickness, delay time between spreading of each powder layer and printing orientation on the porosity and compression strength of the porous structures. Solving all the related governing equations using the analytical or numerical methods to obtain a mathematical model of the 3DP process is not only difficult but may also be impossible. To overcome this problem, the best way is to use a soft method to obtain a data-driven mapping system to approximately analyze the destined properties of the porous structures. Many researchers prefer to use semi-experimental models instead of numerical models to model the physical process, such as the 3DP process. Artificial neural network (ANN) [27–30], fuzzy system [31,32], Hammerstein–Wiener [33,34], time series [34], and Kalman filter are some of the well-known methods for establishing an experimental model of a system based on the available experimental data. To select a soft method which can be reliably used for this case study, the authors considered several techniques and conducted a primitive study such as neural networks, polynomials, splines, and etc. Published papers on ANNs suggest that this modeling methodology is a promising alternative tool for process modeling [35–40]. This method can overcome conventional modeling difficulties as it has the advantages of ease of implementation and capability of constructing a complex nonlinear map between inputs and outputs of a system. A few studies have been conducted on ANN modeling of the 3DP process. This research aims at developing an experimental based predictive model for the 3D printing process using the aggregated artificial neural network (AANN) method. The AANN algorithm is one of the well-known variants of the neural networks models which has been used in many engineering applications [41–45]. Aggregating multiple neural for improving the generalization of neural networks, is its main contribution. Many researchers have shown that a more accurate predictive model can be obtained in comparison with a single neural network with the same number of neurons by aggregating several neural networks [46,47]. Finding a single neural network that can model a highly uncertain complex engineering phenomenon is often difficult. The major drawbacks of these artificial machines often result from over fitting and high computational complexity. Combining a set of independent networks as cooperative learnable agents appear to be a promising strategy in enhancing the robustness and generalization of these artificial machines. Another promising aspect in designing a modeling machine is to find a system that can handle more than one task simultaneously. To the knowledge of the authors, ensemble artificial machines are best suited in this case, as a single network may concentrate on modeling a specific task while neglecting others. The predominance of AANN for modeling multi-output phenomena is reported in many studies [46]. In the recent study of Furtuna et al. [47], they developed a stacked neural network (SNN) and an evolutionary hyper-heuristic method for the optimum modeling of a complex chemical process. Their results imply the obvious advantages of AANNs for modeling complex engineering application. Selecting the best topology is the main drawback of AANN. For training an AANN it is needed to select the number of neural networks, number of neurons and hidden layers in each neural network. However, no convenient approach exists for the optimal design of these systems. Many researchers have proposed different methods for grasping an optimal topology for AANNs. Zhou et al. [46] applied a simple genetic algorithm (named GASEN) and showed that GASEN could generate an aggregated neural network with a far smaller size and stronger generalization ability compared with other common techniques. In another study, they developed a non-dominated sorting genetic algorithm as a high-level heuristic algorithm and a well-known back propagation method called quasi Newton training as a low-level heuristic algorithm for optimizing the structure of AANN [47]. They reported the effectiveness of their method, but it had some limitations, such as high computational time and complexity.

In this study, meta-heuristic algorithms are used as supervised algorithms for finding the stage of the optimum topology of the AANN. Meta-heuristic algorithms are population-based artificial methods that are widely used to handle real-life and hard nonlinear engineering problems [48,49]. These algorithms that initiate the natural evolutionary mechanisms have many advantages compared with the conventional methods. The particle swarm optimization (PSO) algorithm is the selected algorithm for constructing the optimal topology of the AANN. To select PSO, the authors considered some potential training methods, such as PSO, GA, ABC, and FA. It was observed that PSO has a very high computational speed and does not result in a computational stagnation. This is not the case when using GA and ABC which have relatively complicated algorithmic structures, and should activate so many exploration/exploitation operators at each iteration. Given the fact that training AANN is a time-consuming task, and PSO can effectively balance the exploration and exploitation over the searching period, it was selected as the fit algorithm for evolving the architecture of AANN. Furthermore, the authors’ experiments revealed that, at-least for the current case study, PSO could afford the best results as it is just related to inertia weight and can converge to an acceptable solution in a logical period of time. This was not the case when we used GA and ABC. For AG, several parameters, e.g. number of elite chromosomes, mutation probability and crossover probability and etc., would be taken into account, which result in a complex optimization algorithm. The same observation was valid for ABC in which there was a need for fine-tuning of several parameters, such as number of employed and onlooker bees and number of limits for abounding, a cite. Moreover, the simulations clearly demonstrated that PSO can show a faster and much robust exploration/exploitation over the procedure, and also can guarantee the convergence to a near optimum structure for AANN, which was not the case when using the other methods. Such observations have brought the authors to the conclusion that, in spite of its simplicity, PSO is the most logical choice for evolving the architecture of AANN.

The main objective of the present study is to develop the best AANN model to analyze the nonlinear effect of 3D printer machine parameters on the compressive strength and porosity of printed porous structures, which is one of the more widely challenging aspects of printing scaffolds. To the best knowledge of the authors, using an aggregated structure has not been proposed before for the considered case study. This is when it is highly necessary to make sure the developed soft sensor possesses an acceptable generalization, as the number of data points is often limited for such applications and there is a possibility for over fitting or under fitting, which makes the soft-sensor unreliable for unseen data (testing phase). In this way, the experiments of the current study take a stride toward indicating that the aggregated structures are best suited for applications the same of Scaffold modeling in which it is not easy to gather a rich database, and it takes a long time (even years) to come up with an exhaustive database which can be fed to simple soft models, such as NN and ANFIS. The rest of the paper is organized as follows. In Section 2, the structure of the 3D printing and its parameters are presented brieﬂy. The aggregated artificial neural network and its structure are introduced in Section 2.4. In Section 2.5, the authors provide the stepwise explanations of the particle swarm optimization algorithm. The experimental and numerical results are given in Section 3. Finally, the paper is concluded in Section 4.

Previous studies show that among the various process parameters, the printing direction (axial direction aligned with the x, y, and z directions of the printing build-bed) of a part seems to have the greatest impact [25,50]. The adequate pore size for BTE is generally reported to be in range 100–800μm for cell attachment and vascularization [51]. The ability of a 3D printer to fabricate a minimum geometrical size is restricted by the powder particle size, which determines the thinnest layer thickness. In 3DP processes, layer thickness refers to the height of the powder bed that is spread along the z-axis during the procedure. The typical layer thickness is generally at least twice the powder particle size dimension, which is approximately 100μm [3,52]. Therefore, one of the important factors for building the tiny pore size of engineered scaffolds is layer thickness [18,19]. Furthermore, spraying the binder drops causes shear forces that are applied to the top layer of the powder bed. As a result, the thin printed structures may be displaced, possibly affecting the integrity and accuracy of the printed object. Mechanical features may also be affected, and thus another important factor is stability of the pre-deposit powder layer during the reaction between powder and binder [53,54]. Therefore, adequate time between spreading one layer and jetting the binder to start spreading the next one to relax and desensitize the powder and the binder is another important factor. We refer to this delay as the delay time. Increasing the powder delay time, particularly in pores and channels, results in further densification. Added time can also affect layer-to-layer bonding, which will consequently affect the mechanical and dimensional features of the specimens. Therefore, finding adequate time for the fabrication of small-scale parts is challenging.

In this study, a scaffold was considered as a cylindrical structure shaped by an extruding cut by small cubicle elements that determine the pore and strut size. Scaffold prototypes with 12mm height, 6mm diameter, 0.8mm pore size, and 0.6mm strut size were designed using the 3D design software SolidWorks®2012 and exported as an STL file. The height and the diameter circumscribed the number of pores, so the porosity of CAD model was 45.04%. The geometry of the scaffolds was chosen as it represents the typical feature sizes found in the BTE scaffolds. Fig. 2
                         presents the CAD model of the scaffolds.

The 3D-printing machine Zprinter®450 (Z-Corporation, Burlington, USA) was used to produce the prototypes. A high-performance composite material (Zp150) and a water-based binder (Zb63) were also supplied by Z Corporation [50,55]. After printing, all the samples were dried for 90min in the machine at the ambient temperature. Then, the printed porous bodies were de-powdered with compressed air to remove any trapped and unbound powder. In this study, the authors avoided any further post hardening or infiltration.

The 3DP process parameters examined in this study were layer thickness, delay time in spreading a new layer, and build orientation. All other machine setting parameters were the same as the default, and the binder saturation core and shell for all runs were considered 100%.

An experiment plan based on a full factorial design of experiments (DOE) was used to print the scaffold prototypes. Layer thickness was selected from four possible values of 89, 102, 114, and 127μm. The chosen delay times were 50, 100, 300, and 500ms, and X, Y, and Z were considered as part orientations.

A porous scaffold is required in BTE to act as an ECM and guide for cell proliferation, differentiation, and eventual tissue growth. Fluid flow through a bone scaffold (permeability) is an important factor because of its ability to build living tissue. Successful BTE depends on the scaffold's ability to enable nutrient diffusion and waste removal from the regeneration site, as well as to provide an appropriate mechanical environment. In other words, maximum permeability is needed as far as the mechanical properties are not compromised. Therefore, a trade-off exists between these two requirements [56].

Note that only open and interconnected pores contribute to permeability and cell in-growth, whereas closed pores only reduce the strength. In conclusion, we need to minimize the closed porosity and maximize the open porosity in a way that the mechanical properties (strength and modulus) are not compromised.

For the reconstruction of complex bone defects such as osteoporotic fractures, patient-specific BTE implants with a proper internal structure and mechanical properties are needed. Therefore, from the fabrication point of view, maximum compressive strength, maximum fidelity with the CAD design (DA), and maximum permeability are needed to print such a scaffold. These features were used to evaluate the quality of the printed scaffolds for all DOE test samples.

The diameter and the height of the fabricated samples were measured using a Mitutoyo digital caliper at the smallest measurement of 0.01mm. In this study, we considered the degree of anisotropy as another factor for evaluating the DA. Here, a DA of 0 corresponded to fully isotropic samples and tended toward 1 as the samples became increasingly anisotropic. The DA values were reported by CT-analyzer software. The scanner used in the experiments was a high-resolution, compact desktop unit (SkyScan In Vivo X-ray 1076, Belgium). As the CAD design was symmetrical, a printed scaffold with a lower DA would possess a greater DA than a sample with a larger DA.

Uniaxial compressive testing was conducted using an Intron 5848 Micro Tester (USA) instrument with a 10 KN load-cell and crosshead-loading rate 0.5mm/min−1. Nine specimens of each DOE test run were tested.

The porosity was reported by SkyScan micro-CT's 3D analysis software (SkyScan In Vivo X-ray 1076, Belgium). The resolution of the scanner was set to 18μm, and aluminum (0.5mm) was set as a filter. The region of interest was considered at 6×6. Almost 700 scan slices were taken for each specimen.

This section discusses the structure of the proposed model. As previously mentioned, the AANN model was used as the structure for predicting the model, and the experimental data were used for training it.

The standard topology of AANN is shown in Fig. 3
                        . It is composed of several single feed-forward neural networks, the outputs of which are added together with some weighting coefficients.

An important factor in designing the AANN is to find the fittest weighting coefficients in a manner that AANN has the best performance (minimum of prediction error) and the lowest complexity (minimum size) simultaneously. The generalized performance of a neural network is expressed as the following formula:
                           
                              (1)
                              
                                 
                                    Error
                                    =
                                    M
                                    S
                                    E
                                    t
                                    r
                                    a
                                    i
                                    n
                                    +
                                    M
                                    S
                                    E
                                    t
                                    e
                                    s
                                    t
                                    ,
                                 
                              
                           
                        where MSEtrain and MSEtest are the mean squared errors in the training and testing steps. Zero is the ideal performance. However, in many practical applications, obtaining exactly zero error is impossible, and the authors expect an acceptable generalization from a network with error closer to zero. The mean squared error is defined as
                           
                              (2)
                              
                                 
                                    M
                                    S
                                    E
                                    =
                                    
                                       
                                          
                                             1
                                             
                                                N
                                                t
                                                ⋅
                                                N
                                                o
                                             
                                          
                                       
                                    
                                    ⋅
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          0
                                       
                                       
                                          N
                                          o
                                       
                                    
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          0
                                       
                                       
                                          N
                                          t
                                       
                                    
                                    
                                       
                                          (
                                          
                                             d
                                             
                                                i
                                                j
                                             
                                          
                                          −
                                          
                                             y
                                             
                                                i
                                                j
                                             
                                          
                                          )
                                       
                                       2
                                    
                                    ,
                                 
                              
                           
                        
                     

where No is the number of AANN outputs, and Nt is the number of training or testing data. Parameters Y and d represent the actual output of AANN and the desired AANN output (target), respectively. Each individual neural network estimates the compressive strength and open porosity independently, and the actual outputs of AANN are derived from a linear superposition of these independent outputs. These independent outputs are accumulated mathematically to form the actual outputs as
                           
                              (3)
                              
                                 
                                    
                                       y
                                       j
                                    
                                    =
                                    
                                       ∑
                                       
                                          k
                                          =
                                          0
                                       
                                       
                                          N
                                          N
                                          n
                                          o
                                       
                                    
                                    
                                       
                                          w
                                          
                                             j
                                             k
                                          
                                       
                                       ⋅
                                       
                                          y
                                          
                                             j
                                             k
                                          
                                       
                                       ,
                                    
                                 
                              
                           
                        where y
                        
                           j
                         is the jth the output of the stacked neural network, NNno is the number of independent networks, and w
                        
                           jk
                         and y
                        
                           jk
                         are the jth weight and output of the kth independent neural network, respectively.

Computational complexity is one of the objective values in designing an AANN. Reducing the computational complexity is equivalent to designing a network with the lowest number of neurons in the hidden layers. Therefore, the following criterion is defined as a metric of complexity:
                           
                              (4)
                              
                                 
                                    Complexity
                                    =
                                    
                                       ∑
                                       
                                          k
                                          =
                                          0
                                       
                                       
                                          N
                                          N
                                          n
                                          o
                                       
                                    
                                    
                                       H
                                       
                                          n
                                          k
                                       
                                       ,
                                    
                                 
                              
                           
                        where Hn
                        
                           k
                         is the number of neurons in the cat independent neural network.

To obtain a model with the lowest prediction error and computational complexity, the authors define the following total objective function:
                           
                              (5)
                              
                                 
                                    m
                                    i
                                    n
                                     
                                    
                                       F
                                       1
                                    
                                    :
                                    f
                                    (
                                    N
                                    N
                                    n
                                    o
                                    ,
                                    
                                       w
                                       
                                          j
                                          k
                                       
                                    
                                    ,
                                    H
                                    n
                                    )
                                    =
                                    γ
                                    (
                                    M
                                    S
                                    E
                                    t
                                    r
                                    a
                                    i
                                    n
                                    +
                                    M
                                    S
                                    E
                                    t
                                    e
                                    s
                                    t
                                    )
                                    +
                                    (
                                    1
                                    −
                                    γ
                                    )
                                    
                                       ∑
                                       
                                          k
                                          =
                                          0
                                       
                                       
                                          N
                                          N
                                          n
                                          o
                                       
                                    
                                    
                                       H
                                       
                                          n
                                          k
                                       
                                       ,
                                    
                                 
                              
                           
                        where γ is the scaling factor between [0,1] which represents the degree of importance of each objective function. The lowest value of γ means that complexity is more important than the prediction error. In this paper, since a limited amount of actual data is available, so complexity is as important as efficiency. It is noteworthy, as the complexity increases there are more possibilities for over fitting. Thus constant value for γ
                        =0.5 is considered.

The correlation between the actual and the desired output data is another important factor in designing an AANN. The training procedure should be done in such a way that the highest correlation value occurs between the actual and the desired data. For this purpose, a minimum acceptable value of correlation is imposed on the training phase as a constraint. The mathematical expression of the correlation is as follows:
                           
                              (6)
                              
                                 
                                    r
                                    =
                                    
                                       
                                          
                                             1
                                             
                                                N
                                                o
                                             
                                          
                                       
                                    
                                    ⋅
                                    
                                       ∑
                                       
                                          j
                                          =
                                          0
                                       
                                       
                                          N
                                          o
                                       
                                    
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   0
                                                
                                                
                                                   N
                                                   t
                                                
                                             
                                             
                                                (
                                                
                                                   y
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                −
                                                
                                                   
                                                      y
                                                      ¯
                                                   
                                                   j
                                                
                                                )
                                                (
                                                
                                                   d
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                −
                                                
                                                   đ
                                                   j
                                                
                                                )
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         0
                                                      
                                                      
                                                         N
                                                         t
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               y
                                                               
                                                                  i
                                                                  j
                                                               
                                                            
                                                            −
                                                            
                                                               
                                                                  y
                                                                  ¯
                                                               
                                                               j
                                                            
                                                            )
                                                         
                                                         2
                                                      
                                                   
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         0
                                                      
                                                      
                                                         N
                                                         t
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            (
                                                            
                                                               d
                                                               
                                                                  i
                                                                  j
                                                               
                                                            
                                                            −
                                                            
                                                               đ
                                                               j
                                                            
                                                            )
                                                         
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 
                                    0.9
                                    <
                                    r
                                    <
                                    1
                                 
                              
                           
                        where r is the correlation, 
                           
                              
                                 
                                    y
                                    ¯
                                 
                                 j
                              
                           
                         is the average of the actual values obtained in the processing element j of the neural network output, and đ
                           j
                         is the average of the desired values for the processing element j of the neural network output.

Before entering the training phase, these experimental data were normalized according to the following equation:
                           
                              (8)
                              
                                 
                                    
                                       u
                                       i
                                    
                                    =
                                    
                                       2
                                       
                                          u
                                          
                                             p
                                             i
                                          
                                          −
                                          l
                                          
                                             b
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             u
                                             i
                                          
                                          −
                                          
                                             1
                                             2
                                          
                                          (
                                          l
                                          
                                             b
                                             i
                                          
                                          +
                                          u
                                          
                                             b
                                             i
                                          
                                          )
                                       
                                    
                                    ,
                                     
                                    i
                                    =
                                    1,2,3
                                 
                              
                           
                        where up
                        
                           i
                        , u
                        
                           i
                        , lb and ub
                        
                           i
                         are actual input, normalized input, lower bound, and upper bound of the ith input, respectively. It is worth noting that the upper bound and lower bound values are the maximum and minimum values of actual input data. Using the above equation, the acceptable range of the inputs is between [−1,1]. The same preprocessing procedure is conducted for the outputs.

The PSO algorithm is a population-based soft computing technique that has attracted the attention of many researchers in solving applied engineering optimization problems. This algorithm, which is based on the behavior of a swarm of ants, a flock of birds, or a school of fish, mimics their social behavior in finding food or their actions in encountering danger. This social behavior can be used in developing modern optimization algorithms. Kennedy and Eberhart [57] originally proposed the PSO algorithm in 1995.

In this algorithm, each solution of the optimization algorithm is considered a particle, and a swarm of particles located randomly in the feasible searching domain is initially selected. These particles (i.e., candidate solutions) are updated using an evolutionary mechanism to obtain a better solution. The proposed evolutionary mechanisms are similar to what happens in nature. In nature, each particle tends to act similar to its best experience in life and moves to the best successful experience of its neighbors. These two behaviors, which are called exploration and exploitation, respectively, can be computationally implemented as follows.

In the PSO algorithm, for an optimization problem min f(x), each particle is presented by its position vector as
                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      
                                                         ij
                                                      
                                                   
                                                
                                                (
                                                t
                                                )
                                                =
                                                [
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      
                                                         ij
                                                      
                                                   
                                                
                                                ]
                                                =
                                                [
                                                
                                                   x
                                                   
                                                      i
                                                      1
                                                   
                                                
                                                ,
                                                
                                                   x
                                                   
                                                      i
                                                      2
                                                   
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   x
                                                   
                                                      i
                                                      (
                                                      n
                                                      −
                                                      1
                                                      )
                                                   
                                                
                                                ,
                                                
                                                   x
                                                   
                                                      i
                                                      n
                                                   
                                                
                                                ]
                                                ,
                                                 
                                                i
                                                =
                                                1,2
                                                ,
                                                …
                                                ,
                                                N
                                                ,
                                             
                                          
                                          
                                             
                                                j
                                                =
                                                1,2
                                                ,
                                                …
                                                ,
                                                n
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where t is the generation time, x
                        
                           ij
                         is the jth variable of ith particles, N is the swarm size, and n is the searching space dimension. 
                           x
                        
                        
                           
                              i
                           
                        (t) is the solution of the optimization problem, and the swarm is a set of swarm={
                           x
                        
                        
                           1
                        , 
                           x
                        
                        
                           2
                        , …, 
                           x
                        
                        
                           
                              N
                           
                        }.

To formulate the evolutionary mechanism, a velocity vector is assigned to each particle as follows:
                           
                              (10)
                              
                                 
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    =
                                    [
                                    
                                       v
                                       
                                          1
                                          i
                                       
                                    
                                    ,
                                    
                                       v
                                       
                                          2
                                          i
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       v
                                       
                                          (
                                          n
                                          −
                                          1
                                          )
                                          i
                                       
                                    
                                    ,
                                    
                                       v
                                       
                                          n
                                          i
                                       
                                    
                                    ]
                                    ,
                                     
                                    i
                                    =
                                    1,2
                                    ,
                                    …
                                    ,
                                    N
                                    ,
                                 
                              
                           
                        where 
                           v
                        
                        
                           
                              i
                           
                        (t) is the velocity of the ith particle. This velocity specifies the updating direction and updating rates of each particle position. The particles are assumed to move iteratively within the search space.

The best experience of each particle up to time t is stored in a variable called best position and is expressed as 
                           p
                        
                        
                           
                              i
                           
                        (
                           i
                        )=[p
                        1i
                        , p
                        2i
                        , …, p
                        (n−1)i
                        , p
                        
                           ni
                        ]. The set {
                           p
                        
                        
                           1
                        , 
                           p
                        
                        
                           2
                        , …, 
                           p
                        
                        
                           
                              N
                           
                        } is a memory set that shows the best positions of the swarm explored by each particle. Evidently, the best position with the lowest fitness function value of this set becomes the global best solution of the minimization problem. This global minimal position is represented by 
                           P
                        
                        
                           
                              g
                           
                        (t) and is computed as
                           
                              (11)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      p
                                                   
                                                   
                                                      g
                                                   
                                                
                                                (
                                                t
                                                )
                                                =
                                                arg
                                                min
                                                (
                                                f
                                                (
                                                
                                                   
                                                      p
                                                   
                                                   
                                                      i
                                                   
                                                
                                                )
                                                )
                                                .
                                             
                                          
                                       
                                       
                                          
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        
                     

In a classic variant of the PSO, the updating rule is mathematically expressed as follows:
                           
                              (12)
                              
                                 
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    w
                                    ⋅
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       c
                                       1
                                    
                                    ⋅
                                    
                                       R
                                       1
                                    
                                    ⋅
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       
                                          x
                                       
                                       i
                                    
                                    (
                                    t
                                    )
                                    )
                                    +
                                    
                                       
                                          c
                                       
                                       2
                                    
                                    ⋅
                                    
                                       R
                                       2
                                    
                                    ⋅
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          g
                                       
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    )
                                    ,
                                 
                              
                           
                        where w is the weighting coefficient, c
                        1 and c
                        2 are the cognitive and the social acceleration coefficients, respectively, and R
                        1 and R
                        2 are the two random numbers uniformly distributed within [0,1].

According to the relation (12), the weighting coefficient w gives the inertia behavior to the motion of the particle. Higher values of w result in more exploration behavior, whereas a lower value increases the exploitation performance. This parameter should be controlled during the generation time. After updating the velocity of the particle, each particle adjusts its current position using the following relation:
                           
                              (13)
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    ,
                                     
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    N
                                    .
                                 
                              
                           
                        
                     

In this paper, PSO with constant inertia weight has been used and the AANN structural parameters considered as particle parameters in swarm. In fact, each particle create AANN network and return network error (Eq. (5)) as PSO min function.
                           
                              (14)
                              
                                 
                                    
                                       
                                          
                                             
                                                m
                                                i
                                                n
                                                 
                                                
                                                   F
                                                   1
                                                
                                                :
                                                f
                                                (
                                                N
                                                N
                                                n
                                                o
                                                ,
                                                
                                                   w
                                                   
                                                      j
                                                      k
                                                   
                                                
                                                ,
                                                H
                                                n
                                                )
                                                =
                                                γ
                                                (
                                                M
                                                S
                                                E
                                                t
                                                r
                                                a
                                                i
                                                n
                                                +
                                                M
                                                S
                                                E
                                                t
                                                e
                                                s
                                                t
                                                )
                                                +
                                                (
                                                1
                                                −
                                                γ
                                                )
                                                
                                                   ∑
                                                   
                                                      n
                                                      =
                                                      0
                                                   
                                                   
                                                      N
                                                      N
                                                      n
                                                      o
                                                   
                                                
                                                
                                                   H
                                                   
                                                      n
                                                      n
                                                   
                                                   γ
                                                   =
                                                   0.5
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                t
                                                )
                                                =
                                                
                                                   
                                                      [
                                                      N
                                                      N
                                                      n
                                                      o
                                                      ,
                                                      
                                                         
                                                            
                                                               W
                                                               m
                                                            
                                                         
                                                         _
                                                      
                                                      ,
                                                      
                                                         
                                                            H
                                                            
                                                               n
                                                               n
                                                            
                                                         
                                                         _
                                                      
                                                      ]
                                                   
                                                   i
                                                
                                                ,
                                                 
                                                i
                                                =
                                                1,2
                                                ,
                                                …
                                                ,
                                                N
                                                ,
                                                   
                                                m
                                                =
                                                1,2
                                                ,
                                                …
                                                ,
                                                2
                                                ×
                                                N
                                                N
                                                n
                                                o
                                                ,
                                                   
                                                n
                                                =
                                                1,2
                                                ,
                                                …
                                                ,
                                                N
                                                N
                                                n
                                                o
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where NNno is the number of single neural networks, 
                           
                              
                                 
                                    
                                       W
                                       m
                                    
                                 
                                 _
                              
                           
                         is the number of weighting coefficients and Hn
                        
                           n
                         is the number of hidden layers for each single neural network. Topology of AANN, coefficients and the hidden layers are depicted at Fig. 3. More details are given in next Section.

@&#RESULTS AND DISCUSSION@&#

In this section, a predictive model for 3DP process is extracted. The model predicts the mechanical strength, and the open porosity of a part fabricated using this process. Mechanical strength and open porosity are the two fundamental properties in tissue engineering applications. The influencing parameters are build orientation, delay time, and layer thickness. Moreover, sufficient green strength is necessary for the depowdering step, and more compressive strength decreases the need for further post-processing.

Therefore, the input parameters of the AANN model include orientation, thickness, and delay time, and its output parameters are mechanical strength and open porosity. The required identification data were prepared by conducting experimental tests at different values and permutations of input parameters. The orientation input could be any axis along the X, Y, and Z directions. For the layer thickness, four levels of 89, 102, 114, and 127μm were used, and the chosen delay times were 50, 100, 300, and 500ms between the spreading of each layer. The total number of experimental tests was 48. All the samples after printing and drying (1.5h) were depowdered and then characterized for compressive strength and porosity. Table 1
                      shows the experimental data of the printed porous structures used for training the AANN model.


                     Fig. 4
                      shows the effect of each parameter on the compressive strength. The compressive strength of the printed porous specimens, which were printed in the X direction, was significantly higher than that of the specimens printed in other directions. Insufficient compressive strengths of the Z-direction fabrication led to the fracture of some samples during depowdering. Furthermore, the samples printed with a 300ms delay time between spreading each layer had more compressive strength compared with other samples. As shown in Fig. 4(a), the effect of each input on the process outputs is complicated and nonlinear, and no meaningful trend exists between them. The X-printed samples with 89μm and 114μm and a delay time of 300ms between spreading of each layer had more strength than the other printed samples. The direction of the print and the direction of the applied compression load significantly affected the strength of the specimens. The loads applied parallel to the layers of the printed structure were fabricated along the X and Y axes, and those applied perpendicular to the layers were fabricated in the Z-printed samples. In addition, the cross section in which the Z samples were mathematically sliced and then printed layer-over-layer was circular, but that for the X and Y specimens was cylindrical. The samples printed in the Z direction were fabricated by more layers to be completed, but the samples printed in the X and Y directions needed the overlay of the fewest layers because of their cross section. Thus, more layer displacement occurred in the Z-printed samples that resulted in more distortion and fractures in struts.


                     Fig. 5
                      shows the effect of each setting parameter on the porosity of printed specimens. The specimens printed in the X direction with 114μm layer thickness and 100ms delay between spreading each layer, as well as the specimens printed in the Z direction with 102μm layer thickness and 500ms delay, had the most open porosity. In total, the specimens printed in the Y and Z directions were more porous than the other prototypes. However, although porous scaffolds are desired, the compressive strength should not be compromised.


                     Fig. 5(a) shows the effect of each input on the process outputs. The effect is complicated and nonlinear, and no meaningful trend exists between them. Open porosity refers to both macro and micro pores. As the CAD model porosity is 45.04%, the increase in open porosity is related to the micro pores of the powder particles.

The proposed topology of the AANN model includes 2 NNno +1 independent variables. In this relation, NNno is the number of single neural networks, and 2 NNno is the number of weighting coefficients. Aside from these unknown parameters, each single neural network is also unknown. The number of neurons in each hidden layer of a single neural network and its weighting and biasing coefficients are undetermined. These variables should be obtained in such a manner that the prediction error should be as small as possible. The training process is conducted at two levels. At the lower level, each single neural network is trained according to the well-known back propagation algorithm called quasi Newton learning technique. In this study, 300 epochs were considered as the stopping criterion for the quasi Newton training method. At the higher level, which is called the supervising level, the PSO algorithm is used as a supervising optimization algorithm to find the optimal topology.

At the supervising level, the number of single networks is limited to 2, 3, and 4 and Input vector has 6, 9, and 12 independent variables respectively. The variable indicates the weighting coefficients and number of hidden layer of each single network. To find the best number of single neural networks in the structure of AANN, this process has been implemented for a number of AANNs with a different number of single neural networks. With this method, the quasi Newton learning technique is used to train each of the single networks and 300 epochs are considered as a criterion to stop the procedure. Our experience shows that the combination of PSO and quasi-Newton method is a useful tool to find the optimal topology of AANN. Independent variables of solution vector are listed in Table 2
                     . The optimum solution of the AANN is shown in Table 3
                     , which indicates a topology with three single neural networks. Consequently, six weighting coefficients (
                        
                           W
                           _
                        
                     ) become the best AANN model for the 3DP process. Moreover, the number of neurons in the hidden layers are 5, 4, and 8 
                        
                           
                              
                                 
                                    
                                       H
                                       n
                                    
                                    _
                                 
                              
                           
                        
                     . After the optimum AANN structure is found, PSO applied once again under this structure to find optimum weighting coefficients, this process leads to a more accurate solution. This solution is shown in Table 4
                     . To make sure that the selected parameters are stable, the simulation with the selected parameters were carried out for 30 independent runs and it was observed that the variation of the final solutions over independent runs was very trivial, which anticipates the robustness of the searching mechanism.


                     Fig. 6
                      shows the training and testing accuracy of the obtained AANN in predicting mechanical compression strength. In these figures, aside from the compression strength (in normalized value), the regression analysis, mean square predicting error, and normal distribution of predicting error are also presented for both training and testing.

Clearly, the prediction error is within the acceptable range, and the resulting AANN network is reliable in predicting compression strength.

Similar to compression strength, the same results are shown in Fig. 7
                      for the open porosity parameter. Unlike compressive strength, open porosity in some regions of the testing does not match with the training data, and the higher prediction errors can be seen. These errors indicate that open porosity is a more sensitive parameter than mechanical strength, and that many uncertainties may influence it. For example, if some internal channels are blocked or filled by unbound powder during the imperfect depowdering step, porosity will decrease. These uncontrolled effects will produce some distributed data. Therefore, obtaining highly correlated data is not possible.


                     Fig. 8
                      shows the variations of open porosity with respect to the variations of delay time and layer thickness for different depositing directions. The behavior of open porosity is complicated and nonlinear. The related surfaces show that the orientations are not effective in open porosity, whereas delay time and thickness are significant.

Regarding the mechanical compression strength, the same results are obtained for the variation of mechanical strength as a result of the process parameter variations. Fig. 9
                      shows the mechanical strength behavior when time delay and thickness vary while the orientation is kept constant. By contrast, the open porosity and the nonlinearity of mechanical strength are low, whereas the deposition orientation is effective for the obtained mechanical strength.

In this step, the AANN model was used for the optimal designing of the 3DP process parameters to fabricate the desired scaffold. As both mechanical strength and open porosity are fitness functions, a multi-objective optimization algorithm is used. In the multi-objective optimization context, the Pareto front is a comprehensive solution. By knowing the Pareto front, a designer can select the desirable solution based on the imposed constraints. In this research, the Pareto front for the 3DP process regarding scaffold fabrication is shown in Fig. 10
                     . According to the Pareto front, open porosity conflicts with the mechanical strength in such a way that increasing the open porosity will result in a decrease in mechanical strength, and vice versa. This figure is summarized in Table 5
                     , which shows that orientation and layer thickness are not effective, whereas delay time is the most effective parameter.

To obtain a scaffold with the highest mechanical strength, the delay time should be selected at around 200ms, but it should be at around 135ms to achieve the highest porosity.

@&#CONCLUSION@&#

In this study, the AANN was used to investigate the simultaneous effects of layer thickness, delay time between spreading each layer, and print orientation on the compressive strength and porosity of porous structure prototypes. Two optimization methods were applied to obtain the optimal 3D parameter settings for printing tiny porous structures as a real BTE problem. First, the PSO algorithm was implemented to obtain the optimum topology of the AANN. Then, the Pareto front optimization was used to determine the optimal setting parameters for the fabrication of the porous structure with high compressive strength and porosity. The relationship between layer thickness, delay time between spreading each layer, and print orientation of powder-based 3D printed scaffolds and their compressive strength as an index of mechanical performance and porosity were also discussed. The ANN-based model is a powerful tool to predict the compressive strength and porosity of 3D-printed scaffolds over a wide range of layer thicknesses, delay times of spreading each layer, and print orientations, using a limited set of experiments designed using the full factorial design of experiments. The results predict the best mechanical strength and porosity based on the setting parameters. The third contribution of the current study is that the trained model has been used to precisely analyze the properties of the scaffolding procedure. The presented results and discussion can give informative information to practitioners who want to design a porous structure, and need to know the impact of influential design parameters, e.g. layer thickness, delay time between spreading of each powder layer and printing orientation, on the porosity and compression strength of the porous structures.

@&#ACKNOWLEDGMENT@&#

This study was supported by the High Impact Research Grant from the Ministry of Higher Education of Malaysia (UM.C/HIR/MOHE/ENG/10 D000010-16001).

@&#REFERENCES@&#


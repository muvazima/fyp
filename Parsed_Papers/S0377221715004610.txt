@&#MAIN-TITLE@&#Instance-based credit risk assessment for investment decisions in P2P lending

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We use an instance-based model to assess a loan’s credit risk.


                        
                        
                           
                           We formulate P2P lending into portfolio optimization with boundary constraints.


                        
                        
                           
                           We describe the similarity of two loans using default likelihood distance.


                        
                        
                           
                           We use kernel weighting to smooth risks of loans.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Data mining

P2P lending

Credit risk assessment

Instance-based method

Investment decisions

@&#ABSTRACT@&#


               
               
                  Recent years have witnessed increased attention on peer-to-peer (P2P) lending, which provides an alternative way of financing without the involvement of traditional financial institutions. A key challenge for personal investors in P2P lending marketplaces is the effective allocation of their money across different loans by accurately assessing the credit risk of each loan. Traditional rating-based assessment models cannot meet the needs of individual investors in P2P lending, since they do not provide an explicit mechanism for asset allocation. In this study, we propose a data-driven investment decision-making framework for this emerging market. We designed an instance-based credit risk assessment model, which has the ability of evaluating the return and risk of each individual loan. Moreover, we formulated the investment decision in P2P lending as a portfolio optimization problem with boundary constraints. To validate the proposed model, we performed extensive experiments on real-world datasets from two notable P2P lending marketplaces. Experimental results revealed that the proposed model can effectively improve investment performances compared with existing methods in P2P lending.
               
            

@&#INTRODUCTION@&#

Peer-to-peer (P2P) lending, also known as person-to-person lending, allows individuals to directly lend to and borrow from each other on an Internet-based platform, without the involvement of traditional financial intermediaries. In this marketplace, borrowers submit applications for loans, called listings, by specifying loan details, such as loan amount and description. Then, prospective lenders are allowed to fund these listings partially by specifying the loan amounts they will provide. If the total dollar amount requested by a listing is fulfilled within a pre-specified period of time, the listing becomes a loan. Due to the elimination of a traditional financial intermediary, and a more dynamic environment that taps into the collective intelligence of the crowd, P2P lending has the potential to reduce financing costs and increase efficiency of the financial market.

To help personal investors manage risk, state-of-the-art P2P lending platforms, such as Prosper and Lending Club, provide risk ratings for each loan. Such ratings take into account many variables about the loan and the applicant, such as FICO scores, the amounts and terms of the loans, borrowers’ assets, debts, types of employment, and so on. This process of credit rating is similar to those traditional evaluation techniques commercial banks employ to evaluate the risk levels of borrowers. As a result, loans are categorized into a small number of risk groups. For example, Prosper uses a seven-level risk rating (i.e., AA, A, B, C, D, E, NR). This “rating-based” model provides basic evaluation of loans’ credit risk, and the loans within each rating group are assumed to bear the same level of risk. In order to diversify their portfolios, investors are allowed to pick loans from different risk groups, according to their risk-return preferences.

Rating-based credit risk assessment models are practical and has been widely utilized by financial institutions for issuing loans. However, this model may be too coarse to meet the needs of personal investors in P2P lending. Since traditional financial institutions possess large amounts of cash, they are able to fund millions of loans, which facilitates myriad opportunities for diversification. For P2P lending, each personal investor has much less money for investment. However, because they are allowed to partially fund each loan, effective diversification has been made possible. Therefore, investors in the P2P lending marketplace not only need to decide which loans to fund, but also how much money to allocate to each of them, which minimizes risk for a given expected return. While this feature presents as a typical portfolio optimization problem, it is very challenging to accurately assess the credit risk of each individual loan for P2P lending, which will serve as necessary input for portfolio optimization. Moreover, real-world P2P lending marketplaces typically impose minimum investment amount constraints. For example, the minimum required investment on each loan is $25 at Prosper. Such constraints are substantial for individual investors in P2P lending, due to their limited amount of total funds. Thus, a new decision making tool is required for lucrative P2P lending.

In this study, we propose a more accurate credit risk model for P2P lending, which allows personal investors to optimize investment decisions. Without enough historical data of closed loans for each individual borrower, it is impossible to predict the performance of new loans based on a borrower’s past ones. As a result, we identified past loans with similar attributes, and aggregated performance outcomes to predict the performance of a new loan. This is called an “instance-based” approach.

Specifically, in the proposed instance-based model, we first defined the similarity of loans as the difference between their probabilities to default, which was derived from a logistic regression of borrower’s credit attributes. We then predicted the return of each loan as a weighted average of similar loans, and the risk as the weighted variance, where the optimal weights were learned within the mathematical framework of kernel regression. Furthermore, based on this instance-based credit risk model, we formulated the investment decisions in P2P lending as a portfolio optimization problem with boundary constraints. To validate the proposed model, we performed extensive experiments on real-world data from two state-of-the-art P2P lending marketplaces. Experimental results demonstrated that the proposed model effectively outperforms existing rating-based models.

The remainder of this paper is organized as follows. A literature review is performed in Section 2, and a description of the data is provided in Section 3. Section 4 is devoted to describing the instance-based model for credit risk assessment. Combined with a formal formulation of portfolio optimization in P2P lending, Section 5 describes the investment decision model. To better explain the model, an end-to-end example of the instance-based credit risk assessment and investment decision process is provided in the appendix. In Section 6, we report empirical results on effectiveness of the proposed model. Finally, Section 7 concludes this work.

@&#LITERATURE REVIEW@&#

P2P lending has been introduced as a new e-commerce phenomenon in the financial field for its potential to provide more economical efficiencies, as supported by an Internet-based information system (Berger & Gleisner, 2009; Wang, Greiner, & Aronson, 2009). P2P lending is also known as online social lending (Hulme & Wright, 2006), microlending (Conlin, 1999) or crowdfunding (Belleflamme, Lambert, & Schwienbacher, 2014; Mollick, 2014), each of which emphasizes a different set of unique characteristics of P2P lending. Namely, the online social interactions among participants, the small amounts of transactions, and the large number of investors who may not be experts in loan investing.

Participants in the P2P lending marketplace can be roughly divided into two groups: borrowers and lenders. Like traditional credit marketplaces, risk assessment and decision making can be viewed from their different perspectives (Wu & Hsu, 2012). From the borrower’s perspective, a common goal is securing loan funding. Among all the information provided by the borrower, researchers aim to find determinants of the success of a loan. For instance, Larrimore, Jiang, Larrimore, Markowitz, and Gorski (2011) analyzed the impact of language used in the listing, which can help borrowers strengthen persuasiveness for getting funds. Puro, Teich, Wallenius, and Wallenius (2010) proposed a borrower decision aid system to help borrowers quantify their strategic options, such as starting interest rate and the amount of loan to request, in order to have their listings successfully funded. In spite of a focus on borrower’s decisions, their models may also be adapted for lenders, aiming for predicting loans’ pay-back statuses. Specifically, they formulate a query-based approach, which looks for similar listings in the past to make an overall prediction for a new listing. They report that this technique is equivalent to the logistic regression model in most cases, but may become less stable when only a small number of similar loans can be found. Instead of identifying similar loans in the past, our framework of instance-based model uses all loans in the past, and optimize their weights through kernel regression. Other works in borrower decision support include Wu and Xu (2011), which proposes an intelligent agent system that make recommendations to the borrowers. With a focus on system design rather than analytical modeling, their work is not being compared with ours.

When considering the lenders’ perspective, researchers investigate lender’s investment decision making and bidding behavior. For example, Sonenshein, Herzenstein, and Dholakia (2010) examined the roles of social accounts in influencing lenders’ decisions about lending money to borrowers. Klafft (2008) examined whether lenders can profit from this new market as claimed. Based on data from Prosper.com, they found that it is possible for lenders to achieve satisfactory returns if they employ a sound strategy. Moreover, Krumme and Herrero-Lopez (2009) found that many transactions are based upon sub-optimal decisions. Puro, Teich, Wallenius, and Wallenius (2011) provided bidding strategies in the context of small loan auctions. Their study showed that bidding behavior is not homogeneous among bidders, but bidders use many different bidding strategies. It has been found that investors are more likely to bid on loans with more existing bids (Herzenstein, Dholakia, & Andrews, 2011). This phenomenon is known as herding, and is commonly observed in online social loan auctions. Existing studies provide valuable insights into how lenders screen and select loans, and succeed in bidding. However, effective decision support is lacking to guide personal investors’ selection of investments, and determination of optimal amounts to put forward in each of them.

Since making decisions on whether or not to fund certain loans is a central task for investors in the P2P lending marketplace, traditional loan evaluation techniques also relate to P2P lending. In order to distinguish good loan applications (i.e., those expected to be successfully paid back) from bad ones (i.e., those predicted to default), many different data mining techniques have been used in the literature. A number of examples include logistic regression (Thomas, 2009; Wiginton, 1980), linear discriminate analysis (Rosenberg & Gleit, 1994), k-nearest neighbors (Chatterjee & Barcun, 1970), classification trees (Feldman & Gross, 2005), Markov chains (Frydman, Kallberg, & Kao, 1985; So & Thomas, 2011), survival analysis (Andreeva, Ansell, & Crook, 2007; Stepanova & Thomas, 2002), linear and nonlinear programming (Bugera, Konno, & Uryasev, 2002; Mangasarian, 1965), neural networks (Malhotra & Malhotra, 2002; Yang, Li, Ji, & Xu, 2001), support vector machines (Huang, Chen, Hsu, Chen, & Wu, 2004; Kim & Sohn, 2010), genetic methods (Desai, Conway, Crook, & Overstreet, 1997; Huang, Tzeng, & Ong, 2006), and so on. These studies examine the classification of each loan, but do not scrutinize loan investment portfolio as a whole.

In recent years, kernel methods have been broadly applied in many credit scoring and optimization problems (Yang, 2007; Zhang, Gao, & Shi, 2014). In this study, we exploit the mathematical framework of the kernel regression (Nadaraya, 1965) and extract the regression coefficients as the optimal weights for credit risk assessment. As a flexible statistical technique to study nonlinear relationships, kernel regression is increasingly utilized in many financial and economical studies, such as nonparametric VaR measurements (Aıt-Sahalia & Lo, 2000), nonlinear relationships between international real interest rates (Mancuso, Goodwin, & Grennes, 2003), and time-varying diffusion processes for forecasting financial crashes (Fernandes, 2006). Our study illuminates suitability of kernel regression for assisting individual investors in P2P lending to make decisions.

Advances in the development of P2P lending markets have provided large amounts of real-world P2P lending transaction data. Our empirical study is based on public datasets from two state-of-the-art P2P lending marketplaces.

The first dataset is from Lending Club, which consists of 2016 loans. The second dataset is from Prosper, which consists of 4128 loans. In both datasets, a predictive model is used to transform loan attributes into the probability of default. These attributes include the borrower’s credit score from FICO, the amount of the loan, the borrower’s number of inquires in the past six months, the borrower’s debt-to-income ratio, the borrower’s number of current delinquencies, and the borrower’s home ownership status.

Many predictive models are available for quantifying the likelihood of loans to default. Choice and implementation of such a predictive model is beyond the scope of our study, since we assume the probability of default of each loan is known. Among the many models that exist to predict the probabilities of loan default, logistic regression has been the most widely used in the literature. For example, Puro et al. (2010) uses logistic regression to determine the probability of successful loan funding in the P2P lending marketplace. As a data preprocessing step, we use logistic regression to predict each loan’s probability of default in both datasets.

In this section, we first describe an instance-based credit risk assessment model to quantitatively assess the return and risk of loans in P2P lending. Then, we transform loans’ default likelihood distances into optimized weights, exploiting the mathematical framework of kernel regression.

It is common practice to predict the future using data from the past. Unlike working with stocks, there are very few historical observations for each individual borrower to analyze to make predictions on his or her new loan request. Alternatively, a feasible approach is to use similar loans, such as borrowers with similar profiles, to predict the credibility of a new loan request. Directly using other instances to make predictions about a particular instance is called an “instance-based” method.

In particular, for loan portfolio optimization, we would like to predict the return and risk of each loan. For a given loan i (i.e., the “focal” instance), based on n past loans (i.e., the “voting” members), each with an observed return rate Rj
                         (
                           
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                           
                        ), we can directly predict loan i’s return, μi
                        , using a weighted average of the performance of past loans

                           
                              (1)
                              
                                 
                                    
                                       μ
                                       i
                                    
                                    =
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       R
                                       j
                                    
                                    .
                                 
                              
                           
                        Here, wij
                         represents the weight of loan j for predicting the return of loan i. This is similar to a “voting” scheme, where each vote is counted with a different weight. A critical step for instance-based approaches is to determine the weights of the “voting” instances. Our solution for determining optimized weights will be presented in Section 4.2.

Using a weighted average of similar loans’ performance to predict the return of a new loan is straightforward. However, for the prediction of risk, we cannot take such a weighted average directly, since the risk values of past loans are not quantified. As a result, we quantify the risk of a new loan i, 
                           
                              
                                 σ
                                 i
                                 2
                              
                              ,
                           
                         as the weighted variance among the voting members

                           
                              (2)
                              
                                 
                                    
                                       σ
                                       i
                                       2
                                    
                                    =
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    
                                       
                                          (
                                          
                                             R
                                             j
                                          
                                          −
                                          
                                             μ
                                             i
                                          
                                          )
                                       
                                       2
                                    
                                    ,
                                 
                              
                           
                        where μi
                         is the weighted average given in Eq. (1), and wij
                         carries the same meaning as in Eq. (1). Since a low-risk loan tends to bear a stable return, it is intuitive that the variation of the return rates among voting members can serve as an indicator of risk.

The weights for instance-based models are based on the proximity of the focal instance to its voting members. Intuitively, more similar items should have more weights, whereas less similar ones should have less weights. For loan assessment, the proximity between instances are primarily tied to their probability of default. In particular, we define the default likelihood distance between loans i and j, as

                           
                              (3)
                              
                                 
                                    
                                       d
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       |
                                       
                                          p
                                          i
                                       
                                       −
                                       
                                          p
                                          j
                                       
                                       |
                                    
                                    ,
                                 
                              
                           
                        where pi
                         and pj
                         are the probabilities of default for loans i and j, respectively. Intuitively, the more default likelihood distance, the less weight should be presented in wij
                        . Naïve weighting schemes, such as equal weights of nearest neighbors and reciprocal of distances, are easy to implement, but are not optimized for the most accurate predictions. To determine the function that maps the raw distances into optimal weights, we will employ kernel regression, to be presented in the next subsection.

Kernel regression (Nadaraya, 1965) is a statistical technique to find non-linear relation between a pair of random variables. In particular, suppose that each observation is evaluated on two dimensions, X and Y, where X is the predictive variable and Y is the response variable. With observations of n instances, 
                           
                              {
                              
                                 (
                                 
                                    x
                                    j
                                 
                                 ,
                                 
                                    y
                                    j
                                 
                                 )
                              
                              |
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                              }
                              ,
                           
                         the estimation of an outcome y given its predictive observation x, will be

                           
                              (4)
                              
                                 
                                    y
                                    =
                                    
                                       f
                                       ^
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   x
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                          
                                             y
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   x
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        Here, K( · ) is a kernel function that is usually specified as Gaussian. More specifically,

                           
                              (5)
                              
                                 
                                    K
                                    
                                       (
                                       u
                                       )
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             2
                                             π
                                          
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          
                                             1
                                             2
                                          
                                          
                                             u
                                             2
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        In this way, more weights are assigned to observations closer to x and less weights to those further apart. The parameter h (h > 0) is called the “bandwidth,” which determines the proportion of local versus remote information used in the summation.

In the context of our instance-based risk modeling, the probability of default pj
                         serves as the predictive variable, and the return rate Rj
                         is the response variable. Thus, we may rewrite Eq. (4) as

                           
                              (6)
                              
                                 
                                    
                                       μ
                                       i
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                          
                                             y
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      p
                                                      i
                                                   
                                                   −
                                                   
                                                      p
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                          
                                             R
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      p
                                                      i
                                                   
                                                   −
                                                   
                                                      p
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where μi, Rj, pi
                        , and pj
                         follow the same definitions as in Section 4.1. By comparing the predicted return rate in Eq. (1) with the kernel regression in Eq. (6), it is straightforward to extract the optimal weight as

                           
                              (7)
                              
                                 
                                    
                                       w
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      p
                                                      i
                                                   
                                                   −
                                                   
                                                      p
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      p
                                                      i
                                                   
                                                   −
                                                   
                                                      p
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    =
                                    
                                       
                                          K
                                          
                                             (
                                             
                                                
                                                   d
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   d
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where dij
                         is given in Eq. (3). In other words, the loan weight wij
                         is computed with the default likelihood distance dij
                        , and loans with smaller default likelihood distances will carry more weights.

To fit the kernel regression model, the bandwidth h needs to be optimized based on training data. To this end, Clark (1975) proposed the leave-one-out least-squares cross-validation method. Specifically, the bandwidth is chosen to minimize the following cross-validation error
                        
                           
                              (8)
                              
                                 
                                    C
                                    V
                                    
                                       (
                                       h
                                       )
                                    
                                    =
                                    
                                       1
                                       n
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          (
                                          
                                             
                                                f
                                                ^
                                             
                                             h
                                          
                                          
                                             (
                                             
                                                x
                                                
                                                   −
                                                   i
                                                
                                             
                                             )
                                          
                                          −
                                          
                                             y
                                             i
                                          
                                          )
                                       
                                       2
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              
                                 f
                                 ^
                              
                              
                                 (
                                 
                                    x
                                    
                                       −
                                       i
                                    
                                 
                                 )
                              
                           
                         is the leave-one-out estimation of yi
                        , using kernel regression. In other words,

                           
                              (9)
                              
                                 
                                    
                                       
                                          f
                                          ^
                                       
                                       h
                                    
                                    
                                       (
                                       
                                          x
                                          
                                             −
                                             i
                                          
                                       
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                                ,
                                                j
                                                ≠
                                                i
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                          
                                             y
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                                ,
                                                j
                                                ≠
                                                i
                                             
                                             n
                                          
                                          K
                                          
                                             (
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                
                                                h
                                             
                                             )
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        In our context of instance-based risk modeling, we may rewrite Eq. (8) as

                           
                              (10)
                              
                                 
                                    C
                                    V
                                    
                                       (
                                       h
                                       )
                                    
                                    =
                                    
                                       1
                                       n
                                    
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       
                                          [
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      k
                                                      =
                                                      1
                                                      ,
                                                      k
                                                      ≠
                                                      j
                                                   
                                                   n
                                                
                                                K
                                                
                                                   (
                                                   
                                                      
                                                         
                                                            p
                                                            j
                                                         
                                                         −
                                                         
                                                            p
                                                            k
                                                         
                                                      
                                                      h
                                                   
                                                   )
                                                
                                                
                                                   R
                                                   j
                                                
                                             
                                             
                                                
                                                   ∑
                                                   
                                                      k
                                                      =
                                                      1
                                                      ,
                                                      k
                                                      ≠
                                                      j
                                                   
                                                   n
                                                
                                                K
                                                
                                                   (
                                                   
                                                      
                                                         
                                                            p
                                                            j
                                                         
                                                         −
                                                         
                                                            p
                                                            k
                                                         
                                                      
                                                      h
                                                   
                                                   )
                                                
                                             
                                          
                                          −
                                          
                                             R
                                             j
                                          
                                          ]
                                       
                                       2
                                    
                                    .
                                 
                              
                           
                        
                     

To find the optimal bandwidth efficiency, we adopt a mixed bandwidth selection strategy recommended by Silverman (1986). This strategy searches for the optimal bandwidth between 0.25h
                        0 and 1.5 h
                        0, where h
                        0 is given by

                           
                              (11)
                              
                                 
                                    
                                       h
                                       0
                                    
                                    =
                                    
                                       
                                          (
                                          
                                             4
                                             
                                                3
                                                n
                                             
                                          
                                          )
                                       
                                       
                                          1
                                          /
                                          5
                                       
                                    
                                    σ
                                    .
                                 
                              
                           
                        Since we use Gaussian kernel, σ is the standard deviation of the predictive variable (i.e., the probability of default in our case).

In Fig. 1
                        , we provide an illustrative example of default likelihood distances and kernel weights. In particular, the horizontal axis represents the space for probabilities of default for all loans, which ranges from 0 to 1. For demonstrative purposes, we consider three loans: L
                        1, L
                        2, and L
                        3, each of which is placed on the axis properly, according to their respective probabilities of default, p
                        1, p
                        2, and p
                        3. We further assume L
                        3 is our focal loan instance, whereas L
                        1 and L
                        2 are the voting members.

A straightforward way of assessing the similarity between different loans is to calculate the default likelihood distances, as defined in Eq. (3). As a result, we may calculate 
                           
                              
                                 d
                                 13
                              
                              =
                              
                                 |
                                 
                                    p
                                    1
                                 
                                 −
                                 
                                    p
                                    3
                                 
                                 |
                              
                              ,
                           
                         and 
                           
                              
                                 d
                                 23
                              
                              =
                              
                                 |
                                 
                                    p
                                    2
                                 
                                 −
                                 
                                    p
                                    3
                                 
                                 |
                              
                           
                        . From Fig. 1, we can tell clearly that d
                        13 > d
                        23, and thus the voting weight from L
                        1 should be lower than that from L
                        2. Transformation from such distances to voting weights can be done using an arbitrary non-increasing function, but an optimal transformation can be learned as a kernel function whose parameters can be optimized by kernel regression. In our case, we follow Eq. (7), so that w
                        13 < w
                        23. This is because the Gaussian kernel, as described in Eq. (5), provides a larger output value for inputs with smaller absolute values. Compared with parametric regression of loan returns, the non-parametric kernel regression is able to approximate arbitrary relationships without assuming oversimplified data distributions.

In this section, we first formulate investment decisions in P2P lending as a portfolio selection problem with boundary constraints. Then, we combine the instance-based credit risk assessment model described in Section 4 with portfolio selection, and summarize the unified investment decision process. Finally, we describe our model and baseline models for experimental comparison.

Different from traditional banks, personal investors in P2P lending not only need to distinguish good loans from bad ones, but also need to know how to spread optimal proportions of available money across different loans to minimize risk for a given level of expected return. As a result, investing in P2P lending can be formulated as a typical portfolio selection problem, whose basis is modern portfolio theory (Markowitz, 1991). Specifically, by ignoring the negligible correlation between different loans, the objective of the portfolio selection problem is to minimize the investment risk

                           
                              
                                 
                                    
                                       ∑
                                       i
                                    
                                    
                                       λ
                                       i
                                       2
                                    
                                    
                                       σ
                                       i
                                       2
                                    
                                    ,
                                 
                              
                           
                        subject to λi
                         ≥ 0, 
                           
                              
                                 ∑
                                 i
                              
                              
                                 λ
                                 i
                              
                              =
                              1
                              ,
                           
                         and a given level of expected return

                           
                              
                                 
                                    
                                       R
                                       *
                                    
                                    =
                                    
                                       ∑
                                       i
                                    
                                    
                                       λ
                                       i
                                    
                                    
                                       μ
                                       i
                                    
                                    .
                                 
                              
                           
                        The optimization variable λi
                         represents the optimal proportion of money invested into the i-th loan.

Moreover, constraints on investment amounts need to be considered. On the one hand, P2P lending marketplaces usually require a minimum investment amount to each loan. For example, at Prosper, the minimum amount on each loan is m = $25. Investors in P2P lending are especially sensitive to this constraint (Kraft & Steffensen, 2013; Woodside-Oriakhi, Lucas, & Beasley, 2011), because personal investors tend to have much less funds than commercial banks. On the other hand, for the i-th loan, the investor can only lend an amount less than the loan’s requested amount ei
                        . As a result, suppose M is the total investment amount an investor has available, for a loan that he or she invests in (i.e., λi
                         > 0), we require

                           
                              
                                 
                                    m
                                    ≤
                                    
                                       λ
                                       i
                                    
                                    M
                                    ≤
                                    
                                       e
                                       i
                                    
                                    .
                                 
                              
                           
                        Otherwise, we have

                           
                              
                                 
                                    
                                       λ
                                       i
                                    
                                    =
                                    0
                                    .
                                 
                              
                           
                        
                     

As summarized in Algorithm 1, the investment decision process may be described as follows.

There are two input datasets and three parameters in the model. DataH is the historical performance dataset that includes past loans whose pay-back statuses are known. We call this set the “training data.” DataI is the current set of listings that are open for investment, and thus their pay-back statuses are unknown. We call this set “testing data.” The minimum investment amount (m) is determined universally at the P2P lending marketplace. The total investment amount M and the expected overall return rate R
                        * allow for personalizing to the needs or preferences of any individual investor.

In the initialization and training processes (Lines 1–3), we first find out the total number of historical loans in DataH (n), the performance of each historical loan (Rj
                        ), the number of listings that are open for investment (l), and the amount requested by each listing (ei
                        ). Then, we build a logistic regression model with DataH and extract the default probability (pj
                        ) of each loan. Finally, we use cross-validation to optimize the bandwidth (h).

In the credit risk assessment process (Lines 4–12), we first predict the default probability (pi
                        ) of each loan in DataI using the logistic regression model trained in Line 2. Then, for each loan i in DataI, we compute dij
                        , its default likelihood distance to each loan j in DataH (
                           
                              i
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              l
                              ;
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                           
                        ). Furthermore, we compute the kernel weights wij
                         based on dij
                         and optimize bandwidth h by minimizing Eq. (10). Finally, we assess the return (μi
                        ) and the risk (
                           
                              σ
                              i
                              2
                           
                        ) based on the kernel weights (wij
                        ) and the performance (Rj
                        ) of each historical loan in DataH using Eqs. (1) and (2).

In the portfolio selection and investment recommendation process (Lines 13–19), we implement the model described in Section 5.1.

To further demonstrate how the instance-based credit risk assessment model works, we provide an end-to-end numeric example in Appendix A.

In this paper, we propose an instance-based decision model for risk assessment in P2P lending. In order to show its effectiveness, we compare it with two rating-based baselines. The models are described in detail below.

                           
                              RBM
                              is a basic rating-based model, where all the loans are segmented into seven grades according to the loans’ credit risk. Loans in the same grade are assumed to have the same return and risk.

is a refined rating-based model, where each grade in RBM is further segmented into five sub-grades, and the number of sub-grades is selected based on cross-validation. In other words, RBM+ is a rating-based model with optimized grade segmentation.

is the instance-based model proposed in this study. Each loan is assessed using kernel weights and the historical performance of similar loans.

In summary, RBM is the basic version of rating-based credit risk model that is used practically. RBM+ is an enhanced version of rating-based credit risk model, which is used to compare the results when finer levels of risk grades are implemented.

Moreover, we divide each dataset into k subsets and use k-fold cross-validation to verify the effectiveness of our model. In other words, each time we use one of the subsets as the testing set (DataI) and all others as the training set (DataH). Specifically, we divide the Lending Club dataset randomly into 12 subsets, and each subset contains about 168 loans. Similarly, the Prosper dataset is randomly divided into 24 subsets, and each subset contains about 172 loans.

We compare the three models by the following procedure:

                           
                              1.
                              Train each model with the training set, and use the trained model to predict the return rate (μi
                                 ) and risk (σi
                                 ) of each loan in the testing set.

                                    
                                       •
                                       For rating-based models, including RBM and RBM+, we first find the mean and standard deviation of the return rate of loans in each rating grade in the training set. Then, we predict the credit rating of each testing loan. The mean and standard deviation from that credit grade will be used as the predicted return and the predicted risk, respectively.

For the IOM model, we first train the kernel weights of all training loans (Eq. 7), and use such weights for predicting the return of a testing loan with the weighted average (Eq. 1) and risk with the weighted variance (Eq. 2).

Check the prediction accuracy of the models by comparing the predicted return rate (μi
                                 ) and the actual return rate (Ri
                                 ).

For each model, feed the predicted return μi
                                  and risk σi
                                  of each testing loan into the portfolio selection algorithm, and compute the return of investment on the optimal portfolio.

Compare the return rate and Sharpe ratio of the three models.

@&#RESULTS AND DISCUSSIONS@&#

Extensive experiments have been performed on real-world datasets described in Section 3. Specifically, we compare our model with two rating-based models as described in Section 5.3 with respect to prediction accuracy and investment performances.

We predict the default probability pi
                      using the logistic regression model and attribute variables of each loan. Then we run the credit risk model on the Lending Club and the Prosper datasets to predict the return rate μi
                      and the risk 
                        
                           σ
                           i
                           2
                        
                     . Fig. 2
                      shows the relationship between the default probability and the return rate (or the risk) on the Lending Club and the Prosper datasets, respectively. For either dataset, the overall trend is that as the default probability increases, the predicted rate of return decreases, and the risk increases. It is obvious that the curves of IOM is smoother than RBM and RBM+, which demonstrates that IOM has the capacity of predicting the return and risk with better granularity, and provides more accurate overall prediction of loan returns.

Furthermore, we compare the predicted return rate μi
                      by each model against the actual return rate Ri
                     . Specially, we computed the Euclidean distance and R
                     2 as the accuracy metrics. As shown in Table 1
                     , IOM model has better prediction accuracy than either the RBM or RBM+ model on both datasets.

Based on the predicted return μi
                      and risk 
                        
                           σ
                           i
                           2
                        
                      from the output of each credit risk model, we execute the portfolio selection to find the optimal portfolio, and compute the overall rate of return. By default, the parameters are investment amount M = $15,000 and target return rate 
                        
                           
                              R
                              *
                           
                           =
                           0.06
                        
                     . We also assume risk-free return rate to be 0.025, which is equivalent to the average return from T-Bills at the same period of time.


                     Table 2
                      shows the investment return rate on each testing subset and the average performance on Lending Club dataset. Both the average investment return rate and the Sharpe ratio demonstrate that the IOM model performs better than both the RBM and the RBM+ models. Similar results are found for the Prosper dataset, as shown in Table 3
                     .

Finally, we find that the IOM credit risk assessment model can effectively improve the investment decisions for different investors as compared to rating-based credit models, when they have different investment amounts and expected returns. We run portfolio selection on both the Lending Club and the Prosper datasets with different combinations of input parameters.

As listed in Table 4
                     , we consider nine different combinations of investment amounts and investors’ expected return rates. For each combination of parameters, we use the same portfolio selection algorithm to find the optimal asset allocation (i.e., amount of money to be allocated to each loan), as described in Section 5.1. The only difference is that the input for portfolio selection (i.e., the predicted return and risk for each loan) is produced by each of the RBM, RBM+, and IOM models, respectively, as described in Section 5.3. We compute the actual return of investment and Sharpe ratio on all loans for each set of parameters in Table 4 as well as the average, as shown in Fig. 3
                     .


                     Fig. 3 demonstrates a performance comparison of the three models on the Lending Club and Prosper datasets in terms of overall return and the Sharpe ratio. We can see that for each combination of parameters (sets 1 through 9 from Table 4, as listed on the x-axis in each subfigure) as well as the average (number 10 on the x-axis in each subfigure), the IOM model performs better than both RBM and RBM+ models on both datasets, by having higher average investment return and higher Sharpe ratio.

In summary, our experiments show that the IOM credit risk assessment makes more accurate predictions of risk and returns. Moreover, when its output is used for portfolio selection, it yields better portfolios of investment than the rating-based models.

@&#CONCLUSIONS@&#

In this study, we proposed an instance-based credit risk assessment model to quantify the risk of each loan in the P2P lending marketplace, and formulated the investment decision in P2P lending as a portfolio optimization problem with boundary constraints. The proposed credit risk assessment model has at least three major advantages. Firstly, it has the ability of quantifying the credit risk of each individual loan, instead of categorizing the loans into a small number of risk groups. Such granularity provides an easy way to compare risks of different loans, and the potential of more accurate predictions. Secondly, this model can assess the credit risk of a new loan based on its default likelihood distances to past loans, without requiring detailed historical observations of the same borrower. Finally, the weights of past loans are determined within the mathematical framework of kernel regression, which guarantees the optimality and does not require strong statistical assumptions. As demonstrated by experimental results on two real-world datasets, the proposed model has better performances than existing models available at the P2P lending marketplaces.

@&#ACKNOWLEDGMENT@&#

The authors would like to thank the anonymous reviewers for their constructive comments. The research presented in this paper was partially supported by Natural Science Foundation of China (No. 71028002, 71372083, 71402014), Humanities and Social Science Program of the Ministry of Education in China (No. 14YJCZH044) and Fundamental Research Funds for the Central Universities (No. DUT15RW116).

In this section, we present an end-to-end example to demonstrate the instance-based credit risk assessment model for making investment decisions in P2P lending.
                     
                     
                     
                  


                     Step 1: Data preparation (Line 1 in Algorithm 1) Suppose that a historical dataset (DataH) is provided in the first seven columns in Table A.5, which includes n training instances (
                        
                           n
                           =
                           30
                        
                     ). The input variables (Columns 2-6 in Table A.5) and the target variable (Column 7 in Table A.5) are described in Table A.6.

Also suppose that a testing dataset (DataI) of l instances (
                        
                           l
                           =
                           10
                        
                     ) is provided in the first six columns in Table A.7, with the same input variables, but values of the target variable are unknown.


                     Step 2. Logistic regression (Line 2 in Algorithm 1) Based on the training set DataH, fit a logistic regression model. More specifically, estimate the parameters 
                        
                           
                              β
                              k
                           
                           ^
                        
                      (
                        
                           k
                           =
                           0
                           ,
                           1
                           ,
                           …
                           ,
                           5
                        
                     ) in the following equation

                        
                           (A.1)
                           
                              
                                 logit
                                 
                                    (
                                    
                                       p
                                       ^
                                    
                                    )
                                 
                                 =
                                 
                                    
                                       β
                                       0
                                    
                                    ^
                                 
                                 +
                                 
                                    
                                       β
                                       1
                                    
                                    ^
                                 
                                 
                                    X
                                    1
                                 
                                 +
                                 
                                    
                                       β
                                       2
                                    
                                    ^
                                 
                                 
                                    X
                                    2
                                 
                                 +
                                 
                                    
                                       β
                                       3
                                    
                                    ^
                                 
                                 
                                    X
                                    3
                                 
                                 +
                                 
                                    
                                       β
                                       4
                                    
                                    ^
                                 
                                 
                                    X
                                    4
                                 
                                 +
                                 
                                    
                                       β
                                       5
                                    
                                    ^
                                 
                                 
                                    X
                                    5
                                 
                                 .
                              
                           
                        
                     
                  

Based on the training set DataH, we find the estimated coefficients as listed in Table A.8. Using Eq. (A.1), we find the predicted probability of default for all training instances, as listed in Column 9 of Table A.5.

Note that since logistic regression modeling is beyond the scope of our study, and that we are using a small dataset for illustrative purposes, we ignore many issues in logistic regression, such as assumption checking, variable transformation, model selection, and diagnosis. Here we assume that these tasks are robustly performed without distraction from our main procedure.


                     Step 3: Scoring the testing data (Line 5 in Algorithm 1) Using Eq. (A.1), find the predicted probability of default for all testing instances, as listed in the column of 
                        
                           p
                           ^
                        
                      in Table A.7.

We can then calculate the similarity between each pair of testing instance and training instance, using Eq. (3). More specifically, we produce the matrix of dij
                      in Table A.9, where rows correspond to training instances and columns correspond to testing instances. These raw distances only measure proximity among loans in terms of probability to default, but do not provide weights of voting from training instances whose return rates are known. In the next few steps, we find such weights by utilizing kernel regression.
                     
                     
                  


                     Step 4: Bandwidth optimization (Line 3 in Algorithm 1) The bandwidth is to be optimized by using the training data only. Since the sample size is 
                        
                           n
                           =
                           30
                        
                      and the standard deviation of 
                        
                           p
                           ^
                        
                      is 
                        
                           σ
                           =
                           0.2581
                           ,
                        
                      according to Eq. (11), we find that

                        
                           
                              
                                 
                                    h
                                    0
                                 
                                 =
                                 
                                    
                                       (
                                       
                                          4
                                          
                                             3
                                             ×
                                             30
                                          
                                       
                                       )
                                    
                                    
                                       1
                                       /
                                       5
                                    
                                 
                                 ×
                                 0.2581
                                 =
                                 0.1385
                                 .
                              
                           
                        
                     
                  

Using Eq. (8), i.e., leave-one-out least-squares cross validation, calculate the CV(h) for all possible values of h, varying from 0.25h
                     0 to 1.5 h
                     0. For any given bandwidth h, the calculation of CV(h) is based on Eq. (10).

For each possible value of h/h
                     0, ranging from 0.25 to 1.5, in increments of 0.05, Table A.10 lists the calculated CV(h) based on the training set. Fig. A.4 visualizes the trend of CV(h) with respect to h/h
                     0, which clearly shows a minimal point roughly at 
                        
                           h
                           /
                           
                              h
                              0
                           
                           =
                           0.65
                        
                     . This indicates that the optimal bandwidth will be

                        
                           
                              
                                 h
                                 =
                                 0.65
                                 
                                    h
                                    0
                                 
                                 =
                                 0.65
                                 ×
                                 0.1385
                                 =
                                 0.0900
                                 .
                              
                           
                        
                     
                  


                     Step 5: Calculating kernel weights (Line 8 in Algorithm 1) Using Eq. (7) and the optimized bandwidth h from the previous step, find the kernel weight wij
                      between each testing loan i to each training loan j. The calculated weights are listed in Table A.11.


                     Step 6: Predicting return and risk (Lines 10 and 11 in Algorithm 1) Based on wij
                      and Rj
                      in historical data, find the predicted return (μ) and risk (σ
                     2), as listed in the 9th and 10th columns of Table A.7.


                     Step 7: Portfolio selection (Lines 13–19 in Algorithm 1) Given expected return 
                        
                           
                              R
                              *
                           
                           =
                           0.08
                           ,
                        
                      and the minimum investment m = $25, based on the average rate of return μ and risk σ
                     2, as listed in the 9th and 10th columns of Table A.7, find the weights of investments, as listed in the 11th column of Table A.7.

Given total amount for investment M = $5000, the investment amounts include Loan 6 of OM
                     6 = $3250, and Loan 9 of OM
                     9 = $1750.

@&#REFERENCES@&#


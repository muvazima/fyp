@&#MAIN-TITLE@&#Selecting significant genes by randomization test for cancer classification using gene expression data

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new approach was developed to identify genes from gene expression data.


                        
                        
                           
                           A statistic is defined to evaluate the significance of the genes in the method.


                        
                        
                           
                           Informative genes are selected by the statistic for cancer classification.


                        
                        
                           
                           The method may provide an alternative for gene selection problem.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gene expression data

Randomization test

Partial least squares discriminant analysis

Gene selection

Cancer classification

@&#ABSTRACT@&#


               
               
                  Gene selection is an important task in bioinformatics studies, because the accuracy of cancer classification generally depends upon the genes that have biological relevance to the classifying problems. In this work, randomization test (RT) is used as a gene selection method for dealing with gene expression data. In the method, a statistic derived from the statistics of the regression coefficients in a series of partial least squares discriminant analysis (PLSDA) models is used to evaluate the significance of the genes. Informative genes are selected for classifying the four gene expression datasets of prostate cancer, lung cancer, leukemia and non-small cell lung cancer (NSCLC) and the rationality of the results is validated by multiple linear regression (MLR) modeling and principal component analysis (PCA). With the selected genes, satisfactory results can be obtained.
               
            

@&#INTRODUCTION@&#

Cancer classification based on microarray has become a popular research topic in bioinformatics, which can be used to detect subtypes of cancers and produce therapies. A great many of studies have appeared for cancer classification [1–3]. These methods include principal component analysis (PCA) [4,5], k-nearest neighbor (k-NN) [6], hierarchical clustering analysis (HCA) [7], support vector machine (SVM) [8], Bayesian method [9], partial least squares discriminant analysis (PLSDA) [10], ensemble methods [11], etc. Among these methods, PLSDA has been the most commonly used one for cancer classification due to its simplicity [12–14]. Moreover, as a dimension reduction technique, PLS has been used in gene expression data analysis even in the case where the number of genes exceeds the number of samples.

Except for a few classification methods using full genes [15], classification is generally performed based on selecting significant genes for constructing accurate prediction models. Furthermore, gene selection may provide insights into understanding the underlying mechanism of a specific biological phenomenon. Also, such information can be useful for designing less expensive experiments by targeting only a handful of genes [16]. However, how to effectively select significant biomarker genes from thousands or even ten thousands of genes is a difficult problem. A comprehensive review of feature selection methods has been described by Saeys et al. [17]. Depending on how the genes interact with the construction of the classification model, feature selection techniques can be characterized into three classes: filter, wrapper and embedded methods. Filter methods [18] assess the relevance of features by looking only at the intrinsic properties of the data, and thus they are computationally simple and fast. Wrapper methods [19] employ a selection strategy in the space of all possible feature subsets, guided by the predictive performance of a classification model. Advantage of these methods includes the interaction between gene subset search and model selection. However, they may have a higher risk of over-fitting than filter methods and may be computationally intensive. Embedded methods [20] make use of the internal parameters in a classification model to perform feature selection, and, therefore, the computational cost is reduced but the advantage of the interaction between the gene selection and classification model is preserved. Based on the three classes of feature selection techniques, various gene selection algorithms have been proposed and successfully used in selecting informative genes for cancer classification [21–25]. In our previous works, Monte Carlo based uninformative variable elimination (MC-UVE) [26], randomization test (RT) [27], PLS with the influential variables (IVs) [28] and latent projective graph (LPG) [29] have been proposed for selecting informative variables in near-infrared spectral analysis. Among these methods, RT has been proved to be an efficient approach to extract useful information from the spectra. The method builds a regular model and a series of random models, and then evaluates the importance of the variables based on the significance test of coefficients in regular and random models. The variables with high significance can be selected as the informative ones.

In this study, RT coupled with PLSDA was employed to seek the significant genes for cancer classification. A set of PLSDA models are built by permutation, and the significance of genes are evaluated by a statistic. To validate the performance and applicability of the method, four gene expression datasets were investigated. The results show that the method can select significant genes for cancer classification.

@&#METHODS@&#

Partial least squares (PLS) regression is a well-known method to find the relationship between predictor variables X and dependent variables y. In a PLS model, not only the variance of X, but also the covariance between X and y is taken into account. Therefore, the central point of PLS is to find latent variables in the feature space that have a maximum covariance with y. PLSDA is a variant of PLS to improve the separation between classes using a categorical response variable y. In this study, X is the matrix of gene expression values and the values of y are given as 1 and −1 for positive and negative class, respectively. Each row of X matrix represents the gene expression values of all the genes for each sample, and each column corresponds to the gene expression values of all samples for a gene. PLSDA is used for modeling the genes expression data (X) and the response variable (y) using the training set. In the calculations, the optimal latent variable (LV) number used in the modeling is determined by Monte Carlo cross validation (MCCV). In the prediction, the samples with predicted values above zero are ascribed to positive class, otherwise to negative class. The parameters of accuracy (Acc), precision (P), recall (R) and F-measure (F) are used to evaluate the classification effect.

RT is a method for variable selection by employing the statistics of the regression coefficients in the models built with permutation of the dependent variables y in the training set [27]. In the calculation of RT, a regular model showing the relationship of y and X is built for reference and a number (M) of random PLSDA models are built by randomization, i.e., randomly scrambling the indices of y while keeping the indices of X. In this study, the number of the permutations is 1000, as discussed in our previous work [27]. In each of the random models, a regression coefficient can be obtained for each gene. Clearly, the regression coefficients of each gene in the random models must be due to chance. Therefore, the values of the regression coefficients can be referred to as ‘noise values’.

A statistic, P, is defined as the fraction of the ‘noise values’ exceeding the regression coefficient in the regular PLSDA model,
                           
                              (1)
                              
                                 
                                    
                                       P
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 num
                                 (
                                 |
                                 
                                    
                                       β
                                    
                                    
                                       j
                                    
                                 
                                 |
                                 >
                                 |
                                 
                                    
                                       β
                                    
                                    
                                       0
                                       ,
                                       j
                                    
                                 
                                 |
                                 )
                                 /
                                 M
                                 
                                 (
                                 j
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 …
                                 ,
                                 p
                                 )
                              
                           
                        where j is the index of the genes, and p is the number of genes. β
                        
                           j
                         and β
                        0,
                        
                           j
                         represent the ‘noise values’ and the regression coefficient in the regular model of the gene j, and M is the number of random models. Since the value of the regression coefficient for each gene is a reflection of its importance in the model, the informative or relevant genes generally have coefficients of large absolute values. Therefore, the ‘noise values’ should be significantly smaller than the coefficients of the normal model, because they are obtained by randomization, and the significance of a gene can be assessed by its P value. If a cutoff value is defined, the genes whose coefficients are smaller than the threshold should be selected as informative ones. In this study, all the genes are ranked by their P values, and thus the genes are selected according to the order from low to high P values.

RT-PLSDA means a combination of RT and PLSDA, in which the coefficients of PLSDA models were used to calculate P values. Four steps are included in the calculations. Among the steps, the first two steps are used for selecting the informative genes according to the P values. The third step determines the retained genes by repetition of RT procedures to make the result more reliable, and the fourth step involves the modeling and prediction with the selected genes. The calculation details can be described as follows.
                           
                              (1)
                              With the training set, a regular PLSDA model is built, and the regression coefficients for the genes are recorded in a 1×
                                 p vector β
                                 0. With the same training set, M permutations of y are performed to build M PLSDA random models. The regression coefficients are recorded in an M
                                 ×
                                 p matrix β as the ‘noise values’. It should be noted that before the calculation, auto-scaling were performed to the datasets in order to eliminate the effect of intensity difference between genes and make each gene have a comparable contribution to the classification.


                                 P value of each gene is calculated by using Eq. (1), and the genes are ranked in an ascending order of P values. With a number (N) of genes with lower P values, the error of cross-validation (ECV), which is defined as the number of misclassified samples, is obtained by MCCV. In the calculation of MCCV, 50% of the samples in the training set are randomly selected to build the model and predict the remaining samples, and 1000 repetitions were performed. The ECV value is calculated by the sum of misclassified samples number in the 1000 repetitions. The number of genes with the minimum ECV value is selected.

Because random permutation is involved in the calculations, the distribution of P values is not identical in different runs. A large number of runs may not be necessary considering the time consumed, 100 was used for ensuring the reliability and for investigating the repeatability of the method. A frequency number in the 100 runs is used to further describe the significance of each gene. The selected genes are ranked in a descending order with the frequency number, and with different number of the selected genes, a series of PLSDA models are built and the ECV is obtained by MCCV. The optimal number of retained genes can be therefore determined by the lowest ECV value for the training set as calculated in step (2).

With the retained genes, a multiple linear regression (MLR) model for classification is built and used to predict the test set.

In RT method, the distribution of P values is plotted for determination of the variables with low value. In this study, −lg
                        P is used in place of P to make the distribution more clear. In this case, the genes with higher values will be more significant. It should be noted that for few genes, P value may be zero when the regression coefficient in the regular model is larger than all the ‘noise values’. Such genes are obviously significant ones. For these genes, −lg
                        P is defined as 4 because the maximum value of −lg
                        P is 3 when only one of the ‘noise values’ is larger than the regression coefficient in the regular model.

Four gene expression datasets of prostate cancer [30], lung cancer [31], leukemia [32] and non-small cell lung cancer (NSCLC) [33] were used in this study. A summary of the four datasets are listed in Table 1
                     . In the calculations, the training and test set described in the website was used for the lung cancer and Leukemia dataset, but Kennard–Stone algorithm (KS) [34] was used to divide the two sets for the prostate cancer and NSCLC datasets. The KS algorithm sequentially selects a subset of samples that are uniformly distributed over the predictor variables space based on the Euclidean distance between samples.

@&#RESULTS AND DISCUSSION@&#

In order to show the procedures of gene selection by RT method, prostate cancer dataset is used as an example. In the calculations, eight principal components are used for the dataset. Fig. 1
                         shows the −lg
                        P values of the 12,600 genes obtained in one independent run. In the figure, most of the −lg
                        P values are less than one, meaning that their significance is near a random variable. Therefore, these genes are not significant at all in the classification model. On the other hand, only a small number of the genes have a large −lg
                        P value, and two of them are 4, corresponding to a zero P value. The result indicates that there is only a small number of genes are informative and it may be possible to select the significant genes with the −lg
                        P values.

In order to determine the number of significant genes, the genes are ranked in a descending order of −lg
                        P values. With a number (N) of genes with higher −lg
                        P values, ECV value is calculated by MCCV. Fig. 2
                         shows the variation of ECV with the number of selected genes from N
                        =9 to 30. The reason for starting with nine genes is because the number of genes must be bigger than the LV number of the PLSDA model, and the reason for ending at 30 is just for clarity of the figure. Calculations show that the variation after 20 is almost the same until 100. It can be seen that, the ECV decreases from a large value to a minimum at N
                        =16, and then the ECV fluctuates around a number slightly bigger than the minimum. The result indicates that the best model for the classification can be obtained with the 16 selected genes.

Because random permutation is involved in the calculations, the distribution of −lg
                        P values may not be identical in different runs. Therefore, 100 independent runs are performed to obtain a reliable result. The results show that the number of the selected genes in the 100 runs is between 10 and 30. Therefore, the frequency number was calculated for further ranking the selected genes. As defined in the method, the higher the frequency number of a gene, the more significant. Fig. 3
                         displays the frequency number of the selected genes. In the figure, the genes are ordered by the frequency number along the abscissa axis. It is clear that only 48 genes are selected, and most of the genes are selected in a high frequency. With this figure, the significant genes for classification can be selected according to the frequency number. On the other hand, the result also shows that, although random permutation is involved, the algorithm has a good reproducibility. Similar result can be obtained in different independent run.

To determine the number of retained genes, ECV value is calculated by MCCV with different number of the selected genes from high to low frequency number. The calculation starts with nine genes as the same reason mentioned above. The variation of ECV with the number of retained genes is shown in Fig. 4
                        . It can be seen that the ECV decreases from a large value to a minimum when the number of retained genes is 18. Then, with the increase of the number, the ECV fluctuates slightly, and reaches a minimum at 43. If tested with F criterion [35], however, it can be found that the ECV values with 18 and 43 genes have no significant difference. Therefore, the 18 genes can be identified as the significant genes for the classification of the dataset.

For testing the efficiency of the retained significant genes in classification of the dataset, the classification model with the 18 genes is investigated. Because the number of retained genes is smaller than that of the samples, MLR model is adopted for modeling and prediction to make the model less complicated. An accuracy of 97.06% (66/68) was obtained for the training set by leave-one-out cross validation (LOOCV), and the accuracy for the test set is 91.18% (31/34). It is obvious that the results are acceptable, indicating that the genes obtained by the proposed method is informative enough for the classification.

To further illustrate the performance of the proposed method, the lung cancer dataset, leukemia dataset and NSCLC dataset are investigated. In the calculations, 3, 5 and 3 principal components are used for the three datasets, respectively. Because the same procedures were used in the calculation and the similar results were obtained as in the calculation of prostate cancer dataset, only the frequency number of the genes was given. Fig. 5
                         shows the frequency numbers of the selected genes for the three datasets. With the same calculation for the prostate cancer dataset, i.e., the variation of ECV values with the number of selected genes in MCCV, the number of significant genes for the three datasets is 4, 9 and 7, respectively.

The rationality of the significant genes was also investigated by MLR models, as did for the prostate cancer dataset. The accuracies, P, R and F for the training and test sets are summarized in Table 2
                        . It can be seen that both the accuracies and the statistical parameters are acceptable, demonstrating the rationality of the retained genes.

In order to validate the selected genes, Table 3
                         summarizes the index, gene IDentity (Gene ID), definition and annotation date of the 18 genes in an order of frequency number.

As labeled in the table, most of these genes are consistent with the results reported in the previous studies [30,36–40]. For examples, X07732 was reported to encode hepsin, a serine protease that overexpresses in most prostate cancers. It has been known as a potential prostate cancer biomarker [41,42]. M84526 encodes another serine protease adipsin that is secreted by adipocytes into the bloodstream and functions as part of the alternative complement pathway of the innate immune system [43]. Hokaiwado et al. [44] showed that glutathione transferase (M96233) mediates the proliferation of androgen-independent prostate cancer cells. M22832 has been correlated to different cancer types with consistent up-regulation in tumor [45].


                        Table 4
                         lists the information of the four genes for the lung cancer datasets. The first gene (AL050224) has been selected by Wang and Simon [46]. It may play a role in the RNA polymerase and the expression of the gene was found to be high in lung tissues [47]. Wang and Gotoh [37] reported that FBP1 (U21931) was likely to have high discriminative power for the ADCA and MPM samples. As for the last two genes in the table, Claudin-7 (AJ011497) was found underexpressed in MPM while overexpressed in ADCA, and in contrast, MRC OX-2 (X05323) was found overexpressed in MPM [31]. Therefore, they are considered as biomarkers for the lung cancer.


                        Table 5
                         presents a summary of the nine genes for the leukemia datasets. As labeled in the table, all of the nine genes have been identified as significant ones in previous studies [32,48,49]. For examples, CD33 (M23197_at) has been developed for targeted antibody therapy to kill leukemia AML cells [32,50], and the zyxin gene (X95735_at) has been shown to encode an LIM domain protein that is important in cell adhesion of fibroblasts [51].


                        Table 6
                         shows a summary of the seven genes for the NSCLC dataset. Because the dataset is a relatively new one, it is difficult to find the literatures for biological interpretation of the genes. Thus further discussions are not given in this paper.

To further investigate the significance of the selected genes, PCA score plots obtained with the selected genes of the four datasets are shown in Fig. 6
                        . Using these plots, the distribution of the samples for the datasets can be observed.

It is clear that a very good clustering occurs for all the four datasets, although the result of prostate cancer dataset is relatively not so satisfactory. By using Fisher linear discriminant [52], the number of misclassified samples for the four datasets is 7, 3, 3, and 1, respectively. The results clearly demonstrate that the retained genes can describe the nature of the samples in the two classes, and thus imply that the selected genes are significant for discriminating the samples. Therefore, the proposed method may be an efficient tool for finding possible biomarkers from gene expression data.

In order to investigate the performance of the proposed method, the number of selected genes by different methods and the classification effect by using these genes are summarized in Table 7
                        .

At first, from the number of selected genes, the difference between methods can be clearly found. For several methods, the number is as high as 50 or even 100, but for some methods, the number is less than 10, even only 1 or 2. However, it is difficult to do a further comparison of the selected genes for all the method listed in the table because the genes selected by the compared methods were not provided. The results may be accounted for by the small number of the dataset and the properties of the data [56].

As for the classification accuracies, the proposed method produced the results of 97.06% and 91.18% for the training and test sets, respectively, using the 18 selected genes for the prostate cancer dataset. The result is similar to most of the published works, except that Wilcoxon–Mann–Whitney (WMW) and effective range based gene selection (ERGS) method produce a slightly different accuracy. However, it may be noticeable that the accuracy by ERGS method was obtained by LOOCV of all the samples in the dataset, instead of the samples in the test set. For the lung cancer dataset, Gordon et al. [31] obtained the best classification among the summarized methods. The proposed method produces a similar result with the others including by k-top scoring pairs (k-TSP), ERGS, WMW and recursive feature elimination (RFE), which were obtained by LOOCV. For the leukemia dataset, the accuracy of the proposed method seems not as good as the previously reported ones. As for the NSCLC dataset, it is still difficult to find the reference data for comparison. The accuracy of 94.87% and 94.74% for the training and test sets is obtained by the proposed method.

Clearly, the proposed method cannot outperform all the existing methods. However, it can outperform some of the published methods, and can obtain a comparable result with most of the published methods. The difference in the number of misclassified samples is only one or two. More importantly, the results listed in Table 7 for the proposed method were obtained by an independent test set, but that for most of the published methods were obtained by using LOOCV based on all the samples. Generally, the former obtains a more reasonable result. On the other hand, some of the methods producing high prediction percentage used too large or small number of the selected genes in the classification. For examples, only one or two genes were used in the classification of prostate cancer dataset by k-TSP and WMW method and of lung cancer dataset by WMW, RFE and decision rules method. In some classification, however, more than 50 genes were employed. Such results may be difficult for a biological interpretation.

@&#CONCLUSIONS@&#

Randomization test is employed as a gene selection method. The method can evaluate the significance of a gene by a statistic of the regression coefficients in a series of random PLSDA models. Therefore, a few of the significant genes can be selected from the thousands or more genes in an expression data. With repetition of the calculations, the frequency number of a gene can be further used as a criterion to evaluate its significance. Four datasets of prostate cancer dataset, lung cancer dataset, leukemia dataset and NSCLC dataset are investigated by the method. 18, 4, 9 and 7 significant genes are identified, respectively, and the rationality of the results is validated by MLR modeling and PCA. Compared with the results obtained in previous studies, the superiority of the method is proved. Therefore, the method may be an alternative tool for classification using the expression data.

@&#ACKNOWLEDGMENT@&#

This work was supported by the National Natural Science Foundation of China (No. 21175074).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Observer performance in estimating upper arm elevation angles under ideal viewing conditions when assisted by posture matching software

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           On average, observers were virtually unbiased in estimating upper arm elevation to the nearest 1°.


                        
                        
                           
                           Observers were most proficient at estimating 0° and 90°, and least proficient at 60° postures.


                        
                        
                           
                           Within observer variance was considerable, indicating the risk of relying on single observations.


                        
                        
                           
                           If high precision is required & repeated observations are not feasible, inclinometry is suggested.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Measurement error

Working postures

Observation

@&#ABSTRACT@&#


               
               
                  Selecting a suitable body posture measurement method requires performance indices of candidate tools. Such data are lacking for observational assessments made at a high degree of resolution. The aim of this study was to determine the performance (bias and between- and within-observer variance) of novice observers estimating upper arm elevation postures assisted by posture matching software to the nearest degree from still images taken under ideal conditions. Estimates were minimally biased from true angles: the mean error across observers was less than 2°. Variance between observers was minimal. Considerable variance within observers, however, underlined the risk of relying on single observations. Observers were more proficient at estimating 0° and 90° postures, and less proficient at 60°. Thus, under ideal visual conditions observers, on average, proved proficient at high resolution posture estimates; further investigation is required to determine how non-optimal image conditions, as would be expected from occupational data, impact proficiency.
               
            

@&#INTRODUCTION@&#

Body posture is a commonly accepted physical risk factor associated with musculoskeletal disorders (MSDs). While considerable efforts have been made to characterise and quantify the effects of working postures, detailed exposure–response relationships are still lacking, and most large epidemiological studies have failed to show associations between postural exposure factors and MSDs (National Research Council, 2001; Punnett and Wegman, 2004). Insufficient exposure assessment has been cited as a possible explanation (Winkel and Mathiassen, 1994; Burdorf et al., 1997; van der Beek and Frings-Dresen, 1998; Punnett and Wegman, 2004). Thus, valid and reliable postural exposure measurement methods are required to provide meaningful and consistent posture data that can support successful investigations into the role of posture in MSD onset and mediation.

To date, a wide range of methods has been used to assess posture, from self-report to observation to direct technical measurements. It has generally been considered that posture estimates become ‘more correct’ as one moves along this spectrum (Winkel and Mathiassen, 1994; van der Beek and Frings-Dresen, 1998). While this hierarchy is supported from a reliability standpoint – tools at lower levels are typically associated with larger methodological variance – it is not as clear whether this supposition holds regarding the validity of a tool. This seemingly paradoxical situation can result since the ability of a measurement tool to produce a faithful measurement depends on the conditions in which the measurements are made and not only on the technical attributes of the device itself. During posture measurement, errors can occur when using highly precise technical devices due to the interaction between the externally mounted device and the soft tissue overlying the rigid bony structures to be measured. A recent publication from our research team (Jackson et al., 2015) challenged the notion of whether direct technical measurement using inclinometry (INC) constitutes a superior, ‘gold standard’ scale on which to measure upper arm elevation angles (UAEA – Table 1
                     ) found a systematic bias in INC measured UAEA when compared to ‘true’ angles determined via meticulous, assisted-observation positioning of the arm: INCs underestimated both arm abduction and arm flexion angles by an average of approximately 10° across the 0–180° range of postures tested (Jackson et al., 2015). These findings are concerning in two ways. First, they question whether the results of an INC data collection quantify upper arm elevation postures in a way that matches our inherent understanding of how arm angles should appear. By extension, this also questions the use of INC data as a ‘gold standard’ to which other data are validated. Second, if INC data differ systematically from data obtained using other posture assessment methods, direct comparison of results is questionable. This is paramount to consider since postures determined using different methods or tools are routinely compared without adjusting for difference in scale; for example, direct comparison of arm posture estimates obtained via observation and inclinometry (Juul-Kristensen et al., 2001; Trask et al., 2013, 2014). Utilisation of postural data obtained according to different measurement scales (or differently biased measurement tools) will hinder attempts to elicit clear exposure–response relationships.

Observation tools are also routinely used for assessing postures. This group of tools are generally considered to provide a good trade-off between the high error of self-reported data and the seemingly high cost of direct technical measurements (Kilbom, 1994; David, 2005; Bao et al., 2009) - although this cost supposition has recently been questioned (Trask et al., 2013). A wide range of observational tools exist, ranging from checklists performed in real time to assess activities or general workloads, to posture ratings from video sequences or still images, made at differing levels of resolution. Validity and variability (‘reliability’ between and within observers) have been considered for many observation tools (see Takala et al. (2010) for a thorough review). However, only a few studies evaluated methods that required observers to make postural estimates at a high degree of resolution, i.e. to the nearest degree rather than within the range of a posture interval (Ericson et al., 1991; Genaidy et al., 1993; Covalla, 2003; Bao et al., 2009; Dartt et al., 2009; Xu et al., 2011; Qu et al., 2012; Rezagholi et al., 2012). This high degree of resolution would be required for detailed comparisons of results between studies, determining the effects of ergonomic interventions, or establishing exposure–response relationships. Of these papers, two binned the estimated data prior to evaluating the statistical properties (Bao et al., 2009; Dartt et al., 2009), and thus could not report observer agreement or error in high-resolution angle measurements. Five studies evaluated validity by providing estimates of error between observation and ‘true’ angles: two examining static, planar UAEA, and three examining UAEA during simulated work. In all cases, image data for observation was collected in the laboratory under ideal viewing conditions, that is, with good lighting, no visual obstructions, no baggy clothing. Among the planar posture studies, the mean absolute observation errors across the full range of shoulder angles tested ranged from 6° to 9° (Genaidy et al., 1993; Qu et al., 2012) (where ‘truth’ was determined either by goniometer measurement (Genaidy et al., 1993) or digitization of the observed images (Qu et al., 2012)). These error estimates include contributions from within-observer variability between repeated estimates and from bias (if present), but do not discriminate between the two. Only Genaidy reported algebraic mean error and showed a slight underestimation of −1.3° by observers assessing planar arm flexion postures. Of the studies investigating a simulated work task, where UAEAs were not restrained to a single plane (Ericson et al., 1991; Covalla, 2003; Xu et al., 2011), one reported a similar slight underestimation of −3.0°, particularly for angles above 50° (Covalla, 2003) while one reported overestimations of UAEA, with a mean error of approximately 8° (Xu et al., 2011). The third study found that the median observed value overestimated arm elevation by approximately 5° (Ericson et al., 1991). It is therefore difficult to conclude whether observed estimates are biased from the truth under ideal observation conditions, let alone under conditions occurring in real working environments. Variability expressed in terms of variance components within and between observers was only presented in one of the aforementioned ‘high resolution’ posture assessment papers (Rezagholi et al., 2012), and data were only given averaged across the range of angles seen during the task. Within- and between-observer variance estimates are required in addition to measures of the validity to truly understand the practical application of observation as a posture exposure quantification method. Further, to understand whether observers are equally consistent and correct at estimating different UAEAs, information on variance components is required at specific angles rather than just across a range of angles.

The aims of this study were therefore (i) to determine the performance (i.e. the bias and within- and between-observer variability) of observers estimating upper arm postures repeatedly via a posture matching computer software program from still images taken under ideal observation conditions; (ii) to determine the extent to which performance is dependent on the posture at which observations are made; and (iii) if observations are biased, to determine whether that bias can be effectively adjusted for via calibration.

@&#METHODS@&#

The images observed in this study were collected as part of a larger study which examined the relationship between inclinometer and meticulous, assisted-observation measured angles (Jackson et al., 2015). Twelve males and seven females wearing a fitted or no shirt were meticulously positioned twice at each of seven arm abduction (AA) and eight arm flexion (AF) set angles (0°, 30°, 45°, 60°, 90°, 120°, 150° for AA and AF; -15° for AF only), presented in random order. Subjects maintained a straight arm with a downward facing palm for all flexion and abduction trials. The same physiotherapist guided all subjects to each set angle assisted by a projection of the set angles on the wall and atop the subject. The physiotherapist meticulously matched the midline of the long axis of the humerus to the projected line of the target posture, with the projected vector passing through the centre of the elbow joint (Fig. 1
                        ) – a process we have termed ‘meticulous, assisted observation’. A mirror assisted subjects in maintaining each set posture. The projected arm axis system location was customised for each subject so the origin aligned with the estimated centre of rotation of that subject's shoulder joint. Three additional AA and AF trials at 30°, 60° and 90° were conducted with an upward facing palm.

Subjects held each test posture for 5 s during which time the projected axis system was removed and a still image was taken. The data set of photos from which observer proficiency was assessed (see below) constituted 38 photos at each of the 15 set postures.

Three adults were recruited via local advertisement as video observation workers (2 male and 1 female; ages 23, 27, 43). Potential analysts were excluded if they had any knowledge of the prior study (cf. Section 2.1) during which image data for the present study were collected (Jackson et al., 2015).

Observers completed a standardized 3 h training session in estimating postures from still images using a simplified version of the custom-made software program, Vispa (Trask et al., 2013). Estimated angles were made for each image and could be entered as a number (the estimated angle in degrees) in a box or by dragging a rotating vector to an angle judged to resemble the image (Fig. 2
                        ); the resolution level was to the nearest degree irrespective of data entry method. The set of training images contained postures taken at random angles – that is, postures that were not even multiples of 5° or 10°, for example, 57°. If the rotating vector was used to identify the posture, the software program assigned the estimated angle, to the nearest degree, based on the angle of the vector with respect to the vertical. A combination of lectures and practice sessions were used to teach observers how to correctly identify arm flexion, abduction and trunk flexion angles, and how to use the software: training protocol detailed in Trask et al. (2013). Observers first worked as a group to interpret frames contained in a training database with known ‘true’ angles and group discussions were used to harmonize interpretations of difficult or unusual images. The training concluded with independent identification work, again with feedback comparing observers' estimates with the known angles.

Observers estimated AA, AF angles and trunk flexion angles (the later were not used in this study) via the Vispa software program. Observers were instructed to assess as many images as possible within a 3 h time period, but that quality of the assessment was more important than the quantity of assessments made. Observers were free to take breaks throughout the working time, as was needed.

Observer reported data were manually inspected. Nine reported values deviated by more than 30° from the set angles and, following examination, were deemed to be erroneous data entries and discarded. Five of the discarded cases were errors in plane identification (for example, AA was reported rather than AF) while the other four discarded values were off by 45–50° and uncharacteristic of the observer's other responses.

Absolute values were used for all negative angle estimates so as to express estimates as UAEAs (angles relative to the line of gravity).

For each observer, estimated angles from all observed images were plotted with respect to set angle for both AA and AF planes. For each observer, i, mean algebraic (
                           
                              
                                 X
                                 ¯
                              
                              i
                           
                        ) and mean absolute (
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 
                                    i
                                    
                                    a
                                    b
                                    s
                                 
                              
                           
                        ) errors were calculated between the observed and set angles at each set angle: 
                           
                              
                                 
                                    
                                       
                                          X
                                          i
                                       
                                    
                                    ¯
                                 
                              
                              =
                              
                              
                                 
                                    ∑
                                    1
                                    n
                                 
                                 
                                    
                                       
                                          (
                                          
                                             o
                                             b
                                             s
                                             e
                                             r
                                             v
                                             e
                                             d
                                             −
                                             t
                                             r
                                             u
                                             t
                                             h
                                          
                                          )
                                       
                                    
                                 
                                 /
                                 n
                              
                           
                         ; 
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                    
                                       i
                                       
                                       a
                                       b
                                       s
                                    
                                 
                              
                              =
                              
                                 
                                    ∑
                                    1
                                    n
                                 
                                 
                                    
                                       |
                                       
                                          
                                             (
                                             
                                                o
                                                b
                                                s
                                                e
                                                r
                                                v
                                                e
                                                d
                                                −
                                                
                                                t
                                                r
                                                u
                                                t
                                                h
                                             
                                             )
                                          
                                       
                                       |
                                    
                                 
                              
                              /
                              n
                              
                           
                         , where n = number of observed images. Group mean algebraic (
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                        ) and mean absolute (
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 
                                    μ
                                    
                                    a
                                    b
                                    s
                                 
                              
                           
                        ) errors were calculated across all observers at each set angle in both planes.

A one-way random effects model was utilised at each set angle to partition the total variability of the observed error into the appropriate variance components: 
                           
                              
                                 E
                                 
                                    ij
                                 
                              
                              =
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                              +
                              
                                 α
                                 i
                              
                              +
                              
                                 ε
                                 
                                    ij
                                 
                              
                           
                        , where E
                           ij
                         is the algebraic error in the jth estimation for observer i; 
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                         is the algebraic mean error across all observers and estimates, αi is the random effect of observer on the algebraic error for i = 1, 2, 3 and εij is the residual error term, which contains the within-observer variability. The effects, αi and εij, were assumed to be independently and normally distributed, to have means of zero, and variances σ2
                        
                           BO
                         and σ2
                        
                           WO, respectively. Estimates of σ2
                        
                           BO
                         and σ2
                        
                           WO
                         were obtained by resolving the statistical model for s2
                        
                           BO
                         (between-observer variance) and s2
                        
                           WO
                         (within-observer variance).

The random effects models were fitted using the lmer function from the R package lme4 (
                        Bates et al. 2014
                        
                        ). Tests from the R package lmerTest were utilised to assess whether 
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                         was significantly different from zero, i.e. whether observers were biased from the truth (as determined using meticulous, assisted observation – c. f. Section 2.1). Since a test was made at each set angle, Holm's method was employed to correct the p-values (Holm, 1979) to reduce the risk of false positives due to multiple tests.

To assess whether all observers were equally consistent in estimating postures, Levene's tests were employed at each set angle to test for equal within-observer variance in posture estimation across observers. Again, Holm's method was used to correct the p-values for the purpose of controlling the family error rate.

To assess whether observers were similarly consistent at observing different set angles, Levene's tests were employed to test for differences in within-observer variances between each pair of set angles.

Together, these measures of consistency and bias were used to assess whether observers were equally proficient at observing different set angles.

@&#RESULTS@&#

None of the observers demonstrated a clear tendency to consistently under- or overestimate set angles for either AA (Fig. 3
                        A, Table 2
                         - Section I) or AF (Fig. 3B, Table 3
                         - Section I) postures. At the level of the individual observer and set angle, mean algebraic errors (
                           
                              
                                 X
                                 ¯
                              
                              i
                           
                        ) were typically less than 5° (Fig. 3; Table 2; Table 3) and the maximum mean algebraic error at any given set angle was 10.6° in AA (observer 1 at set angle 60°) and 9.5° in AF (observer 1 at set angle 120°). When summarizing the estimates from all observers across all angles, the mean error between the observed and set angles was also small: the mean algebraic difference was −1.7° for AA and −1.4° for AF; the mean absolute difference was 4.7° for AA and 4.5° for AF.

Mean errors across all observers at each set angle are given in Tables 2 and 3 for AA and AF, respectively (
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                        ), and show that the mean algebraic error was less than 2.5°, and thus arguably small, in all but four cases: AA 30°, 60°, 150° and AF 120°. Even at the set angles that were most poorly estimated (as seen from the largest 
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                         values – i.e. AA 60° (7.1°) and AF 120° (5.9°) – the error was still not significantly different from 0 (p = 0.36 and p = 0.90, respectively; Tables 2 and 3, p (
                           
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                 
                                 μ
                              
                           
                         = 0) row). Given the minimal variability between observers in postural estimates, we present the p-values in these tables with some hesitancy and urge caution in interpreting the seemingly significant values for AA 30°, 150° and AF 90° as even very small effects can reach significance when the variability of the data is small.

Considering these data in conjunction with Fig. 3, we found insufficient reason to develop equations for use with observational estimates of UAEA made under ideal viewing condition to adjust for the apparently small error with respect to true angles.

Levene's tests for equal within-observer variance showed observers, in general, did not differ in the dispersion of their postural estimates, regardless of plane or set angle (Table 4
                        ); this is also evident in the reasonably consistent vertical spread across observers at each set angle (Fig. 3). A significant difference was seen between observers in the dispersion of AA and AF estimates at 0°, which appears to be driven by the complete lack of variability between estimates by observer 3 (Fig. 3, blue markers) compared with the small amount of variability made by the other two observers. A difference was also seen in AA 60° estimates, which appears to be driven by the somewhat larger variability in estimates from observer 3 compared to the other two observers.

The planned assessment of whether observers were similarly consistent at observing different set angles via the use of repeated Levene's tests assumed equal variances across observers at each set angle. While this was shown to not strictly hold at 0° or 60° AA, the assumption proved valid at all other test angles (cf. Section 3.2.). Accordingly, we proceeded with the planned analyses.

Within-observer variance was significantly different at 0° and 90° compared to all other AA (Table 5
                        ) and AF (Table 6
                        ) angles. The smaller within-subject variances at 0° and 90° (Tables 2 and 3) indicate a higher precision of observation at these angles; the difference is also evident in Fig. 3A and B. Together, the increased precision and the very high accuracy obtained at 0° and 90° indicate observers were more proficient at estimating these angles compared to all other set angles.

Observers were also differently consistent when estimating 60° arm elevation postures compared with 15° (AF), 45° (AA and AF), and 120° (AF); Tables 5 and 6 Estimates at 60° had higher magnitudes of within-observer variability and larger mean errors (Tables 2 and 3 - s2
                        
                           WO
                        ,
                           
                              
                                 
                                    
                                       
                                          
                                          X
                                       
                                       ¯
                                    
                                 
                                 μ
                              
                           
                        ; Fig. 3) indicating observers were less proficient at estimating this angle.

@&#DISCUSSION@&#

Our data demonstrate that estimates of upper arm postures by observation from still images taken under ideal conditions, i.e. images with good lighting, no visual obstructions, no baggy clothing, camera at 90° to the segment angle, and strictly planar arm postures performed with an upright trunk (thus providing a built in 0° reference angle to which arm postures could be compared), showed minimal error with respect to ‘true’ upper arm elevation angle (UAEA) determined via meticulous, assisted observation. At the level of the individual observer, mean error was typically less than 5° across the range of tested postures; across observers the mean error was less than 2°. In general, observers did not differ in the magnitude of uncertainty across their estimates at a given angle, and no consistent pattern of over- or underestimation at specific angles was evident. Thus, we deemed the small error between mean observed values and true angles was not sufficiently meaningful to warrant calibration efforts. Pooled data across observers showed observers were more consistent and less biased (i.e. more proficient) when identifying 0° and 90° than all other set angles; conversely, observers were less proficient at correctly identifying 60° UAEA postures.

The lack of notable, meaningful bias in observed UAEAs may only be representative of observations made under ideal conditions. Increased error and/or bias may result when observing non-planar elevation angles, partially obscured data, workers wearing bulky clothing, and/or when several non-ideal conditions occur together as typically happens in field collected video from workers performing actual work tasks. UAEAs observed at 45° to the plane of movement had an absolute mean error of 8.2° (flexion/extension) and 10.9° (ab-/adduction), which was only 2–3° higher than the planar observation mean errors (6.3° and 8.8°, respectively) (Qu et al., 2012). While these differences were not large, no information was provided regarding the composition of the respective error terms, and thus we do not know how the less ideal viewing angles specifically affected bias. Observation of still images taken from video recordings of hairdressers during actual work (non-planar actions with a potential for visual occlusion, but with reasonably good lighting and not overly baggy clothing) showed observer estimates of mean upper arm angles over a 30 min clip were only 0.2–1.9° higher than mean INC angles recorded simultaneously ((Rezagholi et al., 2012) – table A3, WS-15 and WS-120 strategies). It is important to bear in mind that the errors reported in this study are for a mean angle exposure estimate averaged over either 120 or 15 frames (for WS-15 and WS-120, respectively) and over the full range of angles occurring in the job, not for an individual frame at a particular set angle as in the current study. Still, the magnitudes of error appear similar to those in the current study, suggesting that observation data are, on average, reasonably correct if made on field data recorded under less ideal, yet still favourable visual conditions. It remains unknown, however, whether even more difficult viewing conditions will result in bias, such as when observed workers wear bulky clothing, interact with their surroundings so that body parts may become partially or fully obstructed, and perform dynamic tasks so not all movements occur perpendicular to the camera (Trask et al., 2015). Under such circumstances, it seems reasonable that an observer would base ratings on prior knowledge of how the job is typically performed, resulting in increased error, increased differences between observers in ratings, and increased uncertainty within each observer. Observer training may also play a key role in the eventual magnitude of potential bias (van der Beek et al., 1992; Denis et al., 2002) and should therefore also be considered.

Within- and between-observer variance is also crucial to consider when evaluating the attractiveness of observation as an exposure assessment tool. While many studies have reported data on agreement within and between observers, only one, to our knowledge, reported estimates of within- and between-observer variance. In that study, four observers made repeated estimates of UAEAs on video from hairdressers and found an average mean exposure angle of 30.9° using a work sampling method observing one frame every 15 s (WS-15 method (Rezagholi et al., 2012). Variance values both within (39.6) and between (2.4) observers were similar to those seen in the current study, averaged across set angles and planes: s2
                     
                        WO
                      = 34.8, s2
                     
                        BO
                      = 5.6. The hairdresser variance components were based on average UAEA estimates across 120 observed frames, while our current data reflect the variance when observers assessed single frames. We analysed data from the hairdresser study to assess the variance of single-frame estimates, and again, values of within- (57.2) and between-observer (1.7) variances were remarkably similar to our present results. This agreement suggests that under favourable (if not ideal) viewing conditions in the field, observers are similarly proficient in assessing upper arm elevation postures as under ideal laboratory conditions. We hypothesise that individual observers will become less consistent as observation conditions become less favourable. The extent to which specific factors affect an individual observer's consistency as visual conditions become increasingly less optimal or observed tasks become increasingly complex is still unknown. It is also unknown to what extent differences between observers will grow in less favourable conditions. It is possible that training of observers to ensure consistent decision criteria may minimise between-observer variance. Similarly, exposing observers to the working task to ensure a consistent understanding of the work being observed may also serve to improve inter-observer agreement.

We have deemed the magnitude of algebraic error in the current study to be ‘small’ and therefore acceptable at the level of both the individual observer (mean error typically less than 5°) and across observers (the mean error less than 2°). Arguably, the magnitude of acceptable error will vary with the purpose of a study. Differences of up to 10° may be acceptable for contexts such as crude screenings of hazardous postures (Trask et al., 2015). Conversely, when attempting to compare results between studies, determine the effects of ergonomic interventions, or establish exposure–response relationships, a much smaller margin of error would likely be desired than 10°. It is important to bear in mind that the error margins reported in this study are a mean of error values for repeated assessments of individual frames of data at a given set angle: typically 10–20 frames were observed by each observer for each set angle. If only one observation was considered for a single observer, the errors could be much higher. For example, the range of values estimated by the three observers for 30° UAEA (AA and AF) were 12–45°, 26–42° and 17–50° for observers 1, 2, and 3, respectively. Expressed in terms of a prediction interval for single observations, there is a 5% likelihood that a ‘true’ angle of 30° will, for example, be estimated by observer 1 to be less than 13.2 or larger than 46.8°. This considerable uncertainty at the level of single observations underlines the low precision of observation relative to inclinometry, and the necessity to collect sufficient amounts of data in observational studies (Mathiassen et al., 2013).

When holding a static posture, postural sway will occur. Some minor sway may have occurred during the very short time between the removal of the projected axis system and the snapping of the photograph, and thus the posture in the observed image may have deviated slightly from the intended ‘true’ posture. We claim any deviations were very small given the meticulous assisted observation approach used to position subjects in ‘true’ angles and the clear instruction to subjects to maintain the position during the short window in which the photograph was taken after the projected axis system had been removed. We acknowledge postural sway as a contributing source of error between observed and ‘true’ angles, but we believe that it is unlikely that the minor postural sways would result in bias as sway would be expected to occur symmetrically about the true, meticulously controlled posture. Postural sway could inflate within-observer variability as an observer would attempt to estimate slightly incorrect angles from the photos, but would not affect between-observer variability since all observers rated images from the same set of 570 photos (38 photos at each of the 15 set angles). There is no reason to believe that the magnitude of sway will vary at different postures, and thus any potential effects on the size of observer variability caused by photos showing angles which deviated slightly from the truth due to postural sway induced errors cannot explain the major findings of the study – that is, that observers are not equally proficient at estimating different set angles and thus demonstrate differing amounts of uncertainty and bias at different observed postures. To that end, given the very good agreement between ‘true’ and observed angles at 90°, and assuming the amount of sway at 90° was similar to all other postures, our empirical results confirm that postural sway had only very small effects, if any, on our findings.

In the introduction we raised the question of whether inclinometer (INC) data should be considered as a ‘gold standard’ to which other data are validated. Findings of the current study indicate observation data made under ideal visual conditions do not appear to be biased to the same extent as was shown for INC data: across the same testing range, INC data underestimated true set angles by an average of approximately 10°, with even larger underestimates seen for postures over 60° (Jackson et al., 2015). However, where all observers demonstrated a quantifiable within-observer variance at all set angles, the imprecision associated with repeated INC measurements at a set posture is negligible (Hansson et al., 2001). Thus, selecting between the two alternatives of observation and inclinometry presents a bias-variance trade-off decision. In our previous study we showed that calibration of INC data was effective at minimising the bias occurring during upper arm elevation assessment to, on average, less than 1° (Jackson et al., 2015). This adjustment, however, will itself introduce uncertainty to the calibrated INC data, since the calibration equation is determined by a regression procedure associated with residual variance (Teschke et al., 2009). If, however, the uncertainty introduced by calibration does not approach the magnitude of within- and between-observer variance of observation, it seems reasonable to suggest that adjusted INC upper arm elevation data could be a more efficient approach for data collection than observational studies of the size required to obtain a similar precision of the resulting exposure estimate (Mathiassen et al., 2013).

Data showed observers were significantly better at observing 0 and 90° angles. This finding is in line with the so called ‘Goldmeier effect’ which states that humans have an excellent ability to identify normal right angles (Ferrante et al., 1995). This finding is also in agreement with the decreased magnitude of error previously reported by Qu et al. (2012) and Covalla (2003) at these postures. Interestingly, our data also showed that observers were more uncertain in their estimates and had higher mean algebraic and absolute error estimates at 60° arm elevation – a finding also reported by Qu et al. (2012). Given the regular use of a 60° cutoff to identify upper arm postures associated with increased risk of musculoskeletal disorders (Armstrong et al., 1982; Persson and Kilbom, 1983; Kilbom et al., 1986; van der Beek et al., 1992; Wahlström et al., 2010; Andrews et al., 2012), correct identification of 60° is arguably more important than proficiency at other angles. This angle has also recently been recommended as an optimal cut-off angle in the proposed upper arm posture classification categories (NIOSH, 2014). In the current study, observers were asked to estimate angles to the nearest 1°. Whether or not the increased variance we saw in observers' repeated estimates of 60° upper arm elevation postures would also manifest as increased variance in correct bin matching for angles of approximately 60° is unknown, but is a question worth pursuing given the regular use of postural observation methods which employ binning.

@&#CONCLUSION@&#

Observers were found, on average, to be virtually unbiased in their estimates of upper arm elevation angles made under ideal conditions with mean algebraic errors across all observers below 2° for all of the tested angles. Observers proved most proficient at 0° and 90°, and least proficient at 60°. Empirical values presented for the magnitude of within-observer variance underlined the risk of relying on single observational assessments: all observers showed substantial inconsistencies in repeated estimates at a given set angle; thus repeated observation efforts are required to provide a reasonable approximation of the truth. The within-observer variance was very similar for all observers – i.e. no one particular observer was closer to the truth on each observed frame. Further, observers agreed, on average, in their posture ratings at a given angle, as evident from the small between-observers variance, indicating that, under ideal viewing conditions, the specific individual selected to perform the observations may not be of particular importance. When high precision of posture estimates is required and repeated observational estimates of ideal images are not feasible, a technical method for posture assessments may be preferable.

The present study was supported by a grant from the Swedish Research Council for Health, Working Life and Welfare (Forte Dnr. 2009-1761).

@&#ACKNOWLEDGEMENTS@&#

The authors are grateful to Mikael Forsman and Jens Wahlström, who assisted the lead author in launching the overall study and for all their work with the data collection during which the image data were obtained.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Recognizing and regulating e-learners’ emotions based on interactive Chinese texts in e-learning systems

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A textual interaction based emotion recognition research and application framework.


                        
                        
                           
                           Defined an e-learner oriented emotion category by the questionnaire survey.


                        
                        
                           
                           Presented the active learning strategy for emotion recognition and regulation.


                        
                        
                           
                           A two-phase cost-sensitive emotion classification combining with topic detection.


                        
                        
                           
                           A case based reasoning instance recommendation for e-learner emotion regulation.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Sentiment classification

Interactive Chinese texts

Feature extraction and selection

Emotion regulation

E-learning

@&#ABSTRACT@&#


               
               
                  Emotional illiteracy exists in current e-learning environment, which will decay learning enthusiasm and productivity, and now gets more attentions in recent researches. Inspired by affective computing and active listening strategy, in this paper, a research and application framework of recognizing emotion based on textual interaction is presented first. Second, an emotion category model for e-learners is defined. Third, many Chinese metaphors are abstracted from the corpus according to the sentence semantics and syntax. Fourth, as the strategy of active learning, topic detection is used to detect the first turn in dialogs and recognize the type of emotion in the turn, which is different from the traditional emotion recognition approaches that try to classify every turn into an emotion category. Fifth, compared with Support Vector Machines (SVM), Naive Bayes, LogitBoost, Bagging, MultiClass Classifier, RBFnetwork, J48 algorithms and their corresponding cost-sensitive approaches, Random Forest and its corresponding cost-sensitive approaches achieve better results in our initial experiment of classifying the e-learners’ emotions. Finally, a case-based reasoning for emotion regulation instance recommendation is proposed to guide the listener to regulate the negative emotion of a speaker, in which a weighted sum method of Chinese sentence similarity computation is adopted. The experimental result shows that the ratio of effective cases is 68%.
               
            

@&#INTRODUCTION@&#

An e-learning system, including real-time class subsystem [56] and intelligent personalized learning recommender subsystem [27] is an open and networked platform full of multimedia and digitalized learning resources, which is a second classroom for continuing education and inquiring about knowledge. However, paying attention to e-learners’ cognition rather than their sentiment is dominated due to the space and time separation between students and teachers. 1-to-N teaching mode is the dominating mode in the classic educational scenarios, such as real-time class and online question–answering, in which teachers are very easy to be distracted from teaching if they concentrate more on each e-learner’s emotional state. Thus, a teacher must limit his/her desire to follow the e-learners’ emotions. As a result, the lack of affective interaction between students and teachers seriously affects the learning process, causes learner emotional illiteracy, and decays their learning enthusiasm.

In many recent works, psychologists and neurologists pointed out the important role of the motivation and affectivity in cognitive activities, such as learning. Psychologists and pedagogues pointed out the way that the emotions affect learning. Researchers of computer science in education field had studied techniques of artificial intelligence in order to make the educational systems more customized for the affective states of students [18].

Affective computing is proposed by Picard in 1994, and her work introduces affective computing techniques into the intelligent education environment, such as detecting learners’ frustration and correcting their emotion [35,21]. According to Picard’s definition [35], an affective (computational) system must have the capacities to recognize, express, and possess emotions. Inspired by Picard’s work, many education-related affective researches [4,1] were carried out. To solve the problem of lack of affective interaction, researches have involved four kinds of major techniques, human–machine interaction, emotion category, emotion recognition method, and emotion regulation means.

In the field of human–machine interaction, Rodrigo et al. [39] built a software agent to study the affective states exhibited by students, and emphasized on the affective states and transitions between affective states. Huang et al. [14] analyzed the emotion model for designing learning companion agent. Chao et al. [5] built an affective interface with an animated agent to achieve the human–machine interaction function of affective feedback in intelligent tutoring systems. All these works focused on making machine understand one side emotion and pay little attention to understand the emotions of the two interacted parties (such as teacher–student or student–student in an e-learning environment).

There are many emotion categories [35] in the field of affective computing. Besides the four most common types, fear, anger, sadness and joy, which are accepted widely, Plutchik’s [36], Izard’s [17], and Paul Ekman’s [9] are the three popular emotion categories, but more researches on e-learner oriented emotion category need to be done due to its application-specific feature.

In the field of emotion recognition, on the one hand currently many researches focused on recognizing e-learners’ emotional states from various biological signals [2,55]. For example, D’Mello et al. [7] adopted various biological signals, such as facial expression, heart beating, and body temperature, to determine the feelings of students; Heraz and Frasson [13] analyzed brainwaves to classify emotional states. On the other hand, some researchers noticed the importance of text-based affective computing. Liu [24] adopted natural language processing technology to determine the attitude of a speaker or a writer with respect to some topic. From the viewpoint of methods for text oriented sentiment classification, most existing works [15,20,24,26,28,25,3,37,42,54,50,57,10] employed machine-learning techniques, like Decision Tree, Naive Bayesian models and Support Vector Machines (SVM), to perform sentiment classification. For example, Sriram and Yuan [42] adopted a customized decision tree algorithm to identify six emotion types (anger, disgust, fear, joy, sadness, and surprise) in text. Liu et al. [25] focused on the sentiment analysis on movie rating and reviews in a mobile application environment by using SVM, and believed that SVM is a state-of-the-art method. Wang et al. [50] applied SVM and Multinomial Naive Bayes to emotion identification on Twitter and evaluated many features, such as word-net lexicon, POS, and bags of words. Gokulakrishnan et al. [10] adopted six classifiers, including Complement Naive Bayes, SVM, J48, and Random Forest to recognize twitters’ emotions. Khan et al. [20] carried out a task of comparison among some popular classification methods, such as SVM, Naive Bayesian Classifier, Maximum Entropy, Decision Tree, and Neural Network. In addition, Zhao et al. [57] combined the methods of conditional random field with the characteristics “contextual dependency” and “label redundancy” in sentence sentiment classification. These methods generally perform well on topic-related and chapter/document-level sentiment classification, but all existing works do not perform well on the dialog-like interactive Chinese texts, while the interactive texts characterize with not only the richness of short sentences and phrases, but also interactivity and non-linguistic symbols.

In the field of emotion regulation means, many researches adopted a software agent to “talk” or play music and cartoons in order to regulate students’ negative emotions [39,21,4]. For example, D’Mello and Art [6] built an affective autotutor to help students Learn by talking with cognitively and emotionally intelligent computers that talk back. Iovane et al. [16] proposed a model to represent and manage affective/emotional feedback in order to form a methodology through the steps that lead us to the identification and quantification of the emotional state of a learner.

In general, we have found that the existing researches paid little attention in applying the affective computing technology to help the two interacted parties (such as teacher–student or student–student) understand their emotion in the interactive Chinese text-based applications. In e-learning systems, there are some typical teaching scenarios: online question–answering scenario, real-time Internet classroom, and group discussion in a special forum, among which it is difficult to understand each other’s emotions over the Internet without face-to-face communication. If every e-learner is equipped with detecting devices, the large quantity of cameras and wearable devices may cause high cost and inconvenience to the users. With recent achievements in natural language processing and psychology, it is believed that lots of interactive textual data exist in the e-learning systems which can help us understand the e-learners’ emotions. We can imagine that, during group discussion, other students could know a student’s interest and emotion after he/she typed a sentence parsed and analyzed by affective computing techniques. This is the goal of this paper.

For achieving this goal, in e-learning systems, the first thing is to enhance the mutual perceiving and understanding of the e-learners’ emotions, and to guide the teacher/e-learner’ friends to adjust the e-learner’ negative emotion through interactive textual messages, but conventional affective computing applications are focused on making machine affective/emotional. Second, the interpersonal and intrapersonal emotions state that the e-learner related emotions, such as anxiety, anger and frustration, sympathy, should be introduced. Third, the basis of recognition in our research is the interactive text in e-learning systems, while conventional researches are based on facial expression, gesture, bio-information, and images. Therefore, the interactive Chinese text-based emotion classification methods should be studied to detect and recognize the e-learners’ emotions. Finally, a text-based emotion regulation method should be designed. Conventional approaches lack emotion regulation strategies for his/her teacher/friends to help the e-learner, who is in a negative emotional state.

Aiming at the above mentioned issues, we propose an e-learner affective category model acquired by questionnaires and previous models [17,36]. Based on the model, we present a research and application framework on recognizing the e-learners’ emotions from interactive Chinese texts. Furthermore, we exhibit some initial experiment results to illustrate how our method works, and propose the case-based reasoning for emotion regulation instance recommendation to emulate the active listening strategy.

The rest of this paper is organized as follows. Section 2 introduces related works such as basic concepts, emotion categories, computational models of emotion, and emotion regulation rules. A research and application framework is shown in Section 3. Following which, the e-learners’ emotion category, model, affective word base, affective computing rules, and syntax features are introduced in Sections 4 and 5, respectively. Methods of classifying the e-learners’ emotions and its experiment are described in Section 6, while the case-based reasoning for emotion regulation instance recommendation is presented in Section 7. This paper is concluded and the future work is showed in Section 8.

Note:
                        
                           •
                           Two words, “speaker and listener”, used in the following sections, should be distinguished from their original meanings. In this paper, a speaker is a person who sends textual messages, while a listener is a person who receives the message sent by the speaker. We would like using “speaker and listener” rather than “sender and receiver”, because a receiver receives a textual message from a sender without detecting and regulating emotion.

We focus on Chinese texts due to two reasons: (1) only Chinese is chosen, other languages are still not on our schedule because this will distract us from the focus of our research and (2) multi-national and cultural background of e-learners will not be considered in this paper, although many researchers believe that culture has influence on emotion.

@&#RELATED WORKS@&#

Affective computing is a branch of artificial intelligence that deals with the design of systems and devices that can recognize, interpret, and process human emotions. It is an interdisciplinary field spanning computer sciences, psychology, and cognitive science. Before introducing our research, some concepts and the related key techniques are shown in this section.

Emotion is the mental and physiological state associated with a wide variety of feelings, thoughts, and behavior, which includes the individual feeling of inside and outside. Sentiment holds the same meaning of emotion in the field of sentiment analysis which refers to a broad area of natural language processing, computational linguistics, and text mining [24].

A similar concept, “mood”, should be mentioned. Generally, mood is a relatively long-lasting emotional state. Moods differ from simple emotions in that they are less specific, less intense, and less likely to be triggered by a particular stimulus or event [44].

Affect refers to the experience of feeling or emotion, especially, a tender feeling toward another, in the view of psychology [49].

Sentiment, emotion and affect share the same definition in this paper, while there are still different explanations in various fields, such as affective computing, psychology, and artificial psychology.

There are many emotion categories. Picard [35] mentioned that there are 2–20 basic emotions and the most common four types are: fear, anger, sadness, and joy. Plutchik [36] distinguished eight basic emotions: fear, anger, sorrow, joy, disgust, acceptance, anticipation, and surprise. Some researchers used the Paul Ekman’s emotion category [9] that is often adopted in facial expression recognition related applications. Some used Izard’s emotion category which includes 10 types of emotions [17].

As mentioned earlier, affective computing focuses on applications. Many applications, like intelligent tutor [7], emphasize on recognizing and understanding emotions of a user by a computer, and build their own emotion category or adopt the emotion category of others [34]. Our research focuses on text-based applications in e-learning systems. Thus, we need to develop a suitable emotion category of an e-learner. A similar research shows academic emotions of students, which includes the emotion of joy, enthusiasm, hope, relief, pride, admiration, sadness, anger, anxiety, hopelessness, shame-and-guilt, disappointment, boredom, envy, contempt, and surprise 
                        [33]. However, it lacks clarity in the number of kinds of emotions expressed by e-learners through textual information, and fails to explain whether they have influence on e-learners, especially in interactive text-based e-learning environments. The detailed information will be discussed in Section 4.

On the other side, there is a debate about the purity of basic emotional states [34]. For example, Plutchik [36] stated that any emotion can be described by a mixture of the basic emotions. This issue is investigated through a series of questionnaires in this paper.

Computational model of emotion, also called affective computing model in some literatures, can be divided into three types: the computational model for discrete state, the computational model for emotion space, and the rule-based model [34]. The most widely accepted computational model for discrete state is the Hidden Markov Model (HMM), which is proposed by Picard [34] and is applied to predict the user’s emotion. The OCC model, a kind of rule-based model, is also adopted by some researchers as their emotion model [18]. Watson and Tellegen’s Circumplex Theory of Affect is a well-known computational model for the emotion space with two major bipolar dimensions: positive affect and negative affect. Positive affect reflects a combination of high energy and positive evaluation, while negative affect comprises feelings of upset and distress [43].

Until now, most researchers paid attention to users’ emotion model for HCI. As we know, affective computing is application-specific. Consequently, more tractable and understandable models for e-learners should be considered, which is out of the topic in this paper.

There are many methods of emotion detection and classification, which process and analyze the facial expression [21,30], body gesture [19], speech [23,2,55,10], and multimodal-based methods [53] to classify the user’s emotion.

Recently, text sentiment-oriented analysis gets more attention [37,24,26,54,28,15,25,42]. From the viewpoint of methods for sentiment classification, most existing works employed supervised machine-learning techniques, like Naive Bayesian models, Artificial Neuron Network (ANN), Decision Tree and Support Vector Machines (SVM), to perform sentiment classification, and their results showed that the SVM algorithm performs better. For example, Wang et al. [50] applied SVM and Multinomial Naive Bayes to emotion identification on Twitter and evaluated many features, such as word-net lexicon, POS, and bags of words. Bai [3] introduced a heuristic search-enhanced Markov blanket model to capture the dependencies among words, and then used Naive Bayesian Classifier based on the multivariate Bernoulli distribution, SVM, the voted perceptron and a maximum entropy conditional random field learner to train the classification model for the binary and multiclass emotion classification on movie and news. Khan et al. [20] carried out a task of comparison among some popular classification methods, such as SVM, Naive Bayesian Classifier, Maximum Entropy, Decision Tree, and Neural Network. In addition, Zhao et al. [57] combined the methods of conditional random field with the characteristics of “contextual dependency” and “label redundancy” in sentence sentiment classification. Currently, many researches recognized the emotions from English/Chinese text, but their emotion categories were relatively coarse with three kinds: neutral, positive (happiness), and negative (sadness), which may not be suitable for the e-learner and emotion regulation because there are many kinds of emotions that may affect the learning efficiency.

Moreover, the emotion classification is applied into texts of various styles. For example, Durant and Smith [8] tried to analyze the opinions based on political web logs by using Naive Bayes classifier and SVM. Now, Chinese is a popular language chosen by researchers. For example, Liu et al. [26] proposed a dynamic sentiment words polarity adjustment algorithm based on the context information to implement the task of sentiment classification for Chinese documents. But paragraphs or documents, instead of sentences or turns, were focused on in the above-mentioned researches.

A few researchers realized the importance of sentiment analysis on short text or sentence level in interactive Chinese text applications. Thelwall et al. [45] extracted sentiment strength from informal English text and used new methods to exploit the de facto grammar and spelling styles of cyberspace. In sentence level sentiment analysis, Wang and Fu [51] proposed a fine-to-coarse strategy for Chinese sentence-level sentiment classification based on sentiment dictionary. These researches may not be suitable for interactive Chinese texts in e-learning systems, because the dialog-like interactive Chinese texts characterize with not only the richness of short sentences and phrases, but also the e-learner-used lexicon and the e-learner-oriented emotion category.

Failure to manage one’s emotions may have profound effects, including decreased productivity and inability to concentrate [21,11].

Fortunately, humans possess skills and strategies for emotion regulation that can mediate frustration levels to varying degrees [21,11]. Emotion regulation, which also described as emotion self-management, is once an aptitude and a skill for modulating and managing one’s emotional state. It has been identified as the primary component of emotional intelligence, which contains a set of essential emotional skills, whose development have been argued to correlate more to IQ with a person’s success in life [21,40].

According to Klein’s summary, there are two kinds of emotion regulation approaches: the social approach and the computer-based approach [21].
                           
                              •
                              In the social approach, there are two kinds of support for emotion regulation: passive support and active support. Passive support is used by people to manipulate moods, without necessarily addressing or discussing the emotion itself. It includes media, activities, food and other substances. Interactions with people can fall into active support. Active support occurs when people discuss or address their emotions (and the emotion elicitors) directly, by means of managing them.

The computer-based emotion regulation approach, especially in recent HCI applications, is applied by means such as playing comedy cartoons or soft/favorite music to adjust the user’s emotion.

It is believed that talking to parents or close friends about what is the reason for being upset and how that makes the person feel is a good way to regulate people’s emotion [11]. The active listening approach [31,32] is perhaps the best acknowledged example of providing active support. It can be described as providing sincere, non-judgmental feedback to an emotionally distressed individual, with a focus on providing feedback of the emotional content itself. Active listening is rooted in social psychology [38], but one does not have to be a psychotherapist to practice this skill [21]. The tone of effective active listening feedback reflects their attitude like sympathy or empathy, and conveys that the person’s emotional experience is understandable and acceptable. When active listening is practiced with these attributes, it is effective to relieve strong, negative emotional states quickly and efficiently in the context of HCI [21].

But the problem is what the active listener should do or how the active listener should be. For example, when an e-learner complains that the content of study material is too hard for him/her, whether a listener should say as “I understand what you are going through, this is how I would feel in your situation.” How can the computer help us to do it in textual interaction applications will be discussed in this paper.

Based on the above five subsections, the main difference between our research and theirs can be concluded that our method: (1) focuses on the e-learners’ emotion category. the set of emotional state is extended with the e-learner related emotions, such as “anxiety,” “sympathism,” “shame-and-guilt,” and “inhospitality.” In addition, the interpersonal and intrapersonal emotion category is considered, which means the mutual interaction of the e-learners’ emotions. A by-product is that it is validated through the questionnaire that the mixture of the basic emotions in one sentence exists in textual interaction applications; (2) emphasizes on supporting technology of the e-learner’s emotional interaction. Some researchers identified the user’s emotion from texts or sentences in HCI application, while we emphasize on recognizing the emotional state of a speaker and giving listeners support on active listening strategy in order to enhance their effective communication, even to regulate their emotion; (3) analyzes interactive Chinese texts which are characterized by richness of emoticons, short and abbreviation; and (4) has a low cost. Currently, some researchers aim at building an intelligent tutoring system with expensive equipments and technologies, such as visual computation, physiological signal processing, and while our method only relies on what e-learners type on the keyboard.

Aiming at reducing emotional illiteracy in e-learning systems, we strive to identify the e-learners’ emotions in online communication and give his/her listeners advices on emotion regulation instances when he/she is in unexpected emotions.

As described in Section 2.5, active listening is an effective approach to regulate one’s emotion in real life. We believe that the computer can play an important role in regulating the e-learner’s emotion if it adopts/imitates active listening strategy. [29] stated that the active listening strategy includes four steps, (a) listen, empathize, and communicate respect; (b) ask questions and ask permission to take notes; (c) focus on the issues; and (d) find a first step. For a computer, the first thing is to listen, which is to detect the e-learners’ emotional state; and then, identify the issues, and take a first step to help the e-learners.

Inspired by affective computing and active listening strategy, we design our research and application framework as shown in Fig. 1
                     .

As shown in Fig. 1, there are four research tasks for off-line learning process. The first is to categorize the e-learners’ emotion. The second is to represent and extract emotion feature from the corpus collected from the Internet. The third is to compare between emotion words and measure the intensity of every emotion word in each emotion category. The fourth is to collect emotion regulation instances and extract its feature in order to build an emotion regulation case-base and support its on-line application. After off-line learning process, two kinds of databases, emotion words and syntax database, and emotion regulation casebase are obtained.

As for online applications, a text-oriented emotion classification method with active learning is applied to identify the e-learner’s emotion after he types a sentence, which is the listening step in active listening strategy. Furthermore, the case-based reasoning algorithm is adopted to recommend a similar emotion regulation instance such as a text-based advice, when the e-learner’s emotion is in an unexpected state such as boredom, frustration, and fury. It imitates the steps of focusing on the issues and taking a step in active listening strategy.

Based on the academic emotions [33] and Izard’s 10-class emotion, we propose an initial emotion category model for e-learners. A questionnaire about the model is handed out to 200 college students at Xi’an Jiaotong University and Xi’an Telecommunication College. In the questionnaire, questions such as which kinds of tools are to be used, and which kind of emotions are to be expressed, are designed in order to obtain the students’ emotion, preference, and interest.

According to the investigation result and consultation with psychology experts, we proposes a refined emotion category model for e-learners, which is shown in Table 1
                     .

In Table 1, the emotion types from the 1st row to the 3rd row are the interpersonal emotional states, while emotion types from the 4th row to the 7th row are the intrapersonal states that the e-learner expresses the emotion himself/herself. The middle column indicates that “neutral” between positive emotions and negative emotions, which means a smooth and peaceful emotional state. Note that a emotion type, astonishment/surprise, is not listed in Table 1, but is included in our emotion category. In our e-learners’ emotion category, some basic emotion types, such as “anxiety,” “sympathism,” “shame
                     +
                     guilt,” and “inhospitality,” are different from the most common category [34], because our category reveals the characteristic of the e-learning applications.

To detect emotions in sentences, a rule-based method is adopted, in which the affective words, syntax features, and computing rules are recognized.

Our interactive Chinese text corpus is composed of three parts: (1) about 59M collected from the BBS of Xi’an Jiaotong University; (2) about 1M of chat logs in our lab collected from the instant messaging tool QQ; and (3) about 3.2M collected from the online admission advisory system of Xi’an Jiaotong University. Based on the analysis of the corpus, an affective word base with the size of 4177 words is constructed, and its composition is illustrated in Fig. 2
                        .

Based on the e-learners’ emotion category, a series of questionnaires are designed, each questionnaire includes 20 affective words or less. An extensive testing is carried out 543 times and involved in 239 students, in which every person tested is asked to answer two questions for each affective word: which kind of emotion class this word belongs to (note that multiple choice is allowed), and which level the emotion that this word belongs to, if you use it to communicate with others on the Internet. Note that the range of intensity [−1,1], is divided into 21 discrete levels.

After weighted average statistics, all of these words are sorted and marked according to the e-learners’ emotion category in Table 1.

Some examples selected randomly from our affective word base are shown in Table 2
                        . Note that some affective words show the combined emotional state according to our questionnaire results. Take the 5th row in Table 2 for an example, the word, “
                           
                         reveals” that the combination of basic emotional states, frustration and hopelessness, exists.

Based on the careful observation on annotated corpus, some affective computing rules are induced to compute the affection in a sentence. Some basic patterns of rules are shown in Table 3
                        . These rules take the combination of verb, adverb, adjective and noun into consideration. In Table 3, a “privative+verb” pattern can be considered as a logic operation on one type of emotion category indicated by verb. For instance, “
                           
                        ” (dislike) equals to “NOT” operation on “love” emotion. A “how+verb” means increase/decrease in degree on one type of emotion category indicated by verb. For instance, “
                           
                        ” (admire somebody very much) equals to the increase of degree for “adoring somebody.” It is obvious that there are complicated rules or combined patterns. For instance, “
                           
                        ”(not so good) is an instance of the “privative+how+adj” pattern.

Other important patterns, complicated or combined one, include “nounconjunction+noun” and “adj+conjunction+adj,” for example, “
                           
                         (dread and greedy) and 
                           
                         (guilty and ashamed).

The syntax features that e-learners used are the important indicator, which point out the kind of emotion that a speaker has or the kind of feeling that a speaker believe listeners have. In our research, we conclude some rules:
                           
                              •
                              The speaker’s name, nickname and pronoun are the most crucial, and some verbs are also important crucial indicator. An example is shown in last row of Table 4
                                 .

The indicator of subordinate clauses, such as “that”, “which” and “who”, can describe the complicated emotion or implied emotion. An example is shown in first row in Table 4. Some of the kind indicators are shown also in Table 4.

Experts believed that the age difference plays an important role in emotional discourse or on-line discussion. Li et al. [22] examined how age identities are presented in an on-line discussion forum for older adults. Does this actually happen in the interactive Chinese interaction? That is to say whether the feature age influences on interactive text oriented emotion classification. To verify this point, we do some experiments in the next section.

Identifying the e-learners’ emotions is a classification issue from the viewpoint of data mining. There are many algorithms for classification. For validating the proposed features and selecting classification method, we carried out two kinds of experiments. The first one, also called Experiment I, is to verify the emotion classification performance and whether the feature age influences on interactive text oriented emotion classification. Another one, called Experiment II, is to verify the active listening strategy based emotion recognition in interactive Chinese texts.

Note that (1) in Experiments I and II, the features, such as syntax feature, affective computing rules and affective word, are extracted and transformed from the labeled file into the .arff form, with class label (end of each line). This file with the .arff form can be used in Weka [12] and (2) the test option is set as the 10-fold cross-validation, when the selected algorithms run in Weka.

The steps in Experiment I are as follows:
                           
                              1.
                              Step 1: Collecting a corpus. A 1531-turn corpus (called MM_Corpus), collected from an on-line discussion group, mobile-multimedia, in QQ (a famous instant Chinese message tool). The division type and statistical data in terms of the feature age are shown in Tables 5 and 6
                                 
                                 .

Step 2: Generating datasets. According to Tables 5 and 6, we have several labeled data sets: MM_Corpus_TypeI_3Class, MM_Corpus_TypeII_3Class, MM_Corpus_TypeIII_3Class, MM_Corpus_3Class, MM_Corpus_TypeII_Neg5Class and MM_Corpus_Neg5Class. MM_Corpus_3Class and MM_Corpus_Neg5Class represent the dataset that do not have the feature age and labeled with three emotion types, positive, negative and neutral, or top-5 negative emotions, anxiety, anger, sad, and hopeless, respectively. MM_Corpus_TypeI_3 Class means that the dataset is produced by labeling data with three emotion types according to Type I age division. MM_Corpus_TypeII_3Class and MM_Corpus_TypeIII_3Class are the datasets similarly defined in Type II age division and Type III age division, respectively. MM_Corpus _TypeI_Neg5Class is the dataset with top-5 negative emotions in Type I age division.

Step 3: Carrying out the experiments. We selected sixteen algorithms, Bagging, LogitBoost, libsvm, Naive Bayes, MultiClass Classifier, J48, RBFnetwork, Random Forest, and their combination with the cost-sensitive classifier (denoted as Bagging_CSC, LogitBoost_CSC, libsvm_CSC, MultiClassClassifier_CSC, RandomForest_CSC, J48_CSC, Naivebays_CSC, and RBFNetwork_CSC), for validating the feature age’s influence on interactive text-oriented emotion classification.

The results of Experiment I are shown in Tables 7–9
                        
                        
                         and in Figs. 3–5
                        
                        
                        . For the task of recognizing three emotion types, positive, negative, and neutral, we found that:
                           
                              •
                              Obviously, in terms of weighted average indicators (see in Tables 7,8), the best classification performance is obtained on the dataset with the feature age, and Randomforest_CSC beat other algorithms (see the bold values in Tables 7,8).

It can be observed from Tables 7–9, that, with age division increasing, the classification performance of the selected algorithms shows varieties. For example, SVM’s performance remains stable, and the decision-tree-based methods (such as Random Forest), perform better, while the performance of RBFnetwork is decreasing.

Based on the above discussion, we can conclude that RandomForest_CSC beats other algorithms, and the feature age can help the algorithms improve their classification performance in the aspect of weighted average indicators.

Through a chat system in an intelligent e-learning platform constructed before [48], 527 dialogs, including 9957 sentences were saved in a “.txt” file. Then, considering that regulating the e-learners’ negative emotions is our goal and observing that an e-learner who types the first turn in one dialog is the target of emotion regulation, the first turn in each dialog is extracted, which forms our corpus, XJTU_Corpus. Then, each sentence in the corpus is parsed by ChineseParser, a Chinese words segmentation software developed by our lab.

Further, each sentence is labeled manually with the coarse emotion types and the five negative emotion types. The former, called as XJTU_Corpus_3class, includes neutral, positive, and negative. The latter, XJTU_Corpus_Top5NegClass, includes sad, anger, hopeless, anxiety, and disgust. The statistics of instances in the corpus are shown in Tables 10 and 11
                        
                        .

Considering that detecting the negative emotions is the goal of our research, two-phase experiment is designed. In the first phase, the coarse emotion types, including neutral, positive and negative, are identified from the sentence. In the second phase, the five negative emotion types, including sad, anger, hopeless, anxiety, and disgust, are recognized.

Through many experiments have been carried out, eight classic algorithms and their associated cost-sensitive classifiers are discussed in the following section. The eight classic algorithms and their combination with the cost-sensitive classifier are libsvm, Naive Bayes, MultiClass Classifier, J48, RBFnetwork, Bagging, LogitBoost, Random Forest, RandomForest_CSC, J48_CSC, Naivebays_CSC, and RBFNetwork_CSC.

After experiments are carried out in Weka, the results in the first phase are shown in Tables 12–14
                        
                        
                        , while the results in the second phase are shown in Tables 15–17
                        
                        
                        .

From Tables 12–17 and from Figs. 6–11
                        
                        
                        
                        
                        
                        , it can be observed that:
                           
                              •
                              On the aspect of weighted average measures, precision, recall, and F-measure, RandomForest_CSC achieve better performance on three emotion type oriented classifications (see the bold values in Tables 12–14), while Random Forest and RandomForest_CSC beat the other classification methods on the top-5 negative emotions (see the bold values in Tables 15–17).

When all things considered, RandomForest_CSC is the best of classification method on three emotion type, and it also performs best on classifying top-5 negative emotion types.

Because the target types are negative emotions, RandomForest_CSC is chosen for the coarse emotion classification and for the top-5 negative emotion classification according to the performance index shown in Tables 12–17.

In general, as shown in Tables 15–17, the recall values of some emotion types, such as “disgust” are lower. This is due to: (1) syntax errors and misnomers in interactive sentences give us many misleading signals; (2) the noise of the emotion words, which means that some emotion words do not convey affective information in some sentences; and (3) the sizes of these emotion types in the training and testing data sets are relatively small compared with the total dataset. To enlarge the size of emotion word base, more emotion features need to be detected from interactive texts of the bigger training data.

@&#DISCUSSION@&#

Comparing the results of Experiment I with those of Experiment II, we found that.
                           
                              •
                              for the task of classifying three coarse emotion types, RandomForest_CSC performs the best from the weighted average indictors, and RandomForest_CSC performs better on MM_Corpus_TypeI_3Class than on XJTU_Corpus_3Class.

the active listening strategy can help classification algorithms achieve better performance. Comparing the values of weighted average precision in Table 7 with those in Table 12, we can find that the performance of the selected algorithms on XJTU_Corpus_3Class is from 73.4% to 86.1%, while the performance of the selected algorithms on MM_Corpus_TypeI_3Class is from 53.2% to 62.7%. It seems that the classification performance can be improved if we can obtain enough corpus with negative and positive emotion and train on them after detecting more first turns.

In both tasks of classifying three coarse emotion types and top-5 negative emotion types, libsvm fails to win from the aspect of any indictor. To analyze the phenomenon of SVM fail to success further, it was found that, after sorted by information gain method, the top 50 features in the sorted feature list belong to syntax features rather than affective word base (lexicons). This means that, comparing with the syntax features, the weights of these affective words play weaker role in emotion classification.

Moreover, the syntax features result in many categorical variables in feature vectors and the phenomenon of value sparsity in high dimension feature vector is common, which is caused by the short sentences frequently used in the interactive Chinese texts. For example, the number of feature sets in Corpus_XJTU is 890, and 89% feature values for each turns are default (as zero). Therefore, we believe that the richness of categorical variables in feature vectors and the phenomena of feature value sparsity contribute to is that the tree-based methods perform better than SVM, RBFnetwork, and Naive Bayes.

As mentioned earlier, our goal is to emulate the four steps in the active listening. Obviously, in the first step of our approach, two factors, who-is-the-target and his/her-emotion-state, should be identified, because finding out who-is-the-target is very important, especially in the complex scenarios that are involved in many e-learners’ interaction, such as on-line group discussion and on-line Q&A. Observing that in a new event, the first turn in a dialog perhaps gives a way to find out who-is-the-target, an topic detection and tracking method proposed by [47] is used to identify new events and who-is-the-target. Then, his/her-emotion-state can be recognized by using the algorithm in Section 6, when he/she types a sentence. Thus the goal of the first step is achieved.

The second step is to record or take a note about what the speaker speaks. The computer can do it for us during interaction. Now the most important thing is to implement the third and the fourth steps.

The third step is to “focus on the issues,” which is the basis of the fourth step, “taking a step,” the core part of supporting emotion regulation instance recommendation. To achieve this goal, we must first obtain the emotion regulation instances for different emotion categories in various situations, which seems to be difficult. Fortunately, the corpus we collected includes some lively instances of the e-learners’ emotion regulation. For example, the e-learner complains that his supervisor criticized his report which he/she put much effort in. When he represents his upset in an online chatting room, many other users comfort him/her and give some counsel. Finally, the e-learner is free from his/her frustration and anxiety. Many instances of this kind motivate us to construct an emotion regulation strategy database.

Inspired by successful stories of emotion regulation, the constructed database are provided as materials for “taking a step” by teacher/listener. To support the similarity computation between the successful stories and current e-learner emotion affairs/events, the concerned affairs/events are summarized from these stories. The following section will discuss how it is achieved.

According to Pekrun’s research [33], academic emotions of students are related to their experience during study, such as test taking, class attendance, and teachers’ attitude. Thus, the basis of our research is to conclude e-learners’ related affairs or events that may influence their emotions. Hierarchical emotion influencing affairs/events are proposed and shown in Fig. 12
                        .

Every successful emotion regulation instance can be presented in a tuple as follows:


                        (Event_set, Event_type, Emotion_category, Regulation_strategy)
                     

The above quadruple is called Event Emotion regulation-inStance (EES), in which the first element Event_set marks the instance by a summary sentence, such as “the teacher criticized my report,” and is extracted from the successful instance by experts; Event_type is the type which the instance belongs to in the hierarchical relationship shown in Fig. 12; Emotion_category indicates the emotional state of the e-learner when he/she suffers from the events of the record. Regulation_strategy is the marked advices and comforting sentences in the records, which may be composed of many turns in a dialog.

The steps of constructing successful instances of emotion regulation are as follows:
                           
                              1.
                              Delete the instances that do not express any emotion or discuss emotion.

Delete the instances that the speaker’s emotion strength is below the constraints.

Delete the instances that the speaker’s emotion is not regulated at the end of the events even after many turns of the speaker’s persuasion.

For the remaining instances, make a summary sentence for each one, and record them to the database, and classify/rank the instances into hierarchical relationship shown in Fig. 12.

Identify the emotion category of this instance.

Following the above steps, the database is built manually.

After constructing emotion regulation strategy database, the next question is how to use it to “find the issue” and “take a step.” This subsection discusses how to “find the issue”.

Inspired by the question–answering system [46], a ranked list of successful instances will be recommended to the listener by computing the similarity between the speaker input sentence and the summary sentences in emotion regulation strategy database.

Currently, there are some frequently used Chinese sentence similarity measures: Vector Space Model (VSM) based IF-IDF measure, semantic-dependency-parsing based measure, and Levenshtein-distance-based measure [52].

Vector space model (or term vector model) is an algebraic model for representing text documents (and any objects, in general) as vectors of identifiers, for example, index terms. It is used in information filtering, information retrieval, indexing and relevancy rankings. In the classic vector space model proposed by Salton et al. [41], the term specific weights in the document vectors are products of local and global parameters. The model is known as term frequency-inverse document frequency model. The weight vector for document d is 
                           
                              
                                 
                                    W
                                 
                                 
                                    d
                                 
                              
                              =
                              
                                 
                                    
                                       
                                          
                                             
                                                w
                                             
                                             
                                                1
                                                ,
                                                d
                                             
                                          
                                          ,
                                          
                                             
                                                w
                                             
                                             
                                                2
                                                ,
                                                d
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             
                                                w
                                             
                                             
                                                N
                                                ,
                                                d
                                             
                                          
                                       
                                    
                                 
                                 
                                    T
                                 
                              
                           
                        , where
                           
                              (1)
                              
                                 
                                    
                                       w
                                    
                                    
                                       t
                                       ,
                                       d
                                    
                                 
                                 =
                                 
                                    
                                       tf
                                    
                                    
                                       t
                                    
                                 
                                 •
                                 log
                                 
                                    
                                       ∣
                                       D
                                       ∣
                                    
                                    
                                       ∣
                                       {
                                       t
                                       ∈
                                       d
                                       }
                                       ∣
                                    
                                 
                              
                           
                        and tf
                        
                           t
                         is the term frequency of term t in document d (a local parameter)


                        
                           
                              log
                              
                                 
                                    ∣
                                    D
                                    ∣
                                 
                                 
                                    ∣
                                    {
                                    t
                                    ∈
                                    d
                                    }
                                    ∣
                                 
                              
                           
                         is the inverse document frequency (a global parameter). ∣D∣is the total number of documents in the document set; ∣{t
                        ∈
                        d}∣ is the number of documents containing the term t 
                        [41].

For simplicity, the most frequently used formula for computing weights in W is
                           
                              (2)
                              
                                 W
                                 =
                                 
                                    
                                       TF
                                       ×
                                       IDF
                                    
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   n
                                                
                                             
                                             
                                                
                                                   (
                                                   TF
                                                   ×
                                                   IDF
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        which is adopted in our approach.

Generally, cosine similarity computation is adopted to compute similarity between two sentences when using VSM based TF-IDF measure. But, VSM based TF-IDF measure has its limitations. (1) Long documents are poorly represented because they have poor similarity values; (2) search keywords must precisely match document terms; (3) semantic sensitivity; (4) the order that the terms appear in the document is lost in the vector space representation [41]. So we proposed some other similarity computing strategies: word order similarity computation, sentence type similarity computation and emotion word similarity computation. The four similarity computing strategies are as follows:
                           
                              (1)
                              Cosine similarity computation

Cosine similarity is a measure of similarity between two vectors of n dimensions by finding the cosine of the angle between them, which is often used to compare text documents. Given two vectors of attributes, A and B, the cosine similarity, θ, is represented using a dot product as:
                                    
                                       (3)
                                       
                                          similarity
                                          =
                                          cos
                                          (
                                          θ
                                          )
                                          =
                                          
                                             
                                                A
                                                ·
                                                B
                                             
                                             
                                                ∥
                                                A
                                                ∥
                                                ∥
                                                B
                                                ∥
                                             
                                          
                                       
                                    
                                 
                              

For text matching, the attribute vectors A and B are usually the term frequency vectors of the documents.

After parsing a speaker’s input sentence, we obtain a feature vector T, T
                                 =(T
                                 1,
                                 T
                                 2,…;
                                 T
                                 
                                    n
                                 ); the expected record in the emotion regulation strategy database is T′=(T′1,
                                 T′2,…,
                                 T′
                                    n
                                 ), where the number of dimensions of the vector, n, is the same as a term set acquired from the summary sentence for each record in the emotion regulation strategy database. Then, the formula of cosine measure is as follows:
                                    
                                       (4)
                                       
                                          Similarity
                                          (
                                          T
                                          ,
                                          
                                             
                                                T
                                             
                                             
                                                ′
                                             
                                          
                                          )
                                          =
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   
                                                      n
                                                   
                                                
                                                
                                                   
                                                      T
                                                   
                                                   
                                                      i
                                                   
                                                
                                                ×
                                                
                                                   
                                                      T
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      ′
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            i
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      ×
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            T
                                                         
                                                         
                                                            i
                                                         
                                                         
                                                            ′
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Word order similarity computation

Word order similarity is the keyword order similarity of two sentences, which reflects the similarity in the position of the same word or a synonym contained in two sentences, ranked by the reverse number of the same sequence of adjacent words or synonyms contained in the two sentences. The computation formula is as follows:
                                    
                                       (5)
                                       
                                          OrdSim
                                          (
                                          q
                                          ,
                                          S
                                          )
                                          =
                                          1
                                          -
                                          
                                             
                                                Rev
                                                (
                                                q
                                                ,
                                                S
                                                )
                                             
                                             
                                                MaxRev
                                                (
                                                q
                                                ,
                                                S
                                                )
                                             
                                          
                                       
                                    
                                 where q refers to a query sentence, S represents a summary sentence in database.


                                 MaxRev (q,S)—the maximum reverse number in the same index term in sentence q and sentenceS.


                                 Rev (q,S)—the reverse number of natural number which is constituted by position of the search word, in the sentence q, appeared in the sentence S, and the first position is counted if a word appears repeatedly in the sentence S.

Eq. (5) means that: closer orders of keywords in two sentences are, the more similar the two sentences are. In a sequence, if the location order of a pair of numbers is against the ranking according to their value, that is, the front number is bigger than the later one, and then they are called a reverse. If the emotional sentence input by a user has n matched records in the database, the maximum reverse number is (n
                                 −1)! For example, compared with a user input emotional sentence, if the word order of a pair of feature words in the database is different from the user input word order; the pair of feature words is called a reverse. The total number of reverse in a sequence is called the sequence reverse number. For example, in a natural number sequence (2,4,3,1), 2 and 1, 4 and 3, 4 and 1, 3 and 1 are reverse, then the sequence reverse number is 4, and its maximum reverse number is (4−1)!=6, so it is similarity with the natural number sequence (1,2,3,4) is 1–4/6=0.33.

Sentence type similarity computation

Sentence type similarity is to compute the type similarity between a query q and summary sentences in database because of the characteristic of Chinese. For example, natural language questions contain interrogative words [46]. The type code will be included in this query and be used to compute the similarity with a summary sentence type in emotion regulation strategy database.

Emotion word similarity computation

Emotion word similarity computation is to compute the similarity of affective words appeared in the query and a summary sentence in emotion regulation strategy database. Obviously, the affective words appeared in a query express user’s emotion directly.

Finally, taking into account the advantages and disadvantages of each measure, a weighted sum method is proposed. The weighted sum formula is shown as follows:
                                    
                                       
                                          similar
                                          =
                                          cosSimilarWeigh
                                          *
                                          cosSimilar
                                          +
                                          seqSimilarWeigh
                                          *
                                          WOSimilar
                                          +
                                          typeSimilarWeigh
                                          *
                                          typeSimilar
                                          +
                                          ewSimilarWeigh
                                          *
                                          EWSimilar
                                       
                                    
                                 where the parameters, cosSimilar, WOSimilar, typeSimilar and EWSimilar are the results derived from cosine similarity computation, word order similarity computation, type similarity computation, and emotion word similarity computation, respectively. The parameters, cosSimilarWeigh, seqSimilarWeigh, typeSimilarWeigh, and ewSimilarWeigh are their weights which are manually configured.

For example, under a scenario of student group discussion, the e-learner types that he is depressed because his supervisor criticized his report. A topic detection and tracking method proposed in Tian et al. [47] is used to identify whether this is an new event or a recipient’s input. If the sentence is identified as new event, it is classified as an affair/event in Fig. 12.

After labeling the sentence and extracting the event content and emotional states, the former two elements of an EES are formed as (“his supervisor criticized his report”, “frustration”). We use this feature to match the former element of EES of instances in the emotion regulation strategy database. Some results can be found in Table 18
                        .

Note that: (1) the event type of the successful instances in the database is still identified manually and (2) case-based reasoning for emotion regulation instance recommendation is activated, when the degree of negative emotion detecting from the user input sentence is above 0.3.

According to the recommended successful instances, a listener who communicates with this depressed e-learner will suggest him/her or say something as presented in Table 18. This will comfort/relax the e-learner’s negative emotions.

Experiments are carried out 50 times: 34 effective versus 16 failures, where one e-learner is practicing a negative emotion, after being told a bad news, and the other texted the recommended sentences according to the two sentence similarity computation. The regulation efficiency is influenced by two factors. The first one is the accuracy of emotion classification method and computation of similarity between the user input sentence and instances in emotion regulation strategy database.


                        Fig. 13
                         is a screenshot of a chat-room system built according to the above method and named “Emotion-chat” in which the top-left area is the chatting area, while the bottom-right area shows the recommended emotion regulation strategy to a user, named “Homer5800,” according to the similarity computation method when another user, name “111,” in negative emotions is recognized.

In this paper, first, we propose an e-learner oriented emotion category, in which, the interpersonal and intrapersonal category is emphasized, so as to understand the mutual interaction of the e-learners’ emotions in text-based interaction. Second, a framework of our research is given, which includes recognizing and regulating the e-learner’s emotions based on interactive Chinese texts. Third, after the affective word base and the rules of feature extraction are described, first turn in dialogs is detected, and Random Forest based classification algorithm and its corresponding cost-sensitive approach are chosen according to performance comparison with other 14 classification algorithms, including SVM, Naive Bayesian model, LogitBoost, Bagging, MultiClass Classifier, RBFnetwork, J48 and their combination with the cost-sensitive classifier. Finally, emotion regulation based on active listening is introduced, in which a successful emotion regulation case base is built manually, and the computation of similarity between short sentences and emotion regulation instances is presented. Experiment results show that our method have positive role in emotion regulation in interactive text based applications.

However, our work is still in trial and only partially supports our idea. The future work is to enlarge the size of our emotion word base, use larger trained dataset and develop high efficient algorithm to ensure the precision of classification on 17 emotion types in the future, or verify the influence of feature age and its distribution on emotion classification. In addition, more features should be selected or discovered according to theories of syntax, discourse analysis, psychology, etc. Moreover, the EES database needs to be built or updated by machine-learning algorithm. The self-evaluation mechanism of emotion regulation instances is not considered in this paper and will be done in further research.

@&#ACKNOWLEDGMENT@&#

This project is partially supported by the National Science Foundation of China under Grant Nos. 61103239, 61070072, 61103160, the National Key Technologies R&D Program of China under Grant No. 2013BAK09B01, and the Fundamental Research Funds for the Central Universities under Grant No. xjj20100057. The authors would like to thank the editor and anonymous reviewers for their valuable comments and suggestions, which were helpful in improving the paper.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.knosys.2013.10.019.


                     
                        
                           
                              3classFmeasurenew9957.
                           
                           
                        
                     
                  


                     
                        
                           
                              3classprecisonnew9957.
                           
                           
                        
                     
                  


                     
                        
                           
                              3classrecallnew9957.
                           
                           
                        
                     
                  


                     
                        
                           
                              fig2.
                           
                           
                        
                     
                  


                     
                        
                           
                              Neg5Fmeasurenew.
                           
                           
                        
                     
                  


                     
                        
                           
                              Neg5precisonnew.
                           
                           
                        
                     
                  


                     
                        
                           
                              Neg5recallnew.
                           
                           
                        
                     
                  


                     
                        
                           
                              TypeIIIIIInoageweightedfmeasure.
                           
                           
                        
                     
                  


                     
                        
                           
                              TypeIIIIIInoageweightedprecision.
                           
                           
                        
                     
                  


                     
                        
                           
                              TypeIIIIIInoageweightedrecall.
                           
                           
                        
                     
                  

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A Swarm Optimization approach for clinical knowledge mining

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Wind-driven Swarm Optimization (WSO) is used for optimizing the rule base of a Clinical Decision Support System.


                        
                        
                           
                           WSO is a bio-inspired approach inspired from the flight of birds.


                        
                        
                           
                           WSO uses Jval to evaluate the efficiency of a rule based CDSS.


                        
                        
                           
                           Experiments with six medical datasets show that WSO provides efficient rulesets.


                        
                        
                           
                           The novelty of WSO lies in its biological motivation and customization for rule base optimization.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Bio-inspired computing

Swarm intelligence

Clinical decision making

Medical decision support systems

Rule-based classification

@&#ABSTRACT@&#


               
               
                  Background and objectives
                  Rule-based classification is a typical data mining task that is being used in several medical diagnosis and decision support systems. The rules stored in the rule base have an impact on classification efficiency. Rule sets that are extracted with data mining tools and techniques are optimized using heuristic or meta-heuristic approaches in order to improve the quality of the rule base. In this work, a meta-heuristic approach called Wind-driven Swarm Optimization (WSO) is used. The uniqueness of this work lies in the biological inspiration that underlies the algorithm.
               
               
                  Methods
                  WSO uses Jval, a new metric, to evaluate the efficiency of a rule-based classifier. Rules are extracted from decision trees. WSO is used to obtain different permutations and combinations of rules whereby the optimal ruleset that satisfies the requirement of the developer is used for predicting the test data. The performance of various extensions of decision trees, namely, RIPPER, PART, FURIA and Decision Tables are analyzed. The efficiency of WSO is also compared with the traditional Particle Swarm Optimization.
               
               
                  Results
                  Experiments were carried out with six benchmark medical datasets. The traditional C4.5 algorithm yields 62.89% accuracy with 43 rules for liver disorders dataset where as WSO yields 64.60% with 19 rules. For Heart disease dataset, C4.5 is 68.64% accurate with 98 rules where as WSO is 77.8% accurate with 34 rules. The normalized standard deviation for accuracy of PSO and WSO are 0.5921 and 0.5846 respectively.
               
               
                  Conclusion
                  WSO provides accurate and concise rulesets. PSO yields results similar to that of WSO but the novelty of WSO lies in its biological motivation and it is customization for rule base optimization. The trade-off between the prediction accuracy and the size of the rule base is optimized during the design and development of rule-based clinical decision support system. The efficiency of a decision support system relies on the content of the rule base and classification accuracy.
               
            

@&#INTRODUCTION@&#

Clinical decision making is a pervasive task that needs to be accurate and quick. Medical diagnosis, prognosis, patient-care and research have many objectives and constraints, in the midst of which optimal decisions have to be made. In order to provide quality health care, the process of decision making is enhanced and supported by various systems such as Decision Support Systems (DSS) [1], Rule-Based Clinical Decision Support Systems [2], Expert System [3], Automatic Diagnosis System [4], Diagnosis Support System [5], Clinical Information System [6], Medical-Record System [7] and hybrid intelligent system [8].

Clinical DSS focus on providing information and knowledge for decision makers at various levels in a health care organization. Every day increasing amount of health-care data is maintained in repositories but the emphasis is on mining knowledge from clinical data. The extracted knowledge should be novel, interesting, precise and comprehensible so as to improve the decision making process. Efficient and robust computational algorithms, are required to develop an optimized decision making model.

Several mathematical, evolutionary and swarm intelligence optimization approaches have been proposed in the literature. Some of these approaches used in medical informatics and clinical diagnosis are the following: Numerical analysis [9], Linear programming [10], Non-Linear analysis [11], genetic algorithm (GA) [12], Immune-GA [13], Simulated Annealing [14], Tabu Search [15], Ant Colony Optimization [16], Artificial Bee Colony (ABC) [17] Algorithm, Particle Swarm Optimization (PSO) [18,19].

Harmony search is a metaheuristic approach for optimization of continuous variables [20]. The approach is inspired from the music and harmony construction. Each musician can be compared to a decision variable and the pitches are possible values of that variable. There are three rules followed by the variables to choose a feasible value which are as follows: first, choosing a value from the harmony search (HS) memory, second, choosing an adjacent value from the existing set of values and third choosing a random value. A certain set of values for each variable, which maximizes or minimizes the objective, constitutes the optimal solution.

Erol et al. proposed an optimization method inspired by the evolution of the universe [21]. The big bang and the big crunch theory consist of two phases namely, the big bang phase and a big crunch phase. The big bang phase deals with the creation (initialization) of a population in the search space. The entire set of solutions initialized in the big bang phase is given as input to the big crunch phase, and the centre of mass (x
                     
                        c
                     ) is obtained as output. The centre of mass is considered to be the optimal solution or the best-fit individual.

Oftadeh et al. proposed an optimization algorithm based on the group hunting behaviour of animals [22]. Animals that hunt their prey in groups follow certain procedures to effectively get hold of the prey. The group leader is closer to the prey and hence the members of the group follow the leader. The group leader can be compared to an optimal solution and the other hunting animals as feasible (candidate) solutions.

Yang proposed the Firefly Algorithm (FA) for global optimization problems [23]. Fireflies emit light to attract the prey. The flashing light is formulated in such a way that it is associated with the objective function to be optimized. In optimization, each fly is analogous to a solution and the fly with the maximum intensity of brightness is considered as an optimal solution.

Particle Swarm Optimization [24], a population based meta-heuristic stochastic optimization algorithm, has been applied for optimizing typical data mining tasks such as classification, regression, clustering and association analysis. An overview of PSO is presented in the related works section.

Due to several drawbacks and complexities in the design and application of metaheuristic approaches, new algorithms and approaches are developed by the research community. In this work, a swarm intelligence-based metaheuristic optimization approach is used to build efficient rule-based clinical decision support systems.

The rest of the paper is organized as follows: Section 2 presents the related work. Section 3 presents the biological motivation of the proposed optimization approach. In Section 4, a description about the datasets and the application of WSO for clinical rule-based classification is discussed. Section 5 presents the results, findings and suggestions along with the pros and cons of different approaches used. Finally Section 6 concludes the paper highlighting the scope for future work.

@&#RELATED WORK@&#

This section provides an overview about the generic global PSO, followed by its variants and modifications proposed by different researchers. Application of PSO for clinical data mining is presented. Similar optimization approaches such as Glowworm Swarm Optimization (GSO), Wind Driven Optimization (WDO) are also discussed. Finally, the issues and drawbacks of swarm intelligence based optimizers are discussed and the significance of this work is highlighted.

Kennedy and Eberhart proposed the original Particle Swarm Optimization algorithm in the year 1995 [24], after which various PSO variants have been developed to improve its performance. For many cases, the variations and changes have been imposed over the methods that control the working of the algorithm. In short, these changes range from adding constants in the particles’ velocity update rule to stand-alone algorithms that are used as extensions of hybrid PSO algorithms. In this section we present the generic PSO algorithm, different variations in PSO and the modifications in the variations.

A population based stochastic optimization algorithm has a swarm of particles (feasible solutions) moving towards an optimal position (optimal solution) in a search space. The basic position update and velocity update rules in the generic PSO are as follows:
                           
                              (1)
                              
                                 
                                    
                                       x
                                       i
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    
                                       x
                                       i
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       v
                                       i
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       v
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    
                                       v
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       c
                                       1
                                    
                                    
                                       r
                                       
                                          1
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    [
                                    
                                       y
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       x
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    ]
                                    +
                                    
                                       c
                                       2
                                    
                                    
                                       r
                                       
                                          2
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    [
                                    
                                       
                                          y
                                          ˆ
                                       
                                       j
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       x
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    ]
                                 
                              
                           
                        where x
                        
                           ij
                        (t) is the position of particle i in dimension j at step t, v
                        
                           ij
                        (t) is the velocity of particle i in dimension j
                        
                        =
                        
                        1,2,…,n
                        
                           x
                         at time t. c
                        
                           1
                         
                        and c
                        
                           2
                         are cognitive acceleration coefficient and social acceleration coefficient respectively. The variables r
                        
                           1
                        , r
                        
                           2
                         take up random values that are generated for every iteration from a normal distribution. y
                        
                           i
                         is the personal best position of particle i and 
                           
                              y
                              ˆ
                           
                         is the global best. For optimization problems which search for a minimum point, the personal best position is updated as follows.
                           
                              (3)
                              
                                 
                                    
                                       y
                                       i
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         y
                                                         i
                                                      
                                                      (
                                                      t
                                                      )
                                                   
                                                
                                                
                                                   
                                                      i
                                                      f
                                                       
                                                      f
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      (
                                                      t
                                                      +
                                                      1
                                                      )
                                                      )
                                                      ≥
                                                      f
                                                      (
                                                      
                                                         y
                                                         i
                                                      
                                                      (
                                                      t
                                                      )
                                                      )
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         x
                                                         i
                                                      
                                                      (
                                                      t
                                                      +
                                                      1
                                                      )
                                                   
                                                
                                                
                                                   
                                                      i
                                                      f
                                                       
                                                      f
                                                      (
                                                      
                                                         x
                                                         i
                                                      
                                                      (
                                                      t
                                                      +
                                                      1
                                                      )
                                                      )
                                                      <
                                                      f
                                                      (
                                                      
                                                         y
                                                         i
                                                      
                                                      (
                                                      t
                                                      )
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     


                        Algorithm 1 is the generic global best (gbest) Particle Swarm Optimizer. The notations and pseudocode are adopted from [25]. S denotes a swarm and S.x
                        
                           i
                         denotes the position of particle x
                        
                           i
                         in swarm S and S.n
                        
                           s
                         denotes the nth particle in swarm S. PSO updates the particles’ velocity and position iteratively until a stopping criterion is met. The basic velocity and position-update rules are governed by acceleration coefficients (c
                        1, c
                        2) and random constants (r
                        1, r
                        2).
                           Algorithm 1
                           gbest PSO
                                 
                                    
                                 
                              
                           

Constricted Particle Swarm Optimizer [26] adds a constriction factor to the particles’ velocity-update rule to avoid the unlimited growth of the particles’ velocity.
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   v
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                (
                                                t
                                                +
                                                1
                                                )
                                                =
                                                χ
                                                (
                                                
                                                   v
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                +
                                                
                                                   c
                                                   1
                                                
                                                
                                                   r
                                                   
                                                      1
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                [
                                                
                                                   y
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                −
                                                
                                                   x
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                ]
                                                +
                                                
                                                   c
                                                   2
                                                
                                                
                                                   r
                                                   
                                                      2
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                [
                                                
                                                   
                                                      y
                                                      ˆ
                                                   
                                                   j
                                                
                                                (
                                                t
                                                )
                                                −
                                                
                                                   x
                                                   
                                                      i
                                                      j
                                                   
                                                
                                                (
                                                t
                                                )
                                                ]
                                                )
                                             
                                          
                                       
                                       
                                          
                                             
                                                χ
                                                =
                                                2
                                                /
                                                |
                                                2
                                                −
                                                c
                                                −
                                                
                                                   
                                                      
                                                         c
                                                         2
                                                      
                                                      −
                                                      4
                                                      c
                                                   
                                                
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where χ is the constriction factor and 
                           
                              c
                              =
                              
                                 
                                    
                                       ∑
                                       i
                                    
                                    c
                                 
                                 i
                              
                               
                              and
                               
                              c
                              >
                              4
                           
                        .and i is the iterator for the number of coefficients. For an optimization problem that uses Constricted PSO, some recommended parameter values are: Acceleration coefficients c
                        1 and c
                        2
                        =2.05, Constriction factor (χ)=0.729, maximum velocity (V
                        
                           max
                        )=±X
                        
                           max where X
                        
                           max
                         is the maximum of the search range.

Shi and Eberhart [27] noticed that the first term of the velocity update rule plays the role of a particle's “inertia” and they introduced the idea of an inertia weight (w). There is a trade-off between the ability of the swarm to explore or exploit and the inertia weight parameter is used to control this. The basic velocity update equation is modified as follows
                           
                              (5)
                              
                                 
                                    
                                       v
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    +
                                    1
                                    )
                                    =
                                    
                                       w
                                    
                                    
                                       v
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       c
                                       1
                                    
                                    
                                       r
                                       
                                          1
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    [
                                    
                                       y
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       x
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    ]
                                    +
                                    
                                       c
                                       2
                                    
                                    
                                       r
                                       
                                          2
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    [
                                    
                                       
                                          y
                                          ˆ
                                       
                                       j
                                    
                                    (
                                    t
                                    )
                                    −
                                    
                                       x
                                       
                                          i
                                          j
                                       
                                    
                                    (
                                    t
                                    )
                                    ]
                                 
                              
                           
                        
                     

They also proposed a time-varying version of inertia weight. The function used to schedule ‘w’ is as follows:
                           
                              
                                 
                                    
                                       w
                                       t
                                    
                                    =
                                    
                                       
                                          w
                                          
                                             t
                                             
                                                max
                                             
                                          
                                          −
                                          t
                                       
                                       
                                          w
                                          
                                             t
                                             
                                                max
                                             
                                          
                                       
                                    
                                    (
                                    
                                       w
                                       
                                          max
                                       
                                    
                                    −
                                    
                                       w
                                       
                                          min
                                       
                                    
                                    )
                                    +
                                    
                                       w
                                       
                                          min
                                       
                                    
                                 
                              
                           
                        where wt
                        max
                         and wt
                        min are the maximum and minimum values the inertia weight can take. Zheng et al. proposed a variant to the inertia weight PSO (IW PSO) referred to as increasing-IW PSO where the values of w
                        max and w
                        min were interchanged [28]. In IW PSO acceleration coefficients c
                        1 and c
                        2
                        =2.0, inertia weight w
                        
                           max
                         and w
                        
                           min
                         is set to 0.4 and 0.9 respectively. Maximum velocity (V
                        
                           max
                        )=±X
                        
                           max
                        .

Mendes et al. proposed the Fully Informed Particle Swarm (FIPS), in which a particle uses information from all its topological neighbours [29]. Constriction factor is also adopted in FIPS; however, the value c (c=c
                        1
                        +
                        c
                        2) is equally distributed among all the neighbours of a particle. The parameters and corresponding values for FIPS is as follows: Acceleration coefficient c
                        =4.1, constriction factor (χ)=0.729 and maximum velocity (V
                        
                           max
                        )=±X
                        
                           max
                        .

Ratnaweera et al. proposed the self-organizing hierarchical Particle Swarm Optimizer (HPSO) with time-varying acceleration coefficients (TVAC) [30]. Time-varying acceleration coefficients (TVAC) are introduced in addition to Eberharts’ time-varying inertia weight factor. This variation can be represented as follows:
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   c
                                                   1
                                                
                                                =
                                                (
                                                
                                                   c
                                                   
                                                      1
                                                      f
                                                   
                                                
                                                −
                                                
                                                   c
                                                   
                                                      1
                                                      i
                                                   
                                                
                                                )
                                                
                                                   
                                                      i
                                                      t
                                                      e
                                                      r
                                                   
                                                   
                                                      M
                                                      a
                                                      x
                                                      I
                                                      T
                                                      R
                                                   
                                                
                                                +
                                                
                                                   c
                                                   
                                                      1
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   c
                                                   2
                                                
                                                =
                                                (
                                                
                                                   c
                                                   
                                                      2
                                                      f
                                                   
                                                
                                                −
                                                
                                                   c
                                                   
                                                      2
                                                      i
                                                   
                                                
                                                )
                                                
                                                   
                                                      i
                                                      t
                                                      e
                                                      r
                                                   
                                                   
                                                      M
                                                      a
                                                      x
                                                      I
                                                      T
                                                      R
                                                   
                                                
                                                +
                                                
                                                   c
                                                   
                                                      2
                                                      i
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where c
                        
                           1f
                        , c
                        
                           2f
                        , c
                        
                           1i
                        , c
                        
                           2i
                         are constants, iter is the current iteration and MaxITR is the maximum allowable iterations. Furthermore they have introduced the concept of mutation, by adding a variation to a randomly selected dimension of a random particle in the swarm. Randomness is induced by choosing from a uniformly distributed random number within in the range [0,1].

In addition to the discussed basic variations in the PSO algorithm, there are many more modified variants and applications of PSO found in literature. Some of them include Orthogonal Learning PSO [31], Gaussian-Distributed PSO [32], Comprehensive Learning PSO [33], Frankenstein's PSO [34], Cooperatively Coevolving PSO [35], Dissipative PSO [36], Distance-based Locally Informed PSO [37], Ageing Leader and Challengers PSO [38], Crown-Jewel-Defence Strategy based PSO [39], Immune Cooperative PSO [40], hybrid Multi-Objective PSO [41], Niching PSO [42], Chaos-PSO [43], Binary Multi-Objective PSO [44], PSO with Speciation and Adaptation [45], Discrete PSO [46] and Binary PSO [47].

Sousa et al. uses Discrete PSO to generate and validate classification rules [48]. The Covering algorithm generates a sequential rule set. The validation algorithm evaluates the performance based on accuracy, time spent, size of rule set and number of attributes per rule. They have experimented with three datasets from the UCI repository namely, Zoo, Breast Cancer-L and Breast Cancer-W and have achieved an accuracy of 91%, 76% and 94% respectively.

Falco et al. in their work have used PSO for classification of instances in multiclass databases [49]. The fitness evaluation module of their PSO consists of three functions to evaluate an individual (particle). The first function computes the classification error rate of an individual. The second function computes the Euclidean distance of the instance from the centroid of the class label. The third fitness function is a linear combination of the two functions. On the whole, the classification problem turns out to be a typical minimization problem. They have tested their PSO combined classification approach over thirteen benchmark datasets from the UCI machine learning repository. Their approach has an average error rate of 13.95%.

Yeh et al. have used an approach for mining breast cancer patterns using a Discrete Particle Swarm Optimization for classification [46]. They have experimented on Wisconsin Breast Cancer Database and have performed attribute reduction using correlation and regression analysis. They have chosen six features namely, clump thickness, uniformity of cell size, uniformity of cell shape, bare nuclei, bland chromatin and normal nucleoli. Classification accuracy alone is used as a fitness evaluation measure for each particle of the swarm. They have achieved an accuracy of 98.7%. Neither the number of rules in the rule base nor classification performance issue is addressed.

Glowworm Swarm Optimization (GSO) [50], is well suited for search optimization. The algorithm is designed to find multiple optima having either equal or unequal function values. GSO, PSO and ACO are all agent-based swarm intelligence algorithms where each artificial agent has memory for storing their positions. GSO has some resemblance with ACO and PSO, but it is distinct in the following ways: First, the direction of movement is based on previous best movement in PSO whereas it is along the line-of-sight with a neighbour in GSO. Second, PSO is limited to numerical optimization models whereas GSO is applicable to multiple source localization. GSO has several algorithm parameters such as luciferin decay constant (ρ), luciferin enhancement constant (γ), number of neighbours (n
                        
                           t
                        ), weight constant (β), and parameters that influence the behaviour of the algorithm. These parameters need to be pre-determined based on many experiments.

Bayraktar et al. have proposed a wind driven optimization (WDO) approach [51] that outperforms PSO and GA. The approach is inspired from the earth's atmosphere where the position and velocity of an air parcel (analogous to particle) is guided by the wind and other factors such as gravitational force, coriolis force, pressure gradient force and friction force. The optimum performance of the WDO can be achieved by proper selection of the values for the coefficients of the four forces. WDO requires certain assumptions and simplifications in order to achieve optimal performance. The authors have applied WDO for solving problems in electromagnetic design such as synthesis of a linear antenna array, a double-sided magnetic conductor for WiFi applications and an E-shaped microchip patch antenna. The efficiency of WDO is purely dependent on the initial parameter settings furthermore different problems require different settings. Though wind is the driving force behind WDO and WSO, the parameters of WDO cannot be easily tuned to fit all optimization problems. The designer is expected to have knowledge on all the parameters for effective utilization of that meta-heuristic whereas the parameters and working procedure of WSO are custom-developed for rule base optimization.

According to ‘no-free-lunch’ (NFL) theorem [52], there is no universally better algorithm that is generic and suitable for all problems [53]. Nature-inspired metaheuristic algorithms are analyzed in terms of its parameters used for exploration and exploitation or the ways that generate solutions using operators. The more an algorithm explores the search space it is less likely to get struck in a local minimum. However, slow convergence and wastage of computational efforts have to be compromised. On the other hand, more of exploitation and less exploration may lead to faster convergence but the true global optimum is not guaranteed. A proper balance is required between these two parameters.

In general, PSO, WDO, GSO can be used to solve optimization problems; however, due to many variations and modifications, the ease of adapting these meta-heuristic optimizers for rule based DSS has decreased. Some major drawbacks of swarm optimizers that we observed are as follows: First, the developer is expected to have a clear knowledge about the working of the algorithm, only then the optimizer can be made suitable for a specific application. Second, swarm optimizers have several parameters which influence the performance of the algorithm which in turn would influence the heuristic. Third, some variants of PSO require binary conversion instead of working with direct real valued variables.

Compared to the works discussed in literature the work proposed in this paper is novel and significant in the following ways: First, a novel model for optimization, based on the flight of birds is used. A swarm of birds adapt certain food habits and flight directions while flying long distances. The Wind Driven Swarm Optimizer derives its biological inspiration from the flight and food consumption of birds that travel along the drift of the wind. Second, a new evaluation metric, Jval, is incorporated in WSO. Jval is specifically designed to evaluate the performance of a rule-based classifier. Third, the performance of WSO with Jval is validated over benchmark medical datasets.

Birds continue to be a source of inspiration not only to a biologist but also to a common man. Their flight, food habits and social behaviour have several analogies to real world situations and can be used for developing problem-solving strategies too. Migratory birds arrive at a destination within a limited span of time. There are several factors that affect migration such as energy, time, safety, orientation ability, fuel for flight, wind direction and wind speed.

Wind is an important factor affecting the flight and departure decision of migratory birds [54]. Wind also has an impact on the number of birds in the swarm. The atmosphere, which is ever-changing, has a significant influence on all aspects of a bird's migration. Hence a swarm of birds should be able to learn the dynamic wind-forces and thereby use the wind factor to enhance its flying efficiency.

Flight range (Y) can be regarded as a function of fat load (f). The constant (c) differs between species and individuals depending on their size, morphology and flight efficiency [55]. To analyze the effect of wind, a factor ‘a’, representing the tailwind component is used. However, the actual wind situation is relevant for the value of fat with respect to flight distance.
                        
                           (6)
                           
                              
                                 Y
                                 =
                                 c
                                 ×
                                 
                                    
                                       1
                                       −
                                       
                                          1
                                          
                                             
                                                
                                                   1
                                                   +
                                                   f
                                                
                                             
                                          
                                       
                                    
                                 
                                 ×
                                 a
                              
                           
                        
                     
                  

Benefits and costs according to wind depend on the time spent flying, which depends on the actual fat load. The gain in distance while resting has to be related to the gain in distance by wind assistance, when moving on. The effect of wind on the expected flight range can therefore be expressed as the expected gain in flight distance when the bird is flying.
                        
                           (7)
                           
                              
                                 
                                    G
                                    
                                       w
                                       i
                                       n
                                       d
                                    
                                 
                                 =
                                 
                                    Y
                                    i
                                 
                                 ×
                                 (
                                 
                                    a
                                    i
                                 
                                 −
                                 
                                    a
                                    ¯
                                 
                                 )
                              
                           
                        
                     where Y
                     
                        i
                      is the flight range according to the actual fat reserves as introduced in Eq. (6), but without the wind effect; a
                     
                        i
                      is the actual wind support and 
                        
                           a
                           ¯
                        
                      is the average wind support expected. G
                     
                        wind
                      depends on actual fuel load and wind support and can be regarded as wind support per day [56].

The Wind-driven Swarm Optimization algorithm (Algorithm 2) is inspired from the above biological models. WSO is designed and developed to optimize the overall performance of a classifier. The Jval is a novel evaluation metric for rule based classifier. The accuracy of a classification model is not the only factor that is to be considered for building a classifier but the size of the ruleset is also important for the design of an efficient rule-based classifier. Both the factors are considered in Jval's evaluation with user defined weights. The health of an individual, h(S
                     .
                     x
                     
                        i
                     ), is the Jval value associated with that individual. h(S
                     .
                     y
                     
                        i
                     ) is the personal best health.
                        
                           
                              
                                 Jval
                                 ∝
                                 
                                    
                                       Accuracy
                                    
                                    
                                       No.
                                        
                                       of
                                        
                                       Rules
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (8)
                           
                              
                                 J
                                 v
                                 a
                                 l
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         Correctly classified instances
                                                      
                                                      
                                                         Total instances
                                                      
                                                   
                                                
                                             
                                          
                                          α
                                       
                                    
                                    
                                       
                                          
                                             (
                                             No. of rules
                                             )
                                          
                                          
                                             α
                                             −
                                             β
                                          
                                       
                                    
                                 
                              
                           
                        
                     where α and β are proportionality weight constants for accuracy and number of rules respectively. The values of these constants decide the trade-off between classifier accuracy and size. The variance of results for different values of α and β is shown in the results section.
                        Algorithm 2
                        Wind-driven Swarm Optimization
                              
                                 
                              
                           
                        

It is interesting to observe that the biological model-based approach for position-update ensures that the gain in distance G(S.x
                     
                        i
                     
                     ), increases faster initially but slower in latter iterations though Jval may increase linearly. This allows the search to explore the search-space during the initial iterations and exploit during the latter iterations. Furthermore, 
                        
                           a
                           ¯
                        
                      which is the average wind support, is a non-increasing positive integer variable, initially set to high values and gradually decreased in steps of two. It is used to balance between the exploration and exploitation trade-off. Based on experimental trials and analysis we set the value of MAX
                     
                        ITER
                      to 50 and 
                        
                           a
                           ¯
                        
                      to 100. Since the average wind support (
                        
                           a
                           ¯
                        
                     ) is non-increasing, its step-length decides the convergence speed of the algorithm. It can be observed that average wind support is analogous to learning rate in other algorithms. The basic biological model that is based on the flight of birds ensures that the algorithm diverges (explores) during the initial stages and converges (exploits) at latter stages.

In this work, experiments were conducted on six benchmark medical datasets obtained from the UCI machine learning repository [57], namely, Liver Disorders dataset, Cleveland Heart Disease dataset, Hepatitis Dataset, Pima Indians Diabetes dataset, Wisconsin Breast Cancer Dataset and Lymphoma dataset.

The liver disorders dataset includes 6 attributes and 345 records. A description about the dataset is given in Table 1
                     . The Heart Disease Dataset consists of 303 instances spread across five class labels. The description about the attributes is presented in Table 2
                     . Hepatitis dataset includes 155 samples from two different classes. Attributes of symptoms that are obtained from patient are given in Table 3
                     . Diabetes dataset consists of 768 instances out of which 268 are tested positive. All patients of the Diabetes dataset are Pima Indian women. A description about the attributes and their values is given in Table 4
                     . The Breast Cancer Dataset comprises of 699 instances out of which 458 are benign. A description about the attributes is given in Table 5
                     . The Lymphoma Dataset comprises of 148 instances and 18 attributes spread across four classes namely, normal find, metastases, malign lymph and fibrosis. Detailed description about the datasets can be obtained from the UCI Repository [57].

The data are split into testing set and training set using holdout approach [58]. The training data are used for creating the learning model and then C4.5 algorithm [59] presents the model (decision tree) into sets of IF-THEN rules. As an individual (particle/ruleset) begins its flight in the search space, its’ combination of rules and the number of rules changes for each iteration. In a rule-based classification system that uses meta-heuristics, there are two ways to represent a particle or solution, the Michigan and Pittsburgh approach [60]. The former approach encodes a single rule for each particle whereas the latter approach each particle encodes a rule set. In this work, Pittsburgh approach is adopted. A distance computation measure, comparable to GBI measure [61], is used. Let R
                     
                        i
                      and R
                     
                        j
                      be two rulesets (particles) with n and m rules respectively. The distance (d) between the ith ruleset and the jth ruleset is obtained based on the degree of duplications of their rules. In order to decrease the distance between R
                     
                        i
                      and R
                     
                        j
                      the degree of duplication is increased by transferring the m
                     −
                     d rules from R
                     
                        j
                      to R
                     
                        i
                     . If m
                     =
                     n
                     =
                     d then we can infer that both the particles are at the same region in the search space. From vast experimentation we observed that the algorithm converges between 40 to50 iterations and this depends on the number of rules generated by C4.5.

@&#EXPERIMENTAL RESULTS@&#

WSO based rule selection is compared with state-of-art rule-learning approaches which are extensions of decision trees, namely Partial Decision Tree (PART) [62], Repeated Incremental Pruning to Produce Error Reduction (RIPPER/JRIP) [63], Fuzzy Unordered Rule Induction Algorithm, FURIA [64], and Decision Tables (DT) [65]. The analysis of the results with varying values of alpha and beta is presented in Tables 6 and 7
                     
                     . Furthermore the performance of WSO after removal of irrelevant attributes is presented in Table 8
                     . Correlation based feature subset selection [66] was used to eliminated irrelevant attributes.

The trade-off between the number of rules and the accuracy of prediction needs to be balanced. From the results, it can be observed that classification models with more number of rules have superior accuracy. There is a fall in accuracy when the number of rules in the classification model (rule set) is reduced. Hence it can be inferred that the size of the classification model and accuracy are directly proportional.

Classification models can be built and organized based on heuristics such as rule interestingness measures. RIPPER (JRIP) and PART algorithms maintain the accuracy though they produce concise classifier models. The use of interestingness measures such as coverage, confidence, support for rule pruning and rule ordering enhances the efficiency of the classifier but excessive use of these measures may result in loss of information. The loss of information due to excessive filtering may lead to the over-fitting problem. The learning model cannot generalize over unseen instances. Repeated-randomized-hold-out approach (5×2-fold cross validation) and the stochastic evolutionary rule building model ensure that the rule based classifier minimizes the over-fitting problem.

Real world data are often characterized by uncertainty and vagueness. Hence often decisions are indiscernible. It can be observed that WSO achieves superior accuracy for datasets characterized with more than two classes. Meta-heuristic approaches are more robust in handling multi-class classification problems than the traditional binary classification problem.

Clinical datasets are relatively small when compared to other real world datasets. Most clinical datasets would consist of less than thousand samples (rows) and an average of ten to twenty features (columns). Whereas real world datasets, often contain more than fifteen thousand instances and sometimes even more than thousand attributes. As a consequence of this, the number of rules generated for the former datasets are less when compared to the latter datasets. From the results it can be inferred that WSO performs better for clinical datasets than other approaches.

Removal of redundant and irrelevant attributes enhances the quality of the data whereby the knowledge mined from that data is more suitable for decision making. The results on attribute reduction show a decrease in the number of rules. As the number of rules increases the accuracy of the prediction model increases but presence of irrelevant rules may affect classification accuracy. From the experiments conducted it was inferred that reduction in attributes significantly causes a reduction in the size of the rule antecedent. From Table 8 we can observe a drop-off in accuracy and the number of rules for C 4.5 algorithm but WSO's performance remains stable even after compromising on the number of rules in the ruleset. WSO chooses the best subset of rules though the size of the initial ruleset may be large.

The variance in the performance of WSO when compared with PSO is presented in Table 9
                        . For a small search space, where the chance of getting trapped in a local minimum is less, both the approaches tend to be similar. This can be inferred from the liver, breast cancer and lymph datasets. The variation with respect to the population size is significant for large search spaces as in the case of Hepatitis dataset, where the initial number of rules is more when compared to other datasets. It can also be inferred that as the number of individuals increase, the performance of WSO increases but the performance of PSO remains stable. The traditional PSO maintains a balance between the exploration and exploitation of the search space by using c
                        1 and c
                        2 (cognitive acceleration coefficient and social acceleration coefficient respectively) whereas in order to make the algorithm more simple WSO avoids such complexities. The objective of developing WSO is to present a customized approach for rule base optimization. PSO is more generalized. Further advancements and modifications in PSO are more complex in terms of algorithm design and parameter tuning.


                        Table 10
                         presents the deviation of classification accuracy for repeated-randomized-hold-out approach. It can be inferred that the deviation of traditional rule-based approaches (C4.5, PART, FURIA, JRIP, DT) are lower than swarm intelligence based approaches (PSO, WSO). All swarm intelligence approaches and evolutionary paradigms consists of a randomization component in their algorithm that induces an initial diversification. This ensures that the algorithms are not trapped in the local minima. However, the deviation of WSO is lower than PSO for LIVER, C-HEART, HEPATITIS and W-BREAST datasets.

Evolutionary algorithms (EAs) and population based meta-heuristic stochastic optimization approaches still lack proper performance measures for evaluations. Each algorithm suits a specific problem or a domain of problems for which it is designed. EAs can be analyzed using optimization problems that have practical applications [67]. This work uses classifier performance measures to compare its performance with traditional algorithms. The performance of an evolutionary algorithm is dependent on the problem. There is no universally best algorithm that performs consistently better than all other algorithms for all problems.

A statistical test enables to detect significant improvements though some improvements may be small. In general Wilcoxon and Sign tests are considered to be poor in detecting potential improvements [68]. Hence significance of the proposed approach over C4.5 was evaluated using Student's two-tailed paired t-test [69]. Since randomized holdout was repeated five times, there are five independent variables and hence degree of freedom is four. The significance level of the test was set to 0.05 (5%). From the observations it was inferred that the performance of WSO and C4.5 are significantly same for all datasets, but significantly better for C-Heart Dataset, whereas conventional approaches (JRIP and Decision Table) are significantly worse.

This work presents an optimization approach for rule based classification. The biologically inspired swarm intelligence based design of the algorithm suits the optimization of rule based systems. Addition of more parameters or components may improve the working of the algorithm but the simplicity and ease of application would be lost. The novelty of WSO lies in its biological inspiration and its unique design meant for rule base optimization. Algorithm dependent parameters can affect the parameters of an algorithm significantly. WSO is designed for ruleset selection and it has lesser parameters compared to WDO, GSO and PSO. Parameter tuning is still a broad area of research [70]. Furthermore the optimizer can be tested over many real world and synthetic datasets in order to gain a better perspective to design and develop efficient Rule-based Clinical Decision Support Systems.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Distributed multi-agent scheme support for service continuity in IMS-4G-Cloud networks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Quality of Service supports service continuity in heterogeneous networks is achieved by agent-based concepts.


                        
                        
                           
                           The shorter handoff delay and better QoS for real-time service applications is proposed.


                        
                        
                           
                           The QoS mechanism and the intelligent agent are required for cooperative QoS-awareness networking.


                        
                        
                           
                           The QoS management mechanism based on agents develops a cost-effective manner in IMS-4G-Cloud network.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Heterogeneous network

Cooperative networking

Distributed Multi-Agent Scheme (DMAS)

IP Multimedia Subsystem (IMS)

Q-Learning algorithm

Quality of Service (QoS)

@&#ABSTRACT@&#


               
               
                  In this study, the Quality of Service (QoS) needed to support service continuity in heterogeneous networks is achieved by a Distributed Multi-Agent Scheme (DMAS) based on cooperation concepts and an awareness algorithm. A set of problem solving agents autonomously process local tasks and cooperatively interoperate via an in-cloud blackboard system to provide QoS and mobility information. A Q-Learning awareness algorithm calculates the exceptive rewards of a handoff to all access networks. These rewards are then used by problem solving agents to determine what actions must be performed. Agents located in the integrated IMS-4G-Cloud networks handle service continuity by using a handoff mechanism. Through operations and cooperation among active agents, these phases select a policy for predictive and anticipated IP Multimedia Subsystem (IMS) handoff management. Compared with conventional IMS handoff management, the proposed DMAS scheme achieves shorter handoff delay and better QoS for real-time service applications.
               
            

@&#INTRODUCTION@&#

Because of the rapid development of Internet technology, service network providers have pushed wireless communication and mobile computing technologies into new directions. Wireless communication system architectures have rapidly changed from merely offering voice connections to providing extensive, fast, and rich data services. In the service domain, Cloud Computing systems have facilitated the dispersal of service application from a single domain to multiple domains and have enabled new services provided through virtualization and distributed computing technology. Recently, IP Multimedia Sub-systems (IMSs) have emerged as a new method for delivering applications and for enhancing service application experiences of end users.

The IMS also supports heterogeneous networking and provides Quality of Service (QoS) policies [1]. In addition to supporting heterogeneous networking and provides QoS policies, an IMS has three main functions in a packet switching core network: it provides QoS for applications, it provides extensible charging mechanisms for multimedia services, and it integrates all-IP services. To provide high quality services, this study developed a promising IMS-4G-Cloud heterogeneous network architecture that combines Third generation (3G)/Universal Mobile Telecommunications System (UMTS), Wireless Local Area Network (WLAN)/Wireless Fidelity (WiFi), and Worldwide Interoperability for Microwave Access (WiMAX) access technologies in Fig. 1
                      
                     [2]. The User Equipment (UE) can use different access technologies and its own corresponding components, such as SGSN (Serving GPRS Support Node), GGSN (Gateway GPRS Support Node), AAA (Authentication, Authorization and Accounting) server and PDG (Packet Data Gateway). Cloud Computing is currently developing very rapidly as a client-server technology infrastructure and as a platform for distributed service applications. Three distinct categories within Cloud Computing: Software as a Service (SaaS), Platform as a Service (PaaS), and Infrastructure as a Service (IaaS). The SaaS enables users to access the applications via a network. The PaaS provides users with the resource needed to enable applications. The IaaS is used for processing, storage, networking, and other fundamental computing resources. Bringing Cloud Computing technology to the mobile communication domain to communicate with another UE through the IMS or to access services offered by the IMS and Cloud. Fig. 1 shows the efficient and flexible QoS-aware strategy. In this integrated network, mobility management is essential for supporting the QoS mechanism. However, the conventional method of mobility management only minimizes paging cost.

A new method is needed to simplify mobility management in the IMS-4G-Cloud heterogeneous network architecture. One approach is to use IMS to exploit Session Initiation Protocol (SIP) capabilities so that service continuity can be provided for real time applications such as Voice over Internet Protocol (VoIP) and video streaming. Support for IMS is very prominent in the IMS-4G-Cloud heterogeneous network architecture since application layer-based handoff is highly suitable for UDP applications. However, because IMS-supported handoff uses reactive methodology to maintain connections, the new connection is initiated only if the previous section is interrupted. As a result, long handoff delay diminishes QoS performance. On solution proposed in [3] is using the application server for IMS-compliant handoff management to handle vertical handoff and ensure mobile multimedia session continuity.

This study proposes a Distributed Multi-Agent Scheme (DMAS) based on IMS-4G-Cloud network architecture for use as a new artificial intelligence mechanism for IMS-based mobility management. The DMAS consists of semiautonomous problem-solving agents that can solve large, complex problems and can cooperate with other agents [4]. A group of knowledge modules that collaborate through an in-cloud database is also used to perform problem solving tasks.

We describe the DMAS scheme based on QoS mechanism in Section 2. We then discuss the proposed agent implementation in DMAS architecture in Section 3. In order to fulfill these required results and analysis, we implement the prototype multi-agent paradigm and analyze the performance in Section 4. Finally, we summarize and conclude the analysis in Section 5.

The QoS mechanism and the intelligent agent required for cooperative QoS-awareness networking are described as follows.

The QoS metrics can be measured and monitored to determine whether an offered service level is achieved. These metrics include network availability, bandwidth, delay, jitter, and packet loss. Each QoS metric affects application performance. The differentiated service mechanism (Diffserv mechanism) guarantees QoS for Internet users. Instead of per flow guarantees by the integrated service mechanism (IntServ mechanism); it maps multiple flows into an aggregate service class denoted by a 6-bit Differentiated Services Code Point (DSCP) in the IP packet header. After the marked DSCP packets are recognized, a particular treatment or Per-Hop Behavior (PHB) is performed according to the class priority of each network node along a path. The proposed method uses a cost function and a QoS function that combines delay, jitter, the packet loss, free resource, mobility, and service fare. Delay, jitter, and packet loss are expressed by the ratio of the evaluated network to the accumulated networks parameter. Since this calculation assumes n number of evaluated WLAN, WiMAX, and UMTS networks, delay, jitter, and packet loss parameters are respectively given by:
                           
                              (1)
                              
                                 
                                    
                                       D
                                    
                                    
                                       ‾
                                    
                                 
                                 =
                                 1
                                 -
                                 
                                    
                                       
                                          
                                             delay
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             delay
                                          
                                          
                                             n
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       J
                                    
                                    
                                       ‾
                                    
                                 
                                 =
                                 1
                                 -
                                 
                                    
                                       
                                          
                                             jitter
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             delay
                                          
                                          
                                             n
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       L
                                    
                                    
                                       ‾
                                    
                                 
                                 =
                                 1
                                 -
                                 
                                    
                                       
                                          
                                             loss
                                          
                                          
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                          
                                       
                                       
                                          
                                             loss
                                          
                                          
                                             n
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Mobility cost is calculated by defining a parameter m as the ratio of the duration of user movement 
                           
                              τ
                           
                         to the total user lifetime connection t, i.e., 
                           
                              m
                              =
                              
                                 
                                    τ
                                 
                                 
                                    t
                                 
                              
                           
                        . Here, two conditions are applied: first, m is minimum if 
                           
                              τ
                              ≈
                              0
                           
                        , and m is maximum if 
                           
                              τ
                              ≈
                              t
                           
                        . According to the coverage areas of the UMTS, WiMAX, and WLAN networks, mobility cost M may vary by 0 or 1 depending on the value of 
                           
                              τ
                           
                         given by:
                           
                              (4)
                              
                                 
                                    
                                       M
                                    
                                    
                                       UMTS
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   1
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   τ
                                                   ≈
                                                   0
                                                
                                             
                                             
                                                
                                                   0
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   τ
                                                   =
                                                   t
                                                
                                             
                                          
                                       
                                    
                                 
                                 ;
                              
                           
                        
                        
                           
                              (5)
                              
                                 
                                    
                                       M
                                    
                                    
                                       WLAN
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   τ
                                                   ≈
                                                   0
                                                
                                             
                                             
                                                
                                                   1
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   τ
                                                   =
                                                   t
                                                
                                             
                                          
                                       
                                    
                                 
                                 ;
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       M
                                    
                                    
                                       WiMax
                                    
                                 
                                 =
                                 m
                              
                           
                        
                     

Additionally, network resource availability R equals 1 when resources are available. The service fare parameter applies a constant value C. The value is set to 1 for UMTS and WiMAX networks and to 0 for WLAN networks. Combining all parameters eventually obtains QoS cost given by:
                           
                              (7)
                              
                                 
                                    
                                       C
                                    
                                    
                                       QoS
                                    
                                 
                                 =
                                 
                                    
                                       (
                                       ε
                                       
                                          
                                             M
                                          
                                          
                                             (
                                             n
                                             )
                                          
                                       
                                       +
                                       β
                                       
                                          
                                             D
                                          
                                          
                                             ‾
                                          
                                       
                                       +
                                       δ
                                       
                                          
                                             J
                                          
                                          
                                             ‾
                                          
                                       
                                       +
                                       ϕ
                                       
                                          
                                             L
                                          
                                          
                                             ‾
                                          
                                       
                                       +
                                       θ
                                       C
                                       )
                                    
                                    
                                       R
                                    
                                 
                              
                           
                        
                     

The weighting value 
                           
                              ε
                              +
                              β
                              +
                              δ
                              +
                              ϕ
                              +
                              θ
                              =
                              1
                           
                         and parameters values are normalized as 0–1; i.e., the maximum QoS cost is 1. A lower score indicates a high quality network is being accessed. Regarding the intelligent agent, the operating value is first calculated based on the cost function. The Q-value is then estimated by the Q-Learning algorithm. Finally, the Q-value is stored by the DMAS Knowledge Source for use in finding the adaptive network when the original access network cannot guarantee QoS.

By learning the behavior of a network and its patterns, an intelligent agent can improve its efficiency in solving network problems [5]. Agents are software modules with cooperative capabilities such as capability to assist users and other agents. Fig. 2
                         compares the operations between an environment and intelligent agent. Reinforcement learning, which is based on the concept of an intelligent agent, is a learning mode. When a learning agent performs an action during a certain status, the environment rewards the learning agent with a reinforcement value or, conversely, punishes it.

The Q-Learning algorithm enables learning by reinforcement [6–8]. The algorithm enables systems to record all exceptive rewards and then execute all possible actions in each state. This operation requires Q-Learning operation exceptive reward E given by:
                           
                              (8)
                              
                                 E
                                 =
                                 Q
                                 
                                    
                                       
                                          
                                             
                                                s
                                             
                                             
                                                t
                                             
                                          
                                          ,
                                          
                                             
                                                a
                                             
                                             
                                                t
                                             
                                          
                                       
                                    
                                 
                                 +
                                 α
                                 
                                 
                                    
                                       
                                          
                                             
                                                r
                                             
                                             
                                                t
                                                +
                                                1
                                             
                                          
                                          +
                                          γ
                                          
                                             
                                                max
                                             
                                             
                                                a
                                             
                                          
                                          Q
                                          
                                             
                                                
                                                   
                                                      
                                                         s
                                                      
                                                      
                                                         t
                                                         +
                                                         1
                                                      
                                                   
                                                   ,
                                                   a
                                                
                                             
                                          
                                          -
                                          Q
                                          
                                             
                                                
                                                   
                                                      
                                                         s
                                                      
                                                      
                                                         t
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         a
                                                      
                                                      
                                                         t
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Eq. (8) shows the optimal exceptive reward of an action in each state. After executing each action, the system updates the exceptive reward based on the actual reward after executing an action and then updates the new exceptive reward of the new state. Notably, 
                           
                              Q
                              (
                              
                                 
                                    s
                                 
                                 
                                    t
                                 
                              
                              ;
                              
                                 
                                    a
                                 
                                 
                                    t
                                 
                              
                              )
                           
                         is the exceptive reward of adoptive action 
                           
                              
                                 
                                    a
                                 
                                 
                                    t
                                 
                              
                           
                         in state 
                           
                              
                                 
                                    s
                                 
                                 
                                    t
                                 
                              
                           
                        . Action 
                           
                              
                                 
                                    a
                                 
                                 
                                    t
                                 
                              
                           
                         is an action vector; 
                           
                              
                                 
                                    r
                                 
                                 
                                    t
                                    +
                                    1
                                 
                              
                           
                         is a reward; 
                           
                              γ
                           
                         is a discount rate; and 
                           
                              α
                           
                         is a learning rate of control convergence speed and also the weight of the reward just received. Initially, the system usually sets 
                           
                              α
                           
                         to 1, which is the maximum weight for the learning experience. When the learning system starts, 
                           
                              α
                           
                         gradually decreases to 0 and then 
                           
                              Q
                              (
                              
                                 
                                    s
                                 
                                 
                                    t
                                 
                              
                              ;
                              
                                 
                                    a
                                 
                                 
                                    t
                                 
                              
                              )
                           
                         stabilizes. Fig. 3
                         shows the steps of one-step Q-Learning.

DMAS consists of a collection of interacting agents connected to form a communications network. Each agent is a problem solver that can solve QoS policy issues in a heterogeneous network. Such an environment must interoperate to share knowledge/data and cooperate to problem solvers. Fig. 4
                         shows the basic DMAS system, which retrieves network QoS information from each accessible network and then sends it to other agents for learning and operations. The QoS_pAgent exchanges QoS parameters with each agent in heterogeneous networks. The QoS_dbAgent stores QoS parameters in the IMS database and in-cloud database and can immediately display QoS parameters via a web interface. The QoS_learningAgent selects one adaptive network from the Q-learning reward set. To obtain a satisfactory solution for a QoS policy issue, each agent in such an environment can either compute autonomously or cooperate with other agents. To realize this idea, the following three major modules were designed.

This multi-agent paradigm, as well as the relationship between different modules, is illustrated in Fig. 5
                        . Next, each problem-solving module is discussed separately.

For a large-scale application, the concept is to develop many expert systems (problem solvers) to assist an analyst with problem solving. Each expert, KS, has different knowledge and a different reasoning philosophy. To consider the practical applications of this research, the following five categories of KS were classified:
                           
                              (1) Local-planning KS.

(2) Meta-planning KS.

(3) Communication KS.

(4) Domain KS.

(5) Constraint KS.

The local-planning KS incrementally collects the partial results derived from the problem-solving QoS_pAgent. The meta-planning KS maintains the global status and makes decisions. The communication KS receives and broadcasts results in a network environment. The domain KS manipulates the heuristic rules (i.e., service priority, minimal bandwidth for different types of traffic) and facts related to QoS policy issues. The constraint KS defines the required criteria (i.e., Bandwidth B: the 
                           
                              
                                 
                                    B
                                 
                                 
                                    Allocated
                                 
                              
                           
                         is less than the 
                           
                              
                                 
                                    B
                                 
                                 
                                    Total
                                 
                              
                           
                        ) in the application domain. Fig. 6
                         gives examples of a basic rule in the rule base and a datum in the database. After the DMAS scheme is enabled and the current status is input into the test environment, the domain KS is fed into the scheme to infer the feasible schedules that satisfy the basic rules. Some criteria in the constraint KS must also be defined in order optimize the solution.

The in-cloud blackboard system is shared by KSs when they cooperatively solve problems. In this paradigm, the in-cloud blackboard module, which is a shared in-cloud database, consists of a data blackboard and a control blackboard. Both blackboards are structured with layers for parallelism, community and plurality. The data blackboard, which synthesizes the results, is separated into five layers:
                           
                              (1) Basic answer.

(2) Hypothesis.

(3) Partial result.

(4) Local optimality.

(5) Global optimality.

For enhanced efficiency of the inference process, the control blackboard also includes operation, model, policies, evaluation, and network layers.

Two basic issues should be considered when designing a multi-agent cooperative paradigm. The first is the optimal control of each problem-solving agent. The second is the transfer of partial results into a global optimal. Fig. 7
                         shows the control engine solves these problems by performing the following steps.
                           
                              Step 1.
                              Both domain knowledge and constraint knowledge are broadcasted to each agent (QoS_pAgent) assigned to participate in the problem-solving tasks.

Each agent executes local control based on the blackboard system with QoS mechanisms.

Partial results or local optimal results are broadcasted to the idle agents (QoS_learningAgent) to resolve conflicts in the Q-learning algorithm.

The process is executed repeatedly until a global optimum is reached.

The capability of DMAS to provide QoS extends the functionality of agents to support of session service continuity in the mobility management scheme. In the proposed agent implementation shown in Fig. 8
                     , QoS_pAgent is distributed along the boundary IP core network on each access network gateway. A Loc_pAgent is located on the edge domain of access network and is connected hierarchically to the QoS_pAgent, which is the parent agent that monitors movement of the Mobile Node (MN) in Fig. 9
                     . One QoS_pAgent controls several Loc_pAgents to obtain the information needed to maintain service continuity. In this extended architecture, the QoS_pAgent interchanges not only QoS parameters, but also the location information of MNs.

Interoperability between QoS_pAgent and Loc_pAgent perform by Universal Resource Identifier (URI). The URI message specifies the QoS parameter per Loc_pAgent@QoS_pAgent format. Fig. 10
                      shows the conventional IMS handoff mechanism used to maintain service continuity. An interruption in the data flow from Corresponding Node (CN) to MN triggers the IMS system to generate a new session setup to re-establish the service flow. After a new IP address is obtained from Dynamic Host Configuration Protocol (DHCP) server by performing a data link layer handoff, the MN sends a new REGISTER message to its Serving Call Session Control Function (S-CSCF). The S-CSCF may reply with 401 messages if MN is not authorized to access the service. When MN gets an OK message from S-CSCF, it sends an INVITE message to its S-CSCF, which then forwards the message to S-CSCF of CN. After data flow resumes, the CN replies with an OK message to the MN. The conventional IMS operations are shown in Fig. 10.

The DMAS system enables a predictive system to anticipate the session setup by imitating the reactive approach used in the conventional IMS mechanism. Three phases are defined to identify the proposed session setup by DMAS: prediction phase, pre-registration phase, and pre-negotiation phase. These three phases are adjusted into two cases of handoff. The first case assumes handoff is motivated by the need for an MN to change its attachment points due to service quality degradation, and the second case assumes handoff is motivated by MN mobility.

In the first case of handoff, the QoS_pAgent analyzes the QoS parameter on the evaluated network during the prediction phase. By coordinating with its Loc_pAgent, QoS_pAgent determines whether MN is experiencing QoS degradation. The updated parameter from MN is then passed to the QoS_learningAgent. The QoS_learningAgent immediately notes the updated cost and then compares the QoS parameter with the stored QoS cost parameter in QoS_dbAgent. It then replies to QoS_pAgent with a message containing the desired QoS cost for MN. The QoS_pAgent then broadcasts the minimum QoS cost obtained from the QoS_learningAgent to the neighboring QoS_pAgent. The QoS_pAgent that fulfills the QoS cost request is assigned as the candidate of new attachment point.

In the pre-registration phase, the candidate QoS_pAgent prepares its Loc_pAgent located close to the original attachment point of MN to register the new IP to DHCP server. The QoS_pAgent itself prepares the registration to S-CSCF. Meanwhile, in the pre-negotiation phase, the QoS_learningAgent prepares the Proxy-Call Session Control Function (P-CSCF) to buffer the data flow when the connection is interrupted. The data buffer space depends on the service application type.

In the second case of handoff, the difference in prediction phase is that the QoS_pAgent notices the handoff while monitoring the significant change in mobility parameter M from cost function given by Eqs. (4)–(6). Therefore, in the pre-registration phase, the QoS_learningAgent queries the QoS_pAgent to gain information about the network with a larger coverage area. In subsequent phases, handoff processes for this case are the same as those in the handoff case. Fig. 11
                      compares the handoff delay reduction with that in the conventional IMS handoff scheme.

@&#IMPLEMENTATION@&#

The prototype multi-agent paradigm is implemented using the Jess toolkit, which is a clone of the popular expert system shell written entirely in Java [9]. After users connect to networks to access services, the QoS_pAgent sends QoS parameters to another QoS_pAgent, to the QoS_dbAgent and to the QoS_learningAgent. When QoS_dbAgent receives the QoS parameters, it updates the IMS system database and in-cloud database and displays the update result on the web interface. The QoS_learningAgent then receives the QoS parameters and makes a handoff decision.

@&#RESULTS AND ANALYSIS@&#

Two analyses are performed to assess the performance of the proposed DMAS mechanism: cost analysis and handoff delay analysis. The environment has UMTS, WiMAX and WLAN with bandwidth capacity of 2Mbps, 14Mbps and 54Mbps, respectively. The UMTS/Node B, 802.16BS and 802.11AP are connected to their gateway with 8Mbps wired link. Links between each gateway have a 20Mbps capability. Links between the Internet and CN have a 100Mbps capability. The traffic types include VoIP and video streaming. The VoIP has 200bytes per packet, data rate of 64kbps, arrival at 2.0+ intervals and stop time of 120s. The video streaming has 1500bytes per packet, data rate of 256kbps, arrival at 5.0+ intervals and stop time of 120s. For cost analysis, one parameter was set to represent each network at each moment. Eq. (7) is the cost function. The 
                           
                              
                                 
                                    R
                                 
                                 
                                    UMTS
                                 
                              
                              ,
                              
                              
                                 
                                    R
                                 
                                 
                                    WLAN
                                 
                              
                           
                         and 
                           
                              
                                 
                                    R
                                 
                                 
                                    WiMAX
                                 
                              
                           
                         cannot all equal zero, since each mobile node must be in either a UMTS, WLAN or WiMAX network and must use resources while the cost function is calculated. The system operator can adjust parameter 
                           
                              ε
                              ,
                              
                              β
                              ,
                              
                              α
                              ,
                              
                              ϕ
                           
                         and 
                           
                              θ
                           
                        . If some mobile nodes intend to pay much to use UMTS and ensure that the connection is stable during movement, then parameter 
                           
                              θ
                           
                         can be enlarged. Parameters 
                           
                              β
                              ,
                              
                              α
                           
                         and 
                           
                              ϕ
                           
                         can be increased to ensure a QoS sufficient for conversational class service. Finally, if the service fare issue is very important for some users, then parameters 
                           
                              ε
                           
                         and 
                           
                              θ
                           
                         can be adjusted separately to suitable values. The simulation results are shown as follows. Fig. 12
                         shows the performance (cost) of VoIP and video streaming application.

The handoff case is tested for the QoS degradation case. Fig. 13
                         shows that the DMAS-IMS scheme outperforms the basic IMS handoff methodology in terms of handoff delay. The DMAS achieves this short delay by using the proposed a three-phase mechanism to shorten the handoff time. The DMAS-IMS also achieves a very low percentage of packet loss while the basic IMS suffers from packet loss because it lacks a buffering mechanism.

@&#CONCLUSION@&#

A DMAS is based on the distributed artificial intelligence technique and a group of knowledge modules that cooperate with one another through an in-cloud database to generate a policy that solves certain problems in an economic manner. It was developed for use with an efficient and flexible QoS-aware strategy to support IMS session continuity in a heterogeneous network. The developed system is implemented using the Jess toolkit and a Q-Learning awareness algorithm is then utilized to implement the DMAS to achieve overall utility in real-time, measured by network availability, the mobility of users, bandwidth, delay, jitter, and packet loss of components, which are optimized to maximize QoS and performance. The scheduling plan in the multi-agent scheme also satisfies all heuristic rules. The operations of, and cooperation among, the active agents, result in the selection of a policy and the generation of a user-accepted schedule that delivers the specified QoS.

The analysis of the performance based on a simulation verifies that the approach outperforms existing approaches. The DMAS not only is a valuable tool for managing QoS, but also can be extended to IMS-based mobility management. A similar methodology is applicable to the design of large-scale all-IP networks that support various traffic models to improve the optimization capabilities. Therefore, the proposed mechanism can be extended to inter-IMS scenarios. The proposed DMAS will help IMS-4G-Cloud network managers in QoS management in a cost-effective manner that is acceptable to customers.

@&#ACKNOWLEDGMENT@&#

This paper is a partial result of Project Nos. NSC 97-2219-E-011-008, NSC 98-2219-E-011-006 and NSC 99-2219-E-011-006 conducted by National Taiwan University of Science and Technology under the Sponsorship of the National Science Council, ROC.

@&#REFERENCES@&#


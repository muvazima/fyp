@&#MAIN-TITLE@&#Evaluating 3D spatial pyramids for classifying 3D shapes

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We introduce the 3D spatial pyramid representation for 3D shape categorization.


                        
                        
                           
                           This pyramid representation repeatedly subdivides a cube inscribed in the 3D shape.


                        
                        
                           
                           Then, a weighted sum of histogram of visual word occurrences is computed.


                        
                        
                           
                           Different types of kernels are integrated into the approach for training a SVM.


                        
                        
                           
                           Results on publicly available benchmarks have been reported.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

3D shape recognition

3D spatial pyramids

3D SURF descriptors

@&#ABSTRACT@&#


               
                  Graphical abstract
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

3D shape classification is a fundamental task to access existing 3D models on the level of object categories. This is specially important, if we take into account that the number of 3D models is growing rapidly, due to the fast evolution in both graphics hardware and software for 3D model acquisition and manipulation (e.g. 
                     [1–4]).

Recently, a novel approach, the 3D Spatial Pyramid Matching Kernel (3DSPMK) [5], has been introduced for object recognition in point clouds. Inspired by this work, we extend the original approach to be used in the context of category-level 3D shape recognition. First, we generalize the formulation of the 3DSPMK to arbitrary kernels, note that in [5] only the Histogram Intersection Kernel (HIK) is considered. This way, we propose a holistic representation for 3D shapes defining a general 3D Spatial Pyramid (3DSP) decomposition which can be used with multiple kernels, such as the extended Gaussian Kernel with the 
                        
                           
                              χ
                           
                           
                              2
                           
                        
                      distance. Note these kernels have shown promising results in image categorization [6].

We formulate a discriminative approach for recognizing 3D shape categories which is depicted in Fig. 1
                     . We start extracting 3D local descriptors (e.g.3D SURF [7] descriptors) from 3D shapes. These descriptors are then quantized, e.g. using K-means, so as to obtain a 3D visual vocabulary. Essentially, we build a Bag-of-Words (BoW) representation [8,9], which is a popular strategy for representing images, within the context of image categorization. Therefore, this visual vocabulary is used to represent the shapes following a BoW approach. The 3DSP repeatedly subdivides a cube inscribed in the 3D shape, and computes a weighted sum of histogram of visual word occurrences at increasingly fine sub-volumes. Selective volume decomposition strategies are used, as in [5], which drastically reduce the volume to consider, while the performance does not decrease.

In order to offer to the research community a clear benchmark for establishing further comparisons among different 3D shape categorization methods, we also propose an elaborate experimental setup using different publicly available datasets (SHREC'12 [10], Princeton Shape Benchmark [11], TOSCA [12] and Sumner[13]). We perform a thorough evaluation of our novel approach on this experimental setup.

The rest of the paper is organized as follows. Section 2 describes related work. The 3DSP is detailed in Section 3. The experimental setup and results are presented in Sections 4 and 5, respectively. We conclude in Section 6.

@&#RELATED WORK@&#

The problem of 3D shape class recognition has been extensively explored in the literature, and both local and global features have been proposed. A considerable variety of global descriptors have been detailed, such as the shape moments [14] or the shape histograms [15]. However, neither partial shapes, nor intra-class variations are successfully handled by global descriptions.

In the 2D case, it is well known that the use of local features is beneficial for the object recognition problem. In the literature, there are also 3D shape categorization methods using local features. Local 3D features can be extracted directly from the 3D volume (voxels) (e.g. 
                     [7,16–18]) or from 2D surfaces embedded in the 3D space (3D mesh) (e.g. 
                     [19–22]). Within the first group, scale-dependent and scale-invariant local 3D shape descriptors are proposed in [16], variants of SIFT [23] and SURF[24] are introduced in [17] and [7] respectively, and a localized version of the volumetric feature SHD [25] is proposed in [18]. Mian et al.introduce the use of local tensors [26]. Additionally, we also find works where the descriptors are extracted from range data, e.g. 
                     [27] where 3D shape context descriptors are extracted in 3D from the point cloud which emerges from the depth image.

Knopp et al.
                     [7] introduce the 3D SURF descriptors in combination with a probabilistic Hough voting framework for the purpose of 3D shape class recognition. Our approach significantly differs from [7]. First, their model does not introduce any 3D pyramid representation for the shape. Second, instead of providing a discriminative approach with a SVM framework, a generative approach inspired by the Implicit Shape Model [28] is presented.

A BoW for 3D shape categorization can be found in [29]. Toldo et al.
                     [29] describe 3D shapes by splitting them into segments, which are then described on the basis of their curvature characteristics. These novel descriptors attached to the regions are then vector-quantized into multiple visual vocabularies. For each shape a BoW representation per codebook is build, and multiple SVMs are used for classification. The main differences between our approach and [29] are the following. In [29] a standard BoW characterization approach is used in conjunction with the HIK for a classification with SVMs. That is, the approach in [29] does not build any 3D spatial pyramid representation which is able to enrich the BoW representation with coarse-grained geometric cues. Furthermore, instead of using just a single visual codebook, in [29] up to 108 different visual vocabularies are needed for the categorization of each particular 3D shape.

The method closest to ours is that of Redondo-Cabrera et al.
                     [5]. They introduce the 3DSPMK, using only the HIK kernel, and for the particular problem of recognizing objects in depth images. However, we proceed to extend this approach to the problem of 3D shape recognition. Moreover, instead of just using the HIK kernel, we generalize the formulation to define a 3D spatial pyramid decomposition which can be integrated with different type of kernels in a discriminative approach using a SVM framework. This way, we are able to combine the 3D spatial pyramid with an extended Gaussian kernel using 
                        
                           
                              χ
                           
                           
                              2
                           
                        
                      distances. Our results confirm the convenience of this extension so as to increase the shape class recognition performance.

For the 3DSP, we propose to characterize each 3D shape using local features. As it is shown in Fig. 1, the approach starts from a 3D shape of the object of interest. Each shape is characterized by a set of 3D local descriptors, e.g.3D SURF descriptors [7]. Fig. 2
                         shows an example of extraction of 3D SURF descriptors from a 3D shape. In contrast to a random or dense coverage of the shape with spin images [19], the 3D SURF is equipped with a 3D interest point detector, which picks out a repeatable and salient set of interest points in the shapes. The local 3D SURF descriptors are computed in these points via uniformly sampling Haar-wavelet responses. Then, by following a traditional BoW approach, we quantize these 3D descriptors, into 3D visual words. Finally, each 3D shape can be characterized by a histogram of its 3D visual words.

We proceed to generalize the formulation of the 3DSPMK introduced in [5]. Let us assume we model a 3D shape 
                           S
                         by an orderless set of 3D visual words. That is, if we define a visual codebook C of size K, each 3D feature is associated to a codebook label 
                           {
                           1
                           ,
                           …
                           ,
                           K
                           }
                        . We could characterize each shape 
                           S
                         with a histogram 
                           H
                           (
                           S
                           )
                         quantizing the occurrences of the 3D visual words.

However, the 3DSP representation should be able to capture the spatial distribution of such labels at different scales and locations in a working volume 
                           
                              
                                 Ω
                              
                              
                                 (
                                 0
                                 )
                              
                           
                        . Therefore, we define a pyramid structure by partitioning 
                           
                              
                                 Ω
                              
                              
                                 (
                                 0
                                 )
                              
                           
                         into fine sub-cubes (see Fig. 3
                        ). For each level l of the pyramid, the volume of the previous level, 
                           
                              
                                 Ω
                              
                              
                                 (
                                 l
                                 −
                                 1
                                 )
                              
                           
                        , is decomposed into eight sub-cubes, hence a pyramid P(L) of L levels contains 
                           D
                           =
                           
                              
                                 8
                              
                              
                                 L
                              
                           
                         sub-cubes.

Before building the spatial pyramid representation, and in order to achieve a spatial distribution of 3D visual words that occupies the greatest possible proportion of working volume 
                           
                              
                                 Ω
                              
                              
                                 (
                                 0
                                 )
                              
                           
                        , we perform a centering and scaling process of the initial spatial distribution of 3D visual words. This process is detailed in Fig. 4
                        .

Once a pyramid P(L) is composed, we define the 3DSP representation of a particular 3D shape 
                           S
                         by a weighted ensemble of histograms 
                           H
                           (
                           S
                           )
                         as follows:
                           
                              (1)
                              
                                 H
                                 (
                                 S
                                 )
                                 =
                                 [
                                 
                                    
                                       ω
                                    
                                    
                                       0
                                    
                                 
                                 
                                    
                                       H
                                    
                                    
                                       0
                                    
                                 
                                 (
                                 S
                                 )
                                 ,
                                 
                                    
                                       ω
                                    
                                    
                                       1
                                    
                                 
                                 
                                    
                                       H
                                    
                                    
                                       1
                                    
                                 
                                 (
                                 S
                                 )
                                 ,
                                 …
                                 ,
                                 
                                    
                                       ω
                                    
                                    
                                       L
                                    
                                 
                                 
                                    
                                       H
                                    
                                    
                                       L
                                    
                                 
                                 (
                                 S
                                 )
                                 ]
                                 ,
                              
                           
                        where 
                           
                              
                                 H
                              
                              
                                 l
                              
                           
                           (
                           S
                           )
                         is the histogram of the features in the level l of the pyramid. Each 
                           
                              
                                 H
                              
                              
                                 l
                              
                           
                           (
                           S
                           )
                         is obtained by concatenating 
                           
                              
                                 8
                              
                              
                                 l
                              
                           
                         histograms computed in all of the 
                           
                              
                                 8
                              
                              
                                 l
                              
                           
                         sub-cubes for level l. In order to penalize the future matches (between histogram bins) found in larger volumes, we define the weight 
                           
                              
                                 ω
                              
                              
                                 l
                              
                           
                         as


                        
                           
                              (2)
                              
                                 
                                    
                                       ω
                                    
                                    
                                       l
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             2
                                          
                                          
                                             L
                                             −
                                             l
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Eq. (1) contains the general formulation of the 3DSP representation for any shape. In order to use the 3DSP representation in a discriminative approach, we can incorporate different kernels into the formulation. This way, based on the fundamental concept of defining similarities between objects, these representations allow the integration of the 3DSP in a SVM classifier, for example. In particular, we propose to incorporate two different kernels: the Histogram Intersection Kernel (HIK) and the extended Gaussian kernel with 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         distances.

The 3DSP-HIK kernel 
                           
                              
                                 K
                              
                              
                                 3
                                 DSP
                                 -
                                 HIK
                              
                           
                         is formulated as follows. When a pyramid decomposition P(L) is constructed, we are able to perform a pyramid matching in 3D of two 3DSP 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                           )
                         and 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 Y
                              
                           
                           )
                        , computed for shapes 
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                         and 
                           
                              
                                 S
                              
                              
                                 Y
                              
                           
                        . The 3DSP-HIK kernel is defined as
                           
                              (3)
                              
                                 
                                    
                                       K
                                    
                                    
                                       3
                                       DSP
                                       −
                                       HIK
                                    
                                 
                                 (
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       X
                                    
                                 
                                 )
                                 ,
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       Y
                                    
                                 
                                 )
                                 )
                                 =
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                 min
                                 
                                    
                                       (
                                       H
                                       (
                                       
                                          
                                             S
                                          
                                          
                                             X
                                          
                                       
                                       )
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 H
                                 
                                    
                                       (
                                       
                                          
                                             S
                                          
                                          
                                             Y
                                          
                                       
                                       )
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                              
                           
                        where N is the number of components of histograms 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                           )
                         and 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 Y
                              
                           
                           )
                        , and 
                           H
                           
                              
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       X
                                    
                                 
                                 )
                              
                              
                                 i
                              
                           
                         represents the value of the ith bin of the histogram.

Additionally, we can formulate the 
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         kernel 
                           
                              
                                 K
                              
                              
                                 3
                                 DSP
                                 -
                                 
                                    
                                       χ
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        . Starting from a pyramid decomposition P(L) and two 3DSP representations 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                           )
                         and 
                           H
                           (
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                           )
                         for shapes 
                           
                              
                                 S
                              
                              
                                 X
                              
                           
                         and 
                           
                              
                                 S
                              
                              
                                 Y
                              
                           
                        , we first define the 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         distance between them as
                           
                              (4)
                              
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             χ
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       X
                                    
                                 
                                 )
                                 ,
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       Y
                                    
                                 
                                 )
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       
                                          
                                             (
                                             H
                                             
                                                
                                                   (
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         X
                                                      
                                                   
                                                   )
                                                
                                                
                                                   i
                                                
                                             
                                             −
                                             H
                                             
                                                
                                                   (
                                                   
                                                      
                                                         S
                                                      
                                                      
                                                         Y
                                                      
                                                   
                                                   )
                                                
                                                
                                                   i
                                                
                                             
                                             )
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       H
                                       
                                          
                                             (
                                             
                                                
                                                   S
                                                
                                                
                                                   X
                                                
                                             
                                             )
                                          
                                          
                                             i
                                          
                                       
                                       +
                                       H
                                       
                                          
                                             (
                                             
                                                
                                                   S
                                                
                                                
                                                   Y
                                                
                                             
                                             )
                                          
                                          
                                             i
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        and we formulate the 
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         kernel as follows:
                           
                              (5)
                              
                                 
                                    
                                       K
                                    
                                    
                                       3
                                       DSP
                                       −
                                       
                                          
                                             χ
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       X
                                    
                                 
                                 )
                                 ,
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       Y
                                    
                                 
                                 )
                                 )
                                 =
                                 exp
                                 (
                                 −
                                 
                                    
                                       1
                                    
                                    
                                       A
                                    
                                 
                                 
                                    
                                       D
                                    
                                    
                                       
                                          
                                             χ
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       X
                                    
                                 
                                 )
                                 ,
                                 H
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       Y
                                    
                                 
                                 )
                                 )
                                 )
                                 ,
                              
                           
                        where A is a scalar which normalizes the distances. In the experiments, one can set A to the average 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         distance between all elements of the training set.

Note that the HIK and the extended Gaussian with 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         distances kernels satisfy the Mercer's conditions, as it has been proved in [30,31] respectively.

The 3DSP has one clear disadvantage: its high computational cost. For a pyramid of L levels and a vocabulary of size K, we will obtain a vector of dimensionality 
                              K
                              
                                 
                                    ∑
                                 
                                 
                                    l
                                    =
                                    0
                                 
                                 
                                    L
                                 
                              
                              
                                 
                                    8
                                 
                                 
                                    l
                                 
                              
                           , that is 
                              
                                 
                                    2
                                 
                                 
                                    l
                                 
                              
                            times more bins in each level with respect to the 2D version introduced in [32]. With the aim of jointly increasing the classification accuracy and the computational efficiency of the 3DSP, we can incorporate to our approach the equivalent selective volume decomposition schemes based on representative and discriminative (sub-)volume selection processes detailed in [5]. The main objective of these approaches is to reduce the large number of uninformative sub-cubes that yield unnecessary long histograms, while the performance does not decrease.

We define the 3DSP-K-Repre as the 3DSP with kernel K using the Representativeness-based selection method in [5]. This selective pyramid decomposition will incorporate into the pyramid only those (sub-)cubes that are likely to represent shape classes in our dataset. Let 
                              
                                 
                                    Ω
                                 
                                 
                                    (
                                    0
                                    )
                                 
                              
                            be the working cube for level zero. We first perform the pyramid decomposition until level L, so we obtain 
                              
                                 
                                    Ω
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    L
                                    )
                                 
                              
                            sub-volumes, where 
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    8
                                 
                                 
                                    L
                                 
                              
                           . We now define the working volume of level zero as 
                              
                                 
                                    
                                       
                                          Ω
                                       
                                       
                                          ^
                                       
                                    
                                 
                                 
                                    (
                                    0
                                    )
                                 
                              
                           , where the decomposition only includes those sub-cubes 
                              
                                 
                                    
                                       
                                          Ω
                                       
                                       
                                          ^
                                       
                                    
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    L
                                    )
                                 
                              
                            in which a percentage p of the 3D shape models are represented. We consider that a 3D shape is represented in a sub-cube if there is at least one feature for this shape falling in the sub-cube. Note that this pyramid volume selection process is performed at the beginning of the training, once all the 3D features have been extracted. This way, the new working volume 
                              
                                 
                                    
                                       
                                          Ω
                                       
                                       
                                          ^
                                       
                                    
                                 
                                 
                                    (
                                    0
                                    )
                                 
                              
                            can be used to build all the features to represent the different shapes.

We also define the 3DSP-K-Disc as the 3DSP with kernel K using the Discriminative Feature-based Selection approach in [5]. Although the representativeness-based selective method drastically reduces the working volume, it does not exploit the fact that the sub-volume selected may contain features that are not discriminative for the classes of interest. The objective of the Discriminative Feature-based selection scheme is to select those cubes that are likely to contain discriminative features. This time, we consider all the training shapes of all the classes to compute. Given a pyramid P(L), we inspect all the sub-volumes in level L, i.e. 
                           
                              
                                 
                                    Ω
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    l
                                    )
                                 
                              
                            for 
                              i
                              =
                              1
                              ,
                              …
                              ,
                              
                                 
                                    8
                                 
                                 
                                    L
                                 
                              
                           . For each sub-volume and each 3D shape class, we measure the proportion of shape models that contain at least one discriminative feature in each sub-volume. If this ratio is greater than an empirically fixed threshold, then the sub-volume 
                              
                                 
                                    Ω
                                 
                                 
                                    i
                                 
                                 
                                    (
                                    l
                                    )
                                 
                              
                            is considered as discriminative for the analyzed object class. The final discriminative decomposition is obtained by merging all the discriminative sub-volumes for each category. When do we consider a feature discriminative? We follow the feature score formulated in Eq. (3) of [5]: the ratio between the percentage of descriptors that belong to a particular feature for a shape class, and the proportion of descriptors that belong to the same feature when all the 3D shape categories are considered. That is, we are able to measure how informative for a particular 3D shape class a feature is. Subsequently, we select only those sub-volumes that contain this type of discriminative features.

Note that the proposed approaches are feature selection methodologies that do not affect the kernel formulations proposed.

For the 3D shape categorization problem, we propose an elaborate experimental setup with different publicly available datasets. Our aim is to provide to the research community a clear benchmark so as to establish further comparisons among different methods. We start describing the databases, and then how the evaluation of the results is going to be performed.

The following state-of-the-art publicly available databases are going to be used: SHREC'12 [10], Princeton [11], and TOSCA + Sumner [12,13]. All these datasets consists of clean and segmented 3D shapes (see Fig. 5
                        ).

The SHREC'12 - Generic 3D Shape Retrieval contest dataset [10] offers 1200 different 3D models distributed across 60 classes. Specifically, for each class, 10 models are used for training and 10 models for testing. We have done a random distribution of the 20 models per class in order to obtain the training and testing subsets. This distribution of data results interesting to analyze the performance of different approaches when only limited training data is available.

The challenging Princeton Shape Benchmark database [11] offers 1800 shapes of 7 classes. For the 3D shape classification experiment, we propose to use the coarse level two, with the subsets for training and testing proposed in [7]: for each class, half of the 3D shapes are used for training and half for testing.

Finally, the TOSCA [12] and the Sumner [13] databases are jointly used. This combination offers 474 shapes for a total of 12 classes. The 3D shapes appear in a variety of poses and with deformations. 66 randomly selected models are used for testing, and the rest for training, as in [7].

The proposed datasets define an experimental setup where more than 3400 3D shapes can be used for the performance evaluation of the different methods. We publicly distribute
                           1
                        
                        
                           1
                           The experimental setup described can be downloaded from http://agamenon.tsc.uah.es/Personales/rlopez/data/3dsr
                           
                         this experimental setup, including: the annotations and the training and testing subsets described; and a set of tools for accessing and managing the database annotations. Our aim is to establish a new benchmark for evaluating 3D shape categorization algorithms. By making this experimental setup available, we make it effortless for future researchers to perform similar performance analysis of their methods. Furthermore, a reference implementation of the code for reproducing all the results reported in this paper is also released.

For each database, we have clearly defined two main subsets: training and testing. Although the ground truth is offered for both subsets, the testing data must be used strictly for reporting of results alone, i.e. it must not be used in any way to train or tune the proposed approaches. Only the training data can be used for parameter tuning or feature selection, e.g. using n-fold cross-validation.

The proposed experimental setup offers a multi-class problem, and we propose two evaluations measures in order to compare different methods. First, the performance p of the classifier defined as
                           
                              (6)
                              
                                 p
                                 =
                                 
                                    
                                       TP
                                    
                                    
                                       TP
                                       +
                                       FP
                                    
                                 
                                 ,
                              
                           
                        where TP and FP are the number of true positives and false positives, respectively. Second, we propose to compute the confusion matrix for each method, and to calculate the mean of the elements on the main diagonal, a measure we refer to as Mean Correct Classification (MCC).

@&#RESULTS@&#

We evaluate our 3D shape categorization approach on all the dataset proposed in Section 4. In the experiments, we use a visual vocabulary of different sizes (K=200, K=400 and K=1000). The visual vocabulary is obtained performing a K-means clustering on a subset of the 3D SURF [7] descriptors extracted from the training 3D shapes. We represent each 3D shape by a 3D spatial pyramid. Typical pyramid level values for our experiments are 
                        L
                        =
                        {
                        0
                        ,
                        1
                        ,
                        2
                        }
                     . Note that when L=0, we simply have a standard BoW, but in our case in 3D. We report the performance of the 3DSP using the full volume of pyramid and also following the selective algorithms described in Section 3.2.1.
                        2
                     
                     
                        2
                        For the representativeness method, we fix the parameter p to 0.1. For the Discriminative Feature-based selection method, we fix 
                              τ
                            and 
                              β
                            to 0.7 and 0.5 respectively.
                     
                  

For the extraction of 3D SURF descriptors we use the original implementation provided in [7].
                        3
                     
                     
                        3
                        The binaries for computing 3D SURF descriptors can be downloaded from http://homes.esat.kuleuven.be/~jknopp/codes/index_codes.html
                        
                      Specifically, we start scaling each 3D shape to fit a cube with a side of length 256. Then, each shape is voxelized into the cube grid using the intersection of faces with the grid-bins. With the aim of covering the full 3D shape with local descriptors, we have experimentally chosen the following parameters for the 3D SURF descriptors: the distance between triangle mesh and the border of the cube is fixed to 30, and the threshold is fixed to 
                        
                           
                              10
                           
                           
                              −
                              8
                           
                        
                     .

For classification we use Support Vector Machines (SVMs). We explore how different kernel functions perform categorizing shapes. Specifically, we combine the 3DSP pyramid decomposition with HIK (3DSP-HIK) and 
                        
                           
                              χ
                           
                           
                              2
                           
                        
                      (
                        3
                        DSP
                        -
                        
                           
                              χ
                           
                           
                              2
                           
                        
                     ) kernels, which have shown promising results in image categorization [6]. The multi-class classification problem is solved training the SVM using the one-against-one strategy. We follow the approach in [33], and train 
                        N
                        (
                        N
                        −
                        1
                        )
                        /
                        2
                      classifiers (being N the number of classes) where each one is trained on data from only two classes. For testing, we follow the Max Wins voting strategy [33]: if one of the classifiers votes for the class i, then the vote for the i-th class is added by one. The class with the highest number of votes is selected for each image. In case that two classes have identical votes, we select the one with smaller index. Specifically, we use libSVM [34] for training and testing the classifiers. A 5-fold cross-validation on the training set to tune SVM parameters is conducted.

The results obtained by our method for the SHREC'12 data are show in Table 1
                        . The best result is obtained for the 
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                        , with a vocabulary size of 1000 and L=0. These results reveal that, for vocabularies of size 200 or 400, the higher the level of the 3DSP, the better the results. Both the -Disc and -Repre approaches significantly reduce the computation time, while, generally, the performance does not decrease. In this experiment we can observe that the SHREC'12 is a challenging dataset due to the high number of classes and the low number of training 3D shape examples (only 10 per class). In the winner configuration, only for two classes, Plier and NonFlying Insect, we obtain a classification accuracy of 100%, and for the classes, Door and Truck NonContainer the classification rate is 0%. Interestingly, when the vocabulary size is fixed to 1000, an increment in the pyramid level does not improve the classification results. Actually, the best results have been obtained by a 3DSP with L=0, i.e. a standard BoW approach. As we shall see in the experimental validation with the rest of datasets, this behavior is only observed with the SHREC'12 database. We believe this may have been caused by the following reasons: first, this dataset offers a high variability in terms of rotation and changes of viewpoint of the different models, a fact that definitely does not benefit our 3DSP approach when 
                           L
                           >
                           0
                         (we provide more details in Section 5.5.2); and second, the experimental setup designed for the SHREC'12 dataset is very challenging, offering just 10 examples to train each of the 60 classes.

The results obtained by our method for the Princeton Shape Benchmark data are show in Table 2
                        . The best result is obtained for the 
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                        , with a vocabulary size of 1000 and L=1. Again, we observe that the 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         kernel is obtaining the best results. Systematically, the -Repre approach is also casting better results than the -Disc based version.


                        Figs. 6 and 7
                        
                         show the classification accuracy and the confusion matrix, respectively, for the best approach, i.e. 
                        
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         for L=1 and K=1000. For the Miscellaneous class is where our approach incurs the maximum confusion, and this is due to its high variability. The best recognition performance is achieved for the classes Plant and Furniture.

The confusion matrices and graph bars for all the approaches included in Table 2 can be inspected in the Experiment Code Item 1 in the Collage Platform.

The results obtained by our method for the TOSCA and Sumner databases are show in Table 3
                        . Our best result is 95.7%, which is obtained by several parameters configurations of our method. Figs. 8 and 9
                        
                         show the results per class for the 3DSP-HIK with K=1000 and L=1. First, one can observe that for 9 classes, our method obtains a classification rate of 100%. Furthermore, for all the classes, this percentage is above 80%. The confusion matrices and graph bars for all the approaches included in Table 3 can be inspected in the Experiment Code Item 1 in the Collage Platform.

In Table 4
                         we compare our results with the results reported in [7] for 3D shape classification. The 3DSP based approach improves the state-of-the-art for the Princeton database. It is worth to mention that this dataset is very challenging, not only due to the number of shapes, but because it presents a very high variation amongst the classes (e.g. within the class Animal, the dataset provides models for ants and fishes).

For the TOSCA+Sumner dataset, our best 3DSP based approach, i.e. the 3DSP-HIK with K=1000 and L=1, is able to retrieve 63 shapes (of 66) correctly. Note that in [7], authors claim they use 66 shapes for testing, but they only report results for 57, so the results for this dataset are not comparable.

In the novel SHREC'12 dataset, and to the best of our knowledge, we are the first reporting results for generic 3D shape categorization. We achieve a performance of 63.83% for the following configuration of our approach: 
                           3
                           DSP
                           -
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                        , K=1000 and L=1. This dataset offers a high number of classes, and the experimental setup designed provides very few shapes for training and testing, 10 per class. This makes the problem of training a SVM based approach, such as the 3DSP, really hard.

@&#DISCUSSION@&#

After this thorough performance evaluation, let us discuss the most relevant aspects of the 3DSP approach within the context of 3D shape categorization.

This paper introduces a novel and holistic approach for 3D shape categorization. The 3DSP approach has shown promising results on three diverse datasets. Apart from the parameters of the feature extraction stage and the kernels, two are the parameters that completely characterize the 3DSP approach: the pyramid levels (L) and the size of the vocabulary (K).

First, let us examine the behavior of the 3DSP when L increases. For all the kernels used, and when the vocabulary is small (e.g.200), the categorization results improve as we go from L=0 to a multi-level pyramid structure (L=1), in all the datasets. If we continue increasing the pyramid levels to L=2, the results do not generally improve. Actually, for the three datasets, one can observe how the performance of the entire 3DSP remains essentially identical or even decreases. This means that the highest level of the 3DSP if too finely subdivided in subcubes (for L=2 the number of subcubes is 64), which yield too few matches between the features within them. It is worth to mention that a similar behavior was observed in [32] but for the 2D spatial pyramids. To summarize, when using the 3DSP a good choice is to use L=1, because: a) higher values do not always guarantee better results, and b) the computational cost for 3DSP with 
                              L
                              ≥
                              2
                            increases.

In any BoW based approach the size of the visual vocabulary matters, and the 3DSP is no exception. In the experiments, we have increased the size of the vocabulary from K=200 to K=400 and K=1000. It is interesting to observe that increasing the size of the codebook for L=0 results in a small performance increase, if we compare it with the results obtained by smaller vocabularies used with a 3DSP structure of higher levels. For instance, in the Princeton dataset, we observe that a 3DSP with L=2 and K=200 obtains a higher performance (
                              64
                              ,
                              22
                              %
                           ) than a simple BoW (i.e.3DSP with L=0) with a vocabulary of size 400 (
                              61
                              ,
                              92
                              %
                           ) or 1000 (
                              63
                              ,
                              91
                              %
                           ). In general, the geometric cues provided by the 3DSP have a similar or even greater discriminative power than an enlarged visual vocabulary. For all the datasets the best results have been obtained by the biggest vocabularies. It is worth to recall that the dimensionality of the histogram-based feature of the 3DSP increases with K and L, so the smaller these parameters, the less the computational cost of the approach.

With respect to the feature extraction and kernel parameters, we can conclude that: a) in general, the performance of the 
                              
                                 
                                    χ
                                 
                                 
                                    2
                                 
                              
                            version of the kernel is better, although the runtime for the computation of the HIK is the lowest; b) the performance of the 3DSP-K-Repre approaches is slightly better than for 3DSP-K-Disc versions. Note that these two selective approaches significantly reduce the dimensionality of the histogram-based representation, while the performance does not worsen.

Definitely, one of the limitations of the 3DSP representation is its ability to deal with isometric transformations and deformations of the 3D shapes. It is important to analyze these aspects, because, when dealing with 3D data, the objects are rarely observed in a canonical frame of reference with respect to orientation. This is specially relevant to 3D categorization systems, where the test 3D shapes are generally given in arbitrary scale, position and orientation in 3D-space. Furthermore, these arbitrary orientations do not necessarily correspond to the orientations of the training samples.

In this section, we analyze the influence of the different parameters of the 3DSP approach on the recognition performance under rotations and deformations of the 3D shapes. For this analysis, we have decided to use the TOSCA+SUMNER dataset (this database presents a high variability in terms of both deformations and changes of orientation of the 3D models).

First, note that in the pipeline proposed for the 3DSP, we do not control the orientation of the 3D shapes given, i.e. the scaling and centering process shown in Fig. 4 does not modify the original orientation of the shape. The 3DSP is able to capture the spatial distribution of the local features extracted from the training 3D shapes at different scales and locations in a predefined working volume. Because the 3DSP only learns the geometric cues from the training data, it has some rotational variability.

If we inspect the 3D shape categorization results in the TOSCA + SUMNER dataset we observe that the 3DSP is able to deal quite well with the deformations and rotations of the models. For instance, as it can be seen in the confusion matrix provided in Fig. 9, for the class horse all the testing 3D shapes are correctly recognized. Fig. 10
                            shows all the test 3D shape for the class horse, note the changes of orientation and deformations. We explain this performance as follows.

The variance of the 3DSP to rotation will specially depend on the number of levels of the pyramid structure. Essentially, when L=0, our 3DSP is a standard BoW approach. Such an approach is invariant to rotation, if the local features extracted are also invariant under rotation and scale, which is the case for the 3D SURF features used. When 
                              L
                              >
                              0
                            the variance to rotation can augment. First, we have to recall that the 3DSP representation is a weighted ensemble of the histograms at each of the levels of the pyramid, including L=0 (see Eq. (1). This means that, even for a 3DSP of 
                              L
                              >
                              0
                           , the representation includes the invariant to rotation histogram for level 0. Additionally, it might happen that the rotation (or deformation) is so slight that the features involved do not move to different sub-volumes within the pyramid. Furthermore, the training data might provide similar rotation and deformation configurations to the ones observed during testing. These reasons explain the results of the 3DSP model in the TOSCA+SUMNER dataset.

In order to thoroughly evaluate the rotational variability of our approach, we have performed an additional experiment. It consist of the following steps. First, we take the previously trained models on the TOSCA+SUMNER dataset with the HIK kernel, for L=1 and L=2, and with a vocabulary of size 1000. For all the test 3D shapes, we incrementally rotate them from 0 to 
                              7
                              π
                              /
                              4
                           , in steps of 
                              π
                              /
                              4
                            radians (see Fig. 11
                           ). After each rotation, the 3D SURF descriptors are computed and the 3DSP representation is build. In Fig. 12
                            we show the classification performance versus the change in orientation.

First, Fig. 12(a) shows how the classification accuracy varies for 3DSP representations when no feature selection methods are used. It is interesting to observe the performance of the configuration 3DSPMKHIK for L=0, i.e. a standard BoW approach where no spatial pyramid is used. This configuration also shows a decrease of the performance under severe rotations of the models, which indicates that 3D SURF descriptors are not totally rotation invariant. We experimentally observe that the higher the level of the pyramid, the higher its rotational variability. Second, Fig. 12(b) shows that the rotational variability slightly increases for the Discriminative Feature-based approach.

We can conclude that the level of the pyramid is the most significant parameter. So, as for the 2D spatial pyramid [32], the 3DSP is not fully invariant to rotations and deformations. Even if the local features used are invariant to rotation, it is important that all further steps along the 3D shape categorization pipeline are as well. As a solution, any technique for automatically aligning the 3D shapes into a canonical coordinate frame (e.g. 
                           [35,36]) could be incorporated to our approach as a pre-processing stage.

The code has been written in Matlab with some parts in C. To perform the test we used an Intel Core 2 Quad CPU Q6600 @ 2.40GHz, running OS Ubuntu 12.04. The entire approach is computationally efficient. Recall that the 3DSP representation uses histogram vectors which are extremely sparse. Three are the parameters that most affect the runtime of the proposed pipeline: the vocabulary size, the pyramid levels and the type of Kernel (HIK or 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                        ). We again used the TOSCA+SUMNER dataset for this evaluation of the timing information. The overall process of building and testing the 3DSP representations for the 66 test models in the TOSCA+SUMNER dataset takes the times detailed in Table 5
                        . In general, the runtime slightly increases with the vocabulary size and the pyramid levels. The results also confirm that the HIK is more efficient than the 
                           
                              
                                 χ
                              
                              
                                 2
                              
                           
                         kernel.

We encourage the readers to try our methods through the Collage Platform. In Experiment Code Item 2, readers are allowed to upload the 3D SURF descriptors extracted from their own 3D shapes. With these descriptors, our algorithms will estimate a shape class. We refer to Experiment Data Item 2 to know more details on how to compute the 3D SURF descriptors, and how to use them with our trained models.

@&#CONCLUSION@&#

In this paper, we introduced the 3DSP representation in combination with two kernel definitions (the 3DSP-HIK and the 
                        3
                        DSP
                        -
                        
                           
                              χ
                           
                           
                              2
                           
                        
                     ) for the problem of 3D shape categorization. A thorough evaluation of these kernels has been carried out, and it demonstrates the power of the classification framework proposed on state-of-the-art databases. Rather than simply releasing a set of classification results, we defined an elaborate experimental setup, which we hope will allow to establish further comparisons with other methods dealing with the challenging problem of 3D shape class recognition. Last but not least, we have released a publicly available version of all the codes and data needed to reproduce the results.

Bringing in some weak form of textured information (if available in the 3D shape) is one interesting avenue of future research that might bring us closer to our goal. One way of doing so is combining the 3DSP approach with appropriate local 3D features, which also capture information from the texture.

@&#ACKNOWLEDGMENTS@&#

We want to thank the reviewers for their constructive and helpful suggestions. This work was partially supported by projects TIN2010-20845-C03-03, UAH2011/EXP-030 and IPT-2011-1366-390000.

Supplementary data associated with this article can be found in the online version at 10.1016/j.cag.2013.04.003.

Note from publisher: this material was originally submitted as part of the Collage Executable Paper pilot, please visit http://www.elsevier.com/executablepaper for more information.


                     
                        
                           
                              Note from publisher: this material was originally submitted as part of the Collage Executable Paper pilot, please visit http://www.elsevier.com/executablepaper for more information.
                           
                           
                        
                     
                  

@&#REFERENCES@&#


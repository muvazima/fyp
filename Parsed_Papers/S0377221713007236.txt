@&#MAIN-TITLE@&#Applying simulated annealing using different methods for the neighborhood search in forest planning problems

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We solve forest planning problems with adjacency and sequential flow harvest constraints.


                        
                        
                           
                           We develop three methods for introducing bias in the neighborhood search.


                        
                        
                           
                           Three hundred forests defined by three different initial age classes were tested.


                        
                        
                           
                           Comparisons based on objective function value and time consumption.


                        
                        
                           
                           Better results can be achieved by using the new methods compared to the conventional.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

OR in natural resources

Metaheuristics

Adjacency unit restriction model

Sequential flow

Biased probabilities

@&#ABSTRACT@&#


               
               
                  Adjacency constraints along with even flow harvest constraints are important in long term forest planning. Simulated annealing (SA) is previously successfully applied when addressing such constraints. The objective of this paper was to assess the performance of SA under three new methods of introducing biased probabilities in the management unit (MU) selection and compare them to the conventional method that assumes uniform probabilities. The new methods were implemented as a search vector approach based on the number of treatment schedules describing sequences of silvicultural treatments over time and standard deviation of net present value within MUs (Methods 2 and 3, respectively), and by combining the two approaches (Method 4). We constructed three hundred hypothetical forests (datasets) for three different landscapes characterized by different initial age class distributions (young, normal and old). Each dataset encompassed 1600 management units. The evaluation of the methods was done by means of objective function values, first feasible iteration and time consumption. Introducing a bias in the MU selection improves solutions compared to the conventional method (Method 1). However, an increase of computational time is in general needed for the new methods. Method 4 is the best alternative because, for large parts of the datasets, produced the best average and maximum objective function values and had lower time consumption than Methods 2 and 3. Although Method 4 performed very well, Methods 2 and 3 should not be neglected because for a considerable number of datasets the maximum objective function values were obtained by these methods.
               
            

@&#INTRODUCTION@&#

Long term forest management planning and optimization of forest management are complex tasks, and are highly dependent on mathematical programming and information technology. A typical example is optimization of economic income under temporal restrictions on roundwood harvest, e.g. non-decreasing harvest over time. This problem may be solved using different techniques, ranging from linear programming to other options like meta-heuristics depending on the complexity of the problem at hand. An important aspect of long term forest planning is spatial considerations and constraints on management in adjacent management units (MUs, i.e. forest stands), which are often imposed in order to preserve wildlife habitats or enhance scenic beauty. Such adjacency constraints typically restrict harvesting (clear cut) of neighboring MUs within or between time periods and have become an important part of forestry practices worldwide. For example in Norway, adjacency constraints as part of forest planning have recently been accentuated in a new act relating to nature areas in Oslo and nearby municipalities (Norwegian Act No. 35 of 5. June 2009) that imposes detailed spatial and temporal regulations on harvesting practices.

Norway has a long tradition in developing and applying decision support systems for long term forest planning (e.g. Bergseng, Eid, & Gobakken, in press). Gaya-SGIS, for example, is a system with a forest simulator (Hoen & Eid, 1990) and a linear programming (LP) module (Lappi, 2005) integrated in a GIS environment. In addition to timber production and corresponding cash flow, the forest simulator has been developed for studying carbon flows (e.g. Raymer, Gobakken, & Solberg, 2011) and utilization of biomass for bioenergy (e.g. Bergseng, Eid, Løken, & Astrup, 2013; Rørstad, Trømborg, Bergseng, & Solberg, 2010). The GIS linking of Gaya-SGIS allows for spatial considerations where GIS is used to modify the dataset for the simulator or to set restrictions for the input/output matrix that transfers data from the forest simulator to the LP solver (Lappi, 2005). No presently working decision support system developed in Norway, however, has incorporated any functionality dealing with adjacency constraints.

Internationally a lot of work has been done related to adjacency constraints in forestry (e.g. Baskent & Keles, 2005; Shan, Bettinger, Cieszewski, & Li, 2009). Adjacency constraints in long term forest planning as defined by Murray (1999) are divided into the unit restriction model (URM), where neighboring MUs are not allowed to be finally harvested in the same time period, and the area restriction model (ARM), where the total area of neighboring MUs with final harvest in the same time period should not exceed a defined maximum. Also, the concept of “green-up constraints” has been introduced in order to guarantee a time buffer between two consecutive final harvests in neighboring units, which can be used along with the URM and ARM approaches (e.g. Boston & Bettinger, 1999; Boston & Bettinger, 2006; Brumelle, Granot, Halme, & Vertinsky, 1998; Strimbu, Innes, & Strimbu, 2010).

In applications dealing with adjacency constraints two broad categories of optimization methods may be applied: exact techniques and heuristic methods. The exact techniques essentially make use of Integer Programming (IP) or Mixed Integer Programming (MIP). However, for some problems the use of such techniques may become impractical and time consuming, mainly due to the high combinatorial nature. In long term forest planning for example, the number of variables and constraints involved in the mathematical formulations grow exponentially with the number of MUs, the number of treatment schedules within MUs (a treatment schedule is a sequence of silvicultural treatments over time) and the number of time periods involved in the problem.

Heuristic methods aim for providing acceptable solutions within a given amount of time, rather than the optimal solution. Such methods are often used when the search space is discrete, which is the case in forest planning problems with adjacency constraints. Heuristic methods are often based on a neighborhood solution search approach. A broad definition of a neighborhood of a solution is “the set of solutions which differs slightly from the original one”. A search procedure usually iteratively move from one potential solution S, to an improved solution S′, in the neighborhood of S, until a stopping criterion has been satisfied. The size of a solution neighborhood can be extremely large depending on the size of the problem and how the neighborhood is defined, and may therefore be almost impossible to explore within reasonable time. Tabu Search (Glover, 1989; Glover, 1990) for example, analyzes the entire neighborhood before making a decision to move from one solution to another. Thus, techniques to reduce the neighborhood size are often applied in Tabu Search applications. These techniques are memory structures known as Tabu lists (e.g. Caro, Constantino, Martins, & Weintraub, 2003; Legües, Ferland, Ribeiro, Vera, & Weintraub, 2007).

Other heuristics such as Monte Carlo integer programming (MCIP) (e.g. Boston & Bettinger, 1999), threshold accepting (Dueck & Scheuer, 1990), great deluge algorithm (Dueck, 1993) and simulated annealing (SA) (Kirkpatrick, Gelatt, & Vecchi, 1983) are more suitable for working in large neighborhoods, since the criteria for moving from one solution to another depend on a stochastic process, i.e. a neighborhood solution is randomly chosen and then evaluated as acceptable or not. Most of these heuristics essentially differ based on the parameters used and mechanisms applied to prevent solutions from being stuck in local optima. MCIP, however, does not have this mechanism, so usually several initial starting points are needed to get a range of solution values.

SA has been successfully applied in forestry problems addressing adjacency constraints (e.g. Bettinger, Graetz, Boston, Sessions, & Chung, 2002; Boston & Bettinger, 1999; Liu et al., 2006; Lockwood & Moore, 1993; Öhman & Eriksson, 2002; Öhman & Lämås, 2005). The main reason for selecting SA is that this method is suitable for problems with a large solution space (neighborhood), which is particularly important in spatial adjacency forestry problem. SA is also simple to implement and fast in evaluating solutions.

A vital part of any SA application is how the solution neighborhood is constructed. The conventional approach in SA forestry applications is to generate a neighborhood solution by assuming a uniform probability distribution to select an MU, and then within the MU, another uniform probability distribution is applied to select either the period where the final harvest should occur or which treatment schedule to apply (e.g. Pukkala & Heinonen, 2006). Some studies have implemented approaches deviating from the conventional. Baskent and Jordan (2002) selected MUs assuming a uniform probability distribution, but final harvest was assigned to the period which returns the lowest harvested volume. Boston and Bettinger (1999) also assumed a uniform probability distribution when selecting MUs and planning periods in applications of MCIP and SA. For the MCIP application, however, they suggested a biased selection criterion for MUs to improve the solution quality as well as to extend the method to be applicable for more than three planning periods. A biased selection criterion in this context means that selection of MUs is not based on a uniform probability distribution. O’Hara, Faaland, and Bare (1989) used a heuristic that moved only through the feasible space and here three approaches with biased MU selection were compared with the unbiased approach. The biased approaches were based on improvements in the objective function value and on the fewest effective adjacent units, i.e. MUs producing fewer adjacency violations are prioritized. Barrett and Gilless (2000) compared several different heuristics, and implemented a bias in the MU selection by sorting MUs in descending order according to the total net present value (NPV) and NPV per ha of the MU.

Obviously, other methods for introducing biased distributions in the MU selection are possible, for example according to some properties related to the MUs such as mean NPV, number of constraints involving the MU or the number of treatment schedules for the MU. We are not aware of any previous work in the literature that has introduced bias in MU selection when using SA. The objective of this paper is therefore to assess the performance of SA under three different methods of introducing bias in the MU selection and compare them to the conventional method that assumes a uniform probability. We applied a case study with a large number of randomly generated forest landscapes to compare the four methods.

The remaining of this paper is organized as follows: Section 2 describes the general planning model, the case study based on a forestry problem, the simulated annealing approach including the four methods to explore the neighborhood of a solution and finally the measures for how the four methods are compared. Section 3 describe the results, Section 4 contains a discussion on how the methods perform, whereas Section 5 presents the conclusions.

@&#MATERIAL AND METHODS@&#

We use a standard formulation of a forestry planning problem where treatment schedules are selected within all MUs to fulfill the URM adjacency constraints and the sequential flow constraints regarding volume harvested (VH). The net present value (NPV) is maximized over an infinite time horizon. Only one treatment schedule is allowed per MU. The mathematical formulation of the problem is as follows:
                           
                              (1)
                              
                                 
                                    max
                                 
                                 
                                 Z
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       NPV
                                    
                                    
                                       ij
                                    
                                 
                                 ·
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 s
                                 .
                                 t
                                 .
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 1
                                 ,
                                 
                                 ∀
                                 i
                                 ∈
                                 N
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                 
                                    
                                       VH
                                    
                                    
                                       t
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                 
                                 ν
                                 
                                    
                                       h
                                    
                                    
                                       ijt
                                    
                                 
                                 ·
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                                 ,
                                 
                                 ∀
                                 t
                                 ∈
                                 T
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                 0.9
                                 ·
                                 
                                    
                                       VH
                                    
                                    
                                       t
                                       -
                                       1
                                    
                                 
                                 ⩽
                                 
                                    
                                       VH
                                    
                                    
                                       t
                                    
                                 
                                 ⩽
                                 1.1
                                 ·
                                 
                                    
                                       VH
                                    
                                    
                                       t
                                       -
                                       1
                                    
                                 
                                 ,
                                 
                                 t
                                 =
                                 2
                                 ,
                                 …
                                 ,
                                 T
                              
                           
                        
                        
                           
                              (5)
                              
                                 
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                                 +
                                 
                                    
                                       x
                                    
                                    
                                       
                                          
                                             i
                                          
                                          
                                             ′
                                          
                                       
                                       
                                          
                                             j
                                          
                                          
                                             ′
                                          
                                       
                                    
                                 
                                 ⩽
                                 1
                                 ,
                                 
                                 ∀
                                 (
                                 i
                                 ,
                                 
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                                 )
                                 ∈
                                 I
                                 ,
                                 
                                 ∀
                                 (
                                 j
                                 ,
                                 
                                    
                                       j
                                    
                                    
                                       ′
                                    
                                 
                                 )
                                 ∈
                                 J
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                 
                                    
                                       x
                                    
                                    
                                       ij
                                    
                                 
                                 ∈
                                 {
                                 0
                                 ,
                                 1
                                 }
                                 ,
                                 
                                 ∀
                                 i
                                 ∈
                                 N
                                 ,
                                 
                                 ∀
                                 j
                                 ∈
                                 
                                    
                                       M
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        where N is the number of MUs, Mi
                         is the number of treatment schedules within the MU
                           i
                        , T is the number of planning periods, I is the set of MU pairs that shares a border, J is the set of treatment schedule pairs within neighboring MUs that share at least one common clear cut period, NPVij
                         is the net present value associated with MU
                           i
                         when treated by treatment schedule j, VHt
                         is the total volume harvested in period t, vhijt
                         is the volume harvested in period t in MU
                           i
                         when treated by treatment schedule j.

The decision variables xij
                         takes the value 1 if treatment schedule j is applied to MU
                           i
                        , and 0 otherwise. Thus, Eq. (1) defines the objective function which maximizes NPV, Eqs. (2) and (6) secures that only one treatment schedule is allowed per MU and Eq. (3) defines the total volume harvested in each period. Inequalities (4) define a 10% allowed variation in the flow of the harvested volume between periods and inequality (5) defines the pairwise URM adjacency constraints, i.e. a constraint denying MUs sharing an edge (or a point) to be harvested in the same time period. These URM constraints are not exactly the same as defined by Murray (1999), because they can include more than one common clear cut period between two neighboring MUs. This type of constraints could also be formulated in a different way by using graph theory. Consider a graph where each node corresponds to an MU and the set of edges correspond to the neighboring between MUs, i.e. if two MUs are sharing a border (or point) an edge between the corresponding nodes is added to the graph. If we take into account a subset of MUs where all are neighbors to each other (complete sub-graph), and no other MU added to the set will fulfill this condition, then only one MU of the set forming a complete sub-graph can be clear cut in a certain period. The relation to graph theory is that a set of MUs in this condition is known to form a maximal clique. Thus, for each maximal cliques of the graph a constraint should be added to the model. Examples of using this formulation, and other formulations describing adjacency constraints, can be found in McDill and Braze (2000), McDill, Rebain, and Braze (2002), and Goycoolea, Murray, Vielma, and Weintraub (2009). The decision to formulate the URM adjacency constraints as pairwise in the present study was done in order to get it in accordance with our simulated annealing approach.

To compare the four methods for selection of a neighborhood solution in the SA approach, artificial forest landscapes were generated based on 8990 sample plots from the Norwegian national forest inventory (NFI). Sample plots were chosen with respect to productivity, stocking density and stand age in order to represent a very wide range of forest conditions in Norway. One hundred artificial forest landscapes for three different age class distributions were generated, i.e. “young”, “normal” and “old” forest landscapes (Table 1
                        ). Each dataset within a forest landscape encompasses 1600 MUs distributed over a grid of 40×40 cells. An area of 1ha was assigned to all cells. The grid configuration and the area assigned to each cell prevent effects of MU size and number of neighbors per MU to be involved when assessing the methods.

The artificial forest landscapes were generated in the following way: (1) the data base comprising the 8990 sample plots was grouped according to a age class distribution, (2) the number of NFI plots needed for each age class to obtain the desired age class distribution in the defined grid was computed, (3) select randomly from each age class the number of plots needed and randomly assign one NFI plot to each grid cell and finally (4) the treatment schedules simulated by the growth simulator GAYA for each chosen NFI plot were assigned to the corresponding grid cell. Step (3) and (4) were repeated 100 times creating 100 datasets within each forest landscape.

The total number of treatment schedules (number of decision variables) for young, normal and old forest landscapes, respectively, varied between 131,102 and 156,505, 136,044 and 156,963, 133,741 and 156,058. The average number of treatment schedules per MU were 89, 91 and 89 for young, normal and old forest landscapes, respectively. However, the number of treatment schedules per MU varied between 1 and 833.

The growth simulator GAYA (Gobakken, 2003; Hoen & Eid, 1990) was applied to generate treatment schedules. The simulator takes as input a set of MUs (plots) and a set of rules which define how and when forest treatments may be applied. The output provides detailed information on common forest state variables (e.g. standing volume) as well as treatments (e.g. harvested volumes) and corresponding economic values (incomes and costs) for all periods in each treatment schedule. In addition, the NPV based on an infinite planning horizon is provided for each treatment schedule. In this study the following treatments were allowed; natural regeneration and planting, pre-commercial thinning, conventional thinning and final harvest. This means that not only final harvests contribute to the volume harvested in a period but also conventional thinnings. Simulations were performed for ten 10-year periods. A 3% discount rate was applied.

@&#OVERVIEW@&#

SA is a meta-heuristic that establishes a relationship between the annealing of solids and optimization problems (Dowsland, 1995). The most important parameters used in SA applications are an initial temperature, the number of iterations allowed at each temperature, the cooling rate, and the final temperature at which the search is finished (e.g. Bettinger & Kim, 2008). During the search, solutions that produce improvements in the objective function value are always accepted. However, solutions with poorer objective function values can also be accepted depending on a probabilistic threshold which is defined by the current temperature and the difference between the current and candidate solution values. This prevents the search to get trapped in local optima. Also, during the search, the temperature is kept constant for a certain number of iterations and then reduced, thus lowering the probability of accepting solutions with poorer objective values. Candidate solutions are generated based on the current solution, and the search process usually finishes when certain criteria are fulfilled, e.g. when reaching the final temperature, after performing a certain number of iterations or when a consecutive number of iterations without improvements occur. In the present study SA was implemented as illustrated in Fig. 1
                           .

Four different methods were used to generate new solutions, the first method being the conventional one which was compared to three alternative methods (see Section 2.4 for details). For each method the solutions were evaluated according to the difference between the value of the objective function and the value of the penalty functions associated with the adjacency and sequential flow constraints. The resulting evaluation function is usually named “fitness function” and the respective value is named “energy”. A more specific description of the implemented SA is as follows:
                              
                                 1.
                                 Set SA parameters nv, coolr, itemp and method to select MUs (see Section 2.3.2 for details).

Generate an initial solution by assigning a random treatment schedule to each MU. Set this solution as current (S1) and best solution (BS).

Calibrate penalty functions and SA parameters (st and ft) according to the initial solution (see Section 2.3.2 for details).

Compute the energy of S1, i.e. the value of the objective function minus the value of the penalty functions.

Generate a candidate solution (S2) based on S1 by selecting randomly nv MUs according to one of the methods and assign a random treatment schedule.

Compute the energy of S2.

If the energy of S2 is greater than the energy of S1 (i.e. improvement occurs), go to step 8. Otherwise go to step 10.

If energy of S2 is greater than energy of BS, then BS becomes S2. Move to step 9.


                                    S2 becomes S1 and go to step 12.

If S2 does not produce any improvement, this inferior solution is accepted or not depending on a comparison between the value of a function e
                                    (Z1−Z2)/temp and a random number between 0 and 1 that follows a uniform distribution. Z1 and Z2 are the energy of S1 and S2 respectively and temp is the current temperature.

If the inferior solution is accepted, S2 becomes S1 and go to step 12. Otherwise go directly to step 12.

If itemp is reached, lower the temperature according to coolr and reset itemp to zero. Otherwise increase itemp by one.

If ft is not reached, go to step 4. Otherwise, report the BS found.

In general heuristics use procedures for local search and thus require a definition of the neighborhood. For our problem different neighborhoods could be considered, for instance only feasible solutions that are reachable from the current solution (e.g. Liu et al., 2006; Murray & Church, 1995). However, this approach is costly in terms of computational time (Liu et al., 2006). Instead, we define a simple neighborhood where one treatment schedule of a selected MU is changed for each iteration, typically called 1-opt moves. This definition preserves the non-violation of constraints (2) and (6) in the management model (see Section 2.1). Thus, only the URM and sequential flow constraints need to be evaluated regarding solution feasibility.

When using heuristics, one way to deal with constrained optimization problems is to relax some of the constraints by including them in the objective function as penalties in order to reduce the value of solutions that do not fulfill such constraints. The magnitude of the values for the penalty functions should be close to the original objective function values to secure that none of the components of the fitness function have influence on the others. However, construction and interpretation of penalty functions is a difficult task (Falcão & Borges, 2001) and if not calibrated properly, this may lead to non-convergence towards feasible solutions (Lockwood & Moore, 1993).

For our case, penalty functions for the URM and sequential flow constraints also needed to be developed. Quadratic penalty functions, which are frequently applied because they ensure that larger deviations from the targets are penalized more than small ones (e.g. Falcão & Borges, 2001; Falcão & Borges, 2002; Öhman & Eriksson, 1998) were adopted to address both adjacency and sequential flow constraints. The resulting penalty function and respective value at each iteration i is given by the following formula:
                              
                                 
                                    Φ
                                    (
                                    i
                                    )
                                    =
                                    
                                       
                                          A
                                       
                                       
                                          URM
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ∑
                                                      
                                                      
                                                         p
                                                         =
                                                         1
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                
                                                
                                                   
                                                      NoConflicts
                                                   
                                                   
                                                      ip
                                                   
                                                
                                             
                                          
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          A
                                       
                                       
                                          SF
                                       
                                    
                                    
                                       
                                          
                                             
                                                β
                                                
                                                   
                                                      
                                                         ∑
                                                      
                                                      
                                                         p
                                                         =
                                                         1
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                
                                                
                                                   
                                                      DevVH
                                                   
                                                   
                                                      ip
                                                   
                                                
                                             
                                          
                                       
                                       
                                          2
                                       
                                    
                                    ,
                                    
                                    
                                       
                                          A
                                       
                                       
                                          URM
                                       
                                    
                                    ,
                                    
                                    
                                       
                                          A
                                       
                                       
                                          SF
                                       
                                    
                                    >
                                    0
                                 
                              
                           where the process of convergence is influenced by the parameters AURM
                            and ASF
                            (Falcão & Borges, 2001) and where NoConflictsip
                            is the total number of clear cuts in neighboring MUs in period p at iteration i and DevVHip
                            is the deviation of volume harvested from the allowed interval in period p at iteration i.

Because URM and sequential flow constraints are measured in different units, we introduced the scaling factor β derived from the quotient between the total NoConflicts and the total DevVH obtained in the initial solution. This scaling factor can be seen as the value of one cubic meter deviation for URM adjacency violations. Due to the scaling factor β, both components of the penalty function (i.e. total NoConflicts and total DevVH) are in the same units. Along with the SA parameters tested (described next paragraph), we also tested the following three values for AURM
                            and ASF
                           :
                              
                                 (a)
                                 
                                    AURM
                                       =ASF
                                       =2×AverageNPV/MU, the loss of two average NPV per MU.


                                    AURM
                                       =ASF
                                       =AverageNPV/MU, the loss of one average NPV per MU.


                                    
                                       
                                          
                                             
                                                A
                                             
                                             
                                                URM
                                             
                                          
                                          =
                                          
                                             
                                                A
                                             
                                             
                                                SF
                                             
                                          
                                          =
                                          
                                             
                                                AverageNPV
                                                /
                                                MU
                                             
                                             
                                                2
                                             
                                          
                                       
                                    , the loss of half of the average NPV per MU.

These values represent how much the loss in monetary values will be if one URM adjacency constraint is violated. The Average NPV/MU is computed by first calculating the average NPV for each MU according to the treatment schedule list. Finally, an overall average is computed based on all MUs.

The quality of the obtained solutions is dependent on the parameters set and finding suitable values therefore require several test runs. Usually some values for each parameter are tested and the combination producing the best results is adopted. Since a large number of datasets were evaluated, the parameterization process was simplified, i.e. rather than applying this process to all datasets, we used subsets from each forest landscape (5%) and a reduced number of parameter options. Then, the best parameter values found for these subsets were applied to all datasets within each forest landscape. Since our aim is to assess the performance of the new methods for generating a neighborhood solution against the conventional method, the parameters were set for the latter and then applied also for the new methods.

The starting temperature (st) was set considering the first solution produced (Bettinger & Kim, 2008). The following formula was used:
                              
                                 
                                    st
                                    =
                                    
                                       
                                          -
                                          
                                             
                                                p
                                             
                                             
                                                1
                                             
                                          
                                          ×
                                          (
                                          
                                             
                                                NPV
                                             
                                             
                                                0
                                             
                                          
                                          )
                                       
                                       
                                          ln
                                          (
                                          
                                             
                                                p
                                             
                                             
                                                2
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           where NPV
                           0 is the NPV from the initial solution produced by SA, p
                           1 is a percentage of the initial NPV defining a variation value and p
                           2 is the probability to accept the previous variation. We define the probability of p
                           2 to accept worse solutions that vary by p
                           1 from the initial NPV value. For our datasets we set p
                           1
                           =1% and tested p
                           2
                           =1%, 10%, and 20%. Regarding the final temperature (ft), exploratory analysis indicated that setting the value to 1% of the st was more than enough to secure convergence. This also shows that the total number of iterations performed for each dataset within a landscape was very similar. Finally, for each option of the penalty function parameters, we tested different values for the cooling rate and for the number of iterations at the same temperature. For all datasets, four cooling rates (0.97, 0.98, 0.99, and 0.995) and four distinct numbers of iterations at the same temperature (2000, 3000, 4000, and 5000) were tested.

Because SA has stochastic properties, we performed 10 runs with different seeds (same seeds were applied for all methods) for each dataset, and all runs started with the same initial random solution. The number of test runs in each dataset, within a forest landscape used to find the best combination of parameters, was 1440 leading to a total of 21,600 test runs. Moreover, we also obtained the optimal solution of each dataset using CPLEX 1.25 with the default settings. The difference between a solution reported from each test run and the value of the optimal solution of the CPLEX is defined as GAP.The final parameters used (Table 2
                           ) were set to the combination of parameters producing the lowest average GAP of SA regarding the solution obtained by CPLEX. This average GAP was obtained by averaging the GAPs obtained by each feasible test run of SA within a combination of parameters. The values for β and ft, were obtained from each dataset, i.e. they were dataset specific.

The same procedure as described for the test datasets was also performed for the remaining datasets. The SA implementation was developed in VB.NET, framework 4.0 and tests were run in an Intel(R) Xeon(R) X5650, 2.67gigahertz CPU.

Method 1 (i.e. the conventional method) assumes a uniform probability distribution for selection of a new solution (candidate solution) in the neighborhood of the current solution, i.e. the neighborhood of a solution is explored by first randomly selecting MUs and then randomly selecting treatment schedules within MUs.

Exploring the neighborhood of a solution in this way may in certain occasions be inefficient because a large number of iterations are performed without any improvement in the solution. Fig. 2
                            shows two possible situations where the number of treatment schedules within the MUs is equal (a) and different (b). In the example in Fig. 2b, it is expected that one third of the overall iterations performed will generate new solutions where MU3 and TS1 (within MU3) are selected. This movement, with a high probability (1/3) to be proposed, will result in a candidate solution equal to the current solution. Thus, MUs with few treatment schedules will dominate the search and make it less flexible. A solution taking into account the number of treatment schedules might be more efficient.

In Method 2, the probabilities assigned to each solution in the neighborhood of a solution are defined taking the number of treatment schedules into account. Instead of using a uniform distribution probability to select MUs, the probability distribution is defined according to the number of treatment schedules within each MU. This approach is intended to diversify the search in a simple way, i.e. explore solutions that might not be evaluated when using the conventional method.

To maintain the process of generating new solutions, i.e. randomly selecting MUs and afterwards randomly selecting treatment schedules for the MUs, and at the same time taking into consideration that the selection of MUs should be done according to the number of treatment schedules (Fig. 2c), SA needs an adaptation before it starts to produce new solutions. We introduce a static search vector, where the values assigned to each entry of the vector are unchanged throughout the search. The procedure to create the search vector was as follows:
                              
                                 1.
                                 First, for each MU (N), the probability of selection (P(MUi)) is computed by dividing the treatment schedules within each MU (Mi
                                    ) with the total number of treatment schedules among all MUs;


                           
                              
                                 2.
                                 Then a search vector is created such that each entry i corresponds to the cumulative probability of selecting an MU
                                       i
                                    . The procedure was as follows:
                                       
                                          (1)
                                          Create a vector with dimension equal to the number of MUs plus one and set the first entry to zero.

Then for each entry i (greater than zero), compute the summation between the previous entry and the P(MUi
                                             ).

The main advantage of building the search vector in this way is that it is sorted (ascending) and thus, a binary search can be applied. From the example in Fig. 2c we can see that by letting X
                           ∊[0,1] be a uniform random variable, and if X
                           ⩽2/9,then MU1 is selected to assign a treatment schedule, if 2/9<
                           X
                           ⩽8/9,then MU2 is selected and if 8/9<
                           X
                           ⩽1, then MU3 is selected.

This method may also produce ineffective search of the neighborhood since a large number of treatment schedules not necessarily implies that the schedules are strongly dissimilar in terms of for example the contribution to the value of the objective function.

In Method 3, the probabilities to select a neighborhood solution are defined in order to prioritize the selection of MUs that have the highest standard deviation for NPV (SDNPV) between treatment schedules within an MU;
                              
                                 
                                    P
                                    (
                                    
                                       
                                          MU
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                SDNPV
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                SDNPV
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ,
                                    
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    N
                                 
                              
                           
                        

Thus, this approach searches solutions in the neighborhoods with large variability in order to obtain better gains in the objective function. This means that we have built a static search vector as in Method 2, but instead of using the number of treatment schedules as a basis for defining the probabilities associated with each MU, we use the standard deviation of the NPV values among all treatment schedules within each MU.

Searching the neighborhood for a solution using this method may result in the assignment of a probability equal to zero for MUs that have a standard deviation equal to zero. This could be beneficial since after the initial solution, MUs with only one treatment schedule will not be proposed again and also since small standard deviations in NPV indicates that related gains in the objective function value are small. However, at the same time, MUs with few treatment schedules, but with a large standard deviation in NPV may cause the search to perform many turns around the same solution.

In Method 4, we combine Methods 2 and 3. The probabilities to select a neighborhood solution are defined considering both the number of treatment schedules and the NPV standard deviation value within MUs. The combination of these two methods aims to mitigate the disadvantages of both, and at the same time use the best of them. Thus, the idea is to assign to each MU a probability by using the following formula;
                              
                                 
                                    P
                                    (
                                    
                                       
                                          MU
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    =
                                    α
                                    ×
                                    
                                       
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                M
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    +
                                    (
                                    1
                                    -
                                    α
                                    )
                                    ×
                                    
                                       
                                          
                                             
                                                SDNPV
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                N
                                             
                                          
                                          
                                             
                                                SDNPV
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    ,
                                    
                                    ∀
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    N
                                    ,
                                    
                                    α
                                    ∈
                                    [
                                    0
                                    ,
                                    1
                                    ]
                                 
                              
                           Here α may take any value between 0 and 1, but is in our case set to minimize the absolute difference between the Pearson correlation coefficient obtained between the number of treatment schedules and the probability assigned and between the NPV standard deviation and the probability assigned. Note that we did not consider α
                           ∊{0,1} because these values are particular cases equal to Methods 2 and 3, respectively. The resulting static search vector is obtained by applying the procedure as described for Methods 2 and 3.

As we use penalty functions and have no guarantee that the final solutions reported are feasible, average values for the objective function value, first feasible iteration and time consumption were computed considering only runs that report solutions without violation of the constraints.

The performance of the four methods follows some of the proposed procedures described in Bettinger, Sessions, and Boston (2009). We started by comparing the solutions obtained from each dataset and each SA run against the respective optimal solution (CPLEX solution) of the dataset, i.e. the Level 6 procedure described in Bettinger et al. (2009). Also first feasible iteration and time consumption is computed and compared for the four methods. Within a dataset averages of these three criteria were computed and compared. Thus, the average performance is established (Bettinger et al., 2009). We also evaluated the methods statistically applying the Wilcoxon pairwise signed-rank test (Wilcoxon, 1945).

The new methods were also compared (pairwise) against the conventional method through the relative difference (RD) approach (see e.g. Yoshimoto, Brodie, & Sessions 1994);
                           
                              
                                 
                                    
                                       RD
                                    
                                    
                                       Mi
                                    
                                 
                                 (
                                 %
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             GAP
                                          
                                          
                                             Mi
                                          
                                       
                                       -
                                       
                                          
                                             GAP
                                          
                                          
                                             M
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             GAP
                                          
                                          
                                             M
                                             1
                                          
                                       
                                    
                                 
                                 ×
                                 100
                              
                           
                        where GAPMi
                         is the average GAP obtained by method i and GAPM1
                         is the average GAP obtained by the conventional method. Thus, negative values of RD imply that the proposed method perform better than the conventional method. Here we assumed that Method 1 is the standard heuristic as described by Bettinger et al. (2009) for the Level 3 procedure.

Finally, for each dataset within a forest landscape, we compared the best objective function values (without constraints violations) obtained from each method by ranking them as the 1st (best), 2nd, 3rd and 4th (worst). This comparison establishes what is called the best case performance (Bettinger et al., 2009).

@&#RESULTS@&#

The average GAPs, average numbers of first feasible iteration and average time consumption obtained by the methods are shown in Fig. 3
                      while statistical tests comparing these measures are shown in Table 3
                     .

For all methods and forest landscapes, the average GAPs display medians below the median of Method 1 (red in Fig. 3). For this measure all the three new methods therefore performed better than Method 1. This was also confirmed by the statistical tests (Table 3). The comparisons between Methods 2, 3 and 4 showed that the GAPs for Method 4 was significantly lower than for Method 2 and 3 in young and normal forest landscapes while no significant difference was seen in the old forest landscape.

For young and old forest landscapes the average number of iterations needed to reach the first feasible solution seemed to be higher for the new methods (Fig. 3). However, the statistical tests did not confirm this for the young forest landscape while they did for the old forest landscape (Table 3). In the normal forest landscape no special trends were observed.

In general the time consumption l for the old and normal forest landscapes was higher for the new methods compared to Method 1. Method 4 seemed to need less time than the other methods in young and normal forest landscapes (Fig. 3). However the latter was not confirmed by the statistical test (Table 3).

The RD regarding the average GAP (Fig. 4
                     ) showed that in more than 75% of the young and normal forest landscapes improvements were obtained by the new methods. Moreover, in almost all datasets in the young forest landscape, Method 4 was capable of producing improvements. For the old forest landscape the new methods performed better in more than 50% of the datasets. However, statistical tests (Wilcoxon pairwise signed-rank test at 0.01% significance level) showed no significant differences between the methods.

The ranks obtained for the best objective function values for each method and forest landscape are reported in Table 4
                     . Method 1 obtained very few datasets as the best method and often appeared as the 3rd or 4th best method. The total frequencies of 3rd and 4th ranks for Method 1 were 91, 88 and 83 for young, normal and old forest landscapes, respectively. The rankings obtained for Method 4 were in general the opposite of those obtained for Method 1, i.e. Method 4 returned the 1st and 2nd rank values for 79, 77 and 73 datasets in young, normal and old forest landscapes, respectively. No obvious trends regarding ranks were seen when comparing Method 2 and 3 in the normal forest landscape. In young and old forest landscapes Method 2 was ranked in 1st more often than Method 3. However, both methods in general performed better than Method 1 and poorer than Method 4.

@&#DISCUSSION@&#

Spatial considerations and adjacency constraints are important aspects of long term forest planning. It is therefore crucial to develop efficient tools for decision support in forestry that are able to handle these aspects. In the present study we developed three new methods introducing bias in the neighborhood search when implementing SA. The methods were implemented as a search vector approach based on the number of treatment schedules and standard deviation of NPV within MUs and were tested against the conventional method through a comprehensive experimental design. From NFI sample plots comprising a multitude of forest conditions, we constructed three hundred hypothetical forests within three different forest landscapes characterized by different initial age class distributions (young, normal and old). Each dataset within a forest landscape encompasses in total 1600 MUs, defined in a grid of 40 rows and columns. The proposed new methods were evaluated by means of multiple measures such as the value of the objective function, first feasible solution and time consumption.

Compared to previous work with very few datasets (e.g. Boston & Bettinger, 1999; Crowe & Nelson, 2003; Falcão & Borges, 2001; Falcão & Borges, 2002; O’Hara et al., 1989), our experimental design provides a solid base for evaluation of the developed methods. Large numbers of datasets are important because of the stochastic nature of the method applied (SA) and because this enables better assessment of the impacts of using the different ways to introduce bias in the selection of MUs. Since the forests landscapes are defined as a grid configuration with equal cell size (1ha), we are also able to exclude factors that influence harvest decisions such as the number of neighbors (Li, Bettinger, & Weiskittel, 2010) and the area of each MU, which again may influence the evaluation of the methods.

In general, the average objective function values obtained in all forest landscapes showed that new methods provide higher values (lower GAPs) than the conventional method (Fig. 4). This confirms our expectations because by assigning a higher probability of selecting some MUs to change the treatment schedule, it was possible to find solutions not exploited by the conventional method and therefore we in general get higher objective function values.

According to e.g. McDill and Braze (2000), it is harder to solve problems with spatial constraints for old forests than for young and normal forests. Also, in our case the datasets within the old forest landscape were in general harder to solve. However, when applying the new methods the situation get even worse, since Methods 2, 3 and 4 needed more iterations to find the first feasible solution and more computation time than Method 1. Method 4 turned out to be a good alternative compared to Method 1 for young and normal forests landscapes, since this method produced the best (smallest) GAPs for the majority of the datasets (Fig. 4), since almost no statistical differences regarding the appearance of the first feasible solution were observed (Table 3) and since this method used less computational time (Fig. 3). We actually expected an increase in time consumption for the new methods compared with the conventional one, since a search function (for each iteration) needs to be performed in order to find the MU that will change the assigned treatment schedule. However, for the young and normal landscapes Method 4 spent less time than all other methods. For old forest landscape the results were as expected, i.e. an increase in time consumption. Furthermore, Method 4 performed better than Methods 2 and 3 (Fig. 3). This result is probably due to the fact that Method 4 removes the adjacency constraints in a more efficient way than Methods 2 and 3.

Compared to the conventional method, generally higher objective function values were found when using Methods 2, 3 and 4. The latter tended to be the one producing the highest objective values (Table 4). This along with the previous presented and discussed results, show that the best alternative to the conventional method is Method 4. However, one disadvantage of using Method 4 compared to Methods 2 or 3 is that an additional parameter is required, i.e. a weight between the number of treatment schedules and the NPV standard deviation when selecting the neighborhood solution (see Section 2.4.4). In order to reduce this disadvantage, we implemented a procedure for automatic setting of this parameter. This procedure adapts to the problem at hand (specific dataset) and is defining the weights by minimizing the difference between the Pearson correlations obtained between number of treatment schedules and standard deviation of the NPV, respectively, and the resulting search vector. In our datasets, the weights given to the component defined by the number of treatment schedules varied between 0.44 and 0.50, 0.41 and 0.46, and 0.38 and 0.44 for young, normal and old forest landscapes, respectively. These results seem to indicate that the more old forest that is present, the less importance is given to the treatment schedules and more to the standard deviation of the NPV. A sensitivity study should probably be done to understand more of the impacts of this weighting. Moreover, the method used to calibrate the components of the penalty function turned out to be a simple and effective alternative to some other methods (see e.g. Falcão & Borges, 2002).

The methods presented in this paper do not take into account sequential flow or adjacency constraints violations when defining a bias for the MU selection, i.e., they do not incorporate any bias in the MU selection focusing on constraint mitigation. Previous works applying other heuristic methods (Bettinger & Zhu, 2006; O’Hara et al., 1989) have shown that high quality solutions can be obtained if such information is integrated in the selection of MUs. Thus, a dynamic search vector approach seems to be an interesting challenge for future research. Here, the bias introduced for selecting MUs could be adapted according to the solution at each iteration instead of being static throughout the entire SA search. A method which potentially faster reaches feasible and high quality solutions and at the same time potentially has lower time consumption is always an asset to any heuristic method (Li, Bettinger, & Boston, 2010).

@&#CONCLUSIONS@&#

Introducing a bias in the neighborhood search for selecting MUs in SA is in general improving solutions compared to the conventional method when forestry planning problems with adjacency and sequential flow constraints are addressed. However, a small increase of the time consumption is needed for the new methods. In general, Method 4 (using both the number of treatment schedules and the standard deviation of NPV in the neighborhood search) is the best alternative to Method 1 (conventional method). This method for large parts of the datasets produced the best average objective value (lower GAPs) for young and normal forest landscapes, it produced the highest objective function values (best ranks) and it had lower time consumption than Method 2 (using the number of treatment schedules) and Method 3 (using the standard deviation of NPV). Although Method 4 performed very well, Methods 2 and 3 should not be neglected since for a considerable number of datasets the maximum objective function values were obtained by these methods.

@&#ACKNOWLEDGEMENTS@&#

This work was funded by the Research Council of Norway, a number of industrial partners and the participating research institutions, among them Norwegian University of Life Sciences, through the Norwegian Bioenergy Innovation Centre (CenBio).

@&#REFERENCES@&#


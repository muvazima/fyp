@&#MAIN-TITLE@&#ASE: A comprehensive pattern-driven security methodology for distributed systems

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Incorporating security features when designing distributed systems is a challenge.


                        
                        
                           
                           We propose ASE, a unique pattern-driven security methodology for this purpose.


                        
                        
                           
                           We describe ASE in detail, emphasizing the analysis and design life-cycle phases.


                        
                        
                           
                           We illustrate and evaluate ASE by designing a realistic distributed software system.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Secure software engineering

Security methodologies

Distributed systems security

Security patterns

Security solution frames

@&#ABSTRACT@&#


               
               
                  Incorporating security features is one of the most important and challenging tasks in designing distributed systems. Over the last decade, researchers and practitioners have come to recognize that the incorporation of security features should proceed by means of a structured, systematic approach, combining principles from both software and security engineering. Such systematic approaches, particularly those implying some sort of process aligned with the development life-cycle, are termed security methodologies. There are a number of security methodologies in the literature, of which the most flexible and, according to a recent survey, most satisfactory from an industry-adoption viewpoint are methodologies that encapsulate their security solutions in some fashion, especially via the use of security patterns. While the literature does present several mature pattern-driven security methodologies with either a general or a highly specific system applicability, there are currently no (pattern-driven) security methodologies specifically designed for general distributed systems. Going further, there are also currently no methodologies with mixed specific applicability, e.g. for both general and peer-to-peer distributed systems. In this paper we aim to fill these gaps by presenting a comprehensive pattern-driven security methodology – arrived at by applying a previously devised approach to engineering security methodologies – specifically designed for general distributed systems, which is also capable of taking into account the specifics of peer-to-peer systems as needed. Our methodology takes the principle of encapsulation several steps further, by employing patterns not only for the incorporation of security features (via security solution frames), but also for the modeling of threats, and even as part of its process. We illustrate and evaluate the presented methodology in detail via a realistic example – the development of a distributed system for file sharing and collaborative editing. In both the presentation of the methodology and example our focus is on the early life-cycle phases (analysis and design).
               
            

@&#INTRODUCTION@&#

Incorporating security features is one of the most important and also one of the most challenging tasks in designing distributed systems [1,2]. Over the last decade, researchers and practitioners have come to recognize that the incorporation of security features should proceed by means of a structured, systematic approach, combining principles from both software and security engineering [3–7]. Such systematic approaches, particularly those implying some sort of process aligned with the software development life-cycle, are termed security methodologies 
                     [8]. There are a number of security methodologies in the literature, of which the most flexible and most satisfactory from an industry-adoption viewpoint are methodologies that encapsulate their security solutions in some fashion (see [8]), especially via the use of security patterns 
                     [9,10]. While the literature presents over a dozen such pattern-driven security methodologies, both young and mature [8,11] – possessing a range of valuable and beneficial features – with respect to system applicability, these methodologies are uncomfortably positioned at two extremes of a spectrum: either they are highly specific, or highly generic. This makes such methodologies inadequate for project situations requiring the development of general distributed systems, since the methodologies will either lack provisions for the specific security concerns of general distributed systems or different types of distributed systems (too generic) [5]; or they will be incompatible with the features of the target system (too specific) [11] – whether because of the processes involved (e.g. PWSSec [12]); or because of the conceptual artifacts used (e.g. the methodology of Delessy and Fernandez [13]).

At present, there are no pattern-driven security methodologies specifically designed for general distributed systems – i.e. positioned somewhere in the middle of the specificity–generality spectrum referred to above (we are considering here exclusively methodologies using security patterns, not patterns interpreted as architectures or components as in the work of [14]). Going further, there are also currently no methodologies in the literature with mixed specific applicability [11] – for example, for both general and peer-to-peer distributed systems; or for general and web-based applications.

In this paper we aim to fill the latter gaps, by presenting a comprehensive pattern-driven security methodology specifically designed for general distributed systems, named ASE, which is also capable of taking into account the specifics of peer-to-peer systems as needed. ASE emphasizes the early life-cycle phases (analysis and design) – since this is where all security countermeasures are planned [2], as well as where, according to Jaquith [15], approximately half of all major security flaws can be prevented (cf. [16]); and takes the principle of solution encapsulation several steps further, by employing patterns not only for the incorporation of specific security attributes (via security solution frames), but also for the modeling of threats, and even as part of its process. Through its distributed-systems-specific set of conceptual artifacts and its comprehensive process, ASE is capable of addressing all or most of the core distributed systems security concerns, providing developers with detailed guidance on how and where to introduce relevant security features into a system's architecture during development.

Besides being a self-contained security methodology, ASE is also an example of a re-engineered methodology, arrived at by applying the approach to engineering security methodologies presented in [17] in its tailoring capacity – with the methodology of Fernandez et al. [18] as a base methodology. From the latter standpoint, if a security methodology is considered a solution to the problem of introducing security into software systematically, and the aforementioned engineering approach is seen as a meta-solution capable of generating solutions, then ASE can be seen an example of just one particular solution, with its own set of beneficial features.

The rest of this paper is structured as follows. In Section 2 we provide some brief background on security methodologies as well as an overview of the construction of ASE. We describe ASE in depth in Sections 3 and 4, focusing on the activities relevant to the early life-cycle phases (especially design). In Section 5 we illustrate and evaluate ASE in detail via a realistic example, namely, the development of a distributed system for file sharing and collaborative editing. In Section 6 we consider related work; and finally, in Section 7 we conclude and discuss future directions.

@&#BACKGROUND@&#

A security methodology constitutes a “systematic way of doing things in a particular discipline” [19], where in this case the discipline is secure software engineering. Security methodologies are strongly related to development methodologies, however, in our work and for the rest of this paper, security methodologies will be considered as separate entities in their own right, distinct from any development methodology to which, or in which, the latter might be related or integrated, respectively. Unlike a development methodology, a security methodology's primary aim is not to provide guidance for producing particular software artifacts, but rather, for improving the security attributes of a given system, i.e. a security methodology is process-centric. This is not to imply, of course, that security methodologies cannot prescribe the production of various software artifacts also.

Despite their process-centric nature, security methodologies are not simply “bare” processes in the sense of simply being descriptions of activities – a consideration of existing methodologies (see [8]) reveals an inherent dichotomy, reflecting the process-product dichotomy of development methodologies: that of process-framework, which is to say, a security methodology is a process for improving the security attributes of a system via the use of a conceptual framework, consisting of various “security improvement artifacts” (e.g. security solutions and attendant conceptual artifacts – cf. [6]). A security methodology SM can thus be defined more formally as a couple:
                           
                              
                                 S
                                 M
                                 =
                                 
                                    
                                       S
                                       P
                                       ,
                                       
                                       C
                                       F
                                    
                                 
                              
                           
                        where SP is a security process – the activities and/or steps taken to secure a software system of some type; and CF is a conceptual security framework, consisting of the conceptual artifacts used by the methodology's process, the number and type of which, in theory at least, can be arbitrary, but as a minimum must include a set of security solutions (defensive artifacts), as well as a set of threats (offensive artifacts) leading to those solutions, whether explicitly defined and cataloged or otherwise. Henceforth we will refer to the two constituents of a security methodology as a security process aspect and a conceptual framework aspect, respectively.

Over the last two decades, a number of researchers have come to regard fixed, “one-size-fits-all” development methodologies as inadequate and unable to meet the needs of different organizations – a realization that has given impetus to the field of (Situational) Method Engineering – (S)ME [101]. Similar arguments can be adduced with respect to security methodologies (see [8]), which have led to the proposal of a comprehensive, pattern-oriented approach to engineering security methodologies in [17] inspired by a number of SME ideas.

The approach for engineering security methodologies in [17] is composed of three interconnected parts: a framework of interrelated security process patterns and pattern modifiers ([102]) called SPPF (Security Process Pattern Framework), for engineering the process aspect of a security methodology; a meta-model for engineering a methodology's conceptual security framework aspect; and a unifying meta-methodology (S-SMEP) to guide engineers in using the latter artifacts in a step-wise fashion.

The pattern framework is divided into three levels, only the second of which, strictly speaking, contains process patterns pertaining to the security process aspect of a methodology. Security process patterns are essentially traditional (development-oriented) process patterns encapsulating re-usable collections of security-related techniques and/or activities in a generic fashion. Patterns are more abstract than detailed process descriptions, and their encapsulated solutions emphasize what should be done in a given context, rather than how – the latter details being specified in the pattern instances. The process patterns can be classified according to their granularity as phase (P), stage (S) and task (T) patterns. A number of the patterns in the first part of the framework with different granularities are also usable as modifiers to other patterns (in the same level), which can result, according to the intents of the methodology engineers, in an interconnected “web” of patterns mutually influencing each other's solutions.

In contrast to the second framework level where most modifiers are implicit, the first level of the framework contains a collection of explicit pattern modifiers termed generic life-cycle modifiers, which help align particular process patterns to a given development phase/stage, and determine solution variants.

Engineering a security methodology using S-SMEP – which can take on the form of tailoring an existing (base) methodology or constructing a methodology “from scratch” – entails constructing pattern-based methodology models using SPPF and the conceptual framework meta-model, and subsequently specifying the patterns and artifacts. The latter models are represented via a UML-inspired notation.

To give further insight into this approach (represented schematically in Fig. 1
                        ), we briefly describe the intents (essential solutions) of several of the second-level SPPF patterns below, and duplicate the conceptual framework meta-model diagram from [17] in Table 1
                        . In the table presentation of the SPPF patterns, the granularity (Phase/Stage/Task) appears in the column marked “Gr”.

Regarding the approach to engineering a methodology's conceptual framework, our meta-model in Fig. 2
                         effectively prescribes a set of constraints on the nature of, and relationships between, the various conceptual artifacts to be used in a security methodology. In particular, the meta-model dictates that all conceptual security frameworks should consist of a set of Conceptual security artifact collections, which aggregate Conceptual security artifacts. Such artifacts can be specified or documented explicitly, thus forming an Explicit artifact collection, which may be structured (e.g. a catalog) or unstructured; or they may be based purely on implicit (expert) knowledge, in which case they form an Implicit artifact collection. In both cases conceptual artifacts may be related, or relatable, to a particular system characterization (e.g. vulnerabilities being related to a network model). The artifacts, their groupings and their instances, can be coarsely categorized into two main classes (not shown in the Figure): offensive artifacts (threat, attack, vulnerability) and defensive artifacts (security solution, security requirement and derivatives). Regarding presentation, the dashed boxes in the figure (Fig. 2) represent elements that cannot be instantiated and are included only for the sake of clarification, while the colors (or shades of gray if not viewed in color) are used simply to improve readability and to emphasize the importance of the Conceptual security artifact model element.

ASE can be seen as an evolution of the security methodology of Fernandez et al. [18] (see also [8] for an overview), arrived at by applying two iteration of S-SMEP: initially in [17] for the purpose of tailoring the Fernandez et al.'s methodology to a general distributed systems setting; and again in [32] for the improvement of the resulting methodology's quality attributes, as defined in that reference. Each application of S-SMEP resulted in a number of changes that took into account the target system (class) specifics, this being the situational methodology requirement of primary concern in the latter publications.

In its overall structure, ASE follows the order of development phases for a generic software development life-cycle [8,17] (the short-hand notation in brackets will be used throughout the rest of this paper): Requirements analysis (ReqAn), encompassing requirements elicitation/gathering (Req) and analysis (An) activities; Design (Des), encompassing architecture development (Arch) and detailed design (DetDes) activities; Implementation (Impl), encompassing coding (Cod) and testing (Test) activities; and Deployment (Deploy), encompassing administration and installation activities.

In essence, ASE begins by considering the use cases of a system during Requirements analysis, and how such use cases can be subverted either by insiders or outsiders (Security Requirements Determination (SecReq) phase, Adversary Modeling (AdvMod) stage). This leads to an identification of countermeasures appropriate at this early stage of development and their modeling into the system's conceptual model. A similar sequence of activities is performed during Design, this time with respect to the system's architecture, considering in detail areas of functionality, threats, appropriate countermeasures, and then modeling the countermeasures to produce a secure software architecture. The remaining activities are concerned with verification (at different stages) and security implementation. A pattern-based model of ASE is shown in Fig. 3
                        , with the left-hand side containing ASE's security process aspect, and the right-hand side containing ASE's conceptual security framework aspect. The reader is referred to [17] for details on the notation and the semantics of such models – for this paper the figure can be taken simply as a schematic view of the flow of activities and the conceptual artifacts used.

In the next two sections (Sections 3 and 4) we describe the two aspects of the methodology in turn.

The elements constituting ASE's conceptual security framework adhere closely to the original classes of elements in the domain-specific meta-model of [17]. Referring to the right-hand side of Fig. 3, besides generic artifacts connected with object-oriented use cases – employed in the early phases of the security process – there are both offensive and defensive artifacts (Threat and several Security solution element instances), as well as a number of supportive artifacts in the form of various mapping tables. Below we briefly describe the features of three core artifacts from the aforementioned collection used specifically throughout the Design-phase parts of ASE's security process. More details, as well as finer-grained models of these artifacts that allow a fuller version of ASE's conceptual security framework to be reconstructed can be seen in the relevant paper cited next to each artifact's name below. We mention other relevant artifacts (in italics font) as part of the descriptions with reference to the model in Fig. 3.

Architectural decomposition is a form of system characterization, which, when complemented by an analysis process, provides structure for guiding the incorporation of early non-functional (in our case security) requirements and the determination of new requirements [20]. The architectural decomposition framework artifact resides at a complementary level of abstraction to the software architectural models, and is stratified into three layers, with the first containing a conceptual model of distributed systems, usable as a meta-model for creating derived architectural models; the second containing a simple, layered architectural meta-model allowing for the separation of the architecture according to areas of functionality (functionality decomposition layers); and the third containing a set of meta-modeling elements (technical realization abstractions) that detail the decomposition.

The threat taxonomy and library of [21] is a two-level collection of threat patterns – a type of abstract software pattern encapsulating threats, architectural contexts and mitigating security policies – for general distributed systems, encompassing both system threats and meta-security threats (threats to the security infrastructure itself). The base taxonomy for general distributed systems can be extended by specializing individual patterns for different architectural contexts to produce system-/technology-specific taxonomies. These taxonomies (like the base taxonomy itself) combine the benefits of a structured library and a STRIDE-like classification scheme, and support threat modeling by allowing non-expert developers to consider a wide variety of threats (threat pattern instances) tailored to particular applications. The threat taxonomy artifact is linked with the distributed architecture decomposition framework artifact, as the latter defines the architectural contexts for the individual threat patterns.


                        Security solution frames are solution structures that encapsulate and organize security patterns (see [9,10]) into different levels of abstraction (vertically) and different facets of a root security policy (horizontally), providing guidance in realizing the security patterns from an abstract conceptual to a concrete design level, and simultaneously across the development life-cycle [22,23]. Security solution frames also form a bridge between security tactics 
                        [24,25], which, in our interpretation, embody a single generic security policy; and patterns, which address more specific security policies. Neither tactics nor security policies are shown in Fig. 3 for the sake of simplicity – their relationships can be seen in [22,23].

The literature presents frames for the most essential distributed systems security concerns (cf. [11]), though, at the time of this writing, not for all (see Section 7 on future work). We describe the current solution frames together with projected frames for addressing other major security concerns, along with the tactics they realize, in Table 2
                         (an asterisk next to the name of a frame indicates the description is a future projection). In Table 3
                         we show the relationships between the solution frames (see [22,23] for details), which are also valid for the identically named generic security policies encapsulated in the threat patterns as mitigating policies – and mirrored in the relationships of the tactics embodying those policies (which we omit for the sake of brevity). The relationships are represented in the table using the following letters: requires (not necessarily strictly) (R), supports (or is beneficial to) (S) and depends on (the way one or more patterns are realized in the target frame) (D). We provide an overview of the structure of the currently available solution frames in Appendix A, Table 11.

Although in ASE we employ the solution frames without modifications/customizations, their encapsulated patterns can be replaced by, or related to, other conceptual security artifacts not shown in Fig. 3 – e.g. security aspects [26] – while retaining the overall intrinsic structure of solutions (as specific security policy encapsulations).

In this section we outline ASE's security process aspect following the sequence of phases for the generic development life-cycle, describing in each development phase the relevant SPPF process pattern instance(s) (see Section 2). Since our emphasis is on the improvements and novel contributions of the methodology over its antecedent (base methodology), we focus predominantly on activities performed during the design development phase, describing activities performed during other phases only briefly.

The security process of ASE can be seen in outline in Table 4
                      in the form of semi-formalized specifications using the textual notation for OMG's SPEM 2.0 standard [92] as employed in the work of [5,73,74] (the template for which can be seen in those publications). To construct this specification, we have mapped the phases of ASE's security process onto SPEM 2.0 tasks, which means that ASE's security process has essentially been modeled as five assignable work units. Of course, ASE consists of many more tasks or “assignable work units” than five (the SPEM 2.0 notions of Activity, Phase, Task, etc. differ from what we term activities, phases, stages and tasks in ASE – see Section 7 on future work), so the specifications in Table 4 should only be taken as representative – aiming to explain the structure of ASE from yet another point of view, in addition to the graphical representation in Fig. 3 – and, above all, as a summary of the “steps” constituting ASE's security process, while including some details (also representative) on the roles and work products that would be part of an enactment of ASE in the context of some development methodology.

ASE's activities performed during the requirements analysis development phase essentially take a “system use security” viewpoint, concerned with the (external) interactions with the system to be developed.

The early phases of ASE are for the most part identical to those of its antecedent methodology [18,27] (see also [8] for an overview), with the creation of a set of security use cases according to a set of standard (object-oriented) use cases. Each use case is analyzed for how it can be subverted, considering four main security attributes: confidentiality, integrity, availability and accountability [27]. This activity is in all respects an instance of the Security Requirements Determination (SecReq) process pattern in [17], with the main goal being to determine a collection of (early) security requirements, which can be carried over into later phases of the security process. The requirements can (optionally) be related to a collection of encompassing requirements classes from the left-most column of Table 7, to ease the transition into the next ASE stages.

Secure Semantic Analysis Patterns (SAPs [28]) are used during the analysis phase, where appropriate, to create a secure conceptual model efficiently. The use case analysis results from before are carried over to determine a set of abstract security patterns [29] that collectively embody, or, more precisely, are interpreted as embodying, a subset of the early security requirements. The latter patterns aim to guide the solution and are not requirements per se (in contrast to the original methodology of Fernandez et al., where they essentially take on that role). These patterns can be chosen from, or be related to, abstract patterns belonging to one or more pattern families from appropriate security solution frames (at their Conceptual analysis abstraction level), according to corresponding generic security policies, and instantiated in the conceptual model. In this case the mappings in Table 7 are employed to determine the relevant solution frames.

In this sub-section we describe ASE's activities performed during the design development phase, namely, the determination of design-level security requirements; the identification of appropriate security countermeasures satisfying those requirements; and the modeling of the identified countermeasures in the system's software architecture. In all cases the activities take a “system architecture security” viewpoint.

To determine a set of design-level security requirements, we perform a detailed threat modeling process (instantiating the Adversary Modeling stage process pattern from [17]) that relates various threats to different parts of a target system's software architecture in a systematic, structured fashion. The first step in the latter process is to create a well-defined system characterization: in our case, this is an architectural decomposition as per [20]. The decomposition forms the basis for the analysis of threats, which are uniformly selected from the collection of threat patterns in [21]. Below we describe the steps of the threat modeling process, omitting the details of the (sub-)process for architectural decomposition, which is presented in [20], and focusing on the (sub-)process for analyzing threats and determining security requirements. For the sake of consistency, we should point out that the latter threat analysis is based on a customization of the related security analysis process presented in [20]. From the viewpoint of the latter paper, threat analysis is but one particular process for security which can be attached to the architectural decomposition framework.


                              Decomposition steps 1 to 3: (1) Using the meta-model from the framework's first level, create a derived architectural model representing a high-level decomposition into nodes, components, associations, domains, etc. (2) Identify/assign elements of the model to the decomposition framework's (second level) functionality layers. (3) Finally, for each functionality decomposition layer, map the corresponding elements of the derived model to technical realization abstractions (from the third level of the framework) as appropriate. The process of architectural decomposition should not be confused with the similarly termed functional decomposition (an architecture development technique), which is concerned with partitioning the system into logical units according to requirements – analogous to constructing a chart of a country. Architectural decomposition is concerned with the creation of a meta-level representation of the system's architecture according to a fixed, invariant set of models and abstractions (in the case of [20], structured into a framework) to which existing architectural elements can be mapped – analogous to overlaying an atlas “grid” on top of an existing chart.


                              Threat analysis preparatory step (optional): The rest of the adversary modeling process relies on the use of the threat patterns from the threat taxonomy and library of Uzunov and Fernandez [21] (see Section 3). In a number of situations the base taxonomy for general distributed systems in the latter reference may provide a sufficient number of threats for consideration, however, in many situations it may be advantageous to specialize this base taxonomy to a specific system/technology context (e.g. when developing web applications, multi-agent systems, systems using J2EE and so forth). The details of the specialization process, which, when applied, produces a derived, application-specific taxonomy, are described in [21]. For the rest of this paper we will assume that the base threat taxonomy and the peer-to-peer system-specific taxonomy presented in [21] are sufficient for the situation at hand.

Threat analysis step 1: Once an architectural decomposition has been obtained, threat analysis can be performed via two complementary approaches, in both cases utilizing either the base or an application-specific threat taxonomy constructed in the previous, preparatory step.

The first approach (context-driven) relies on considering each functionality decomposition layer (in no particular order) and selecting appropriate threat classes containing patterns with matching architectural context(s) defined by the decomposition (see Table 5
                              ). Patterns for related technical realization abstractions are chosen in like manner (see Table 6
                              ). In this way, threats can be (1) mapped or related to the elements corresponding to the high-level modeling abstractions of the decomposition; (2) considered with respect to the different areas of functionality of the system, e.g. communication, and all related elements; and (3) considered with respect to particular realizations of the functionality, e.g. particular network protocols, messages (integrity, confidentiality) and so on.

The second approach (threat-driven) relies on selecting threat patterns in some order – either predetermined or arbitrary – and relating them, via their architectural contexts, to the different parts of the architecture. This approach is more suited for developers with security expertise (unless every single pattern in the threat taxonomy is considered iteratively, in which case little expertise is required).

Regardless of the approach taken, associations between software components (the terminology pertains to the architectural decomposition) play an important role in this process step inasmuch as they help to determine component relationships and hence the possible vulnerabilities that can be exploited.

Once a threat pattern has been selected, it must be instantiated for the given architecture in order to determine the exact threat. Every threat is also analyzed with respect to the whole set of decomposition layers, considering its repercussions vertically down the layers, one by one.

Threat analysis step 2: Once a list of threats has been compiled, the importance and possibility of each threat can be considered and ranked appropriately (i.e. some form of risk assessment can be performed).

Threat analysis step 3: When a particular requirement or policy has been determined, it can be “passed” vertically down the decomposition layers (as was done with the threat) to determine applicable enforcement strategies and/or further requirements. Note that this step applies to the incorporation of security requirements from previous development stages as well.

It should be remarked that the combined decomposition and threat modeling process is iterative in nature, i.e. the steps above may need to be repeated as the architecture is being created. An additional step concerned with a consideration of meta-security threats from the second level of the threat taxonomy in [21] is described later, in Section 4.2.2.4.

Either following, or in parallel with, the threat analysis process, corresponding technical (design-level) security requirements are determined for every important threat. These technical requirements are specified in one of two (canonical) forms:
                                 
                                    •
                                    
                                       negative: <protect from X>, where X is a given threat pattern instance; or


                                       positive: <enforce Y>, where Y is the general (or specific) security policy encapsulated in the threat pattern corresponding to threat X.

This style of specifying requirements reflects the duality of threat patterns/security solutions constituting the conceptual security framework for the methodology, as explained in Section 3, which is exploited in the next phase of the methodology to determine the appropriate countermeasures mitigating or stopping the threats.

The above specification of requirements also applies to the early (high-level) security requirements determined at the previous phase of the methodology (and previous development phase: Analysis), which are converted to design-level requirements via the aid of two mapping tables. The first of these tables – Table 7
                            (the Requirement class to policies table CF element in Fig. 3) – maps general security requirement classes (first column) to generic security policies (third column). The requirements classes are described in the second column, with the descriptions taken from Firesmith [30] (often verbatim, and sometimes with adaptations). The second table – Table 8
                            (the Policies to threats table CF element in Fig. 3) – maps generic security policies to threat classes and threat patterns within those classes from the base threat taxonomy (for general distributed systems) of Uzunov and Fernandez [21]. In this table, the rows with italics are the meta-security threat classes (differentiated further by the use of an asterisk in brackets) and patterns. It should be noted that while threat classes and patterns in the table pertain to the base threat taxonomy (for general distributed systems), the mappings also apply to specializations of the base patterns (the exceptions being patterns that augment or alter the base version of their encapsulated mitigating security policies), and hence for derived taxonomies.

The mappings in both tables (which we do not claim are exhaustive), should be applied during the analysis of different software components at different levels of granularity, including the security infrastructure itself – e.g. by considering the security information management infrastructure as a system in its own right, decomposing it, and considering threat patterns for the resulting architectural contexts.

Regarding threats that are linked together, if a given threat T contains in its description threat pattern instances TPn
                           1, …, TPnk
                           , then the set of technical security requirements can be expressed simply by using <protect from TPni
                           > clauses for each threat, but grouped under the single requirement. This provides traceability between the requirements and threats found during the threat analysis process. If each requirements were to refer to only one threat pattern instance at a time the traceability would be harder to keep.

Once specified in canonical form, the requirements can be used in the threat analysis process along with all others (see Threat analysis step 3).

In all cases the requirements are refined iteratively along with the threat analysis process, until a finalized set of specified requirements is obtained.

With respect to the construction of the methodology (see Section 2.3), this activity as a whole is an instance of the Security Modeling (SecMod) SPPF stage pattern, modified, however, by the encompassing Security Requirements Determinatin (SecReq), which implies that not countermeasures, but requirements, are being specified (according to the specify SPPF task pattern).

Once requirements are specified in the canonical forms as per the Requirements Determination phase, they must all be mapped to concrete countermeasures. As with the threat modeling, there are two approaches for achieving this. In the first approach, countermeasures are determined from the generic policies encapsulated by the threat patterns according to a given threat (in the threat enumeration). In the second approach, tactics are directly used to improve certain (security) quality attributes, such as confidentiality, integrity etc. as per the traditional usage of tactics (see [24]). The duality of threats-solutions allows an immediate evaluation of whether a give tactic is needed by considering the relevant threat patterns and their applicability in a given context (as per the threat modeling phase in Section 4.2.1 above). Below we describe the first approach in more detail.

As a first step to determining countermeasures from security requirements, all negative requirements are converted into their (dual) positive form on the basis of the generic security policies encapsulated in the relevant threat patterns, i.e.:
                                    
                                       
                                          <
                                          protect
                                          
                                          from
                                          
                                          X
                                          >
                                          
                                          →
                                          
                                          <
                                          enforce
                                          
                                          
                                             
                                                generic
                                                
                                                security
                                                
                                                policy
                                                
                                                encapsulated
                                                
                                                b
                                                y
                                                
                                                X
                                             
                                          
                                          >
                                       
                                    
                                 
                              

In this way all requirements are converted into a set of policies requiring enforcement. Those requirements already in positive form referring to specific policies are converted to requirements for enforcing generic policies with the specific requirements referenced alongside (e.g. in brackets, or whatever other notation is deemed suitable):
                                    
                                       
                                          <
                                          enforce
                                          
                                          Y
                                          >
                                          
                                          →
                                          
                                          <
                                          enforce
                                          
                                          
                                             
                                                generic
                                                
                                                security
                                                
                                                policy
                                                
                                                Y
                                                *
                                                
                                                of
                                                
                                                which
                                                
                                                Y
                                                
                                                is
                                                
                                                a
                                                
                                                refinement
                                             
                                          
                                          
                                          
                                             Y
                                          
                                          >
                                       
                                    
                                 
                              

The list of these requirements in positive form are subsequently mapped to concrete countermeasures at various levels of abstraction and granularity (as required) in one or more of the following ways:
                                    
                                       1.
                                       To security tactics embodying the corresponding generic policies (see Section 3), which in turn are realized by security solution frames, and, subsequently, by relevant security pattern families within those frames.

Directly to security solution frames and, subsequently, to relevant security pattern families within those frames. Since the names of the generic policies are identical to the names of the solution frames, this mapping is very straightforward. Following the organization of the relevant families, requirements can also be mapped to the encapsulated patterns which address more specific policies.

To standalone or compound security patterns – especially for a distributed systems context (see [11,65,33]) – that are not part of any solution frame. This particular mapping is realized with the help of another table – Table 9
                                           – which, acting as an adapter, maps requirements to security patterns via distributed systems security concerns and generic policies. This gives developers the option to use standalone security patterns when a frame or pattern within a frame for a given generic or specific policy, respectively, is not available and/or not appropriate. For the concerns in the table we follow the scheme used in [11]; the last column lists some example security patterns (see [10] and [11] for descriptions and references).

If a given specific security policy is not addressed by either standalone patterns or patterns constituting the solution frames, then developers can resort to using custom, on-the-fly, expert-created countermeasures to realize a given policy.

In the case of mappings 1 and 2, any defined solution relationships should be followed to ensure that the selected solutions are not incompatible, including the relationships between security frames (as shown in Table 3), between pattern families and individual patterns within, and across, other families – as well as between standalone patterns where appropriate (as in [34]; see also [10]). Following these relationships not only allows for a more complete coverage of the security requirements, but can also help to cover unexpected requirements arising from the selection of particular solutions (cf. [35]).

Collectively, the four mappings outlined above promote flexibility in employing any combination of security tactics, security solution frames (and their encapsulated patterns) and standalone security patterns – as well as custom-made solutions – in realizing the policies resulting from the security requirement conversion. The use of the mapping tables (Tables 5 to 9) provides strong traceability between security solutions, threats (together with the architectural contexts, and the components therein, to which the threats apply), policies and requirements.

When appropriate countermeasures have been identified, their encapsulated solutions can be realized in the system's software architecture. Regardless of whether one started with security tactics to arrive at solution frames, or directly selected relevant frames, the process for incorporating the encapsulated solutions proceeds by following the abstraction levels of the pattern family structures as per the implicit or explicit implementation micro-process pattern contained in the frame. More specifically, this implies that first abstract patterns are selected from a given family, which define the concepts of the solution and an abstract architecture; then the abstract architecture is refined in successive levels of concreteness, leading to a detailed design; and finally, a number of technology realizations are chosen for the design to be transferred to (code-level) implementation. In this way developers are guided in introducing particular security solutions in a stepwise fashion.

Throughout this process, the patterns are related to the system characterization – namely, the original architectural decomposition from the earlier phases – beginning with the highest layer of the functionality decomposition layers and proceedings downwards, relating the patterns to the abstractions (and have the corresponding parts of the actual software architecture) in each succeeding layer as was done in the Adversary Modeling stage during Design (see Section 4.2.1.1). This extends the similar process in the methodology of Fernandez and colleagues.

A given pattern or collection of patterns (for a given iteration, since this activity is done several times) is instantiated into the software architecture as per the standard pattern instantiation approach (mapping participants to components, or realizing them with collections of components – see [39,40,11]) to produce a secure software architecture. The security slice of this, i.e. the security architecture proper, consists of all the pattern instances and their relationships, and, due to the very nature of patterns, is itself re-usable. The following strategies – adapted from the work of [41] – are used to resolve pattern participants during the instantiation process:
                                 
                                    •
                                    
                                       Absorb participants: the functionality of a given participant in one pattern is absorbed in the components of another pattern instance.


                                       Merge participants: the functionality two or more participants in several patterns is combined and realized in a single, multi-functional component.


                                       Employ another pattern: another pattern is used to realize the participants of a given pattern. Note that this can be recursive, leading to multiple pattern instances (usually of non-security architectural or design patterns) for a given security pattern.

UML is used as a modeling language as per the original methodology of Fernandez and colleagues.

With respect to specific micro-process patterns that can be employed during this stage, special attention should be given to Secure Protocol Design from the Secure communications frame [23] whenever protocols of any kind are designed as part of the standard development activities (usually at detailed design). Such protocols could be of a general nature, “for describing how components in a distributed system synchronize, exchange messages and share resources” [42]; or for security-related tasks, such as how cryptographic keys are distributed.

The next step in the process is to verify that the security architecture resulting from instantiating the different patterns does indeed satisfy the requirements, and, in particular, addresses the threats enumerated earlier. This is accomplished by tracing the solutions to the original threat patterns and set of security use cases constructed during the design and analysis development stages, respectively, and inspecting whether they are addressed appropriately in the security architecture. In terms of the SPPF framework of [17], this process is essentially an instance of the Manual inspection task pattern.

Since software components can either relate to the system's business (functional) concerns or, in this case, to security (see [20]), it is necessary to repeat the decomposition and threat analysis described in Section 4.2.1.1 for each newly introduced security component, protocol, etc. to protect the security infrastructure itself from threats. To do this, the threat analysis steps 1 to 3 are repeated, this time selecting appropriate threat patterns from the meta-security threats class [21].

Although our focus is on design-level security, for the sake of completeness in this section we briefly describe ASE's activities performed during the implementation development phase. We do not consider any activities aligning with the deployment development phase, even though some solution frames provide patterns that are specifically applicable then (e.g. for secure network configuration [23]).

During this phase, the security pattern instances that collectively form the security architecture are coded together with the rest of the system. Secure coding practices are used throughout (see [43,44]), with appropriate language idioms (e.g. [45] for C constructs) employed where appropriate. Static analysis tools can be used during this stage to increase code quality and hence to reduce the number of vulnerabilities arising (purely) from the implementation [46,47].

There may also be a need to map certain features or components of the architecture to COTS components (as per the Map SPPF stage pattern in [17]), in which case the WRAPPER FACADE pattern [48] can be used to ensure appropriate security functionality if it is not already present in the target component(s).

Once all iterations of the security implementation stage are completed, the resulting software system must be carefully verified as to whether it really does satisfy the security architecture specifications. This is accomplished by considering misuse and attack pattern realizations (see [49] and [16], respectively) of each of the threat patterns found during the design development phase, and performing penetration testing on the software system (cf. [21]), as per the Penetration test SPPF task pattern. This helps to not only verify that a particular countermeasure has been implemented correctly, but to also determine whether that countermeasure is effective against (corresponding) representative attacks.

In this section we demonstrate how ASE is applied in practice to the development of an architecturally non-trivial, secure distributed system. In keeping with our focus on design-level security, we apply ASE up to, but excluding, implementation (hence we do not demonstrate ASE's implementation stages, which were described very briefly in Section 4.3). We omit a number of the details in our descriptions of how ASE is applied during requirements analysis, since they are well documented in [27] and [18,10] (cf. Section 4.1). This allows us to focus on the novel contributions of ASE during design, as we did in the description of ASE itself (cf. Section 4.2).

As remarked earlier, security methodologies are entities independent of, but related to, development methodologies, within which they must be integrated. Unlike the methodology of Fernandez et al., which is integrated or at least aligned to a generic object-oriented methodology, we do not wish to advocate any particular paradigm or development methodology. We thus take a development approach that can be termed loosely “architecture-oriented”. The SDLC for this approach is aligned with the generic life-cycle in [17], and begins with a requirements analysis phase encompassing the familiar requirements elicitation/analysis activities (including, in particular, the creation of a domain-driven conceptual model, as per the Domain Model pattern of [50]). Transitioning from the problem to the solution space, development subsequently focuses on the design of software architectural models via the creation of manager components akin to the generic services of [51], which encapsulate the requirements and provide some piece of functionality at a logical level; as well as via the application of software patterns – both architectural [39] and domain-specific [52–54]. The resulting models are separated into several architectural views, mixing the available views from the literature (both older and more recent [55,56]): logical, execution and deployment (physical). The models are refined and elaborated and then transitioned into implementation. Regardless of our brief, explicit description of our espoused development approach above (purposefully not a full development methodology per se), we must emphasize that it is by no means the only possibility, and that other development approaches with different paradigms can also be employed in conjunction with ASE.

In the ensuing presentation we follow the order of development phases, as we did when describing ASE, and within this the order of ASE's phases and stages, with the shorthand notation from [17] in brackets next to each phase or stage name.

The purpose of our example system, called SHARED (SHAring and collaboRative EDiting environment), is to offer intra- and inter-organizational file sharing and multi-user, collaborative document editing capabilities. Each user has a single “Sharespace” containing graphical representations of the files that are shared for a given company project: documents, supporting multimedia files and executables. Files can be downloaded locally, and new ones can be shared with other team members/collaborators through the same interface. Each users can edit document files collaboratively via a graphical user interface integrated with their personal Sharespace interface (on their local machine), based on a partially synchronous paradigm. During editing, an authoring user selects a section to edit (or end-of-file to augment the document), which causes it to be locked, and after editing makes an explicit update, which causes an event to be broadcast to other participants.

Users can thus work on a document simultaneously while all being online in a collaborative session, as well as off-line, whereby changes are propagated and synchronized at startup. While all the participants are part of the same organization (or a linked group), external reviewers can also take part in viewing and commenting on the documents. A conceptual model of SHARED is shown in Fig. 5
                           
                           . The model contains a (customized and adapted) instance of the Communications Architecture for Groupware Systems pattern from [57] to capture a number of the generic functional aspects. A collection of use cases for SHARED is shown in Fig. 4, with the most notable ones being Share file (with Share document – whereby a document is created and shared with other users or with the world – as a derivative) and Edit document. We omit the descriptions of these use cases for the sake of space, and also because they are largely self-explanatory and/or well known from similar existing (collaborative) systems.

Applying ASE's early phases (at Requirements analysis – see Fig. 3), we consider how the system uses can be subverted by an insider (user/author) or an external attacker, with respect to confidentiality, integrity, availability and accountability. In performing this task we employ the threat patterns in an ad-hoc fashion to provide additional guidance beyond our own expertise. The partial results are tabulated in Table 10
                           , with the first two columns referring to the use case and the remaining columns describing the possible misuse activities. The latter misuse activities give rise to a set of early security requirements, several of which we make explicit and summarize below (with encompassing security requirement classes from Table 7 in brackets, and relevant misuse activities from Table 10 after the arrow):
                              
                                 •
                                 SR1: only authorized users with appropriate rights should be able to view documents (Authorization & Trust Requirements, Confidentiality Requirements) ← M6, M8

SR2: only authorized users with appropriate rights should be able to edit documents (Authorization & Trust Requirements, Integrity Requirements) ← M4, M9

SR3: files sharing and download should be restricted to a subset of users (e.g. team/project) according to appropriate rules (Authorization & Trust Requirements) ← M1, M3, M7

SR4: shared files should be “sanity checked” or adhere to some kind of rules (Immunity Requirements, Exportability (Code mobility) Requirements) ← M2

SR5: users should be accountable for their document editing changes, and should not be able to deny they have made a change (Nonrepudiation Requirements, Integrity Requirements) ← M5

When complete, the latter list forms part of the early requirements of SHARED (along with any prescribed requirements, which we have consciously omitted).

Carrying the system uses into ASE's Security Modeling (SecMod at ReqAn) stage, we can consider abstract security patterns embodying the early security requirements or forming an initial solution for a given problem. Using Table 7 in the process, we determine to use the Authorization security solution frame for setting up appropriate authorization models in response to SR1, SR2 and SR3. Since there are effectively two main sets of functionality in SHARED – file sharing and document editing – each part requires a different authorization model. We begin by instantiating the Abstract authorization pattern from the frame's Conceptual analysis abstraction level twice, with appropriate merging of elements, and subsequently add pattern modifiers for the specifics of file sharing:
                              
                                 •
                                 The Group modifier, to group together authors of a given document;

and a second instance of the Group modifier, to group together files based on their properties (Attribute modifier);

as well as for the specifics of document editing:
                              
                                 •
                                 a Role modifier, whereby each user can be an Author, a Co-author or a Reviewer;


                                    Fine granularity, so that not only individual documents, but also the editing actions over parts or paragraphs of a document can be controlled;


                                    Security session, so that editing actions need only be authorized once per editing/collaborative session (for a given Role or a given author);


                                    User-driven authority, whereby the Author Role has control over the file, and other roles can have ownership rights.

The last modifier was used as a result of considering the modifier relationships in [22] for the given context. With respect to the early security requirements, the two instances of the Abstract authorization pattern can be thought as embodying SR1/SR2 and SR3, respectively (i.e. the further development of the solution is required to take into account the model), while the modifiers give initial solutions to the problem of authorizing users, which is worked out during design.

At this point we also consider the possible actions that can be performed in file sharing and in editing at an abstract, conceptual level, and link the rights associated with the subject–object pairs resulting from Abstract authorization accordingly.
                              
                                 •
                                 Sharing environment actions (initial): add file, share file, download file, open document

Editing actions (initial): read document, update document, read paragraph, update paragraph, modify document, modify paragraph

The refinement and determination of the specifics of these actions and rights is left for the design development phase (Section 5.2).

The “secured” conceptual model resulting from the pattern instantiations is shown in Fig. 6
                           , with green elements (or light gray, if viewing in black and white) being those that have been modified; gray elements are those arising from the file sharing (conceptual) authorization model; and black elements are those arising from the document editing authorization model.

In similar fashion, we can consider abstract security patterns for the other requirements and instantiate them into the conceptual model to guide the development of the pertinent solutions.

SHARED's initial, “insecure” architecture is constructed by instantiating a number of (non-security) architectural patterns and applying appropriate partitioning (see [58]). Following the patterns of [52], the resulting architectural design can be described briefly as follows:
                              
                                 –
                                 
                                    Distribution model: We employ the 
                                       Distributed Application Kernel
                                     client/server pattern from [59] for the overall distributed architecture.


                                    Message exchange model: The messaging infrastructure is realized using 
                                       Broker
                                     for the client/server communication, and 
                                       Publish/subscribe
                                     (see [39] for both patterns) for notifying users of editing updates. From a higher-level perspective, the communications infrastructure forms a single unit spanning both the client and server.


                                    Functional decomposition model: The core functionality is contained in the application server, which manages the sharing of files as well as all editing sessions. All components are structured into five 
                                       Layers
                                     
                                    [39], addressing concerns in (ordered highest to lowest): session management; event management; file and document management; notification management; and communications management. The client functionality is also stratified according to the 
                                       Layers
                                     pattern in a similar fashion, closely mirroring the structure of the server, with a top-level layer addressing user interface concerns and subsequent layers encapsulating editing functionality, event management, document management and synchronization and communications management. The overall structure of the clients and server also accords with the three-layered re-usable architecture proposed by Neyem et al. [60], in which the Collaboration layer contains all user interfaces/editing and sharing functionality; the Coordination layer contains all session, event and data management details; and the Communications layer contains the messaging infrastructure. On the client side, the editing functionality is realized using the 
                                       Model-View-Controller (MVC)
                                     pattern [39], with the model being the (local, cached) document, the view contained in the user interface, and the controller residing partially in the user interface and partially in the editing management components.


                                    Sharing model: The data shared (from a purely functional viewpoint) includes the files, of which documents are a subset, accompanying (static) meta-information (
                                       Information Object
                                     pattern [53]), as well as editing information such as the editing state and session information (cf. [52]). All files have full persistence (
                                       Persistency
                                     pattern [52]) and are stored by the server (
                                       Centralized Objects
                                     pattern [54]), which in turn uses a 
                                       Shared Repository
                                     
                                    [61] for back-end data storage, thus off-loading some of the data management burdens. Server and repository replicas can also be employed, however, we do not consider this explicitly, since it complicates the example.

During editing, documents are downloaded by each (authorized) user to their machine and are managed by a local cache, in addition to being stored on the server, implying a semi-replicated 
                                       (Data) Distribution scheme
                                     [52].


                                    Concurrency model: The 
                                       Reactor
                                     pattern [48] is used in the server's event management layer, to demultiplex events and create appropriate handlers for both file sharing and document editing activities. The use of 
                                       Publish/Subscribe
                                     introduces event asynchrony, hence 
                                       Half-Sync/Half-Async
                                     
                                    [48] is used across the event management and editing layer components for handling (incoming) notification events and (outgoing) editing events.


                                    Synchronization model: Non-document files do not need to be synchronized, since sharing takes on a global namespace (everything being controlled by the server first in this initial design). Documents, however, do need synchronization. This is implemented in the session management components, where users choose to edit particular sections of a document, which in turn are locked (
                                       Don't trust your friends
                                     
                                    [54]). This also implies a turn-taking 
                                       Floor control
                                     approach (see [52]) to editing document sections (though not whole documents). When a user updates the document, the change is sent to the server and again passed on to the session management layer, and from there to document management components in lower layers where the changes are handled. Notifications are subsequently sent to all users in a given session, or set as pending for when the authors are online (
                                       Mediated updates
                                     pattern [54]).

A model of the resulting architecture can be seen in Fig. 7
                           . This model attempts to capture several architectural views: the colors indicate the different layers that are part of the Functional decomposition model, with their major constituent components, some of which are shown in more detail with their internal composition, in boxes (logical view); arrows indicate the flow of control (execution view); and the dashed borders indicate machine boundaries (deployment view).

In what follows we describe the application of ASE during the Design (development) phase.

Taking the architectural model in Fig. 7 together with the descriptions in Section 5.2.1 as a starting point, we use the distributed architecture decomposition framework (see Section 3) to create a derived architectural model, partially shown in Fig. 8
                              . For the derived model we have used a UML-like notation, where the green (or gray, if viewing in black and white) associations are compounded from the existing UML associations, which are modeled without association classes for the sake of saving space. The dashed one-way arrows indicate that particular software components reside on a given physical node; dashed two-way arrows between components are a shorthand notation for indicating that two components reside on the same node. Regarding the level of detail, making this model (or others like it) more detailed, by, for example, considering the sub-components of the major components, will provide greater breadth for the threat analysis; however, in this case this would also lead to unnecessary complexity and make the example less tractable.

We assign each of the components in the derived model to functionality decomposition layers. This is shown partially in Fig. 9
                              , where most components and some associations have been assigned to appropriate layers (note that a given component and/or association can straddle multiple layers, and can also be re-assigned if needed). In the figure letter are used as a short-hand notation for the layers: User interaction (U), Resource management (R), Data/Storage management (S), Distribution control (D), Communications (C) and Addressing (A). Since at this point in the development, and at this level of abstraction, we do not know how all the architectural elements will be realized (e.g. the Broker may be realized using CORBA, or may be realized using a custom, simplified RPC-based infrastructure), we make conjectures regarding the technical realization abstractions as required.

We next perform the threat analysis by considering threat patterns from the base taxonomy as per Tables 5 and 6, starting with the User Interaction decomposition layer and the relevant abstractions there, and proceeding downwards.

We analyze both the client and the server together, and also separately. Once a threat was determined to be likely and selected for inclusion in our list, we passed it down the decomposition layers to consider it against other architectural contexts and abstractions (and hence components to which the latter correspond) as appropriate. To complement this, we also consider threats from the taxonomy individually, and match them to appropriate contexts. We group together threats (i.e. threat pattern instances) that are linked or result from the realization of one or more other threats.

Below we briefly outline the resulting list of threats at the application level (we do not consider threats to the underlying infrastructure for this example), focusing on those with the greatest likelihood. We continue to use the shorthand notation for the decomposition layers in the brackets describing the architectural context.
                                 
                                    •
                                    T1: Identity spoofing (D – all <maps to: client-side UI>) via Identity spoofing (U – input ports <maps to: Sharespace interface>): users can attempt to gain unauthorized access to files and documents if there is no mechanism to check their identities.

T2: Repudiation (U – input ports <maps to: editing interface>) via Track erasing (S – data structures <maps to: client document management components>) and/or Track erasing (S – file systems): users can make changes to a document and subsequently manipulate the local data stores prior to synchronization so that updates are not detected properly, leading to erasure of changes.

T3: Data inference (S – storage abstractions <maps to: documents local to Client>) linked to Data inference (U – output ports <maps to: editing interface>): users can infer additional data/sections from a file, which they would otherwise not be able to.

T4: Corruption (S – <user meta-data on Client>) linked with Corruption (S – <user meta-data on Server>): users can manipulate any number of abstractions to change their local meta-data.

T5: Unauthorized access (R – resources & S – storage abstractions <maps to: file store on Server>) via Invoking unauthorized operations (D – operations <maps to: Server event handler>): malicious requests could result in files being downloaded without appropriate rights.

T6: Resource exhaustion (R – resources & S – database systems <maps to: file store on Server>): purposefully sharing a large number of files or files with a large size could cause depletion of space on the server storage back-end.

T7: Session state poisoning (S – data structures <maps to: client data store>): editing session information carried through the communications medium can be modified by corrupting session information (see also T6).

T8: Exploiting concurrency flaws (D – all <maps to: event handling mechanisms>): purposeful or accidental requests can be made that affect the asynchronous handling of editing (especially update) events, causing clashes and/or inconsistencies of document data.

T9: Exploiting concurrency flaws (R – algorithms <maps to: document management>): it may be possible to exploit the algorithms for updating documents to either erase tracks or cause corruption (see also T2, T4)

T10: Message secrecy violation (C – all abstraction <maps to: communications infrastructure on clients and server>): attackers can eavesdrop on the communications medium to obtain document and/or file information.

T11: Message integrity violation (C – all <maps to: comm. infr. on clients and server>): attackers can eavesdrop on the communications medium to change document and/or file information, potentially without detection.

T12: Message authenticity violation (C – messages and message channels <maps to: comm. infr. on clients and server>): attackers or users can change the source of their message to interfere with the collaborations or obtain information.

Some threats were deemed feasible, but unlikely, e.g. Injection (S – database systems <maps to: Server database>) via Injection (U – input ports <maps to: editor interface>), which although theoretically possible, would be made difficult since the flow of control to the database back-end is interrupted by a number of other components that transform the requests into various formats.

Following the Adversary Modeling (at Design) stage (this can also be performed simultaneously with it), we form a list of canonicalized security requirements (refer to Fig. 3 for the flow of activities) based on the threats from the analysis process as well as the early security requirements. More specifically, the early requirements are converted to technical requirements using Table 7 as follows:
                                 
                                    •
                                    TSR1: <enforce Authorization (for document viewing and editing)> ← SR1, SR2

TSR2: <enforce Authorization (for file sharing)> ← SR3

TSR3: <enforce Identity management (for users)> ← SR1, SR5

TSR4: <enforce Storage security (documents)> ← SR1, SR2

TSR5: <enforce Storage security (shared files)> ← SR3

TSR6: <enforce Storage security (ID binding and hashing of documents)> ← SR5

TSR7: <enforce Execution control (for shared files)> ← SR1, SR2

TSR8: <enforce Logging and monitoring (document changes) > ← SR5

These technical requirements are relatively specific, since the mapping of early requirement classes to generic policies was guided by our expertise. If developers are not experienced, however, then the more generic forms of, for example, “<enforce Storage security> ← SR1, SR2, SR3, SR5” should be sufficient, and can be refined during later ASE stages.

Regarding the technical security requirements arising from the threat analysis, some concrete examples in summarized form are:
                                 
                                    •
                                    TSR9: <protect from Identity spoofing (D – all)>, <protect from Identity spoofing (U – input ports)>

TSR13: <protect from Unauthorized access (R – resources & S – storage abstractions)>, <protect from Invoking unauthorized operations (D – operations)>

TSR15: <protect from Session state poisoning (S – data structures)>

TSR17: <protect from Exploiting concurrency flaws (D – all)>

TSR18: <protect from Message secrecy violation (C – all)>

Having enumerated all the technical requirements, we convert them into positive form to determine the precise realizations, thereby extending and consolidating the previous Countermeasure Identification stage performed during Analysis (Section 5.1.2). The reference to architectural contexts is kept to give guidance during the modeling of corresponding solutions. Besides TSR1 to TSR8 (above), which are already in positive form, some example conversions (briefly summarized) are:
                                 
                                    •
                                    TSR9 → <enforce Identity management> at the Client user interfaces

TSR2, TSR13 → <enforce Authorization> for file sharing, at the Server-end

TSR15 → <enforce Storage security> on the Client-end meta-data

TSR16 → <enforce Execution control (process serialization)>

TSR18 → <enforce Secure communications> between the Client and Server components

As shown above, some requirement mappings may overlap or come from early requirements. Putting all the requirements together and using the four mappings from Section 4.2.2.1, allows us to arrive at the following countermeasures (we have decided not to use tactics directly in this example):


                                 
                                    
                                       •
                                       Authorization solution frame (as already chosen in Section 5.1.2), for controlling sharing and editing actions ← TSR1, TSR2, TSR13

Identity management solution frame (Authentication pattern family) ← TSR3, TSR9

Secure communications solution frame ← TSR18 to TSR22

Security information management solution frame (Policy management pattern family) ← as a result of using Table 2 (solution frame relationships) for Authorization

Security information management solution frame (Key management pattern family) ← as a result of using Table 2 (solution frame relationships) for Secure communications

Appropriate patterns can be selected in accord with the structure of the solution frames to develop the solution for a set of given requirements. In this sense, a further, finer-grained identification of countermeasures is obtained by following the solution frame structures.

Since solution frames are not available for some requirements (e.g. TSR15 from T7, or TSR16 from T8), we use Table 9 and the patterns catalog in [11], to determine appropriate standalone or compound patterns. We omit the details of this step.

At this stage we design the security architecture of SHARED using the standalone patterns and the patterns encapsulated in the solution frames identified previously. Below we describe in some detail the design of the enforcement architectures for the two conceptual authorization models (document editing and file sharing) from Section 5.2.2.2, and in less detail the design of the secure communications and authentication infrastructures – all using the previously identified solution frames. For the sake of simplicity, in our descriptions we do not always strictly follow the progressive refinement process inherent in the pattern family structures, but discuss only the final results, after the design decisions have been made.

From the Secure communications solution frame (Secure two-party communications pattern family) we first instantiate 
                                    Secure message channel
                                  between the clients and the server, which will be placed inside the Communications Infrastructure components (see bottom part of Fig. 7). In satisfying the security properties implied by requirements TSR18 to TSR22 we also add to the 
                                    Secure message channel
                                  the modifiers 
                                    Message encryption
                                 , 
                                    Message tampering protection
                                  and 
                                    Message source authentication
                                 . We apply 
                                    Secure communications session
                                  across the Session Layer of the server and the Communications Infrastructure components, such that session initiation is begun, managed and terminated by the (server-side) Session Manager component (Fig. 7). We omit describing the details of the actual protocols. Assuming that the Communications Infrastructure will be realized using a COTS middleware solution, we instantiate the 
                                    Infrastructure-driven message transform
                                 . This implies that we rely on the necessary algorithms and protocols (e.g. SSL/TLS) to have been implemented as part of the middleware infrastructure. We omit the details of key management for the sake of space and simplicity.

From the Identity management solution frame (Authentication pattern family), we instantiate the 
                                    Authenticator
                                  pattern across the clients and server architectures, and realize it as an 
                                    Authentication Server
                                  (centralized) on the server-side. We subsequently use the 
                                    Password-based Authentication
                                  and 
                                    Cryptographic Authentication
                                  solution design strategies for allowing users to login with a password, sent to the 
                                    Authentication Server
                                  via a protected communications channel (unilateral authentication). User IDs are assigned administratively and encapsulated (together with certain authorization rights, as discussed below) in 
                                    Credentials
                                  stored on the clients for later use. Since users only need to login once for a given collaborative 
                                    Session
                                  (whether sharing or editing), the 
                                    Single Sign On
                                  pattern is realized as a side-effect.

From the Authorization solution frame we first instantiate 
                                    Abstract authorization architecture
                                  twice for the two conceptual authorization models.

For file sharing, all of the 
                                       Abstract authorization architecture
                                    's participants – PEP (Policy Enforcement Point), PDP (Policy Decision Point), PIP (Policy Information Point) and PAP (Policy Administration Point) reside on the server. The 
                                       Abstract authorization architecture
                                     is realized using an 
                                       Interceptor
                                     connected to the Event Manager. When users share a file, the PDP components must check the file group as well as the allowable user groups with which the file can be shared; when users wish to download a file, only the user group is checked. Using 
                                       Pull authorization strategy
                                    , the rules associated with the sharing operations are encapsulated in ACLs (
                                       Access Control List
                                     pattern) attached to each file. These rules are determined in part administratively (group assignment), and in part by users (allowable operations based on groups) via the client-side Sharespace interface. The ACLs are thus stored according to the 
                                       Centralized Policy Manger
                                     from the Security information management solution frame (Policy management pattern family) with 
                                       Pull security information
                                     semantics, where the central administrative interface participant residing on the server is accessible to the client Sharespace UI.

For document editing, we choose to span the PEP and PDP participants (from the second 
                                       Abstract authorization architecture
                                     instance) across both the clients and server, to reduce the performance bottlenecks associated with realizing the 
                                       Fine granularity
                                     authorization modifier (Fig. 4). Following this decision, editing operations are separated into two categories: viewing and modification operations. To enforce viewing operations using the PEP on the server-side (and hence avoid placing overhead on the client), we apply the 
                                       View
                                     pattern [53], whereby after a document is requested by a user – and after the relevant File Sharing model ACLs are checked – only those document parts are sent which the user is allowed to view and/or modify. Besides the document, a 
                                       Credential
                                     encapsulating the user's editing rights is sent to the client, which can be presented again in subsequent modification operations.

Modification operations are enforced via the client-side PEP, which is linked to the server PDP. The server PDP works in conjunction with the PIP participant (which gathers the necessary meta-data from the document and user, combined with the user 
                                       Credentials
                                    ) and passes the client-side PEP the result. Both client- and server-side PEPs from the 
                                       Abstract authorization architecture
                                     are realized as 
                                       Interceptors
                                     playing the role of 
                                       Reference Monitors
                                    , in the client case connected to the Editing Controller and in the server case connected to the Session Manager (Fig. 7).

Given our use of 
                                       Credentials
                                    , we are in effect realizing a 
                                       Push authorization strategy
                                     for all modification operations, with the 
                                       Credentials
                                     acting as 
                                       Capabilities
                                    , which encapsulate the authorization rules. A 
                                       Decentralized Policy Management
                                     realization of the 
                                       Abstract Policy Manager
                                     pattern is used to manage all the user-related security information on the client (including the 
                                       Credentials
                                    ), also requiring an addition of another, secondary store local to each client.

Since the majority of both the File Sharing and Document Editing enforcement architecture functionality resides on the server, some participants (e.g. the PDP) can be merged as per the pattern participant resolution strategies in Section 4.2.2.2.

5.2.3.2.4. Discussion. Naturally, the descriptions above are hardly sufficient to capture the whole design of the security architecture for SHARED. For example, to satisfy TSR15 in conjunction with the 
                                       Security Session
                                     modifier from the authorization model (see Fig. 6), implies the use of the 
                                       Session
                                     pattern in the Session Management layer (Server-side), using, for example, Session Objects which are bound and cryptographically hashed with the identities of users (cf. Identity management solution frame) and used as part of, or in conjunction with, the 
                                       Credentials
                                     during editing updates. A number of such fine-grained detailed design decisions must be considered and refined, perhaps iteratively, together with the (initial functional) architecture from Section 5.1.1 to obtain the final secure software architecture.

During this stage we check all the traceability links to make sure that the countermeasures we have incorporated into SHARED's architecture really do protect from all the threats and satisfy all the necessary requirements.

Having designed SHARED's security architecture, we perform the threat analysis process with the meta-security threat patterns. This allows to determine, for example, that, with respect to the authorization infrastructure, messages sent between the client-side PEP (connected to the Editing Controller) and the server-side PDP realizations can be eavesdropped (considering patterns from the Network communication attacks threat class); or that the authorization rules for file sharing, which are determined administratively, can be subverted (Unauthorized modification of rights threat pattern).

Addressing these threats follows the same stages as on the initial iteration, i.e. transitioning into ASE's Countermeasure Introduction stage. For example, with respect to the second threat above, we can identify an application of the 
                                 Meta-authorization control
                               pattern from the Authorization solution frame as being suitable, which in turn implies the creation of an additional conceptual authorization model and enforcement architecture (in this case we would choose to use the existing 
                                 Reference Monitor
                               based infrastructure to avoid duplication of functionality).

Below we discuss some alternative design decision that could have been taken, and how ASE can be applied for them.

If during the initial architecture development phase it was decided that instead of the client–server architectural style a peer-to-peer style would be used for file sharing, or editing, or both, then the threat analysis process of ASE (Security Requirements Determination at Design stage) would have been performed using threat patterns from the peer-to-peer taxonomy (which itself encompasses the general distributed systems threat taxonomy) in [21]. Such a decision during later development would simply imply re-iterating the relevant ASE stage to consider the appropriate threats. In both cases this would reveal additional, system-specific threats, for example:
                                 
                                    •
                                    Churn (R – <maps to: file manager components>) (a variation of T8) potentially in conjunction with Query flooding (C – message channels <maps to: comm. infr. and also Notification Layer on Server>): users share a large number of files and/or cause a large number of notifications to be broadcast.

Unauthorized operation on data (S – <maps to: document manager and client document store>): depending on the peer-storage scheme, users may be able to manipulate local documents to cause changes to propagate to other users.

Mapping to concrete solutions would be done as before, with the difference being that there are no patterns specific to peer-to-peer systems in any of the solution frames (at the time of this writing) and only one such independent security pattern (
                                 Data Integrity in P2P Systems
                               
                              [37]). This implies that custom-made solutions will need to be created, as per mapping number 4 in Section 4.2.2.1, thereby reducing the ease of use and hence usability of ASE for the Security Modeling (at Design) stage.

Regarding the existing solutions that are already modeled (or will be modeled, if the peer-to-peer style supplants the client/server style early on), some pattern instances would require reconsideration. For example, with respect to the patterns for the authorization infrastructure, the 
                                 Abstract authorization architecture
                              's PEP will have to span a single peer, and a View of a given document will have to be generated individually. The peer-to-peer style similarly impacts the management of policies as well as cryptographic keys; in most of these cases the existing security patterns, or customizations thereof, should continue to be applicable and could be re-instantiated.

Another highly relevant design decision with impact on the security architecture is the choice of fully synchronous, real-time editing. In this case the patterns 
                                 Believe In Your Group and Detect a Conflicting Change
                               
                              [54] would be used in the Concurrency model realization, and locking would no longer be required. This would also lead to a consideration of data consistency issues (considering threats with respect to the Distribution Control decomposition layer, the Event Manager and Session Manager components, etc.), not only in the actual documents, but also between the authorization rules and the document updates (see [62]). Thus the meta-security threats iteration of ASE (Section 5.2.3.4) would gain greater importance. As for the peer-to-peer decision above, appropriate countermeasures would include process serialization, which would be part of the Execution Control solution frame (currently not specified in the literature), hence custom-made solutions based on synchronization patterns in, e.g. [48] (see [52]) or [63] would have to be used.

Although implementation is beyond the scope of this paper, applying the corresponding phase of ASE to SHARED would imply implementing the security architecture by mapping some parts to COTS components (as in the secure communications protocols to an underlying middleware platform supporting the relevant features), and manually coding the rest (e.g. the authorization infrastructure) as separate modules that are part of the system implementation itself. Good coding practices, static tools, etc. can be used to reduce the number and severity of code-related vulnerabilities that could be introduced at this phase; and the Wrapper Facade pattern [48] (cf. [64]) and its secured counterpart Secure Wrapper Facade 
                           [65], as well as other adaptation patterns such as Adapter and Proxy 
                           [39,66], can be used when interfacing with COTS components and/or legacy code [67] (see also [72]).

Our experience with applying ASE can be summarized as follows:
                           
                              •
                              As anticipated from some of the conclusions in [8] (cf. Introduction – Section 1), we found that encapsulation in the form of solution frames and threat taxonomies helped us to quickly analyze and introduce security features into SHARED. If we had to rely on ad hoc checklists or our own expertise alone the process would have certainly been slower. Solution frames in particular offered a very effective means of incorporating security solutions into SHARED's software architecture, allowing us to work from higher-level concepts to more concrete designs progressively (as per the purpose of solution frames). The latter point is in general an advantage of the “aggressive” use of encapsulation in ASE, which supports the principle of abstraction and hence allowed us to first conceptualize, and deal with details later.

Applying ASE during Requirements Elicitation proceeded as per the original methodology of Fernandez et al. During Analysis we found that building up and incorporating a custom authorization model into the conceptual model was quite easy and efficient using the Authorization solution frame. This in turn helped us to guide the design of the authorization-related features during ASE's later stages.

As can be surmised from the preceding points, we found ASE easy to use overall (i.e. with a good degree of usability), as can be expected of a pattern-driven methodology, thus retaining the usability of the original methodology of Fernandez et al.

Performing threat modeling (Adversary Modeling stage) twice at two different stages helped to capture a variety of threats, from both a user-centric and architecture-centric viewpoint. Threat patterns were valuable in both stages, and during the second stage in particular (enacted during design) ensured that the process was systematic. Nevertheless, precisely this systematicity, especially when using the threat-driven analysis strategy, was also found to be somewhat taxing. In part, this was due to our wish to comprehensively consider all threats and thus ensure the system is maximally protected, at least from threats that can be addressed leading up to (but excluding) implementation. Nevertheless, we believe that some form of tool-support specifically for the Adversary Modeling stage during Design would help to reduce the time spent on considering all threats in these circumstances, and hence increase ASE's efficiency.

Regardless of the extra effort we expended in threat analysis, we did not find ASE laborious overall, and continue to believe it can be used without tool-support on at least small- to mid-size projects. Of course, we do acknowledge that tool support would make a number of activities more efficient (see Section 7 discussing future work), and would become of greater importance for large-scale projects – something that could be said for all security methodologies.

Although we applied ASE in an academic environment, we anticipate that the overall process – as in the particulars of the activities carried out – benefits and drawbacks will be similar in industry environments. Needless to say, further case studies on a variety of projects would help to form a more comprehensive assessment of ASE's features.

@&#RELATED WORK@&#

There are a number of security methodologies of various paradigms for, or applicable to, distributed systems, which are related to ASE and which are reviewed in detail in [8]. Some examples include Secure Tropos [78], SEPP [14], PSecGCM [5,31], PWSSec [12], SERENITY [70,75,76], AORDD [26,77], SECTET/SECTISSIMO [79,80] and security-enhanced SPACE [81] (for methodologies of a model-driven paradigm see also [82]). Naturally, of these we can consider comprehensive pattern-driven methodologies (SEPP, PSecGCM, SERENITY, PWSSec and the original methodology of Fernandez et al. [18]) to be the most closely related, as other comprehensive methodologies differ fundamentally by virtue of their paradigm. With respect to these (pattern-driven) methodologies, ASE is distinct in its almost ubiquitous use of encapsulation via solution frames and threat taxonomies, which themselves organize and encapsulate different types of software patterns; and by virtue of the fact that it is designed specifically for (general) distributed systems, while being able to take into account specifics of peer-to-peer systems as required – making ASE an example of a flexible methodology as defined in [17]. The latter two characteristics are interconnected, insofar that the types of artifacts used in ASE also determine its system focus. The artifacts also influence ASE's security process, e.g. the threat analysis process based on threat patterns; the (micro) processes for applying patterns by following the solution frame structures (these processes are themselves instances of a micro-process pattern in each frame) – etc. Another distinction worth repeating from the Introduction is that in contrast to pattern-driven methodologies specifically using security patterns (not components or generic architectures treated as patterns, as is done in SEPP, PSecGCM or SERENITY), ASE strikes a balance between being too specific (cf. PWSSec for Web-service-based systems or the methodology of Delessy and Fernandez [13] for SOA systems) and too generic (cf. the original methodology of Fernandez et al., or a number of other partial and/or young methodologies for applying security patterns reviewed in [11]).

Of course, regardless of unique features, it is also possible to find in the aforementioned related methodologies activities that resemble or can be compared to some of the activities performed in ASE. For example, SEPP uses mapping tables to determine additional security requirements, akin to Table 3 for security solution frames, and also maps requirements to pre-defined solutions [14,35]; PSecGCM constructs a secure conceptual model, which is subsequently used when constructing a security architecture; and Delessy and Fernandez refine a set of basic “defenses” as patterns and use pattern relationships for their collection of SOA-specific security patterns, similarly to the way SECTISSIMO uses pattern refinement in a Model-Driven Architecture context. All of these similarities indicate nothing other than the fact that a successful way of doing something within one context tends to appear in similar forms within similar contexts, i.e. the latter features are really instances of specific security process patterns (cf. [17]), which could be abstracted and re-applied in the construction of other methodologies. In this sense, the fact that ASE possesses such similar features is an advantage, not a disadvantage that diminishes ASE's uniqueness – just as ASE does not diminish the value or uniqueness of its related security methodologies, which possess their own unique advantages within their own specific constraints and objectives.

A number of other security methodologies exist in the literature which attempt to take into account the specifics of different system types – e.g. databases/data warehouses [83–86]; as well as specific project situations – e.g. systems being developed using business processes [88,89] or as software product lines [73,87]. Needless to say, their specific features are quite distinct from those of ASE, even though, they do, of course, follow a general model of gathering and analyzing security requirements, considering security during system design, etc. (cf. [8]).

Besides related security methodologies taken as holistic units, a number of security process fragments and conceptual security artifacts can be found in the literature that are related to ASE's security process and conceptual framework, respectively – even within the aforementioned methodologies themselves. For example, security requirement gathering and analysis approaches as reviewed in [93] could be compared to ASE's Security Requirements phase activities; standalone threat modeling processes such as SREP [94] or those in [95,96] could be compared to ASE's Adversary Modeling stages (see Fig. 3); security verification approaches such as those taken in MBSE/UMLsec [97–99] could be compared to ASE's Security Verification stages performed during system design and implementation – etc. Although related and comparable in some sense, these individual processes are clearly distinct from each of ASE's corresponding phases, stages and tasks.

With respect to security artifacts, and in particular defensive artifacts, one can mention security ontologies [100], UML profiles [85,89], problem frames [14,35], ESPs (enterprise security patterns) [90], security-aware database schemas [91] and many others that could be compared in utility to the various types of patterns constituting ASE's conceptual framework. Such artifacts have their own benefits and drawbacks when compared to ASE's patterns, but it is perfectly conceivable for them to be used in the context of ASE – especially since solution frames allow for other artifacts to be employed instead of security patterns within the same overall structure. Such use would require, however, re-engineering ASE and hence a re-application of S-SMEP in its tailoring capacities, which would result in a further evolution of the methodology.

In this paper we presented ASE – a comprehensive pattern-driven security methodology designed specifically for (general) distributed systems – focusing on the early life-cycle phases, and especially the design phase. Through its distributed-systems-specific set of conceptual artifacts and its comprehensive process, ASE is capable of addressing all or most of the core distributed systems security concerns, providing developers with detailed guidance on how and where to introduce relevant security features into a system's architecture during development. After presenting ASE's conceptual framework and security process aspects (Sections 3 and 4, respectively), we showed in detail how ASE can be applied in practice via the development (up to and including design) of a realistic case study – the SHARED distributed collaborative system (Section 5).

ASE inherently possesses beneficial features that allow it to fully satisfy a number of the core security methodology evaluation criteria for industry adoption in [8], which in turn can be seen as elementary metrics for methodology quality (in what follows the corresponding criterion number from the latter reference appears in brackets):
                        
                           •
                           The provision of guidance on what security measures should be applied and where they should be applied; as well as the essential use of threat modeling (criterion no. 2);

Sensitivity to the system or application, with security measures specific to the nature of the application, with a wide range of solutions (for distributed systems) (criterion no. 3);

Low security expertise requirements, with strong reliance on the existing software engineering skillsets of developers (criterion no. 4).

The beneficial features of ASE aligned with those of the aforementioned evaluation criteria that have secondary importance include (cf. [8]):
                        
                           •
                           Use of established modeling languages, such as UML, to reduce developer training and effort (criterion no. 6);

Presence of assessment and verification activities to ensure the introduced security solutions correctly counter the relevant threats (criterion no. 8);

Manageable overhead in proportion with the complexity of the target system (criterion No. 9);

Use of common repositories or catalogs of security knowledge relating to solutions (security patterns, solution frames) and threats (threat patterns) to encourage the application of best practices, increase productivity and aid developer training (criterion no. 10).

Besides being applicable to general distributed systems, ASE is also capable of addressing the specifics of peer-to-peer systems (Section 5.3.1.1), making it a first example of “a methodology that makes provisions for both specific distributed system types and general distributed systems” [11], and hence a flexible security methodology in the technical sense of [17]. With respect to this flexibility, it is important to note that ASE is currently limited in practice by the lack of security solution artifacts specific to peer-to-peer systems that would correspond to the relevant patterns from the peer-to-peer-specific threat taxonomy/library of Uzunov and Fernandez [21] – cf. Section 5.3.1.1. The construction of a range of such solutions in the form of security patterns encapsulated in the various solution frames thus forms an important task for the future. A related and similarly important task is the specification of the “missing” solution frames that were marked with an asterisk in Tables 2 and 3.

In this paper we have focused almost exclusively on the early development life-cycle phases (analysis and especially design), with little consideration given to ASE's Security Implementation phases. Detailing and evaluating the latter stages forms another important future task. A particularly worthwhile pursuit towards this end would be the automatic or semi-automatic generation of test cases from the threat patterns utilized during ASE's Adversary Modeling stage, which could build on existing approaches for other threat artifacts – such as that of Marback et al. for threat trees [68]. Continuing the focus on the testing development stage, the integration and use of security test patterns [69] for penetration testing, potentially as a complement to the aforementioned test cases, would be another valuable addition to ASE.

Following on from the latter implementation-oriented direction is the construction of appropriate security metrics for measuring the effectiveness of ASE, i.e. whether a given degree of security, in some sense, has been achieved. Some relevant work in this direction that would be directly applicable to ASE was begun in [103]; and other relevant proposals, such as those of Heyman et al. [104] and Alkussayer and Allen [105], could also be leveraged for the same purpose. A consideration of metrics for ASE could in turn lead to a consideration of measuring the effectiveness of security methodologies in general – a subject which has received very little attention (cf. [32]).

With respect to practical application in industry scenarios, one area where ASE is lacking is the provision of software tool support. While, as illustrated in our case study in this paper, the development overhead is not unmanageable, a number of the tasks could be made more efficient via the use of tools, even of an elementary nature (e.g. showing developers a list of available patterns with descriptions for a given solution frame). More advanced tools that can “recommend” solutions (cf. [70]) or manage the traceability links are also an option.

While in our illustration of ASE we espoused a (purposefully) loose “architecture-oriented” development approach, ASE is not tied to this approach or to any specific development methodology. Incorporating an object-oriented-like analysis stage is certainly helpful for ASE's early phases, however, it is perfectly feasible to employ an approach (or strict methodology) with an altogether different paradigm for the other stages and phases, e.g. the architecture-centric Attribute-Driven Design (ADD – see [24]) for the design phase. A good example of such a hybrid-paradigm methodology can be found in [71].

Similarly, there is no reason why ASE should not be compatible with an agile or an agile-inspired methodology – so long as the methodology does not eschew upfront architecture development, which, as Meyer points out, is an essential element in any development project [106] (see also [107]). As ASE (at its present state) is fundamentally architecture-centric, integration with such an “upfront architecture” agile methodology should be no more problematic than integration into a “heavy-weight” methodology based on a traditional development life-cycle model.

In all cases, one way integration could be performed is to align the phases and stages of ASE by way of the generic life-cycle modifiers to the appropriate phases of the respective development methodology. This would lead to a set of additional activities that are performed during those development phases and/or stages (or their equivalents). In this sense, ASE would be enacted alongside, or where appropriate, following after, the development activities. Of course, it is certainly conceivable that the specifics of the target development methodology could influence the order and enactment of ASE's activities. More generally, the nature and paradigm of the development methodology used along with any given security methodology is not without importance, and an investigation of the precise compatibility and interplay between development and security methodologies, and the subsequent formulation of techniques for security methodology integration in general (cf. [17]), which could then be applied to ASE in particular, constitute important research directions.

In Table 4 we outlined and summarized ASE's security process aspect via a SPEM 2.0 specification, however, we indicated that this specification should not be taken as definitive or indeed as more than just a different, semi-formal, development-oriented view of ASE. Representing the elements of ASE's security process in terms of SPEM 2.0 definitively would require a mapping between the notions and corresponding notation (from [17]) as seen in Fig. 3, and SPEM 2.0 – something that is a non-trivial undertaking. Doing this may help, however, with integration as discussed above, insofar that ASE could be more easily aligned with development methodologies that are already specified, or specifiable, in SPEM.

As final, concluding remark, it is worth pointing out that most of the future directions outlined thus far that imply some kind of improvement to ASE can be realized not only in an ad-hoc fashion, but also by systematically re-engineering ASE. As mentioned in Section 2.3, ASE itself is the result of such a re-engineering endeavor, using the approach presented in [17]. This also accentuates the point that the beneficial features of ASE (especially the distributed-systems-specific artifacts, which are themselves generic) can also be engineered into other security methodologies, just as other features of other methodologies can be engineered into ASE. In this sense, ASE can indeed be seen – as remarked in the Introduction – as just one particular solution with its own beneficial, self-contained features, generated by a meta-solution for the problem of systematically introducing security into software.

In this appendix we outline the structure of the currently available solution frames that can be used in ASE [22,23], presented in the form of a table – Table 11. Each pattern name is listed followed by its type in brackets (asp — abstract security pattern; sp — security pattern; mpp — micro-process pattern; pm — pattern modifier). The italics font on a given row indicates the canonical levels for each pattern family in a given frame, while the non-canonical levels (within each canonical level, internal to the frame) appear in curly brackets. The downward order of abstraction levels in a given table column follows the structure of each pattern family. However, the order of presentation of the families within each solution frame, as well as the order of presentation of patterns in each abstraction level (within a given pattern family), is non-specific (i.e. the ordering in this case is not relevant). We only include abstraction levels in which there are actual patterns, and not ones which are described for the sake of completeness in the aforementioned references. We also omit to list the implementation workflow micro-process patterns for each frame that indicate how that frame, or certain families therein, should be applied.


                     
                  

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Automated detection of age-related macular degeneration using empirical mode decomposition

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Fundus images are converted to 1D signals using Radon transform.


                        
                        
                           
                           Empirical Mode Decomposition (EMD) is applied on the 1D signal.


                        
                        
                           
                           Nonlinear features are extracted from IMFs derived from EMD.


                        
                        
                           
                           Various ranking methods are used to identify optimal features.


                        
                        
                           
                           Classification accuracy of 100% is obtained for STARE database.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Age-related macular degeneration

Fundus imaging

Empirical mode decomposition

Locality sensitive discriminant analysis

Decision support system

@&#ABSTRACT@&#


               
               
                  Age-related Macular Degeneration (AMD) is the posterior segment eye disease affecting elderly people and may lead to loss of vision. AMD is diagnosed using clinical features like drusen, Geographic Atrophy (GA) and Choroidal NeoVascularization (CNV) present in the fundus image. It is mainly classified into dry and wet type. Dry AMD is most common among elderly people. At present there is no treatment available for dry AMD. Early diagnosis and treatment to the affected eye may reduce the progression of disease. Manual screening of fundus images is time consuming and subjective. Hence in this study we are proposing an Empirical Mode Decomposition (EMD)-based nonlinear feature extraction to characterize and classify normal and AMD fundus images. EMD is performed on 1D Radon Transform (RT) projections to generate different Intrinsic Mode Functions (IMF). Various nonlinear features are extracted from the IMFs. The dimensionality of the extracted features are reduced using Locality Sensitive Discriminant Analysis (LSDA). Then the reduced LSDA features are ranked using minimum Redundancy Maximum Relevance (mRMR), Kullback–Leibler Divergence (KLD) and Chernoff Bound and Bhattacharyya Distance (CBBD) techniques. Ranked LSDA components are sequentially fed to Support Vector Machine (SVM) classifier to discriminate normal and AMD classes. The performance of the current study is experimented using private and two public datasets namely Automated Retinal Image Analysis (ARIA) and STructured Analysis of the Retina (STARE). The 10-fold cross validation approach is used to evaluate the performance of the classifiers and obtained highest average classification accuracy of 100%, sensitivity of 100% and specificity of 100% for STARE dataset using only two ranked LSDA components. Our results reveal that the proposed system can be used as a decision support tool for clinicians for mass AMD screening.
               
            

@&#INTRODUCTION@&#

Age-related Macular Degeneration (AMD) is a irreversible, chronic and multi-factorial ocular condition, identified by the presence of clinical features namely drusen, Retinal Pigment Epithelial Defect (RPED), Choroidal NeoVascularization (CNV) and Geographic Atrophy (GA) [1]. AMD is caused by ageing of cells in the macula region. It affects the people above the age of 50years and may lead to blindness [1]. United Nations (UN) and World Health Organization (WHO) estimates 20–25 million people are affected worldwide and 8 million people have severe visual loss [2]. According to the presence of above mentioned clinical features AMD is mainly categorized into early, intermediate and advanced stages [3]. Further, advanced AMD is classified into dry and wet type. The clinical features, symptoms, detection methods and treatment options are described in Table 1
                     
                     .

Early stage of AMD shows no symptoms, however it can be detectable by the presence of drusen [4]. According to Wisconsin AMD grading [6] drusen is classified as per the size and boundary visibility. This work utilized Wisconsin AMD grading [6] to examine the fundus images of private dataset which is used in this study and the images are labelled as early, intermediate and late AMD by the clinical experts. Several works reported in the literatures proposed various AMD detection methods using drusen segmentation which are briefly explained in Table 2
                     .

Most of the reported works in Table 2 concentrates on drusen segmentation except few studies [9,14,16,19]. The works in [9,14,16,19] uses drusen segmentation for automated detection of AMD. However, segmentation of drusen is a challenging task due to poor boundary visibility and other abnormal lesions [21]. Hence, few works [5,7,21–27] proposed image analysis and pattern classification techniques for automated screening of AMD. Hijazi et al. [21] proposed hierarchical decomposition and spatial histogram techniques for automated AMD screening and reported an accuracy of 74% and 100% respectively. Inverse segmentation method using statistical texture features is proposed in [22,23] to identify healthy and unhealthy region in AMD images. Their method obtained an inverse segmentation accuracy of 90% for unhealthy region [22]. The statistical segmentation in [23] obtained segmentation accuracy of 89.59%, 92.69% and 93.03% for small, medium and large degeneration [23] respectively. Instantaneous Amplitude (IA) and Instantaneous Frequency (IF) are used in [24] for the detection of drusen, pigmentation, GA and extended to AMD screening. These IA and IF are extracted using Amplitude Modulation (AM)–Frequency Modulation (FM) method. Their method is evaluated using two private datasets namely Retina Institute of South Texas (RIST) and University of Texas Health Science Centre in San Antonio (UTHSCSA) and reported an Area Under receiver operator characteristics Curve (AUC) of 0.84 and 0.77 respectively. Discrete Wavelet Transform (DWT) and wavelet energy and entropy feature are used in [5] for automated screening of AMD. Their method analysed various feature ranking methods to select optimum features for AMD detection and reported an accuracy of 93.70%. Automated AMD screening using Case Based Reasoning (CBR) and Dynamic Time Warping (DTW) is proposed in [25] and performance of their method is compared with the manual graders and reported a sensitivity of 86%. Hierarchical decomposition using trees and Weighted Frequent Sub-Graph Mining (WFSM) methods are proposed in [26] to identify normal and AMD classes using fundus images. Various texture features and ranking methods are experimented in [7] to discriminate normal and AMD classes with an accuracy of 95.07%. Hijazi et al. [27] proposed automated screening of AMD using data mining approaches. Their method extracted wavelet, texture features namely Gray Level Co-occurrence Matrix (GLCM), colour histogram features and colour features from normal and AMD fundus images and reported a classification accuracy of 99.6%.

Aforementioned works utilized data mining and pattern recognition techniques for automated screening of AMD. However, these works has following limitations: (i) lesion segmentation (drusen) [22–24], Optic Disc (OD) and blood vessel removal are mandatory [25–27]; (ii) many features are used to design a classification model [5,7,21,26,27]; (iii) existing works [22–27] uses either private or public domain datasets to evaluate their techniques. The reported works [5,7,21,26–28] for AMD detection used 1262, 1000, 50–400, 121, 54 and 22 features respectively to obtain highest classification performance. The execution time may extend with more features. Our proposed work uses less number of features for classification, it does not require any segmentation (as will be shown later in this paper), and performance is evaluated using both private and public domain datasets.

In the present work various nonlinear features are extracted from Intrinsic Mode Functions (IMF) [29]. The Empirical Mode Decomposition (EMD) is widely used to analyse biomedical signals such as Electrocardiogram (ECG) [30], near-infrared spectroscopy muscular signals [31] and Electroencephalogram (EEG) [32,33] to detect diabetes [30,31], QRS complex [34], epilepsy [32,33] and texture analysis [35]. However, to the best of our knowledge, this is the first work applying EMD for the AMD detection. EMD breaks the signal without loosing the time domain information [29]. It can capture the subtle changes present in the biomedical signals [31]. In the past, this method yielded good classification performance by capturing the signatures present in the phonological signals. The pixel variation in AMD images is not uniform due to the presence of drusens [5,7,28]. These nonlinear changes can be captured only by nonlinear feature extraction methods [29,31,33]. Hence, in this work, we have used EMD and nonlinear features to discriminate normal and AMD classes.

The block diagram of the proposed AMD detection system is shown in Fig. 2
                     . In the first step green channel is separated from normal and AMD colour fundus images and contrast enhancement is performed using Contrast Limited Adaptive Histogram Equalisation (CLAHE) [36] to improve the image contrast. Further, Radon Transform (RT) is performed on preprocessed 2D green channel fundus images at each 5°. Now the images are converted into 1D signals. These signals are subjected to EMD to generate IMFs and various non-linear features are extracted from these IMFs. The dimension of the extracted features are reduced using Locality Sensitive Discriminant Analysis (LSDA) [37] and subsequently ranked using various feature ranking techniques namely minimum Redundancy Maximum Relevance (mRMR) [38], Kullback–Lieber Divergence (KLD) [39] and Chernoff Bound and Bhattacharyya Distance (CBBD) [40]. Further, ranked features are sequentially fed to different Support Vector Machine (SVM) classifier kernels [41] namely linear, quadratic, polynomial and Radial Basis Function (RBF). The average classification performances are calculated using 10-fold cross validation.

The rest of the paper is organized as follows: Fundus image dataset description, preprocessing, empirical mode decomposition, feature extraction, reduction and ranking are explained in Section 2. SVM classification method is briefly described in Section 3. The results of the proposed system is presented in Section 4 and discussed in Section 5. Finally, the paper concluded in Section 6.

In this section we explained private and public dataset description, preprocessing, RT, EMD, feature extraction, feature ranking and classification.

Proposed method is evaluated using both private and two public datasets namely Automated Retinal Image Analysis (ARIA) and STructured Analysis of the Retina (STARE). A brief description of the database is given below.
                           
                              i.
                              
                                 
                                    Private dataset:
                                  images were collected from Department of Ophthalmology, Kasturba Medical College, Manipal, India. The normal (n
                                 =270) and AMD (n
                                 =270) images were captured using Zeiss FF450 plus mydriatic fundus camera using 50° Field of View (FOV). Patient’s consent was taken to use the images for research purpose. Clinical experts reviewed the acquired images and graded as early AMD, intermediate AMD and late AMD (see Fig. 3
                                 ) using Age-Related Eye Disease Study (AREDS) classification. These images were stored in 24bit rate format and 
                                    
                                       480
                                       ×
                                       364
                                    
                                 
                                 pixel resolution.


                                 
                                    ARIA dataset:
                                  images were collected from St. Pauls Eye Unit and University of Liverpool, UK. Fundus images of normal (n
                                 =101) and AMD (n
                                 =60) were captured using Zeiss FF450+ fundus camera using 50° FOV. The acquired images were stored using 24bit rate format with 
                                    
                                       768
                                       ×
                                       576
                                    
                                 
                                 pixel resolution. ARIA dataset images are available in the following link: http://www.eyecharity.com/aria_online.


                                 
                                    STARE dataset:
                                  images were collected from the Shiley Eye Centre, University of California and Veterans Administration Medical Centre, USA. These images (normal=36 and AMD=47) were captured using TOPCON fundus camera using 35° FOV and stored with 24bit rate format. STARE dataset has 
                                    
                                       700
                                       ×
                                       605
                                    
                                 
                                 pixel resolution and it is available in the following link: http://www.ces.clemson.edu/∼ahoover/stare.

Fundus images of all three datasets (private, ARIA and STARE) are processed to enhance the contrast using CLAHE [36]. Generally, histogram equalization is used to enhance the contrast by stretching the most occurring intensities to produce the better contrast distribution in the image. However, histogram equalization enhances bright region into more bright and hence edges are not clearly visible [36]. CLAHE is used to overcome this problem. CLAHE separates the images into different regions and do the Adaptive Histogram Equalization (AHE) on each region. Hence, each region pixel intensities maps into new pixel intensity values which is proportional to the rank of the each region intensity histograms [36]. This method enhances the normal structures of the retinal images namely OD, macula, blood vessels and abnormal lesions (drusen, GA and CNV).

RT is a mathematical approach developed by Johann Karl August Radon [42]. The basic principle of RT is line parametrization and it is widely used in various applications like computer vision, seismic data processing, radar imaging, geophysics, non-destructive testing and medical image processing [43]. In this work, the contrast enhanced green channel fundus image intensity is projected along a radial line at a specific angle [44] using RT. It captures the directional features of an image using series of line integrals at different angles from the centre of an image [44]. In this work, RT is performed to generate 1D projections of 2D image intensity for every step size (theta) of 5° [7]. RT of a 2D image 
                           
                              f
                              (
                              x
                              ,
                              y
                              )
                           
                         in 
                           
                              (
                              r
                              ,
                              θ
                              )
                           
                         plane is computed using the following equation:
                           
                              (1)
                              
                                 
                                    R
                                    (
                                    r
                                    ,
                                    θ
                                    )
                                    =
                                    
                                       
                                          ∬
                                       
                                       
                                          -
                                          ∞
                                       
                                       
                                          ∞
                                       
                                    
                                    f
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    δ
                                    (
                                    r
                                    -
                                    x
                                    cos
                                    θ
                                    -
                                    y
                                    sin
                                    θ
                                    )
                                    dxdy
                                 
                              
                           
                        where r is the perpendicular distance of a line integral from the centre, 
                           
                              θ
                           
                         is the angle formed by the distance vector, 
                           
                              δ
                              (
                              r
                              )
                           
                         is the Dirac function [44] and 
                           
                              δ
                              (
                              x
                              cos
                              θ
                              +
                              y
                              sin
                              θ
                              )
                           
                         denotes the line integration function of 
                           
                              f
                              (
                              x
                              ,
                              y
                              )
                           
                         
                        [7,44] and defined using
                           
                              (2)
                              
                                 
                                    r
                                    -
                                    x
                                    cos
                                    θ
                                    -
                                    y
                                    sin
                                    θ
                                    =
                                    0
                                 
                              
                           
                        
                     


                        Fig. 4
                        a shows the illustration of RT computation and Fig. 4b is the result of RT for an angles 
                           
                              θ
                              =
                              {
                              
                                 
                                    0
                                 
                                 
                                    ∘
                                 
                              
                              ,
                              
                                 
                                    5
                                 
                                 
                                    ∘
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    175
                                 
                                 
                                    ∘
                                 
                              
                              }
                           
                        .

The EMD [29] is a data driven method which performs multi-scale decomposition and time–frequency analysis of nonlinear and non-stationary signals [29]. Using this method original signal is modulated into amplitude and frequency components called IMFs [45]. The IMF of a given signal depends on the signal local characteristics like scale and time. The condition for the IMF is given below [29,30,34,46]:
                           
                              (a)
                              Each IMF should have the same number of extrema (maxima and minima) and zero-crossings or differ at most by one.

The mean value of the two envelops corresponding to local maxima and minima should be zero.

For a given signal (1D Radon projection of either normal or AMD fundus image) 
                           
                              x
                              [
                              t
                              ]
                           
                        , the EMD generates a set of IMFs and a monotonic residue signal and is given below:
                           
                              (3)
                              
                                 
                                    x
                                    [
                                    t
                                    ]
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             N
                                          
                                       
                                    
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    t
                                    )
                                    +
                                    r
                                    (
                                    t
                                    )
                                 
                              
                           
                        where 
                           
                              
                                 
                                    {
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    [
                                    t
                                    ]
                                    }
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    N
                                 
                              
                           
                         is a set of IMFs and 
                           
                              r
                              (
                              t
                              )
                           
                         is the residue signal. These IMFs can be extracted using sifting algorithm. The first IMF of a signal 
                           
                              
                                 
                                    x
                                 
                                 
                                    ̃
                                 
                              
                              (
                              t
                              )
                           
                         can be computed as follow [29].
                           
                              (i)
                              Let 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             ̃
                                          
                                       
                                       (
                                       t
                                       )
                                       ≔
                                       x
                                       (
                                       t
                                       )
                                    
                                 .

Detect the all local maxima and minima of signal 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             ̃
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                 .

Lower signal envelope 
                                    
                                       
                                          
                                             e
                                          
                                          
                                             min
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                  and upper signal envelope 
                                    
                                       
                                          
                                             e
                                          
                                          
                                             max
                                          
                                       
                                       (
                                       t
                                       )
                                    
                                  are obtained by interpolating minima and maxima using cubic spline interpolation.

Calculate the local mean 
                                    
                                       m
                                       (
                                       t
                                       )
                                       =
                                       [
                                       
                                          
                                             e
                                          
                                          
                                             min
                                          
                                       
                                       (
                                       t
                                       )
                                       +
                                       
                                          
                                             e
                                          
                                          
                                             max
                                          
                                       
                                       (
                                       t
                                       )
                                       ]
                                       /
                                       2
                                    
                                 .

Amplitude and frequency modulated oscillatory mode 
                                    
                                       s
                                       (
                                       t
                                       )
                                       =
                                       
                                          
                                             x
                                          
                                          
                                             ̃
                                          
                                       
                                       (
                                       t
                                       )
                                       -
                                       m
                                       (
                                       t
                                       )
                                    
                                  is obtained by subtracting the mean from the original signal.

Let 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             ̃
                                          
                                       
                                       (
                                       t
                                       )
                                       ≔
                                       s
                                       (
                                       t
                                       )
                                    
                                  and go to step (ii) and repeat the process until 
                                    
                                       s
                                       (
                                       t
                                       )
                                    
                                  satisfies the conditions of an IMF.

Once the first IMF is derived, to obtain the successive IMFs, the steps (ii)–(vi) is repeated recursively to the residue signal 
                           
                              r
                              (
                              t
                              )
                              =
                              x
                              (
                              t
                              )
                              -
                              s
                              (
                              t
                              )
                           
                         until the residue signal 
                           
                              r
                              (
                              t
                              )
                           
                         becomes a monotonic function where any more IMFs can be extracted.

This amplitude and instantaneous frequency combination used for time–frequency analysis [46]. The first three IMFs of 1D Radon transformed normal (see Fig. 5
                        a and b) and AMD (see Fig. 5c and d) fundus images are shown in Fig. 5e–h.

The AMD lesions (GA, CNV and drusen) change the spatial orientation and colour intensity in digital fundus images. These nonlinear pixel changes quantified using EMD are reflected in IMFs (see Fig. 5g and h). Moreover, nonlinear changes can be appropriately captured using nonlinear feature extraction methods like Energy, Fractal Dimension (FD), Largest Lyapunov Exponent (LLE), Recurrence Rate (RR), Determinism (DET), Mean diagonal line length (〈L〉), Longest diagonal line (
                           
                              
                                 
                                    L
                                 
                                 
                                    max
                                 
                              
                           
                        ), Entropy, Laminarity (LAM), Trapping Time (TT), Longest vertical line (
                           
                              
                                 
                                    V
                                 
                                 
                                    max
                                 
                              
                           
                        ), Recurrence times of 1st pointcare recurrence points (T1), Recurrence times of 2nd pointcare recurrence points (T2), Recurrence (REC), Trend, Sample Entropy (SE) and Tsallis Entropy (TE). These features are used for various other applications namely epilepsy detection [47–49], power signal analysis [50], sleep stages [51] classification and nonlinear system dynamics [52] have yielded excellent results. Hence, in this work we have used various nonlinear feature extraction techniques on first three IMFs.

Energy is used to compute the amount of information present in each IMFs. FD [51] is used to compute the self-similarity of IMFs at different scales which quantifies the roughness present in the IMFs. Lyapunov exponent is used to quantify sensitivity of the system to initial conditions, if LLE value is high which indicates more pixel variations in the fundus image due to AMD lesions [47]. Recurrence Quantification Analysis (RQA) is used to identify the number of recurrence and duration of recurrences of a signal in state space trajectory [52]. Various non-linear RQA features namely RR, DET, 〈L〉, 
                           
                              
                                 
                                    L
                                 
                                 
                                    max
                                 
                              
                           
                        , Entropy, LAM, TT, 
                           
                              
                                 
                                    V
                                 
                                 
                                    max
                                 
                              
                           
                        , T1, T2, REC, Trend [48] all are extracted from first three IMFs. SE measures the regularity of the given data where high values of SE indicates that the data is irregular and vice versa [49]. TE is a generalized version of Shannon entropy and derived using Boltzmann–Gibbs statistics [50]. It has ability to explain complexity of non-additive systems [50]. These nonlinear features quantify the subtle pixel changes in the normal and AMD fundus images.

Higher Order Spectra (HOS) is also known as polyspectra which are nothing but spectral representations of the higher order moments or cumulants of a given signal [53,54]. This work computes the 3rd order polyspectrum or bispectrum from the normal and AMD fundus images and subsequently bispectral entropies namely phase entropy (
                              
                                 
                                    
                                       P
                                    
                                    
                                       E
                                    
                                 
                              
                           ), normalized bispectral entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       1
                                    
                                 
                              
                           ), normalized bispectral squared entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       2
                                    
                                 
                              
                           ) and normalized bispectral cubed entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       3
                                    
                                 
                              
                           ) are computed from the bispectrum. The bispectrum (3rd order correlation) of a given signal is computed using the following equation [53,54]:
                              
                                 (4)
                                 
                                    
                                       B
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             f
                                          
                                          
                                             2
                                          
                                       
                                       )
                                       =
                                       E
                                       [
                                       X
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             1
                                          
                                       
                                       )
                                       X
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             2
                                          
                                       
                                       )
                                       
                                          
                                             X
                                          
                                          
                                             ∗
                                          
                                       
                                       (
                                       
                                          
                                             f
                                          
                                          
                                             1
                                          
                                       
                                       +
                                       
                                          
                                             f
                                          
                                          
                                             2
                                          
                                       
                                       )
                                       ]
                                    
                                 
                              
                           where 
                              
                                 X
                                 (
                                 f
                                 )
                              
                            is the Fourier transform of a given signal 
                              
                                 x
                                 (
                                 nT
                                 )
                              
                            and approximated using fast Fourier transform, 
                              
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                              
                            are frequency components of a signal and varies from 0 to 1 and normalized using Nyquist criteria, 
                              
                                 E
                                 [
                                 ·
                                 ]
                              
                            is expectation operation [54]. The bispectrum of a real signal can be represented using unique triangle 
                              
                                 0
                                 ⩽
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                                 ⩽
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                                 ⩽
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                                 +
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                                 ⩽
                                 1
                              
                           . The bispectrum features are extracted by integrating the bifrequency space and line of integration in the non-redundant region [54]. The first three IMFs are used to compute HOS bispectrum. Further, phase entropy (
                              
                                 
                                    
                                       P
                                    
                                    
                                       E
                                    
                                 
                              
                           ), normalized bispectral entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       1
                                    
                                 
                              
                           ), normalized bispectral squared entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       2
                                    
                                 
                              
                           ) and normalized bispectral cubed entropy (
                              
                                 
                                    
                                       E
                                    
                                    
                                       3
                                    
                                 
                              
                           ) are derived from the bispectrum [54]. The extracted entropies quantify the variations present in the pixels of normal and AMD fundus images.

From each IMF 21 nonlinear features are extracted, there are three IMFs and 36 RT projection angles (
                              
                                 0
                                 °
                                 ,
                                 5
                                 °
                                 ,
                                 10
                                 °
                                 ,
                                 …
                                 ,
                                 175
                                 °
                              
                           ) resulting in 2268 features. Then the dimension of the extracted features are reduced using LSDA method.

Linear Discriminant Analysis (LDA) is one of the popular feature reduction technique and helps to analyse the relationship between data points and classes [37]. However, it fails to identify the local geometry of the data points when the number of training sample is small. LSDA significantly identifies the local geometry of the data even when the training samples are less [37]. Since, ARIA and STARE are small databases, LSDA can be useful to reduce the features dimension.

Considering N training samples 
                           
                              
                                 
                                    x
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    N
                                 
                              
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    q
                                 
                              
                           
                         are sampled from the submanifold M 
                        [55]. In LSDA within-class variance is constructed using the vertex set 
                           
                              X
                              =
                              
                                 
                                    x
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    2
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                 
                                 
                                    N
                                 
                              
                           
                         and within-class weight matrix 
                           
                              
                                 
                                    W
                                 
                                 
                                    m
                                 
                              
                           
                         can be defined as
                           
                              
                                 
                                    
                                       
                                          W
                                       
                                       
                                          ij
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      1
                                                      ,
                                                   
                                                   
                                                      if
                                                      
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      ∈
                                                      N
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      )
                                                      
                                                      or
                                                      
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ∈
                                                      N
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      )
                                                   
                                                
                                                
                                                   
                                                      0
                                                      ,
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              N
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              )
                           
                         is the set of points which are k-Nearest Neighbour (k-NN) of 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         and has the same label of 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         
                        [55].

Within-class compactness (
                           
                              
                                 
                                    G
                                 
                                 
                                    w
                                 
                              
                           
                        ) and between-class separability (
                           
                              
                                 
                                    G
                                 
                                 
                                    b
                                 
                              
                           
                        ) of LSDA [55] can be computed using following equations
                           
                              (5)
                              
                                 
                                    
                                       
                                          G
                                       
                                       
                                          w
                                       
                                    
                                    =
                                    
                                       
                                          
                                             min
                                          
                                          
                                             y
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             ij
                                          
                                       
                                    
                                    
                                       
                                          (
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          W
                                       
                                       
                                          w
                                          ,
                                          ij
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       
                                          G
                                       
                                       
                                          b
                                       
                                    
                                    =
                                    
                                       
                                          
                                             max
                                          
                                          
                                             y
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             ij
                                          
                                       
                                    
                                    
                                       
                                          (
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                          -
                                          
                                             
                                                y
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          W
                                       
                                       
                                          b
                                          ,
                                          ij
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    α
                                 
                                 
                                    T
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                              =
                              
                                 
                                    α
                                 
                                 
                                    T
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                           
                         is 1D mapping of 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              ,
                              α
                           
                         is the projection direction [55]. Applying such method 2268 features are reduced to 30 LSDA components. The dimension of the reduced LSDA components can be chosen manually. In this work, we have chosen 30 which provided maximum classification performance. Further, these LSDA components are ranked using various ranking techniques namely mRMR, KLD and CBBD which are briefly explained as on below.

Feature selection process is used to identify the most significant subset of the original features to reduce the classification error [56]. In this work, we have used mRMR, KLD and CBBD techniques to rank the features.

Maximum relevance in mRMR method searches the features where the mutual information between independent feature and target is maximum, similarly minimum redundancy is used to identify the features that are mutually maximally distinct [38]. These two criterion’s are combined in mRMR to avoid the correlated and redundant features [38]. Mutual information between the features is computed using fuzzy entropy [57]. KLD is a distance function which compares entropy of two density distributions without prior assumptions [39]. In this work, KLD compares two feature distributions by computing entropy between the features, if the relative entropy value of a feature is high then that particular feature is considered as most significant [39] in discriminating normal and AMD classes. CBBD selects the best possible features assuming that features are normally distributed [40]. Chernoff bound on tail distributions with independent random variables gives exponential decay [40]. Hence, Chernoff bound combined with Bhattacharyya distance is used to perform feature selection. Further, these three methods are used to rank the features according to their significance and ranked features are fed to SVM classifier.

Automated classification of AMD is carried out using SVM classifier with various kernel functions namely linear, quadratic, polynomial and RBF. SVM is used to construct the decision planes (hyperplanes) to separate the two classes. It follows the concept of structural risk minimization [41]. SVM can be used for linearly and nonlinearly separable datasets [41]. Various kernel functions namely quadratic, polynomial and RBF are used to project the non-linearly separable data into an higher dimensional feature space where the features are linearly separable [40]. In this work sigma of the kernel function is varied in steps (
                        
                           σ
                           =
                           0.1
                           ,
                           0.2
                           ,
                           0.3
                           ,
                           …
                           ,
                           5
                        
                     ) to obtain the highest classification performance using Bootstrap method [58].

@&#RESULTS@&#

One dimensional RT projections of normal and AMD images from three datasets generate minimum three IMFs. Since, IMFs are arranged as high frequency to low frequency components are shown in Fig. 5. IMFs extracted from normal images have high variations as indicated in IMF 1, IMF 2 and IMF 3 (see Fig. 5e and f) due to continuous pixel variations of various anatomical structures. In case of AMD images the IMF 1, IMF 2 and IMF 3 have low variations (see Fig. 5g and h) due to the presence of GA and CNV in the AMD images. Each IMF is used to extract 21 nonlinear features (refer Section 2.5) for every 
                        
                           5
                           °
                        
                      of RT projections. Table 3
                      shows features of IMF1 at 
                        
                           0
                           °
                        
                      of RT projection for normal and AMD classes of all three datasets. Similarly 2268 features are extracted for first three IMF (see Fig. 5e–h) for 36 angles of RT projections.

Most of the nonlinear features show (see Table 3) high value for AMD and low value for normal class. In private database, the LLE, Entropy, SE, TE, 
                        
                           
                              
                                 E
                              
                              
                                 1
                              
                           
                           ,
                           
                              
                                 E
                              
                              
                                 2
                              
                           
                        
                      and 
                        
                           
                              
                                 E
                              
                              
                                 3
                              
                           
                        
                      are high for AMD and low for normal class. These entropies quantify the randomness associated with image pixels. The high entropy values for AMD class reports that variation in the pixels of AMD image which may be due to the presence of abnormal lesions namely drusen, GA and CNV.

The dimensionality of the extracted features are high, hence LSDA is used to reduce the feature dimension. LSDA reduces the 2268 original features into 30 LSDA components. Further, reduced features (LSDA components) are ranked using mRMR, KLD and CBBD ranking methods.


                     Fig. 6
                      shows the plot of ranked features versus divergence value of KLD (see Fig. 6a and c) and CBBD (see Fig. 6b). Feature ranking methods rank the features as per the criterion value (i.e. mutual information, divergence and Chernoff bound) of the particular method. Further, ranked optimum features provided the maximum classifier performance (see Tables 4–6
                     
                     
                     ) for three datasets. KLD and CBBD methods for private and ARIA datasets revealed that first 10 ranked LSDA components are most significant as per the divergence and Chernoff bound value respectively (see Fig. 6a and b). However, KLD for STARE dataset shows that first nine ranked LSDA components are highly significant (see Fig. 6c) according to the divergence value.

Kernel density estimation [59] is performed on significant ranked LSDA components to verify the discrimination ability of LSDA components for normal and AMD classes. Probability density estimation plots (see Figs. 7
                     a, 8a and 9a) reveal that LSDA3, LSDA6 and LSDA2 have less overlapping zone for private, ARIA and STARE datasets respectively. Moreover, boxplots (see Figs. 7b, 8b and 9b) of LSDA2, LSDA4 and LSDA3 show that the median of each LSDA component is significantly different for normal and AMD class for private, ARIA and STARE datasets respectively. These plots (Figs. 7–9
                     
                     ) confirm that extracted LSDA components are statistically significant (
                        
                           p
                           <
                           0.0001
                        
                     ). Further, the ranked LSDA components are fed to SVM classifier to discriminate normal (see Fig. 5a and b) and AMD (see Fig. 5c and d) classes. The performance measures such as accuracy, sensitivity and specificity is computed over 10-fold cross validation.

Average performance measures of different classifiers for private, ARIA and STARE datasets using mRMR, KLD and CBBD are shown in Tables 4–6. The results in Table 4 using private dataset illustrates that first five KLD ranked LSDA components integrated with SVM-RBF kernel obtained a highest average accuracy of 91.67%, sensitivity of 90.74%, specificity of 92.59% and AUC of 0.92 (see Fig. 11a). Similarly, CBBD provided ten ranked LSDA components and yielded highest average accuracy of 91.67%, sensitivity of 87.41% and specificity of 95.93% using SVM-RBF kernel. Moreover, mRMR ranking method provided 30 LSDA features and achieved average accuracy of 85.93%, sensitivity of 88.15% and specificity of 83.70% using SVM-RBF kernel, but this performance measure is less compared to KLD and CBBD ranking methods.


                     Table 5 represents the results of ARIA dataset. It shows that, first four CBBD ranked LSDA components coupled with SVM-RBF provided an highest average accuracy of 85.09%, sensitivity of 86.14%, specificity of 83.33% and AUC of 0.85 (see Fig. 11b). Likewise, first ten KLD ranked LSDA components obtained an highest average accuracy of 84.47%, sensitivity of 84.16% and specificity of 85%. Whereas, SVM-Polynomial (SVM-P) used 30 LSDA components to achieve average accuracy of 76.40%, sensitivity of 88.12% and specificity of 13.36% using mRMR ranking method. It is significantly less compared to KLD and CBBD ranking methods.

STARE dataset results are shown in Table 6 and it reveals that SVM-RBF classifiers use only two and three KLD and CBBD ranked LSDA components and yielded the best average accuracy, sensitivity, specificity of 100% and AUC of 1 (see Fig. 11c). However, the same classifier uses 30 mRMR ranked LSDA components to obtain an average accuracy of 95.18%, sensitivity of 93.62% and specificity of 97.22%.

The best performance of different kernels of SVM classifier and ranking methods for private, ARIA and STARE datasets are shown in Fig. 10
                     a–c. Number of features versus average accuracy for private dataset is shown in Fig. 10a. It reveals that KLD and CBBD ranking method yielded an average classification accuracy of 91.67% using five and ten optimum LSDA components. Since, KLD and SVM-RBF combination obtained an highest average accuracy of 91.67% and AUC of 0.92 (see Fig. 11
                     a) using only five LSDA components, it is considered as best ranking and classifier combination for private dataset. Fig. 10b reveals that CBBD and SVM-RBF fusion obtained an highest classification accuracy of 85.09% and AUC of 0.85 (see Fig. 11b) using four optimum LSDA components. Hence, CBBD and SVM-RBF pairing is considered as the best combination for ARIA dataset. Finally, KLD and CBBD ranking method yielded a highest average classification accuracy of 100% and AUC of 1 (see Fig. 11c) using two and three optimum LSDA components with SVM-RBF classifier. Moreover, SVM-L obtained an highest average classification accuracy of 100% using two optimum LSDA components (see Table 6). However, KLD and SVM-RBF combination provided highest average classification accuracy consistently using only two optimum LSDA components (see Fig. 10c). Hence KLD and SVM-RBF ranking and classifier pairing is considered as best combination for STARE dataset. The variations in the accuracy may be due to different resolution of private (Resolution: 480×360), ARIA (Resolution: 768×768) and STARE (Resolution: 700×605) datasets. Also, the presence of abnormal lesions are different for three datasets.

In this work, we have evaluated the performance by combining the three datasets: (i) Private, (ii) ARIA and (iii) STARE with all images resized to 480×360 resolution. We have obtained highest classification accuracy of 84.06%, sensitivity of 82.30% and specificity of 86.07% for combined dataset (private, ARIA and STARE) using CBBD and SVM-RBF combination. However, the performance measures are not high as compared to individual datasets (see Tables 4–6). The reason being that private, ARIA and STARE datasets have different resolution. Hence, the proposed approach is valid when resolution of the images are uniform and that is the limitation of this work.

@&#DISCUSSION@&#

Routine eye examination may help to identify various eye diseases like cataract, Diabetic Retinopathy (DR), glaucoma and AMD at an early stage. Fundus imaging is economical compared to Optical Coherence Tomography (OCT). Automated fundus image analysis may help clinicians to expedite the mass screening of eye diseases [60–62]. Hence, in this work, we have used EMD to quantify bright (OD, drusen, GA) and dark regions (macula, blood vessels and CNV) of fundus images which may be reflected in high and low frequency signal components. EMD has several advantages, it helps to identify intrinsic patterns at different scales and ensures time–frequency accuracy at instantaneous frequency level. Moreover, due to property of integrity, it can be used for data fusion studies [63]. LSDA keeps the intrinsic and discrimination nature of data by pairing the local and global geometric structures of data [55] to obtain better discrimination of normal and AMD classes.

Our EMD-based feature extraction, LSDA-based feature reduction and KLD & CBBD ranking methods reported the highest classification performance (see Table 6 and Fig. 10c). The proposed system obtained a highest classification accuracy of 91.67%, 85.09% and 100% for private, ARIA and STARE dataset using only five, four, two (see Fig. 10a–c) KLD and CBBD ranked LSDA components and SVM-RBF classifier respectively. Density estimation plots show (see Fig. 7a, 8a and 9a) that the features are well separated to discriminate normal and AMD classes. LSDA2 has very less overlapping in density estimation plot (see Fig. 9a), which resulted in the highest classification accuracy, sensitivity and specificity of 100% respectively using only two optimum LSDA components (see Table 6 and Fig. 10c) for STARE database. Number of LSDA components used to get highest classification performance for each dataset is different (see Fig. 10a–c), the reason may be that the energy in the LSDA component corresponding to the abnormal lesions like drusen, GA and CNV are different for each dataset. However, results in this work suggests that KLD ranking method and SVM-RBF classifier combination is the best one in discriminating normal and AMD images.

The proposed work is compared with the existing literatures [5,7,21−28] for automated AMD detection using fundus images. These literatures are briefly discussed in Section 1. In this list, literatures [5,22–24] used private dataset and [21,25–27] used public domain datasets namely ARIA and STARE and [7,28] used both private and public datasets for their proposed system evaluation.

Agurto et al. [24] have used AM–FM based feature extraction approach for AMD detection. However, their system is evaluated with private dataset using 507 fundus images. Hijazi et al. [21,25] proposed DTW, spatial histogram and hierarchical decomposition techniques for automated diagnosis of AMD using ARIA database. They have used 1262 features and obtained an accuracy of 100%. Hierarchical decomposition and weighted frequent sub-graph mining are used in [26] to discriminate normal and AMD classes. Their method used ARIA and STARE and utilized 1000 features to yield 99.6% accuracy. Texture features and data mining techniques are used in [27] to classify Non-AMD and AMD classes with an accuracy of 99.6% with 50–400 features and ARIA and STARE datasets. Mookiah et al. [5] used DWT features to discriminate normal and AMD fundus images and reported an accuracy of 93.70% using 121 features. However, their method is evaluated only in private dataset. Similarly, texture and higher order statistics are used in [7] for AMD diagnosis and their method obtained an accuracy of 95.07% using 54 features. Recently, same group proposed local configuration pattern based feature extraction technique for AMD detection and obtained an accuracy of 97.78% using 22 features [28]. In this proposed EMD-based technique only two LSDA components are used to discriminate normal and AMD images and reported an accuracy, sensitivity and specificity of 100% and AUC of 1 (see Fig. 11c) for STARE dataset. The summary of automated AMD detection is presented in Table 7
                     .

Unique characteristics of the proposed work is summarized as follows:
                        
                           •
                           Obtained the highest performance of 100% average accuracy, 100% sensitivity, and 100% specificity.

The morphological features of fundus image namely OD and blood vessel need to be segmented and removed [21,24−27] prior to feature extraction. In this study and Refs. [5,7,28] do not perform any segmentation.

The present study uses only two features to achieve the highest average (10-fold) accuracy of 100% and AUC of 1 (see Fig. 11c) for STARE dataset (see Table 6). However, previous works [5,7,21,26–28] used 1262, 1000, 50–400, 121, 54 and 22 features and reported an accuracy of 100%, 99.6%, 99.6%, 93.70%, 95.07% and 97.78% (see Table 7) respectively.

This study uses EMD and nonlinear features to quantify the pixel variations in the fundus images and reported highest sensitivity and specificity of 100% (see Table 6) respectively for STARE dataset.

The current study is evaluated using three databases: private, ARIA and STARE. Hence, the reported results are reliable and reproducible.

The proposed system (see Tables 4–6) used Intel i7-4770 3.47GHz processor, 16GB 1600MHz CL9 DDR3-RAM and MATLAB 2012b package. The time taken for feature extraction is 78665; 60998; 9496s and classification is (Training: 0.7829, Testing: 0.0013)s; (Training: 0.2664, Testing: 0.0013)s; (Training: 0.2307, Testing: 0.0013)s for entire private, ARIA and STARE datasets respectively.

This study uses early, intermediate and late AMD images from private and two public datasets namely ARIA and STARE for automated screening of AMD. The extremity of lesions in private, ARIA and STARE datasets varies significantly, which may overestimate the real life performance of the system. The presence of lesions in STARE dataset is large as compared to private and ARIA dataset, hence STARE dataset (see Table 6) provides highest classification performance compared to private (see Table 4) and ARIA (see Table 5) dataset. However, in the real life scenario anyone with wet or late AMD can have the symptom of blurred vision and diagnosed accurately. Hence, in the future work, telescreening or screening system involving only normal and early AMD images, which do not have any visual symptoms, if captured during routine screening will significantly aid the clinicians.

@&#CONCLUSION@&#

It is strenuous and time-consuming for the clinicians to diagnose the AMD. Hence, in this study we propose an automated AMD detection approach using EMD coupled with other nonlinear features which can identify the pixel variations due to the presence of drusen, GA and CNV in AMD fundus image. Our results show that, LSDA coupled with KLD and CBBD are able to produce highest classification accuracy of 91.67%, 85.09% and 100% using five, four and two LSDA components and SVM-RBF classifier for private, ARIA and STARE datasets respectively. The feature extraction, training and testing time of the proposed method for single image is significantly less. Hence, our proposed system can be used as AMD screening tool and can be used in polyclinics and hospitals for mass screening. Further, system performance can be improved by integrating morphological and texture features. Also, such a proposed system can be extended for other eye diseases like, glaucoma, maculopathy, DR, dry eye and other type of similar diagnosis.

The authors do not have any related conflict of interest.

@&#ACKNOWLEDGEMENTS@&#

Authors thank Social Innovation Research Fund (SIRF/Project Code: T1202), Singapore for providing grant for this research. Also authors would like to acknowledge Head of Department and all staff members of Department of Ophthalmology, Kasturba Medical College, Manipal, India for sharing the images for this study.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Extended modeling procedure based on the projected sample for forecasting short-term electricity consumption

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Forecasting electricity consumption plays a vital role for policy makers.


                        
                        
                           
                           Short-term predictions using new limited data for managers are important.


                        
                        
                           
                           The proposed modeling procedure can extract hidden information for knowledge learning.


                        
                        
                           
                           The proposed method is an appropriate tool for forecasting short-term consumption.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Forecasting

Small data set

Latent information

Electricity consumption

@&#ABSTRACT@&#


               
               
                  Effectively forecasting the overall electricity consumption is vital for policy makers in rapidly developing countries. It can provide guidelines for planning electricity systems. However, common forecasting techniques based on large historical data sets are not applicable to these countries because their economic growth is high and unsteady; therefore, an accurate forecasting technique using limited samples is crucial. To solve this problem, this study proposes a novel modeling procedure. First, the latent information function is adopted to analyze data features and acquire hidden information from collected observations. Next, the projected sample generation is developed to extend the original data set for improving the forecasting performance of back propagation neural networks. The effectiveness of the proposed approach is estimated using three cases. The experimental results show that the proposed modeling procedure can provide valuable information for constructing a robust model, which yields precise predictions with the limited time series data. The proposed modeling procedure is useful for small time series forecasting.
               
            

@&#INTRODUCTION@&#

Energy is a vital strategic resource that affects the national economy and social development [1]. Economic growth and industrialization rapidly increase energy consumption and production. Therefore, a nation’s energy policy is crucial, because it not only guides the development of a country but also affects the operating environment of various industries [2]. Electricity is a form of energy that is arduous to store [3], and considerable evidence supports a causal relationship between economic growth and electricity consumption [4].

Because of the large amount of capital investment and lengthy construction time required in electricity systems expansion planning, an incorrect direction of development causes a dramatic effect. To advance the economic growth and fulfill future power requirements, forecasting electricity consumption effectively is essential. However, effective forecasting has become a challenge to overcome. Therefore, forecasting the future electricity consumption correctly and scientifically to manage power systems is crucial [5].

Several methods have been used to forecast electricity consumption over the last few decades [6–10]. These forecasting methods can be approximately classified into three categories: causal models, time series analysis, and artificial intelligence approaches. Causal models probe the relationships among multiple variables and assume that the variations in dependent variables can be explained by independent variables; specifically, historical data are used to establish a multivariate model for dependent variable forecasting [11]. The forecasting accuracy of a causal model depends on the selection of independent variables. If the selected independent variables cannot effectively explain the variation in the dependent variables, an inaccurate forecast is produced.

Time series models include linear regression and autoregressive integrated moving average analysis. Time series models require only historical observations to construct a model for forecasting the development of data trends [12] and are commonly used in forecasting energy demand. However, they require high quantities of samples for accurate forecasting.

Artificial intelligence approaches include data mining techniques, artificial neural networks, and heuristic algorithms. They are often used to solve forecasting problems and attain extremely high forecasting performance [13]. However, the forecasting results depend on the number of training samples and their representativeness; these modeling restrictions must to be overcome.

In all the aforementioned methods, the sample size is a key element that affects the forecasting performance and limits the applicability of the forecasting approach to certain situations; forecasting the energy demand in rapidly developing countries is a positive example of it. Although it can collect a large amount of historical observations, they usually deviate considerably from the real increasing trend in electricity consumption. Because electricity consumption typically exhibits an exponential trend, common forecasting methods using large quantities of historical data, such as basic time series approaches, are unsuitable [14]. Therefore, it is beneficial to develop a new modeling procedure by using small data sets for forecasting the electricity consumption.

The difficulty of small-data-set learning tasks is due to the limited samples being unable to completely reflect all characteristics of a population [15]. To overcome this particular forecasting problem, some studies have adopted virtual sample generation (VSG) techniques to enhance the learning stability for constructing robust and exact models [16–20]. These VSG approaches have been used in many fields, such as manufacturing, engineering, and medicine [21–24]. However, the process of generating artificial samples usually does not consider the relationship among dependent attributes, limiting its usefulness. Time series data constitute one typical example of dependent attribute data. In such data, correlations exist between the developing trends of observations and the order of observations. Hence, VSG is not applicable to time series data; the generated virtual samples cannot effectively improve the modeling performance because the relationship between a datum and time is not considered.

For solving this learning problem, this study proposes a procedure that involves first employing the latent information (LI) function proposed by Chang et al. [25] for analyzing data to extract the concealed information. Next, we develop the projected sample generation for combining the LI values and original data to extend the data set and thus enhance the forecasting accuracy of a back propagation neural network (BPNN).

The main purpose of the projected samples is to provide additional information for enhancing the learning stability. VSG techniques improve the learning performance by extending the sample size. Their similarity between the projected samples and VSG is that they increase the information input in the learning process; however, the difference is the type of information input. The sample pattern generated using VSG is the same as that of the original sample, whereas that of the projected sample is different. To increase the information input, the projected sample generation changes the dimension of the independent variable.

To verify the effectiveness of the proposed approach, this study first used electricity consumption data collected from the Asia–Pacific Economic Cooperation (APEC) energy database. Moreover, two additional cases, data on the wafer-level packaging (WLP) process and monthly demand for thin film transistor liquid crystal display (TFT-LCD) panels, were examined to further verify the performance of the proposed approach. The experimental results showed that the proposed modeling procedure based on the LI function is an appropriate technique for small-data-set forecasts because of its ability to provide valuable information and precise forecasts with limited time series data.

The remainder of this paper is organized as follows. The LI function, projected sample generation, and modeling procedure are introduced in Section 2. Section 3 provides comparisons among forecasting methods. Finally, the conclusion is presented in Section 4.

@&#METHODOLOGY@&#

The learning procedure of a forecasting model is ineffective when the sample size is small because it provides insufficient information. Therefore, this study developed a novel modeling procedure, called projected sample generation, to enhance the short-term forecasting performance with limited time series data. The concept and implementation of the proposed approach are described in this section.

Previous studies have reported that increasing the information content enables obtaining a sufficient sample for effective learning and thus attaining a more stable forecasting result. Therefore, this study employed the LI function for analyzing data behavior and extracting hidden information to facilitate discovering new knowledge by using small data sets.

The LI function was proposed by Chang et al. [25], and its main concept is to appropriately expand the margins of data by using four indices to fill the data gaps, where the extent of the range is determined by the sample size. Specifically, for a high number of observations, the data profile becomes clearer because of the high amount of information, and substantially extending the data range is not necessary. Conversely, if the information is insufficient, the extent of the range must be increased. The degree of extension can be determined using the range divided by the number of samples, and the ratio of leftward or rightward extension is determined according to the Skewness. The extended boundaries are called the upper bound (UB) and lower bound (LB), which are then combined with the central tendency (CT) to jointly construct the LI function. The range of the LI values lies between 0 and 1, representing the likelihood of occurrence of the potential data. The complete procedure for formulating the LI function is described as follows:
                           
                              1.
                              For an n-periods time series data set 
                                    
                                       X
                                       =
                                       {
                                       
                                          
                                             x
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       …
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             n
                                          
                                       
                                       }
                                    
                                 , let 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             min
                                          
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             max
                                          
                                       
                                    
                                  be the element in X with the minimal and maximal values, respectively. Then calculate the range R by using Eq. (1).


                        
                           
                              2.
                              Determine the CT using Eq. (2).


                        
                           
                              3.
                              Determine the central location (CL) of the existing data by using Eq. (3).


                        
                           
                              4.
                              Determine the number of elements in the subset comprising data with values greater than the CL and denote it by 
                                    
                                       |
                                       
                                          
                                             X
                                          
                                          
                                             +
                                          
                                       
                                       |
                                    
                                 ; determine the number of elements in the subset comprising data with values less than the CL and denote it by 
                                    
                                       |
                                       
                                          
                                             X
                                          
                                          
                                             -
                                          
                                       
                                       |
                                    
                                 .

Compute the increasing tendency (IT) and decreasing tendency (DT).


                        
                           
                              6.
                              Employ the IT and DT to asymmetrically expand the domain range. The extended UB and LB are determined by the following formulas.


                        
                           
                              7.
                              Use the CT, UB, and LB to form a triangular LI function, as shown in Fig. 1
                                 . Here we set the LI value of the CT to 1 and the LI values of the boundaries (UB and LB) to 0. Therefore, we can attain the LI values of the existing data through properties of similar triangles.

In a dynamic and unstable environment, more recent observations may provide more valuable information about system variation than less recent observations do; therefore, equally using less recent and more recent data does not facilitate updating the information. An alternative treatment is to unevenly repeat the more recent data to enhance their influence in the learning process. On the basis of this concept, we further analyzed the relatedness among the time series data to effectively employ the information in the obtained small samples. We assumed that the data trend depends on the time factor; therefore, any datum is influenced by all forward data. Fig. 2
                         illustrates this concept. The latest datum, x
                        5, is directly influenced by x
                        4, and x
                        1, x
                        2, or x
                        3 has an indirect relation with x
                        5. This relatedness among time series data provides additional useful information for knowledge discovery; therefore, we can integrate it with the LI function to modify the data set.

Because all relationships are crucial for learning, we let each relationship generate a training sample and then obtain an amplified new training set. This process is similar to the repeated sampling process in bootstrap methods; however, the sampling process is based on a subjective setting, and the generated training samples add an attribute named LI value.

Specifically, we add some samples for extending the data set to provide more information in the learning process. These artificial samples are called projected samples here because they are derived from the original data. We use the setting employed for the LI function to determine the number of learning samples. Table 1
                         presents the extended data set. Thus we can provide more samples with additional information compared with the original data set in Table 2
                         to improve small-data-set learning.

To solve the small data set forecasting problem, we developed a method based on the LI function to generate projected samples and applied these artificial samples to enhance the forecasting performance of the BPNN model by using the small data set. Specifically, we first use the LI function to determine the LI value of the obtained observations at each stage; the training and testing sets are then extended to improve the forecasting accuracy of the BPNN model. Fig. 3
                         depicts a flowchart of the proposed method, of which the modeling steps are detailed as follows:
                           
                              1.
                              Assume that we have five nonnegative time series data: 
                                    
                                       X
                                       =
                                       {
                                       
                                          
                                             x
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             2
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             3
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             4
                                          
                                       
                                       ,
                                       
                                          
                                             x
                                          
                                          
                                             5
                                          
                                       
                                       }
                                    
                                 .

Obtain the LI values of the existing data at all stages by Eqs. (1)–(6), that is, 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             i
                                          
                                       
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                       )
                                    
                                 , where 
                                    
                                       i
                                       =
                                       1
                                       ,
                                       2
                                       ,
                                       3
                                       ,
                                       4
                                       ,
                                       5
                                    
                                 , 
                                    
                                       j
                                       =
                                       1
                                       ,
                                       2
                                       ,
                                       3
                                       ,
                                       4
                                       ,
                                       5
                                    
                                 , and 
                                    
                                       j
                                       <
                                       i
                                    
                                 . 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             i
                                          
                                       
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                       )
                                    
                                  represents the LI value of the datum 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                    
                                  at the ith stage.

Construct the modified data set by using the projected samples.

Learn the network structure of the BPNN model by using the extended training set.

Input the independent variable to obtain five possible forecast outputs for 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             6
                                          
                                       
                                    
                                 , which are 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             -
                                             1
                                          
                                       
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             -
                                             2
                                          
                                       
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             -
                                             3
                                          
                                       
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             -
                                             4
                                          
                                       
                                    
                                 , and 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             -
                                             5
                                          
                                       
                                    
                                 .

Obtain the final forecast value for 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             6
                                          
                                       
                                    
                                  through the weighted average method.

@&#EXPERIMENTAL RESULTS@&#

We first use the APEC energy database to illustrate our modeling approach; next, two cases, data on the WLP process and TFT-LCD panel monthly demand, were examined to further verify the performance of the proposed approach. The data features, experimental design, and model parameter settings are described in the following subsections.

The APEC energy database
                           1
                           
                              http://www.ieej.or.jp/egeda/.
                        
                        
                           1
                         obtained from the Asia–Pacific Energy Research Center comprises information on the energy status of 21 Pacific Rim member economies. To ensure that the experimental analysis was relevant to the current status of energy development, only the 2000–2012 electricity consumption data of all members was used as raw data, as shown in Table 3
                        . Electricity is measured in kilotons of oil equivalent.

@&#EXPERIMENTAL DESIGN@&#

The purpose of this study was to construct forecasting models for forecasting the electricity consumption trends by using small data sets. We adopted the moving cross-validation scheme (Fig. 4
                        ) [26] to evaluate the effectiveness of the proposed approach. The electricity consumption value for 2005 was forecast using the 2000–2004 data that for 2006 was forecast using the 2001–2005 data, and so on. A total of 168 models and forecasts were obtained in the experiment on the APEC energy database.

The BPNN model is a commonly used forecasting tool because of its convenience; the learning tool adopted in this study was the Pythia software.
                           2
                           
                              http://www.runtime.org/pythia.htm.
                        
                        
                           2
                         We input four training samples for learning the network structure of the BPNN model, and each paired sample had one input and one output attribute as follows: 
                           
                              {
                              (
                              
                                 
                                    x
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    2
                                 
                              
                              )
                              ,
                              (
                              
                                 
                                    x
                                 
                                 
                                    2
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    3
                                 
                              
                              )
                              ,
                              (
                              
                                 
                                    x
                                 
                                 
                                    3
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    4
                                 
                              
                              )
                              ,
                              (
                              
                                 
                                    x
                                 
                                 
                                    4
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    5
                                 
                              
                              )
                              }
                           
                        . Because the training set was limited, we use a BPNN model with a 1–2–1 structure (three layers, and two hidden neurons within the hidden layer), as shown in Fig. 5
                        , for forecasting. In addition, the learning parameter settings used here were the default settings of Pythia.

The BPNN model was used to forecast the electricity consumption in Australia in 2005 as an example. The training set in this case comprised five observations, 
                           
                              {
                              14
                              ,
                              856
                              ,
                              15
                              ,
                              514
                              ,
                              16
                              ,
                              096
                              ,
                              16
                              ,
                              555
                              }
                           
                        ; four paired learning samples 
                           
                              {
                              (
                              14
                              ,
                              856
                              ,
                              15
                              ,
                              514
                              )
                              ,
                              (
                              15
                              ,
                              514
                              ,
                              16
                              ,
                              436
                              )
                              ,
                              (
                              16
                              ,
                              436
                              ,
                              16
                              ,
                              096
                              )
                              ,
                              (
                              16
                              ,
                              096
                              ,
                              16
                              ,
                              555
                              )
                              }
                           
                         were obtained. The first and second values are used as the input and output, respectively, to train the BPNN topology. After the training, we input 
                           
                              
                                 
                                    x
                                 
                                 
                                    5
                                 
                              
                              =
                              16
                              ,
                              555
                           
                         and obtained the forecast value as 
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          ̂
                                       
                                    
                                 
                                 
                                    6
                                 
                              
                              =
                              16382.57
                           
                        . Table 4
                         provides the details of the training and testing data.

Because the training set comprised an insufficient number of observations (only five) for developing robust neural network learning, this study applied the projected sample generation in extending the training set to enhance the learning performance of the BPNN model. In the training process, ten learning samples were used to construct a model, and each sample had two input attributes and one output attribute. Moreover, the learning topology was determined using Pythia; we use a 2–2–1 neural network structure (three layers, with two hidden neurons within the hidden layer), as shown in Fig. 6
                        . As in the previous approach, the learning parameter setting here were the default settings of Pythia.

The original data set used in the analysis was 
                           
                              {
                              14
                              ,
                              856
                              ,
                              15
                              ,
                              514
                              ,
                              16
                              ,
                              436
                              ,
                              16
                              ,
                              096
                              ,
                              16
                              ,
                              555
                              }
                           
                        . We used the LI function to extract additional information and construct a modified training set with the projected samples, as illustrated in Table 5
                        . The first two values in each datum were used as inputs, and the other value was used as the output. After the learning procedure was complete, the next output value was obtained using the weighted average method and was forecast as 
                           
                              
                                 
                                    x
                                 
                                 
                                    ̂
                                 
                              
                              =
                              16391.97
                           
                        . The computational procedure is detailed as follows:
                           
                              1.
                              The original data set is 
                                    
                                       {
                                       14
                                       ,
                                       856
                                       ,
                                       15
                                       ,
                                       514
                                       ,
                                       16
                                       ,
                                       436
                                       ,
                                       16
                                       ,
                                       096
                                       ,
                                       16
                                       ,
                                       555
                                       }
                                    
                                 .

Compute the LI values of the existing data at each stage by using Eqs. (1)–(6) to obtain 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             1
                                          
                                       
                                       =
                                       {
                                       1
                                       }
                                    
                                 , 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             2
                                          
                                       
                                       =
                                       {
                                       0.2727
                                       ,
                                       0.4286
                                       }
                                    
                                 , 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             3
                                          
                                       
                                       =
                                       {
                                       0.2581
                                       ,
                                       0.7418
                                       ,
                                       0.2353
                                       }
                                    
                                 , 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             4
                                          
                                       
                                       =
                                       {
                                       0.1533
                                       ,
                                       0.6641
                                       ,
                                       0.2876
                                       ,
                                       0.8220
                                       }
                                    
                                 , and 
                                    
                                       
                                          
                                             LI
                                          
                                          
                                             5
                                          
                                       
                                       =
                                       {
                                       0.0951
                                       ,
                                       0.5554
                                       ,
                                       0.5299
                                       ,
                                       0.9437
                                       ,
                                       0.3346
                                       }
                                    
                                 .

Construct a modified learning set by using projected sample generation, as shown in Table 5.

Learn the network structure of the BPNN model by using the extended training set.

Input the independent variables to obtain five possible forecasting outputs for 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             6
                                          
                                       
                                    
                                 , which are 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             1
                                          
                                       
                                       =
                                       16
                                       ,
                                       431
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             2
                                          
                                       
                                       =
                                       16
                                       ,
                                       419
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             3
                                          
                                       
                                       =
                                       16
                                       ,
                                       422
                                    
                                 , 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             4
                                          
                                       
                                       =
                                       16
                                       ,
                                       401
                                    
                                 , and 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             5
                                          
                                       
                                       =
                                       16
                                       ,
                                       348
                                    
                                 .

Obtain the final forecasting value for 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             6
                                          
                                       
                                    
                                  through the weighted average method. 
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                
                                                
                                                   ̂
                                                
                                             
                                          
                                          
                                             6
                                             –
                                             1
                                          
                                       
                                       =
                                       (
                                       1
                                       ×
                                       16
                                       ,
                                       431
                                       +
                                       2
                                       ×
                                       16
                                       ,
                                       419
                                       +
                                       ⋯
                                       +
                                       5
                                       ×
                                       16
                                       ,
                                       348
                                       )
                                       /
                                       (
                                       1
                                       +
                                       2
                                       +
                                       ⋯
                                       +
                                       5
                                       )
                                       ≈
                                       16391.97
                                    
                                 .

Because accuracy is a critical index for evaluating the effectiveness of forecasting methods [27], this study used the mean absolute percentage error (MAPE) as a measure of forecasting performance. The MAPE is computed using Eq. (8), where 
                           
                              m
                           
                         is the number of testing samples, and 
                           
                              
                                 
                                    
                                       
                                          x
                                       
                                       
                                          ̂
                                       
                                    
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           
                         are the forecast and actual values of the ith testing sample, respectively.
                           
                              (8)
                              
                                 
                                    MAPE
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          m
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             m
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            
                                                               ̂
                                                            
                                                         
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   -
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    ×
                                    100
                                    %
                                 
                              
                           
                        
                     

To verify the effectiveness of the proposed method, we compare its results with those of two common forecasting approaches: support vector regression (SVR) and radial basis function network (RBFN). Table 6
                         presents the analytical results of these forecasting approaches. The experimental results showed that the proposed method based on projected samples outperforms the other methods for the APEC energy database. The MAPE of the proposed approach approximates 3.23%; moreover, the improvement of the revised BPNN relative to the original BPNN was greater than 12%, implying that proposed approach is a feasible method for improving the performance of the BPNN. However, the projected sample generation can be improved further because it does not exhibit high performance for all APEC members.

To further confirm feasibility and usefulness of the proposed method, two small data sets on the WLP process and TFT-LCD panel monthly demand were examined in additional experiments.

WLP process data were collected from the related literature [28]. The case firm is a leading packaging manufacturer in Taiwan. The data were collected at the end of 2011, when the case firm conducted a post-installation test for introducing a new WLP process. The pilot run yielded only 13 observations, as listed in Table 7
                           . The height was measured in micrometer (μm). The objective of this experiment was to forecast the height of solder balls over time; therefore, modeling with a small amount of data was preferred. Five data were used for modeling and the next datum was used for testing. A total of eight models and forecasts were obtained in the experiment on the WLP process data.

The data set here is the total demand of the case firm for TFT-LCD panels provided by a leading Taiwanese manufacturer of TFT-LCD panels; the data set comprised time series data for 36months from January 2010 to December 2012. All observations were converted to be within 
                              
                                 [
                                 1
                                 ,
                                 2
                                 ]
                              
                            by using minimum–maximum standardization for confidentiality requirements. Table 8
                            lists the standardized observations. Here, we used five data to construct a model for forecasting the desired output. A total of 31 models and forecasts were obtained in the experiment on the TFT-LCD panel monthly demand.


                           Tables 9 and 10
                           
                            provide comparisons of the analytical results of various forecasting approaches. The revised BPNN model produced favorable results for the two data sets, and its MAPEs were within an acceptable range (10%; [29]). Moreover, the improvements of the revised BPNN relative to the original BPNN for these two data sets were 12.00% and 30.08%, respectively. These findings demonstrated again that the proposed method is feasible for improving the BPNN model by using small data sets.

Overall, the experimental results from the three data sets used in this study are consistent with general intuition. SVR has high learning ability for limited samples, whereas the performance of the neural-network-based methods relies on sample size. The results of the BPNN and RBFN models were, therefore, not outstanding. However, appropriate increasing training information is beneficial for learning network topologies; this is the theoretical basis of projected sample generation and produces acceptable forecasting results.

@&#CONCLUSIONS@&#

Determining future electricity consumption requires accurately forecasting the amount of electricity. If the electricity demand cannot be determined correctly, the electricity supply cannot be ensured, potentially resulting in an energy deficit. Therefore, future energy demand estimation is vital for effective energy system planning. However, historical observations tend to deviate from the current situation under the condition of rapid economic growth. This phenomenon poses a modeling challenge for commonly used forecasting techniques; therefore, forecasting the electricity consumption with limited samples is beneficial. Thus, the specific purpose of this study was to construct a suitable model for short-term forecasting by using small data sets.

In this study, the forecasting performance of the BPNN model was improved using a procedure called projected sample generation. Both the number of training samples and amount of information obtained from the data set, which are crucial factors for constructing a robust model, were extended to enhance the accuracy of the BPNN model. The results proved that the revised BPNN model was superior to the original BPNN model because of the usage of the LI function in the projected sample generation. We conclude that the BPNN model with projected samples can be successfully used as a tool for small time series forecasts.

Few studies have conducted short-term forecasting by using small data sets, and more comprehensive theories for obtaining higher accuracy can be derived in the future. Specifically, the effect of the sample size on small-data-set learning can be analyzed. In addition, projected samples can be used to implement midterm electricity consumption forecasting based on limited samples in the future. Finally, projected sample generation should be applied to other practical fields, such as financial, transportation, and industry fields, to further confirm its effectiveness.

@&#ACKNOWLEDGMENTS@&#

This research is partially sponsored by K.C. Wong Magna Fund in Ningbo University; Natural Science Foundation of Zhejiang Province (China) under Grant LY16G010002; Ningbo University under Grant XKW15D201.

@&#REFERENCES@&#


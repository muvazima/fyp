@&#MAIN-TITLE@&#The clinician in the Driver’s Seat: Part 1 – A drag/drop user-composable electronic health record platform

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           EHRs which let clinician users create and share tools and layout are feasible.


                        
                        
                           
                           Theory suggests HCI/cognition, efficiency, produsage advantages.


                        
                        
                           
                           Drag/drop software design allows clinicians to create patient-specific displays.


                        
                        
                           
                           User control of EHR design can leverage user expertise to fit tools to medical tasks.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

User-configurable EHR

Human–computer interaction

Electronic health record

Composable EHR

Electronic medical record

MedWISE

@&#ABSTRACT@&#


               
               
                  Creating electronic health records that support the uniquely complex and varied needs of healthcare presents formidable challenges. To address some of these challenges we created a new model for healthcare information systems, embodied in MedWISE,
                        2
                        Medical widget-based information sharing environment.
                     
                     
                        2
                      a widget-based highly configurable electronic health record (EHR) platform. Founded on the idea that providing clinician users with greater control of the EHR may result in greater fit to user needs and preferences, MedWISE allows drag/drop user configurations and the sharing of user-created elements such as custom laboratory result panels and user-created interface tabs.
                  After reviewing the current state of EHR configurability, we describe the philosophical, theoretical and practical rationales for our model, and the specific functionality of MedWISE. The alternative approach may have several advantages for human–computer interaction, efficiency, cognition, and fit of EHR tools to different contexts and tasks. We discuss potential issues raised by this approach.
               
            

@&#INTRODUCTION@&#

Developing systems that best fit the needs of healthcare is a complex endeavor. Although decades of research have focused on defining requirements for systems that support clinicians and their tasks, studies suggest that healthcare information systems often fail to support effective and efficient clinical decision making and completion of relevant tasks [1,2]. Systems may fail to take into consideration the significant variability of medical information needs that differ according to context, specialty, role, individual patient, and institution. They may also fail to address the highly collaborative nature of the work, and challenges of addressing rapidly changing or emergent needs. User control of modular user-composable systems has promise for addressing these issues [3]. This approach involves supplementing automation by letting the nonprogrammer clinician user create and share systems (including patient-specific displays) by assembling information elements from multiple sources on screen via drag/drop actions. They can also share their creations (individual widgets or interface tabs or templates) with a click, making them available to colleagues or to all clinicians in a setting.

We expect three main advantages of this approach. First, the ability to move and assemble elements together on the same page has several desirable properties that can impact the cognitive efficiency and efficacy of coordinated interaction with an electronic health record (EHR) system. To substantiate this claim, we draw on theory from human computer interaction (HCI) and the theory of distributed cognition [4]. Second, we anticipate that clinicians can create a system that affords them the capability to solve problems and that better fits the tasks that they are required to perform. The premise is that by providing a set of building blocks that the user assembles to create novel elements and structures, we can leverage the fact that clinician data users have greater medical, contextual and tacit knowledge than do programmers. Their creations may also be more congruent with their mental models of the patients or the tasks. Third, the features that enable sharing may be used to facilitate communication/collaboration and ‘produsage’, which refers to the construction of a large set of user-created resources and tools adapted to specific user needs and different contexts.
                        3
                        Produsage has been defined by Alan Bruns as collaborative and continuous building and extending of existing content in pursuit of further improvement, by creation of shared content in a networked, participatory environment, in a way that breaks boundaries between consumers and producers [5] Bruns. Produsage, 2009. All participants are users and producers, (hence ‘produser’). Usage is necessarily also productive, as the participant’s very patterns of usage become direct inputs. An example is Amazon recommendations based on aggregated user browsing and purchasing actions.
                     
                     
                        3
                     
                  

The purpose of this paper is to describe this novel approach to EHRs, as embodied by our system, MedWISE. We briefly state the theoretical rationale that supports this innovation. However, the primary purpose of this paper is to allow readers to understand the system’s capabilities. Empirical studies of users engaging with the system are reported in other papers [6–9]. The conceptual model is covered in more depth in [3]. As background, we describe problems and user configurability in current EHRs, followed by concepts from theory and research in cognition and HCI. These suggest the relative value in this kind of approach. We then discuss our rationale, and describe the system.

@&#BACKGROUND@&#

Many current systems offer limited end-user configurability and require skilled programmers to make significant changes. At the individual level, the majority of EHRs requires the user to adapt to the program. However, the interface may not reflect how clinicians think about patient problems, and this may result in a workflow that is not optimally tuned for patient care. Communication and collaboration needs are also frequently not met because systems are designed solely for an individual’s linear workflow without the ability to share or to leverage features that support collaboration [1,2]. Accessing large amounts of information via finite screen space necessitates negotiating multiple screens. In addition, the organization of information on a cluttered or poorly organized display may create a burden on limited human cognitive resources [10]. Furthermore, most systems lack the agility required for rapid adaptability to emergent conditions. Integration of multiple information sources may be difficult. Even minor modification or customization of EHRs can be delayed by vendor- and programmer-controlled development processes that require consensus, time, extra cost, and often vendor agreement. Overall, the current approach does not leverage user expertise or provide users with creative potential solutions to clinical technology problems based on their understanding of patient problems. It also sometimes fails to accommodate the complexity of health care and the changes occurring in this sector, which continue apace.

Giving users greater control of a modular system could potentially address some of these problems, and EHR approaches are evolving to that end. However, current EHRs generally permit user participation and control of configuration and display only in limited areas as determined by the vendor [11]. User-configurable order sets are a well-known example [12], and permit users to select combinations of orders to be stored and selected as desired, or as associated with specific patient conditions. Current EHR user-customizable features are summarized in Table 1
                        .

Overall, most current EHRs require the user to negotiate multiple screens in the course of obtaining information sufficient for the diagnosis and treatment process. Their configuration features are usually form-based, sometimes requiring the user to learn forms navigation, and move away from the usual EHR screens in a separate workflow, or even a separate program. In general, they do not employ a direct-manipulation interaction approach. Most allow the user only partial control of certain categories of information.

In recent years, there have been a growing number of resources, tools and applications that facilitate user control of the computing experience. Modern approaches in the public internet space emphasize the creation of platforms for user-directed remixing of snippets of information from multiple sources, mashups, and interactive visualizations. They also employ social networking, aggregation of user-created resources in new useful ways, and crowdsourcing. These approaches accentuate user participation and control more than the typical highly directed and circumscribed applications to which users must adapt. Metadesign is one of the core concepts underlying our approach. Fisher describes it as follows:
                           Meta-design extends the traditional notion of system design … to include an ongoing process in which stakeholders become co-designers—… throughout the whole existence of the system. A necessary … condition for users to become co-designers is that software systems include advanced features that permit users to create complex customizations and extensions. …. broad participation in design activities (in both design time and use time) is as important as creating the artifact itself. [24]
                           
                        
                     

The recently enacted Health Information Technology for Economic and Clinical Health Act (HITECH) has served to dramatically increase the number of EHR implementations and this has revealed the extent to which usability problems impede adoption and diminish the user experience [25–27]. Studies of HCI in EHRs have focused on providing cognitive support [28], particularly on interactive information visualizations such as timelines. Incorporating sufficiently flexible interaction into the highly varied institutional and clinical specialty workflows has been recognized as a particular problem:
                           [There is]… no shortage in theories and principles related to the effective display of information in multiple contexts. …The difficulty appears to be in applying these principles with specificity within the complex clinical environment. Alignment of information displays …with physician cognition, workflows, and decision making in particular is an aspect of EHR design often cited as lacking in the current product market [25].
                        
                     

Most work has focused on specific tasks such as decision support [29], ordering, medication reconciliation [30], interactive data visualization and exploration via timelines [30–32], workflow, and automated summarization [32]. For example, Plaisant et al. developed a novel interactive visualization for medication reconciliation [33].


                        Cognitive load is an expression referring to the burden on working memory imposed by a task, system or environment [34,35]. Cognitive load is increased when the presentation format on a display does not match task requirements or workflow. Increased load also results from having to manually integrate information from diverse resources [36].


                        The keyhole effect describes a common problem in human–computer interaction when trying to access a large amount of information via a small screen, as if viewing a large room through a keyhole [37]. In conventional systems, this usually necessitates viewing multiple screens, since each screen has only part of the required information.

The most common approach for software development is modeling the task and then designing software to carry it out according to the model. This approach tries to identify common use cases and create software that meets those needs by specifying a series of steps the user must take based on the task model. Models assume that there are classes of commonality, e.g. in information content or task structure, which can be ascertained before system use. Although this is not an unreasonable assumption, the variability of patient care, including factors associated with the individual patient condition and exigencies of context (e.g. time and resource scarcity in emergencies), may mean that there are new needs that cannot be covered or anticipated by any particular class. The cost and difficulty of attempting to ascertain and model every task and variation in advance is likely to be prohibitive.

Metadesign is based on the premise that there are benefits to allowing the user, who is aware of the context, to determine some software features at runtime.
                           4
                           Spreadsheets are an example of software involving metadesign; the end user does the final configuration.
                        
                        
                           4
                         Allowing user control might also result in a set of software resources adapted to the actual tasks and contexts at hand, in a way that is not possible when this is done in advance by programmers lacking in medical expertise. For example, five patients in a given clinical unit at any one time may have the same condition, require the same investigative measures, and necessitate similar drug regimens. In this scenario the creation of a template could greatly simplify the work process. Although templates are extremely useful, they are limited in their expressiveness. For example, one of the patients may also have an unrelated condition and be on additional drugs that could conflict with his/her present treatment, requiring different interventions and monitoring. The concept of metadesign means greater flexibility and customizability that goes well beyond templates.

The assertions regarding the limitations caused by HCI problems are substantiated by research findings. Weir et al. found that the number of EHR screen transitions affected the preparation and control of the visit, and concluded that
                           “information relevant to a patient encounter is scattered throughout the EHR. Providers spend significant time organizing information in the EHR, either by searching and sifting or by constructing pre-documents […]. The VA’s EHR and most others available today do little to help providers collect and organize pertinent information. These findings imply that utilities built into the EHR to help organize information […]are likely to improve healthcare processes.” [38].
                        
                     

Horsky demonstrated that the absence of a relevant set of external representations (as expressed on the display) can increase cognitive load and exacerbate usability problems [39]. Staggers found that nurses eschew computerized handoff tools because they are not flexible enough for their needs, preferring to produce paper ‘brains’ of their own design, that summarize the patient condition and are updated throughout the day. A HIMSS’ study of usability “pain points” based on a survey of 106 clinicians, identified workflow, data integration, and data presentation as top pain points in EHR usability [40]. Comparative studies show that including all relevant information on one screen is associated with greater efficiency without decreasing accuracy [41,42].

Concepts from formal theory and research on cognition and interaction reveal deeper reasons why the new functionality in MedWISE (e.g. drag/drop ability to assemble elements on screen) could have advantages. We briefly describe these here with a view to characterize how these features may facilitate performance on clinical tasks.

The basic task in clinical case appraisal involves assembling and considering multiple pieces of information. The use of any complex system such as an EHR necessitates that the user divide his or her attention between negotiating the system (e.g., navigating to the needed screen) and performing the task at hand (e.g., characterizing the patient problem) [10,43]. MedWISE aims to provide a physical manipulable platform that can more closely approximate the clinician’s cognitive processes. It aims to reduce the effort necessary for negotiating interfaces so that more cognitive resources can be put towards thinking about the patient problem.

In the next sections, we discuss the conceptual basis for MedWISE functionality. This is grounded in theories such as distributed cognition, and concepts derived from the literature on work, HCI, and modern web techniques, such as produsage [4,43–46].

The practice of produsage, involving the creation of shared content in a networked, participatory environment, is effective when it is easy and appealing for a wide range of users to participate. Hence the simple drag/drop, single-click configuration and sharing features involving screen ‘objects’, incorporated into the normal EHR workflow, were designed to facilitate easy use, acceptance, and ideally, appeal to busy clinicians.

Distributed cognition is a theory in which the boundaries of cognition are stretched across technologies, artifacts and other humans [4]. It is one of a family of theories including, situated action [47] activity theory [48] and enactive and embodied cognition [49]. Although the theories differ in certain respects including their historical origins and domains of application, they all share the intent to extend the locus of cognition beyond the solitary individual and situate it in the social and technological world. The theory of distributed cognition has been widely used in informatics research [4,10,43] and provides an appropriate theoretical lens to characterize the ways in which various kinds of artifacts serve to differentially mediate creativity and cognition.

Distributed cognition theory states that work takes place across a network of human actors and artifacts that can be considered a primary unit of analysis [4]. A representational state is a particular configuration of an information-bearing element, such as monitor display or written document that has a role in a work process. Representational states are propagated across media and agents to coordinate task performance in the workplace [50]. Fig. 1a
                         has an example. In addition, because humans have limited cognitive resources (perception, attention, and memory) the division of information resources internal to the human actor or external is significant for system usability [39,51]. Externalizing resources, for example, by making them available on a visual display, can serve to reduce the burden on working memory. The more relevant information that is externalized (up to a reasonable limit), the fewer cognitive resources the user must employ to retain information and the more resources are available for higher cognitive functions such as diagnostic reasoning [51].

Ability to compose displays allows the user to create his/her own representations by creating, selecting, arranging, marking and sharing desired elements. This enables the user to create a representation that matches his/her mental representation of the case more precisely, and thus facilitate task performance. For example, the ability to order elements in the screen corresponding to their priority for treatment, or their importance to the diagnostic process, is a more informative representation than a random or alphabetized order such as is found in many conventional EHRs. See Fig. 1b
                        . The ability to visually categorize elements (e.g., by assigning them the same header color and placing them together) can allow the user to communicate to colleagues his or her thinking about how the case evidence, diagnostic tools, or other information should be used in treatment and/or considered in diagnosis. Sharing a complete externalized view could facilitate rapid comprehension and subsequently save search time for colleagues.

Kirsh studied how workers’ restructure their work environment by arranging objects. He classifies intelligent uses of space into three main categories: arrangements that simplify choice, arrangements that simplify perception (such as calling attention to a group of items e.g. radiology studies), and spatial dynamics that simplify computation (such as juxtaposition aiding calculation of clinical ratios) [52]. He found that experts constantly rearrange items to track the task state, assist in memory or understanding, predict effects of actions, and so on. Restructuring often serves a cognitive function: it can reduce the cost of visual search, make it easier to notice, identify and remember items, and simplify task representation (see Fig. 1b for an example of how the user can arrange problem list items in the same order of priority on screen as she thinks of them. This means the user need not retain that order in mind, since it is available externally. This is one of the ‘intelligent uses of space’).

Researchers have studied related interaction and representation effects. Zhang found that depending on their form, external representations do not merely provide affordances for offloading short-term memory, but also constrain, guide and determine cognitive behavior in the context of problem solving [53]. Kerne et al. conducted extensive studies demonstrating that the ability to arrange and juxtapose information objects can facilitate brainstorming, insight, creativity, and knowledge acquisition [54–57]. Kirsh and Maglio et al. studied ‘epistemic action’, which they define as actions that are not required as part of the goal task but which provide an advantage for intermediate mental processing [58]. An example of epistemic action would be a customer creating a table to compare cell phone brands and features before buying, and juxtaposing valued criteria (e.g., price) to make the brand comparison easier. The simple act of juxtaposing to create a more usable representation can minimize visual search and significantly reduce cognitive load. Examples of how spatial arrangement might assist in case review include clustering like items or items pertaining to a diagnostic facet, or ordering items according to treatment priority.

To summarize, a system that exemplifies these ideas may facilitate distributed cognition in several ways:
                           
                              1.
                              Representations may be constructed to better fit the case.

A system that can be modified in seconds can change accordingly as the user’s thinking or the patient’s condition changes.

It decreases the need for working memory needed to manage multiple screens, thus potentially decreasing cognitive load and repeat navigation [59].

More aspects of the patient problem representation can be externalized, thus further decreasing cognitive load.

Providing a ‘common ground’ display for communication might facilitate transfer of representations among colleagues.

We will now describe our system, MedWISE, which embodies these theoretical concepts. Studies of users interacting with the system are described elsewhere [6,7,9,59].

MedWISE is an illustrative EHR platform built to realize a model for a healthcare information system that incorporates metadesign and draws on the theory of intelligent uses of space. It attempts to accommodate the immense variability of healthcare information needs and the need to assemble information from multiple sources. In the past, advanced programming skills were required to create new configurations (such as the patient-specific displays described above). Our aim is to provide a simplifying technology that will allow nonprogrammer users to do so within certain constraints. This is analogous to the way in which word processors allow anyone to produce complex documents, or how graphical browsers allow everyone to use the Internet. It is beyond the scope of this paper to elaborate on the model. The model is described in [3] and the system architecture is described in [60].

This approach differs from the traditional approach in several ways: First, it is a general approach to EHR interaction rather than one that is narrowly focused on a single task such as medication reconciliation. Second, it is based on a modular composable architecture that supplements automated interfaces by providing a drag-drop platform for users to create and share their own resources and tools. Third, it allows social networking, including sharing of user-created elements. Direct manipulation and ongoing clinician involvement are prominent features of MedWISE.

The MedWISE core novel functionalities are listed in Table 2
                        . These basic features are used compositionally (assembled like building blocks in theoretically infinite ways) to meet user needs in a specific situation. As a consequence, basic features can be combined and repurposed to support multiple functions. Table 2 has descriptions including composed uses, their purposes and their expected advantages.

The core functionalities include the ability to select any EHR information elements, or create new ones via special mashup tools, and mark them (for example, by coloring the header), gather them on the same screen, arrange them spatially into a multi-column ‘tab’ (screen interface), and share created elements or interfaces with colleagues. Information is included in draggable blocks, or ‘widgets’, that have editable titles, and can be collapsed to show only the header line, or alternatively expanded to full screen. External materials such as RSS feeds from medical journals or other sources can also be included. ‘Sticky notes’ (text blocks) can be added anywhere, and users can plot any desired laboratory results together on the same axes, as well as create custom lab panels; both of these can be shared.

Users can also set an assembled screen as a template, in which case the laboratory results will automatically update. This template can be applied to other patient records.

In summary, the ability to select or create information elements allows increased presence of relevant items on screen, thereby decreasing the keyhole effect and reducing screen transitions. In addition, this leads to increased externalization of the information the user has to consider, facilitating distributed cognition. The ability to spatially arrange elements allows the user to create a representation that better fits the user’s internal mental representations and/or the external features of the task, such as problem priorities or diagnostic categories, making use of the ‘intelligent uses of space’. The sharing features allow produsage, the eventual creation of a large set of customized tools better fitted to the work context. In addition, it might facilitate the development of ‘common ground’ for communication, by employing the visual space as a means of explicitly communicating intent with colleagues (e.g., items are grouped together for a reason or may signal the need for closer scrutiny).
                     

MedWISE was built as an illustrative system to test the new user-composable widget approach. To ensure that it is only the new features are being tested, the MedWISE information menus match those of WebCIS [61], an EHR used at New York Presbyterian Hospital (NYP), with which all clinicians at the institution were familiar. WebCIS users click on links in a left-hand menu to view individual laboratory panels, notes, and study (e.g. X-ray) reports, which appear one at a time in the right-hand pane. Users usually start with a recent note to obtain an overview. Reichert et al. provide a detailed illustration of WebCIS use [62]. The left-hand menu links in MedWISE are the same as those in the usual WebCIS system; thus the usual WebCIS interface is simultaneously available during MedWISE use (see Fig. 2
                         caption). In MedWISE, clicking on a link in the left-hand menu puts the element into the MedWISE interface as a single widget, so that as the user continues clicking on different items they are gathered together in the large right-hand pane. Clicking on the icon next to the link makes items visible in the right pane one at a time, WebCIS-style. MedWISE interfaces are saved by default. Thus, ‘creating an interface’ in MedWISE is not a separate activity from using MedWISE for case assessment. Since the links for MedWISE and WebCIS are adjacent in the same menu structure, merely gathering the widgets in MedWISE requires the same number of clicks as viewing the same items in WebCIS. Saving them as self-updating template requires two more clicks. Fig. 4
                        
                         compares the interaction style of the two systems.


                        Fig. 4 illustrates the fundamental interaction differences between conventional systems (here WebCIS) in which information location is fixed, and the composable approach. Diagrams should be read in the numbered order.

In the conventional interaction, each screen has only part of the required information (keyhole effect), so the viewer must view several screens. In between screens s/he must keep information in memory (or externalize it in some way, such as by writing it down). Thus the balloons over the user’s head show information being kept in memory. Successive screen views require more information to be stored in memory; then the user considers this information (clinical data) with his/her medical knowledge, decision making occurs, and note writing is done.

In the second (MedWISE) set of diagrams, the user chooses relevant information, which stays on screen, so the user does not need to retain it in memory; hence the balloons over his/her head are blank. Successive views of different information allow the user to gather information s/he finds relevant on screen, so between screens the user does not have to keep it in memory. S/he can view all the relevant information s/he has assembled together on screen, combine it with his/her medical knowledge, and decision making, to create a note.

In the composable interaction style afforded by MedWISE, the user does not have to retain information in memory between screens. Thus information is external to the user for a greater part of the whole process. This putatively decreases cognitive load and fosters enhanced usability/distributed cognition. The ability to juxtapose information in the way the user considers useful (such as putting lab tests that must be compared next to each other) makes use of epistemic action processing. Thus the system can mitigate the problems of negotiating multiple fixed screens and the associated cognitive burdens and attentional bottlenecks.

MedWISE was built for use on ward and office desktop computers by clinicians in a large inner city tertiary care academic medical center. Many patients in this environment are seriously ill with multiple comorbidities thus requiring extensive laboratory tests and studies. This information as well as notes written by a range of clinicians (e.g., attendings, nurses, residents, and physician assistants) are available in WebCIS, a home-grown system that aggregates and displays information from dozens of clinical systems [61]. All clinicians in this institution typically have access to all patient information for all patients, and read colleagues’ notes asynchronously in collaboration among care teams and in consultation with colleagues in other departments. Thus, our clinicians were familiar with the note and laboratory test formats, colleague authors, hospital service organization, and other pertinent aspects of the context.

Since normally all clinicians at the same level can see all patient records, there are no additional privacy restrictions. The architecture separates interface configurations from patient information, so user creations (e.g. widgets/templates) may be shared by individuals or groups. Our model’s produsage paradigm allows for different degrees of sharing, allowing clinicians the flexibility to share information amongst their own teams, amongst other clinicians with the same role (for example, residents sharing care of the same patient), or more widely (e.g., for a specialty).

@&#DISCUSSION@&#

In this paper, we have defined a novel paradigm for EHR interaction, based on a set of theoretical concepts such as distributed cognition, keyhole effect, and produsage. The rationale for this paradigm is to afford greater flexibility and leverage clinician users’ deep domain and contextual knowledge. This may allow a better fit to task, provide more robust cognitive support, and facilitate rapid configuration to accommodate the complexity and changing nature of the healthcare domain. We described a set of functionality and core candidate features, which are hypothesized to confer significant advantages over conventional systems for clinical computing. Although we describe their instantiation in a particular system, MedWISE, the individual features are broadly available in modern computing environments. We believe that this approach may be applicable more generally in health care, including applications for patient personal health records, clinical research protocols, specialized visualization needs such as those found in critical care, public health surveillance, handoff, and rapid development of tools for emergent public health threats [63].

The architectural features allow rapid accommodation of a wide variety of contexts, without the time, cost and obstacles involved in programmer/vendor changes in conventional fixed systems; thus it might also be a new mode of software development with attendant changes in the economics of system creation. Of course, this remains to be tested. In our experience, the code base and amount of programming required to create a flexible composable system may be smaller than that required to accommodate each individual need and context ad hoc.

User control and sharing may also affect user attitudes toward EHRs and hence facilitate adoption, as well as usability and transmission of user expertise. Simplifying technologies that shift some control to the user (such as the aforementioned web browsers and GUIs) have led to a proliferation of activity in the public sphere, with transformative effects.

There are also safety implications of the MedWISE model. Systems that are designed and evolve based on hundreds of clinician judgments, fit a myriad of local needs, and in which errors or omissions can be corrected by clinicians in seconds, may be safer than static systems designed by programmers. Some of the arguments put forth in this paper have been subjected to empirical testing (discussed in [6,7,59,60]) and others await further substantiation.

There is a potential risk of increased errors or error propagation if users using a shared element fail to detect omissions of essential information, or are overly influenced by a prior clinician’s diagnostic reasoning (diagnosis momentum error) [64]. The magnitude of this risk can only be determined by empirical studies or logfile analyses of deployed systems [65]. The experimental system is in equipoise with current practice, in which clinician viewing of clinical information (aside from attested notes) is not monitored for completeness. Thus the risk of a user neglecting to review important information is putatively the same as with current practice. In general, in existing practice each user reviews the elements of his/her choice, and this review is not overseen or checked. See [7] for further discussion of this issue of omissions, errors and safety. Users sharing interfaces could potentially experience increased cognitive burden if newly borrowed interfaces clash with their mental models. This is discussed below in ‘future work’. Theoretically users might also experience cognitive burden due to initial learning how to use the system, or from the process of creation.

The work presented in this paper is aligned with a growing number of innovative initiatives that share the common goal of affording greater control and flexibility in the user’s EHR experience. Kohane and Mandl [66] present the idea of substitutability, with independent applications interchangeable in a common framework, such as the Smartplatforms project. This does not involve user creation, but presents an idea similar to the updateability of widgets by third parties. Patrick [20] devised a paradigm in which clinician users design the system including database fields and features via a system generator that facilitates the process. The project employs technical approaches different from ours, but shares the basic concept that users can be instrumental in designing the system from a set of familiar resources that can be manipulated. Mitre Corporation’s MedCafe employs an approach [67] that similarly uses movable blocks, though with different specific features. In another high-stakes domain, NASA’s Mission Control software (MCT) employs a user-composable platform approach in order to cope with the need for software change while accommodating consistency and reliability [68]. There have been various calls for use of more modern web approaches and tools, such as the call to have a ‘Facebook’-like collaborative documentation system. As the need for greater usability and fit to task is increasingly recognized, and the progress of the cell phone apps paradigm continues, more and more researchers and developers are thinking about how these may be adapted as solutions for the multitude of user-related problems presented by healthcare systems.

It is important to note that MedWISE is an experimental system that has not been tested in a production system in a clinical setting. Therefore, we cannot say with any degree of certainty that the system will be well-received and widely adopted by users. In this paper, we have explained the advantages of this kind of system from both a theoretical and practical vantage point. However, we do not know if users will perceive such advantages or whether they will expend the effort to master the system. In other papers [6,7,59,60] we report on user behavior and perception which indicate favorable attitudes towards this approach. Nevertheless, such a system needs to be tested by actual users in routine clinical practice to discern patterns of user behavior and scale of adoption. Of course, actual use will be determined by a multitude of factors including the support of stakeholders in an institution, convenience of use and a host of other factors that are well beyond our control.

@&#FUTURE WORK@&#

It is well established that interface consistency is important for users to find items easily, learn the system, and operate smoothly within it [69]. It is important to note that this is initial work. Since user configuration could result in unwanted inconsistencies, further research may look at methods to ensure consistency appropriate to context and/or meet user preferences while still retaining the same relevant patient information in the interface. This could include ‘locking down’ parts, switching optional or user-specific default formats, marking regions, coupling items which should be viewed together for safety reasons, recommender systems, and interface methods of constraining choices (e.g. autocomplete/preview). This would also assist in the management of large numbers of user-created resources. It is important to note that modularity and composability can be separated. For example, since MedWISE is a widget-based system, it could anticipate user needs based on context, via knowledge or data analytics, and automatically prepopulate the interface.

Advanced mashup features exist, and may be used for rapid configuration (e.g. for decision support for emergent public health threats [63]), or implementation of new treatments. As with modular systems in general, the time taken to build such systems can be offset by the rapid configuration possible when needed [70]. Likewise, MedWISE could be used for testing the effectiveness of different information collections, tools, visualizations and interfaces for different contexts. Rapid configurability could allow rapid prototyping and iterative testing of new functions, an important component of the diffusion of innovation [71].

It is also important to note that our philosophy does not mean nonprogrammer clinicians design everything. Our ‘metadesign’ model aims at creating a simplifying technology platform carefully incorporating diverse expertise including that of security and usability experts, administrators and others [63]. Information selection, arrangement, and a certain level of creation and sharing are functionalities given to clinicians because those functions are most appropriate to be governed by their deep medical and contextual knowledge. To continue the word-processing analogy, a word processor allows the user to create complex documents, but does not require that s/he design fonts. Complex aspects of the programming should be left to the relevant experts. For example, usability principles such as consistent and prominent display of patient names, or Tall Man lettering for drug names, are the province of usability experts and should be included without option.

Usefulness of this paradigm includes the potential ability for clinicians to create software that truly addresses their needs, centered on the necessities of clinical care rather than billing and administration. The flexible architecture allows for new functionalities to be incorporated easily as new components or widgets, placing them directly in the existing EHR. For example, a widget providing treatment recommendations based on ‘outcomes of patients like this at this institution’ could be included easily without complete reprogramming or introduction of a new system. While individual users may create tools with greater or lesser efficiency and validity, the rapidly changeable system means items found to be erroneous or suboptimal could be changed in seconds. Our paradigm includes levels of vetting corresponding to potential risk [3]. It is unlikely that all users would have the same level of engagement, but the paradigm allows for this, allowing a range from no use to complex tool creation. It is likely that most users would use the simplest select/arrange functions while fewer more interested superusers would create more complex tools which colleagues would borrow, as happens in the public web. This is consistent with the responses from focus groups [65]. The ready availability of functions does however allow for a user to learn gradually.

The sharing feature is a simple but critical function for the model, potentially saving time and resources by allowing component reuse, saving search time for colleagues caring for the same patient, and allowing consistent display configurations. Most importantly overall, it allows for evolutionary growth of the system. Users start with a consistent set of building blocks, the selection and organization of which are mediated by each clinician’s creations and judgments (akin to a form of crowdsourcing). Sharing allows the system to differentiate to fit needs and contexts, mediated by clinician creations and judgments. Further explanation is found in [3].

@&#CONCLUSIONS@&#

We propose a new modular, user-composable platform approach to developing healthcare IT that can adapt to variable or rapidly changing needs. In developing an illustrative system that gives clinicians greater control of the EHR, we demonstrated the technical feasibility of this approach. User-configurable interfaces have relevance to system design for other fields in which deep user expertise in complex critical processes is paramount. The system flexibility opens new options for developing EHRs as real tools for information organization and thinking, beyond the storage and retrieval (paper-like) paradigm from which current systems originate. Precisely how much control should be assumed by the user is a matter for empirical study. Some studies of user behavior are described in separate papers [6,7,59,60].

There is still much left to learn if we are to produce the simplifying inventions that could shift some control to the user and perhaps increase widespread productive EHR use, analogous with similar change as has been realized in other spheres such as the public web. The current project provided building blocks toward achievement of that goal.

@&#ACKNOWLEDGMENTS@&#

We gratefully acknowledge Justin Starren and Jan Horsky for their role as committee members in this PhD research. We would like to thank Herbert Chase and David Vawdrey for their technical assistance. In addition, we greatly appreciate the time and effort of the participants in the study.

Dr. Senathirajah was supported by Irving Institute for Clinical and Translational Research grant #UL1RR024156 and NLM/RWJ ST15 LM007079-15 Research Training Grant.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.jbi.2014.09.002.


                     
                        
                           Supplementary Video 1
                           
                        
                     
                     
                        
                           Supplementary Video 2
                           
                        
                     
                  

@&#REFERENCES@&#


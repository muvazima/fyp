@&#MAIN-TITLE@&#Thirty years of artificial intelligence in medicine (AIME) conferences: A review of research themes

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Fifteen Artificial Intelligence in MEdicine (AIME) conferences have been organized over the last 30 years.


                        
                        
                           
                           We review the main research themes and investigate their scientific impact.


                        
                        
                           
                           Knowledge engeering for medical expert systems dominated the first decade of AIME, while machine learning and data mining prevailed thereafter.


                        
                        
                           
                           The work on guidelines and protocols has been highly cited, followed by temporal information management and machine learning/data mining.


                        
                        
                           
                           Promising directions for future research are Big Data, personalized medicine, Evidence Based Medicine, business process modeling, process mining and NLP in social media.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Artificial Intelligence in Medicine

Literature review

History of science

@&#ABSTRACT@&#


               
               
                  Background
                  Over the past 30 years, the international conference on Artificial Intelligence in MEdicine (AIME) has been organized at different venues across Europe every 2 years, establishing a forum for scientific exchange and creating an active research community. The Artificial Intelligence in Medicine journal has published theme issues with extended versions of selected AIME papers since 1998.
               
               
                  Objectives
                  To review the history of AIME conferences, investigate its impact on the wider research field, and identify challenges for its future.
               
               
                  Methods
                  We analyzed a total of 122 session titles to create a taxonomy of research themes and topics. We classified all 734 AIME conference papers published between 1985 and 2013 with this taxonomy. We also analyzed the citations to these conference papers and to 55 special issue papers.
               
               
                  Results
                  We identified 30 research topics across 12 themes. AIME was dominated by knowledge engineering research in its first decade, while machine learning and data mining prevailed thereafter. Together these two themes have contributed about 51% of all papers. There have been eight AIME papers that were cited at least 10 times per year since their publication.
               
               
                  Conclusions
                  There has been a major shift from knowledge-based to data-driven methods while the interest for other research themes such as uncertainty management, image and signal processing, and natural language processing has been stable since the early 1990s. AIME papers relating to guidelines and protocols are among the most highly cited.
               
            

@&#INTRODUCTION@&#

In September 1985, Ivo de Lotto and Mario Stefanelli organized a 2-day conference on Artificial Intelligence (AI) in medicine at the University of Pavia in Italy [1]. The idea was to bring together researchers working in this field, that had emerged in the early 1970s and that sits at the crossroads of AI, Computer Science, Medicine and Biology. By the close of the meeting, the participants agreed that they clearly shared a common interest and that it would be valuable to organize similar meetings in the future. Subsequent, biennial meetings were organized in different European cities, as detailed in Table 1
                     .

Initially, the name “Artificial Intelligence in Medicine Europe” was adopted but later changed into “Artificial Intelligence in MEdicine”; the acronym “AIME” has remained. Since 1998, the Artificial Intelligence in Medicine journal has been connected to the AIME conference by publishing a series of eight special issues with extended versions of selected AIME papers, thus opening a selection of work presented at the conference to a wider audience.

Throughout the years, AIME has established itself as a meeting that focuses on methods and techniques from computer science and artificial intelligence, but with a strong attention to applications in biomedicine and healthcare. Accordingly, papers in AIME conferences are selected by methodological rigour, originality of the proposed solutions, and to their effectiveness in addressing biomedical and healthcare problems. This distinguishes AIME from general AI conferences, (e.g., the Association for the Advancement of AI [AAAI] conferences, International Joint Conferences on AI [IJCAI], European Conference on AI [ECAI]), biomedical engineering conferences (e.g., IEEE Engineering in Medicine and Biology Society) and medical informatics conferences (e.g., Medinfo, American Medical Informatics Association [AMIA] Annual Symposium). As a result, AIME is also smaller than these more general conferences (usually around 125–150 attendants), and is comparable to other technically-oriented conferences such as the IEEE International Conference on Healthcare Informatics and the Conference on Bioinformatics, Computational Biology and Health Informatics from the Association for Computing Machinery.

The three decades that have passed since the inception of AIME have witnessed major changes to biomedicine and healthcare and revolutionary developments in information technology. Evidence based medicine and clinical practice guidelines have become leading paradigms for clinical decision making, and the growing incidence of chronic illness and the rising costs of healthcare have been identified as primary challenges for the healthcare system. Technological developments have brought us computers that are many times smaller, faster, equipped with more storage capacity, and more connected to each other than 30 years ago, while high-throughput sequencing techniques have created unprecedented opportunities for collecting biological information. These changes are reflected by the research themes that have been addressed at AIME conferences over the years. Most presentations at the 1985 meeting focused on knowledge engineering for expert systems and other forms of computerized clinical decision support, and on qualitative modeling and reasoning in physiological systems, while these themes have received little attention during the last decade. Instead, guidelines and protocols, machine learning, semantic technology and bioinformatics have become prominent themes in recent editions of the conference.

The 30th anniversary of AIME provides the opportunity to look back at the history of the conference and assess how research themes have changes and emerged over time, and what their scientific impact has been. Therefore we studied the history of AIME, with the following objectives:
                        
                           •
                           to identify the main research themes that have been addressed at AIME conferences, as well as their evolution over the years and

to assess the scientific impact of these research themes, measured by the number of citations to papers associated with the themes.

To this end, we first conducted a qualitative analysis of research themes and topics covered by the AIME proceedings 1985–2013, by categorizing all published papers in these proceedings using a combination of established taxonomies and bottom-up classification. Then, we performed a bibliographic analysis of papers published in the conference proceedings and in the series of special issues of the Artificial Intelligence in Medicine journal. Finally, based on the results of the two previous phases and our own experience in the field, we identified research challenges and promising research areas for the future of AIME.

As the analysis focused on AIME papers and on related special issue papers published in this journal, this survey is limited in scope and deliberately focused. A comprehensive survey of the entire field is beyond the scope of this paper. Nevertheless, we believe that much of the developments that have occurred within the AIME conferences are representative for the wider AI in medicine field, and therefore our work provides insights that reach beyond the AIME conference itself.

This paper is structured as follows. In Section 2, we describe the qualitative and bibliographic analysis methods that were used in this review in more detail. Section 3 presents the results of the analysis using twelve broad research themes that have been covered at AIME conferences through the years, and describes the results of the bibliographic analysis by discussing the 25 most influential papers that have been published in AIME proceedings or in one of the affiliated special issues. In Section 4, we address limitations of our analysis and reflect on future challenges and opportunities for the field. The paper ends with a conclusion in Section 5.

@&#METHODS@&#

We adopted a mixed-methods approach involving both qualitative and quantitative methods. First, we assessed a taxonomy of persistent research themes that have been addressed at AIME conferences, and counted the occurrences of these themes over the years. Second, we identified influential papers presented at AIME conferences and published in the affiliated special issues of this journal using bibliographic methods. Both procedures are detailed below.

To identify broad and persistent research themes covered at AIME conferences, we systematically collected all titles of paper sessions at these conferences from published proceedings. These titles helped us to understand which themes and topics were perceived as important, and how their importance changed over time. In considering session titles, we excluded sessions with general names such as “methodologies” and “clinical applications”, as these titles were deemed non-informative and the sessions usually contained a heterogeneous set of papers.

Based on broadly accepted taxonomies of research topics in computer science, artificial intelligence and biomedical informatics [16–18], we grouped and classified the entire set of session titles thus obtained into broad themes. Among the possible taxonomies we used the one subtended by most session titles, closely related to the methodological/research field and usually not related to the clinical application domain of papers.

Subsequently we created a list of all papers published in AIME proceedings and assigned one or more research topics to each paper, based on paper title and session title. More research topics were assigned to papers only when it was clear that such topics were dealt with in a balanced way within the considered paper. In cases of doubt, the abstract of the paper in question was consulted. All the authors together defined the adopted taxonomy, while two authors of this paper performed the classification and the other two author independently verified the assigned categories. During this process, subtopics were identified when appropriate and added to the taxonomy. Finally, we assessed the relative importance of research topics by considering their overall frequency of occurrence, and analyzed temporal trends by assessing their frequency of occurrence over time.

To analyze the scientific impact of AIME conferences, we created a list of all papers that have been published in AIME proceedings or in special issues of the Artificial Intelligence in Medicine journal related to AIME. A total of eight of such special issues have been published since 1998; they are listed in Appendix 1.

The process of developing and producing these special issues was as follows. After each AIME edition, several papers were selected according to review rates and interest during the oral presentation. Authors of selected papers were invited to submit an extended version of the conference paper and each extended version, containing new original parts, was reviewed according to the standard process of the journal Artificial Intelligence in Medicine. Accepted papers were then published in a special issue, usually appearing before the next AIME edition.

We used Google Scholar [scholar.google.com] and Web of Science [webofscience.com] to assess the total number of citations and the average number of citations per year, of each paper on the list. Papers were ranked by the average number of citations per year.

@&#RESULTS@&#

We analyzed a total of 122 session titles of 15 AIME conferences; the first conference (1985) did not use a thematic session breakdown. Subsequently we analyzed a total of 734 contributions to 16 AIME proceedings: 24 keynote summaries, 447 long papers (6–10 pages) and 263 short papers (up to 5 pages). The average number of contributions per conference, excluding keynote summaries, was 44.4; the highest number of contributions was reached in 2005 with 37 long papers and 29 short papers (Fig. 1
                        ).

We identified 12 broad research themes that persisted through most AIME editions over the years. Table 2
                         provides an overview of the full taxonomy. Naturally, there are many links between these research themes and in some cases they overlap. And indeed there have been many AIME papers that address more than one theme or topic. Nevertheless, we believe that this division of themes, topics and subtopics provides a useful conceptualization of the AIME research domain.


                        Table 3
                         lists the frequencies with which the 12 research themes occurred in AIME conferences over the years. As appears from the table, knowledge engineering strongly dominated the first six editions of AIME. After 1990 the field started to expand and new research themes emerged. Machine learning and data mining became the most broadly covered themes after 2000. Some themes, such as uncertainty management, and image and signal processing, remained more or less equally popular over the years.

In the following sections we will discuss the 12 main research themes in more detail and describe their development through the years.

Knowledge engineering has its roots in symbolic approaches that dominated AI in the 1980s. The years 1975–1985 saw an explosion of successful AI applications in medicine that were based on the computational representation of human knowledge. Many reasons for this success have been described, among them the availability of systematic knowledge sources and the existence of well-defined, reasonably-sized subdomains [19,20].

During the first decade of AIME, nearly 50% of all the work presented was devoted to knowledge engineering. Many papers addressed the development of expert systems or other types of knowledge-based systems for specific clinical problems. In some cases, the focus was on the difficulties associated with integrating knowledge-based systems into clinical practice [21]. Additionally, a significant number of papers were devoted to software tools for developing expert systems, anticipating further efforts on the design of successful software methodologies for KBS [22].

Each conference during the first 10 years of AIME included a session specifically devoted to knowledge acquisition. Implicit here was the recognition that there was a bottleneck in knowledge based system development. Manual knowledge elicitation techniques therefore evolved toward machine learning approaches, which are discussed separately in Section 3.1.10.

The first decade of knowledge engineering in AIME also witnessed a major role for model-based reasoning. This area focused mostly on models of physiological systems, qualitative reasoning methods and simulation. It reached its peak in 1993 when an extensive session on model based reasoning was included.

The knowledge engineering field reached maturity during the 1990s [20]. Traditional knowledge engineering topics progressively lost prevalence or were substituted for more specialized topics. For instance, representing and reasoning with time in medical knowledge based systems [23] grew out to become a major independent theme at subsequent conferences; this is discussed in Section 3.1.5. Refinement of skeletal plans was an important precedent of further work on guidelines [24]. A similar development was witnessed for ontologies and terminologies, as discussed below. So, while knowledge engineering nowadays plays a smaller role at AIME, it has sourced other major themes that still prevail today.

A closely related theme that emerged out of the area of knowledge engineering concerns biomedical ontologies and terminologies. This theme first emerged at AIME in the mid-1990s and has steadily increased in importance since then. The relevance of the work on ontologies was confirmed by a keynote presentation on ontology mapping at AIME 2005 [25].

It has been argued that the work on ontologies and terminologies signifies maturation of the AI in medicine field [26] because this work does not directly aim to solve biomedical problems. Instead, it is “inward-looking” in the sense that it focuses on the creation of reusable knowledge artefacts that comprehensively describe concepts and terms in the biomedical domain, including their mutual relations.

Looking in detail at papers that have been presented in this area, we find papers that study ontologies or terminologies for specific medical domains [27–29], as well as papers focusing on specific tasks such as information retrieval and patient eligibility assessment for clinical trials [30,31]. Another class of papers addresses representation and inference problems, such as formal representation of part-of relations, ontology mapping, or identification of redundant elements in concept definitions [32,33].

As of 2015, ontological and terminological systems are broadly considered indispensable for many areas of AI in medicine and biomedical informatics, ranging from knowledge based systems to Big Data analytics. Much of the work on ontologies is nowadays labeled under the heading “semantic technology”. Ontologies and terminologies therefore arguably belong to the core areas of the field.

Natural language processing (NLP) is an important issue in managing, modeling, querying and reasoning on medical information and knowledge, as it is often provided through natural language sentences and, in general, in unstructured documents.

In the years 1997–2001, most AIME papers in this area studied automatic generation of natural language for decision support and health promotion [34,35]. But soon the emphasis switched to natural language interpretation in areas such as learning morphological knowledge from medical corpora; knowledge acquisition from narrative sources; automatic indexing of textual information resources; and analyzing and classifying unstructured medical documents [36–39].

Three further topics have emerged in the last decade. First, NLP researchers developed techniques for text mining, i.e., discovering new knowledge from text corpora in the form of previously unknown patterns and relations between concepts [40]. Second, researchers have started to apply NLP techniques to code the narrative parts of electronic health records, for instance to extract information of adverse drug events; this topic was addressed in a keynote presentation in 2009 [41]. Third, a relatively new and promising area is epidemic surveillance from web news and social media through NLP methods [42].

Modeling and managing clinical practice guidelines (CPGs) focuses on processes and, more particularly, on the knowledge related to the management of care-related processes. Its centrality to AIME is confirmed by several keynote lectures over the years [43–45].

Research in computational CPGs faces many challenges such as formal specification, representation and verification of CPGs [46,47], development of tools for CPG execution [48,49], merging of concurrent CPGs [50], measuring CPG compliance [51], integrating CPGs with medical records, pathways and healthcare processes [52], or adapting general-purpose tools and methodologies coming from the growing area of business process and workflow technology.

Some papers deal with general topics that can be characterized as software-engineering oriented, as the use of design patterns in process design, the support of authoring and versioning, the issue of quality checking, the design and implementation of run time engines, the verification and data/flow aspects and workflow and process aspects [53,54]. Other papers have integrated with guidelines other AI techniques, such as natural language processing, information extraction, ontologies and semantic-web frameworks [55–58].

In recent AIME editions, we continue to observe both foundational topics and more specific ones as merging of guidelines, natural language analysis of guidelines, merging of process and medical knowledge, managing (possibly) multiple CPGs for comorbid patients. In addition, some papers address topics more related to the execution of clinical plans and therapies. Finally, some papers focus on specific clinical domains and tasks [50,59,60].

The temporal dimension is of paramount importance for the design of successful medical application of intelligent systems, and it is therefore not surprising that this has been addressed by many AIME papers over the years. The importance of temporal information management for AIME is confirmed by keynote lectures in 1993 [61] and 1999 [62].

The topic appeared in 1995 with three papers dealing with different issues, from modeling and reasoning to a framework for monitoring the evolution of patients through abstraction mechanisms [63–65]. In subsequent AIME editions most papers dealing with temporal information focused on specific clinical domains with different methodological approaches [66–68]. In addition, a few papers on the analysis of medical time series were presented and the new topic of temporal information visualization appeared [69–71]. In 2003 the increasing interest in temporal reasoning and representation was confirmed by many papers focusing on temporal data mining, temporal series analysis, temporal abstraction and semistructured temporal clinical data [72–75].

Over the last decade, time-related topics have become wider, including new research themes as temporal data analysis, temporal data mining, temporal patterns, temporal data modeling, Bayesian dynamic networks, and clinical workflows [54,76–78]. Temporal data mining has continued to receive attention together with temporal constraints and temporal knowledge retrieval [79–81]. Several papers have applied time-related research methods to deal with different clinical domains and tasks such as prognosis in the intensive care [82], querying and visualization of clinical abstractions [83] and guidelines-based care [84]. Finally, in 2013 the theme of temporal information management played a smaller role in AIME, and the main interest shifted towards more specific topics such as temporal data mining [85], rule derivation in surveillance systems [86] and care trajectory mining [87].

Case-based reasoning (CBR) is a symbolic reasoning approach that uses medical data as a starting point, and which became popular in the late 1980s. In contrast to machine learning, CBR does not try to induce rules or models from data: it makes inferences from historical cases directly by comparing them to the current patient [88]. An early example in the field of liver transplantation was presented at AIME 1987 [89]. The CBR community has always been relatively small, but papers on CBR have been presented at many AIME conferences [90–93]. Recently, interest for CBR seems to be fading.

Automated planning and scheduling emerged in the 1980s as a separate branch of AI that focuses on the realization of strategies or action sequences for reaching a particular goal by searching a multidimensional state space [94]. Planning and scheduling appeared in the 1990s as a research theme in AIME when researchers moved away from clinical decision making as the prime focus for AI applications in medicine, and increasing attention was given to clinical processes in care organizations. For instance, Spyropoulos et al. [66] studied the scheduling of patient tests in hospital laboratories; Modgil et al. [95] developed a Prolog system that revises therapy plans such that they conform to safety requirements; and Bradbrook et al. [96] used AI planning methods in computerized clinical practice guideline. As appears from these examples, planning and scheduling has tight links with two other themes, namely temporal information management, and guidelines and protocols.

The 1990s also witnessed a new class of problem solving methods that were inspired by distributed algorithms from computer science on the one hand, and by metaphors from social and evolutionary systems on the other. An early example at AIME is the use of a blackboard architecture, a common knowledge base which is iteratively updated by a diverse group of specialist knowledge sources, for therapy planning [97]. Later examples are the papers on multi-agent systems by [98,99], Vermeulen et al. [100] and others, which were applied for a wide variety of tasks ranging from therapy planning to image segmentation. The significance of multi-agent systems for AIME was underlined by a keynote lecture on this theme in 2001 [101]. Another research stream related to this theme uses evolutionary approaches such as genetic algorithms to solve search problems [102,103].

Reasoning with uncertainty in the biomedical domain has been considered a key challenge since the early days of AI in Medicine, as reflected by the seminal work on certainty factors in rule-based expert systems by Shortliffe and Buchanan [104]. Incomplete, imprecise and inconclusive knowledge plays an important role in all areas of clinical reasoning (diagnosis, therapy selection and prognosis). Within the AIME conferences, most of the papers in this theme have been devoted to probabilistic graphical models such as Bayesian networks.

Until the mid-1980s, following a probabilistic approach to uncertainty management was considered intractable. AI researchers looked for other, heuristic ways to deal with the incompleteness and ambiguity that is inherent to biomedical knowledge. However, these approaches were increasingly criticized as being too ad hoc, lacking a mathematical underpinning; for instance Berzuini et al. [105] argued that AI researchers should instead embrace probabilistically sound methods. By the late 1980s, such methods started to appear in the form of Bayesian networks [106].

Efficient inference methods for these models became a lively area of research in the late 1980s and early 1990s, addressed by many papers at AIME conferences [107–109]. As inference algorithms improved and CPU speed increased over the years, the size of Bayesian networks that were used in biomedical applications increased accordingly. In 2007, Wemmenhove et al. [110] presented the Promedas Bayesian network for diagnosis in general internal medicine, which modeled approximately 2000 diagnoses, 1000 findings and 8600 connections. As computational issues with inference in Bayesian networks became less of a problem, research focus shifted towards model specification during the 1990s. For instance, Ramoni and colleagues [111] presented a class of influence diagrams (Bayesian networks augmented with decision nodes and value functions) that were able to reason on the basis of incomplete probabilistic information. Larranaga and colleagues [112] introduced a method based on genetic algorithms to induce Bayesian networks from data and Zaffalon et al. [113] extended the naive Bayesian classifier to handle imprecise probabilities that are obtained from small and incomplete datasets.

While Bayesian networks have generally dominated the research on uncertainty management within the AIME community, other approaches have also been explored. In particular, fuzzy logic was used in several papers to reason about dynamic biomedical processes with incomplete or uncertain information in the 1990s. Mason and colleagues [114] proposed a method for self-learning fuzzy logic control that could accommodate uncertain, non-linear and time-varying process characteristics. It can be applied to common clinical processes such as blood pressure control and intra-operative control of anaesthetic depth. Similarly, Bellazzi et al. [115] described a method for learning the dynamics of non-linear systems from data by integrating qualitative modeling techniques with fuzzy logic, which they used to identify the response to insulin therapy in insulin-dependent diabetic patients.

In the last decade, Bayesian network software has become widely available and is now part of the standard toolbox for computer science and AI. AIME research has increasingly focused on exploiting Bayesian networks for specific biological or clinical problems, such as mammographic image interpretation [116] and risk factor interactions in multimorbid patients [117].

Machine learning has been one of the most dynamic fields within AI in medicine over the last 30 years. It was almost absent when AIME started in 1985, but has evolved into a major theme that has links to many other areas (e.g., knowledge representation, uncertainty management, temporal reasoning, image and signal processing and bioinformatics), and which has continuously progressed over the years under the influence of emerging trends such as Data Mining, Intelligent Data Analysis and Big Data.

Machine learning developed in the 1960s and 1970s as a subfield of computer science, AI and statistics. However, in the 1980s symbolic approaches based on logic and knowledge engineering dominated AI; subsymbolic methods such as “connectionism” (artificial neural networks) and statistical modeling were not considered proper AI. During the early years of AIME, interest in machine learning was therefore scarce, and mostly grew out of a need to populate the knowledge bases of expert systems. One source of knowledge were medical experts, but they were difficult to access, the methods to elicit their knowledge were laborios, and for some complex tasks it was too hard to find experts at all. Medical databases were identified as a complementary knowledge source, and methods were needed to extract the knowledge from them. For instance, Funk et al. [118] presented a machine learning method to induce rules from data for an expert system that assisted in the interpretation of gel electrophoresis images, and Pirnat et al. [119] reported on the automatic induction of diagnostic rules in rheumatology.

Machine learning started to flourish in the 1990s by moving towards methods borrowed from statistics and probability theory. Bayesian networks were becoming popular at the time, and it quickly became obvious that statistical machine learning methods were indispensible to estimate their hundreds, sometimes thousands, numerical parameters representing conditional probabilities [107,120].

In the 1990s there was also a strong interest in “connectionist” approaches such as artificial neural networks, also thanks to the reinvention of backpropagation by Rumelhart and McClelland [121]. In the biomedical field, neural networks are potentially useful to identify complex patterns in high-dimensional data, for instance image or signal data [122]; a common application is diagnosis [123–125]. During the last years, the topic of neural networks has become less prominent at AIME conferences.

Many machine learning papers that have been presented at AIME conferences over the years address methodological issues that are especially important for the biomedical field. Abu-Hanna and De Keizer [126] described an integration of a classical symbolic machine learning approach, decision tree learning, with a statistical modeling method (local logistic regression). Kukar [127] addressed reliability estimation of diagnostic classifications based on machine learning, and Jakulin et al. [128] presented a method to augment one of the most popular machine learning methods, the naive Bayesian classifier, with attribute interactions derived from the data. Finally, Antal et al. [129] described a hybrid Bayesian methodology to incorporate prior knowledge, acquired from on the biomedical literature and clinical experts, into artificial neural networks.

Traditionally, data analysis was the final phase of an experimental design that typically included the formulation of a hypothesis, patient recruitment and data collection. With the introduction of data warehouses in the 1990s this selective approach to data collection was abandoned: data were increasingly gathered with no specific analytic purpose in mind. Instead they were seen as a useful resource for hypotheses generation and discovery of new knowledge. This development gave a major impulse to the field of machine learning, and led to novel concepts such as ‘Knowledge Discovery from Databases’, ‘Data Mining’, and ‘Intelligent Data Analysis’, as addressed in an AIME keynote in 1999 [130]. Mining of biomedial data has become an important topic at AIME conferences. Pre-conference workshops on Intelligent Data Analysis in bioMedicine and Pharmacology (IDAMAP) were organized at AIME in 2003, 2005, 2007, 2009 and 2011 [www.idamap.org].

Image and signal processing has played a modest but sustained role throughout the history of AIME. These fields have a long tradition in biomedical informatics, and have changed dramatically over the years due to technological advances. As with many research themes that are covered at AIME conferences, biomedical image and signal processing also exist as independent fields with their own challenges, their own meetings, and their own journals. The work presented at AIME conferences is characterized by exploring the utility of specific AI methods for addressing methodological challenges.

Image processing first appeared at AIME in 1989 [131] and was addressed by a keynote presentation in 1991 [132]. The early 1990s were characterized by the rise of Magnetic Resonance Imaging (MRI), a technique which permits the three-dimensional visualization of tumors, lesions and abnormalities within the soft biological tissues of the body. MRI thus produces a wealth of data which is far more difficult to interpret than the traditional, two-dimensional X-ray image. Important analytical tasks are image segmentation and classification. Model-based approaches to segmentation and classification perform these tasks by matching a prespecified object model to the image data [132]. For instance, Kamber et al. [133] represented knowledge of the brainʼs anatomy as a probability model which provides prior probabilities of brain tissue distribution per unit voxel in a standardized three-dimensional ‘brain space’. Dameron et al. [134] described a reusable ontology of the brain cortex anatomy comprising both numeric and symbolic knowledge. In contrast, data-driven approaches use statistical methods or machine learning techniques. Neural networks are particularly popular here. For instance, Blonda et al. [135] used a self-organizing map for segmentation and a multilayer perceptron for classification of brain MRI. Alternatively, Kerhet et al. [136] used support vector machines to segment lung tumors in positron emission tomography (PET) scans.

An interesting line of work involving distributed and cooperative approaches to image segmentation and interpretation was presented over the years by the research group of C. Garbay [99,137–141]. Their multi-agent approach was later also integrated with classical methods for image segmentation which are based on Markov random fields [142].

Two other papers provide typical examples of the use of AI methods to solve image processing problems. Kókai et al. [102] used evolutionary algorithms to create a grammatical description of the blood circulation of the human retina, for microvascular monitoring of diabetic patients. Caicedo et al. [143] investigated a bag of features approach to image representation, using an analogy in which visual features are to images as words are to text documents. In their study, the bag of features is used to classify histopathology images with support vector machines, but it could also be used for image retrieval and analysis.

Also for signal processing the history of AIME has seen a division between symbolic, model-based approaches and numeric, data-driven approaches. Biomedical signal processing has traditionally focused on the analysis of electrocardiographic (ECG), electromyographic (EMG) and electroencephalographic (EEG) signals. Each of these signals has its own challenges. For instance, the ECG is strongly periodic and features the QRS complex as its main wave; Automatic QRS detection is an essential task of ECG detection. A typical model-based approach was presented by Bottoni et al. [144], who represent cardiologist knowledge used in the interpretation of ECGs by means of a system of conditional attributed rewriting rules. Typical data-driven approaches were presented by Schulz et al. [145], who use self-organizing maps for the interpretation of ECGs, and Portet et al. [146], who use a boosting method based on decision trees. A compromise between the model-based and the data-driven approach was presented by Kókai et al. [147], who use inductive logic programming for learning ECG waveforms, based on an attribute grammar specification of ECGs.

In recent years, physiological instruments that measure heart rate, blood pressure, oxygen saturation levels and other parameters have become so small and inexpensive that they can be used to measure continuously and everywhere instead of temporarily and only at the clinic. These devices are mostly used in chronic disease management and in health promotion. For instance, Palmerini et al. [148] used wearable accelerometry data to evaluate posture, gait, turning and different kind of transitions in Parkinsonʼs disease patients, and García-García et al. [149] investigated the use of statistical machine learning methods for automatic assessment of physical activity intensity from wearable accelerometry and heart rate monitors.

Advances in genomic and proteomic sequencing technology in the 1990s led to a tremendous growth of activity in the fields of bioinformatics and systems biology in these years. At AIME, the first papers on bioinformatics were seen in 2001, and the theme has steadily expanded thereafter. It is interesting to note though that the idea of automated reasoning on biotechnological data was discussed in the second edition of AIME by Cherubini et al. [150]. This specific topic became of crucial importance to the larger scientific community only 20 years later [151].

It is not surprising that the bioinformatics theme was picked up at AIME rather slowly, since the AI in medicine community has traditionally dealt with medical decision-making problems, while only in recent years bioinformatics approaches have become important to support clinical care. Moreover, bioinformatics is neither a single decision-making problem nor is referred to a single method, but it is rather a relatively broad scientific area.

Network biology, a crucial theme of current bioinformatics and computational biology research, was the topic of a keynote lecture during AIME 2003 [152]. In the same AIME edition Gamberger and Lavrac described an application of propositional inductive learning to the analysis of RNA microarrays data [153]. This kind of data has boosted research in data mining over the subsequent decade. Subsequent conferences featured papers on visual data mining approaches to analyze gene expression data [154]; learning causality in gene networks [155]; quality annotation of RNA microarrays data [156]; and various approaches to classification of gene expression microarrays [157–159].

Other papers in the bioinformatics theme addressed text mining strategies to extract functional relations, such as interactions between genes and proteins, from scientific literature [160,161]; the role of integrated IT systems in bioinformatics for handling the complex nature of scientific discovery [162]; the application of the select and test strategies to genome-wide association studies [163]; and transcriptional data analysis and information retrieval [30,164,165].

In summary, the interest of the AI in medicine community has been devoted to three main tracks: (i) the application of machine learning to prediction problem based on molecular data; (ii) the extraction of gene and protein networks from data and (iii) the application of text mining and information retrieval methods to the joint analysis of—omics and clinical literature. Some efforts have been devoted to automated reasoning, while few papers deal with other bioinformatics classical themes, such as prediction of protein structure.

Eight special issues of this journal with a selection of extended AIME papers have been published in this journal since 1998, containing a total of 55 papers (see the Appendix over for an overview of special issues). Table 4
                         shows the 25 papers of that have appeared in AIME proceedings or in AIME special issues with the highest number of yearly citations (according to Google Scholar or Thomson Reuterʼs Web of Science, as of May 1, 2014). We only included papers with 10 or more citations. For each paper both the absolute number of citations and the mean number of citations per year are reported.

Looking at the table and going back to the research themes identified previously, we can make a number of interesting observations.

First of all, papers that have been published in the special issues of Artificial Intelligence dominate the table; only two AIME papers [23,107] are listed. This is probably explained by the fact that bibliographic databases keep much better track of citations to journal publications than to publications in conference proceedings.

Second, the research theme of guidelines and protocols plays a most prominent role in the table, relating to seven papers [166–168,172,173,176], four of which are among the most highly cited. Yet while all these papers connect to this theme, they span a broad range of topics, such as representation of clinical processes and tasks [167], time-oriented clinical guidelines [166], workflow systems dealing with guideline management [168], NLP techniques for modeling clinical guidelines [172] and versioning methods for computer-interpretable guidelines [176].

Two other themes that appears throughout the table are the management of temporal information (six papers, [23,74,166,171,174,175]), and data mining and machine learning (seven papers, [113,126,161,170,171,175,178].

Third, most other research themes have a modest representation in the table, such as uncertainty reasoning [107,113,170]; image and signal processing [124,170]; case-based reasoning [92,93]; planning and scheduling [100]. Remarkably the theme of knowledge engineering, which accounts for 25% of all papers in AIME proceedings, is hardly present in Table 4. This is probably explained by the fact that the series of special issues started only in 1998, while this theme dominated the early days of AIME.

@&#DISCUSSION@&#

In this review we analyzed a total of 122 AIME session titles to create a taxonomy of 12 research themes and 30 research topics. We classified all 734 AIME conference papers published between 1985 and 2013 according to this taxonomy. We also counted the citations to these conference papers and to 55 special issue papers. Our analysis shows that AIME was dominated by knowledge engineering research in its first decade, while machine learning and data mining prevailed thereafter. A number of other research themes, such as ontologies and terminologies, natural language processing, guidelines and protocols, temporal information management, uncertainty management and image and signal processing, first appeared in the 1990s and have received a significant, constant attention since then. Distributed and cooperative systems, case-based reasoning, planning and scheduling and bioinformatics have played a relatively small role at AIME; but some of these themes, such as bioninformatics, are still growing.

The series of AIME conferences launched in the mid-1980s when the AI field was committed by an ideological debate between “symbolic”, knowledge-based and “subsymbolic”, numeric approaches. At the time, knowledge-based methods dominated AI in Medicine. While this debate belongs to the past, the dichotomy between knowledge-based approaches and data-driven approaches is still current. The former dominated the first decade of AIME, the latter was stronger thereafter. More recently, the two approaches are growing closer as large-scale ontologies have become available through the Web and are used as knowledge sources in data-driven discovery. As observed in Patel et al. [20], the evolution of AIME research themes confirms a growing interest in managing and exploring huge amounts of data and knowledge for clinical and research tasks. At the same, social and organizational aspects of healthcare have become more important in recent years, as illustrated by research on clinical practice guidelines, natural language processing and social media. Our analysis also confirms another development discussed by Patel et al. [20], the increasing interest in data mining and intelligent data analysis for decision support.

A number of research topics have been addressed occasionally at AIME meetings, but did not persist and were therefore not explicitly mentioned in this review. Examples are human factors engineering, cognitive models of clinical reasoning, decision theory and clinical decision making, clinical evaluation methods, integration of AI systems in practice, and methods for clinical audit. It would be erroneous to conclude that these topics are not relevant for AIME or, more generally, AI in medicine. But they are studied in-depth by other communities, many of which have also grown significantly over the last decades. It is a continuing challenge for both AIME and these sister communities to exchange ideas and novel developments.

@&#LIMITATIONS@&#

In this paper we provided a survey of the main research themes and trends represented within AIME conferences over three decades. Such a survey, performed by the methodology described in Section 2, has some intrinsic specificities and explicit limitations. First, we built the taxonomy and performed the classification with the implicit bias of our own scientific experience. However, we believe that the risk of bias was low as we derived our taxonomy largely from the session titles that were used at AIME conferences over the years. Therefore the taxonomy may be considered as a “joint” work with all the editors of the different AIME editions. Moreover, we consulted some well-known taxonomies from computer science, AI and informatics, to increase the soundness of our approach. Second, citations to AIME conference papers, especially from the early years, are not well captured by existing bibliographic databases. Therefore the impact analysis presented in Section 3.2 was probably a bit biased towards papers published in the series of special issues of this journal which has started in 1998. As a result, some of the research themes that prevailed during the first decade of AIME, such as knowledge engineering, are underrepresented in this analysis. Third, we would like to stress that citations are just one measure of scientific impact, and that they are subject to several sources of confounding such as the overall increase in scientific production over the years. Finally, each conference and scientific community tends to create its own “subculture”, and AIME is no exception to that rule. Therefore we cannot claim that our findings are representative for the entire AI in Medicine field. Yet we believe that they do reflect trends that have significance beyond AIME.

Based on the analysis of research themes presented we now sketch three research directions that we believe hold significant promise for the future of AIME research.

Big Data are driving a revolution in information and communication technology. Big Data methods are applied in diverse areas such as meteorology, finance, experimental physics, telecommunication, military surveillance and business informatics. Also the life and biomedical sciences are massively contributing to the Big Data revolution, due to uptake of electronic health record (EHR) systems in clinical practice, due to advances in genome sequencing technology and digital imaging, and because patients are now co-producing health-related data through mobile and wearable devices. Personalized medicine, which requires integration of “omics” data with clinical data, will require deep and interdisciplinary research efforts in several areas as data structures and indexing structures for the biomedical domain, distributed and parallel (bio-)computing, new data models and query languages for huge and heterogeneous biomedical datasets. Furthermore, other application areas such as the commercial domain have developed storage and analysis methods that seem mature enough to be moved to the biomedical domain, where some requirements are even more challenging. Among them we mention here temporal multidimensional OLAP analyses, temporal data warehouse design, temporal data mining and visual mining, integrated mining and analytic environments.

Clinical practice guidelines have been broadly accepted as tools for disseminating evidence from clinical studies and to support clinical decision making. This is unlikely to change in the near future. But guideline development, dissemination and implementation are still paper-based, manual and extremely laborious processes. At the same time new evidence is piling up faster and faster, and in increasingly larger volumes. With the broad adoption of EHR systems in clinical practice, there is ample opportunity to streamline the pathway from evidence production to clinical decision support. AI in Medicine will have to provide the tools and the methods.

Over the last decade business process and workflow modeling are receiving a lot of attention, both from theoretical researchers and from engineering work on tools and technologies. The medical domain is considered a major challenge for these technologies and methodologies, as it requires powerful and flexible systems able to properly manage different aspects, such as decision-based process management, temporal constraints, run-time schema changes, exception handling, seamless data and process integration, privacy and security issues and so on. In addition, there are interesting opportunities for cross-cutting research on tools for evidence based medicine and clinical process modeling.

In the area of NLP, there is a growing interest in the analysis and mining of the huge amount of documents produced by social media. Such documents contain often health related data, which are of a completely different kind than scientific documents, clinical texts and scientific terminologies. Here terms and sentences are often full of jargon, common terms, with possibly different (local) meanings. However, such new kind of information sources may be complementary with respect to more sound and acknowledged information and knowledge sources (including healthcare and medical records), in providing in a short time population health information and in supporting a very fast way of information sharing and communication. Several competencies and skills, not only technical, are needed to assign the right value and role to such kind of information in the healthcare and medicine domains. Among those, sophisticated and integrated research efforts in web information retrieval, web text parsing and interpretation, semistructured data analysis, and healthcare social network analysis will allow to put the design of web-based healthcare information systems on a solid ground.

@&#CONCLUSIONS@&#

In this paper, we reviewed 30 years of research in AI in Medicine through an analysis of research themes in AIME conferences, and an assessment of their scientific impact. Over these three decades, there has been a major shift from knowledge-based to data-driven methods. Within AIME, the interest for other research themes such as uncertainty management, image and signal processing, and natural language processing has been stable since the early 1990s. In terms of citations, the largest impact of AIME publications has been in guidelines and protocols, followed by temporal information management, and machine learning and data mining. Promising directions for future research are Big Data and personalized medicine, Evidence Based Medicine, business process modeling and process mining and NLP in social media.

AIME 2011

Artificial Intelligence in Medicine, Volume 57, Issue 2 (February 2013)

Edited by M. Peleg and C. Combi.

AIME 2009

Artificial Intelligence in Medicine, Volume 52, Issue 2 (June 2011)

Edited by Y. Shahar and C. Combi.

AIME 2007

Artificial Intelligence in Medicine, Volume 46, Issue 1 (May 2009)

Edited by R. Bellazzi and A. Abu-Hanna

AIME 2005

Artificial Intelligence in Medicine Volume 39, Issue 2 (February 2007)

Edited by S Miksch, J Hunter, and E Keravnou

AIME 2003

Artificial Intelligence in Medicine, Volume 34, Issue 1 (May 2005)

Edited by M. Dojat and E. Keravnou

AIME 2001

Artificial Intelligence in Medicine, Volume 29, Issues 1–2 (September–October 2003)

Edited by S. Quaglini

AIMDM ‘99

Artificial Intelligence in Medicine, Volume 20, Issue 1 (September 2000)

Edited by W. Horn

AIME ‘97

Artificial Intelligence in Medicine, Volume 14, Issues 1–2 (September–October 1998)

Edited by E. Keravnou

@&#REFERENCES@&#


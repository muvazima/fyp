@&#MAIN-TITLE@&#A novel feature extraction method based on late positive potential for emotion recognition in human brain signal patterns

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The use of stimulation strategy may help to enhance the emotion recognition from human brain signals.


                        
                        
                           
                           The late positive potential (LPP) was analyzed in order to select the features for emotion classification.


                        
                        
                           
                           The LPP based electroencephalography (EEG) features were selected under multiple frequency bands.


                        
                        
                           
                           The emotion classification was performed by using support vector machine (SVM) and k nearest neighbors (KNN).


                        
                        
                           
                           These findings offer experimental evidence that the LPP components may be possible features for emotion recognition.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

EEG pattern recognition

Late positive potential

EEG feature extraction

EEG emotion recognition

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Qualitative developments in the assistance given by human–machine interactions (HMI) have become an essential subject in the computing field [1]. Advancements in HMI now provide the means for users to improve the quality of their lives using intelligent systems. Emotion detection and understanding play critical roles in emotional intelligence. Several studies in affective computing have used visual stimuli to induce human emotions [2,3], whereby the subject may experience an emotional response while receiving a visual emotional stimulus. The emotional response corresponds to the subject's understanding of the current stimulus and situation [4,5]. Furthermore, several studies by cognitive scientists, neuroscientists, and psychologists have shown that emotion plays an important role in intelligent and rational thinking [6–8].

Although the emotional behavior of a subject can be analyzed by neurophysiological processing, emotion recognition is a sophisticated problem for which only simple statistical methods have been employed. Emotion classification using a combination of complex classifiers and event-related potential (ERP) features may help to improve the recognition rate. Recently, researchers have used classifiers with ERP features for emotion detection. These studies have focused only on a limited number of channels (anterior-posterior), early ERP amplitude, and few signal frequencies (delta, theta, and alpha). Although the emotion recognition rate >70%, the emotion recognition results were dependent on each arousal−valence coordinate [9,10].

EEG is a common noninvasive method for recording electrical activity in the human brain. EEG signals generate specific patterns according to the subject's states, such as valance, arousal, and concentration. Today, the emotion-based EEG feature extraction and classification of brain signal patterns have become interesting research topics. The EEG patterns generated from emotional tasks are also applicable. These patterns are useful for disabled people to express their emotions with the help of EEG-based brain−computer interface (BCI) systems. In addition, it has potential for application in a range of activities from ordinary human life to the needs of brain-disorder patients, including driving a car, controlling a cursor, playing a game, communicating with autistic patients, and so on [11].

In general, the implementation of EEG-based emotion recognition has great benefits, including, for example, producing signals from the central nervous system, low intrusiveness, and high temporal resolution. While emotion recognition methods perform effectively, there are several problems with respect to the HMI. For example, the machine must be capable of recognizing emotion in a noisy environment or the subject must be looking directly at the camera. The independent nervous system can be used to overcome the abovementioned issues. Currently, emotion recognition using EEG has been used in several studies and may overcome the problems associated with existing emotion recognition systems.

With these considerations, the most prominent techniques currently employ feature extraction methods such as common spatial patterns (CSP), wavelet transform, higher order crossings (HOC), event-related potential (ERP) amplitude, and statistical-based analysis. These methods typically use EEG features in the time and frequency domains, including gamma event-related dynamics (ERD), frequency bands, and ERP. The support vector machine (SVM) and k-nearest neighbor (KNN) seem to be the most common classifiers employed in these studies. Konstantinidis et al. 
                     [9], used the ERP components N100 and N200 for emotion recognition in the arousal−valence domain. Another study by Frantzidis et al. 
                     [10], proposed the P100, N100, P200, and P300 ERP components for emotion classification. Both of these studies extracted features from early components of ERP and their subjects were all adults. Frantzidis et al., presented a feature set that contained only three central electrodes (Cz, Fz, and Pz) and they used delta, theta, and alpha frequency filters for the EEG data. The SVM results obtained by Frantzidis et al., showed high accuracies of 85.71%, 85.71%, 71.43%, and 82.14% for high arousal and high valence (HAHV), high valence and low arousal (HVLA), low valence and high arousal (LVHA), and low valence and low arousal (LVLA), respectively. This method shows the emotion recognition for each coordinate separately in the arousal−valence model.

Despite the number of emotion recognition approaches to the classification process [9,10,12,13], more research is required to increase recognition accuracy and to determine unknown areas of emotional behavior in the human brain. In affective computing, one study used event-related properties as neural markers for the early detection of emotion [14], and introduced the LPP, which shows the response to emotional stimulus. Our previous study [15] also showed the great potential of adopting LPP-based features for emotion classification. However, there are missing features in the existing ERP-based feature extraction method [10] such as the beta and gamma frequency bands, EEG channels (from temporal and occipital brain regions), and classification in the arousal−valence domain. We propose a method of feature extraction that can recognize the combined set of emotions present in the arousal and valence domains, rather than the single coordinate in the arousal−valence domain of the IAPS. We propose emotion recognition for four emotions in the arousal−valence domain—happy, calm, sad, and scared. We also considered the EEG channels from all important brain regions, including the frontal, central, temporal, parietal, and occipital. Initially, the EEG signals were produced with a single-frequency filter and an output sampling rate of 128Hz. As such, the recorded EEG data contained a lot of noise from the wireless sensors and other environmental sources. Therefore, we chose to cut off the EEG data from 0 to 50Hz. Further, the proposed feature set includes the LPP features for each frequency band, i.e., delta, theta, alpha, beta, and gamma. This frequency domain analysis method helps to identify the optimal frequency band for the LPP features. Here we hypothesize that the LPP features from human brain signals may achieve better classification accuracy than previous methods. To the best of our knowledge, there have been no studies of the LPP feature extraction method for children's EEG-based emotion recognition. This study represents the first time implementation of a methodology for emotion classification based on a combination of LPP features.

The remainder of this paper is organized as follows. Section 2 provides background information on the EEG experiment settings, stimulation process, and preprocessing of the EEG data. The ERP analysis and the proposed method of feature extraction are described in Section 3. Section 4 contains our results and we discuss the experiment in Section 5. Finally, we present our conclusions in Section 6.

The goal of this stimulation experiment was to extract the features of various emotional responses from human subjects while they were given visual emotional stimuli. We used the IAPS database in this experiment, which was mainly developed in the arousal−valence domain for emotion-based experiments [16]. We separately define four emotion-related states as sad, scared, happy, and calm. On the basis of these ratings, we selected 180 pictures (45 pictures x 4 states) from equally distributed groups along the arousal−valence axes from the IAPS database.

For practical EEG applications, costs, placement, and connectivity are major factors to be considered as minimal. The EEG signals were recorded with the Emotiv-EPOC System. The sensors are polycarbonate and the device includes 14 electrodes with two reference channels that offer accurate spatial resolution. The device has an internal sampling rate of 2048Hz before filtering. The output sampling rate is 128 samples per second. We selected a 10/20 electrode placement, which is the most effective international standard for capturing reliable EEG recordings with the least number of electrodes [17]. The 10/20 EEG electrode placement is the commonly used standard by most researchers for EEG-based emotion recognition through audio and visual stimuli. This system is based on the relationship of different electrode positions located on the scalp and the primary side of the cerebral cortex [18]. Fig. 1
                      shows the 16 electrodes (AF3, F7, F3, FC5, T7, CMS, P7, O1, O2, P8, DRL, T8, FC6, F4, F8, and AF4), which were inserted for recording EEG signals. Average reference channels (CMS/DRL) were placed in the P3/P4 locations.

In this experiment, a total of 21 subjects (09 male and 12 female) participated. The subjects were students of the same school, aged from 12 to 14 years. They were informed of the purpose of our research and experiment, and each filled out a consent form after being briefly introduced to our research and the stages of visual simulation.

We recorded the EEG signals of each subject as the designated pictures were presented randomly for 1.5 s, interspersed with 0.5-s intervals showing a black image. The black image is used to release the subject's emotional feeling or brain activity generated by the previous stimulus. We also projected a fixation mark (cross) for 4.0 s exactly in the center of the screen to focus the attention of the subject toward his/her upcoming stimulus. Fig. 2
                      shows the timing diagram of this experiment, in which the total EEG-recording collection time was 368 s for each subject. This procedure was repeated separately for each subject.

The recorded EEG signal patterns were preprocessed using a toolbox called EEGLAB provided by SCCN Lab [20], which runs as a MATLAB plugin. This software includes various functionalities, including data retrieval, channel and event information management, and data visualization. In the preprocessing phase, we used ICA. We also manually rejected artifacts such as eye movements, muscle movements, bad channels, and eye blinks. Fig. 3
                     a shows some eye blinks through the frontal channels, which are marked with black boxes. During preprocessing, we easily removed these artifacts by applying our selected artifact rejection method, as shown in Fig. 3b. We adopted the newly developed band-pass filtering method pop_eegfiltnew() rather than the less effective EEGLAB method pop_eegfilt(). To reject artifacts, we processed the EEG data of all subjects through frequency filters from 0 to 50Hz. This method filters EEG signal data using a Hamming window [21].

We compared our EEG-based emotion recognition results using two existing feature extraction methods. These methods are based on statistical calculations and power-spectrum features in the frequency domain [22–24]. A statistical feature vector (FV) is composed of six kinds of features in the time domain. The frequency domain features are composed by processing the frequency bands in each epoch. We obtained five frequency and six time domain features, and obtained a total of 84 statistical features (14 channels x 6 statistical features). Similarly, we estimated 490 (5 frequencies x 14 channels x 7 sub-windows) features as frequency domain features. Wang et al., and other researchers implemented both of the above methods in different experimental environments. In our experimental settings, we also implemented and analyzed both existing feature extraction methods to compare their results with those of our proposed feature extraction method.

The primary goal of our research was to explore ERP-based features in emotion recognition from EEG brain signals. LPP is a type of ERP that indicates the attention paid by a subject to visual stimuli. Considering that different individuals have slightly different emotional response patterns to the same situation, each subject participating in the experiment reflected their own unique physiological responses for each affected state.


                     Fig. 4
                      shows the average ERP of all subjects between 0 to 50Hz. At the bottom of each image, the color legends show the different emotions. The horizontal axis is the timeline of each epoch and the vertical axis is the ERP amplitude. We used the ANAOVA method to compute the ERP, as displayed by the black box above the timeline of each chart, where p <0.01. AF3, AF4, F3, F7, F8, FC5, FC6, and T7 show the LPP values between 600 and 1000 milliseconds with p <0.01. The remaining channels (O1, O2, P7, and P8) show the LPP values between 300 and 600 milliseconds with p <0.01.


                     Fig. 4 shows the modulation of the grand average ERP amplitude of the four emotion-related interpretations. Before further analysis, it is important to observe the emotion regulation of a subject's emotional activity. Therefore, we first performed ERP analysis to verify the emotion regulation of all subjects. ERP analysis allows for the examination of the physiological behavior associated with a subject's emotion regulation. It shows the existence of LPP in the early, middle, and late windows in spatial-temporal resolution. The frontal region of the brain shows the middle-window LPP, which indicates the late emotion regulation or response from subjects while watching emotional stimuli. The occipital and parietal brain regions show the early window LPP, which corresponds to an early response from a subject to emotional stimuli. The existence of an LPP indicates emotional changes in spatial-temporal resolution. Therefore, we selected the LPP feature set for emotion recognition from brain signals.


                     Fig. 5
                      shows a diagram detailing the proposed EEG-based emotion recognition process. This system process flow diagram shows the single input connection containing the signals of the EEG brain device. The data preprocessing unit filters the signal's data through frequency filters from 0 to 50Hz. It includes five frequency filters—delta, theta, alpha, beta, and gamma. We applied the selected frequency filters to each brain signal separately. We also carried out ICA and manual artifact rejection during this process. The cleaned data was then forwarded to the feature extraction phase. We employed three kind of features: 1) the proposed three-LPP feature sets (early, middle, and late), 2) six statistical feature sets, and 3) five frequency-based feature sets. Further, we extracted these features from brain signals and processed them into the KNN (K=5) and SVM classifiers with 10-fold cross-validation. The classification process was performed using Waikato Environment for Knowledge Analysis (WEKA) software [25]. Both classifiers were trained and tested over the group of four emotions. We used the default settings available in WEKA for both classifiers.

The mathematical formulation of our proposed method describes the EEG-based feature extraction computation process as follows:

                        
                           (1)
                           
                              
                                 T
                                 
                                    (
                                    t
                                    )
                                 
                                 ∈
                                 
                                 
                                    R
                                    T
                                 
                                 
                                    {
                                    
                                       
                                          
                                             
                                                
                                                   R
                                                   T
                                                
                                                
                                                
                                                   denotes
                                                   
                                                   the
                                                   
                                                   vector
                                                   
                                                   of
                                                   
                                                   the
                                                   
                                                   time
                                                   
                                                   series
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                
                                                   of
                                                   
                                                   single
                                                   
                                                   electrode
                                                   
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   T
                                                   
                                                   is
                                                   
                                                   number
                                                   
                                                   of
                                                   
                                                   time
                                                   
                                                   samples
                                                   
                                                   in
                                                   
                                                   T
                                                
                                                
                                                   (
                                                   t
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                       
                                          
                                             
                                                t
                                                
                                                
                                                   represents
                                                   
                                                   single
                                                   
                                                   electrode
                                                   
                                                   and
                                                
                                                
                                                t
                                                :
                                                =
                                                
                                                   [
                                                   
                                                      1
                                                      ,
                                                      2
                                                      ,
                                                      …
                                                      ,
                                                      14
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                    
                                    }
                                 
                              
                           
                        
                     
                     
                        
                           (2)
                           
                              
                                 E
                                 p
                                 o
                                 c
                                 h
                                 M
                                 
                                    (
                                    
                                       subject
                                       ,
                                       T
                                       
                                          (
                                          t
                                          )
                                       
                                       ,
                                       e
                                       c
                                    
                                    )
                                 
                                 =
                                 extract
                                 E
                                 p
                                 o
                                 c
                                 
                                    h
                                    
                                       t
                                       =
                                       1
                                       ,
                                       
                                       subject
                                       =
                                       1
                                    
                                    
                                       
                                          
                                             
                                                14
                                             
                                          
                                       
                                       ,
                                       
                                       21
                                    
                                 
                                 
                                    (
                                    
                                       subject
                                       ,
                                       T
                                       
                                          (
                                          t
                                          )
                                       
                                    
                                    )
                                 
                              
                           
                        
                     where, “ec” is an epoch counter that corresponds to 180 epochs of the four emotions for each “subject.” The method “extractEpoch” returns the matrix “EpochM” of all channels 
                        
                           T
                           (
                           t
                           )
                        
                      with the epoch length (stimulus-time x sample-rate). If we consider the case of a single subject, we compute the frequency band filtering by passing the raw signals of each epoch “
                        
                           E
                           p
                           o
                           c
                           h
                           M
                           (
                           
                              subject
                              ,
                              T
                              (
                              t
                              )
                              ,
                              e
                              c
                           
                           )
                        
                     ” into the following computational process. The method “computeFreq” generates a matrix “
                        E
                     ”of similar size for the current epoch of a given subject:

                        
                           (3)
                           
                              
                                 
                                    E
                                    
                                       f
                                       r
                                    
                                 
                                 
                                    (
                                    
                                       subject
                                       ,
                                       
                                       T
                                       
                                          (
                                          t
                                          )
                                       
                                       ,
                                       
                                       e
                                       c
                                    
                                    )
                                 
                                 =
                                 
                                 c
                                 o
                                 m
                                 p
                                 u
                                 t
                                 e
                                 F
                                 r
                                 e
                                 
                                    q
                                    
                                       f
                                       r
                                       =
                                       1
                                    
                                    6
                                 
                                 
                                    (
                                    
                                       E
                                       p
                                       o
                                       c
                                       h
                                       M
                                    
                                    )
                                 
                              
                           
                        
                     
                     
                        
                           (4)
                           
                              
                                 f
                                 r
                                 ∈
                                 
                                    {
                                    
                                       
                                          
                                             
                                                δ
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      0.5
                                                      ,
                                                      
                                                      4
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                θ
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      4
                                                      ,
                                                      
                                                      8
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                α
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      8
                                                      ,
                                                      
                                                      13
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                β
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      13
                                                      ,
                                                      
                                                      30
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                γ
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      30
                                                      ,
                                                      
                                                      50
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   =
                                                   Γ
                                                
                                             
                                          
                                          
                                             
                                                
                                                   [
                                                   
                                                      δ
                                                      ,
                                                      
                                                      θ
                                                      ,
                                                      
                                                      α
                                                      ,
                                                      
                                                      β
                                                      ,
                                                      
                                                      γ
                                                   
                                                   ]
                                                
                                             
                                          
                                       
                                    
                                    }
                                 
                              
                           
                        
                     where, “fr” has six different types of frequency settings. Furthermore, four types of LPP features are described in the following equations:

                        
                           (5)
                           
                              
                                 V
                                 
                                    (
                                    
                                       e
                                       c
                                       ,
                                       
                                       i
                                       ,
                                       
                                       k
                                    
                                    )
                                 
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             
                                                L
                                                P
                                                
                                                   P
                                                   e
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      
                                                         r
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         6
                                                      
                                                      
                                                         (
                                                         
                                                            E
                                                            i
                                                         
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                
                                                or
                                             
                                          
                                       
                                       
                                          
                                             
                                                L
                                                P
                                                
                                                   P
                                                   m
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      
                                                         r
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         6
                                                      
                                                      
                                                         (
                                                         
                                                            E
                                                            i
                                                         
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                
                                                or
                                             
                                          
                                       
                                       
                                          
                                             
                                                L
                                                P
                                                
                                                   P
                                                   l
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      
                                                         r
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         6
                                                      
                                                      
                                                         (
                                                         
                                                            E
                                                            i
                                                         
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                
                                                or
                                             
                                          
                                       
                                       
                                          
                                             
                                                L
                                                P
                                                
                                                   P
                                                   
                                                      (
                                                      
                                                         e
                                                         ,
                                                         m
                                                         ,
                                                         l
                                                      
                                                      )
                                                   
                                                
                                                
                                                   (
                                                   
                                                      f
                                                      
                                                         r
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         6
                                                      
                                                      
                                                         (
                                                         
                                                            E
                                                            i
                                                         
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                
                                                or
                                             
                                          
                                       
                                    
                                    }
                                 
                              
                           
                        
                     
                     
                        
                           (6)
                           
                              
                                 L
                                 P
                                 
                                    P
                                    k
                                 
                                 ∈
                                 
                                    {
                                    
                                       
                                          
                                             [
                                             
                                                L
                                                P
                                                
                                                   P
                                                   e
                                                
                                             
                                             ]
                                          
                                          
                                             300
                                          
                                          600
                                       
                                       ,
                                       
                                       
                                          
                                             [
                                             
                                                L
                                                P
                                                
                                                   P
                                                   m
                                                
                                             
                                             ]
                                          
                                          
                                             600
                                          
                                          1000
                                       
                                       ,
                                       
                                       
                                          
                                             [
                                             
                                                L
                                                P
                                                
                                                   P
                                                   l
                                                
                                             
                                             ]
                                          
                                          
                                             1000
                                          
                                          1500
                                       
                                       ,
                                       
                                       
                                          [
                                          
                                             L
                                             P
                                             
                                                P
                                                e
                                             
                                             ,
                                             
                                             L
                                             P
                                             
                                                P
                                                m
                                             
                                             ,
                                             
                                             L
                                             P
                                             
                                                P
                                                l
                                             
                                          
                                          ]
                                       
                                    
                                    }
                                 
                              
                           
                        
                     where, “k” represents the type of LPP from the given set of options in Eq. (6). Eq. (5) computes the single-feature vector for the selected LPP type (LPPk
                     ) for every filtered epoch (
                        
                           
                              E
                              
                                 f
                                 r
                              
                           
                           
                              (
                              
                                 subject
                                 ,
                                 
                                 T
                                 (
                                 t
                                 )
                                 ,
                                 
                                 e
                                 c
                              
                              )
                           
                        
                     ). As described by Eq. (4), we employed six types of frequency bands (
                        
                           delta
                           =
                           δ
                           ,
                           
                           
                           theta
                           =
                           θ
                           ,
                           
                           
                           alpha
                           =
                           α
                           ,
                           
                           beta
                           =
                           β
                           ,
                           
                           
                           gamma
                           =
                           γ
                           ,
                           
                           (
                           
                              δ
                              ,
                              
                              θ
                              ,
                              
                              α
                              ,
                              
                              β
                              ,
                              
                              γ
                           
                           )
                           =
                           =
                           Γ
                        
                     ) in this study. Eqs. (5) and (6) define the four kinds of LPP, which are further explained in Fig. 6
                     , showing the proposed feature sets for the emotion classification. The selected LPP windows are denoted by  LPPe, LPPm
                     , LPPl
                     , and 
                     LPP
                     (e, m, l), which correspond to the early, middle, late, and combined-LPP windows, respectively. We can extract 24 kinds of feature vectors by combining the abovementioned LPPs and frequency bands. The selected LPP windows then extract the data samples for 300 to 600, 600 to 1000, and 1000 to 1500 milliseconds of the early, middle, and late LPPs, respectively.

@&#RESULTS@&#

In the classification process, the dataset was comprised of 180 (45 instances x 4 emotions) instances in total, where each instance corresponds to a single emotional class. In Section 3 above, we described the possible feature sets proposed in this paper, which total 24. Visualizations of the emotion classification are shown in Figs. 7
                     b and c, in the form of bar charts describing the averaged emotion recognition accuracy of all subjects. The average results show the four LPP combinations at six different frequency bands, and Fig. 7a gives the chart legends for the four LPP combinations. Each LPP type is represented by a different color, including gray, dark gray, black, and white for  LPP
                     (e, m, l),  LPPe
                     , LPPm
                     , and 
                     LPPl
                     , respectively. For the KNN case, the emotion recognition accuracy of LPP
                     (e, m, l) is maximum at the ₣, α, and β frequencies. Similarly, the LPPe
                      shows better accuracy at the δ and θ frequency bands. LPPm
                       appears only once at the maximum rate of emotion recognition in all cases. For the SVM case, the LPPm
                       shows maximum accuracy at the ₣, α, β, and γ frequency bands. The  LPP
                     (e, m, l)  feature set yields better accuracy only at δ and  LPPm
                       yielded a maximum rate at the θ frequency band. Figs. 7b and c show the average classification results of the proposed method using the KNN and SVM classifiers, respectively, and both figures show the accuracy of emotion recognition for the four LPP windows and six frequency combinations. The overall accuracy of emotion recognition is almost the same in all cases. Also, the average recognition rate of all subjects is 55% and 58% for KNN and SVM, respectively. The feature set extracted at LPPe
                      shows the best emotion recognition rate at the theta and alpha bands for both KNN (56.2%) and SVM (57.9%), respectively.


                     Fig. 8
                      shows the emotion recognition of the proposed features using the KNN and SVM classifiers for all subjects, separately, and the KNN and SVM results are shown in the 2nd and 3rd column, respectively. The 1st column indicates the subject identification number. The emotion recognition rate for all subjects is similar for the SVM case, but we can see differences in the accuracy rates of all subjects for the KNN case.

@&#DISCUSSION@&#

Having implemented existing statistical [22–24] and frequency domain [22] feature methods, the need for a statistical feature vector was highlighted and then proposed. This statistical feature vector (Sfv
                     ) is composed of six different kinds of time-domain features, denoted as Tμ, Tσ, Tϻ, Tʮ, TÆ, Tη
                     , and T
                     
                        
                           
                        
                     , which correspond to the mean of the raw signal, standard deviation of the raw signal, mean of the absolute values of the 1st differences of the raw signal, mean of the absolute values of the 2nd differences of the raw signal, mean of the absolute values of the 1st differences of the normalized signals, and the mean of the absolute values of the 2nd differences of the normalized signals, respectively. The frequency domain features are based on the power spectrum of each of the 192-point EEG epochs. First, the data for each EEG epoch is processed with a Hamming window, and then the processed epoch is further subdivided into several sub-windows. We used the Hamming window again to construct sub-windows for each of the 48 points with 24 point steps. Lastly, we extracted the log power spectrum in each of the frequency bands— delta, theta, alpha, beta, and gamma—denoted by Fδ, Fθ, Fα, Fβ, Fγ, and F
                        
                           
                        
                     , respectively. These frequency domain features form a frequency feature vector (Ffv
                     ). After these calculations, we obtained six time domains and five frequency features. The dimension of each feature is dependent on the number of EEG channels. There are a total of 84 statistical features (14 channels x 6 statistical features). Similarly, we estimated 490 (5 frequencies x 14 channels x 7 sub-windows) features as frequency domain features.

This benchmark provides a means for comparative analysis of the feature extraction methods. Fig. 9
                      shows a comparative view of the emotion recognition for all feature sets using the KNN and SVM classifiers. This comparison chart illustrates the average accuracy of all implemented features and on the horizontal axis is the color bar of each. The emotion recognition rate of both classifiers is shown on the vertical axis. On the x-axis, the proposed feature extraction methods are categorized as statistical (Tμ, Tσ, Tϻ, Tʮ, TÆ, Tη
                     , and T
                     
                        
                           
                        
                     ), frequency-domain (Fδ, Fθ, Fα, Fβ, Fγ, and F
                        
                           
                        
                     ), and LPP-based (LPPl, LPPm, LPP(e, m, l), LPPe) techniques. Further, we sorted the feature sets by their accuracy rate results from low to high. For KNN in Fig. 9a, the LPP(e, m, l) feature set shows the maximum accuracy in the group of our proposed LPP-based feature sets, but this is slightly lower than the two frequency-domain features (Fθ and Fα). Fig. 9b shows the emotion recognition rate of our proposed LPP-based feature sets (LPPl, LPPm, LPP(e, m, l), LPPe) which proves its superior emotion classification accuracy in the group of all feature sets.

Lastly, the proposed LPP-based approach is proved to yield higher accuracy while classifying the four selected emotions in the arousal−valence domain using the SVM classifier. Wang et al., and other researchers have implemented both of the above methods in different experimental environments. We implemented and analyzed both of the existing feature extraction methods in our experimental settings in order to compare them with our proposed feature extraction method. Fig. 9 shows the emotion recognition performance of all the time domain-, frequency domain- and power spectrum- based approaches. We can confirm the hypothesis of this paper of the potential for using late positive potential as a neural marker in affective computing. Furthermore, the proposed LPP-based features may help to increase the accuracy rate of emotion recognition using EEG brain signals.

@&#CONCLUSION@&#

In this paper, we proposed a novel EEG feature extraction method for emotional stimuli (i.e., happy, calm, sad, and scared). We employed the LPP-based feature extraction method since it can efficiently represent the event-related properties of EEG signals. Our proposed method extracts the LPP-based features from EEG signals by band-pass filtering over all EEG channels, separately. We extracted these features after applying the ERP method in MATLAB. Furthermore, we used the KNN and SVM classifiers for the emotion classification of all these feature sets, separately. We also implemented a benchmark, which includes the existing feature extraction methods and our proposed method. The proposed feature set was extracted at the early LPP, which had shown the best emotion recognition rate at the theta and alpha bands for KNN (56.2) and SVM (57.9), respectively. Based on our results, we can conclude that EEG features from the early LPP at the theta and alpha frequency bands may be an optimal choice for emotion recognition. We plan to explore more feature combinations with more emotional classes. We also recommend that results be examined for a larger number of subjects in a future experiment.

@&#ACKNOWLEDGMENT@&#

This work was supported by a grant from the National Research Foundation of Korea (NRF), funded by the Korean government (MEST) (No. 2012R1A2A2A03).

@&#REFERENCES@&#


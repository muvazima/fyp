@&#MAIN-TITLE@&#2D-gel spot detection and segmentation based on modified image-aware grow-cut and regional intensity information

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel approach for 2D-gel image spot detection and segmentation.


                        
                        
                           
                           The segmentation process includes a grow-cut approach with a custom update rule that takes into consideration the inherent characteristics of 2D-gel images.


                        
                        
                           
                           Real and synthetic 2D-gel images containing a total of more than 20,000 protein spots are used for qualitative and quantitative evaluation.


                        
                        
                           
                           Better detection and segmentation performance than state-of-the-art methods.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Segmentation

Proteomicss

2D-gel electrophoresis

@&#ABSTRACT@&#


               
               
                  Background
                  Proteomics, the study of proteomes, has been increasingly utilized in a wide variety of biological problems. The Two-Dimensional Gel Electrophoresis (2D-PAGE) technique is a powerful proteomics technique aiming at separation of the complex protein mixtures. Spot detection and segmentation are fundamental components of 2D-gel image analysis but remain arduous and difficult tasks. Several software packages and academic approaches are available for 2D-gel image spot detection and segmentation. Each one has its respective advantages and disadvantages and achieves a different level of success in dealing with the challenges of 2D-gel image analysis. A common characteristic of the available methods is their dependency on user intervention in order to achieve optimal results, a process that can lead to subjective and non-reproducible results. In this work, the authors propose a novel spot detection and segmentation methodology for 2D-gel images.
               
               
                  Methods
                  This work introduces a novel spot detection and spot segmentation methodology that is based on a multi-thresholding scheme applied on overlapping regions of the image, a custom grow-cut algorithm, a region growing scheme and morphological operators. The performance of the proposed methodology is evaluated on real as well as synthetic 2D-gel images using well established statistical measures, including precision, sensitivity, and their weighted measure, F-measure, as well as volumetric overlap, volumetric error and volumetric overlap error.
               
               
                  Results
                  Experimental results show that the proposed methodology outperforms state-of-the-art software packages and methods proposed in the literature and results in more plausible spot boundaries and more accurate segmentation. The proposed method achieved the highest F-measure (94.8%) for spot detection and the lowest volumetric overlap error (8.3%) for the segmentation process.
               
               
                  Conclusions
                  Evaluation against state-of-the-art 2D-gel image analysis software packages and techniques proposed in the literature, including Melanie 7, Delta2D, PDQuest and Scimo, demonstrates that the proposed approach outperforms the other methods evaluated in this work and constitutes an advantageous and reliable solution for 2D-gel image analysis.
               
            

@&#INTRODUCTION@&#

In recent years, proteomics, i.e. the study of proteomes under different conditions, has been increasingly utilized for revealing the complex processes of cells [1]. Some key opportunities offered by the field of proteomics are the evaluation of new drugs and the exploration of biological events [2–6]. The Two-Dimensional Polyacrylamide Gel Electrophoresis (2D-PAGE) technique is a powerful technique in proteomics aiming at protein separation and identification and has been widely used due to its ability to separate thousands of proteins on polyacrylamide gels. This is achieved using isoelectric focusing and sodium dodecyl sulfate polyacrylamide gel electrophoresis that allows for protein separation according to the differences in their net charge and their molecular mass [7–10]. Results are then visualized into a digital image that can contain thousands of protein spots. In a 2D-gel electrophoresis experiment the aim of 2D-gel image analysis is the rapid identification of: (a) proteins located on a single gel and (b) differentially expressed proteins between samples from a series of 2D-gels.

2D-gel image analysis can be summarized into four main stages: (1) spot detection, (2) spot segmentation, (3) spot quantification and (4) image alignment. The objective of the first three stages is to detect the number of pixels that belong to protein spots in order to quantify the protein expression levels. The fourth stage is performed in order to match the corresponding protein spots from different images. Two different workflows for 2D-gel image analysis can be followed [11,12]. In the straightforward workflow, spot detection and segmentation are performed prior to image-alignment [13,14]. In the workflow followed by the Delta2D [15] and Progenesis Samespots [16] software tools, image-alignment is applied prior to spot detection and segmentation. The characteristics of 2D-gel images make spot detection and segmentation a very challenging task. 2D-gel images may contain thousands of spots that exhibit great variety in intensity, size and shape. Spots can be so poorly contrasted that they are not clearly visible and adjacent spots can often be highly overlapped. Furthermore, the overall quality of these images suffers due to artifacts, inhomogeneous background and high levels of noise [17].

Due to the importance of 2D-gel image analysis, many commercial software solutions have been developed [12]: e.g. PDQuest [18], DeCyder 2D [19], Melanie 7 [20], ImageMaster 2D [21], Delta2D [15] and Progenesis Samespots [16]. Each software has its respective advantages and disadvantages and achieves a different level of success in dealing with the challenges of 2D-gel image spot detection and segmentation [12,22]. An important observation is that all these software tools are dependent on manual parameter tuning, thus requiring human intervention that can lead to subjective results. Moreover, the most common problems in their results are that they may: (1) segment overlapping spots as one single spot, (2) over-segment a single spot into more, (3) fail to detect some spots, (4) mistake artifacts for spots and (5) incorrectly approximate the spot boundaries. The accumulation of all these errors alters the extracted protein expression levels, thus leading to erroneous biological conclusions. This problem is addressed by extensive manual editing of the results, which is a time-consuming process that requires an average of 1 to 4 man-hours per gel [23]. Human intervention leads to subjective and non-reproducible results and limits the throughput of the analysis process. As a result, the development of an automated 2D-gel image analysis method would be of utmost importance since it would allow for high throughput analysis of the expression levels of thousands of proteins, and would lead to safer, objective and reproducible biological conclusions.

Many researchers have tried to address the challenges of 2D-gel image analysis. Based on the assumption that the shape of protein spots follows a Gaussian distribution, Yoon et al. [24] proposed the Reversible Jump Markov Chain Monte Carlo (RJMCMC) method for separating overlapping spots and enhancing the weaker spots. RJMCMC can be very time consuming and due to the original assumption it underperforms in cases of images with many non-Gaussian shaped spots. Morris et al. [25] proposed “Pinnacle”, a method for spot detection and quantification. Pinnacle's spot detection is performed on a denoised average image of a properly aligned 2D-gel image set and is achieved by detecting local minima (“pinnacles”) on the denoised average image and combining them within a defined proximity. Pinnacle's main advantage lies on detecting overlapping spots [25]. Nevertheless, it occasionally results in detecting spurious spots, i.e. false positive spots [26]. Li et al. [27] proposed “RegStatGel”, a method that is also performed on an average image of a properly aligned 2D-gel set and incorporates the watershed algorithm [28] for spot segmentation. Its main drawback is that it underperforms in splitting overlapping spots [26]. Based on morphological operations, Mylona et al. [29] proposed a method for spot detection that achieves increased performance in detecting overlapping spots at the expense of occasionally missed spots. Dos Anjos et al. [14] proposed “Scimo”, a spot segmentation and quantification method that is also based on the watershed algorithm and achieves a more realistic estimation of close proximity spots, as well as partially overlapping non-saturated spots. However, the authors make the assumption that each basin of the watershed contains only one protein spot. This assumption is not always valid in case of major overlapping. An active contour-based method [13] has also been proposed for 2D-gel image segmentation but requires empirical adjustment for a large number of parameters for different image datasets, a process that is lengthy and time-consuming, as described in [13]. Kostopoulou et al. [30] proposed an effective spot detection and segmentation approach based on 2D histograms and 3D spot morphology. Although effective, this approach suffers from a high computational complexity. Zacharia et al. [31] proposed a spot detection approach based on multidirectional texture and spatial intensity information, but is not capable of segmentation.

In this paper, the authors present a novel approach for 2D-gel image spot detection and segmentation. The proposed detection approach is based on a multi-thresholding scheme applied on overlapping regions of the image. For the segmentation process, the proposed method combines a grow-cut algorithm [32] that utilizes a custom update rule, with a region growing approach and morphological operators. The proposed detection and segmentation methodology is evaluated against three commercial packages, Delta2D [15], PDQuest [18] and Melanie 7 [20] as well as against the recently proposed method: “Scimo” [14]. Two datasets of real and synthetic 2D-gel images containing a total of approximately 20,400 spots was used for the experimental evaluation. Experimental results demonstrate the efficiency of the proposed method in detecting and segmenting spots on 2D-gel images.

The rest of this paper is organized in three sections. A thorough description of the proposed methodology is provided in Section 2. The experimental evaluation procedure and results are presented in Section 3, whereas conclusions are drawn in Section 4.

@&#METHOD@&#

The proposed approach is divided in two stages: (1) spot detection and (2) spot segmentation.

The spot detection algorithm's steps are summarized in Table 1
                        .

The initial step for spot center detection is the exclusion of image areas that are not likely to include spot centers. In order to address the problem of uneven intensity values among spot and background regions and the insufficiency of a global threshold to detect regions containing spot centers, the image I is processed locally. The algorithm starts by splitting I into overlapping windows W
                           
                              i
                           , and tiled windows 
                              
                                 
                                    
                                       W
                                       ′
                                    
                                    i
                                 
                                 ,
                                  
                                 i
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                              
                            of size d
                           ×
                           d and d′×
                           d′, respectively, as illustrated in Fig. 1a. Then T
                           
                              i,j
                           
                           =1, …, l, …, h, …, M thresholds are obtained automatically for each W
                           
                              i
                            by using the multiple Otsu thresholding technique [33]. The pixels inside 
                              
                                 
                                    W
                                    i
                                    '
                                 
                              
                            are divided into clusters based on the automatically estimated local thresholds. More specifically, two local thresholds T
                           
                              i,l
                            
                           and T
                           
                              i,h
                            (T
                           
                              i,l
                           
                           <
                           T
                           
                              i,h
                           
                           <
                           T
                           
                              i,M
                           ) are introduced for each W
                           
                              i
                           : A low threshold T
                           
                              i,l
                            such that pixels whose intensity values are less than T
                           
                              i,l
                            are classified as belonging to the background (B
                           
                              i
                           ) and a high threshold T
                           
                              i,h
                            such that pixels whose intensity values are larger than T
                           
                              i,h
                            are classified as pixels belonging to the foreground (F
                           
                              i
                           ). B
                           
                              i
                            and F
                           
                              i
                            are sets containing the background and the spot (foreground) pixels, respectively. The pixels with intensity between the two thresholds may belong to either spot or background regions. An example tiled window of I is illustrated in Fig. 1b whereas the result of clustering with the M
                           +1 thresholds and the two thresholds (T
                           
                              i,l
                           , T
                           
                              i,h
                           ) is illustrated in Fig. 1c and d, respectively. This overlapping-tiled framework minimizes the likelihood of selecting wrong thresholds as it takes into consideration the intensities of pixels located around each tiled window 
                              
                                 
                                    
                                       W
                                       ′
                                    
                                    i
                                 
                              
                           , and enables the characterization of pixels that belong to more than one overlapping window.

The pixels belonging to the set 
                              
                                 
                                    U
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    F
                                    i
                                 
                                 ,
                                  
                                 i
                                 =
                                 1,2
                                 ,
                                 …
                                 ,
                                 N
                                 ,
                              
                            that correspond to local intensity maxima, are selected as candidate spot centers. An example of candidate spot centers is shown in Fig. 2a with black color. As one may observe, some spots may contain multiple candidate spot centers that are located either near their center or near their boundary. In order to select one pixel among the candidates as spot center, the candidate spot centers are (a) filtered by spatial intensity information and (b) merged depending on their distance.

Let s be a spot center candidate, V
                           
                              s
                            a small rectangular region of size a
                           ×
                           a around it and BN
                           
                              s
                            the binary image resulting from the application of a local thresholding technique [34] in V
                           
                              s
                           . If the Euclidean distance among s and its nearest pixel classified as background in BN
                           
                              s
                            is less than k then s is excluded from the spot center candidates. Then the Euclidean distance among spot center candidates is computed and those with a pairwise proximity less than the minimum allowed distance k are merged. If the minimum allowed distance k is set too small then several spot centers might be detected on a single spot. On the other hand, if k is set too large, then overlapping spots might not be separated. An example of the set S
                           
                              i
                            of spot centers for a window W
                           
                              i
                            after the two elimination procedures is illustrated in Fig. 2b. The final set S containing all the spot centers of the image is defined as 
                              
                                 S
                                 =
                                 
                                    U
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    S
                                    i
                                 
                                 ,
                                  
                                 i
                                 =
                                 1,2
                                 ,
                                 …
                                 ,
                                 N
                                 .
                              
                           
                        

Typical values for the parameters of the spot detection algorithm are presented in Section 3.1. Those parameter values were experimentally determined using various 2D-GE image datasets and were kept constant in all our experiments. As it is demonstrated in the results section, these parameter values efficiently work on 2D-GE images from a wide variety of sources. The value of d is dependent on d′ and was experimentally determined as d
                           =
                           d′
                           +2·⌈d′/8⌉. In effect, the larger the tiled windows are, the larger the overlapping windows around them will be. The number of tiled windows N for an image of size Width×Height can be determined from d′ as N
                           =⌈Width/d′⌉·⌈Height/d′⌉. Moreover, an evaluation of the sensitivity of the proposed method on the number of overlapping windows showed that the proposed approach exhibits significant performance stability to variations of the size of the overlapping windows, as explained in Section 3.5.

The steps of the segmentation algorithm that are described in the following paragraphs are summarized in Table 2
                        .

For the segmentation process, the proposed methodology requires the selection of seed pixels that are predefined as spot or background pixels. Let B and F be the sets containing the background and spot seed pixels of image I, respectively. B and F are determined from the previous multithresholding step using the following equations:
                              
                                 (1)
                                 
                                    
                                       B
                                       =
                                       {
                                       p
                                       :
                                       (
                                       p
                                       ∈
                                       I
                                       )
                                       ∧
                                       (
                                       p
                                       ∈
                                       
                                          
                                             W
                                             ′
                                          
                                          i
                                       
                                       )
                                       (
                                       ∧
                                       (
                                       p
                                       ∈
                                       
                                          W
                                          i
                                       
                                       )
                                       ∧
                                       [
                                       I
                                       (
                                       p
                                       )
                                       <
                                       
                                          T
                                          
                                             i
                                             ,
                                             l
                                          
                                       
                                       ]
                                       }
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       F
                                       =
                                       {
                                       p
                                       :
                                       (
                                       p
                                       ∈
                                       I
                                       )
                                       ∧
                                       (
                                       p
                                       ∈
                                       
                                          
                                             W
                                             ′
                                          
                                          i
                                       
                                       )
                                       ∧
                                       (
                                       p
                                       ∈
                                       
                                          W
                                          i
                                       
                                       )
                                       ∧
                                       [
                                       I
                                       (
                                       p
                                       )
                                       >
                                       
                                          T
                                          
                                             i
                                             ,
                                             h
                                          
                                       
                                       ]
                                    
                                 
                              
                           where I(p) is the intensity value of pixel p, i
                           =1, …, N and h
                           =2·l.

The next step of the proposed methodology is the application of the grow-cut [32] segmentation algorithm. Grow-cut [32] is a segmentation algorithm based on Cellular Automata 
                           [35], that can segment grayscale or multichannel images into regions belonging to multiple classes. The grow-cut algorithm is a relatively simple algorithm that can efficiently segment a wide range of images and can be initialized with a large number of seed pixels. Moreover, it has been successfully utilized in a wide variety of applications including brain tumor segmentation [36], IVUS lumen segmentation [37], region-based medical image retrieval [38], tumor segmentation [39], cDNA microarray image segmentation [40], etc.

A triplet 
                              
                                 (
                                 
                                    l
                                    p
                                 
                                 ,
                                 
                                    θ
                                    p
                                 
                                 ,
                                 
                                    
                                       C
                                       →
                                    
                                    p
                                 
                                 )
                              
                            represents each pixel p of the image, where l
                           
                              p
                            is the class label of p, θ
                           
                              p
                            takes values inside [0, 1] and is a measure of certainty that p should be labeled as l
                           
                              p
                           , and 
                              
                                 
                                    
                                       C
                                       →
                                    
                                    p
                                 
                              
                            is a multidimensional vector containing the intensity of pixel p at each channel for multichannel images or 
                              
                                 
                                    
                                       C
                                       →
                                    
                                    p
                                 
                              
                            is equal to the intensity of p in case of grayscale images. A θ
                           
                              p
                            equal to 1 denotes that the label assigned to p cannot be altered, whereas θ
                           
                              p
                           
                           <1 indicates that l
                           
                              p
                            may change during the progress of the algorithm. At the end of the grow-cut algorithm, all the pixels of the image should be assigned with one of the possible labels. Initially, l
                           
                              p
                            for all pixels is set to “Undefined” and θ
                           
                              p
                            to 0. The user provides the initial pixel seeds by setting their l
                           
                              p
                            and θ
                           
                              p
                           . Then, the following steps are iterated until a label has been assigned to all pixels: g(q
                           
                              an
                           ) is computed for each pixel p and its adjacent neighbors q
                           
                              an
                            (an
                           =1, …, 8). g(q
                           
                              an
                           ) is a function bounded to [0,1], defined as:
                              
                                 (3)
                                 
                                    
                                       g
                                       (
                                       
                                          q
                                          
                                             a
                                             n
                                          
                                       
                                       )
                                       =
                                       1
                                       −
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               C
                                                               →
                                                            
                                                            p
                                                         
                                                         −
                                                         
                                                            
                                                               C
                                                               →
                                                            
                                                            
                                                               
                                                                  q
                                                                  
                                                                     a
                                                                     n
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                2
                                             
                                          
                                          
                                             max
                                             
                                                
                                                   
                                                      
                                                         C
                                                         →
                                                      
                                                   
                                                
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 max
                                 
                                    
                                       
                                          
                                             C
                                             →
                                          
                                       
                                    
                                    2
                                 
                              
                            is the maximum value an element of 
                              
                                 
                                    
                                       C
                                       →
                                    
                                    p
                                 
                              
                            can take. For example, for an image with three channels and L bit depth per channel, 
                              
                                 max
                                 
                                    
                                       
                                          
                                             C
                                             →
                                          
                                       
                                    
                                    2
                                 
                                 =
                                 
                                    2
                                    L
                                 
                                 −
                                 1
                              
                           . Then, λ(q
                           
                              an
                           ) is computed for all q
                           
                              an
                            with lq
                           
                              an
                           
                           ≠“Undefined” and is defined as:
                              
                                 (4)
                                 
                                    
                                       λ
                                       (
                                       
                                          q
                                          
                                             a
                                             n
                                          
                                       
                                       )
                                       =
                                       g
                                       (
                                       
                                          q
                                          
                                             a
                                             n
                                          
                                       
                                       )
                                       ⋅
                                       θ
                                       (
                                       
                                          q
                                          
                                             a
                                             n
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        

If λ(q
                           
                              an
                           )>
                           θ
                           
                              p
                           , then p receives the label of q
                           
                              an
                            (l
                           
                              p
                           
                           =
                           lq
                           
                              an
                           ) and θ
                           
                              p
                            becomes equal to λ(q
                           
                              an
                           ) (θ
                           
                              p
                           
                           =
                           λ(q
                           
                              an
                           )). After a number of iterations, pixel labels cease to change and the algorithm reaches a state of convergence where all pixels have been assigned with a label.

The original grow-cut algorithm when applied to 2D-gel images results in image boundaries that do not contain the whole object of interest, i.e. the spot pixels in our case. The reason for this lies in the fact that spot pixels near the spot boundary have intensity values similar to the background. To effectively segment the 2D-gel images, a modified grow-cut update rule that takes into consideration the characteristics of 2D-gel images is proposed. The grow-cut algorithm is applied to I in order to label the pixels of the image I as spot (foreground – f) or background (b). For the proposed methodology, seed pixels are estimated automatically as explained in Section 2.2.1. The use of automatically selected seed pixels enhances the reproducibility of the segmentation results and reduces user intervention. The use of the original g function for the grow-cut algorithm leads to the expansion of background seeds over spot boundaries due to the minimal difference in their intensity values that result to high g values. To address this problem, the g function has been modified in order to take into consideration both the difference in intensity between P and q, and the class q belongs to. The incentive behind this modified g function is to enhance or reduce the strength of an attacking pixel based on the intensity difference between the pixel and the seed pixels of the class the attacking pixel belongs to. If the pixel q is labeled as spot, then if I(p) is close to T
                           
                              i,h
                            then the attack force is enhanced. Otherwise, the attack force is diminished. On the other hand, if the attacker pixel q is labeled as background, then if I(p) is close to T
                           
                              i,l
                            then the attack force is enhanced. Otherwise, the attack force is diminished. Eq. (5) shows the modified g function, while the plots for g are illustrated in Fig. 3
                           .
                              
                                 (5)
                                 
                                    
                                       g
                                       (
                                       q
                                       ,
                                       p
                                       )
                                       =
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         0
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         p
                                                         ,
                                                         q
                                                         :
                                                         (
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         f
                                                         ]
                                                         ∧
                                                         [
                                                         I
                                                         (
                                                         p
                                                         )
                                                         <
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               l
                                                            
                                                         
                                                         ]
                                                         )
                                                         ∨
                                                         (
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         b
                                                         ]
                                                         ∧
                                                         [
                                                         I
                                                         (
                                                         p
                                                         )
                                                         >
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               h
                                                            
                                                         
                                                         ]
                                                         )
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         1
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         p
                                                         ,
                                                         q
                                                         :
                                                         (
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         f
                                                         ]
                                                         ∧
                                                         [
                                                         I
                                                         (
                                                         p
                                                         )
                                                         >
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               h
                                                            
                                                         
                                                         ]
                                                         )
                                                         ∨
                                                         (
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         b
                                                         ]
                                                         ∧
                                                         [
                                                         I
                                                         (
                                                         p
                                                         )
                                                         <
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               l
                                                            
                                                         
                                                         ]
                                                         )
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         1
                                                         −
                                                         
                                                            
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     h
                                                                  
                                                               
                                                               −
                                                               I
                                                               (
                                                               p
                                                               )
                                                            
                                                            
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     h
                                                                  
                                                               
                                                               −
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     l
                                                                  
                                                               
                                                            
                                                         
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         p
                                                         ,
                                                         q
                                                         :
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         f
                                                         ]
                                                         ∧
                                                         [
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               l
                                                            
                                                         
                                                         ≤
                                                         I
                                                         (
                                                         p
                                                         )
                                                         ≤
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               h
                                                            
                                                         
                                                         ]
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     h
                                                                  
                                                               
                                                               −
                                                               I
                                                               (
                                                               p
                                                               )
                                                            
                                                            
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     h
                                                                  
                                                               
                                                               −
                                                               
                                                                  T
                                                                  
                                                                     i
                                                                     ,
                                                                     l
                                                                  
                                                               
                                                            
                                                         
                                                         ,
                                                      
                                                   
                                                   
                                                      
                                                         p
                                                         ,
                                                         q
                                                         :
                                                         [
                                                         l
                                                         (
                                                         q
                                                         )
                                                         =
                                                         b
                                                         ]
                                                         ∧
                                                         [
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               l
                                                            
                                                         
                                                         ≤
                                                         I
                                                         (
                                                         p
                                                         )
                                                         ≤
                                                         
                                                            T
                                                            
                                                               i
                                                               ,
                                                               h
                                                            
                                                         
                                                         ]
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

After the application of the grow-cut algorithm, each region R
                           
                              a
                            formed by pixels labeled as spot pixels, is further processed in order to segment it in the spot regions R
                           
                              a,b
                            it contains, as shown in Fig. 4a and b. The pixels belonging to the subset K, with K
                           ={p
                           :(p
                           ∈
                           S)∧(p
                           ∈
                           R
                           
                              a
                           )}, with S being the set containing the spot centers of the image, are selected as seed points for spot regions inside R
                           
                              a
                           , with each seed pixel being the seed for a different R
                           
                              a,b
                            region. The rest of the pixels L
                           ={p
                           :(p
                           ∉
                           K)∧(p
                           ∧
                           R
                           
                              a
                           )} are labeled based on their neighborhood pixel labels by the following procedure: At each iteration of the procedure, the unique intensities V
                           
                              a
                            of the non-seed pixels of L are determined in descending intensity order and then groups of similar intensity values – each containing x distinct intensities – are formed. Let u be the number of different intensities of L and z
                           =
                           u/x be the number of groups. Each group of pixels GP
                           
                              e
                           , e
                           =1, …, z, contains the pixels of L whose intensities are within the range of [V
                           
                              x·(e−1)+1, V
                           
                              x·e
                           ]. The pixels of each GP
                           
                              e
                            are then labeled based on their neighborhood pixels. For each pixel p, its neighborhood pixels are examined and p is labeled by the application of a majority voting criterion on the labels of its neighbors. Neighbors with undefined labels are not considered for the majority voting process. If a pixel is not assigned with a label then it will be reexamined at the next iteration of the procedure, whereas the assignement of a label to a pixel is considered as final and the pixel will not be reexamined. The processing of pixels in groups of intensities enables the speedup of the algorithm, since pixels with similar high intensity values are examined first and then impose their label on the neighborhood pixels of lower intensity values. As a result, the algorithm can cope with fluctuations in the intensity of the image that may be caused by noise or uneven background. An example of the application of the majority voting process is shown in Fig. 4b.

As it can be observed, in some cases the R
                           
                              a,b
                            regions may contain background pixels, especially in the case of clusters of spots. These pixels are then excluded by applying the optimal thresholding technique [34] in each region 
                              
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                              
                           , which corresponds to an extended region of R
                           
                              a,b
                            (see Fig. 4d) and is defined as 
                              
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                                 =
                                 {
                                 p
                                 :
                                 (
                                 p
                                 ∈
                                 (
                                 
                                    R
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                                 ⊕
                                 D
                                 )
                                 )
                                 ∧
                                 (
                                 p
                                 ∉
                                 (
                                 
                                    R
                                    
                                       a
                                       ,
                                       b
                                       '
                                    
                                 
                                 ⊕
                                 D
                                 )
                                 )
                                 }
                              
                            where R
                           
                              a,b
                           
                           ⊕
                           D denotes the application of the dilation morphological operation with structuring element D (D
                           =disk of radius r in this work) on R
                           
                              a,b
                            and 
                              
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                              
                            is a region other than R
                           
                              a,b
                           . The optimal thresholding technique is applied twice: (a) once on the gradient intensity values of pixels belonging to 
                              
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       b
                                    
                                 
                              
                            in order to detect the pixels near the spot boundary 
                              
                                 (
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       o
                                    
                                 
                                 )
                              
                           , whose gradient intensity value is high (see Fig. 4c) and (b) on the intensity values so as to detect the pixels far from the spot boundary (
                              
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       i
                                    
                                 
                              
                           ) and whose intensity value is high (see Fig. 4d). The final spot pixels are the pixels belonging to the set FS, with 
                              
                                 F
                                 S
                                 =
                                 {
                                 p
                                 :
                                 (
                                 p
                                 ∈
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       o
                                    
                                 
                                 )
                                 ∨
                                 (
                                 p
                                 ∈
                                 
                                    
                                       R
                                       ′
                                    
                                    
                                       a
                                       ,
                                       i
                                    
                                 
                                 )
                                 }
                              
                           . Fig. 4e depicts an example of the final segmentation results for the region depicted in Fig. 1b.

The proposed algorithm has been evaluated on two datasets consisting of real (Re) and synthetic (Sy) 2D-gel images, respectively, in order to allow for a qualitative and quantitative comparison with three established commercial packages (Delta2D [15], Melanie 7 [20] and PDQuest [18]) as well as the recently published method Scimo [14]. Each dataset (Re, Sy) consists of 2D-gel images containing a total of ∼10,200 spots and the bit depth of the images for both datasets is 16 bits. The real dataset has been provided through the courtesy of the Biomedical Research Foundation of the Academy of Athens (BRFAA) [41] whereas the synthetic 2D-gel images have been generated by our research group. The latter images have been created by combining spots produced using the 2-D Gaussian flat top function with background extracted from real images in order to imitate the real ones more accurately and retain their characteristics, i.e. overlapping spots, poorly contrasted spots, inhomogeneous background, artifacts and streaks. An example of a real and a synthetic image from the datasets utilized in the evaluation is shown in Fig. 5
                        . It should be noted that the parameters needed for the proposed algorithm were experimentally adjusted once and then remained constant during all experiments performed on both datasets, in contrast with the parameters of the state-of-art programs which need tuning – by expert biologists – for each particular image. The selected parameters are expected to provide satisfactory performance for 2D-gel images obtained from different sources and are shown on Table 3
                        . In particular, the constants were chosen in order to best detect the real spots, split overlapping spots, avoid detection of spurious spots and create more accurate spot boundaries that do not include background pixels. The parameters for the software packages compared with the proposed method where determined by expert biologists from the Biomedical Research Foundation of the Academy of Athens (BRFAA) [41] for the Melanie 7, Scimo and PDQuest, and from the Institute of Molecular Biology and Biotechnology (IMBB) of the Foundation for Research and Technology-Hellas (FORTH) [42] for Delta2D.

For spot detection, the ground truth information for the real images was provided by expert biologists of the BRFAA, who manually determined the locations of protein spots and marked them by drawing a cross inside each unique spot region. Three ground truth replicates were created for each image and the final ground truth was determined by majority voting. Comparing the detection results with the corresponding ground truth allows the characterization of each spot as “correctly detected” (true positive – TP), “not detected” (false negative – FN) and “falsely detected” as spot (false positive – FP). Then, a quantifiable comparison with the other methods is provided by means of the precision (P), sensitivity (S), and weighted harmonic mean (F-measure) measures [43–45], which are defined as:
                           
                              (6)
                              
                                 
                                    P
                                    =
                                    
                                       
                                          T
                                          P
                                       
                                       
                                          T
                                          P
                                          +
                                          F
                                          P
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 
                                    S
                                    =
                                    
                                       
                                          T
                                          P
                                       
                                       
                                          T
                                          P
                                          +
                                          F
                                          N
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (8)
                              
                                 
                                    F
                                    -measure
                                    =
                                    2
                                    *
                                    
                                       
                                          P
                                          *
                                          S
                                       
                                       
                                          P
                                          +
                                          S
                                       
                                    
                                 
                              
                           
                        
                     

The ground truth information for the segmentation of the real images cannot be available, thus spot boundaries are evaluated through visual inspection. Fig. 6
                         and Fig. 7
                         present the segmentation results obtained by the proposed approach and four other commercial packages and published methods for a real 2D-gel image as well as for magnified regions of this image. It is evident that the proposed approach (Fig. 6a and Fig. 7a1–3) is more successful in detecting and segmenting the protein spots than all the three image analysis software packages, namely Delta2D (Fig. 6b and Fig. 7b1–3), Melanie 7 (Fig. 6c and Fig. 7c1–3) and PDQuest (Fig. 6d and Fig. 7d1–3), as well as the recently published approach Scimo (Fig. 6e and Fig. 7e1–3). Moreover, the proposed approach provides more accurate and smoother spot boundaries as shown in Fig. 6a and Fig. 7a1–3.

In Fig. 7a1–e3, TPs are depicted as spots with a cross and boundaries, FNs as spots with a cross and no boundaries, and FPs as spots with boundaries but no cross inside. The sensitivity and precision values are both important, complementary measures for the detection performance. However, the F-measure can be considered as a more reliable measure, as it takes into account both the number of detected protein spots as well as the number of falsely detected (spurious) spots. Table 4
                         presents the statistical results obtained by the proposed approach and the four other methods, using the real 2D-gel image dataset. The effectiveness of the proposed approach is proved by the high precision (96.5%), sensitivity (93.2%), and F-measure (94.8%) value it achieves. The better spot detection performance of the proposed approach can lead to more accurate overall results since it results to a larger number of correctly detected spots, less false-positive (spurious) spots, and can assist the segmentation algorithm for the separation of overlapping spots.


                        Fig. 8
                         presents the segmentation results obtained by the proposed algorithm and the four other methods for the synthetic image illustrated in Fig. 5b. More detailed regions of these images are shown in Fig. 9
                        . From these images it can be easily derived that the proposed approach (Fig. 8a and Fig. 9a1–3) is more efficient in spot segmentation than the other methods, namely Delta2D (Fig. 8b and Fig. 9b1–3), Melanie 7 (Fig. 8c and Fig. 9c1–3), PDQuest (Fig. 8d and Fig. 9d1–3), and Scimo (Fig. 8e and Fig. 9e1–3), as it creates more plausible boundaries, separates overlapping spots, and includes almost all spot pixels inside the created spot boundaries while avoiding the inclusion of background pixels. It is evident that the proposed approach can effectively segment the protein spots and provide spot boundaries that look plausible and do not contain background pixels. The efficiency of the proposed method is also confirmed by the following statistical evaluation.

Since the ground truth information for the synthetic dataset is available, by comparing it with the segmentation results, each pixel can be characterized as “Actual Spot” (AS) pixel, “False Spot” (FS) pixel, “Actual Background” (AB) pixel and “False Background” (FB) pixel. This pixel characterization is then utilized in order to provide a quantifiable comparison between the examined methods through the Volumetric Overlap (VO), Volumetric Error (VE), and Volumetric Overlap Error (VOE) measures as proposed in Ref. [46], which are defined as:
                           
                              (9)
                              
                                 
                                    V
                                    O
                                    =
                                    
                                       
                                          A
                                          S
                                          V
                                       
                                       
                                          A
                                          S
                                          V
                                          +
                                          F
                                          B
                                          V
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (10)
                              
                                 
                                    V
                                    E
                                    =
                                    
                                       
                                          F
                                          S
                                          V
                                       
                                       
                                          A
                                          S
                                          V
                                          +
                                          F
                                          B
                                          V
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 
                                    V
                                    O
                                    E
                                    =
                                    1
                                    −
                                    
                                       
                                          A
                                          S
                                          V
                                       
                                       
                                          A
                                          S
                                          V
                                          +
                                          F
                                          B
                                          V
                                          +
                                          F
                                          S
                                          V
                                       
                                    
                                 
                              
                           
                        where ASV, FBV, and FSV denote the volume of each pixel group defined as:
                           
                              (12)
                              
                                 
                                    V
                                    =
                                    
                                       
                                          ∑
                                       
                                       
                                          x
                                          ,
                                          y
                                       
                                    
                                    I
                                    (
                                    x
                                    ,
                                    y
                                    )
                                 
                              
                           
                        
                     


                        Table 5
                         and Fig. 10
                         present the results obtained by the proposed approach and the four other methods, using the synthetic 2D-gel image dataset. Based on these results, it is evident that the proposed approach outperforms the four compared software packages and techniques for the synthetic image dataset. In particular, it achieves a very high VO value (97.0%) while having a very low VE value (5.7%). Additionally, it achieves the lowest VOE value (8.3%) which shows that the proposed approach outperforms the compared techniques. The VO, VE, VOE values indicate that the proposed approach manages to: (a) segment the majority of spot pixels (high VO), (b) avoid segmenting background pixels as spot pixels (low VE) and achieves the best balance between VO and VE among the compared software packages and techniques (having the lowest VOE). The latter remark is significant since both high VO and low VE minimize the effort and time needed for validation and correction of the results by expert biologists. While most methods achieve slightly higher or comparable VO, they perform much worse in terms of VE, leading to worse VOE than the proposed method. Delta2D, Melanie 7, PDQuest and Scimo achieve elevated VO because they extend the spot boundaries outside of the spot edges, resulting to the inclusion of background pixels along the spot pixels, that as a result leads also to high VE.

Considering the high VO, low VE and low VOE achieved by the proposed approach, it is evident that it misses only few spot pixels (high VO), while falsely segmenting only few background pixels as foreground pixels (low number of FS pixels, low VE). The low VOE achieved by the proposed approach indicates its superiority over the compared software packages and techniques. For example, PDQuest achieved a slightly higher VO value (99.4% compared to 97.0% for the proposed method) but has simultaneously segmented as spot pixels a much larger number of background pixels (VE value of 82.1% compared to 5.7% for the proposed method). The same happens for Delta2D, Melanie 7 and Scimo. The Volumetric Overlap Error is utilized for perfect segmentation measuring. Its value is 0 when the perfect segmentation is achieved and 100 when there is no overlap among the segmentation result and the ground truth. The VOE achieved by the proposed approach is limited to 8.3% compared to the second and third best VOE values achieved by Scimo and Melanie which are 12.6% and 21.6%, respectively. This result indicates that the proposed approach provides a more balanced and robust solution for 2D-gel image segmentation.

Experiments were conducted on the synthetic image dataset in order to evaluate the use of the proposed custom grow-cut method against other seeded segmentation methods. The performance of the proposed 2D-gel image segmentation methodology was evaluated by replacing the proposed custom grow-cut algorithm with: (a) the original grow-cut algorithm [32], the Fast Marching Method [47], segmentation via adaptive weighted distances [48] and watershed [49]. The same background and foreground (spot) pixel seeds were used for all the examined methods. Additionaly, all the other steps of the proposed methodology remained the same. Performance results for the examined approaches are shown in Table 6
                        , in terms of the VO, VE and VOE measures. It is evident that the proposed custom grow-cut based method achieves more accurate segmentation, as it provides the lowest VE and VOE and comparable VO. The marginally higher VO achieved by the fast marching, adaptive weighted distances (A. W. D.) and watershed methods is attributed to the fact that they extend the spot boundaries outside of the spot edges, resulting to the inclusion of background pixels to the spot area. The higher VE and VOE provided by these methods support this conclusion. Moreover, contrary to the proposed approach, all the alternative methods provide a large number of false positive (spurious) spots, as shown in an example of the final segmentation results for a region of an image, presented in Fig. 11
                        . Nevertheless, the adequate performance of most of the examined methods shows that the proposed seed selection and post initial segmentation processing methods are able to enhance the segmentation results of various methods for the task of 2D-gel image segmentation.

Experiments were conducted on the synthetic image dataset in order to evaluate the effect of the number N of tiled windows on the performance of the proposed approach. As explained in Section 2.1.2, N depends on the dimension d′ of the tiled windows. The proposed approach was applied on the synthetic image dataset for various values of d′, spanning from 20 to 160 pixels. The other parameters were kept as shown in Table 3 and performance was measured in terms of VO, VE and VOE. Results for the various values of d′ are presented in Fig. 12
                        . It is evident that the proposed approach exhibits significant performance stability to variations of d′. As a result, the effect of d′ and consequently of the number of tiled windows N on the performance of the proposed methodology is minimal. Nevertheless, performance suffers for very small values of d′, as shown in Fig. 12.

@&#CONCLUSION@&#

The detection and segmentation of protein spots in 2D-gel images can be very challenging and arduous tasks due to the characteristics of the images. In this paper, an original approach for the detection and segmentation of 2D-gel spots is presented. The proposed approach is based on the grow-cut segmentation algorithm with a custom update rule that takes into consideration the inherent characteristics of 2D-gel images, along a region growing technique and morphological operators. The proposed methodology was evaluated on real as well as synthetic 2D-gel images. The high F-measure as well as the low volumetric overlap error (VOE) value achieved by the proposed approach indicate that it is a robust and effective method for 2D-gel image spot detection and segmentation. The experimental evaluation demonstrated that the proposed approach outperforms state-of-the-art 2D-gel image analysis software packages and techniques including Melanie 7, Delta2D, PDQuest, and Scimo, and as a result constitutes an advantageous and reliable solution for 2D-gel image analysis. The significantly lower volumetric error (VE) and volumetric overlap error (VOE) compared to the other methods shows that the proposed methodology provides more accurate results, enhancing the ability to extract more reliable biological conclusions at the next steps of 2D-gel image analysis. Additionaly, the increased accuracy of the proposed spot detection method, in terms of the more reliable F-measure, reduces the number of false-positive (spurious) spots compared to the other methods and assists the segmentation process to effectively separate overlapping spots.

There are no conflicts of interest.

@&#ACKNOWLEDGMENTS@&#

This work was supported in part by the European Union (European Social Fund – ESF) and in part by Greek national funds through the Operational Program “Education and Lifelong Learning” of the National Strategic Reference Framework (NSRF) – Research Funding Program: THALIS, UOA, CERVI-CAN-PROT. The authors would like to extend their sincere appreciation to the expert biologists of the Biomedical Research Foundation of the Academy of Athens and in particular to Dr. S. Kossida and Dr. A. Vlahou for the provision of the real 2D-gel images and their ground truth and the segmentation results obtained by the Melanie 7 software program and Scimo, and to Dr. M. Makridakis for the segmentation results obtained by PDQuest. Furthermore, the authors would like to thank expert biologist Dr. M. Aivaliotis from the Institute of Molecular Biology and Biotechnology (IMBB) of the Foundation for Research and Technology-Hellas (FORTH) for providing the segmentation results obtained by the Delta2D software package.

@&#REFERENCES@&#


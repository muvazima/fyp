@&#MAIN-TITLE@&#Keypoint descriptor matching with context-based orientation estimation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Novel matching strategies for histogram-based descriptors are presented.


                        
                        
                           
                           Global dominant orientation is used by exploiting the image context.


                        
                        
                           
                           A new 3D extensible framework to evaluate feature descriptors is introduced.


                        
                        
                           
                           2D/3D comparisons with state-of-the-art rotational invariant descriptors are reported.


                        
                        
                           
                           Results show the effectiveness of the proposed matching approaches.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image descriptors

Local features

Dominant orientation

Rotation invariance

Keypoint matching

SIFT

LIOP

MROGH

@&#ABSTRACT@&#


               
               
                  This paper presents a matching strategy to improve the discriminative power of histogram-based keypoint descriptors by constraining the range of allowable dominant orientations according to the context of the scene under observation. This can be done when the descriptor uses a circular grid and quantized orientation steps, by computing or providing a global reference orientation based on the feature matches.
                  The proposed matching strategy is compared with the standard approaches used with the SIFT and GLOH descriptors and the recent rotation invariant MROGH and LIOP descriptors. A new evaluation protocol based on an approximated overlap error is presented to provide an effective analysis in the case of non-planar scenes, thus extending the current state-of-the-art results.
               
            

@&#INTRODUCTION@&#

Keypoints extracted from digital images have been adopted with good results as primitive parts in many computer vision tasks, such as recognition [1], tracking [2] and 3D reconstruction [3]. The detection and extraction of meaningful image regions, named keypoints or image features, are usually the first step of these methodologies. Numerical vectors that embody the image region properties are successively computed to compare the keypoints found according to the particular task.

Different feature detectors have been proposed during the last decade invariant to affine transformations or scale and rotation only, including, but not limited to, corners and blobs. The reader may refer to [4] for a general overview.

After the keypoint is located, a meaningful descriptor vector to embody the characteristic properties of the keypoint support region (i.e. its neighborhood) is computed. Different descriptors have been developed, which can be divided mainly into two categories: distribution-based descriptors and banks of filters. In general, while the former give better results, the latter provides more compact descriptors. Banks of filters include complex filters, color moments, the local jet of the keypoint, differential operators and Haar wavelet coefficients. Refer to [5] for more details.

Distribution-based descriptors, also named histogram-based descriptors, divide the keypoint region, also called feature patch, into different areas and compute specific histograms related to some image properties for each area. The final descriptor is given by the ordered concatenation of these histograms. The rank and the census transforms [6], which consider binary comparisons of the intensity of central pixel against its neighborhood, are the precursors of the histogram-based descriptors. In particular, the CS-LBP [7] descriptor can be considered an extension of this kind of approach. The spin image descriptor, the shape context and the geometric blur and the more recent DAISY, BRIEF, BRISK and FREAK descriptors (see [5,8]) should be mentioned.

One of the most popular descriptors based on histograms is surely the SIFT (Scale Invariant Feature Transform) [9], which is a 3D histogram of gradient orientations on a Cartesian grid. SIFT has been extended in various ways since its first introduction. The PCA-SIFT descriptor [10] increases the robustness of the descriptor and decreases its length by applying PCA (Principal Component Analysis), RIFT (Rotation Invariant Feature Transform) [11] is a ring-based rotational invariant version, while GLOH (Gradient Local Orientation Histogram) [5] combines a log-polar grid with PCA and SURF [12] is an efficient discrete SIFT variant. Recently, RootSIFT [13] improves upon SIFT by replacing the Euclidean distance with the Bhattacharyya distance after the normalization of the descriptor vector with the Manhattan norm instead of the conventional Euclidean norm. Overlapping regions using multiple support regions combined by intensity order pooling are used by MROGH (Multi Support Region Order Based Gradient Histogram) [14]. Furthermore, LIOP (Local Intensity Order Pattern) [15] uses the intensity order pooling and the relative order of neighbor pixels to define the histogram.

Over the last few years, machine learning techniques have been applied to remove the correlation between the descriptor elements and to reduce the dimension [10,16], as well as different histogram distances to improve the matches [17,18].

Different methodologies for evaluating feature descriptors and detectors have been proposed [4,5,8,16,19–23]. In the case of planar images, the Oxford dataset benchmark [4,24] is a well-established set of de facto standard, although an extension to non-planar images is not immediate [19]. Other evaluation methodologies use laser-scanner images [21] or structure from motion algorithms [16,23] or epipolar reprojection on more than two images [20], but in general they require a complex and error prone setup.

This paper presents in Section 2 a matching strategy to improve the discriminative power of histogram-based keypoint descriptors by constraining the range of allowable orientations according to the scene context.

We build the proposed matching strategy on the sGLOH (shifting GLOH) descriptor described in Section 2, presented in our previous work [25]. It uses a circular grid to embed more descriptor instances with different dominant discrete orientations of the same feature patch into a single feature vector. Each descriptor instance is accessible by an internal shift of the feature vector elements without the need to recompute the histograms. The matching distance between features is modified to consider the minimum distance among all descriptor instances for the possible dominant discrete orientations.

The sGLOH design can be used to further constrain the allowable dominant discrete orientations to be considered in the matching distance. A finer selection of the range of the dominant discrete orientations to be considered can be done a priori by defining a very fast matching strategy, named sCOr (shifting Constrained Orientation) or alternatively, when no further information is given in advance, by using an adaptive distance measure according to a voting strategy to get the sGOr (shifting Global Orientation) matching (see Section 2).

In order to assess the properties of the novel matching strategies, different experiments reported in Section 3 were carried out, both on planar and non-planar scenes. To provide more insights, we also evaluated the case when more than just the first dominant orientation is used in SIFT and GLOH. The rotational invariant MROGH [14] and LIOP [15] were also included in the evaluation due to the increasing interest towards them in recent works [14,8].

In the case of non-planar scenes, a novel dataset was created which employs a new evaluation protocol based on the approximated overlap error [26,27]. This evaluation protocol provides an effective analysis in the case of non-planar scenes, extending the current state-of-the-art results [20,22]. Section 4 reports final comments and conclusions.

Patch normalization and orientation methods are presented before defining the keypoint matching with sCOr and sGOr, as well as details on the sGLOH descriptor [25], which is essential in the matching pipeline since it allows constraints on the range of allowable orientations.

Given an image I(x), x
                        ∈ℝ2, the feature patch must be normalized before the computation of the descriptor vector. In the general case of affine-invariant keypoint detectors, which usually represent a good trade-off between transformation invariance and discriminative power, an elliptical region 
                           R
                        
                        ⊂
                        I is extracted. If the ellipse is given by the equation x
                        
                           T
                        Σ−1
                        x
                        =1, considering the keypoint center as coordinate origin, the patch is normalized to a circle of a fixed radius r according to the formula x′=
                        rAx, where 
                           
                              A
                              =
                              
                                 D
                                 
                                    −
                                    
                                       
                                          1
                                          2
                                       
                                    
                                 
                              
                              
                                 R
                                 T
                              
                           
                         with ∑=RDR
                           T
                         by the eigenvalue decomposition [5]. The ellipse axis lengths and orientations are given by the square root of the eigenvalues and the corresponding eigenvectors of Σ, respectively [5]. The symmetric matrix Σ∈ℝ2×2 is obtained as the covariance matrix for some quantity ϕ(x)∈ℝ2 related to the points of the patch 
                           R
                         
                        [4]. This is the gradient vector in the case of the Harris detector or the coordinates of the boundary points for the MSER detector [4].

The affine illumination invariance is obtained by normalizing the intensity value I(x) of the points inside the region 
                           R
                         through their mean μ and standard deviation σ, according to the formula 
                           
                              I
                              ′
                              
                                 x
                              
                              =
                              
                                 
                                    
                                       I
                                       
                                          x
                                       
                                       −
                                       μ
                                    
                                    σ
                                 
                              
                           
                        .

In order to be rotational invariant, most of the histogram-based descriptors have to be rotated according to a reference dominant orientation and different methodologies have been designed for its computation [9,12,28–30].

The common approach was proposed by Lowe [9], where the gradient ∇I(x)=[dx,dy]T is computed for each point x
                        ∈
                        
                           R
                         and a histogram of orientations θ
                        ∇I(x)
                        =arctan(dy/dx) is built up. The contribution of each point x is given by its gradient magnitude ║∇I
                        (x)║, weighted by the Gaussian function
                           
                              
                                 
                                    
                                       g
                                       σ
                                    
                                    
                                       x
                                    
                                    =
                                    
                                       1
                                       
                                          2
                                          π
                                          
                                             σ
                                             2
                                          
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          
                                             
                                                
                                                   ∥
                                                   x
                                                   
                                                      ∥
                                                      2
                                                   
                                                
                                                
                                                   2
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

with standard deviation σ. It is assumed that θ
                        
                           v
                        
                        =arctan(v), i.e. the arctangent of a generic vector v∈ℝ2, and the coordinate origins coincide with the center xc of the feature patch. The orientation Θ of the highest peak in the histogram, interpolated by a parabolic fitting, is chosen as the dominant orientation. More dominant orientations can be assigned to the feature, by retaining other peaks above 80% of the highest peak [9].

Histogram-based descriptors which do not require a dominant orientation have also been proposed [15,14]. The underlying idea, first exploited by RIFT [11], consists in the use of the outside direction perpendicular to the tangent direction at each point as reference in the bin assignment. This is however not sufficient, because patch regions have to be made invariant to rotation, too. The RIFT descriptor uses concentric rings which are clearly rotational invariant, but less discriminative.

A last approach, named intensity order pooling [14], defines regions according the intensity value of the feature patch points without spatial constrains, i.e. points with similar intensity values belong to the same region. This approach is used by MROGH [14], which computes a gradient histogram as for RIFT, and by LIOP [15], where instead the bins represent the relative order of the intensities in a neighborhood of the point. Furthermore, MROGH uses multiple support regions, which result in overlapping regions. According to [8], both LIOP and MROGH seem to outperform recent state-of-the-art descriptors, at least in the case of the Oxford planar scenes. However, it must be noted that the MROGH outer support region is 2.5 times bigger than the standard elliptic region employed by other descriptors [14] in the tests, which lead to better but distorted results, especially in the case of planar scenes. See the additional material formore details.

The sGLOH approach [25] uses the RIFT reference orientation for bin assignment, but a circular grid is maintained instead of concentric rings. The descriptor instances for different dominant discrete orientations obtained by shifting the descriptor vector are compared during the matching step and the best one is selected. Even if this approach is not a novelty [31], it had never been extended and evaluated in the context of histogram-based descriptors. Note that a similar descriptor, named RIFF, was introduced by Takacs et al. [32], contemporaneously to our preliminary paper concerning sGLOH [25].

The sGLOH descriptor grid is made up of n
                        ×
                        m regions 
                           R
                        
                        
                           r,d
                         with r
                        ={0,1,…,n
                        −1} and d
                        ={0,1,…,m
                        −1}, defined by n
                        −1 circular rings centered on the keypoint, plus one small inner circle, all of them containing m sectors, equally distributed along m directions (see Fig. 1
                        ). Previous experiments [25] have shown that not dividing the inner circular region into sectors decreases the discriminative power of the descriptor.

For each region 
                           R
                        
                        
                           r,d
                        , the histogram of m quantized orientations weighted by the gradient magnitude is computed. In order to obtain a better estimation of the gradient distribution, instead of using the trilinear interpolation as in SIFT [9], the bin value hi
                        , where i
                        =0,1,…,m
                        −1, is computed by the Gaussian kernel density estimation for each region
                           
                              
                                 
                                    
                                       h
                                       
                                          r
                                          ,
                                          d
                                       
                                       i
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             2
                                             πσ
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             x
                                             ∈
                                             
                                                R
                                                
                                                   r
                                                   ,
                                                   d
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∇
                                                I
                                                
                                                   x
                                                
                                             
                                          
                                       
                                    
                                    e
                                    −
                                    
                                       
                                          
                                             
                                                
                                                   M
                                                   
                                                      2
                                                      π
                                                   
                                                
                                                
                                                   
                                                      
                                                         θ
                                                         
                                                            ∇
                                                            I
                                                            
                                                               x
                                                            
                                                         
                                                      
                                                      −
                                                      
                                                         m
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                          2
                                       
                                       
                                          2
                                          
                                             σ
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        where ║∇I
                        (x)║ and θ
                        ∇I(x) are, respectively, the gradient magnitude and orientation of a pixel x
                        ∈
                        
                           R
                        
                        r,d; 
                           
                              
                                 m
                                 i
                              
                              =
                              
                                 
                                    
                                       2
                                       π
                                    
                                    m
                                 
                              
                              i
                           
                         is the i-th orientation bin center and 
                           
                              σ
                              =
                              
                                 
                                    
                                       2
                                       π
                                    
                                    m
                                 
                              
                              c
                           
                        , with c
                        ∈ℝ+, is the standard deviation in quantized orientation bin units. The function M
                        2π
                        (x) is used to take into account a periodicity of length 2π
                        
                           
                              
                                 
                                    
                                       M
                                       
                                          2
                                          π
                                       
                                    
                                    
                                       x
                                    
                                    =
                                    
                                       
                                          
                                             
                                                x
                                             
                                             
                                                if
                                                
                                                x
                                                <
                                                π
                                             
                                          
                                          
                                             
                                                2
                                                π
                                                −
                                                x
                                             
                                             
                                                otherwise
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

In modular arithmetic, [d
                        +
                        i]
                           m
                         shifts cyclically by d positions the i-th element of a m dimensional vector, given the relation a
                        ≡
                        b
                        mod
                        m, where the congruence class is represented by [a]
                           m
                        . We define a block histogram
                           
                              
                                 
                                    
                                       H
                                       
                                          r
                                          ,
                                          d
                                       
                                    
                                    =
                                    
                                       
                                          ⊕
                                          
                                             i
                                             =
                                             0
                                          
                                          
                                             m
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       h
                                       
                                          r
                                          ,
                                          d
                                       
                                       
                                          
                                             
                                                d
                                                +
                                                i
                                             
                                          
                                          m
                                       
                                    
                                    ,
                                 
                              
                           
                        where ⊕ is the concatenation operator, so that the first bin of each block has direction d. The final descriptor vector H is obtained by concatenating the histograms
                           
                              
                                 
                                    H
                                    =
                                    
                                       
                                          ⊕
                                          
                                             i
                                             =
                                             0
                                          
                                          
                                             n
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       
                                          ⊕
                                          
                                             j
                                             =
                                             0
                                          
                                          
                                             m
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       H
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

The length of H
                        =[h
                        1,
                        h
                        2,…,
                        h
                        
                           l
                        ] is l
                        =
                        m
                        2
                        n. In order to be more tolerant to noise and errors, the descriptor vector H is normalized to the unit length on the L
                        1 norm instead of the usual normalization through the L
                        2 norm [18]. Moreover, no threshold is applied [9] (e.g. 0.2 for SIFT) to saturate values greater than a given quantity. The values h
                        
                           i
                         are quantized to q levels to reduce the total descriptor to b
                        =
                        l log
                        2
                        q bits [9]. The final descriptor is then H
                        ⋆
                        =
                        wH where 
                           
                              w
                              =
                              q
                              /
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    l
                                 
                                 
                              
                              
                              
                                 h
                                 i
                              
                           
                        . To avoid a complex notation, H will refer to both H and H
                        ⋆ if it is not specified.

The rotation of the descriptor by a factor αk, where 
                           
                              α
                              =
                              
                                 
                                    
                                       2
                                       π
                                    
                                    m
                                 
                              
                           
                        , is obtained by a cyclic shift of the block histogram for each ring and for the inner circle, without recomputing the descriptor vector (see Fig. 1)
                           
                              
                                 
                                    
                                       H
                                       αk
                                    
                                    =
                                    
                                       
                                          ⊕
                                          
                                             i
                                             =
                                             0
                                          
                                          
                                             n
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       
                                          ⊕
                                          
                                             j
                                             =
                                             0
                                          
                                          
                                             m
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       H
                                       
                                          i
                                          ,
                                          
                                             
                                                
                                                   k
                                                   +
                                                   j
                                                
                                             
                                             m
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

In this sense, the sGLOH descriptor packs m different descriptors of the same patch with different dominant orientations. The distance between two features H and 
                           
                              H
                              ¯
                           
                         is then given by
                           
                              (1)
                              
                                 
                                    
                                       D
                                       ^
                                    
                                    
                                       H
                                       
                                          H
                                          ¯
                                       
                                    
                                    =
                                    
                                       min
                                       
                                          k
                                          =
                                          0
                                          ,
                                          …
                                          ,
                                          m
                                          −
                                          1
                                       
                                    
                                    D
                                    
                                       H
                                       
                                          
                                             
                                                H
                                                ¯
                                             
                                             αk
                                          
                                       
                                    
                                 
                              
                           
                        
                     

where 
                           D
                         (.,.) is a generic distance measure.

Experimental tests were carried out [25] on the Oxford dataset by using the setup described by Mikolajczyk and Schmid [5] in order to find the best parameter settings for sGLOH. We found that n
                        =2 and m
                        =8, which imply that the descriptor dimension is l
                        =128 and the discrete orientation step is 45°, provide the best compromise between the descriptor length and its discriminative power. Moreover, the patch radii of the circular grid are set to 12 and 20 so that the patch size is 41×41.

For Gaussian kernel density estimation, the standard deviation in bin units is set to c
                        =0.7 and the quantization levels are set to q
                        =512 as for the Mikolajczyk's SIFT implementation [24]. The normalization of the sGLOH vector to L
                        2 unit length with a successive saturation threshold of 0.2 has been shown to decrease its discriminative power [25]. Furthermore, no additional smoothness on the normalized and bilinear interpolated patches according to the scale to remove high frequencies is needed by sGLOH.

Both sCOr and sGOr reduce the number of wrong matches of sGLOH, as all wrong matches outside the correct range of discrete orientations are discarded and cannot be selected by chance.

In the sCOr approach the range of the allowable orientations to be checked is constrained up to the first clockwise and counterclockwise discrete rotations only, given an a priori fixed reference orientation f
                        ∈{0,1,…,
                        m
                        −1}, i.e. k
                        =[f
                        −1]
                           m
                        ,
                        f,[f
                        +1]
                           m
                         in Eq. (1). Although the range of sCOr applications is limited since high degrees of rotations cannot be handled, the method is general enough to be employed by setting f
                        =0 in common practical applications, such as SLAM [2] and sparse matching [3], since transformations are relatively continuous for close images. Moreover, scenes and objects are usually acquired roughly with the same orientations so that this issue can be often neglected in the general case, since sCOr handles rotations of up to ±67.5∘ (see the experimental section). Note also that sCOr decreases the time required for the distance computation with respect to sGLOH.

The sGOr approach uses the information provided by the scene context to provide a global reference orientation, under the reasonable assumption that all keypoints of the scene undergo roughly the same approximated discrete rotation αg, not known apriori. The range of discrete orientations in Eq. (1) is modified to k
                        =[g
                        −1]
                           m
                        ,
                        g,[g
                        +1]
                           m
                        , where g
                        ∈{0,1,…,
                        m
                        −1} can be estimated according to the most probable relative orientation among all matches.

Given two images I
                        1 and I
                        2, the relative orientation k
                        ⋆(H,
                        S) of the best match pair containing the feature H and any other feature in the other image is considered
                           
                              
                                 
                                    
                                       k
                                       ⋆
                                    
                                    
                                       H
                                       S
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      arg
                                                      min
                                                   
                                                   
                                                      
                                                         
                                                            k
                                                            =
                                                            0
                                                            ,
                                                            1
                                                            ,
                                                            …
                                                            ,
                                                            m
                                                            −
                                                            1
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               H
                                                               ¯
                                                            
                                                            ∈
                                                            S
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                             D
                                             
                                                H
                                                
                                                   
                                                      
                                                         H
                                                         ¯
                                                      
                                                      αk
                                                   
                                                
                                             
                                          
                                       
                                       ⊢
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    k
                                    
                                       H
                                       ¯
                                    
                                 
                                 ⊢
                              
                              =
                              k
                           
                         and S is the set of feature vectors from the image not containing H. We define the histogram of the relative orientations so that the bin z
                        
                           k
                         counts the number of the best matches with relative discrete orientation αk
                        
                           
                              
                                 
                                    
                                       z
                                       k
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             
                                                H
                                                1
                                             
                                             ∈
                                             
                                                S
                                                1
                                             
                                          
                                       
                                       
                                    
                                    
                                    t
                                    
                                       
                                          k
                                          =
                                          
                                             
                                                
                                                   
                                                      k
                                                      ⋆
                                                   
                                                   
                                                      
                                                         H
                                                         1
                                                      
                                                      
                                                         S
                                                         2
                                                      
                                                   
                                                
                                             
                                             m
                                          
                                       
                                    
                                    +
                                    
                                       
                                          ∑
                                          
                                             
                                                H
                                                2
                                             
                                             ∈
                                             
                                                S
                                                2
                                             
                                          
                                       
                                       
                                    
                                    
                                    t
                                    
                                       
                                          k
                                          =
                                          
                                             
                                                
                                                   −
                                                   
                                                      k
                                                      ⋆
                                                   
                                                   
                                                      
                                                         H
                                                         2
                                                      
                                                      
                                                         S
                                                         1
                                                      
                                                   
                                                
                                             
                                             m
                                          
                                       
                                    
                                 
                              
                           
                        where t(W) is 0, 1 if W is false, true respectively. S
                        1 and S
                        2 are the sets of descriptor vectors associated to features belonging to the images I
                        1 and I
                        2 respectively. The value of g is finally given by
                           
                              (2)
                              
                                 
                                    g
                                    =
                                    
                                       
                                          argmax
                                          
                                             k
                                             =
                                             0
                                             ,
                                             1
                                             ,
                                             …
                                             ,
                                             m
                                             −
                                             1
                                          
                                       
                                    
                                    
                                    
                                       z
                                       k
                                    
                                 
                              
                           
                        
                     

We experimentally verified that, consistently to the definition of g, wrong matches are distributed uniformly across the bins z
                        
                           k
                         while correct matches are distributed according to a Gaussian centered in z
                        
                           g
                        . The computation of g is similar to the Hough voting scheme [33] and, with respect to sGLOH, it just adds a minimal amount of computation to evaluate the distance 
                           
                              D
                              ^
                           
                         (see Eq. (1)), since all required values of 
                           D
                         have been computed already.

In order to evaluate the proposed matching approaches, comparisons with SIFT, GLOH, LIOP, MROGH and the original sGLOH were carried out, both in the planar and non-planar cases. The HarrisZ detector [34] which selects robust and stable Harris corners in the affine scale-space was used. Previous evaluations [34] have shown that it is comparable with the state-of-the-art detectors and provides better keypoints than Harris-affine. Moreover, although descriptors are influenced by detectors, the relative performances of the descriptors among different detectors are consistent [14].

In the planar case, precision/recall curves on correct matches were extracted through the overlap error ε for the stereo pairs (I
                     1,
                     I
                     2) in the Oxford dataset [24]
                     
                        
                           
                              
                                 ε
                                 
                                    
                                       R
                                       w
                                    
                                    
                                       R
                                       z
                                    
                                 
                                 =
                                 1
                                 −
                                 
                                    
                                       
                                          R
                                          
                                             
                                             w
                                          
                                       
                                       ∩
                                       
                                          T
                                          
                                             2
                                             →
                                             1
                                          
                                       
                                       
                                          
                                             R
                                             z
                                          
                                       
                                    
                                    
                                       
                                          R
                                          
                                             
                                             w
                                          
                                       
                                       ∪
                                       
                                          T
                                          
                                             2
                                             →
                                             1
                                          
                                       
                                       
                                          
                                             R
                                             z
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

where 
                        R
                     
                     
                        w
                     
                     ∈
                     I
                     1,
                     
                        R
                     
                     
                        z
                     
                     ∈
                     I
                     2 and 
                        
                           T
                           
                              2
                              →
                              1
                           
                        
                      is the function that reprojects the feature 
                        R
                     
                     
                        z
                      from I
                     2 to I
                     1.

Detectors were also considered in the case of 2D planar rotations, to underline the effects of the dominant orientation on descriptors and the benefits of the rotation invariant descriptors. For the non-planar case, a novel supervised evaluation strategy was adopted. An approximated overlap error ε
                     
                        q
                     , given a ground-truth fundamental matrix, was extracted according to the methodology described in [26,27], which is based on the epipolar geometry and tangency relations. Finally, the time complexity of the descriptors is discussed.

As considered in [5], the support region of each keypoint was increased by a factor of 3 and normalized to a 41×41pixel patch.

The Mikolajczyk's GLOH and SIFT implementations were adapted to be used with multiple dominant orientations [9], in order to provide a reference with previous evaluations [24]. In particular, we considered the case when peaks greater by a factor of 0.8 and 0.7 of the maximum peak in the histogram of gradient orientations are retained. Differently from Lowe's implementation, these use finer bins, so that the number of descriptors associated to each keypoint doubles instead of increasing by 15% only [9]. However, as shown in the next section, results improve as more peaks were considered, so that the number of correct matches obtained by our implementations represents an upper bound to Lowe's original implementation. When multiple dominant orientations were considered, similarly to sGLOH, the distance between two keypoints was computed as the minimum distance among all the possible descriptor vectors associated to them. The implementations of LIOP and MROGH, provided by respective authors were used, while the code of sGLOH, sCOr and sGOr can be downloaded from [35]. The MROGH outer support region is 2.5 times bigger than the standard elliptic region employed by other descriptor by design [14], so that better results are expected for this descriptor since more discriminative data are available. Nevertheless, MROGH results were also included as an upper bound to analyze the allowable gain that can be introduced in SIFT-like descriptors by using of a bigger feature area. Moreover, note that while the descriptor vector dimension is 128 for SIFT, GLOH and sGLOH, it is 144 and 192 for LIOP and MROGH, respectively.

The Oxford dataset [24] used in this evaluation contains planar images divided in two categories: structured images, containing homogeneous regions with well defined borders, and textured images. Eight different scenes are presented, each one subject to a different transformation across the images: viewpoint change, scale and orientation change, blur, lossy compression and luminosity. As in [5], the first and the fourth images for each scene were used.

Precision/recall curves for a fixed overlap error ε
                        =50% were extracted for increasing distance values by using NN (Nearest-Neighbor) and NNR (Nearest-Neighbor Ratio) [9] matching criteria with L
                        1 or Manhattan distance and the L
                        2 or Euclidean distance. The more rapidly the precision/recall curve grows and becomes stable with high recall, the better the descriptor is [5].

Finally, 2D rotations were tested by artificially rotating 16 different images, each by a step of 3° until 90°, to get a quantitative evaluation about the possible drawbacks due to a wrong estimation of the dominant orientation and to show the tolerance which can be achieved by descriptors under small orientations.

Relatively small rotations are more interesting in common applications because objects are almost always depicted in their frontal position. Furthermore, in 3D cases such as structure from motion [3] or SLAM [2], small rotations can aid to approximate admissible perspective distortions. To get an extensive analysis in the case of small rotations, the upright SIFT and GLOH descriptors, i.e. with no dominant orientation computation, named as uSIFT and uGLOH respectively, were included in this test.

Note that uSIFT, uGLOH and sCOr were not tested on the Oxford dataset, since rotation sequences contain high degree rotations, while scenes with non-geometric transformations do not contain any rotation. In the former case they could not be correctly applied while in the latter case the comparison would be unfair.

Plots in Fig. 2
                         show precision/recall curves with the best matching strategy for each descriptor, i.e. L
                        1 distance with NN for sGLOH and sGOr and L
                        1 distance with NNR for other descriptors. Results in terms of correct matches are also reported in the right vertical axes.

Plots in the additional material show that NNR allows a better rank of matches especially for SIFT and LIOP, less remarkably for MROGH and GLOH. In the case of sGLOH and sGOr, the NNR distance can be deleterious, since 
                           
                              D
                              ^
                           
                         (see Eq. (1)) minimizes the score across matches so that the ratio in NNR would be maximized. Dealing with the use of L
                        1 or L
                        2 distances, the former is preferable because it is more tolerant to patch transformations, as errors are weighted linearly and not quadratically, which confirms what is stated in [13]. A further clue is provided by the fact that specific distances designed for histogram-based descriptors, which have been applied with good results in [17,18], are based on the L
                        1 distance.

Regarding the descriptors, the use of more than the first dominant orientation in SIFT and GLOH can increase the recall by about 5%. According to other evaluations [5], GLOH performs slightly better than SIFT, but in this evaluation SIFT exceeds GLOH.

MROGH obtains an increase in recall of about 20% with respect to SIFT, which shows the robustness of the new rotational invariant descriptor. Except for the textured scale and rotation cases in the Bark sequence, it achieves the best results. However, a bigger support region is used, the vector length is 50% more than the standard 128 descriptor length and it requires more computational time (see Section. 3.3).

LIOP provides about 10–15% increase in recall, it is fast and increases the descriptor length by 13% only. Apart from the textured Bark sequence (see Fig. 2b), for which it achieves the best results, LIOP works better for structured scenes than for textured scenes. This implies that the relative ordering of pixel intensities is more stable for well defined and homogeneous patches.

The sGOr results are better than sGLOH, which demonstrates the effectiveness of the adaptive distance in constraining the range of discrete rotations. Except for Bark, sGOr results are in general quite similar to those obtained by LIOP, but sGOr works better with textured scenes. Furthermore, sGLOH always surpasses the results obtained by SIFT and GLOH for a precision which is less than 90%.

By inspecting the results in the case of no geometrical transformation (e.g. for the sequences Bikes, Trees, UBC and Leuven) it can be noted that the computation of the dominant orientation could lead to wrong matches. If no dominant orientation is used for SIFT and GLOH, results similar to other descriptors should be expected. Usually this information is not known a priori and needs to be explicitly included for SIFT and GLOH, while it is automatically addressed and handled by MROGH, LIOP, sGLOH and sGOr. Furthermore, larger support regions in the case of MROGH improve the results since more detailed feature patches are available.

Bad performances are evidenced in the case of the Bark sequence only, which is an example of the sGLOH worst case, discussed in detail for the 2D rotation test. Fig. 3
                         shows the average number of correct matches with the L
                        1 distance when an image is rotated up to 90°; for sCOr we set f
                        =0, i.e. k
                        =
                        m
                        −1,0,1 in Eq. (1). No rotation beyond 90° is considered as it can be seen from the plot that results would cyclically come back. Rotational invariant MROGH and LIOP give the best results with about 98% of correct matches, while a single dominant orientation provides about 93% of correct matches with an increase of up to 4% when multiple dominant orientations are used. A lower peak threshold of 0.7 produces more descriptors and provides an increase in correct matches equal to about 2% with respect to the 0.8 peak threshold suggested by Lowe [9]. A greater number of peaks in the orientation histogram improves results, but more descriptors should be computed.

In the case of sGLOH, rotations between two consecutive quantized orientations (i.e. about 22.5°+45°×
                        k, k
                        ∈ℤ) lead to the worst case, with 72% of correct matches. The constraint over the allowable discrete orientation in sGOr and sCOr increases the correct matches to 80%. The sGLOH descriptor and its extensions are more tolerant than SIFT and GLOH to small rotations of about 10–15°, which are quite common in many applications.

The uSIFT descriptor handles small rotations of up to ±22.5° as well as sGLOH, but it clearly cannot cycle on all possible rotations; uGLOH reaches only 15°, because PCA alters the spatial bin relations of the GLOH descriptor. Note that sCOr can handle rotations with a wider angle of up to ±(22.5°+45°)=±67.5°, which is three times the rotations covered by uSIFT and sufficient for a considerable number of tasks.

The evaluation on non-planar images was carried out according to the dataset reported in the additional material. Both the evaluation scripts and the dataset are freely available [35]. The dataset consists of 10 different stereo scenes with 3 images for each scene so that a total of 30 stereo pairs is obtained. Stereo pairs present rotations of less than 45°, since we are interested in testing sCOr and SGOr, which cycle through this value (see Fig. 3).

With respect to other evaluation methodologies [19,20,16,21,23], this comparison strategy does not require a complex setup, depth maps or camera calibration, but only the computation of the ground-truth fundamental matrix, so that the dataset can be easily extended. For each stereo pair, the fundamental matrix was computed with more than 50 hand-taken correspondences and an average epipolar error of about 1pixel. The average number of keypoints extracted for each image was around 800.

The approximated overlap error ε
                        
                           q
                         
                        [26] was applied to unify the comparison framework of non-planar scenes to the more common planar case without any complex schema [19,16,23], taking into account the feature shape and not only the keypoint center, considered through the epipolar distance by Moreels and Perona [20].

The approximated overlap error ε
                        
                           q
                         extends to surfaces the linear overlap error ε
                        
                           l
                         introduced by Forseén and Lowe [22], which is briefly described for the sake of clarity (see Fig. 4
                        ). The tangency relation between epipoles and feature ellipses is preserved by perspective projection (blue), because it is an incidence relation. By intersecting the line through the tangent points with the epipolar lines (yellow) of the corresponding tangent points on the respective ellipse in the other image, we obtain the configuration described in Fig. 4. The linear overlap error ε
                        
                           l
                         is given by the ratio between the small (azure) and the wider (red) segments.

We proposed an extension [26,27] to the linear overlap error measure ε
                        
                           l
                        , by observing that for computing a ground-truth fundamental matrix, not only the correspondence between epipoles is available, but also the fixed correspondences (k,
                        s) provided by the hand-taken points, k,s∈
                        
                           R
                        
                        2. The measure ε
                        
                           q
                         is an overlap between planar approximations of the surfaces inside the feature patches. The assumption that the scene can be approximated by piecewise planar patches was already used successfully to train and test features in [16].

For an ellipse patch 
                           R
                         (orange), tangent points define an inscribed quadrilateral Q
                        ⋆ (azure), while tangent lines limit a circumscribed quadrilateral Q (blue), as in Fig. 5
                        . The corresponding quadrilaterals P
                        ⋆ (light green) and P (dark green) are obtained by projecting from the other images through the fundamental matrix as done for ε
                        
                           l
                        . The area of the ellipse 
                           R
                         can be roughly approximated by the average area between Q and Q
                        ⋆
                        
                           
                              
                                 
                                    R
                                    ≈
                                    
                                       
                                          Q
                                          +
                                          
                                             Q
                                             ⋆
                                          
                                       
                                       2
                                    
                                    .
                                 
                              
                           
                        
                     

The final approximate overlap error ε
                        
                           q
                         is defined as
                           
                              
                                 
                                    
                                       ε
                                       q
                                    
                                    =
                                    
                                       
                                          ε
                                          
                                             Q
                                             P
                                          
                                          +
                                          ε
                                          
                                             
                                                Q
                                                ⋆
                                             
                                             
                                                P
                                                ⋆
                                             
                                          
                                       
                                       2
                                    
                                    .
                                 
                              
                           
                        
                     

The measure ε
                        
                           q
                         is not symmetric so the maximal value obtained for the ordered stereo pairs (I
                        1,
                        I
                        2) and (I
                        2,
                        I
                        1) is assigned to the match. In the computation, the best pair (k,
                        s) of correspondences is considered according to the heuristic constrains described in [27].

A match is considered correct with respect to a given threshold value t
                        
                           ε
                         if 
                           
                              
                                 ε
                                 q
                              
                              <
                              
                                 t
                                 
                                    ε
                                    q
                                 
                              
                           
                        . As 
                           
                              t
                              
                                 ε
                                 q
                              
                           
                         decreases, the precision increases in same way as in the framework by Moreels and Perona eperona and, as for all the methodologies based on a ground-truth fundamental matrix, the precision loss depends on the transformation applied to the scene, as well as, the uncertainty of the feature point on the epipolar line. In particular, wrong matches sharing the same epipolar cone can be misclassified. However, this is a stronger constraint than to take only into consideration the epipolar distance of the feature center. In order to deal with this issue, the error ε
                        
                           q
                         was first computed for the candidate matches and an initial selection of matches was done automatically by thresholding with 
                           
                              
                                 t
                                 
                                    ε
                                    q
                                 
                              
                              <
                              1
                           
                        , removing all matches with no overlap according to ε
                        
                           q
                        . The reduced subset of matches was then manually refined and only the remaining matches with an approximated overlap error less than the threshold 
                           
                              
                                 t
                                 
                                    ε
                                    q
                                 
                              
                              <
                              0.5
                           
                         were retained. This final set of correct matches was used in the evaluation as ground-truth.

In the case of no user inspection, we verified an average error rate equal to about 5% without the high recall loss due to the use of three images [20]. This error rate is sufficiently low and would not alter the results in the case of no manual interaction [27].


                        Fig. 6
                         shows the correct matches for each stereo pair and descriptor, considering SIFT as the reference descriptor. Further plots can be found in the additional material. The matching strategy and the distance used are the same as for the planar test, since the same considerations hold.

Histogram bars are clustered by scenes and then by stereo pairs. As done for the Oxford dataset [4,5], no average histogram for each descriptor on the whole dataset is given, since the scenes contain inhomogeneous context and transformations, which would lead to distorted conclusions.

For each scene cluster, the stereo pair with the highest perspective distortion and occlusion is the one that achieves the lowest number of correct matches. Matches decrease from about 30% to 15% as the amount of image distortions increase. The most challenging scene is represented by Kermit, in which there is a high perspective distortion. By inspecting the gradient variation it turns out that the decrease in the number of matches as the distance grows is consistent and similar among all descriptors.

The difference in correct matches among SIFT, GLOH and other descriptors is reduced from 50% in the planar case to about 20% in the non-planar case. In general, MROGH obtains together with sGOr and sCOr the best results, but none of these approaches clearly outperform the others. The advantage of using a bigger support region in the case of non-planar scenes is reduced, since bigger patches can introduce also more distortions with respect to the planar case, according to the concept of locality of the features [5].

LIOP improvements over SIFT are more limited than the planar case and in some cases obtain a lower number of matches for some image pairs, so that the local relative order of pixel intensity seems to suffer due to image discontinuities associated with perspective distortions in non-planar images.

Regarding GLOH, the same considerations obtained for the planar case still hold, while the number of matches for sGLOH is greater than SIFT but slightly lower than MROGH, sGOr and sCOr. The benefits of sGOr and sCOr over sGLOH are more evident than those obtained in the planar case.

Rotations of the form ±22.5°+45°×
                        k, k
                        ∈ℤ, correspond to the worst case of sGLOH (the third image pair of Teddy). As for the planar case, this issue can be alleviated by focusing on an admissible number of quantized orientations to remove ambiguities, as done by sGOr and sCOr which return similar results to SIFT.


                        Table 1
                         shows the percentage p of correct matches detected by sCOr along the orientation of 0° so that 1−
                        p corresponds to the percentage of correct matches detected along the orientation of ±45°, since discrete rotations are limited to up to this value. The following weighted average provides a rough estimate of the average orientation of the scene
                           
                              
                                 
                                    r
                                    
                                       p
                                    
                                    =
                                    p
                                    ×
                                    0
                                    °
                                    +
                                    
                                       
                                          1
                                          −
                                          p
                                       
                                    
                                    ×
                                    45
                                    °
                                 
                              
                           
                        neglecting the clockwise or counterclockwise direction of the rotation. The ratio of uSIFT correct matches with respect to sCOr is also reported, as for Fig. 6. It can be noted that some image pairs in the Kermit, extitShelf and Teddy sequences (bold values) have rotations of about ±225° or more (see Table 1). While uSIFT would provide better results than SIFT and similar ones to sGLOH, sGOr, sCOr, LIOP and MROGH for small rotations, its performance degrades for these image pairs. Furthermore, the need to decide whether to consider the dominant orientation is present for the SIFT and GLOH descriptors only, while it is automatically handled by the other descriptors. Even in the case of relatively small rotations, sCOr should be preferred to uSIFT, as a wider range of rotations could be handled.

Moreover, results of sCOr and sGOr are the same for all except the first sequences in Shelf and Teddy, showing that the computation of the relative average discrete orientation by sGOr is effective. Results differ with these two scenes because the average rotation is fixed a priori to 0° for sCOr, while sGOr detects g
                        =7 (see Eq. (2)) that implies a rotation of −45°, as expected by Table 1 and by observing the input images.

As a last note, sGOr rotation estimation works even when a low number of correct matches are present so that the corresponding peak in the discrete relative rotation histogram (see Section 2.5) is very low, as for the second scene with Kermit which has about 10% of correct matches.

The descriptor matching time depends on the average number n of extracted keypoints for each stereo pair. Indeed, the total time required is given by the time to compute the descriptors on both images, which is O(n), plus the time to compute the distance for each possible match, which grows as O(n
                        2). Here it is assumed that the computation of the distance between two descriptors requires a constant time and the descriptor length can be neglected.

Plot in Fig. 7
                         shows the computational time for each descriptor with respect to n, obtained by interpolation with a quadratic parabolic fitting on the datasets. Detailed cumulative time histograms are reported in the additional material. Times have been taken on a mid-level PC. For clarity, all timing considerations are made by using the SIFT time as a reference.

The computation of the gradient dominant orientation requires roughly the same time spent to obtain the descriptor vectors, since in both steps most of the time is spent in the computation of similar histograms on the keypoint patch. Thus LIOP, sGLOH, sCOr and sGOr need about half the time with respect to SIFT to compute the descriptor vector, because they do not need to compute the gradient dominant orientation. SIFT is slightly faster than GLOH while MROGH is 50% slower than SIFT because it uses 3 support regions, i.e. the descriptor is computed 3 times, each of them requiring 50% of the SIFT time since no dominant orientation has to be computed.

The quadratic term is comparable and irrelevant for SIFT, GLOH, LIOP and MROGH, if we do not consider large scale problems [3]. In these cases, MROGH and LIOP descriptor dimensions are, respectively, increased by 50% and 13% with respect to the standard 128 descriptor length of SIFT and this implies a similar increasing amount in the matching time. About sGLOH, sCOr and sGOr, the minimization of the distance 
                           
                              D
                              ^
                           
                         (see Eq. (1)) adds a constant multiplicative factor to the quadratic term. This can be neglected in the case of sCOr, comparable to the fast LIOP in terms of running time for a value of n used in common applications. In this case, both sGLOH and sGOr are still faster than MROGH. The sGLOH, sCOr and sGOr descriptors could save space in large scale matching problems with respect to SIFT and GLOH when multiple orientations are used, since a single sGLOH feature descriptor packs 8 different orientations. Note that SIFT and GLOH can require an additional running time proportional to further dominant orientations.

@&#CONCLUSIONS@&#

In this paper we have shown how to improve the discriminative power of histogram-based keypoint descriptors by constraining the range of allowable orientations according to the scene under observation. This is done by computing a global gradient orientation based on the image matching context in the case of sGOr, or can be provided a priori in the case of sCOr.

We tested the proposed descriptors together with SIFT, GLOH and recent rotation invariant descriptors by intensity order pooling, MROGH and LIOP, both on planar and non-planar images. In the former case the Oxford dataset was used, while in the latter case we proposed a novel supervised strategy, based on an approximated overlap error. This method allows one to compare descriptors in the non-planar case in a similar way to the planar case, by taking into account not only the keypoint center but also the feature shape. The new evaluation strategy does not require any complex setup to extend the dataset and the error rate is sufficiently low not to alter the results in the case of unsupervised usage [27]. This new evaluation method adds a valuable tool to be joined with the current evaluation methods in order to provide a more insightful understanding of the descriptors.

According to our tests, the L
                     1 distance should be chosen, while NNR matching is preferable for most descriptors. All investigated descriptors are expected to degrade when passing from the planar to non-planar cases. None of the considered descriptors clearly outperforms the others, since results depend on the input scene and time and space requirements are different, that should be also taken into account.

SIFT results as a good descriptor, while GLOH gives less correct matches in our tests. The rotational invariant LIOP descriptor is very fast, and achieves a higher number of matches with respect to SIFT, especially in the planar case. In non-planar scenes results are less stable, due to the intensity ordering used by LIOP, affected by eventual image discontinuities or in the presence of textured or noisy scenes. MROGH achieves the best results together with sGOr and sCOr, but it uses bigger support regions and also requires the highest computational time. The sGLOH descriptor returns good results on both planar and non-planar images with a time complexity comparable with SIFT in practical situations. The sGLOH descriptor is very tolerant to small rotations, but its results degrade for planar rotations between two quantized orientations, which limit its usability in general applications. The sCOr and the more general sGOr descriptors are very suitable for non-planar scenes and can be applied to common tasks with results comparable to MROGH and LIOP. Furthermore, sCOr and LIOP have a comparable running time while sGOr is faster than MROGH.

Results achieved by sGOr, sCOr and sGLOH, considering their similarity with SIFT, underline how the reference orientation represents a possible drawback in the matching process. In the case of small rotations, this issue can be removed by uSIFT. However, the need to use the dominant orientation has to be explicitly included in SIFT or GLOH, which is automatically handled by the other descriptors. For this reason, the sCOr descriptor should be preferred to uSIFT, as a wider range of rotations can be handled.

@&#ACKNOWLEDGMENTS@&#

This work was supported partially by grant B71J12001380001, University of Palermo FFR 2012/2013.


                     
                        
                           
                              Supplementary material.
                           
                           
                        
                     
                  

Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2014.05.002.

@&#REFERENCES@&#


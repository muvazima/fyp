@&#MAIN-TITLE@&#Novel risk index for the identification of age-related macular degeneration using radon transform and DWT features

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Automated detection of normal and AMD classes using fundus images.


                        
                        
                           
                           Radon transform and discrete wavelet transform are used for feature extraction.


                        
                        
                           
                           Proposed method is evaluated using private and public (ARIA and STARE) datasets.


                        
                        
                           
                           Obtained highest classification accuracy of 100% for STARE dataset.


                        
                        
                           
                           AMD risk index is proposed to discriminate the two classes using a single number.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Fundus imaging

Age-related macular degeneration

Radon transform

Discrete wavelet transform

Locality sensitive discriminant analysis

Computed aided diagnosis

@&#ABSTRACT@&#


               
               
                  Age-related Macular Degeneration (AMD) affects the central vision of aged people. It can be diagnosed due to the presence of drusen, Geographic Atrophy (GA) and Choroidal Neovascularization (CNV) in the fundus images. It is labor intensive and time-consuming for the ophthalmologists to screen these images. An automated digital fundus photography based screening system can overcome these drawbacks. Such a safe, non-contact and cost-effective platform can be used as a screening system for dry AMD. In this paper, we are proposing a novel algorithm using Radon Transform (RT), Discrete Wavelet Transform (DWT) coupled with Locality Sensitive Discriminant Analysis (LSDA) for automated diagnosis of AMD. First the image is subjected to RT followed by DWT. The extracted features are subjected to dimension reduction using LSDA and ranked using t-test. The performance of various supervised classifiers namely Decision Tree (DT), Support Vector Machine (SVM), Probabilistic Neural Network (PNN) and k-Nearest Neighbor (k-NN) are compared to automatically discriminate to normal and AMD classes using ranked LSDA components. The proposed approach is evaluated using private and public datasets such as ARIA and STARE. The highest classification accuracy of 99.49%, 96.89% and 100% are reported for private, ARIA and STARE datasets. Also, AMD index is devised using two LSDA components to distinguish two classes accurately. Hence, this proposed system can be extended for mass AMD screening.
               
            

@&#INTRODUCTION@&#

Age-related Macular Degeneration (AMD) is an eye disease that affects people aged 50 years and above [1]. It slowly affects the central vision and worsens over time. Macula is responsible for sharp and central vision in the retina [2]. It is concentration of colored light sensitive nerve units called cones where light normally focusses in the inner layer of the eye (retina) [2,3]. Death of these receptors in the macula causes AMD. World Health Organization (WHO) and United Nations (UN) report reveal that AMD affects 20–25 million people globally and among them 8 million are experiencing loss of vision [4]. People aged 60 years and above is estimated to be 606 million in 2000 will increase up to 2 billion in 2050. Hence, the number of subjects suffering from AMD are likely to triple in another 30 to 40 years [4]. In some patients AMD can progress slowly without affecting the vision and in the rest, it may progress rapidly causing vision loss. The earliest signs of AMD are the presence of drusens in the retina. AMD can be classified in to dry (non- neovascular) or wet (neovascular) [5].
                        
                           i.
                           
                              Dry AMD: it is the most common type of AMD and is caused due to thinning of tissues in the macula. It usually begins with the formation of drusens which tiny yellow fatty protein deposits are causing gradual vision loss [6]. People with dry macular degeneration need to regularly monitor their central vision. Dry AMD is further classified as early, intermediate and advanced. In early AMD, the size of the drusen varies from 63μm to 124μm in diameter and retinal pigmentation is present. In intermediate AMD, at least one drusen measuring more than 124μm and also medium sized drusens are present [7]. In both early and intermediate AMD, the drusen are mostly present away from macular center. Advanced AMD is characterized by the presence of drusens at the macular center or periphery. Also, there will geographic atrophy (area with 175μm diameter) and neovascular lesions present [8]. 
                              Fig. 1(b) shows the sample Dry AMD fundus image.


                              Wet AMD: caused due to Choroidal Neovascularization (CNV) which is an abnormal blood vessel formation from choroid region of the retina [8–10]. These vessels are very thin and leak blood, leading to vision loss. Wet AMD is more visible as compared to dry AMD and damages the retina more severely [8–10]. Among AMD subjects 10% of them are affected with wet AMD [8–10]. Fig. 1(c) shows the sample wet AMD fundus image.

Many studies have been conducted to segment the drusens using advanced image processing techniques. 
                     Table 1 summarizes the various methods used for the drusen detection.

Above mentioned methods rely on segmentation of drusen which is a challenging task due to the presence of other lesions and noise with same contrast as drusen [19]. Hence, in this work we have proposed an automated classification of fundus images into normal and AMD without segmenting the drusen. 
                     Fig. 2 show the steps involved in the proposed system. Contrast enhancement is performed on green channel of fundus image using Contrast Limited Adaptive Histogram Equalization (CLAHE). Radon Transform (RT) is applied on preprocessed image at each one degree to get the sinogram. Further, three level 2D Discrete Wavelet Transform (DWT) decomposition is performed on sonogram. Only approximate coefficients of three levels are concatenated and subjected to Locality Sensitive Discriminant Analysis (LSDA) to reduce the number of features. Further, LSDA components are ranked using t-value and then fed to various classifiers and compared the performance of various classifiers to find the best classification performance using minimum number of features with 10-fold cross validation.

Image acquisition, preprocessing, Radon transform, discrete wavelet transform, feature reduction, ranking and classification steps are explained in Section 2. Results are presented in Section 3. The results of the proposed approach are discussed in Section 4 and the paper concludes in Section 5.


                        Private dataset: retinal fundus images were collected from Department of Ophthalmology, Kasturba Medical College, Manipal, India and images were acquired using mydriatic fundus camera Zeiss FF450 plus. Patients were informed and consent was taken to use the images. In this study, we have collected 785 fundus images (404 normal and 381 AMD) with the resolution of 2588×1958 pixels and stored in JPEG format.


                        Public dataset: it consists of ARIA and STARE datasets. ARIA dataset images (Normal=101 and AMD=60) were acquired using Zeiss FF450 plus fundus camera at 768×576 pixels resolution and 50° Field of View (FOV). STARE dataset images (Normal=36 and AMD=47) were acquired using TOPCON fundus camera at 700×605 pixels resolution and 35° FOV. The ARIA and STARE images can be downloaded from [20] and [21] links respectively.

Fundus images suffer from non-uniform illumination due to eye pigmentation. The non-uniformity is corrected using Contrast Limited Adaptive Histogram Equalization (CLAHE) [22] on green channel fundus image. The objective of applying CLAHE is to stretch the contrast throughout the image and provide enhanced image. This makes the retinal landmark features such as macula, Optic Disc (OD), blood vessels and abnormal features of AMD such as drusen and CNV more visible.

Radon Transform (RT) is mainly used to reconstruct the image from computed tomography data [23]. It converts image pixels into line parameters at given angle which are mathematical features and can be used to discriminate the normal and AMD classes. Moreover, RT captures directional features of an image using line integrals [23]. AMD fundus images exhibit lesions such as drusen, GA and CNV. Among these, drusen and GA are high-frequency components (lesions with bright pixels) and CNV is low-frequency component (lesion with dark pixels) [28]. RT preserves intensity variations in the pixels. Hence, spatial-frequency information is preserved and boosted using RT [26]. The sinogram or plot of RT is graph of a sine wave which reflects the AMD lesions in terms of spatial-frequency features [26]. Further, DWT is performed on sinograms (RT projections) to quantify the pixel variations [26]. In this work, angle (theta) is varied from 0° to 179° at 1° interval to generate sinograms. 
                        Fig. 3b shows the sinogram of green channel normal fundus image (Fig. 3a) and Fig. 3d shows the sinogram of green channel AMD fundus image (Fig. 3c).

DWT is used to perform multiresolution analysis and space-frequency localization using low pass and high pass filters [24]. It decomposes the images into low (approximate coefficients) and high (detail coefficients) frequency components [24,25,60]. In this work ‘db3’ mother wavelet function is used to decompose Radon projections (sinogram) which reflects sum of pixel variations of AMD lesions (Fig. 3d). DWT performs three levels of decompositions on each sinograms (See 
                        Fig. 4) [26]. It generates approximate, horizontal, vertical and diagonal coefficients in all three levels [24,25]. However, approximate coefficients (low-frequency components) are used as features for AMD recognition [26]. The low-frequency components describes the global features of normal and AMD fundus images. The approximate coefficients are concatenated to form feature vector. Fig. 4(a) and Fig. 4(b) shows three levels of DWT decomposition of sinogram images of normal (corresponding to Fig. 3(a)) and AMD (corresponding to Fig. 3(b)) respectively. The approximate coefficients of level 3 in both normal and AMD sinograms (See Fig. 4) are clearly distinct. We have used this information to discriminate the two classes.

Locality Sensitive Discriminant Analysis (LSDA) is used to reduce the feature dimension by identifying relationship between data point and classes [27]. It can find the local geometry of the data with few training samples. ARIA and STARE dataset consists of less number of images for normal and AMD classes [27,28]. The within-class compactness (
                           
                              
                                 C
                              
                              
                                 a
                              
                           
                        ) and between-class separability (
                           
                              
                                 C
                              
                              
                                 b
                              
                           
                        ) is computed as follows:
                           
                              (1)
                              
                                 
                                    
                                       
                                          C
                                       
                                       
                                          a
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          min
                                       
                                       
                                          y
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ij
                                          
                                       
                                       
                                          
                                             
                                                (
                                                
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   
                                                      −
                                                   
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                                )
                                             
                                             
                                                2
                                             
                                          
                                          
                                             
                                                W
                                             
                                             
                                                
                                                   a
                                                
                                                
                                                   ,
                                                
                                                
                                                   ij
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       
                                          C
                                       
                                       
                                          b
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          max
                                       
                                       
                                          y
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ij
                                          
                                       
                                       
                                          
                                             
                                                (
                                                
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   
                                                      −
                                                   
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                                )
                                             
                                             
                                                2
                                             
                                          
                                          
                                             
                                                W
                                             
                                             
                                                
                                                   b
                                                
                                                
                                                   ,
                                                
                                                
                                                   ij
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              
                                 =
                              
                              
                                 
                                    α
                                 
                                 
                                    T
                                 
                              
                              
                                 
                                    ℵ
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                              
                                 =
                              
                              
                                 
                                    α
                                 
                                 
                                    T
                                 
                              
                              
                                 
                                    ℵ
                                 
                                 
                                    j
                                 
                              
                           
                         are 1D mapping of 
                           
                              
                                 ℵ
                              
                              
                                 i
                              
                           
                         and 
                           
                              
                                 ℵ
                              
                              
                                 j
                              
                           
                        , 
                           
                              α
                           
                         denotes direction of data projection [27, 28]. Using this method all three level approximate coefficients are reduced to 30 LSDA components.

In this work, t-test is used to rank the features. It rejects the null hypothesis when population means of samples from two groups is larger [29].


                        Null hypothesis H
                        
                           0
                        : population means of data between the groups is equal [29].


                        Alternative hypothesis H
                        
                           1
                        : population means of data between the groups is not equal [29].

The t-test provides t-value and the features with highest t-value considered as most significant feature [29] and are ranked first and vice versa [30]. Further, these highly ranked LSDA components are used for classification.

DT constructs tree from training data and rules derived from this tree classifies the classes [31]. Classification and regression tree algorithm is used to construct the tree [31]. k-NN is a non-parametric classification method [32,33]. It discriminates the classes using distance computation between nearest neighbors and majority voting to decide the class [32,33]. In this work k=5 is used to obtain maximum classification performance. PNN uses Parzens’ window estimation [34,61], it consists of input, pattern and summation layers. The decision is made using summation layer with compete transfer function [34]. In SVM classifier, the input space is mapped into a higher dimensional space called the feature space where the two classes are separated using hyperplane [35,36]. SVM uses kernel functions to convert non-linearly separable data into linearly separable one [35,36]. Various kernel functions such as Linear (L), Polynomial (P), Quadratic (Q) and Radial Basis Function (RBF) [35,36] are used to classify the two classes. Different classifiers are used to compare the performing classifier among them and finally best performance is used to design the final system.

The concept of integrated index is proposed by Ghista et al. [37] and Acharya et al. [38]. It is used to discriminate various diseases such as sudden cardiac death [39], glaucoma [40], depression [41], DR [42], fatty liver disease [43], epilepsy [44], carotid plaque [45], coronary artery disease [46], oral cancer [47] and thyroid [48]. Similarly, AMD index is derived using LSDA3 and LSDA5. The formula (Eq. (3)) is obtained by trial and error using these two LSDA components to discriminate the two classes distinctly for all three databases
                           
                              (3)
                              
                                 
                                    
                                       AMD
                                    
                                    
                                        
                                       
                                          Index
                                       
                                    
                                    
                                       =
                                    
                                    
                                       (
                                       
                                          
                                             0
                                             .
                                             326
                                             ×
                                          
                                          
                                             LSDA
                                          
                                          
                                             3
                                          
                                       
                                       )
                                    
                                    
                                       +
                                    
                                    
                                       (
                                       
                                          
                                             0
                                             .
                                             2
                                             ×
                                          
                                          
                                             LSDA
                                          
                                          
                                             5
                                          
                                       
                                       )
                                    
                                    
                                       +
                                       4
                                       .
                                       5
                                    
                                 
                              
                           
                        
                     

@&#RESULTS@&#

Sinogram of RT and DWT are used to extract features from normal and AMD fundus images. The approximate coefficients are considered as features. The dimension of the feature set is reduced using LSDA and obtained 30 LSDA components. Further, these components are ranked using t-value. 
                     Fig. 5 shows the highly ranked LSDA components which yielded highest classification performance for private, ARIA and STARE datasets (See Fig. 7).

The probability density estimation of LSDA24, LSDA5 and LSDA1 for three datasets are shown in 
                     Fig. 6. It can be seen from the figure that the extracted features are statistically significant. Further, ranked features are used to classify the two classes.

Ten-fold cross validation approach is used to evaluate the classifier performance. Using this approach the dataset (785 samples) is approximately equally divided into 10 sets with each set having about 79 samples. During training 9 sets (~707 samples) are used to train the classification model and remaining 1 set (~79 samples) is used for testing. This procedure is repeated 10 times and average performance is computed over 10-folds. The classification performance of DT classifier for private dataset is shown in the confusion matrix (See 
                     Table 2) [59]. It is a matrix of true diagnosis (clinician decision) versus proposed method (classifiers) [59]. 
                     
                     
                     Tables 3, 4, and 5 contains Number of Features (NOF), True Positive (TP), True Negative (TN), False Positive (FP) and False Negative (FN), Accuracy (Acc), Sensitivity (Sen), Specificity (Spec), Positive Predictive Value (PPV) and Negative Predictive Values (NPV) of different classifiers for private, ARIA and STARE datasets respectively.

The classification performance of various supervised classifiers using 10-fold cross validation for private, ARIA and STARE datasets are shown in Tables 3, 4 and 5 respectively. The results obtained using private dataset (See Table 3) shows that, DT classifier used first 11 ranked LSDA components to obtain highest accuracy of 99.49%, sensitivity of 99.21%, and specificity of 99.75%. Table 4 indicates the classification results obtained for ARIA dataset with first three ranked LSDA components. It has yielded the highest accuracy of 96.89%, sensitivity of 100%, and specificity of 91.67% using PNN and SVM-RBF classifiers. However, classification results of STARE dataset (See Table 5) reveals that except SVM-Polynomial classifier all other classifiers obtained accuracy, sensitivity, and specificity of 100%.

The plot (See 
                     Fig. 7) of number of features versus highest classification accuracy shows DT used eleven and two ranked LSDA components to get the maximum classification accuracy of 99.74% and 100% for private and STARE datasets respectively. However, SVM-RBF used three ranked LSDA components to obtain the highest classification accuracy of 96.89% for STARE dataset.


                     
                     Table 6 and 
                     Fig. 8 shows the typical values of AMD index for three datasets. This index is derived using trial and error approach. It clearly discriminates the two classes using two LSDA components (See Eq. 3) for all the three datasets.

@&#DISCUSSION@&#

Fundus imaging has contributed significantly in screening many eye diseases such as Diabetic Retinopathy (DR) [49], glaucoma [50] and AMD [51]. It is simple to acquire, analyze, low cost and can be extended to other (DR, glaucoma, and maculopathy etc.) eye diseases [49]. Automated diagnosis of AMD reduces the screening time and effort. The presence of drusen and CNV in the retina is the basis for the classification of fundus images into normal and AMD [25,28,30]. The AMD fundus images will have higher contrast than the normal fundus images in the green channel due to the presence of drusen and CNV [25,28,30]. Also the homogeneous appearance of normal fundus image will be disturbed in AMD fundus image due to the presence of abnormal features [25,28,30]. Hence, in this work, RT and DWT based method is used to extract these salient features. RT line integrals acts like low pass filters and DWT extracts multiresolution features from the RT space [26]. The approximate coefficients are the low-frequency components [26] and it captures the AMD changes in RT space. Hence, these features are useful to identify normal and AMD classes.

The results of different classifiers for three different datasets are tabulated in Tables 3, 4 and 5. For the private dataset DT classifier obtained the highest accuracy of 99.49% with eleven features. Public datasets (STARE and ARIA) are also used for cross validation. ARIA dataset yielded maximum accuracy of 96.89% using three features with SVM-RBF classifier. STARE dataset provided the highest classification accuracy of 100% using only two features with DT classifier. Hence, our results indicate that extracted features are able to capture AMD changes and contributed to the highest classification performance for all three datasets. 
                     Table 7 shows the summary of previous works reported for an automated AMD detection.

The proposed AMD classification system has following salient features.
                        
                           •
                           System does not rely on segmentation of abnormal features (drusens and CNV).

Algorithm is validated using various databases such as private, ARIA and STARE datasets.

Used maximum number of images in the private database (785 images) in this study.

System is developed using 10-fold cross validation data resampling and obtained highest classification accuracy of 99.49%, 96.89% and 100% for private, ARIA and STARE dataset (See Fig. 7). Hence it can predict the unknown class more accurately. So, the proposed method is more robust.

Proposed AMD Index (See Fig. 8) to diagnose the AMD for all the three databases using same equation.

Proposed approach can be extended for automated detection of glaucoma, diabetic retinopathy and diabetic maculopathy.

The limitation of the work may be to identify the early stage of AMD.

@&#CONCLUSIONS@&#

AMD is an irreversible medical condition and its diagnosis is extremely time-consuming process. To overcome this limitation, in this work we proposed RT and DWT based feature extraction to identify the variations in the pixels due to AMD condition. This system is evaluated using private and public datasets and obtained an accuracy of more than 96% for all datasets consistently. We have also developed unique AMD index for the discrimination of AMD using a single number. Hence, this system may be used to design an automated AMD screening tool which may reduce screening time of the clinicians. Moreover, this system can be extended to diagnose other eye diseases such as wet AMD, dry eye, diabetic retinopathy, glaucoma and maculopathy.

The authors do not have any related conflict of interest.

@&#ACKNOWLEDGMENTS@&#

Authors thank Social Innovation Research Fund (SIRF/Project Code: T1202), Singapore for providing grant for this research.

@&#REFERENCES@&#


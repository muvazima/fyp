@&#MAIN-TITLE@&#Accurate abandoned and removed object classification using hierarchical finite state machine

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a novel and accurate ARO classification method.


                        
                        
                           
                           We propose a hierarchical FSM consisting of pixel-, region-, and event-layers.


                        
                        
                           
                           State transition is done by the pre-trained SVM using 7 different input features.


                        
                        
                           
                           The proposed ARO method shows higher classification and low false alarm.


                        
                        
                           
                           The proposed ARO method can be applied to many practical applications.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Support vector machine

Hierarchical finite state machine

Pixel classification

Region classification

Event classification

@&#ABSTRACT@&#


               
               
                  The ability of most existing approaches to classify abandoned and removed objects (AROs) in images is affected by external environmental conditions such as illumination and traffic volume because the approaches use several pre-defined threshold values and generate many falsely-classified static regions. To reduce these effects, we propose an accurate ARO classification method using a hierarchical finite state machine (FSM) that consists of pixel-layer, region-layer, and event-layer FSMs, where the result of the lower-layer FSM is used as the input of the higher-layer FSM. Each FSM is defined by a Mealy state machine with three states and several state transitions, where a support vector machine (SVM) determines the state transition based on the current state and input features such as area, intensity, motion, shape, time duration, color and edge. Because it uses the hierarchical FSM (H-FSM) structure with features that are optimally trained by SVM classifiers, the proposed ARO classification method does not require threshold values and guarantees better classification accuracy under severe environmental changes. In experiments, the proposed ARO classification method provided much higher classification accuracy and lower false alarm rate than the state-of-the-art methods in both public databases and a commercial database. The proposed ARO classification method can be applied to many practical applications such as detection of littering, illegal parking, theft, and camouflaged soldiers.
               
            

@&#INTRODUCTION@&#

Identification of abandoned and removed objects (AROs) in videos is used to identify illegal activities. An abandoned object is a new object which has been brought into a scene and remains there for more than a given time; a removed object is an object that has disappeared from the scene, so that its former location remains empty for more than a given time [1]. Classification of AROs has been intensively studied since the PETS 2006
                        1
                     
                     
                        1
                        
                           http://www.cvg.rdg.ac.uk/PETS2006/.
                      and AVSS 2007
                        2
                     
                     
                        2
                        
                           http://www.eecs.qmul.ac.uk/andrea/avss2007.html.
                      challenges.

One of the most important problems in this research is to accurately determine static regions, which means both of abandoned object and removed object, because these are often falsely classified due to the existence of temporarily-stationary objects and to changes in illumination, or both [2]. Most existing ARO classification methods use either intensity or motion cues and many pre-defined threshold values to find static regions; these approaches result in poor classification accuracy and a large false alarm rate when traffic is heavy and the background is complex.

Existing ARO classification methods can be divided into feature-based methods and the finite state machine (FSM)-based methods. Feature-based methods use the temporal pattern of intensity or motion to find static regions. Beynon [3], Miguel [4], and Hassan [5] used the mixture-of-Gaussian (MoG) background model to classify the foreground regions, computed an association cost function based on position, size, color and edge information to track the foreground region, and identified the foreground region with the smallest cost value as the foreground region in the next frame. They classified the static regions by selecting the foreground regions with no motion during a pre-defined time. Liao [6] and Chang [7] used the foreground mask sampling method to find static regions. They sub-sampled six frames evenly during the previous 30s and generated six foreground images by taking the frame differences between the sub-sampled frame and its preceding frame. They obtained the static regions by taking the intersection of the foreground regions over six foreground images. Bayona [8] combined the foreground mask sampling method with the traditional foreground classification method to reduce the number of falsely classified static regions. They obtained the foreground images by subtracting the background for 30s and used the morphological operation to integrate the foreground images for 900 frames. They used the same morphological operation to identify static regions by re-combining the integrated foreground image with the resultant image. Porikli [1] used two MoG background models (short-term and long-term background models) with different learning rates to extract two different types of foreground images. They obtained the static regions by selecting the foreground regions that were not extracted from the short-term background model but were extracted from the long-term background model. Tian [9] used three MoG background models, assuming that the second dominant Gaussian represented the static regions. If the weight of the second dominant Gaussian for a pixel was larger than a threshold value, then the pixel was defined as a static pixel and the static pixels were grouped using the connected component analysis (CCA) [10,11]. They also introduced a simple tracking method that used the overlap ratio between two foreground regions during consecutive frames to reduce the number of false static regions.

However, heavy occlusion by other moving objects severely degrades the tracking accuracy of feature-based methods that use motion features, so these methods are ineffective in crowded environments, especially for objects that have similar color or texture. Although Ortego [12] proposed a multi-feature framework robust to crowded environments, most of feature-based methods that use intensity features are strongly dependent on many pre-defined threshold values, and therefore generate many falsely-classified static regions.

The FSM-based method uses a FSM to find static regions. Fujiyoshi [13] presented a method that used the stability of color information to find the static regions. They classified each pixel as stationary or transient according to its color history, and used CCA to define the static region by clustering the stationary pixels. Their method could successfully identify overlapped static regions but generated many static region classification errors due to illumination changes and noise. Mathew [14] suggested a FSM with five states: creation, deletion, foreground Gaussian (FG), background Gaussian (BG) and background dominant Gaussian (BDG), to classify objects which have appeared and remained stationary in the scene. If a new object was present in the same location for a pre-defined time, its state was changed from FG to BG and from BG to BDG (static region) over time. Evangelio [15] proposed using a short-term and a long-term background model to classify foreground objects, and classified each pixel into either background, foreground, static or uncovered background states by using dual background models to combine foreground classification results. Their method generated static regions by grouping static pixels, which are foreground pixels that are obtained from only the long-term background model. Then they used the edge information of their boundary regions to classify static regions as abandoned or removed objects. Fan [16] used the FSM to define the life cycle of a temporally static region (TSR), i.e., a foreground region whose bounding box does not move over a pre-defined time. The overlap ratio with other foreground regions was used to classify the state of the TSR into visible, occluded, or healed states. If the maximum overlap ratio was less than the pre-defined threshold value, then the state of the TSR was changed from ‘occluded’ to ‘visible’, which represented a true static region. If the TSR with the visible state was absorbed into the background model, then the state was changed from ‘visible’ to ‘healed’.

However, the existing FSM-based methods consider only pixel-level FSM, cluster the connected pixels to find the static region, and use intensity or edge-based features to classify a static region as an abandoned or a removed object; they do not consider higher-level FSMs such as region-layer or event-layer FSM systematically. Also, their ARO classification accuracies are largely dependent on the environmental conditions such as illumination, traffic and background complexity because their state transitions are based on many non-trained pre-defined threshold values.

To solve these problems, we propose a novel ARO classification method that uses a hierarchical FSM that consists of pixel-layer, region-layer and event-layer FSMs, where the decision results from the lower layer FSM are fed forward into the inputs of the next higher layer FSM. We also propose using SVM classifiers to determine the state transitions of the pixel-layer, region-layer and event-layer FSMs, because SVM classifiers can be trained to determine the state transitions optimally from a large number of training samples. The trained SVM removes the burden of requiring users to set pre-defined threshold values experimentally, and reduces the effect of the pre-defined threshold values on the ARO classification accuracy. The proposed ARO classification method consists of three stages: pixel classification, region classification and event classification, performed sequentially by the pixel-layer FSM, the region-layer FSM, and the event-layer FSM, respectively, as shown in Fig. 1
                     .

The main contributions of this paper are summarized as follows. First, we propose the hierarchical structure of FSMs consisting of low-level, middle-level and high-level processing that describes the entire ARO classification very systematically and accurately. Second, we propose the state transitions using SVM classifiers instead of a lot of pre-defined threshold values, which make the proposed ARO classification method robust to the change of environmental conditions such as light, traffic volume, and background complexity. Third, we propose a number of new features that reduce false static regions and improve ARO classification performance greatly.

This paper is organized as follows. Section 2 explains the structure of the proposed ARO classification method, the features and SVM classifiers for state transitions that are used in the pixel-layer, the region-layer and the event-layer FSMs, respectively. Section 3 summarizes how the proposed ARO classification method works. Section 4 presents extensive experimental results using the LVSN, Wallflower, PETS2006, AVSS2007, CAVIAR and ObjectVideo databases to evaluate the true classification accuracy and false classification ratio. Section 5 concludes the paper.

We propose a novel ARO classification method based on the hierarchical FSM; all state transitions of each FSM layer are determined by SVM classifiers. The structure of the proposed ARO classification method is shown in Fig. 2
                     . The pixel-layer FSM consists of three pixel states (background pixel b, foreground pixel f and static pixel s); its initial state is b. The region-layer FSM consists of three region states (background region B, foreground region F and static region S); its initial state is the region state (F or S) that is obtained from the pixel-layer FSM. The event-layer FSM consists of three event states (withholding event w, abandonment event a and removal event r); its initial state is w. Final states of this structure are a and r. Altogether, the three FSMs have 20 possible transitions (see Table 1
                     ), where each FSM uses a distinct set of features to determine its state: pixel-layer FSM uses intensity (C
                     
                        d
                     ,
                     C
                     
                        p
                     ,
                     C
                     
                        s
                     ) and time duration (T
                     
                        f
                     ), the region-layer FSM uses area (A
                     
                        F
                     ,
                     A
                     
                        S
                     ), intensity (
                        I
                     ), motion (
                        M
                     ), shape (
                        S
                     ) and time duration (T
                     
                        S
                     ), and the event-layer FSM uses color (D
                     
                        C
                     ) and edge (D
                     
                        E
                     ).

The proposed ARO classification method works as follows. First, we prepare a background image and accept an input image. Second, we perform a pixel-layer processing on each pixel to determine its pixel state by the pixel-layer features and the pixel-layer FSM. Third, we obtain the background, foreground, and static regions using the connected component analysis and morphological operations. Fourth, we perform a region-layer processing on each region to determine its region state by the region-layer features and the region-layer FSM. Fifth, we perform an event-layer processing on each true static region to determine its event state by the event-layer features and the event-layer FSM. Finally, we update the background image by absorbing the classified ARO into the background. We continue the above ARO classification method on the next input image.

In the pixel-layer processing, the pixel-layer FSM determines the state of each pixel by using the intensity and time duration features defined below.

Among the many existing methods [17–23] for moving object detection under a fixed camera, we adopted three different intensity features C
                           
                              d
                           , C
                           
                              p
                            and C
                           
                              s
                            to determine the status of each pixel; these denote distance-based confidence value, probability-based confidence value, and similarity-based confidence value, respectively [23]. The background of each pixel is independently modeled using a mixture of at most K Gaussian models during some initial frames. Let η
                           
                              l
                            be the kth background Gaussian model with normalized weight w
                           
                              l
                           , mean μ
                           
                              l
                           , and variance σ
                           
                              l
                           
                           2, i.e. η
                           
                              l
                           
                           ~
                           G(w
                           
                              l
                           ,
                           μ
                           
                              l
                           ,
                           σ
                           
                              l
                           
                           2), l
                           =1,⋯,
                           K. If an observation I(X
                           
                              t
                           ) of pixel X at current time t has the dominant background Gaussian model η
                           
                              k
                           , k
                           ∈[1,
                           K], the relevant model parameters are updated as
                              
                                 (1)
                                 
                                    
                                       w
                                       k
                                    
                                    ←
                                    
                                       
                                          1
                                          −
                                          α
                                       
                                    
                                    
                                       w
                                       k
                                    
                                    +
                                    α
                                    ,
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       μ
                                       k
                                    
                                    ←
                                    
                                       
                                          1
                                          −
                                          α
                                       
                                    
                                    
                                       μ
                                       k
                                    
                                    +
                                    α
                                    I
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (3)
                                 
                                    
                                       σ
                                       k
                                       2
                                    
                                    ←
                                    
                                       
                                          1
                                          −
                                          α
                                       
                                    
                                    
                                       σ
                                       k
                                       2
                                    
                                    +
                                    α
                                    
                                       
                                          
                                             I
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                             −
                                             
                                                μ
                                                k
                                             
                                          
                                       
                                       2
                                    
                                    ,
                                 
                              
                           where a is the learning rate.

The confidence value C
                           
                              d
                           ′(X
                           
                              t
                           ) measures the distance between I(X
                           
                              t
                           ) and the mean of the dominant background Gaussian model as
                              
                                 (4)
                                 
                                    
                                       C
                                       d
                                       ′
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             I
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                             −
                                             
                                                μ
                                                k
                                             
                                          
                                       
                                       255
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where μ
                           
                              k
                            is the mean of the kth background Gaussian model at the pixel X
                           
                              t
                            and the confidence value has a real number between 0 and 1.

The confidence value C
                           
                              p
                           ′(X
                           
                              t
                           ) measures the probability that the pixel belongs to the background as
                              
                                 (5)
                                 
                                    
                                       C
                                       p
                                       ′
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   ∀
                                                   k
                                                
                                             
                                          
                                          
                                             w
                                             k
                                          
                                          P
                                          
                                             
                                                η
                                                k
                                             
                                          
                                          P
                                          
                                             
                                                I
                                                
                                                   
                                                      X
                                                      t
                                                   
                                                
                                                |
                                                
                                                   η
                                                   k
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   ∀
                                                   k
                                                
                                             
                                          
                                          
                                             w
                                             k
                                          
                                          P
                                          
                                             
                                                η
                                                k
                                             
                                          
                                       
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where w
                           
                              k
                            is the normalized weight of the k th background Gaussian model at pixel X
                           
                              t
                           , P(I(X
                           
                              t
                           )|η
                           
                              k
                           ) is the Gaussian probability of the observation I(X
                           
                              t
                           ) with respect to η
                           
                              k
                           , and P(η
                           
                              k
                           ) is the probability that η
                           
                              k
                            belongs to the background as
                              
                                 (6)
                                 
                                    
                                       
                                          P
                                          
                                             
                                                I
                                                (
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                          |
                                          
                                             η
                                             k
                                          
                                       
                                    
                                    
                                    =
                                    
                                    
                                       1
                                       
                                          
                                             
                                                2
                                                π
                                             
                                          
                                          
                                             σ
                                             k
                                          
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          
                                             
                                                
                                                   I
                                                   
                                                      
                                                         X
                                                         t
                                                      
                                                   
                                                   −
                                                   
                                                      μ
                                                      k
                                                   
                                                
                                             
                                             2
                                          
                                          /
                                          
                                             
                                                2
                                                
                                                   σ
                                                   k
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (7)
                                 
                                    P
                                    
                                       
                                          η
                                          k
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          1
                                          +
                                          
                                             e
                                             
                                                −
                                                a
                                                
                                                   w
                                                   k
                                                
                                                /
                                                
                                                   σ
                                                   k
                                                
                                                +
                                                b
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where μ
                           
                              k
                            and σ
                           
                              k
                            are the mean and the standard deviation of the kth background Gaussian model at pixel X
                           
                              t
                            and a and b are the sigmoid parameters.

The confidence value C
                           
                              s
                           ′(X
                           
                              t
                           ) measures the similarity between observation I(X
                           
                              t
                           ) and the mean μ
                           
                              k
                            of the dominant background Gaussian model as
                              
                                 (8)
                                 
                                    
                                       C
                                       s
                                       ′
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    =
                                    
                                       e
                                       
                                          −
                                          |
                                          I
                                          
                                             
                                                X
                                                t
                                             
                                          
                                          −
                                          
                                             μ
                                             k
                                          
                                          |
                                          /
                                          20
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    .
                                 
                              
                           
                        

We define three different intensity features as the average value of confidence values within the neighbor region as
                              
                                 (9)
                                 
                                    
                                       C
                                       d
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    
                                    =
                                    
                                    
                                       1
                                       
                                          
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ∀
                                             X
                                             ∈
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       C
                                       d
                                       ′
                                    
                                    
                                       X
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (10)
                                 
                                    
                                       C
                                       p
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    
                                    =
                                    
                                    
                                       1
                                       
                                          
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ∀
                                             X
                                             ∈
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       C
                                       p
                                       ′
                                    
                                    
                                       X
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (11)
                                 
                                    
                                       C
                                       s
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    
                                    =
                                    
                                    1
                                    −
                                    
                                       1
                                       
                                          
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ∀
                                             X
                                             ∈
                                             N
                                             
                                                
                                                   X
                                                   t
                                                
                                             
                                          
                                       
                                    
                                    
                                       C
                                       s
                                       ′
                                    
                                    
                                       X
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where N(X
                           
                              t
                           ) is the 8-neighborhood of the pixel X
                           
                              t
                            and |N(X
                           
                              t
                           )| is the neighborhood size.

We compute the time duration T
                           
                              f
                           ′(X
                           
                              t
                           ) which defines the number of consecutive frames in which X
                           
                              t
                            is classified as a foreground pixel [24]. We count the number of consecutive frames in which each pixel belongs to the foreground as
                              
                                 (12)
                                 
                                    
                                       T
                                       f
                                       ′
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    =
                                    
                                       T
                                       f
                                       ′
                                    
                                    
                                       
                                          X
                                          
                                             t
                                             −
                                             1
                                          
                                       
                                    
                                    +
                                    δ
                                    
                                       
                                          s
                                          
                                             
                                                X
                                                t
                                             
                                          
                                          =
                                          f
                                       
                                    
                                    ,
                                 
                              
                           where T
                           
                              f
                           
                           ′(X
                           
                              t
                           ) and T
                           
                              f
                           
                           ′(X
                           
                              t
                              −1) are the accumulated frame count of position X at frames t and (t
                           −1) respectively, s(X
                           
                              t
                           ) denotes the status of pixel X in frame t, s(X
                           
                              t
                           )∈{b,
                           f,
                           s}, and the δ function increments the frame count by 1 when s(X
                           
                              t
                           )=
                           f. Whenever s(X
                           
                              t
                           )≠
                           f, T
                           
                              f
                           
                           ′(X
                           
                              t
                           ) returns to zero. Then, we define a normalized time duration
                              
                                 (13)
                                 
                                    
                                       T
                                       f
                                    
                                    
                                       
                                          X
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             T
                                             f
                                             ′
                                          
                                          
                                             
                                                X
                                                t
                                             
                                          
                                       
                                       
                                          2
                                          ×
                                          
                                             T
                                             min
                                          
                                       
                                    
                                    ,
                                 
                              
                           where T
                           
                              min
                            is the minimum time duration that is needed to change from a foreground pixel to a static pixel.

Generally, transition of a Mealy state machine from a current state to a next state occurs when a given condition (current state, input data) is satisfied. Because the given condition includes many threshold values, they affect the accuracy and robustness of ARO classification. Therefore, the FSM must be devised such that state transitions do not require comparison to threshold values. To meet this requirement, we use SVM classifiers to identify state transitions. For each different pixel state, the SVM is trained differently as detailed in the following paragraphs. In the background pixel state, the background SVM classifier SVM
                           
                              b
                            determines one of two states (b, f) according to intensity features C
                           
                              d
                           , C
                           
                              p
                            and C
                           
                              s
                           . In the foreground pixel state, the foreground SVM classifier SVM
                           
                              f
                            determines one of three states (b, f, s) according to C
                           
                              d
                           , C
                           
                              p
                           , C
                           
                              s
                            and time duration feature T
                           
                              f
                           . In the static pixel state, the static SVM classifier SVM
                           
                              s
                            determines one of two states (b, s) according to C
                           
                              d
                           , C
                           
                              p
                            and C
                           
                              s
                           .

We collected a dataset of 10,000 frames including background, foreground, and static pixels from the personally collected database in real situations, which is disjoint with the benchmark databases for testing and randomly selected 10% of the data set to use to train each pixel-layer SVM as follows (see Table 2
                           ). SVM
                           
                              b
                            was trained using 1000 frames including background and foreground pixels, where each pixel is represented by three intensity features. SVM
                           
                              f
                            was trained using 1000 frames including background, foreground and static pixels, where each pixel is represented by three intensity features and one time duration feature, and the background and foreground pixels are assumed to have zero time duration. SVM
                           
                              s
                            was trained using 1000 frames including background and static pixels, where each pixel is represented by three intensity features. Each SVM classifier in the pixel-layer FSM was trained using a radial basis kernel function (RBF) whose parameter set including a constant for error penalty and covariance matrix was optimized in preliminary trials.

After each pixel is classified as either a foreground, background or static pixel, CCA is used to group all pixels with the same state into a region, and regions that consist of foreground or static pixels are treated as static region candidates. During region-layer processing, the region-layer FSM uses features such as area, intensity, motion, shape, and time duration to classify static region candidates as true or false static regions.

We compute the areas of the foreground and static regions A
                           
                              F
                           ′(R
                           
                              t
                           ) and A
                           
                              S
                           ′(R
                           
                              t
                           ) by counting the number of the pixels within the foreground and static regions, respectively. Then, we define a normalized foreground and static region A
                           
                              F
                           (R
                           
                              t
                           ) and A
                           
                              S
                           (R
                           
                              t
                           ) as
                              
                                 (14)
                                 
                                    
                                       A
                                       F
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    
                                    =
                                    
                                    
                                       
                                          
                                             A
                                             F
                                             ′
                                          
                                          
                                             
                                                R
                                                t
                                             
                                          
                                       
                                       
                                          2
                                          ×
                                          
                                             A
                                             
                                                F
                                                ,
                                                min
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (15)
                                 
                                    
                                       A
                                       S
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             A
                                             S
                                             ′
                                          
                                          
                                             
                                                R
                                                t
                                             
                                          
                                       
                                       
                                          2
                                          ×
                                          
                                             A
                                             
                                                S
                                                ,
                                                min
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where A
                           
                              F,min
                            and A
                           
                              S,min
                            are the minimum areas required before a background (or foreground) region can be changed to a foreground (or static) region. In this paper, we set A
                           
                              F,min
                            and A
                           
                              S,min
                            to 150, which provides the best region classification accuracy.

We consider two intensity features: intensity dissimilarity (I
                           
                              D
                           ) and intensity stability (I
                           
                              S
                           ). I
                           
                              D
                            of region R
                           
                              t
                            measures the dissimilarity between the input image and the background image as
                              
                                 (16)
                                 
                                    
                                       I
                                       D
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             
                                                ∑
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                K
                                             
                                          
                                          
                                             H
                                             ¯
                                          
                                          
                                             k
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          K
                                       
                                    
                                    
                                       
                                          
                                             
                                                H
                                                
                                                   k
                                                
                                                −
                                                
                                                   H
                                                   ¯
                                                
                                                
                                                   k
                                                
                                             
                                          
                                          2
                                       
                                       
                                          
                                             H
                                             ¯
                                          
                                          
                                             k
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where K is the number of bins, H(k) is the kth bin value in the input intensity histogram and 
                              
                                 H
                                 ¯
                              
                              
                                 k
                              
                            is the background intensity histogram of static region candidate R
                           
                              t
                           . I
                           
                              D
                            of a static region candidate increases as the intensity difference between the input image and the background image increases; this correlation implies that high I
                           
                              D
                            corresponds to a high probability that a static region candidate is a true static region.


                           I
                           
                              S
                            of a static region candidate R
                           
                              t
                            measures the normalized variance of the intensity over a fixed number of frames as
                              
                                 (17)
                                 
                                    
                                       I
                                       S
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             A
                                             S
                                          
                                          
                                             
                                                R
                                                t
                                             
                                          
                                          ×
                                          T
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             ∀
                                             
                                                X
                                                t
                                             
                                             ∈
                                             
                                                R
                                                t
                                             
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             s
                                             =
                                             0
                                          
                                          
                                             T
                                             −
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                I
                                                
                                                   
                                                      X
                                                      
                                                         t
                                                         −
                                                         s
                                                      
                                                   
                                                
                                                −
                                                
                                                   I
                                                   ¯
                                                
                                                
                                                   
                                                      X
                                                      t
                                                   
                                                
                                             
                                             255
                                          
                                       
                                       2
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where A
                           
                              S
                           (R
                           
                              t
                           ) is the area of the static region candidate R
                           
                              t
                           , T is the time duration, I
                           
                              S
                           (X
                           
                              t
                              −
                              s
                           ) is the intensity value of X in the region R
                           
                              t
                            at the (t
                           −
                           s) th frame and Ī(X
                           
                              t
                           ) is the mean of the intensity values of X
                           
                              t
                            during the T frames. In this paper, we set the value of T to 30 frames due to a trade-off between many false static regions by a small value of T and many missing static regions by a large value of T. Static region candidates with low I
                           
                              S
                            values have a high probability of being true static regions. The two intensity features are concatenated into an intensity feature vector I
                           
                              T
                           
                           =[I
                           
                              D
                            
                           I
                           
                              S
                           ].

We propose three motion features: degree of overlap (M
                           
                              O
                           ), degree of area change (M
                           
                              A
                           ) and degree of position change (M
                           
                              P
                           ) as bounding boxes that surround the static region candidates. In this paper, we manage the bounding boxes for each region in the following manner: (1) two bounding boxes overlap considerably in consecutive frames, the bounding box in the current frame replaces the bounding box in the previous frame, and (2) if the bounding box in the current frame is significantly displaced from the corresponding bounding box in the previous frame, we add a new bounding box in the current frame. Fig. 3
                            illustrates how a static region candidate changes over time, where the gray and white regions in the bounding boxes represent the foreground region and the static region, respectively, and a static region (a) starts to appear, (b) is growing, (c) is fully grown and (d) is left alone and reaches steady state.


                           M
                           
                              O
                            of a static region candidate R
                           
                              t
                            at the tth frame measures the overlap ratio as
                              
                                 (18)
                                 
                                    
                                       M
                                       O
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                K
                                             
                                          
                                          A
                                          
                                             
                                                
                                                   R
                                                   t
                                                
                                                
                                                   ∩
                                                
                                                
                                                   R
                                                   t
                                                   k
                                                
                                             
                                          
                                       
                                       
                                          A
                                          
                                             
                                                R
                                                t
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where K is the number of foreground regions that intersect the static region candidate, A(R
                           
                              t
                           ) is the bounding box area of the static region candidate and A(R
                           
                              t
                           
                           ∩
                           R
                           
                              t
                           
                           
                              k
                           ) is the common bounding box area between the static region candidate and the kth intersecting foreground region. If a foreground region covers the entire static region candidate, M
                           
                              O
                           
                           =1 (see Fig. 3-(b)). If a foreground region partially overlaps the static region candidate, 0<
                           M
                           
                              O
                           
                           <1 (see Fig. 3-(c)). If the static region candidate is not surrounded by a moving (foreground) object, M
                           
                              O
                           
                           =0 (see Fig. 3-(d)).


                           M
                           
                              A
                            of a static region candidate R
                           
                              t
                            in the tth frame measures the change of the bounding box area between two consecutive frames as
                              
                                 (19)
                                 
                                    
                                       M
                                       A
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    1
                                    −
                                    
                                       
                                          min
                                          
                                             
                                                A
                                                
                                                   
                                                      R
                                                      t
                                                   
                                                
                                                ,
                                                A
                                                
                                                   
                                                      R
                                                      
                                                         t
                                                         −
                                                         1
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          max
                                          
                                             
                                                A
                                                
                                                   
                                                      R
                                                      t
                                                   
                                                
                                                ,
                                                A
                                                
                                                   
                                                      R
                                                      
                                                         t
                                                         −
                                                         1
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where A(R
                           
                              t
                           ) and A(R
                           
                              t
                              −1) are the area of the bounding box of the static region candidate in frames t and (t
                           −1), respectively. If a static region candidate starts to appear, M
                           
                              A
                           
                           =1 (see Fig. 3-(a)). If a static region grows over consecutive frames, 0<
                           M
                           
                              A
                           
                           <1 (see Fig. 3-(b)). If the area does not change in two consecutive frames, M
                           
                              A
                           
                           =0 (see Fig. 3-(c) and (d)).


                           M
                           
                              P
                            of static region candidate R
                           
                              t
                            in the tth frame measures the change of bounding box position between two consecutive frames as
                              
                                 (20)
                                 
                                    
                                       M
                                       P
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    max
                                    
                                       
                                          
                                             Δ
                                             
                                                X
                                                ¯
                                             
                                          
                                          
                                             max
                                             
                                                
                                                   W
                                                   t
                                                
                                                
                                                   W
                                                   
                                                      t
                                                      −
                                                      1
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             Δ
                                             
                                                Y
                                                ¯
                                             
                                          
                                          
                                             max
                                             
                                                
                                                   H
                                                   t
                                                
                                                
                                                   H
                                                   
                                                      t
                                                      −
                                                      1
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where 
                              Δ
                              
                                 X
                                 ¯
                              
                              =
                              |
                              
                                 
                                    X
                                    ¯
                                 
                                 t
                              
                              −
                              
                                 
                                    X
                                    ¯
                                 
                                 
                                    t
                                    −
                                    1
                                 
                              
                              |
                            and 
                              Δ
                              
                                 Y
                                 ¯
                              
                              =
                              |
                              
                                 
                                    Y
                                    ¯
                                 
                                 t
                              
                              −
                              
                                 
                                    Y
                                    ¯
                                 
                                 
                                    t
                                    −
                                    1
                                 
                              
                              |
                            represent the displacement of the bounding box center positions between two consecutive frames along the X and Y axes, respectively, and 
                              
                                 
                                    
                                       X
                                       ¯
                                    
                                    t
                                 
                                 
                                    
                                       Y
                                       ¯
                                    
                                    t
                                 
                              
                           , W
                           
                              t
                            and H
                           
                              t
                            denote the bounding box center position, width and height of the static region candidate in the tth frame, respectively. If a static region candidate starts to appear, M
                           
                              P
                           
                           =1 (see Fig. 3-(a)). If some displacement occurs along the X or Y axes between two consecutive frames, 0<
                           M
                           
                              P
                           
                           <1 (see Fig. 3-(b)). If no displacement occurs along the X or Y axes between two consecutive frames, M
                           
                              P
                           
                           =0 (see Fig. 3-(c) and (d)).

We consider both M
                           
                              A
                            and M
                           
                              P
                            to analyze motion cues because the bounding boxes of static region candidates in two consecutive frames can have the same areas but different positions, or different areas but the same positions. The motion features M
                           
                              O
                           , M
                           
                              A
                            and M
                           
                              P
                            enable to identify static regions completely without using any tracking method. Existing static region classification methods based on the object tracking often failed to detect static regions under heavy occlusion by other moving objects because they usually use the template matching technique to identify the same objects between two consecutive frames. However, the proposed method classifies the static region candidates into true static region when the changes of motions (M
                           
                              O
                           , M
                           
                              A
                            and M
                           
                              P
                           ) of static region candidates are near zero values irrespective of heavy occlusion. Therefore, the proposed motion feature is more discriminative to find the static regions under heavy occlusion than the object tracking approaches. The motion features are concatenated with a motion feature vector M
                           
                              T
                           
                           =[M
                           
                              O
                            
                           M
                           
                              A
                            
                           M
                           
                              P
                           ].


                           Fig. 4
                            shows how M
                           
                              O
                           , M
                           
                              A
                            and M
                           
                              P
                            of the region that includes a bag change over time, where four columns from the top represent the input sequence with region-layer classification results, M
                           
                              O
                           , M
                           
                              A
                           , and M
                           
                              P
                           , respectively. Fig. 4-(a) corresponds to the input image at frame 1700 that has M
                              T
                           
                           =[1.00,0.01,0.00] and shows that the static region candidate has not yet appeared because the man is carrying the suitcase; Fig. 4-(b) corresponds to the input image at frame 2000 that has M
                              T
                           
                           =[0.00,0.05,0.08] and shows that the static region candidate has not been determined as a true static region because the man is wandering around the suitcase; Fig. 4-(c) corresponds to the input image at frame 2300 that has M
                              T
                           
                           =[0.00,0.02,0.02] and shows that the static region candidate is determined as a true static region because the man has left the suitcase.

In this work, we designed shape features because temporarily stopped moving objects with a negligible local motion change (a person, a group of people) often generate false static regions and people are the most dominant factor for generating false static regions as known from the paper [2]. We observed that most of abandoned or removed objects such as bags, satchels, suitcases, and trunks have simple and smooth contours (see Fig. 5
                           ). In contrast, most of foreground objects such as people or groups of people have more complex contours than do abandoned or removed objects. To classify true (abandoned or removed objects) or false (people or groups of people who are standing or sitting temporarily) static regions, we propose three shape features: degree of unevenness (S
                           
                              U
                           ), degree of symmetry (S
                           
                              S
                           ) and degree of filling (S
                           
                              F
                           ) as follows.

Given a foreground (or static) region R
                           
                              t
                            that has a center position 
                              
                                 X
                                 ¯
                              
                              
                                 
                                    R
                                    t
                                 
                              
                            and a boundary contour C(R
                           
                              t
                           ) whose contour length along C(R
                           
                              t
                           ) is L(R
                           
                              t
                           ), we divide L(R
                           
                              t
                           ) into N equal intervals counter-clockwise along the boundary contour C(R
                           
                              t
                           ), starting from the X
                           1 that intersects with the horizontal positive axis; this process generates a sequence of positions X
                           1, X
                           2,⋯,
                           X
                           
                              N
                            (see Fig. 6-(c)). Then, we define a sequence of lengths l
                           1,
                           l
                           2,⋯,
                           l
                           
                              N
                            that connect the center position 
                              
                                 X
                                 ¯
                              
                              
                                 
                                    R
                                    t
                                 
                              
                            and the positions X
                           1, X
                           2,⋯,
                           X
                           
                              N
                           , respectively, and a sequence of angles θ
                           1,
                           θ
                           2,⋯,
                           θ
                           
                              N
                            that are the angles between the horizontal positive axis and the positions X
                           1, X
                           2,⋯,
                           X
                           
                              N
                           , respectively.


                           S
                           
                              U
                            of R
                           
                              t
                            quantifies the degree of unevenness by quantifying the unevenness of C(R
                           
                              t
                           ) as
                              
                                 (21)
                                 
                                    
                                       S
                                       U
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         j
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            l
                                                            
                                                               
                                                                  
                                                                     j
                                                                     +
                                                                     1
                                                                  
                                                               
                                                               %
                                                               N
                                                            
                                                         
                                                         −
                                                         
                                                            l
                                                            j
                                                         
                                                      
                                                   
                                                   
                                                      max
                                                      
                                                         
                                                            l
                                                            
                                                               
                                                                  
                                                                     j
                                                                     +
                                                                     1
                                                                  
                                                               
                                                               %
                                                               N
                                                            
                                                         
                                                         
                                                            l
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                             N
                                          
                                          +
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         j
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            θ
                                                            
                                                               
                                                                  
                                                                     j
                                                                     +
                                                                     1
                                                                  
                                                               
                                                               %
                                                               N
                                                            
                                                         
                                                         −
                                                         
                                                            θ
                                                            j
                                                         
                                                      
                                                   
                                                   
                                                      max
                                                      
                                                         
                                                            θ
                                                            
                                                               
                                                                  
                                                                     j
                                                                     +
                                                                     1
                                                                  
                                                               
                                                               %
                                                               N
                                                            
                                                         
                                                         
                                                            θ
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                             N
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where (j
                           +1)%
                           N denotes a modular operation, i.e., (N
                           +1)%
                           N
                           =1. If contour C(R
                           
                              t
                           ) is simple and smooth, S
                           
                              U
                            is small, and approaches zero in the case of a circle. If C(R
                           
                              t
                           ) is complicated and uneven, S
                           
                              U
                            is large, and approaches one in the case of a star.


                           S
                           
                              S
                            of R
                           
                              t
                            quantifies the degree of symmetry by quantifying the symmetry of the vertically (or horizontally) half-folded subregions as
                              
                                 (22)
                                 
                                    
                                       S
                                       S
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       
                                          
                                             
                                                
                                                   A
                                                   L
                                                
                                                ∩
                                                
                                                   A
                                                   R
                                                
                                             
                                             
                                                max
                                                
                                                   
                                                      A
                                                      L
                                                   
                                                   
                                                      A
                                                      R
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             
                                                
                                                   A
                                                   T
                                                
                                                ∩
                                                
                                                   A
                                                   B
                                                
                                             
                                             
                                                max
                                                
                                                   
                                                      A
                                                      T
                                                   
                                                   
                                                      A
                                                      B
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where A
                           
                              L
                           
                           ∩
                           A
                           
                              R
                            (or A
                           
                              T
                           
                           ∩
                           A
                           
                              B
                           ) is the overlapped area between the left and right (or the top and bottom) subregions of region R
                           
                              t
                            and A
                           
                              L
                            and A
                           
                              R
                            (or A
                           
                              T
                            and A
                           
                              B
                           ) are the areas of the vertically (or horizontally) half-folded subregions, respectively (see Fig. 6-(d)). If the region is a rectangle or circle, S
                           
                              S
                           
                           =1. Because a person or group of people is usually non-symmetric along the vertically or horizontally half-folded directions, the value of S
                           
                              S
                            is small.


                           S
                           
                              F
                            of R
                           
                              t
                            quantifies the degree of filling by calculating the proportion of the bounding box that is filled by the region as
                              
                                 (23)
                                 
                                    
                                       S
                                       F
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          A
                                          
                                             
                                                R
                                                t
                                             
                                          
                                       
                                       
                                          A
                                          
                                             
                                                R
                                                t
                                                ′
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       0
                                       ,
                                       1
                                    
                                    ,
                                 
                              
                           where A(R
                           
                              t
                           ) is the area of the region (computed by counting the number of foreground or static pixels) and A(R
                           
                              t
                           ′) is the area of the corresponding bounding box. If the boundary contour of the region is complicated, S
                           
                              F
                            is low due to the large empty space in the bounding box (see Fig. 6-(e)). The three shape features are concatenated into a shape vector S
                           
                              T
                           
                           =[S
                           
                              U
                            
                           S
                           
                              S
                            
                           S
                           
                              F
                           ].

We compute the time duration T
                           
                              S
                           ′(R
                           
                              t
                           ) which defines the number of consecutive frames in which region R
                           
                              t
                            is classified as a static region as
                              
                                 (24)
                                 
                                    
                                       T
                                       S
                                       ′
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       T
                                       S
                                       ′
                                    
                                    
                                       
                                          R
                                          
                                             t
                                             −
                                             1
                                          
                                       
                                    
                                    +
                                    δ
                                    
                                       
                                          s
                                          
                                             
                                                R
                                                t
                                             
                                          
                                          =
                                          S
                                       
                                    
                                    ,
                                 
                              
                           where T
                           
                              f
                           
                           ′(X
                           
                              t
                           ) and T
                           
                              f
                           
                           ′(X
                           
                              t
                              −1) are the accumulated frame counts of region R in frames t and (t
                           −1), respectively, s(R
                           
                              t
                           ) is the status of region R in frame t, s(R
                           
                              t
                           )∈{B,
                           F,
                           S}, and δ function increments the frame count by 1 when s(R
                           
                              t
                           )=
                           S. Whenever s(R
                           
                              t
                           )≠
                           S, T
                           
                              S
                           ′(R
                           
                              t
                           ) returns to zero. Then, we define a normalized time duration T
                           
                              S
                           (R
                           
                              t
                           ) as
                              
                                 (25)
                                 
                                    
                                       T
                                       S
                                    
                                    
                                       
                                          R
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          
                                             T
                                             S
                                             ′
                                          
                                          
                                             
                                                R
                                                t
                                             
                                          
                                       
                                       
                                          2
                                          ×
                                          
                                             T
                                             min
                                          
                                       
                                    
                                    ,
                                 
                              
                           where T
                           
                              min
                            is the minimum time duration that is needed to change from a foreground region to a static region.

SVMs were trained differently in each region state. In the background region state, the background SVM classifier SVM
                           
                              B
                            determines one of two states (B, F) according to one area feature A
                           
                              F
                           . In the foreground region state, the foreground SVM classifier SVM
                           
                              F
                            determines one of three states (B, F, S) according to two area features A
                           
                              F
                            and A
                           
                              S
                           , intensity features I
                           
                              D
                            and I
                           
                              S
                           , motion feature vector M and shape feature vector S. In the static region state, the static SVM classifier SVM
                           
                              S
                            determines one of three states (B, F, S) according to the area feature A
                           
                              S
                           , intensity features I
                           
                              D
                            and I
                           
                              S
                           , motion feature vector M, shape feature vector S and time duration feature T
                           
                              S
                           .

We collected a dataset of 10,000 frames including background, foreground, and static regions from the personally collected database in real situations, which is disjoint with the benchmark databases for testing and randomly selected 10% of the data set to use to train each region-layer SVM as follows (see Table 3
                           ). SVM
                           
                              B
                            was trained using 1000 frames including background and foreground regions, where each region is represented by one area feature. SVM
                           
                              F
                            was trained using 1000 frames including background, foreground and static regions, where each region is represented by one area feature, two intensity features, three motion features and three shape features. The collected personal database includes a cup on the desk or luggage on the table in the very ideal and simple experimental condition, where the objects are not included in the test databases such as the public databases and a commercial database. Therefore, users can reproduce the training databases easily.

Here, the background region is assumed to have zero A
                           
                              S
                            and to have the same intensity, motion and shape features as the foreground region. SVM
                           
                              S
                            was trained using 1000 frames including background, foreground and static regions, where each region is represented by one area feature, two intensity features, three motion features, three shape features and one time duration feature. Here, the background region is assumed to have the same area, intensity, motion and shape features as the static region, and the foreground region is assumed to have zero time duration. Each SVM classifier in the region-layer FSM was trained using a radial basis kernel function (RBF) whose parameter set including a constant for error penalty and covariance matrix was optimized in preliminary trials.

During event-layer processing, the event-layer FSM uses color and edge features to classify true static regions as either abandoned or removed objects. These features are defined in this section.

We use the change of the color richness of a true static region to discriminate between abandoned or removed objects [25]. We expand the static region by increasing its width and height by a factor of 1.5. Then we compute the color richness of the expanded static region in the input image and the color richness of the region that corresponds to the expanded static region in the background image. For abandoned objects, the color richness is higher in the expanded static region in the input image than in the corresponding region in the background image; for removed objects the opposite relationship is true.

To measure the color richness of the expanded bounding box S
                           
                              t
                           , we divide each color channel (R,G,B) into 8 bins and compute the sum of the top-N most populated bin values as
                              
                                 (26)
                                 
                                    C
                                    R
                                    
                                       
                                          S
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                    
                                    
                                       H
                                       i
                                    
                                    
                                       R
                                       G
                                       B
                                    
                                    ,
                                 
                              
                           where H
                           
                              i
                           (R,
                           G,
                           B) is the top ith most populated bin value among the 83 bins. In this paper, we set the value of N to 10 experimentally. Then, we compute the difference D
                           
                              C
                            of color richness of static region S
                           
                              t
                            as
                              
                                 (27)
                                 
                                    
                                       D
                                       C
                                    
                                    
                                       
                                          S
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          C
                                          
                                             R
                                             I
                                          
                                          
                                             
                                                S
                                                t
                                             
                                          
                                          −
                                          C
                                          
                                             R
                                             B
                                          
                                          
                                             
                                                S
                                                t
                                             
                                          
                                       
                                       
                                          max
                                          
                                             
                                                C
                                                
                                                   R
                                                   I
                                                
                                                
                                                   
                                                      S
                                                      t
                                                   
                                                
                                                ,
                                                C
                                                
                                                   R
                                                   B
                                                
                                                
                                                   
                                                      S
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       
                                          −
                                          1
                                          ,
                                          1
                                       
                                    
                                    ,
                                 
                              
                           where CR
                           
                              I
                           (S
                           
                              t
                           ) and CR
                           
                              B
                           (S
                           
                              t
                           ) denote the color richness of frame t in the input and background images of the expanded static region S
                           
                              t
                           , respectively. Therefore, D
                           
                              C
                           (S
                           
                              t
                           ) approaches 1 in the case of an abandoned object, and approaches −1 in the case of a removed object.

We also accept the change of the edge strength of true static region to discriminate the abandoned or removed objects [15] (see Fig. 7
                           ). We expand the static region by increasing the width and height by a factor of 1.5. Then, we use morphological operations to extract the boundary region S
                           
                              t
                           
                           
                              B
                            of the static region as
                              
                                 (28)
                                 
                                    
                                       S
                                       t
                                       B
                                    
                                    =
                                    
                                       S
                                       t
                                       D
                                    
                                    ∩
                                    
                                       
                                          
                                             S
                                             t
                                             E
                                          
                                       
                                       C
                                    
                                    ,
                                 
                              
                           where S
                           
                              t
                           
                           
                              D
                            and (S
                           
                              t
                           
                           
                              E
                           )
                              C
                            denote the dilated region and the complement of the eroded region of the true static region, respectively. Then, we compute the edge strength of the static region by adding the gradient magnitude |G| on the pixels within the boundary region S
                           
                              t
                           
                           
                              B
                            as
                              
                                 (29)
                                 
                                    E
                                    S
                                    
                                       
                                          S
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          ∑
                                          
                                             X
                                             ∈
                                             
                                                S
                                                t
                                                B
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             G
                                             x
                                             2
                                          
                                          
                                             X
                                          
                                          +
                                          
                                             G
                                             y
                                             2
                                          
                                          
                                             X
                                          
                                       
                                    
                                    ,
                                 
                              
                           where G
                           
                              x
                            and G
                           
                              y
                            represent the gradient component along the x and y directions at pixel position X, respectively. Then we compute the difference D
                           
                              E
                            of edge strength of the static region S
                           
                              t
                            as
                              
                                 (30)
                                 
                                    
                                       D
                                       E
                                    
                                    
                                       
                                          S
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          E
                                          
                                             S
                                             I
                                          
                                          
                                             
                                                S
                                                t
                                             
                                          
                                          −
                                          E
                                          
                                             S
                                             B
                                          
                                          
                                             
                                                S
                                                t
                                             
                                          
                                       
                                       
                                          max
                                          
                                             
                                                E
                                                
                                                   S
                                                   I
                                                
                                                
                                                   
                                                      S
                                                      t
                                                   
                                                
                                                ,
                                                E
                                                
                                                   S
                                                   B
                                                
                                                
                                                   
                                                      S
                                                      t
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                    ∈
                                    
                                       
                                          −
                                          1
                                          ,
                                          1
                                       
                                    
                                    ,
                                 
                              
                           where ES
                           
                              I
                           (S
                           
                              t
                           ) and ES
                           
                              B
                           (S
                           
                              t
                           ) are the edge strength of the boundary region S
                           
                              t
                           
                           
                              B
                            in the input image and the background image, respectively. When ES
                           
                              I
                           
                           =
                           ES
                           
                              B
                           , we do not perform the abandoned or removed object discrimination until the next frame image. D
                           
                              E
                           (S
                           
                              t
                           ) approaches 1 in the case of abandoned objects and approaches −1 in the case of removed object.

SVMs were trained differently for each event state. In the withholding event state, the withholding SVM classifier SVM
                           
                              w
                            determines one of three states (w, a, r) according to one color feature D
                           
                              C
                            and one edge feature D
                           
                              E
                           . Abandonment and removal event states have self-transition because they are the final states.

We collected a dataset of 10,000 frames including withholding, abandonment and removal events from the personally collected database in real situations, which is disjoint with the benchmark databases for testing and randomly selected 10% of the data set to use to train each event-layer SVM as follows (see Table 4
                           ). SVM
                           
                              w
                            was trained using 1000 frames including withholding, abandonment and removal events, where each event is represented by one color feature and one edge feature. Each SVM classifier in the event-layer FSM was trained using a radial basis kernel function (RBF) whose parameter set including a constant for error penalty and covariance matrix was optimized in preliminary trials.

The proposed ARO classification method is executed in five stages (see Algorithm 1). In the initialization stage, it applies MoG to the initial 100 frames to generate the background image and then (line 1) sets the states of all pixels in this image to the background state (line 2).

In the pixel-layer classification stage, it represents each pixel with its position and the pixel state as X
                     
                        t
                     
                     =(x
                     
                        t
                     ,
                     y
                     
                        t
                     ,
                     s(X
                     
                        t
                     ))
                        T
                      at the tth frame, where s(X
                     
                        t
                     )∈{b,
                     f,
                     s} (line 3). Then, for all pixels, it computes the necessary features among {C
                     
                        d
                     ,
                     C
                     
                        p
                     ,
                     C
                     
                        s
                     ,
                     T
                     
                        f
                     } according to the pixel state s(X
                     
                        t
                     ) (line 4) and uses the corresponding pixel-layer SVM classifier according to the pixel state s(X
                     
                        t
                     ) to determine the next pixel state s(X
                     
                        t
                        +1) (line 5). Then it uses the next pixel state that is determined from the pixel-layer SVM classifier to update the next state of each pixel by X
                     
                        t
                        +1
                     =(x
                     
                        t
                     ,
                     y
                     
                        t
                     ,
                     s(X
                     
                        t
                        +1)) (line 6).

In the region-layer classification stage, it uses CCA to obtain the foreground and static regions, and sets these regions as static region candidates (line 7). Then, it represents each static region candidate with its boundary positions and the region state as R
                     
                        t
                     
                     ={x
                     
                        t
                     
                     
                        LT
                     ,
                     y
                     
                        t
                     
                     
                        LT
                     ,
                     x
                     
                        t
                     
                     
                        RB
                     ,
                     y
                     
                        t
                     
                     
                        RB
                     ,
                     s(R
                     
                        t
                     )}, where x
                     
                        t
                     
                     
                        LT
                     ,
                     y
                     
                        t
                     
                     
                        LT
                     ,
                     x
                     
                        t
                     
                     
                        RB
                     ,
                     y
                     
                        t
                     
                     
                        RB
                      denote the x and y positions of the left top point and the right bottom point of the bounding box respectively, and s(R
                     
                        t
                     )∈{B,
                     F,
                     S} (line 8). Then, for all static region candidates, it computes the necessary features among {A
                     
                        F
                     ,
                     A
                     
                        S
                     ,
                     I,
                     M,
                     S,
                     T
                     
                        S
                     } according to the region state s(R
                     
                        t
                     ) (line 9) and uses the corresponding region-layer SVM classifier according to the region state s(R
                     
                        t
                     ) to determine the next region state s(R
                     
                        t
                        +1) (line 10). Then, it uses the next region state that is determined from the region-layer SVM classifier to update the next state of each static region candidate by R
                     
                        t
                        +1
                     ={x
                     
                        t
                        +1
                     
                        LT
                     ,
                     y
                     
                        t
                        +1
                     
                        LT
                     ,
                     x
                     
                        t
                        +1
                     
                        RB
                     ,
                     y
                     
                        t
                        +1
                     
                        RB
                     ,
                     s(R
                     
                        t
                        +1)} (line 11) and sets the static region candidates whose next region states are static region states S as true static regions S
                     
                        t
                      (line 12).

In the event-layer classification stage, it represents each true static region with its boundary positions and the event state as S
                     
                        t
                     
                     ={x
                     
                        t
                     
                     
                        LT
                     ,
                     y
                     
                        t
                     
                     
                        LT
                     ,
                     x
                     
                        t
                     
                     
                        RB
                     ,
                     y
                     
                        t
                     
                     
                        RB
                     ,
                     s(S
                     
                        t
                     )} (line 13). Then, for all true static regions, it computes the features {D
                     
                        C
                     ,
                     D
                     
                        E
                     } according to the event state s(S
                     
                        t
                     ) (line 14) and uses the corresponding event-layer SVM classifier according to the event state s(S
                     
                        t
                     ) to determine the next event state s(S
                     
                        t
                        +1) (line 15). Then, it uses the next event state that is determined from the event-layer SVM classifier to update the state of each event by S
                     
                        t
                        +1
                     ={x
                     
                        t
                        +1
                     
                        LT
                     ,
                     y
                     
                        t
                        +1
                     
                        LT
                     ,
                     x
                     
                        t
                        +1
                     
                        RB
                     ,
                     y
                     
                        t
                        +1
                     
                        RB
                     ,
                     s(S
                     
                        t
                        +1)} (line 16).

In the background image update stage, it uses Eqs. (1), (2) and (3) to update the MoG's parameters for the pixels with the background pixel states (line 17) and absorbs the true static regions into the background image after a user-defined time (line 18).
                        Algorithm 1
                        Algorithm procedure of the proposed ARO classification method.


                           
                              
                           
                        

We used public databases and a commercial database to evaluate the performance of the proposed ARO classification method. The public databases were Laboratoire de Vision et Systemes Numerique (LVSN)
                           3
                        
                        
                           3
                           
                              http://vision.gel.ulaval.ca/en/Projects/Id-283/projet.php.
                        , Wallflower
                           4
                        
                        
                           4
                           
                              http://research.microsoft.com/en-us/um/people/jckrumm/wallflower/testimages.htm.
                        , PETS2006
                           5
                        
                        
                           5
                           
                              http://www.cvg.rdg.ac.uk/PETS2006/data.html.
                        , AVSS2007 (i-LIDS)
                           6
                        
                        
                           6
                           
                              http://www.eecs.qmul.ac.uk/andrea/avss2007.html.
                         and CAVIAR
                           7
                        
                        
                           7
                           
                              http://homepages.inf.ed.ac.uk/rbf/CAVIARDATA1.
                         databases and the commercial database was ObjectVideo (OV) database. The proposed ARO classification method was applied to each frame independently and was implemented in Visual C++ on a Windows PC platform with a 2.94-GHz Intel Core i7 CPU.

To evaluate the pixel-layer classification, we used the precision (P) and the recall (R) as
                           
                              (31)
                              
                                 P
                                 
                                 =
                                 
                                 
                                    
                                       T
                                       
                                          P
                                          P
                                       
                                    
                                    
                                       T
                                       
                                          P
                                          P
                                       
                                       +
                                       F
                                       
                                          P
                                          P
                                       
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (32)
                              
                                 R
                                 
                                 =
                                 
                                 
                                    
                                       T
                                       
                                          P
                                          P
                                       
                                    
                                    
                                       T
                                       
                                          P
                                          P
                                       
                                       +
                                       F
                                       
                                          N
                                          P
                                       
                                    
                                 
                                 ,
                              
                           
                        where TP
                        
                           P
                        , FP
                        
                           P
                         and FN
                        
                           P
                         denote the number of correctly classified foreground pixels (true positives), the number of the falsely classified foreground pixels (false positives) and the number of missed foreground pixels (false negatives) in all frames, respectively.

To evaluate the region-layer classification, we used the true classification accuracy (TCA) and the false classification ratio (FCR) as
                           
                              (33)
                              
                                 T
                                 C
                                 A
                                 
                                 =
                                 
                                 
                                    
                                       T
                                       
                                          P
                                          R
                                       
                                    
                                    
                                       T
                                       
                                          P
                                          R
                                       
                                       +
                                       F
                                       
                                          N
                                          R
                                       
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (34)
                              
                                 F
                                 C
                                 R
                                 
                                 =
                                 
                                 
                                    
                                       F
                                       
                                          P
                                          R
                                       
                                    
                                    
                                       T
                                       
                                          P
                                          R
                                       
                                       +
                                       F
                                       
                                          P
                                          R
                                       
                                    
                                 
                                 ,
                              
                           
                        where TP
                        
                           R
                        , FN
                        
                           R
                        , FP
                        
                           R
                         and GT
                        
                           R
                         denote the number of correctly classified static regions (true positives), the number of missed static regions (false negatives), the number of falsely classified static regions (false positives) and the total number of true static regions (GT
                        
                           R
                        
                        =
                        TP
                        
                           R
                        
                        +
                        FN
                        
                           R
                        ) in all frames, respectively. To evaluate TCA and FCR, we consider the PASCAL measurement (PC) which is an overlap ratio as
                           
                              (35)
                              
                                 P
                                 C
                                 =
                                 
                                    
                                       A
                                       
                                          
                                             G
                                             T
                                          
                                       
                                       ∩
                                       A
                                       
                                          
                                             R
                                             t
                                          
                                       
                                    
                                    
                                       A
                                       
                                          
                                             G
                                             T
                                          
                                       
                                       ∪
                                       A
                                       
                                          
                                             R
                                             t
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where A(GT) and A(R
                        
                           t
                        ) are the bounding box areas of the ground-truth static region and the observed true static region at the tth frame, respectively. If there exists more than one true static region with PC
                        ≥0.5 in the specific frame, then the frame is included to compute TP
                        
                           R
                        ; similarly, if the specified frame includes more than one true static region with PC
                        <0.5, the frame is included to compute FP
                        
                           R
                        . When the specific frame has ground-truth data GT but no true static region with PC
                        ≥0.5, the frame is included to compute FN
                        
                           R
                        .

To evaluate the event-layer classification, we used the static region discrimination accuracy (SRDA) as
                           
                              (36)
                              
                                 SRDA
                                 =
                                 
                                    
                                       T
                                       
                                          P
                                          E
                                       
                                    
                                    
                                       G
                                       
                                          T
                                          E
                                       
                                    
                                 
                                 ,
                              
                           
                        where TP
                        
                           E
                         is the number of the correctly classified events (true positives) and GT
                        
                           E
                         is the total number of events.

In this experiment, we consider the foreground pixel classification performance of the proposed pixel-layer FSM because the LVSN and Wallflower public databases provide the ground-truths for foreground pixels. LVSN consists of two image sequences (Highway I and Highway III) including 20 images. Wallflower consists of seven sequences of seven images; we used the WavingTrees image sequence.

Among three different pixel SVM classifiers, we consider the SVM
                        
                           b
                         classifier because it determines whether a pixel is a background or foreground. Table 5
                         compared the precision and recall in the foreground pixel classification of the proposed ARO classification method (H-FSM) with those of the multi-hypothesis method [23] over all image sequences with ground-truth. From Table 5, we know that the proposed ARO classification method had 5% higher precision and 2% higher recall than the multi-hypothesis method over all image sequences; this means that the proposed ARO classification method has fewer number of falsely classified foreground pixels (false positives) and fewer number of missed foreground pixels (false negatives) than the multi-hypothesis method.


                        Fig. 8
                         shows the examples of the foreground pixel classification results with (a) Highway I, (b) Highway III and (c) Wallflower public database, where the first, second, third and fourth rows represent the input image sequence, the ground-truth sequence of the foreground regions, the results of the multi-hypothesis method [23] and the results of the proposed ARO classification method, respectively.

In this experiment, we consider the true static region classification performance of the proposed region-layer FSM using the public database built by i-LIDS (AB-Easy, AB-Medium, AB-Hard, ABTEA101a, PV-Easy, PV-Medium, PV-Hard, and PV-Night), PETS (Cam3) and CAVIAR (LeftBag), which include ten video clips and a total of twenty-eight static regions.


                           Table 6
                            compared TP
                           
                              R
                            and FP
                           
                              R
                            in the region classification of the proposed ARO classification method (H-FSM) with those of other methods [15,9,26,27], where Kim [27] is our previous method that uses the intensity, motion and shape features and one SVM classifier, over all image sequences with ground-truth and the number within parenthesis following the name of databases is the number of true static regions. From Table 6, we know that (1) all methods classified all true static regions on their test databases, (2) the proposed ARO classification method has the least number of falsely classified static regions and (3) the number of falsely classified static regions was largely dependent on the scene complexity such as traffic volume, and the existence of moving objects in the initial frames. The proposed ARO classification method rejects false static regions more effectively than other methods because it uses together multiple features that define the characteristics of true static regions accurately. Especially, the shape feature classifies well the temporarily stopped objects such as a person and a group of people.

In this experiment, we consider the true static region classification performance of the proposed region-layer FSM using the OV commercial database, which includes 22 video clips with a total of 62 static regions. The video clips are divided into three classes according to the discrimination difficulty levels: eight low, seven medium and seven high, where the high difficulty level consists of high traffic volumes and static regions that are frequently occluded by other foreground regions. To evaluate the true static region classification performance, we used the same SVM classifiers SVM
                           
                              B
                           , SVM
                           
                              F
                            and SVM
                           
                              S
                            which are used in the performance evaluation of the public database.


                           Tables 7 and 8
                           
                            compared TP
                           
                              R
                            (TCA) and FP
                           
                              R
                            (FCR) in the region classification of the proposed ARO classification method (H-FSM) with those of other methods (OV's commercial software) [28] and Kim [27] over all image sequences with ground-truth, and the number within parenthesis following difficulty levels is the number of true static regions. From Tables 7 and 8, we know that (1) TCA of the proposed ARO classification method was 32% higher than that of OV's method at all difficulty levels, (2) FCR of the proposed ARO classification method was 14% smaller than that of OV's method at all difficulty levels, (3) FCR of OV's commercial software was largely dependent on the scene complexity and increased in proportion to the traffic volume and (4) all methods show high average values of FCR because the relatively long playing time of the video clips causes a high probability that foreground regions will be falsely classified as true static regions (false positives). The proposed ARO classification method shows a stable true static region classification among different difficulty levels due to using the trained SVM classifiers for the state transitions. This stability makes the proposed ARO classification method applicable to various real situations. (See Fig. 11.)


                           Fig. 9
                            shows the examples on how a true static region is obtained over time, where the first, second and third rows represent the input image sequence, the foreground region sequence and the true static region sequence, respectively, and (a) one person approaches the fence (1700th frame), (b) he leaves a bag near his leg (1900th frame), (c) he departs from the bag (2100th frame) and (d) he disappears from the scene and the bag is abandoned (2300th frame).

We compared the proposed ARO classification method to OV's commercial software in two cases, one in which OV falsely classified a static region but the proposed ARO classification method did not (see Fig. 10-(a) and (b)); and one in which OV missed a static region but the proposed ARO classification method found it (see Fig. 10-(c) and (d)). OV's commercial software does not consider the shape information in the region-layer classification, so it falsely classified a static region in a group of two persons who did not move for a short time (see Fig. 10-(a)); but the proposed ARO classification method did not make this error (see Fig. 10-(b)). OV's commercial software considers only pixel-layer processing and can therefore be misled by rapid illumination change, so this algorithm missed a static region in an illegal parking scene due to the blinking of the car headlight (see Fig. 10-(c)); but the proposed ARO classification method did not make this error (see Fig. 10-(d)).

In this experiment, we used the OV commercial database to evaluate the abandoned or removed event classification accuracy of the proposed event-layer FSM. This database includes 22 video clips with a total of 62 static regions.


                        Table 9
                         compared SRDA in the event classification of the proposed ARO classification method (H-FSM) with those of other methods (OV's commercial software) [28] and Kim [27] over all image sequences with ground-truth, and the number within parenthesis following difficulty levels is the number of ARO events. From Table 9, we know that (1) OV's software and the Kim [27] method gave almost same SRDA because they use edge strength for event classification, (2) the proposed ARO classification method obtained perfect SRDA because this method uses color richness and edge strength together for event classification, and (3) the proposed ARO classification method had 4–5% higher SRDA than the other methods.

When processing pixels individually, average computation time was 50ms; the pixel (P)-, region (R)-, and event (E)-layer processing and background image update required 38, 6, 0.1 and 6ms, respectively. When processing blocks of 4×4pixels, average computation time was 18ms; the pixel-, region-, and event-layer processing and background image update required 10, 6, 0.1 and 2ms respectively (see Table 10
                        ), where the values in parenthesis are for the block-based processing.

The proposed ARO classification method successfully detected several real cases such as the detection of abandonment (littering, illegal parking (staying), camouflaged soldiers) and detection of removal (illegal parking (leaving), and theft of small and large objects) (see Fig. 11
                        ).

@&#CONCLUSION@&#

Most of existing feature-based ARO classification methods cannot be applied to the real situations because they show a large number of falsely classified static regions and low ARO classification performance due to many pre-defined threshold values which are affected by the environmental conditions such as illumination, traffic and noise. Most of existing FSM-based ARO classification methods consider only pixel-level FSM that is also largely dependent on the environmental conditions because their pixel-layer state transitions are performed using many non-trained pre-defined threshold values.

To overcome these limitations, we proposed a novel ARO classification method using a hierarchical FSM that consists of three layers. The pixel-layer identifies static pixels; the region-layer classifies static region candidates into true static regions; the event-layer classifies the true static regions as either abandoned or removed objects. State transitions using the trained pixel-layer, region-layer and event-layer SVM classifiers instead of many pre-defined threshold values reduce the sensitivity of the proposed ARO classification method to environmental conditions such as illumination, traffic and background complexity. The proposed ARO classification method uses a variety of features that are appropriate for pixel-layer, region-layer and event-layer processing such as area, intensity, motion, shape, time duration, color and edge information. The use of these features reduces the number of falsely classified pixels, regions and events effectively.

In experiments, the proposed ARO classification method gave much higher true classification accuracy and lower false classification ratios than all existing methods at all levels of difficulties in several public and commercial video databases. The proposed ARO classification method is general due to the training of SVM classifiers, and so it can be applied to various real situations such as the detection of littering, illegal parking, thief, and camouflaged soldiers.

@&#ACKNOWLEDGMENT@&#

This work was supported by Institute for Information & Communications Technology Promotion (IITP) grant funded by the Korean government (MSIP) (B0101-15-0552, Development of Predictive Visual Intelligence Technology). This work was also supported by the Implementation of Technologies for Identification, Behavior, and Location of Human based on Sensor Network Fusion Program through the Ministry of Trade, Industry and Energy (Grant Number: 10041629).


                     
                        
                           
                              Supplementary video.
                           
                           
                        
                     
                  

Supplementary data to this article can be found online at http://dx.doi.org/10.1016/j.imavis.2015.09.004.

@&#REFERENCES@&#


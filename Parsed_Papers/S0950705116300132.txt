@&#MAIN-TITLE@&#Item-based relevance modelling of recommendations for getting rid of long tail products

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The liquidation of long tail items can be assisted by recommender systems.


                        
                        
                           
                           We propose a probabilistic item-based Relevance Model (IRM2).


                        
                        
                           
                           IRM2 outperforms state-of-the-art recommenders for long tail liquidation.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Recommender systems

Collaborative filtering

Relevance models

Long tail

@&#ABSTRACT@&#


               
               
                  Recommender systems are a growing research field due to its immense potential application for helping users to select products and services. Recommenders are useful in a broad range of domains such as films, music, books, restaurants, hotels, social networks, news, etc. Traditionally, recommenders tend to promote certain products or services of a company that are kind of popular among the communities of users. An important research concern is how to formulate recommender systems centred on those items that are not very popular: the long tail products. A special case of those items are the ones that are product of an overstocking by the vendor. Overstock, that is, the excess of inventory, is a source of revenue loss. In this paper, we propose that recommender systems can be used to liquidate long tail products maximising the business profit. First, we propose a formalisation for this task with the corresponding evaluation methodology and datasets. And, then, we design a specially tailored algorithm centred on getting rid of those unpopular products based on item relevance models. Comparison among existing proposals demonstrates that the advocated method is a significantly better algorithm for this task than other state-of-the-art techniques.
               
            

Recommender systems are becoming increasingly popular to help users with the finding of relevant items. On the one hand, users are becoming more demanding and, on the other hand, more amount of information is available. For this reason, many e-commerce companies have started to use these systems for product recommendation with the intention of increasing the number of sales. From the business perspective, recommenders are effective tools to improve user satisfaction and, thus, sales revenue. The former is achieved through high quality recommendations whilst the latter is more dependent of the seller circumstances. It is hard to establish what is a good recommendation. Research efforts have focused on accuracy since the very beginning of the field of recommender systems. However, recent studies have pointed out the importance that other properties such as serendipity, novelty or diversity may have as key features to deliver good recommendations [14,23].

There exist several aspects that should be taken into account with respect to revenue enhancement. Fleder and Hosanagar have analysed thoroughly the effect of recommender systems in sales diversity [12]. These authors concluded that recommenders can increase sales if they discount popularity appropriately generating more diverse suggestions. The key idea behind this study is that recommenders should not focus solely on popular products but also on long-tail items. This proposition is the main idea of Anderson’s book The Long Tail: Why the Future of Business Is Selling Less of More 
                     [2]. He coined the term long tail to refer to those less popular products that have a low demand in large catalogues. In the current context of e-commerce, he declared that promoting long tail items is crucial for both the user and the business: customers may discover new and unexpected relevant products while the companies may sell the majority of their stock. He claimed that a retailing strategy based on selling a large number of products in small quantities is more profitable than a business centred on selling large amounts of a small set of popular products.

Traditionally, recommendation approaches in the long tail [27,39] have explored ways for promoting long tail items in the recommendation process. However, addressing the long tail problem in that way is not particularly novel because a high performance recommender should recommend both popular and long tail items according to what fits best to the users’ tastes. A growing body of literature has focused on improving the diversity of recommender systems [1,34]. Since more diverse recommendations are expected to lead to a larger catalogue coverage, more long tail products are likely to be recommended. In the same way, many studies have analysed the importance of novelty in recommendation. A recommendation is considered novel when the recommended item is unpopular (such as a long tail). Although enhancing diversity and novelty is a way for recommending more long tail products, we argue that there will still be items that vendors will be unable to sell.

The long tail nature of a product can be produced by very different factors: it is rarely sold and therefore has very few ratings, it is sold but it has almost no ratings given its embarrassing nature (e.g., sex toys) or it is barely recommended by the existing recommender. All these aspects make recommending in the long tail an extremely difficult task. Thus, effectively suggesting all the products of companies’ catalogues is almost impossible following a unified approach.

In business terminology, the items from the inventory of a company that cannot be successfully sold are called excessive stock or overstock. Overstock can be the result of poor prediction of product demand but it can also be a consequence of market fluctuations.Thus, an effective process management and a diverse recommender may minimise overstock effects. However, as we stated before, despite the efforts oriented towards improving sales of long tail products, there will be situations when companies will not be able to sell some items. In this case, we think that a specially designed recommender may provide interesting benefits. Therefore, in this paper, we develop a formal recommender model for dealing with these products which may help companies to liquidate their excessive stock.

To the best of our knowledge, the specific problem of getting rid of long tail items (i.e., liquidating stock) has never been addressed systematically. Thus, first, we state the overstock clearance problem formally, we study how to evaluate this task and how this process differs from the classic recommendation problem. Next, we propose three methodologies for estimating which items are part of the excessive stock of businesses given a standard recommendation dataset. Then, we adapt a collaborative filtering approach whose roots lie in pseudo-relevance feedback (a well-known task in the Information Retrieval field) to the overstock liquidation problem. This approach builds a statistical relevance model of each of the long tail items which enables the identification of target users for selling those particular items. Finally, we conduct a series of thorough experiments to analyse and compare the performance of our proposal with other collaborative filtering algorithms. The results confirm our intuition that a probabilistic item-based relevance model enables to build an effective recommender to get rid of the long tail products.

In brief, the contributions presented in this article are: (1) the formulation of a novel recommendation task consisting in liquidating long tail items, (2) the proposal of three different methodologies for estimating the overstock products of a dataset and its critical analysis, (3) the design of a collaborative filtering algorithm based on relevance modelling for the task of liquidating long tail items and (4) the empirical comparison of different collaborative filtering algorithms (including the proposed one) under this novel task.

The objective of a recommender system is to elaborate personalised rankings of products for each user. Every recommendation task involves a set of products or items (we will use these two terms interchangeably), which we denote as 
                        
                           I
                           ,
                        
                      and a set of possible customers or users, denoted as 
                        U
                     . Recommendation in the long tail refers to the generation of item recommendations to users including not only popular products but also long tail ones. However, here we propose a different approach: for those items in the long tail we want to get rid of, we want to identify those potential users that will buy the product, even when that item is not on the top of the users’ preferences. Of course, this approach does not replace the classic recommendation. On the contrary, it is specially designed to address a business concern and should be used as a complement to current methods in a operational setting. We claim that recommenders may help to get rid of long tail products which can be seen as a proxy representation of the overstock phenomena.

Recommender systems are usually classified in three main categories: content-based, collaborative filtering and hybrid techniques [6,28]. While content-based recommenders employ the properties of the items to recommend similar items to those appreciated by the user [20], collaborative filtering techniques rely on data about past interactions between users and items (ratings, purchases, clicks, etc.) [11]. And, finally, hybrid methods combine algorithms from both families. Content-based algorithms are usually preferred for improving novelty because they find similar items based on content, not on popularity [24]. However, sometimes the available information about items is not adequate for using this family of methods. Additionally, content-based recommenders may lead to over-specialisation suggesting only items that are very similar to those rated by the target user [11]. Therefore, we propose a collaborative filtering approach specially designed for the task of getting rid of the long tail.

Since we are focusing on a pure collaborative filtering approach, we are interested in the users’ feedback. We are assuming that we have explicit feedback, i.e., ratings from users to items. However, our proposal is also suitable for dealing with implicit feedback such as clicks or purchase information that can be represented with binary ratings. We indicate the relationship between the user u and the item i with the rating r
                     
                        u, i
                     . We can organise these ratings in a user-item matrix R. Additionally, 
                        
                           U
                           i
                        
                      refers to the subset of users that rated the item i. Similarly, 
                        
                           I
                           u
                        
                      denotes the subset of items that have been rated by the user u.

Collaborative filtering algorithms exploit the past interactions between users and items to create meaningful recommendations. We can classify these techniques in two main categories [11]. Model-based approaches build a predictive model from the ratings. In contrast to these systems, which learn patterns from historical data, memory-based methods (also known as neighbourhood-based) actually employ all the ratings stored in the system. Memory-based algorithms can compute suggestions using the information of like-minded people (user-based) or, on the other hand, recommend items that are similar to the ones the user liked in the past (item-based).

The classic task in the field of recommender systems consists in estimating, given a particular user, the top items for which this user is most likely to be interested in. This task can be formulated as finding a scoring function 
                        
                           s
                           
                           :
                           
                           U
                           ×
                           I
                           →
                           R
                        
                      such that, for each user u, we can generate a ranked list of k items 
                        
                           
                              L
                              u
                              k
                           
                           ∈
                           
                              I
                              k
                           
                        
                      sorted by decreasing score order.

In this article, we propose a novel recommendation problem: instead of generating the best item suggestions for each user, we aim to find the best users for each long tail product. The inversion of the classic recommendation task (recommending users to items in the place of suggesting items to users) was recently studied to improve sales diversity [34]. These authors explored the inverted task and proposed a probabilistic approach that enhances sales diversity. Still, at the end, their intent was to improve the original recommendation problem (suggesting items to users). In contrast, our intention is to address a very different problem: how to get rid of the excessive stock suggesting the most suitable users for each item.

We use the notation 
                           
                              I
                              ′
                           
                         to identify the subset of items (
                           
                              
                                 I
                                 ′
                              
                              ⊂
                              I
                           
                        ) that are the part of the catalogue that conforms the products we want to liquidate. For a particular item 
                           
                              i
                              ∈
                              
                                 I
                                 ′
                              
                              ,
                           
                         we intend to find a ranked list of k users, 
                           
                              
                                 L
                                 i
                                 k
                              
                              ,
                           
                         that are most likely interested in such item i. Thus, using the user-item matrix R, our objective is to find a scoring function 
                           
                              
                                 s
                                 ′
                              
                              
                              :
                              
                              
                                 I
                                 ′
                              
                              ×
                              U
                              →
                              R
                           
                        . It is important to remark that we use the ratings emitted to all the items, 
                           
                              I
                              ,
                           
                         but we are only interested in generating recommendations for the overstock products, 
                           
                              
                                 I
                                 ′
                              
                              ,
                           
                         exclusively.

Sales on e-commerce sites depend on multiple factors. Seasonality is especially relevant because some products become outdated while new items appear. Additionally, other factors such as price fluctuations or changes in the users’ needs may affect sales numbers. In order to deal with these issues, we can liquidate stock at the end of the season. Therefore, the recommendation algorithms should use the available data of the season to generate stock liquidation suggestions at the end of this period. Users’s needs should not change extremely during the season and price should be managed according to the liquidation policy of the company. In this way, we can effectively apply a collaborative filtering approach without using outdated information from past seasons.

To evaluate the performance of recommender under this novel task of liquidating stock, we have to adapt current evaluation methodologies for classic recommendation. We describe this process in Section 4.3. Additionally, we need to define what is the set of long tail products 
                           
                              I
                              ′
                           
                        . To the best of our knowledge, there is no public collection available for research that specifies excessive stock. Since we lack of datasets with such kind of information, we designed three approaches to estimate the subset of overstock items. We should note that, for this purpose, we use all the information in the datasets (without training and testing splits) because we are merely designating which items are excessive stock. The splits of the collections will be used to train and evaluate the recommenders. The experiments based on the collections built with the methods here described will be presented in Section 4.

We can argue that the least rated items conform the set of overstock products we want to get rid off because few users have shown interest in them. This is the most common approach used in recent studies [9,39]. Thus, given the threshold c
                           1 we can select a subset of items that have less than c
                           1 ratings/purchases:

                              
                                 (1)
                                 
                                    
                                       
                                          I
                                          ′
                                       
                                       =
                                       
                                          {
                                          
                                             i
                                             ∈
                                             I
                                             
                                             |
                                             
                                             |
                                          
                                          
                                             U
                                             i
                                          
                                          
                                             |
                                             <
                                          
                                          
                                             c
                                             1
                                          
                                          }
                                       
                                    
                                 
                              
                           
                        

We remind that 
                              
                                 U
                                 i
                              
                            refers to the set of users that rated the item i. We decided to use a fixed threshold instead of relying on a percentage (e.g., taking the 5% of least rated products) because in this way we can assure that the selected items are rarely sold (if we choose a proper threshold). In contrast, there will be always items in the bottom percentiles, but we cannot assure that those are long tail items, only that they are the least sold in the dataset.

Another approach to the estimation of the overstock products is to suppose that the items with the lowest ratings are the ones that cannot be sold by the company. We only need to choose a value for c
                           2 to specify the threshold of what is a low rating.

                              
                                 (2)
                                 
                                    
                                       
                                          I
                                          ′
                                       
                                       =
                                       
                                          {
                                          i
                                          ∈
                                          I
                                          |
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      u
                                                      ∈
                                                      
                                                         U
                                                         i
                                                      
                                                   
                                                
                                                
                                                   r
                                                   
                                                      u
                                                      ,
                                                      i
                                                   
                                                
                                             
                                             
                                                
                                                   |
                                                
                                                
                                                   U
                                                   i
                                                
                                                
                                                   |
                                                
                                             
                                          
                                          <
                                          
                                             c
                                             2
                                          
                                          }
                                       
                                    
                                 
                              
                           
                        

Again, the same motivation as in the preceding strategy favours the use of a fixed threshold instead of a percentage. Please note that it is not advisable for a traditional recommender system to recommend low quality items (probably those with low ratings) to their users. However, in this paper, we are tackling a very different problem: we want to get rid of long tail items, no matter the cost. Thus, we are devising a recommendation technique that is able to select which users are the potential buyers of a long tail item. We leave to the manager the responsibility of choosing if liquidating items with very low ratings is a good idea (perhaps offering an important discount). In this work, our objective is to present a recommendation algorithm that is capable of doing so if needed.

Finally, according to a recent study which has pointed out the effect of recommendations diversity in e-commerce sales [12], it is plausible to state that those products that a standard recommender system does not suggest are not going to be sold. Thus, given a particular threshold c
                           3, we can construct a set of items that are not present in the top c
                           3 results of any user recommendation list:

                              
                                 (3)
                                 
                                    
                                       
                                          I
                                          ′
                                       
                                       =
                                       
                                          {
                                          i
                                          ∈
                                          I
                                          
                                          |
                                          
                                          i
                                          ∉
                                          
                                             L
                                             
                                                u
                                             
                                             
                                                c
                                                3
                                             
                                          
                                          ,
                                          
                                          ∀
                                          u
                                          ∈
                                          U
                                          }
                                       
                                    
                                 
                              
                           
                        

In this section we address our proposal for dealing with long tail items. For this purpose, we employed Relevance-based Language Models (frequently abbreviated as Relevance Models or RM). This method is a state-of-the-art technique for performing automatic query expansion via pseudo-relevance feedback [19]. In text retrieval, a user introduces a query into the system and the outcome is a list of documents ranked according to an estimated relevance measure between the documents and the query. Since the query is an imperfect representation of the user’s information need, research efforts have focused on expanding the query with new meaningful terms [8]. Pseudo-relevance feedback is a technique that aims to expand the user’s query automatically extracting terms from a set of pseudo-relevant documents [38]. These documents are obtained as the top results of an initial retrieval process that is carried out with the original query.

Language Models follow the Probability Ranking Principle which states that documents should be ranked in descending order of probability of relevance [29,40]. Despite Language Models do not explicitly include the concept of relevance, they can be derived from a generative relevance model [18]. In contrast, Relevance-Based Language Models estimate a relevance model for each query [19].

Recently, [26] adapted RM to the collaborative filtering task achieving high accuracy figures. The key idea is to adapt the pseudo-relevance feedback paradigm to recommendation. This involves mapping a triadic space (queries, documents and terms) to a dyadic one (user and items). Queries and documents are both mapped to users while terms play the role of items. Thus, instead of expanding a query with new terms, user profiles are expanded with items from a pseudo-relevant set. We can compute this set calculating the target user’s neighbourhood using some standard techniques in the field of Recommender Systems.

In this paper, we designed a different approach to collaborative filtering using also Relevance Models. We propose the construction of a Relevance Model for each long tail product. We intend to expand item profiles with relevant users using information from similar items. The objective is to estimate the probability of a user u under the Relevance Model of an item i, p(u|Ri
                     ). Note that our approach to collaborative filtering recommendation using RM is not just the item-based version of the model proposed in [26]. In [26], the authors built a Relevance Model for each user and estimated the probability of relevance of each item, p(i|Ru
                     ). We cannot apply directly this model to the long tail liquidation task because probabilistic relevance estimates across users are not comparable. Given two users u and v and the long tail item i we cannot generate recommendations of users to liquidate that item sorting p(i|Ru
                     ) and p(i|Rv
                     ) since we are comparing estimates from different Relevance Models. Likewise, we cannot apply Bayes’s Theorem to get the bayesian inversion because the estimation of p(Ri
                     |u) o p(Rj
                     |u) does not make sense within this probabilistic framework. Therefore, we need to build a RM for each item if we want to model long tail items and choose the best users for them.

There exist two methods for approximating a Relevance Model: assuming independent and identically distributed sampling (RM1) or conditional sampling (RM2) [19]. In this paper, we focus on the latter because it has demonstrated better performance on the recommender task in our experiments. We refer to the adaptation of the RM2 model to the long tail liquidation problem as IRM2 (Item Relevance Modelling 2). Next, we present the derivation of the IRM2 algorithm based on the previous work on Relevance-Based Language Models for pseudo-relevance feedback [19].

IRM2 aims to build a relevance model Ri
                         for each long tail product 
                           
                              i
                              ∈
                              
                                 I
                                 ′
                              
                           
                         of the collection. In this way, we can estimate the relevance of each user for a given long tail product. Thus, in our stock liquidation task, we can define an Item Relevance Model as a formalism that enables to compute the probability that a user u rates a long tail item i, p(u|Ri
                        ). We ignore which users will rate certain product, but we can use the history of ratings of that item and other relevant items to estimate it.

We assume that the relevance model Ri
                         generates the long tail item i but also a set of relevant items Ji
                        . Fig. 1
                         illustrates how the item i and the set of relevant items Ji
                         are random samples from an unknown relevance model Ri
                        . As we will see below, the sampling process for the target item i can be different from the sampling for the relevant products Ji
                        . With these assumptions, we are going to estimate p(u|Ri
                        ) for each user 
                           
                              u
                              ∈
                              U
                           
                        .

First, we sample item i from the underlying relevance model Ri
                        . This process consists in repeatedly sampling k users 
                           
                              
                                 v
                                 1
                              
                              ⋯
                              
                                 v
                                 k
                              
                           
                         from Ri
                        . These users correspond to the clients that bought the item i, 
                           
                              
                                 U
                                 i
                              
                              =
                              
                                 {
                                 
                                    v
                                    1
                                 
                                 ⋯
                                 
                                    v
                                    k
                                 
                                 }
                              
                           
                        . Since we sample k users for item i, 
                           
                              
                                 k
                                 =
                                 |
                              
                              
                                 U
                                 i
                              
                              
                                 |
                              
                           
                        . To estimate p(u|Ri
                        ), which is unknown, we rely on what we observed before: the set of users 
                           
                              U
                              i
                           
                        . We need to answer what is the probability that the next user we sample from the relevance model will be u. Formally, we can formulate this question in the following way:

                           
                              (4)
                              
                                 
                                    p
                                    
                                       (
                                       u
                                       |
                                       
                                          R
                                          i
                                       
                                       )
                                    
                                    ≈
                                    p
                                    
                                       (
                                       u
                                       |
                                       
                                          v
                                          1
                                       
                                       ⋯
                                       
                                          v
                                          k
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

Applying the definition of conditional probability, we can reformulate the previous equation in terms of the joint probability of observing the user u along with users 
                           
                              
                                 v
                                 1
                              
                              ⋯
                              
                                 v
                                 k
                              
                           
                         divided by the joint probability of observing users 
                           
                              
                                 v
                                 1
                              
                              ⋯
                              
                                 v
                                 k
                              
                           
                        . Note that we can safely ignore the denominator because it remains constant for the same item i (it would not affect the final ranking):

                           
                              (5)
                              
                                 
                                    p
                                    
                                       (
                                       u
                                       |
                                       
                                          R
                                          i
                                       
                                       )
                                    
                                    ≈
                                    
                                       
                                          p
                                          (
                                          u
                                          ,
                                          
                                             v
                                             1
                                          
                                          ⋯
                                          
                                             v
                                             k
                                          
                                          )
                                       
                                       
                                          p
                                          (
                                          
                                             v
                                             1
                                          
                                          ⋯
                                          
                                             v
                                             k
                                          
                                          )
                                       
                                    
                                    ∝
                                    p
                                    
                                       (
                                       u
                                       ,
                                       
                                          v
                                          1
                                       
                                       ⋯
                                       
                                          v
                                          k
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

Following on the conditional sampling method proposed by Lavrenko and Croft [19], we estimate the joint probability of observing the user u along with the users 
                           
                              v
                              ∈
                              
                                 U
                                 i
                              
                           
                         based on the ratings distribution of the relevant items j ∈ Ji
                        . We present a diagram of this sampling scheme in Fig. 2
                        .

First, to estimate the relevance model of item i, Ri
                        , we pick a user u given the prior probability p(u). This user u will condition the selection of item distributions from which we will sample the users 
                           
                              
                                 v
                                 1
                              
                              ⋯
                              
                                 v
                                 k
                              
                           
                        :

                           
                              (6)
                              
                                 
                                    p
                                    
                                       (
                                       u
                                       |
                                       
                                          R
                                          i
                                       
                                       )
                                    
                                    ∝
                                    p
                                    
                                       (
                                       u
                                       ,
                                       
                                          v
                                          1
                                       
                                       ⋯
                                       
                                          v
                                          k
                                       
                                       )
                                    
                                    =
                                    p
                                    
                                       (
                                       u
                                       )
                                    
                                    
                                       ∏
                                       
                                          v
                                          ∈
                                          
                                             U
                                             i
                                          
                                       
                                    
                                    p
                                    
                                       (
                                       v
                                       |
                                       u
                                       )
                                    
                                 
                              
                           
                        
                     

Following the scheme from Fig. 2, to estimate the conditional probability p(v|u), we repeat the following process k times: we pick an item distribution j according to p(j|u) and, then, we sample a user 
                           
                              v
                              ∈
                              
                                 U
                                 i
                              
                           
                         from the item distribution j with probability p(v|j). Note that this sampling strategy considers that users 
                           
                              
                                 v
                                 1
                              
                              ⋯
                              
                                 v
                                 k
                              
                           
                         are sampled independently of each other, but they are dependent on u. Applying the law of total probability we obtain the following:

                           
                              (7)
                              
                                 
                                    p
                                    
                                       (
                                       v
                                       |
                                       u
                                       )
                                    
                                    =
                                    
                                       ∑
                                       
                                          j
                                          ∈
                                          
                                             J
                                             i
                                          
                                       
                                    
                                    p
                                    
                                       (
                                       v
                                       |
                                       j
                                       ,
                                       u
                                       )
                                    
                                    
                                    p
                                    
                                       (
                                       j
                                       |
                                       u
                                       )
                                    
                                 
                              
                           
                        
                     

If we assume that users 
                           
                              v
                              ∈
                              
                                 U
                                 i
                              
                           
                         become independent of u after choosing an item distribution j ∈ Ji
                        , we can simplify Eq. 7 obtaining the following estimate:

                           
                              (8)
                              
                                 
                                    p
                                    
                                       (
                                       v
                                       |
                                       u
                                       )
                                    
                                    =
                                    
                                       ∑
                                       
                                          j
                                          ∈
                                          
                                             J
                                             i
                                          
                                       
                                    
                                    p
                                    
                                       (
                                       v
                                       |
                                       j
                                       )
                                    
                                    
                                    p
                                    
                                       (
                                       j
                                       |
                                       u
                                       )
                                    
                                 
                              
                           
                        
                     

Applying Bayes’ Theorem, we can estimate p(j|u) as follows:

                           
                              (9)
                              
                                 
                                    p
                                    
                                       (
                                       j
                                       |
                                       u
                                       )
                                    
                                    =
                                    
                                       
                                          p
                                          (
                                          u
                                          |
                                          j
                                          )
                                          
                                          p
                                          (
                                          j
                                          )
                                       
                                       
                                          p
                                          (
                                          u
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

Finally, plugging Eqs. 8 and 9 into Eq. 6, we obtain the final IRM2 estimate:

                           
                              (10)
                              
                                 
                                    p
                                    
                                       (
                                       u
                                       |
                                       
                                          R
                                          i
                                       
                                       )
                                    
                                    ∝
                                    p
                                    
                                       (
                                       u
                                       )
                                    
                                    
                                       ∏
                                       
                                          v
                                          ∈
                                          
                                             U
                                             i
                                          
                                       
                                    
                                    
                                       ∑
                                       
                                          j
                                          ∈
                                          
                                             J
                                             i
                                          
                                       
                                    
                                    p
                                    
                                       (
                                       v
                                       |
                                       j
                                       )
                                    
                                    
                                    
                                       
                                          p
                                          (
                                          u
                                          |
                                          j
                                          )
                                          
                                          p
                                          (
                                          j
                                          )
                                       
                                       
                                          p
                                          (
                                          u
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

For estimating the probability of user u under the Relevance Model Ri
                        , IRM2 iterates over the users who rated that item, 
                           
                              
                                 U
                                 i
                              
                              ,
                           
                         and over the set of relevant items to that item i, Ji
                        . For the sake of simplicity, we consider prior probability estimates, p(u) and p(j), uniform. However, these priors open the door to explore new estimations that may improve the performance or even include business aspects as it was done in [32] with the original Relevance Model recommender proposed in [26]. We leave this possibility for future work.

With the estimate from Eq. 10 we can generate the list of recommendations Li
                         for each long tail item 
                           
                              i
                              ∈
                              
                                 I
                                 ′
                              
                           
                        . Thus, for each user 
                           
                              u
                              ∈
                              U
                              ,
                           
                         we build the list Li
                         sorting those users by decreasing estimated relevance p(u|Ri
                        ).

Additionally, we need to provide two final estimation details. The first question is which items conforms the set of relevant items Ji
                        . We explain this issue in Section 3.2. The other issue is how to calculate the probability of a user u given the item distribution j, p(u| j). For this purpose, we use the maximum likelihood estimate of a multinomial distribution over the ratings:

                           
                              (11)
                              
                                 
                                    
                                       p
                                       
                                          m
                                          l
                                       
                                    
                                    
                                       (
                                       u
                                       |
                                       j
                                       )
                                    
                                    =
                                    
                                       
                                          r
                                          
                                             u
                                             ,
                                             j
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                v
                                                ∈
                                                
                                                   U
                                                   j
                                                
                                             
                                          
                                          
                                             r
                                             
                                                v
                                                ,
                                                j
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

However, this estimate suffers from data sparsity. Thus, we need to use smoothing techniques, which are the way to solve this problem in the language modelling framework [41]. We discuss about smoothing in Section 3.3.

In Eq. 10, we can observe that IRM2 leverages the information from a set of relevant items to estimate the users’ relevance. Since we ignore which items are relevant to some item i and we do not have explicit relevance feedback information, we need to compute approximation using the available data. We assumed that the similar items to item i are the pseudo-relevant items for the relevance model Ri
                        . We use the term pseudo-relevant because we want to emphasize that these products are an approximation of the real relevant items.

We employ clustering techniques for computing the set of pseudo-relevant items based on the ratings. In our case, we used the kNN algorithm which consists in taking the k nearest neighbours (in this case, the k most similar items) according to a pairwise similarity [11]. Even though Pearson’s correlation coefficient is the most common measure, we employed cosine similarity which yielded better results in our experiments—this outcome is consistent with results reported for state-of-the-art top-N recommenders [9]. The cosine similarity s between two items i and j is given by the following formula:

                           
                              (12)
                              
                                 
                                    s
                                    
                                       (
                                       i
                                       ,
                                       j
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                u
                                                ∈
                                                
                                                   U
                                                   i
                                                
                                                ∩
                                                
                                                
                                                   U
                                                   j
                                                
                                             
                                          
                                          
                                             r
                                             
                                                u
                                                ,
                                                i
                                             
                                          
                                          
                                          
                                             r
                                             
                                                u
                                                ,
                                                j
                                             
                                          
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   u
                                                   ∈
                                                   
                                                      U
                                                      i
                                                   
                                                
                                             
                                             
                                                r
                                                
                                                   u
                                                   ,
                                                   i
                                                
                                                2
                                             
                                             
                                                ∑
                                                
                                                   v
                                                   ∈
                                                   
                                                      U
                                                      j
                                                   
                                                
                                             
                                             
                                                r
                                                
                                                   v
                                                   ,
                                                   j
                                                
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The three most popular methods for smoothing Language Models are Jelinek-Mercer, Dirichlet priors and Absolute Discounting [41]. These methods smooth the maximum likelihood estimate pml
                        (u|i) (Eq. 11) with a background model which, in our case, is the user probability in the collection:

                           
                              (13)
                              
                                 
                                    p
                                    
                                       (
                                       u
                                       |
                                       C
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             
                                                j
                                                ∈
                                                I
                                             
                                          
                                          
                                             r
                                             
                                                u
                                                ,
                                                j
                                             
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                v
                                                ∈
                                                U
                                                ,
                                                
                                                j
                                                ∈
                                                I
                                             
                                          
                                          
                                             r
                                             
                                                v
                                                ,
                                                j
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The main goals of smoothing are: on the one hand, preventing the apparition of zeros due to the data sparsity and, on the other hand, adding the effect of the idf (inverse document frequency) [41]. Additionally, some smoothing techniques also provide the effect of length normalisation [21].

The impact of smoothing methods for RM has been studied before in the context of the classic recommendation task [33] concluding that Absolute Discounting is the best choice. Despite our work is devoted to a different task—liquidating excessive stock—, we found the behaviour of these techniques under this new problem is similar. The optimal values of the smoothing parameters vary, but Absolute Discounting is still the best option.

Absolute Discounting subtracts the same constant, δ, from the count of all the seen ratings. Then, a count proportional to the probability in the collection is added to each user:

                           
                              (14)
                              
                                 
                                    
                                       p
                                       δ
                                    
                                    
                                       (
                                       u
                                       |
                                       j
                                       )
                                    
                                    =
                                    
                                       
                                          max
                                          
                                             (
                                             
                                                r
                                                
                                                   u
                                                   ,
                                                   j
                                                
                                             
                                             −
                                             δ
                                             ,
                                             0
                                             )
                                          
                                          +
                                          δ
                                          
                                          
                                             |
                                             
                                                U
                                                j
                                             
                                             |
                                          
                                          
                                          p
                                          
                                             (
                                             u
                                             |
                                             C
                                             )
                                          
                                       
                                       
                                          
                                             ∑
                                             
                                                v
                                                ∈
                                                
                                                   U
                                                   j
                                                
                                             
                                          
                                          
                                             r
                                             
                                                v
                                                ,
                                                j
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Thus, the above estimate is used to calculate p(u|j) and p(v|j) in the computation of the item relevance model (Eq. 10).

@&#EVALUATION@&#

We conducted a series of experiments to analyse the performance of our proposal, IRM2, for the novel task of liquidating long tail items. In this section, we describe the set-up of the experiments and then we present and discuss the results.

We conducted our experiments in three different collections. On the one hand, we used a well-known film dataset, Movielens 1M
                        
                           1
                        
                        
                           1
                           
                              http://grouplens.org/datasets/movielens/
                           
                        , that contains 1 million ratings from users with at least 20 ratings and the LibraryThing
                           2
                        
                        
                           2
                           
                              http://www.macle.nl/tud/LT/
                           
                         dataset which contains 750 thousand ratings. On the other hand, we employed the The detailed statistics of each collection after these preprocessing steps are reflected in Table 1
                        . We selected these datasets because they are from different domains and they have diverse amount of sparsity.

Each collection was divided into training and test subsets. Instead of performing a whole random sampling of the collection, for each item we included the 80% of its ratings in the training subset whilst the rest is part of the test subset. We prefer this partition because, in this way, we assure that each item have ratings both in the training and the test sets. This enables to evaluate the performance of the recommendation algorithms on all the long tail items. The training/test split is designed for evaluation purposes: the training subset is used as seed data for the recommender system while the testing subset is devoted to determine the recommender performance.

To assess the performance of our proposed algorithm, we must compare it with a set of representative baseline recommender systems. To the best of our knowledge, no specific algorithm exists for the novel task we are proposing. Therefore, we had to use standard collaborative filtering algorithms from the state of the art. Since these methods are designed for computing item recommendations for users, we adapted them to the task of long tail liquidation. We describe these adaptations together with the method. Recommending long tail items is difficult and the collections we built are estimations of the excessive stock. Therefore, facing this novel task, it is important to use a great variety of algorithms which employ different strategies in order to make a complete comparison between our proposal and very diverse approaches. We describe the baselines below.

This strategy is not a recommender, but a basic baseline to establish the relative difference among algorithms since it should yield the worst performance. This algorithm simply recommends random users to long tail items.

Again, this is not a proper recommender algorithm, but a naïve approach to compare more sophisticated methods. This strategy chooses the most popular users for all the items. In other words, for each item, we recommend the same set of users: the ones who have more ratings in the training set.

A classic collaborative filtering technique consists in computing a set of k nearest neighbours (kNN) for each user or item [11]. These neighbourhood relationships are computed using pairwise similarities. We used Pearson’s correlation coefficient for this purpose because it is the most common similarity for this method [11]. Once we have calculated the neighbourhood, the recommender aims to predict the rating that the target user would emit based on the ratings of the neighbours. User-based (kNN-UB) and item-based (kNN-IB) versions are presented in Eqs. 15 and 16, respectively.

                              
                                 (15)
                                 
                                    
                                       
                                          
                                             r
                                             ^
                                          
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   v
                                                   ∈
                                                   
                                                      V
                                                      u
                                                   
                                                
                                             
                                             
                                                ρ
                                                
                                                   u
                                                   ,
                                                   v
                                                
                                             
                                             
                                             
                                                r
                                                
                                                   v
                                                   ,
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   v
                                                   ∈
                                                   
                                                      V
                                                      u
                                                   
                                                
                                             
                                             
                                                |
                                                
                                                   ρ
                                                   
                                                      u
                                                      ,
                                                      v
                                                   
                                                
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (16)
                                 
                                    
                                       
                                          
                                             r
                                             ^
                                          
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   
                                                      J
                                                      i
                                                   
                                                
                                             
                                             
                                                ρ
                                                
                                                   i
                                                   ,
                                                   j
                                                
                                             
                                             
                                             
                                                r
                                                
                                                   u
                                                   ,
                                                   j
                                                
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   
                                                      J
                                                      i
                                                   
                                                
                                             
                                             
                                                |
                                                
                                                   ρ
                                                   
                                                      i
                                                      ,
                                                      j
                                                   
                                                
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

where ρ
                           
                              i, j
                            is the Pearson’s similarity between items i and j and Ji
                            indicates the neighbourhood of item i. Likewise, ρ
                           
                              u, v
                            is the Pearson’s similarity between users u and v and Vu
                            represents the neighbourhood of user u.

For recommending users to long tail items, we generate a recommendation list Li
                            for each 
                              
                                 i
                                 ∈
                                 
                                    I
                                    ′
                                 
                              
                           . This list contains those users 
                              
                                 u
                                 ∈
                                 U
                              
                            with the largest predicted rating, 
                              
                                 
                                    r
                                    ^
                                 
                                 
                                    u
                                    ,
                                    i
                                 
                              
                           .

UIR is a probabilistic recommendation technique [37]. Thus, it shares some principles with the RM2 method for recommendation [26]. UIR estimate the relevance of an item for a given user based on the Probability Ranking Principle [29].

Although it was proposed for implicit feedback datasets, their use with explicit feedback is straightforward. In fact, it has been previously used with explicit feedback [26,31]. Both item-based and user-based variants exist. We used the item-based version (UIR-Item) because it clearly outperformed the user-based counterpart in all our testing scenarios. Despite being an item-based approach, UIR-Item still computes an estimate of relevance of an item given a user model as the RM2 model for recommendation does [26]. We will elaborate on this issue later in the discussion section.

The formula for estimating the score of the item i for the user u under the UIR-Item model is given by:

                              
                                 (17)
                                 
                                    
                                       score
                                       
                                          (
                                          u
                                          ,
                                          i
                                          )
                                       
                                       ∝
                                       
                                          ∑
                                          
                                             
                                                
                                                   
                                                      j
                                                      ∈
                                                      
                                                         I
                                                         u
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         U
                                                         i
                                                      
                                                      ∩
                                                      
                                                         U
                                                         j
                                                      
                                                      ≠
                                                      ∅
                                                   
                                                
                                             
                                          
                                       
                                       log
                                       
                                          (
                                          1
                                          +
                                          
                                             
                                                
                                                   (
                                                   1
                                                   −
                                                   λ
                                                   )
                                                
                                                
                                                
                                                   p
                                                   
                                                      m
                                                      l
                                                   
                                                
                                                
                                                   (
                                                   j
                                                   |
                                                   i
                                                   ,
                                                   r
                                                   )
                                                
                                             
                                             
                                                λ
                                                
                                                p
                                                (
                                                j
                                                |
                                                r
                                                )
                                             
                                          
                                          )
                                       
                                       +
                                       log
                                       p
                                       
                                          (
                                          i
                                          |
                                          r
                                          )
                                       
                                    
                                 
                              
                           where the sum is over the items rated by the target user that were rated by other users who also rated the target item i. The probability of an item i assuming relevance is computed as the amount of users that rated that item:

                              
                                 (18)
                                 
                                    
                                       
                                          p
                                          
                                             (
                                             i
                                             |
                                             r
                                             )
                                          
                                          ∝
                                          |
                                       
                                       
                                          U
                                          i
                                       
                                       
                                          |
                                       
                                    
                                 
                              
                           
                        

And the maximum likelihood estimate of an item j given the target item i and assuming relevance is proportional to the number of users that rated both items:

                              
                                 (19)
                                 
                                    
                                       p
                                       
                                          (
                                          j
                                          |
                                          i
                                          ,
                                          r
                                          )
                                       
                                       ∝
                                       
                                          
                                             
                                                |
                                             
                                             
                                                U
                                                i
                                             
                                             ∩
                                             
                                                U
                                                j
                                             
                                             
                                                |
                                             
                                          
                                          
                                             
                                                |
                                             
                                             
                                                U
                                                i
                                             
                                             
                                                |
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

The list of recommendations for each long tail item 
                              
                                 i
                                 ∈
                                 
                                    I
                                    ′
                                 
                                 ,
                              
                            
                           Li
                           , is generated sorting all the users 
                              
                                 u
                                 ∈
                                 U
                              
                            by decreasing score 
                              
                                 score
                                 (
                                 u
                                 ,
                                 i
                                 )
                              
                           .

This recommender system was designed for dealing with the recommendation in the long tail [39]. The authors argued that most collaborative filtering algorithms are not able to recommend long tail items due to data sparsity. The authors overcame this problem modelling the recommendation task as a random walk in a graph. This algorithm builds an edge-weighted undirected graph where the nodes are items and users. Each rating is a weight connecting two nodes (the corresponding user and item). Given that graph, the authors compute the hitting time from item i to target user q, H(q|i), which is the average number of steps that a random walker starting from node i will take to reach node q 
                           [39].

Given the target user q, hitting time is initialised for each node x with 
                              
                                 H
                                 
                                    T
                                    0
                                 
                                 
                                    (
                                    q
                                    |
                                    x
                                    )
                                 
                                 =
                                 0
                              
                           . Then, for each user node u and each item node i, the following is computed iteratively (τ iterations):

                              
                                 (20)
                                 
                                    
                                       H
                                       
                                          T
                                          
                                             t
                                             +
                                             1
                                          
                                       
                                       
                                          (
                                          q
                                          |
                                          i
                                          )
                                       
                                       =
                                       1
                                       +
                                       
                                          ∑
                                          
                                             u
                                             ∈
                                             
                                                U
                                                i
                                             
                                          
                                       
                                       H
                                       
                                          T
                                          t
                                       
                                       
                                          (
                                          q
                                          |
                                          u
                                          )
                                       
                                       
                                       
                                          p
                                          
                                             i
                                             ,
                                             u
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (21)
                                 
                                    
                                       H
                                       
                                          T
                                          
                                             t
                                             +
                                             1
                                          
                                       
                                       
                                          (
                                          q
                                          |
                                          u
                                          )
                                       
                                       =
                                       1
                                       +
                                       
                                          ∑
                                          
                                             i
                                             ∈
                                             
                                                I
                                                u
                                             
                                          
                                       
                                       H
                                       
                                          T
                                          t
                                       
                                       
                                          (
                                          q
                                          |
                                          i
                                          )
                                       
                                       
                                       
                                          p
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                    
                                 
                              
                           where:

                              
                                 (22)
                                 
                                    
                                       
                                          p
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             r
                                             
                                                u
                                                ,
                                                i
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   ∈
                                                   
                                                      I
                                                      u
                                                   
                                                
                                             
                                             
                                                r
                                                
                                                   u
                                                   ,
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (23)
                                 
                                    
                                       
                                          p
                                          
                                             i
                                             ,
                                             u
                                          
                                       
                                       =
                                       
                                          
                                             r
                                             
                                                u
                                                ,
                                                i
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   v
                                                   ∈
                                                   
                                                      U
                                                      i
                                                   
                                                
                                             
                                             
                                                r
                                                
                                                   v
                                                   ,
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Those items whose hitting time with respect to q is the smallest are the candidates for recommendation for the target user q. In the the long tail liquidation task, we build the list of recommendation Li
                            with those users whose hitting times with respect to the long tail product 
                              
                                 i
                                 ∈
                                 
                                    I
                                    ′
                                 
                              
                            are the smallest ones.

Matrix Factorisation techniques are a very fertile area of research. Multiple approaches to collaborative filtering based on low rank approximations have been developed [17]. Here, we chose PureSVD as a representative method of this family because it a simple technique specially oriented to the top-N recommendation problem which has achieved high values of accuracy [9]. Also, it has demonstrated to be capable of recommending long tail items effectively [9]. PureSVD computes the standard Singular Value Decomposition of the ratings matrix 
                              
                                 R
                                 ∈
                                 
                                    R
                                    
                                       |
                                       U
                                       |
                                       ×
                                       |
                                       I
                                       |
                                    
                                 
                              
                            of rank l:

                              
                                 (24)
                                 
                                    
                                       R
                                       ≈
                                       U
                                       
                                       Σ
                                       
                                       
                                          Q
                                          T
                                       
                                       =
                                       P
                                       
                                       
                                          Q
                                          T
                                       
                                    
                                 
                              
                           where 
                              
                                 U
                                 ∈
                                 
                                    R
                                    
                                       |
                                       U
                                       |
                                       ×
                                       l
                                    
                                 
                                 ,
                              
                           
                           
                              
                                 Σ
                                 ∈
                                 
                                    R
                                    
                                       l
                                       ×
                                       l
                                    
                                 
                              
                            and 
                              
                                 
                                    Q
                                    T
                                 
                                 ∈
                                 
                                    R
                                    
                                       l
                                       ×
                                       |
                                       I
                                       |
                                    
                                 
                              
                           . This algorithm aims to minimise the factorisation error in terms of the Frobenius norm:

                              
                                 (25)
                                 
                                    
                                       
                                          min
                                          
                                          ∥
                                          R
                                          −
                                          P
                                          
                                       
                                       
                                          Q
                                          T
                                       
                                       
                                          
                                             ∥
                                          
                                          F
                                       
                                    
                                 
                              
                           
                        

We can estimate the score for a user u and an item i as the dot product between the corresponding u-th latent vector of matrix P, 
                              
                                 
                                    
                                       p
                                       u
                                    
                                    →
                                 
                                 ,
                              
                            and the i-th latent vector from matrix Q
                           
                              T
                           , 
                              
                                 
                                    
                                       q
                                       i
                                    
                                    →
                                 
                                 T
                              
                           :

                              
                                 (26)
                                 
                                    
                                       
                                          
                                             r
                                             ^
                                          
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             p
                                             u
                                          
                                          →
                                       
                                       
                                       
                                          
                                             
                                                q
                                                i
                                             
                                             →
                                          
                                          T
                                       
                                    
                                 
                              
                           
                        

With the predicted ratings 
                              
                                 
                                    
                                       r
                                       ^
                                    
                                    
                                       u
                                       ,
                                       i
                                    
                                 
                                 ,
                              
                            we can build recommendation lists for the long tail liquidation task in the same way as we have done for the neighbourhood methods.

Our last baseline is called Sparse Linear Methods or, simply, SLIM. This technique is one of the strongest state-of-the-art top-N recommendation algorithms [25]. It computes a sparse aggregation coefficient matrix W solving the following optimisation problem with regularisation:

                              
                                 (27)
                                 
                                    
                                       
                                          
                                          
                                             
                                                minimize
                                                W
                                             
                                          
                                          
                                          
                                             
                                                
                                                   1
                                                   2
                                                
                                                
                                                   
                                                      ∥
                                                      R
                                                      −
                                                      a
                                                      RW
                                                      ∥
                                                   
                                                   F
                                                   2
                                                
                                                +
                                                
                                                   β
                                                   2
                                                
                                                
                                                   
                                                      ∥
                                                      W
                                                      ∥
                                                   
                                                   F
                                                   2
                                                
                                                +
                                                α
                                                
                                                   
                                                      ∥
                                                      W
                                                      ∥
                                                   
                                                   1
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                             
                                                subject
                                                
                                                to
                                             
                                          
                                          
                                          
                                             
                                                W
                                                ≥
                                                0
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                          
                                             
                                                diag
                                                (
                                                W
                                                )
                                                =
                                                0
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 R
                                 ∈
                                 
                                    R
                                    
                                       |
                                       U
                                       |
                                       ×
                                       |
                                       I
                                       |
                                    
                                 
                              
                            is the ratings matrix. On the other hand, 
                              
                                 W
                                 ∈
                                 
                                    R
                                    
                                       |
                                       I
                                       |
                                       ×
                                       |
                                       I
                                       |
                                    
                                 
                              
                            represents the item-item similarity matrix.

The score of item i for the user u is estimated as the dot product between the user vector of ratings, 
                              
                                 
                                    
                                       
                                          r
                                          u
                                       
                                       →
                                    
                                    T
                                 
                                 ,
                              
                            and the ith column vector of W, 
                              
                                 
                                    w
                                    i
                                 
                                 →
                              
                           :

                              
                                 (28)
                                 
                                    
                                       
                                          
                                             r
                                             ^
                                          
                                          
                                             u
                                             ,
                                             i
                                          
                                       
                                       =
                                       
                                          
                                             
                                                r
                                                u
                                             
                                             →
                                          
                                          T
                                       
                                       
                                       
                                          
                                             w
                                             i
                                          
                                          →
                                       
                                    
                                 
                              
                           
                        

For the long tail liquidation task, the predicted ratings 
                              
                                 
                                    r
                                    ^
                                 
                                 
                                    u
                                    ,
                                    i
                                 
                              
                            can be used for generating recommendation lists in the same way as we have done for the neighbourhood and PureSVD methods.

The evaluation of recommender systems is still today a topic that raises a lot of discussion [5,14,30]. Traditionally, the main objective of these systems was to predict users’ ratings. Therefore, recommenders used to be evaluated in terms of error metrics such as Root Mean Square Error (RMSE) or Mean Absolute Error (MAE). However, various studies have argued that assessing recommenders based on error metrics does not lead to better algorithms [9,14,30]. Instead of trying to predict users’ ratings, current efforts in the field are directed towards the generation of a ranking of N items that users will probably like. This is usually called top-N recommendation [9]. Within this new paradigm, we can measure the accuracy of recommendations using well-known ranking metrics [5,30].

Since in this paper we are dealing with a novel recommendation task, the discussion on the evaluation methodology is crucial. We employ offline evaluations because, in spite of recent criticism [4,13], they still constitute the first step in the assessment of recommender system considering that online evaluations are much more expensive and they are not always possible.

Under this task, we focus on precision-oriented metrics for assessing the performance of recommenders because our primary concern is to liquidate excess inventories. We consider that a recommendation is precise if and only if it leads to a purchase. Thus, the evaluation in this scenario would demand data about sales and stocking information that unfortunately is not usually available on public recommendation datasets. These collections may provide implicit feedback (such as clicks, visualisations or even purchases) or explicit feedback (ratings). Since we are using ratings-based datasets, we can derive purchase information assuming that each rating represents an acquisition (i.e., the user u bought the item i if there exists a rating r
                        
                           u, i
                        ). Starting from the previous work on precision-oriented metrics for the classic recommendation problem [5], we propose our evaluation methodology.

For the evaluating recommender systems in the classic recommendation task, the TestItems methodology [5] have demonstrated to be a good approach. This method consists in building a list of recommendations for each user that contains all the items that have a rating by some user in the testing set and no training rating by the target user. Since we are tackling an inverted version of the classic recommendation problem, we propose the use of TestUsers methodology which consists in recommending, for each long tail item, all the users who have rated some item in the testing set but have not rated the target long tail product.

We denote the set of relevant users for item i by 
                           
                              R
                              i
                           
                        . This set contains those users who have rated the target item in the test set with at least three out of five stars. Analogously, the set of judged nonrelevant users for item i is composed by the users who have rated the target item in the test set with less than three stars. Thus, we consider that a recommendation is successful if it recommends a relevant user. Although it is known that this approach may underestimate the true values of the metrics, it is a reliable method for comparing among different recommendation algorithms [5,22]. Following this concept of relevance and the TestUsers methodology, we used bpref for assessing recommender systems.

Buckley and Voorhees designed this metric which is highly correlated with Mean Average Precision (MAP) but is more robust to incomplete relevance judgements [7]. Precision, nDCG or MAP are popular ranking metrics; however, their performance tend to degrade when there are a few number of relevance judgements available. The reason is that these metrics depend only on the position of the relevant elements in the ranking. They treat equally those elements that were judged nonrelevant and those that are unjudged. On the contrary, bpref is inversely related to the number of judged nonrelevant users that are located above each relevant user in the ranking list. This difference makes bpref more robust to moderate levels of incompleteness in the relevance set than other metrics [7].

Buckley and Voorhees, in [7], studied how the amount of relevance judgements affects different precision-oriented metrics. They analysed both the absolute scores of the metrics as well as the ranking of systems. Reducing the number of relevance judgements, they found that bpref preserves the absolute scores and the relative ranking of systems better than MAP or precision.

This metric ranges from 0 (no relevant user is recommended) to 1 (all the suggested users are relevant) and is given by the following formula:

                                 
                                    (29)
                                    
                                       
                                          
                                             bpref
                                          
                                          =
                                          
                                             1
                                             
                                                
                                                   |
                                                
                                                
                                                   I
                                                   ′
                                                
                                                
                                                   |
                                                
                                             
                                          
                                          
                                             ∑
                                             
                                                i
                                                ∈
                                                
                                                   I
                                                   ′
                                                
                                             
                                          
                                          
                                             1
                                             
                                                
                                                   |
                                                
                                                
                                                   R
                                                   i
                                                
                                                
                                                   |
                                                
                                             
                                          
                                          
                                             ∑
                                             
                                                u
                                                ∈
                                                
                                                   R
                                                   i
                                                
                                             
                                          
                                          1
                                          −
                                          
                                             
                                                |
                                                
                                                   nonrelevant
                                                   
                                                   users
                                                   
                                                
                                                n
                                                
                                                   APTARANORMAL
                                                   
                                                   above
                                                   
                                                
                                                u
                                                |
                                             
                                             
                                                
                                                   |
                                                
                                                
                                                   R
                                                   i
                                                
                                                
                                                   |
                                                
                                             
                                          
                                       
                                    
                                 
                              where n is a member of the first 
                                 
                                    
                                       |
                                    
                                    
                                       R
                                       i
                                    
                                    
                                       |
                                    
                                 
                               judged nonrelevant users.

Since we are dealing with long tail items, we have a few relevance judgements in the test set. This strongly motivates the use of this metric over other alternatives.

We evaluated IRM2 against the baselines on the MovieLens 1M and LibraryThing datasets. We chose the long tail items following the three approaches described with reasonable values in Section 2.2. In particular, we took those items with less than six ratings (least rated strategy), those with less than a 2.5 average rating in a scale from 1 to 5 (lowest rated strategy) and those who do not appear in the top 50 list of the user-based neighbourhood recommender using 100 nearest neighbours according to Pearson’s correlation coefficient (least recommended strategy). Table 2
                         shows the number of items selected in each approach. We consider that this selection of items is reasonable as well as diverse which may be useful to assess the recommendation approaches in the stock liquidation task.

We optimised the parameters of all the recommendation algorithms with respect to bpref. For the neighbourhoods approaches (kNN+UB, kNN+IB and IRM2), we tuned k from 50 to 500 in steps of 50. The parameter λ in UIR-Item was tuned from 0.0 to 1.0 in steps of 0.1. The number of iterations τ in Hitting Time algorithm was tuned from 5 to 35 in steps of 10. The number of dimensions l in PureSVD was tuned from 50 to 500 in steps of 50. The parameters beta and alpha in SLIM was tuned from 0 to 5 in steps of 1. Finally, for IRM2, we tuned the smoothing parameter δ from 0.0 to 1.0 in steps of 0.1.


                        Table 3
                         and 5
                        
                         show the bpref values following the three long tail strategies on the MovieLens and LibraryThing datasets, respectively. We used Wilcoxon signed-rank test to determine whether the differences in terms of bpref were statistically significant or not. We decided to set the significance level to 0.05. Additionally, for the sake of reproducibility, Table 4 and 6
                         gather the best values of the parameters of the different recommendation approaches.

Even though the results vary among strategies and datasets, we can find some general patterns. Despite all the tested baselines were designed for dealing with the traditional recommendation task—suggesting items to users—the results showed that some techniques are good approaches to the task of recommending users to long tail items. However, our proposed method IRM2 is, in general, the best option for the novel task we are proposing in this paper.

As it was expected, Random and Popularity methods behaved poorly in this task. Nevertheless, the classic neighbourhood methods (kNN+UB and kNN+IB) performed worse than these naïve strategies in some experiments. This result may indicate that traditional neighbourhood algorithms are not suitable for the task we are proposing in this paper. The reason lies in the fact that computing neighbourhoods for long tail items is difficult because they have very few ratings. Pairwise similarities, such as Pearson’s correlation coefficient, provide bad results when only few co-occurrences between vectors are available. We observed that the item-based approach (kNN+IB) performed equal or better than the user-based counterpart (kNN+UB) in all the tested scenarios. Thus, not only finding neighbourhoods for long tail items is challenging in this scenario; finding user neighbourhoods who have information about long tail items is even more problematic. It has been acknowledged that for the traditional recommendation task, item-based approaches tend to achieve better accuracy figures [9,11]. Under this new paradigm, where we want to recommend users to items, we observed that the item-based approaches are also desirable.

UIR-Item performance is acceptable compared to the aforementioned baselines. This may happen because UIR is based on the Probabilistic Ranking Principle [29], as RM [19] and our method IRM2. Additionally, UIR also uses smoothing to deal with data sparsity which may explain the good results in the tested scenarios. However, their performance is much lower than IRM2. This result was expected because UIR ignores the value of the ratings since it was originally designed for dealing with implicit feedback modelling the co-occurrences of ratings. We also tested the user-based version of UIR [37], but the results were unsatisfactory, as with kNN-UB.

Hitting Time (HT) is a graph-based algorithm designed for recommending items in the long tail because it models the task as a random walk in a weighted graph. The experiments showed good values of bpref for this method. We think that this is motivated by the fact that HT computes the average number of steps that a random walker needs to go from one node to other in the graph [39]. This algorithm can generate recommendations for both users and items because all of them are nodes of the same graph connected by ratings—this model do not establish any type of difference between users and items. The symmetry of this algorithm between both entities is key in the quality of the recommendations for this novel task.

PureSVD is a simple, yet effective matrix factorisation (MF) technique. Even though HT outperformed PureSVD in four out of the six scenarios, the MF method showed high figures of bpref. This approach computes a full singular value decomposition of the user-item matrix [9]. If we transpose this matrix and calculate a new decomposition, we will obtain the same user and item latent factors, but in switched places. Thus, this technique is also symmetric with respect to users and items. We consider that this property is responsible for the good results of this method for the stock liquidation task.

Finally, the strongest baseline was SLIM. In fact, in one scenario (MovieLens 1M considering long tail items those with a low average rating), SLIM outperformed IRM2. This method produces scores for user and items. Thus, the creation of a recommendation list in this task is done by sorting users by decreasing score according to one item. We think that SLIM produced very good recommendation since the method needs no adaptation to the stock liquidation task. Additionally, we can consider SLIM as an item-based recommender because, at the end, it is based on computing an item-item similarity matrix [25]. Again, item-based approaches demonstrate superior performance compared to user-based ones. Although each column of the item-item similarity matrix can be computed independently, the learning process uses the global information of the user-item rating matrix. In contrast, IRM2 employs local information relying solely on the ratings of the item neighbourhoods. This difference becomes crucial when scalability is a necessity.

IRM2 showed the best results in all the experiments except for the lowest rated scenario in the MovieLens collection. Yet, in this case, it was the second best method for the long tail liquidation task. We can observe that the smoothing parameter δ is very stable within collections while the number of neighbours k is more dependent of the recommendation situation. However, the perfect optimisation of these parameters is not crucial because the differences in terms of bpref are very slight with nearly-optimal parameters.

We used bpref because it is a robust metric when few relevance judgements are available [7] as it happens in the long tail liquidation task. Although for the sake of brevity we do not report here the results, we also ran the same experiments optimising Precision [36] and Normalised Discounting Cumulative Gain [16]. With these metrics, minor changes in the ranking of systems occur. However, IRM2 was still the best candidate in the same five out of the six scenarios.

The notable figures of IRM2 can be explained studying the roots of the algorithm. For each long tail item, this method computes an item relevance model based on the item neighbours. Then, we can estimate the relevance of each user for a given item model. Within this Bayesian framework, the relevance of an item given a user is different of the relevance of a user given an item. The best baselines were those that are item-based methods or symmetric between users and items (i.e., they produce the same result if we switch users and items). IRM2 yielded better results than these methods because it copes with the new task by building a relevance model in the item space.

In the previous experiment, we treated user ratings as purchases. This may raise doubts about the generality of our approach. Thus, we also tested IRM2 and the baselines on a more sparse dataset that contains purchase information. The Ta-Feng collection has more than 800,000 transactions of 32,000 users over a four-month period (from November 2000 to February 2001 inclusive). We used the data from the three first months to train the recommendation algorithms and the last month as the test set. This temporal split also helps to model a more realistic scenario: we use the information of a short period of time to liquidate the least sold products at the end of this period (see Section 2.1).

Since we have sales information, we designed our experiment with the objective of liquidating those products with a small number of sales. We took those items with no more than n purchases where n ranged from 1 to 10. Instead of using user-item ratings, the recommendation algorithms sued the number of purchases as training data.


                        Fig. 3
                         shows the bpref values of IRM2 and the baselines on this dataset for liquidating those items that have no more than n buyers (n ∈ [1, 10]). To avoid overfitting, we used the optimal parameters for 
                           
                              n
                              =
                              10
                           
                        . We report their values in Table 7
                        .

No algorithm provided valid recommendations for those items that were bought by only one customer except for the Random approach. The reason is that collaborative filtering techniques need training data of an item to be able to recommend it. In the case of products bought once, we either have a purchase in the training set or in the test set. If the purchase is in the training set, there is no relevance judgement left to evaluate the recommendation. In contrast, if the purchase is in the test set, we have no training data to generate recommendations. Thus, only the Random technique was able to generate recommendations in this scenario. The Popularity approach might also have worked because it is not a collaborative filtering technique; however, in this very sparse dataset popularity was not a useful approach.

Omitting the singular point of only one buyer, we can observe that IRM2 outperformed the rest of baselines consistently. The relative performance of some recommenders varies when we change the threshold of the number of buyers (e.g., SLIM is the second best algorithm except when we deal with items with very few buyers). However, IRM2 is able to deal effectively with either a high sparsity scenario or a more uncomplicated one. This is even more remarkable given the fact that in this scenario we do not have ratings. Therefore, our proposal is not in optimal conditions because IRM2 exploits this graded information meanwhile strong baselines such as SLIM and UIR-Item ignore that.

@&#RELATED WORK@&#

While a plethora of research has studied the effect of recommender systems in sales, to the best of our knowledge, there is no previous work on the explicit task of recommending users to long tail items. For addressing the long tail phenomenon, some research efforts have focused on developing effective recommendation algorithms that are capable of suggesting long tail items to users [9,39]. However, there is no previous work on how to deal with those items that recommender systems are unable to sell. These long tail items are key to increase revenue [2,39]. In this paper, we have formulated the problem of stock liquidation within a recommendation framework with the aim of maximising income. A considerable amount of literature have focused on improving revenue from different perspectives. We describe some of the most representative works in this area below.

Several authors have insisted on the importance of sales diversity for maximizing profit [2,12,34] and this is currently a very active topic of research within the field of recommender systems. Fleder and Hosanagar simulated the effects of recommenders and concluded that classic systems reduce sales diversity reinforcing the “blockbuster nature” of media (i.e., promoting popular products) [12]. They also studied whether personalization may create segregation and they find out that recommenders can help users widen their interests and create commonality [15]. In spite of the fact that users can discover new products thanks to recommenders, they tend to find the same popular items. This fact is specially present in collaborative filtering approaches where the system cannot recommend items for which it has no information [24]. These algorithms find popular items in the user neighbourhood (or popular users across similar items). Thus, niche products or new items are hard to recommend.

Serendipity is the key promise of the recommender systems. This term stands for the property of suggesting items that users might not have otherwise discovered [14]. Therefore, recommending only popular products of the catalogue does not seem to be an effective approach to achieve this goal. Enhancing diversity is a proactive way of recommending items of the so-called long tail. Anderson defended in his book that vendors should work on selling niche products to improve their revenues [2].

In the last years, several authors have focused on improving sales diversity as well as novelty in recommender systems [1,12,34]. The probabilistic framework proposed by Vargas and Castells [34] is specially relevant to our paper because they also examined the inversion of the recommendation task although with a different goal in mind. Other approaches reorder the output ranking of standard recommenders taking into account diversity at the expense of a reduced loss in accuracy [1]. However, for the proposed task, diversity in the recommendations will not help to increase the success rate in the suggestion of users to items. In this task we are interested in searching for users that would actually buy surfeit products (i.e., producing high precision recommendations) because we are interested in selling those specific items.

Instead of boosting diversity and novelty in the recommenders trying to improve sales, some authors have developed techniques for maximizing profit directly [3,10]. These methods modify the original ranking of any recommender system improving the business’ revenue. Also, Azaria et al. discovered that the percentage of users that wanted to watch a film again is surprisingly high [3]. This may lead to changing the way recommendation is performed because, in some scenarios, it would be acceptable to suggest products that users have already bought.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this paper, we proposed a new unstudied problem in the field of recommender systems: how to liquidate long tail items (sometimes called overstock). Vendors usually have remaining products in their catalogue they wish to get rid of. Thus, an algorithm that computes which users would be interested in a certain item is worthwhile for targeting users in liquidation campaigns. We described this task formally and we designed a collaborative filtering algorithm to cope with this problem.

We proposed three strategies to estimate the long tail items from a recommendation dataset based on the number of ratings, on the average value of the ratings or on the recommendation frequency. Additionally, we used a dataset with purchase information. Nevertheless, it would be very valuable to obtain a public available dataset with real information about excessive stock instead of elaborating approximated evaluation sets.

We designed a probabilistic collaborative filtering algorithm, IRM2, that builds a relevance model for each long tail item. This approach outperformed a set of representative state-of-the-art recommendation algorithms in our experiments. We also found that traditional item-based approaches worked better than user-based ones.

As future work, we think that it would be interesting to analyse the effect of IRM2 priors in the proposed task. Previous studies have demonstrated that different prior probability estimates can improve the accuracy of the recommendations in the traditional scenario [32]. Moreover, the probability distributions of the user and item priors from Eq. 10, p(u) and p(j), can be modified to introduce business rules into the model. For example, we can demote the probability of certain VIP users because we do not want to overflow them with liquidation advertisements.

Another critical aspect of IRM2 is how to compute neighbourhoods. In this work, we have used kNN with cosine similarity for this purpose. Further investigation on more sophisticated approaches—such as matrix factorisation methods [26] or cold-start clustering techniques [35]—might shed light on enhancing the quality of the recommendations.

@&#ACKNOWLEDGMENTS@&#

This work was supported by the Ministerio de Economía y Competitividad of the Goverment of Spain and FEDER Funds under the research project TIN2015-64282-R. The first author also wants to acknowledge the support of 
                     Ministerio de Educación, Cultura y Deporte
                   of the Government of Spain under the grant FPU014/01724.

@&#REFERENCES@&#


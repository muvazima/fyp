@&#MAIN-TITLE@&#Computer aided detection system for micro calcifications in digital mammograms

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Noise and background removed using histogram equalization and morphological filtering.


                        
                        
                           
                           Local thresholding and Otsu's technique were used to segment masses from the background.


                        
                        
                           
                           Feature extraction of mammograms images was proposed using Gray Level co-occurrence matrix (GLCM).


                        
                        
                           
                           Three classifications techniques of mammogram images were applied.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Micro calcifications (MCCs)

Histogram equalization (HE)

K-nearest neighbor classifier (K-NN)

Support vector machine (SVM)

Artificial neural network (ANN)

Otsu's threshold

@&#ABSTRACT@&#


               
               
                  Breast cancer continues to be a significant public health problem in the world. Early detection is the key for improving breast cancer prognosis. Mammogram breast X-ray is considered the most reliable method in early detection of breast cancer. However, it is difficult for radiologists to provide both accurate and uniform evaluation for the enormous mammograms generated in widespread screening. Micro calcification clusters (MCCs) and masses are the two most important signs for the breast cancer, and their automated detection is very valuable for early breast cancer diagnosis. The main objective is to discuss the computer-aided detection system that has been proposed to assist the radiologists in detecting the specific abnormalities and improving the diagnostic accuracy in making the diagnostic decisions by applying techniques splits into three-steps procedure beginning with enhancement by using Histogram equalization (HE) and Morphological Enhancement, followed by segmentation based on Otsu's threshold the region of interest for the identification of micro calcifications and mass lesions, and at last classification stage, which classify between normal and micro calcifications ‘patterns and then classify between benign and malignant micro calcifications. In classification stage; three methods were used, the voting K-Nearest Neighbor classifier (K-NN) with prediction accuracy of 73%, Support Vector Machine classifier (SVM) with prediction accuracy of 83%, and Artificial Neural Network classifier (ANN) with prediction accuracy of 77%.
               
            

@&#INTRODUCTION@&#

Breast cancer is the most common cancer and continues to be a significant public health problem among women around the world [1], and is the second leading cause of female cancer mortality after lung cancer [2]. Statistics have shown that 1 out of 10 women are affected by breast cancer in their lifetime. According to the American Cancer Society in 2009, approximately 269,800 cancer deaths in women and the breast cancer reaches to 15% from it. The diagnosed cancer cases were 713,220 and the breast cancer occupied 27% of these cases, and estimates that in 2011 [3] approximately 230,480 women in the US diagnosed with tumor breast cancer, and about 39,520 women died from breast cancer. Cancer statistics claim that breast cancer got the third position of appearance in diagnosed new cases following genital organs and digestive systems cancer comparing to other forms of cancer [4]. Over the past decades it has become alarming that breast cancer incidence rates are increasing steadily. Changes in risk factors seem to contribute to the rising incidence. However, the mortality rates for breast cancer have remained relatively constant due to more effective treatment and earlier diagnosis Primary prevention seems impossible since the cause of this disease still remains unknown. It is believed that the most promising way to decrease the number of patient suffering from the disease is by early detection. Early detection [5,6] and diagnosis of breast cancer plays a very important role in cancer treatment and allows a faster recovery for most of the patients, and considered the most effective methods of reducing mortality. There are several ways in which breast cancer can be diagnosed, including breast self-examination (BSE), clinical breast exam (CBE), imaging or mammography, and surgery. A mammogram is the most effective technique for breast cancer screening and early detection of masses or abnormalities; it can detect 85–90% of all breast cancers. Micro calcifications (MCs) are among the earliest signs of a breast carcinoma [7]. Depending on its shape, a mass screened on a mammogram can be either benign or malignant. Usually benign tumors have round or oval shapes, while malignant tumors have a partially rounded shape with a spiked or irregular outline. Noncancerous or benign tumors include cysts, fibro adenomas, and breast hematomas. A cancerous or malignant tumor in the breast is a mass of breast tissue that grows in an abnormal and uncontrolled way. The malignant mass will appear whiter than any tissue surrounding it. Calcifications (both macro-calcification and micro calcification), the second abnormality that can be seen on mammogram images, are most of the time not malignant and not a sign of cancer. Successful diagnosis in mammography is dependent on detecting cancer in its earliest and most treatable stage. Reading mammograms is a very demanding job for radiologists. Their judgments depend on training, experience, and subjective criteria. Even well-trained experts may have an interobserver variation rate of 65–75%. Computer aided diagnosis (CAD) systems may help radiologists in interpreting mammograms for mass detection and classification [8]. Since 65–90% of the biopsies of suspected cancer turned out to be benign, it is very important to develop CADs that can distinguish benign and malignant lesions. The combination of CAD scheme and experts’ knowledge would greatly improve the detection accuracy. The detection sensitivity without CAD is 80% and with CAD up to 90% [9]. The main objective of this study is to discuss the computer-aided detection system that has been proposed, designed and developed in order to overcome the drawbacks of mammograms in detecting the MCCs, and classify those MCCs into two classes (Abnormal–Normal) and (Malignant–Benign).

@&#RELATED WORK@&#

Several works have been done to develop computer aided breast cancer detection tools. Kom et al. [10] proposed a technique for the automated detection of malignant masses in screening mammography. The technique is based on the presence of concentric layers surrounding a focal area with suspicious morphological characteristics and low relative incidence in the breast region. Mavroforakis et al. [11] applied a one-dimensional recursive median filter over a number of different angles to each pixel. Based on the variations in scale for various angles, they can determine whether the structure is a blob or has a more linear shape. Sometimes, a mass looks very much like normal glandular structure, and is only detectable due to asymmetry between the left and right breasts. Tang et al. [12] gave an overview of recent advances in the development of such tools and related techniques. Timp [13] used a generalized Hough transform for circles. The strongest edges in an area of interest are accumulated in a Hough space where each location relates to a center and a radius. A few papers have been published describing approaches for mass detection based on differences in left and right mammograms. These approaches perform some kind of image subtraction, and can also be used to detect temporal changes when a mammogram is compared with an older mammogram of the same breast.

@&#METHODOLOGY@&#

CAD schemes involve the phases which describe techniques of Micro calcifications (MCCs) detection. The CAD system consists of four stages: as demonstrated in Fig. 1
                     ; Enhancement, Segmentation, Feature Extraction, and Classification process. The first stage is the micro calcification enhancement techniques which categorized into two categories: Histogram Equalization (HE) is simple and effective in enhancing the entire image with low contrast, and Morphological Enhancement (top hat) operation for image enhancement in which the combined operations are applied to the original gray tone image and the higher sensitive lesion site selection of the enhanced images are observed. The second stage is the segmentation technique which categorized into Local threshold and Otsu's techniques. Third stage is feature extraction which is an important factor that directly affects the classification result in mammogram classification by applying Gray Level Co-occurrence Matrix (GLCM) will help doctors to discover the existence of the tumor especially when applying these techniques in early stages. Final stage is classification which is still very challenging and a difficult problem for researchers. Researchers spend a lot of time in attempting to find a group of features that will aid them in improving the classification for malignant from benign. In this paper the k-Nearest Neighbor (k-NN), support vector machine (SVM), and Artificial Neural Network (ANN) are used as classifiers.

In this work, all images are downloaded from Image Analysis Society (MIAS), which is an organization of UK research group [14], has produced a digital mammography database (ftp://peipa.essex.ac.uk). The number of images considered in this study is 181 breast images divided into 97 normal images and 84 abnormal images.

Preprocessing is an important issue in low-level image processing. The underlying principle of preprocessing is to enlarge the intensity difference between objects and background and to produce reliable representations of breast tissue structures. An effective method for mammogram enhancement must aim to enhance the texture and features of masses. The reasons of enhancement are: (1) low-contrast of mammographic images; (2) hard to read masses in mammogram; (3) generally, variation of the intensities of the masses such that radiopaque mass with high-density and radiolucent mass with low-density in comparison with the background. The methods used to manipulate mammogram images can be categorized into two main categories; (1) Histogram Equalization techniques (HE); (2) Morphological Enhancement techniques as shown in Fig. 2
                        . The ideal contrast enhancement should enhance the mammograms with no over-enhancement and under-enhancement by increase their contrast and decrease the noise present in order to aid radiologists in the detection of abnormalities.

Histogram Equalization is a technique used widely in image processing to enhance the contrast of an image. It can reduce the effect of over brightness or over darkness to improve visual appearance of images [15,16]. The Histogram Equalization (HE) technique is simple and effective in improve and enhancing the entire image with low contrast as shown in Fig. 3
                           , only if that image contains single object or if there is no apparent contrast change between the object and background. The main idea of histogram equalization technique is to re-assign the intensity values of pixels to obtain a uniform distribution of intensities over the full gray scale range. It increases the image contrast range by increasing the dynamic range of gray levels. Suppose that H(i) is the histogram of the image with size M
                           ×
                           N, and [Gmin, Gmax] is the range of the intensities of the image. We can map the original image intensity I
                           org into the resulting image intensity I
                           new using HE techniques below:
                              
                                 (1)
                                 
                                    
                                       
                                          I
                                          
                                             new
                                          
                                       
                                       =
                                       
                                          G
                                          
                                             min
                                          
                                       
                                       +
                                       (
                                       
                                          G
                                          
                                             max
                                          
                                       
                                       −
                                       
                                          G
                                          
                                             min
                                          
                                       
                                       )
                                       ×
                                       
                                          ∑
                                          
                                             i
                                             =
                                             0
                                          
                                          
                                             
                                                I
                                                
                                                   org
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                H
                                                (
                                                i
                                                )
                                             
                                             
                                                M
                                                ×
                                                N
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Morphology is used to perform object extraction, noise removal procedure [17]. For the same purpose we are applying these operations to enhance the object boundary and to remove the noise from the image. The most basic morphological operations are dilation which adds pixels to the boundaries of objects and erosion which removes pixels on object boundaries.

The simplicity of morphology approach come from the fact that a large class of filters can be represented as the combination of two simple operations: erosion and dilation. Let Z denote the set of integers and f(i,j) denote a discrete image signal, where the domain set is given by {i,j}
                              
                              N1×N2, N1×N2⊂Z2 and the range set by {f}
                              
                              N3, N3⊂
                              Z. A structuring element B is a subset in Z
                              2 with a simple geometrical shape and size. Denote 
                                 
                                    
                                       
                                          B
                                       
                                       3
                                    
                                    =
                                    {
                                    −
                                    b
                                    :
                                    b
                                     
                                    
                                       
                                    
                                     
                                    
                                       B
                                    
                                    }
                                 
                               as the symmetric set of B and 
                                 
                                    
                                       
                                          B
                                       
                                       
                                          
                                             
                                                t
                                                1
                                                ,
                                                t
                                                2
                                             
                                             →
                                          
                                       
                                    
                                 
                               as the translation of B by (tι, t2)
                              
                              
                              Z
                              2.The erosion f
                              ⊝
                              B
                              3 and dilation 
                                 
                                    f
                                    ⊕
                                    
                                       
                                          B
                                       
                                       3
                                    
                                 
                               can be expressed as
                                 
                                    (2)
                                    
                                 
                              
                              
                                 
                                    (3)
                                    
                                 
                              On the other hand, opening 
                                 
                                    f
                                    ∘
                                    
                                       B
                                    
                                 
                               and closing 
                                 
                                    f
                                    *
                                    
                                       B
                                    
                                 
                               are defined as
                                 
                                    (4)
                                    
                                       
                                          (
                                          f
                                          ∘
                                          
                                             B
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          =
                                          (
                                          (
                                          f
                                           
                                          ⊖
                                           
                                          
                                             
                                                B
                                             
                                             3
                                          
                                          )
                                          ⊕
                                          
                                             B
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                       
                                    
                                 
                              
                              
                                 
                                    (5)
                                    
                                       
                                          (
                                          f
                                          *
                                          
                                             B
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          =
                                          (
                                          (
                                          f
                                          ⊕
                                          
                                             
                                                B
                                             
                                             3
                                          
                                          )
                                           
                                          ⊖
                                           
                                          
                                             B
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                       
                                    
                                 
                              A gray value image viewed as a two-dimensional surface in a three-dimensional space. In our image, the opening operation removes the objects, which have size smaller than the structuring element, with positive intensity. Thus, with the specified structuring element, one can extract different image contexts by taking the difference between the original and opening processed image, which is known as “top hat” operation [18].

According to the properties of morphological filters, we designed one type of mass pattern-dependent enhancement approaches. The algorithm is implemented by (a) dual morphological top hat operations, (b) a subtraction which is described as follows.

Step 1) the textures without the pattern information of interest are extracted by a top hat operation
                                 
                                    (6)
                                    
                                       
                                          
                                             r
                                             1
                                          
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          =
                                          max
                                          (
                                          0
                                          ,
                                          [
                                          f
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          −
                                          (
                                          f
                                          ∘
                                          
                                             
                                                B
                                             
                                             1
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          ]
                                          )
                                       
                                    
                                 
                              where f(i,j) is the original image, and r
                              1(i,j) is the residue image between the original image and the opening of the original image by a specified structuring element 
                                 
                                    
                                       
                                          B
                                       
                                       ι
                                    
                                 
                              . The size of 
                                 
                                    
                                       
                                          B
                                       
                                       ι
                                    
                                 
                               should be chosen smaller than the size of masses.

Step 2) Let r
                              2(i,j) be the mass pattern enhanced image by background correction, i.e., by the second tophat operation on f(i,j)
                                 
                                    (7)
                                    
                                       
                                          
                                             
                                                r
                                             
                                             2
                                          
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          =
                                          max
                                          (
                                          0
                                          ,
                                          [
                                          f
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          −
                                          (
                                          f
                                          ∘
                                          
                                             
                                                B
                                             
                                             1
                                          
                                          )
                                           
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          ]
                                          )
                                       
                                    
                                 
                              where 
                                 
                                    
                                       
                                          B
                                       
                                       2
                                    
                                 
                               is a specified structuring element which has a larger size than masses.

Step 3) The enhanced image f
                              1(i,j) can be derived as
                                 
                                    (8)
                                    
                                       
                                          
                                             f
                                             ι
                                          
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          =
                                          max
                                           
                                          (
                                          0
                                          ,
                                          [
                                          
                                             
                                                r
                                             
                                             2
                                          
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          −
                                          
                                             
                                                r
                                             
                                             1
                                          
                                          (
                                          
                                             i
                                          
                                          ,
                                          
                                             j
                                          
                                          )
                                          ]
                                          )
                                       
                                    
                                 
                              This operation is called “dual morphological operation.” remove the background noise and the structure noise inside the suspected mass patterns. Fig. 4
                               shows the mass patch and the enhanced results of each step using the dual morphological operation. As we shown in Fig. 4, both background correction [Fig. 4(a)] and dual morphological operation [Fig. 4(b)] enhanced the mass pattern, but dual morphological operation removed more structural noise inside the mass region as shown in [Fig. 4(C)] which in turn would improve the mass segmentation results.

Distinguishing the suspicious region from its surroundings area is considered important step in analyzing mammogram image. The methods used to separate the Region of Interest from the background are usually referred as the segmentation process. Considered the second stage of mass detection CAD schemes is to separate the suspicious regions that may contain masses from the background parenchyma. This stage segment mammogram image into several non-overlapping regions, then extract regions of interests (ROIs), and locate the suspicious mass candidates from ROIs. The suspicious area is an area that is brighter than its surroundings, has almost uniform density, has a regular shape with varying size, and has fuzzy boundaries [19]. This is a very essential land important step to extract the sensitivity of the entire image. Segmentation methods do not need to be excruciating in finding mass locations but the result for segmentation is supposed to include the regions containing all masses. In this paper, we have used Local thresholding Technique, Otsu technique for segmentation as shown in Fig. 5
                     .

The simplest form of segmentation is Otsu thresholding, we used this automated thresholding method to obtain a binarization of the enhanced image. In this paper, we use Otsu's method to automatically perform histogram shape-based image thresholding or, the reduction of a gray level image to a binary image [20]. We applying binarization on the histogram equalized image. Implementation is done according to the algorithm described below and the output obtained is shown in Fig. 6
                        . In Otsu's method we exhaustively search for the threshold that minimizes the intra-class variance (the variance within the class), defined as a weighted sum of variances of the two classes:
                           
                              (9)
                              
                                 
                                    
                                       σ
                                       ω
                                       2
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       ω
                                       1
                                    
                                    (
                                    t
                                    )
                                    
                                       σ
                                       1
                                       2
                                    
                                    (
                                    t
                                    )
                                    +
                                    
                                       ω
                                       2
                                    
                                    (
                                    t
                                    )
                                    
                                       σ
                                       2
                                       2
                                    
                                    (
                                    t
                                    )
                                 
                              
                           
                        Weights ω
                        
                           i
                         are the probabilities of the two classes separated by a threshold t and 
                           
                              
                                 σ
                                 i
                                 2
                              
                           
                         variances of these classes. Otsu shows that minimizing the intra-class variance is the same as maximizing inter-class variance:
                           
                              (10)
                              
                                 
                                    
                                       σ
                                       b
                                       2
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       σ
                                       2
                                    
                                    −
                                    
                                       σ
                                       ω
                                       2
                                    
                                    (
                                    t
                                    )
                                    =
                                    
                                       ω
                                       1
                                    
                                    (
                                    t
                                    )
                                    
                                       
                                          [
                                          
                                             µ
                                             1
                                          
                                          (
                                          t
                                          )
                                          −
                                          
                                             µ
                                             2
                                          
                                          (
                                          t
                                          )
                                          ]
                                       
                                       2
                                    
                                 
                              
                           
                        which is expressed in terms of class probabilities ω
                        
                           i
                         and class means μ
                        
                           i
                         the class probability ω
                        1 is computed from the histogram as t: 
                           
                              
                                 ω
                                 1
                              
                              (
                              t
                              )
                              =
                              
                                 ∑
                                 0
                                 t
                              
                              
                                 
                                    P
                                 
                                 (
                                 
                                    i
                                 
                                 )
                              
                           
                         While the class mean μ
                        1(t) is: 
                           
                              
                                 μ
                                 1
                              
                              (
                              t
                              )
                              =
                              
                                 
                                    
                                       ∑
                                       0
                                       t
                                    
                                    
                                       
                                          P
                                       
                                       (
                                       
                                          i
                                       
                                       )
                                        
                                       χ
                                       (
                                       
                                          i
                                       
                                       )
                                    
                                 
                              
                              /
                              
                                 ω
                                 1
                              
                           
                         Where χ (i) is the value at the center of the ith histogram bin. The class probabilities and class means can be computed iteratively. This idea yields an effective algorithm.
                           
                              (1)
                              Compute histogram and probabilities of each intensity level

Set up initial ω
                                 
                                    i
                                 (0) and μ
                                 
                                    i
                                 (0)

Step through all possible thresholds t
                                 =1…maximum intensity
                                    
                                       (a)
                                       Update ω
                                          
                                             i
                                           and μ
                                          
                                             i
                                          
                                       

Compute 
                                             
                                                
                                                   σ
                                                   b
                                                   2
                                                
                                                (
                                                t
                                                )
                                             
                                          
                                       

Desired threshold corresponds to the maximum 
                                    
                                       
                                          σ
                                          b
                                          2
                                       
                                       (
                                       t
                                       )
                                    
                                 
                              

You can compute two maxima (and two corresponding thresholds). 
                                    
                                       
                                          σ
                                          
                                             b
                                             1
                                          
                                          2
                                       
                                       (
                                       t
                                       )
                                    
                                  is the greater max and 
                                    
                                       
                                          σ
                                          
                                             b
                                             2
                                          
                                          2
                                       
                                       (
                                       t
                                       )
                                    
                                  is the greater or equal maximum.


                                 
                                    
                                       Desired threshold
                                       =
                                       
                                          
                                             
                                                threshold
                                                1
                                             
                                             +
                                             
                                                threshold
                                                2
                                             
                                          
                                          2
                                       
                                    
                                 
                              

Local thresholding has been widely used for segmentation. This technique is based on the global information, such as the histogram. When the masses are brighter than the surrounding tissues, it makes thresholding a useful method for segmentation [21]. It has been proven to provide an easy and convenient way to perform the segmentation on digital mammogram. The main idea of local thresholding is to determine a single value known as the intensity threshold value. Then, each pixel in the image is compared with the threshold value. Pixel intensity values higher than the threshold will result in a white spot in the output image as shown in Fig. 7
                        .

Texture is a commonly used feature in the analysis and interpretation of images. Texture is characterized by a set of local statistical properties of pixel intensities. We base our texture feature extraction on the spatial gray level co-occurrence-matrix (SGLCM). The GLCM method considers the spatial relationship between pixels of different gray levels. The method calculates a GLCM [23] by calculating how often a pixel with a certain intensity i occurs in relation with another pixel jet a certain distance d and orientation θ as shown in Fig. 8
                     
                  

For instance, if the value of a pixel is 1 the method looks, for instance, the number of times this pixel has 2 in the right side. Each element (i,j) in the GLCM is the sum of the number of times that the pixel with value I occurred in the specified relationship to a pixel with value j in the raw image as shown in Fig. 9
                     .

Once the GLCM [24] is calculated several second-order texture statistics can be computed as shown, where Pd, θ (i,j) is the GLCM between I and j. Co-occurrence matrices are calculated for four directions: 0°, 45°, 90°, 135° degrees. There are four statistical measures such as energy, entropy; homogeneity and sum of square variance are computed based on GLCM [25,26] as follows:
                        
                           
                              Entropy: measures the statistical randomness.
                                 
                                    (11)
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                ,
                                                j
                                                =
                                                0
                                             
                                             
                                                G
                                                −
                                                1
                                             
                                          
                                          
                                             P
                                             (
                                             i
                                             ,
                                             j
                                             )
                                             log
                                             (
                                             P
                                             (
                                             i
                                             ,
                                             j
                                             )
                                             )
                                          
                                       
                                    
                                 
                              
                           


                              Energy: is also known as uniformity of ASM(angular second moment) which is the sum of squared elements from the GLCM.
                                 
                                    (12)
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                ,
                                                j
                                                =
                                                0
                                             
                                             
                                                G
                                                −
                                                1
                                             
                                          
                                          
                                             P
                                             
                                                
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           


                              Homogeneity: is to measure the distribution of elements in the GLCM with respect to the Diagonal.
                                 
                                    (13)
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                ,
                                                j
                                             
                                             
                                                G
                                                −
                                                1
                                             
                                          
                                          
                                             
                                                
                                                   P
                                                   (
                                                   i
                                                   ,
                                                   j
                                                   )
                                                
                                                
                                                   1
                                                   +
                                                   |
                                                   i
                                                   −
                                                   j
                                                   |
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           


                              Sum of square variance: This feature puts relatively high weights on the elements that differ from the average value of P(i,j).

Once the features related to masses are extracted and selected, the features are input into a classifier to classify the detected suspicious areas into normal tissues, benign masses, or malignant masses. Classifiers such as Artificial Neural Network (ANN), the k-Nearest Neighbor (k-NN), and Support Vector Machine (SVM), have performed well in mass classification.

The Artificial neural network [27] is basically having three layers namely input layer, hidden layer and output layer. There will be one or more hidden layers depending upon the number of dimensions of the training samples. Neural network structure used in this study consists of only two hidden layers having 7 neurons in the input layer and 1 neuron in the output layer as shown in Fig. 10
                        . Neural classification consists of two processes: Training and Testing, the classification accuracy depends on training, the most well-known (Artificial Neural Network) ANN architecture is the Multilayer Preceptor (MLP) network which is widely used for solving problems related to data classifications, and we applied the MLP network on Medical diagnosis data studies, breast cancer classification.

K-Nearest Neighbor (KNN) is one of the most simple classification methods. KNN consider the first choice for a classification study when there is little or no prior knowledge about the distribution of the data [28]. KNN is a nonparametric method in that no parameters are estimated. Instead, the proximity of neighboring input (a) observations in the training data set and their corresponding output values (y) are used to predict the class of the objects in the validation data set. Firstly two input variable case is considered since it is easy to represent in two-dimensional space. Euclidean distance between two input vectors a
                        ι and a
                        2 is used in KNN.
                           
                              (19)
                              
                                 
                                    a
                                    ι
                                    =
                                    (
                                    a
                                    ι
                                    ,
                                    x
                                    ,
                                    a
                                    ι
                                    ,
                                    y
                                    )
                                    ;
                                    a
                                    2
                                    =
                                    (
                                    a
                                    2
                                    ,
                                    x
                                    ,
                                    a
                                    2
                                    ,
                                    y
                                    )
                                 
                              
                           
                        The distance between these two vectors is computed as the length of the difference vector aι
                        −
                        a2, denoted by
                           
                              (20)
                              
                                 
                                    d
                                    (
                                    a
                                    ι
                                    ,
                                    a
                                    2
                                    )
                                    =
                                    |
                                    a
                                    ι
                                    −
                                    a
                                    2
                                    |
                                    =
                                    
                                       
                                          
                                             
                                                (
                                                a
                                                ι
                                                ,
                                                x
                                                ,
                                                a
                                                2
                                                ,
                                                x
                                                )
                                             
                                             
                                                2
                                                +
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                (
                                                a
                                                ι
                                                ,
                                                y
                                                ,
                                                a
                                                2
                                                ,
                                                y
                                                )
                                             
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        More generally the distance between two p-dimensional vectors 
                           
                              
                                 U
                              
                              =
                              (
                              
                                 U
                              
                              ι
                              ,
                              
                                 U
                              
                              2
                              ,
                              …
                              
                                 Up
                              
                              )
                           
                         and 
                           
                              
                                 V
                              
                              =
                              (
                              
                                 V
                              
                              ι
                              ,
                              
                                 V
                              
                              2
                              ,
                              …
                              
                                 Vp
                              
                              )
                           
                         is calculated as
                           
                              (21)
                              
                                 
                                    d
                                    (
                                    
                                       U
                                    
                                    ,
                                    
                                       V
                                    
                                    )
                                    =
                                    |
                                    
                                       U
                                    
                                    −
                                    
                                       V
                                    
                                    |
                                    =
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   U
                                                
                                                ι
                                                −
                                                
                                                   V
                                                
                                                ι
                                                )
                                             
                                             2
                                          
                                       
                                    
                                    +
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   U
                                                
                                                2
                                                −
                                                
                                                   V
                                                
                                                2
                                                )
                                             
                                             2
                                          
                                       
                                    
                                    +
                                    ⋯
                                    +
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   Up
                                                
                                                −
                                                
                                                   Vp
                                                
                                                )
                                             
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The minimum distance between the vectors gives the closest neighbor so it is predicted that it belongs to the same class with the test object.

SVM is an example of supervised learning methods used for classification and regression analysis. SVM is a binary linear classifier that for each given input data it predicts which of two possible classes comprises the input. For example, as in Fig. 11
                         we have a set of training examples categorized into one of two categories, the SVM goal is to build a model that categorizes any new examples into one of the two categories. In the figure we have three hyperplane: H3 (green) does not separate the two classes, but H1 and H2 do.

The goal is to search for the direction that gives the maximum possible margin. Margin which is defined as the hyperplane leaves from both classes [29]. The margin of H2 is the maximum margin, so for H2, the best hyperplane is used to separate the two classes. After locating the best hyperplane with maximum margin, SVM trained it with samples from two classes.


                        Fig. 12
                         shows some samples located on the margin, these samples are called the support vector. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall on.

The performance of the prediction was evaluated in terms of sensitivity, specificity, accuracy, the respective formula are given in Table 2. Accuracy measures the quality of the binary classification (two-class). It takes into account true and false positives and negatives. Accuracy is generally regarded with balanced measure whereas sensitivity deals with only positive cases and specificity deals with only negative cases. A confusion matrix provides information about actual and predicted cases produced by classification system [31]. The performance of the system is examined by demonstrating correct and incorrect patterns. The higher value of both sensitivity and specificity shows better performance of the system.

@&#RESULTS@&#

The database used into this work is freely available at internet and is named as the Mammographic Institute Society Analysis (MIAS). The specification of the data is given in the referred site. Two enhancement methods were implemented for enhancement of digital mammograms Histogram Equalization and Morphological Enhancement. Then we segmented that enhanced images to get best results. This section details the results of automatic classification on mammograms using GLCM features and three types classifiers. The proposed method tested with 181 mammograms (97 normal, 84abnormal).In this analysis first procedure is extract features from mammograms. Features are extracted from 181 mammograms images and these input fed to three types of classifiers, Multilayer Preceptor (MLP), the k-Nearest Neighbor (k-NN), and Support Vector Machine (SVM) classifier. We have tested the performance of these classifiers by calculating and analysis of accuracy, sensitivity and specificity for each classifier. These are defined as follows:
                        
                           
                              
                                 Accuracy
                                 =
                                 
                                    
                                       number of classified mass
                                    
                                    
                                       number of total mass
                                    
                                 
                                 =
                                 
                                    
                                       T
                                       P
                                       +
                                       T
                                       N
                                    
                                    
                                       T
                                       P
                                       +
                                       T
                                       N
                                       +
                                       F
                                       P
                                       +
                                       F
                                       N
                                    
                                 
                              
                           
                        
                     
                     Table 1
                      shows the sensitivity, specificity and accuracy for testing datasets of Normal and Abnormal images which show respectively results of Artificial Neural Network (ANN) classifier with two layers (Automatic MLP and Traditional MLP) Sensitivity 100%, Specificity 100%, and Accuracy 100%, also show results of the k-Nearest Neighbor (k-NN) classifier Sensitivity 66%, Specificity 69%, and Accuracy 68%, and show the results of Support Vector Machine (SVM) classifier Sensitivity 65%, Specificity 75%, and Accuracy 70%, Table 2
                      shows the sensitivity, specificity and accuracy for testing datasets of Malignant–Benignimages which show respectively results of Neural Network (A NN) classifier for Automatic MLP Sensitivity 100%, Specificity 57%, and Accuracy 61%,and for Traditional MLP Sensitivity 66%, Specificity 77%, and Accuracy 71%, also show results of the k-Nearest Neighbor (k-NN) classifier Sensitivity 62%, Specificity 73%, and Accuracy 68%, and show the results of Support Vector Machine (SVM) classifier Sensitivity 55%, Specificity 83%, and Accuracy 70%.

@&#CONCLUSION@&#

Mammography is the most effective method that is used in the early detection of breast cancer, The CAD system is developed for detection of micro classification from mammogram images. This system performs this detection in multiple phases. In the first phase, Enhancement on mammogram images is done to remove noise and background removal by using Histogram Equalization and Morphological filtering. In the second phase segmentation by Local thresholding and Otsu's technique have been used to segment masses from the background then in the third phase we proposed feature extraction of mammograms images using Gray Level co-occurrence matrix (GLCM). In the last phase, three techniques for classifications of mammograms images were applied; Multilayer Preceptor (MLP), the k-Nearest Neighbor (k-NN), and Support Vector Machine (SVM) these techniques will classify mammogram images into two classes class 1: (Normal and Abnormal) and class 2: (Malignant and Benign) with the aim of supporting radiologists in visual diagnosis.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Robust visual tracking via augmented kernel SVM

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Augmented Kernel Matrix (AKM) is applied to combine complementary features.


                        
                        
                           
                           AKM clustering is utilized to group the tracking results into a few aspects.


                        
                        
                           
                           Representative patches are selected to learn the appearance model.


                        
                        
                           
                           Adding representative patches our tracker more robust to abrupt appearance changes.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Feature representation

Appearance model

Augmented Kernel Matrix (AKM)

@&#ABSTRACT@&#


               
               
                  Most current tracking approaches utilize only one type of feature to represent the target and learn the appearance model of the target just by using the current frame or a few recent ones. The limited representation of one single type of feature might not represent the target well. What's more, the appearance model learning from the current frame or a few recent ones is intolerant of abrupt appearance changes in short time intervals. These two factors might cause the track's failure. To overcome these two limitations, in this paper, we apply the Augmented Kernel Matrix (AKM) classification to combine two complementary features, pixel intensity and LBP (Local Binary Pattern) features, to enrich the target's representation. Meanwhile, we employ the AKM clustering to group the tracking results into a few aspects. And then, the representative patches are selected and added into the training set to learn the appearance model. This makes the appearance model cover more aspects of the target appearance and more robust to abrupt appearance changes. Experiments compared with several state-of-the-art methods on challenging sequences demonstrate the effectiveness and robustness of the proposed algorithm.
               
            

@&#INTRODUCTION@&#

Object tracking is an important problem in computer vision and has many practical applications, especially for vehicle navigation, augmented reality (AR) and human computer interface (HCI). Although many tracking algorithms have been proposed [1–8], it is still a great challenging task to design a robust tracker which can cope with different kinds of objects under various situations. A very common difficulty is to deal with the visual appearance changes of the target over time due to pose changes, sudden illumination changes, partial occlusion and background clutter.

To deal with the changes of the object appearance, a common strategy is to adopt an adaptive appearance model [2,3,5], which updates during the tracking process with the appearance changes of the target. To construct the adaptive model, it often uses the current or the latest few frames and represents the target by one type of the feature. Comaniciu [1] only used the current frame and represented the target as the weighted feature histogram to construct the appearance model. Ross et al. [3] employed the incremental learning scheme to learn a low-dimensional subspace representation, which was based on the pixel intensity. Babenko et al. [5] represented the target by using the generalized Haar-like features [9] and applied Multiple Instance Learning (MIL) [10] to select many discriminative weak classifiers from a feature pool. The weak classifiers were updated online by means of a forgetting factor and this implicitly meant that the appearance model was built only on the latest few frames. Kwon and Lee [4] utilized the first initial and latest four frames and sparse principal component analysis (SPCA) to select a set of complementary feature templates to model the target. Bai and Tang [7] proposed the online Laplacian ranking support vector tracker (LRSVT) to incorporate the initial and the latest frames and the weakly labeled information in the next frame to model the appearance. In the LRSVT system, the target was represented by using Haar-like features.

Many of the aforementioned approaches could not deal with all various appearance changes simultaneously either due to the limited representation of one single type of feature or the only usage of the recent target samples [11]. To cope with the representation limitation, one strategy was that we could design a strong feature which was robust to any change. However, it was not an easy task [12,13], especially for the model-free tracking problem in which no prior knowledge about the target is known except for the object location at the beginning of tracking. Another strategy was that we could propose an efficient scheme that combined different complementary features (e.g. image features based on pixel intensity, edge and texture information) [12,13]. One type of feature captured one channel of information of the target and compensated for others' representation limitation.

To make the tracker be intolerant of abrupt appearance changes in short time intervals, we could add the tracking result into the training set [11]. Nevertheless, if we brutally added all the tracking results, it would need much time to learn the appearance model and even degrade the tracker's performance. Instead, we could mine a few representative examples from the tracking results to add into the training set.

In this paper, we applied the Augmented Kernel Matrix (AKM) classification [14–16] to combine two complementary features, the pixel intensity and LBP [17] features to model the target's appearance. The AKM classification assigns different weights to the information channel per example rather than per kernel. As a result, this could make the AKM learn a much more representative appearance model to cover the target appearance changes. Meanwhile, to make usage of the tracking result, we proposed the AKM clustering algorithm to group the tracking result into a few aspects and selected a few examples from each aspect. The AKM clustering has two advantages as follows. Firstly, it could decide the number of the cluster automatically, which was very important to the tracking problem. We could not give a predefined number of clusters due to the arbitrary appearance changes during the tracking process. Secondly, it could also handle outliers by employing a soft margin constant. Therefore, it might discard a few inaccurate tracking results which were unavoidable in the tracking process. And this contributed to our system to be more robust to abrupt appearance changes in short time intervals.

The rest of this paper is organized as follows. In Section 2, we briefly overview the related work. The novel tracking algorithm, the Augmented Kernel Matrix tracker and the implementation details are given in Section 3. Experimental results and comparison with other state-of-the-art methods are presented in Section 4. Section 5 summarizes our work.

@&#RELATED WORK@&#

To combine different features, Bach et al. [18] formulate the multiple kernel learning (MKL) as a second-order cone programming (SCOP) problem, which can be solved efficiently only for medium-scale problems. Therefore, Rakotomamonjy et al. [19] propose solving by sub-gradient descent approach, which converges rapidly and is favorably efficient compared to other MKL algorithms. Vishwanathan et al. [20] develop a very efficient approach, called SMO–MKL, which uses sequential minimal optimization (SMO) [21] algorithm to solve MKL problem directly and is easily scaled to the large problem.

In computer vision, MKL has been applied to object detection [12,22] and classification [13]. Varma et al. [12] apply MKL to learn a combination of base kernels and show impressive results on varied object classification tasks. To make the system more efficient, Vedaldi et al. [22] extend Varma's work and learn a three-stage classifier which combines linear and non-linear kernels. Gehler and Nowozin [13] compare different feature combination strategies for object classification.

In [14], Yan et al. propose that the AKM learning for a single training example may have different importance in different feature spaces, in contrast to MKL that assigns the same weight to all examples in one feature space. Due to the large augmented matrix which requires a large memory, Awais et al. [15] develop a novel two-stage Augmented Kernel Matrix. Kernels are grouped automatically by kernel alignment and the most influential training examples are identified within each group and used to construct the AKM matrix. The AKM learning has been applied to object recognition [14,15] and shows improvement over MKL and other feature combination schemes.

In the tracking problem, Kim et al. [23] cluster the tracking results into a few aspects and learn cluster-specific appearance models for object tracking. Different from Kim's work, the purpose of the clustering in ours is to mine the most representative tracking results and Kim's work requires an off-line setup to construct the cluster priors.

In [11], Park et al. propose an online clustering algorithm to cluster the historical information into a few clusters and learn a few cluster-specific appearance models as Kim did. Due to the online scheme, the tracker might learn a cluster-specific appearance modeling the background, which causes tracking failures.

In this section, we begin with an overview of multiple kernel learning, which is a common scheme for feature combination and has been widely used in object detection [12,22] and classification [13]. Next, we present the AKM learning [14] for classification and clustering. Finally, we give our tracking algorithm and the implementation details.

MKL is to learn a linear combination of different kernels during the training phase. And the feature combination in MKL can be given in the following formulation:
                           
                              (1)
                              
                                 
                                    
                                       
                                          K
                                          
                                             
                                                x
                                                i
                                             
                                             
                                                x
                                                j
                                             
                                          
                                          =
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   d
                                                   m
                                                
                                                
                                                   K
                                                   m
                                                
                                                
                                                   
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         
                                                            x
                                                            i
                                                         
                                                      
                                                      ,
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         
                                                            x
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   d
                                                   m
                                                
                                                =
                                                1
                                                ,
                                                
                                                   d
                                                   m
                                                
                                                ≥
                                                0
                                                ,
                                                ∀
                                                m
                                                =
                                                1
                                                ⋯
                                                M
                                                ;
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where fm
                         (xi
                        ) is the mth feature of image patch xi
                        , the weight dm
                         stands for the importance of the mth kernel K
                        
                           m
                        (f
                        
                           m
                        (x
                        
                           i
                        ),
                        f
                        
                           m
                        (x
                        
                           j
                        )) and M is the total number of kernels. In our work, one feature only corresponds to one kernel. Therefore, the kernel and feature have the same meaning if there's no other explanation.

Among the many existing MKL learning algorithms, simpleMKL [19] is known for its simplicity and efficiency. The optimization problem of simpleMKL is given as follows:
                           
                              (2)
                              
                                 
                                    
                                       
                                          
                                             min
                                             
                                                d
                                                ,
                                                w
                                                ,
                                                b
                                                ,
                                                η
                                             
                                          
                                          
                                          
                                             1
                                             2
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   1
                                                   
                                                      d
                                                      m
                                                   
                                                
                                                
                                                   
                                                      
                                                         w
                                                         m
                                                      
                                                   
                                                   2
                                                
                                                +
                                                C
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         η
                                                         i
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                          
                                          
                                             y
                                             i
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      m
                                                      =
                                                      1
                                                   
                                                   M
                                                
                                                
                                                   
                                                      w
                                                      m
                                                      T
                                                   
                                                   Φ
                                                   
                                                      
                                                         
                                                            f
                                                            m
                                                         
                                                         
                                                            
                                                               x
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                   +
                                                   b
                                                
                                             
                                          
                                          ≥
                                          1
                                          −
                                          
                                             η
                                             i
                                          
                                          ,
                                          ∀
                                          i
                                          =
                                          1
                                          ⋯
                                          N
                                          ;
                                       
                                    
                                    
                                       
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   d
                                                   m
                                                
                                                =
                                                1
                                                ,
                                                
                                                   d
                                                   m
                                                
                                                ≥
                                                0
                                                ,
                                                ∀
                                                m
                                                =
                                                1
                                                ⋯
                                                M
                                                ;
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where yi
                         is the label of the image patch xi
                        , Φ(f
                        
                           m
                        (x
                        
                           i
                        )) is the implicit mapping of f
                        
                           m
                        (x
                        
                           i
                        ) imposed by the mth kernel, C is the penalty parameter, ηi
                         is the slack factor, b is the bias and N is the total number of training examples. Problem (2) can be solved efficiently by alternating between determining the SVM model parameters via a standard SVM solver and determining the kernel combination importance by using a projected gradient descent method. Details can be found in [19].

The main problem in MKL is that all samples in one feature space are assigned the same weight, however, the individual samples may have different importance. Another problem is that we find that simpleMKL often assigns a major weight to one feature due to the sparsity at kernel level. This would not achieve the goal of feature combination to resist the appearance changes. Therefore, we use the AKM learning to construct the appearance model.

The key idea of the Augmented Kernel Matrix Learning is that the positive and negative training examples in each feature space are classified as positive or negative respectively. This allows to assign different weights to the information channel per example rather than per kernel which exploit information from individual samples deeply. Therefore, the primal SVM of AKM scheme is given:
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             min
                                             
                                                w
                                                ,
                                                b
                                                ,
                                                η
                                             
                                          
                                          
                                          
                                             1
                                             2
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   
                                                      
                                                         w
                                                         m
                                                      
                                                   
                                                   2
                                                
                                                +
                                                C
                                                
                                                   
                                                      ∑
                                                      
                                                         m
                                                         =
                                                         1
                                                      
                                                      M
                                                   
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            
                                                               η
                                                               mi
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                          
                                          
                                             y
                                             i
                                          
                                          
                                             
                                                
                                                   w
                                                   m
                                                   T
                                                
                                                Φ
                                                
                                                   
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         
                                                            x
                                                            i
                                                         
                                                      
                                                   
                                                
                                                +
                                                b
                                             
                                          
                                          ≥
                                          1
                                          −
                                          
                                             η
                                             mi
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                          
                                             η
                                             mi
                                          
                                          ≥
                                          0
                                          ,
                                          ∀
                                          m
                                          =
                                          1
                                          ⋯
                                          M
                                          ,
                                          i
                                          =
                                          1
                                          ⋯
                                          N
                                          ;
                                       
                                    
                                 
                              
                           
                        
                     

By using Lagrange multipliers, the dual of Problem (3) can be derived as:
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             min
                                             α
                                          
                                       
                                       
                                          
                                             1
                                             2
                                          
                                          
                                             α
                                             T
                                          
                                          YKYα
                                          −
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         α
                                                         mi
                                                      
                                                   
                                                
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         α
                                                         mi
                                                      
                                                      
                                                         y
                                                         i
                                                      
                                                      =
                                                      0
                                                      ,
                                                   
                                                
                                                
                                             
                                          
                                          
                                       
                                    
                                    
                                       
                                       
                                          0
                                          ≤
                                          
                                             α
                                             mi
                                          
                                          ≤
                                          C
                                          ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          ∀
                                          m
                                          =
                                          1
                                          ⋯
                                          M
                                          ,
                                          i
                                          =
                                          1
                                          ⋯
                                          N
                                          ;
                                       
                                    
                                 
                              
                           
                        where α
                        =[α
                        11,⋯
                        α
                        1N
                        ,⋯,
                        α
                        
                           m1,⋯
                        α
                        
                           mN
                        ]T, Y=IM ⊗ diag(y1; · · · ; yN) is the diagonal label matrix, where IM is the identity matrix and ⊗ denotes the Kronecker product. K is the Augmented Kernel Matrix, defined as follows:
                           
                              (5)
                              
                                 
                                    K
                                    =
                                    
                                       K
                                       1
                                    
                                    ⊕
                                    ⋯
                                    ⊕
                                    
                                       K
                                       M
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   K
                                                   1
                                                
                                             
                                             
                                                ⋯
                                             
                                             
                                                0
                                             
                                          
                                          
                                             
                                                ⋮
                                             
                                             
                                                ⋱
                                             
                                             
                                                ⋮
                                             
                                          
                                          
                                             
                                                0
                                             
                                             
                                                ⋯
                                             
                                             
                                                
                                                   K
                                                   M
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where Km
                         is the mth base kernel. From the Augmented Kernel Matrix, it is obvious that there is no cross terms between different feature spaces.

This quadratic optimization Problem (4) can be easily solved by standard optimization software such as Gurobi and CPLEX. The resulting decision function of AMK Classification can be expressed as:
                           
                              (6)
                              
                                 
                                    F
                                    
                                       x
                                    
                                    =
                                    
                                       1
                                       M
                                    
                                    
                                       
                                          ∑
                                          
                                             m
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                
                                                   α
                                                   mi
                                                   ∗
                                                
                                                
                                                   y
                                                   i
                                                
                                                
                                                   K
                                                   m
                                                
                                                
                                                   
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         x
                                                      
                                                      ,
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         
                                                            x
                                                            i
                                                         
                                                      
                                                   
                                                
                                                +
                                                b
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

As discussed before, nearly all tracking algorithms construct the appearance model either by using the only current frame or a few recent ones, which makes the tracker intolerant of abrupt appearance changes in short time intervals [11]. To overcome this problem, we exploited the historical information carefully to balance the tracker's performance and processing speed. In this current work, we propose the AKM clustering algorithm which groups the tracking results into a few respects and we could select more representative ones and add them into the training set.

The AKM clustering first maps data points in Xr
                         into a high dimensional space and finds a minimal enclosing sphere. And then, this sphere is mapped back to data space and separated into several components, each enclosing a separate cluster of points. The boundary of the minimal enclosing sphere is defined as follows:
                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             min
                                             
                                                w
                                                ,
                                                ρ
                                                ,
                                                η
                                                ,
                                                ν
                                             
                                          
                                       
                                       
                                          
                                             1
                                             2
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   
                                                      
                                                         w
                                                         m
                                                      
                                                   
                                                   2
                                                
                                                +
                                                
                                                   1
                                                   Nν
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         m
                                                         =
                                                         1
                                                      
                                                      M
                                                   
                                                   
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            N
                                                         
                                                         
                                                            
                                                               η
                                                               mi
                                                            
                                                            −
                                                            ρ
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          
                                       
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                       
                                       
                                          
                                             w
                                             m
                                             T
                                          
                                          Φ
                                          
                                             
                                                
                                                   f
                                                   m
                                                
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                
                                             
                                          
                                          ≥
                                          ρ
                                          −
                                          
                                             η
                                             mi
                                          
                                          ,
                                          
                                             η
                                             mi
                                          
                                          ≥
                                          0
                                          ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          ∀
                                          m
                                          =
                                          1
                                          ⋯
                                          M
                                          ,
                                          i
                                          =
                                          1
                                          ⋯
                                          N
                                          ;
                                          
                                       
                                    
                                 
                              
                           
                        where the penalty parameter ν
                        ∈(0,1) controls the tradeoff between the allowed slack and the complexity of the region boundary. When ν
                        →1, it can tolerate large value of slack variables and this allows many examples to lie outside the sphere; when ν
                        →0, it penalizes significantly on the slack variables, converting the problem effectively into a hard margin decision problem, which leads to a very tight and complex boundary.

By introducing Lagrange multipliers, we can get the dual of Problem (7):
                           
                              (8)
                              
                                 
                                    
                                       
                                          
                                             min
                                             α
                                          
                                       
                                       
                                          
                                             1
                                             2
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   α
                                                   m
                                                   T
                                                
                                                
                                                   K
                                                   m
                                                
                                                
                                                   α
                                                   m
                                                
                                                =
                                                
                                                   1
                                                   2
                                                
                                                
                                                   α
                                                   T
                                                
                                                Kα
                                             
                                          
                                       
                                    
                                    
                                       
                                          s
                                          .
                                          t
                                          .
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         α
                                                         mi
                                                      
                                                      =
                                                      1
                                                      ,
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          0
                                          ≤
                                          
                                             α
                                             mi
                                          
                                          ≤
                                          
                                             1
                                             Nν
                                          
                                          ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          ∀
                                          m
                                          =
                                          1
                                          ⋯
                                          M
                                          ,
                                          i
                                          =
                                          1
                                          ⋯
                                          N
                                          ;
                                          
                                       
                                    
                                 
                              
                           
                        where α
                        =[α
                        11,⋯
                        α
                        1N
                        ,⋯,
                        α
                        
                           m1,⋯
                        α
                        
                           mN
                        ]T, and α
                        
                           m
                        
                        =[α
                        
                           m1,⋯,
                        α
                        
                           mN
                        ], Km
                         is the mt
                        h base kernel and K is the AKM matrix defined in Eq. (5). This optimization Problem (8) can be solved efficiently via MATLAB and Gurobi. Then we get the decision function of the AKM clustering:
                           
                              (9)
                              
                                 
                                    R
                                    
                                       x
                                    
                                    =
                                    
                                       1
                                       M
                                    
                                    
                                       
                                          ∑
                                          
                                             m
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                
                                                   α
                                                   mi
                                                   ∗
                                                
                                                
                                                   K
                                                   m
                                                
                                                
                                                   
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         x
                                                      
                                                      ,
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         
                                                            x
                                                            i
                                                         
                                                      
                                                   
                                                
                                                −
                                                ρ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

After we get the minimal enclosing sphere, an adjacency matrix A is defined as follows:
                           
                              (10)
                              
                                 
                                    
                                       A
                                       ij
                                    
                                    =
                                    
                                       
                                          
                                             
                                                1
                                             
                                             
                                                for
                                                
                                                all
                                                
                                                y
                                                
                                                on
                                                
                                                the
                                                
                                                line
                                                
                                                segment
                                                
                                                connecting
                                                
                                                
                                                   x
                                                   i
                                                
                                                
                                                and
                                                
                                                
                                                   x
                                                   j
                                                
                                                ,
                                                
                                                R
                                                
                                                   y
                                                
                                                ≤
                                                0
                                             
                                          
                                          
                                             
                                                0
                                             
                                             
                                                otherwise
                                                .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Clusters are now assigned as the connected components of the graph induced by A. Details of the assignment are referred to [24]. After we get the cluster assignment, we select the top 50% high score examples to form the representative example set Xb
                        . This helps to discard a few inaccurate tracking results which are unavoidable in the tracking process. The tracking results before and after clustering can be found in Fig. 1
                        .

Let l
                           
                              t
                           
                           ∗ denote the center position of the target in the tth frame. And l
                           
                              t
                           (x) is the center position of an image patch x in frame t. About n examples are randomly sampled from Z
                           ≡{x
                           :
                           r
                           
                              l
                           
                           <∥
                           l
                           
                              t
                           (x)−
                           l
                           
                              t
                           
                           ∗
                           ∥<
                           m
                           
                              l
                           } to form the negative training set X
                           
                              t
                           
                           
                              n
                           . In our tracking system, the positive training X
                           
                              t
                           
                           
                              p
                            is composed of two parts Xt
                           , Xb
                           . All image patches around the target position in the current frame are sampled as positive ones, that is, X
                           
                              t
                           
                           ={x
                           :‖l
                           
                              t
                           (x)−
                           l
                           
                              t
                           
                           ∗‖≤
                           s
                           
                              l
                           }. Xb
                            stands for the historical representative image patches.

Let X
                           
                              t
                              +1 be the set of location candidates of the object in the new frame. L image patches with scale change are randomly sampled under this strategy x
                           ∈‖l(x)−
                           l
                           
                              t
                           
                           ∗‖≤
                           s. Then, image patches are normalized, features are extracted and evaluated via F
                           
                              t
                           (x). The patch with the highest score is accepted as the location of the object in the new frame t
                           +1, i.e.,
                              
                                 (11)
                                 
                                    
                                       
                                          l
                                          
                                             t
                                             +
                                             1
                                          
                                          ∗
                                       
                                       =
                                       l
                                       
                                          
                                             arg
                                             
                                                max
                                                
                                                   x
                                                   ∈
                                                   
                                                      X
                                                      
                                                         t
                                                         +
                                                         1
                                                      
                                                   
                                                
                                             
                                             
                                                F
                                                t
                                             
                                             
                                                x
                                             
                                          
                                       
                                       .
                                    
                                 
                              
                           
                           
                              Algorithm 1
                              The Augmented Kernel Matrix Tracker
                                    
                                       
                                    
                                 
                              

Pixel intensity contains rich visual information that directly shows what the target is, however it is easily affected by illumination changes. In our system, each image patch is normalized into 16×16, and the pixel value is concatenated into the corresponding feature vector.

LBP feature captures the texture information of the target and is more robust to illumination changes than pixel intensity feature. However, it may not be adaptive to background clutter scene. In our system, the patch is normalized into 32×32 and then divided into 2×2 blocks. LBP feature [17] of each block is extracted and concatenated into a longer feature vector.

In our tracking system, we set sl
                           
                           =2, rl
                           
                           =16, ml
                           
                           =40, s
                           =35, the penalty parameter C
                           =0.5, 
                              
                                 
                                    
                                       1
                                       Nν
                                    
                                 
                                 =
                                 0.5
                              
                            and about n
                           =65 negative examples are sampled. The number of the candidate image patches L is set 400. The Gaussian kernel is used for measuring the similarity of image patches in the feature space. And γ is 0.05, 0.3 for pixel intensity and LBP features respectively. The budget Nr
                            of the tracked image set Xr
                            is set as 100 when activating the AKM clustering algorithm.

The entire procedure of the proposed tracking algorithm, the Augmented Kernel Matrix Tracker (AKMT), is summarized in Algorithm 11.

@&#EXPERIMENTS@&#

We implement our Augmented Kernel Matrix Tracker (AKMT) in C++ language and evaluate its performance on public challenging image sequences. AKMT is quantitatively compared with some state-of-the-art tracking algorithms, FragTrack (Frag) [25], MILTracker (MIL) [5], VTS [6] and Struck [26]. Their codes or executable program are publicly available and the parameters are finely turned. The initial positions of the first frame are the same in all tracking algorithms. And the tracking results might be slightly different as stated in their papers, for the initial positions in some sequences from [5] are set as in [5]. We tested the Struck tracker with Haar-like features as Hare did in [26] and we name it as StruckH. We also tested Struck with pixel intensity and LBP features and we name it as StruckIL. We implement the simpleMKL Tracker (SimMKLT) to compare the different feature combination schemes. And for fair comparisons, we also used the AMK clustering algorithm in SimMKLT. We also concatenate the Color and LBP features together and learn the appearance model via the canonical SVM and the support vector clustering algorithm is used in this system. We name this tracker as Concatenated Feature Tracker (CFT).

Throughout the experiments, we evaluated all approaches on the following sequences: Sylvester, David, Girl, FaceOcc, Tiger1, Tiger2, CokeCan, Shaking and Skating1. The first seven sequences are from [5] and the last two from [4]. The main captions of the sequences are listed in Table 1
                     .

The quantitative evaluation of a tracking algorithm is a challenge. To evaluate the performances among the above state-of-the-art algorithms and ours, the center location errors [5] between the tracking results and the ground truth are calculated and reported on image sequences. To reduce the influence of the randomness in our tracking algorithm, we run our tracker five times on every sequence and use the average of the tracking results.

The whole quantitative comparisons are shown in Table 2
                         and Fig. 6
                        
                        
                        
                        
                        . The proposed AKMT achieved the best or the second best tracking results on most tested sequences. It can be concluded that our tracker was almost always more robust than others. (See Fig. 2.)

Trackers are often sensitive to initialization variations. Therefore, we also tested our tracker and others with different initializations to see how these trackers behave. We selected five sequences and set the initial bounding box in the first frame by scaling the ground truth labeled manually. The scale ratio is set 0.8 and 1.2. From Tables 3 and 4
                        
                        , AKMT could achieve superior performance over the other trackers regarding a poor initialization.

Illumination change is the most common appearance change in the tracking problem. And this would result in the drastic difference of the pixel intensity. Features based on the pixel intensity, e.g. Haar-like features, are easily effected and the tracking algorithms that use this kind of feature representation might be degraded due to illumination change. However, features based on edge or texture, e.g. LBP, are more robust to illumination change. This could be observed in David (Fig. 5), CokeCan (Fig. 5), Shaking (Fig. 5) and Skating1 (Fig. 5). In David (Fig. 5), when the target moved from the darker place to the brighter, MILTracker introduced tracking errors gradually from the very beginning. And this was very obvious that MILTracker tracked the target unwell due to the sudden illumination change at frame 393–395 in David (Fig. 5). This could be also observed at frame 72–73 in CokeCan (Fig. 5). In Shaking (Fig. 5) and Skating1 (Fig. 5), MILTracker lost the target after a few frames. Struck Tracker also gave a bad result at frame 228 in CokeCan (Fig. 5) and lost the target in Shaking (Fig. 5) and Skating1 (Fig. 5). Due to the usage of the edge feature, VTS and AKMT performed well when the illumination changed.

Occlusion is a big challenge to a tracker. Struct Tracker performed slightly better than AKMT on Girl (Fig. 5) and FaceOcc. However, on the more challenging sequences, Tiger1 (Fig. 5) and CokeCan (Fig. 5), AKMT worked better. Especially on Tiger1 (Fig. 5), Struct Tracker lost the target at frame 236 due to partial occlusion and never re-catch the target till the end.

VTS might be hijacked by another person at frame 171 in Skating1 (Fig. 5) due to the partial occlusion, whereas our AKMT could handle this well.

Background clutter might easily cause the tracker's failure, for there might be a blob similar to the target and the tracker got a wrong update to this region. MILTracker nearly lost the target at frame 318 in Tiger1 (Fig. 5), at frame 107 in CokeCan (Fig. 5) and at frame 52 in Skating1 (Fig. 5). Struct Tracker introduced tracking errors at frame 153 and totally lost the target at frame 235 in David (Fig. 5). And it was also hijacked at frame 167 in Shaking (Fig. 5). VTS quickly lost the target on Tiger1 (Fig. 5) and CokeCan (Fig. 1) and never recovered from the tracking failure on CokeCan (Fig. 5). Our AKMT performed well on these videos and dealt with the background clutter well due to the usage of the complementary features.

3D rotation introduced new aspects of the target and caused the drifting owing to the loss of depth information in the 2D image [27]. MIL, VTS and Struct, all these three trackers introduced errors at frame 532 on Sylvester (Fig. 5) and at frame 235 on David (Fig. 5) and VTS lost the target at the end on Sylvester (Fig. 5). Our track achieved the best performance well when 3D rotation happened on these two videos. Our tracker also performed better than the others on Tiger1 (Fig. 5), Shaking (Fig. 5) and Skating1 (Fig. 5).

From Table 2, it is easily observed that our AKMT performances are better than CFT and SimMKLT. In Fig. 3 and Table 5
                        , some patches are selected as support vectors in the pixel intensity space while they are non-support vectors in the LBP feature space. Our AMKT can learn different importance of the same patch in different feature spaces. AKMT can also assign more weight on the LBP feature space when large illumination change happens at frame 60 in Sequence Shaking while more weight on the pixel intensity feature space at frame 74. Therefore, AKMT can exploit training examples more efficiently and learn a more describable and robust appearance model.

SimMKLT assigns the same Lagrange multiplier to one training sample in all feature spaces, which is lack of flexibility compared with AKMT. And from Table 6
                        , we can see that SimMKLT often assigns a major weight to one feature space. This would not achieve the goal of feature combination to resist the appearance changes. Therefore, AMKT can perform better than SimMKLT when dealing with occlusion (Fig. 5) and illumination changes (Fig. 5, 5). CFT concatenates different features directly, which makes it hard to select the parameter of the Gauss kernel. The representative tracking results of different feature combination are shown in Fig. 4.

As we discussed in Section 3.3, AKM clustering groups the tracking results of the past frames and representative results are selected and added into the training set to train the tracker. This makes our tracker utilize the historical information of the object and more robust to abrupt appearance changes in short time intervals [11]. The comparisons of AKMT with and without clustering are presented in Fig. 5. In Sequence Sylvester (Fig. 5), AKMT without clustering introduced errors at frame 1150 and lost the target at frame 1169 when the target rotated out-of-plane (3D-rotation). Though AKMT with clustering introduced errors at frame 1169, it re-located the target at frame 1174 because it exploited the historical information with AKM clustering. This could also be observed at frame 248–270 in Sequence CokeCan (Fig. 5). AKMT with clustering re-tracked the target while AKMT without clustering was hijacked by the clutter when target reappeared after occlusion. The center errors of AKMT with clustering are 10 and 5pixels while errors of AKMT without clustering are 17 and 10pixels on these two videos. From the comparisons, we can see that AKMT with AKM clustering is more intolerant of abrupt appearance changes in short time intervals.

@&#CONCLUSION@&#

In this paper, we propose an effective and robust tracking algorithm based on the Augmented Kernel Matrix Learning framework. The Augmented Kernel Matrix classification combines the pixel intensity and LBP features and exploits the information of each training example on each feature space efficiently. In addition, to make our tracker be tolerant of abrupt appearance changes, the Augmented Kernel Matrix clustering is used to mine the historical representative examples in the tracking results. And the representative examples are added into the training examples. Experiments compared with several state-of-the-art methods on challenging sequences demonstrate the effectiveness and robustness of the proposed algorithm.

@&#ACKNOWLEDGMENTS@&#

We thank the reviewers and editors for helpful feedbacks. This work is supported by the National Natural Science Foundation of China under Grants No. 61375035.

@&#REFERENCES@&#


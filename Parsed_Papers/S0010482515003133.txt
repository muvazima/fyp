@&#MAIN-TITLE@&#Reliable resource-constrained telecardiology via compressive detection of anomalous ECG signals

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Reliable resource-constrained telecardiology is proposed in a two-tier framework.


                        
                        
                           
                           Our technique suits rural communities with limited power and bandwidth.


                        
                        
                           
                           Compressive sampling and high-sensitivity detection remain at the core.


                        
                        
                           
                           Classifiers are designed by exploiting self-similarity and periodicity of ECG.


                        
                        
                           
                           High reliability is maintained even at substantial power and bandwidth savings.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Telecardiology

Compressive sampling

Hurst exponent

Autocorrelation

Receiver operating characteristics

@&#ABSTRACT@&#


               
                  Graphical abstract
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

The electrocardiogram (ECG) has emerged as an indispensable tool in diagnosing and managing cardiovascular diseases (CVDs), which account for about 30% of the global death [1]. In certain scenarios, including high-risk-patient care, ECG from a subject is continuously monitored to detect deviation from normal sinus rhythm. However, practical difficulties arise when only a few general physicians (or nurses), but no experts in cardiology, are available locally for on-site monitoring. In such situations, need based transportation of experts, despite being both time consuming and expensive, used to be the only recourse available in the past. With the advent of information technology, telecardiology, possibly accompanied by automated diagnostic assists, is fast becoming an attractive alternative [2–9]. Specifically, rather than physically relocating experts to the bedside of the patient, ECG signal collected from the patient is electronically transported to experts, thereby increasing overall responsiveness while bringing down cost.

A design framework for such systems has been presented, albeit in broader contexts [10,11]. A number of specific aspects, such as data acquisition [12,13], technology adoption [14,15], privacy and security [16–18], and network architectures and protocols [19,20], have also been studied. In this context, various quality-of-service models have been suggested [21]. Such telecardiology systems are already functional in certain communities at an operating cost that is affordable to many [2–4]. For instance, a successful Brazilian system reports a cost of about US$ 9 for single access [22]. However, their operational feasibility crucially depends on various factors, including local availability of health workers with basic medical training, and reliable communication links such as landline phones. Unfortunately, even such basic resources are not available to a large section of world population, and the aforementioned sum may not be affordable to them. In this backdrop, we take a frugal engineering approach [23], and propose a novel telecardiology architecture that ensures reliable cardiac care even under severe resource constraints, and operates at significantly lower costs.

First we attempt to paint a realistic picture of the target demographics, and accordingly, set our objectives. Taking India as an example, about 276 million individuals live on less than US$ 1.25 per day (the figure rises to 1.2 billion worldwide), and a majority of them live in remote rural areas [24]. Many of them need to traverse about 9km to reach the nearest sub-health-center, which typically employs two health workers but no medical doctors, and provides only rudimentary facilities [25]. Further, a large number of rural communities have no access to the electrical grid and landline phones [26]; however, the high penetration of mobile phones, albeit with poor service quality, provides a silver lining [27]. Against this backdrop, we ask: Can such basic mobile network be leveraged to provide reliable healthcare at an attractive cost to the aforementioned communities living at “the bottom of the pyramid” [28], even in the face of attendant severe constraints on power and bandwidth? In this paper, we pose this challenge as an engineering problem, provide a mathematical solution, translate the solution to a novel two-tier telecardiology architecture, and demonstrate its efficacy via extensive simulations on standard databases.

As alluded earlier, a conventional telecardiology system, depicted in Fig. 1
                     a, simply records user ECG, transmits it unaltered to a diagnostic center, and is generally used in primary care centers [2]. Such primary care centers are usually manned by personnel with certain level of medical training, supplied with grid power, and equipped with reliable communication link. However, such a system does not function in our setting, where access to power and bandwidth are unreliable, and health workers are practically absent. In this context, we seek a low-power solution that prolongs battery life of the user device. Further, to utilize the unreliable mobile network, we propose to use the short message service (SMS), a robust alternative to a dedicated link, establishing which over a rickety mobile network could be unreliable. In this setting, consider communication of 8.2s worth of ECG sampled at 500Hz into 12-bit words. The usual ASCII coding would take 44 messages costing about US$ 0.7 (at the rate US$ 0.016 per SMS, now prevalent in India), which is more than half of the target daily income [24], and unacceptably high. Accordingly, it becomes imperative to reduce the bandwidth requirement significantly.

However, design of a low-power low-bandwidth telecardiology system poses considerable engineering challenge. To appreciate the design challenges, first consider a system constrained by communication bandwidth only. Clearly, one would compress the recorded ECG signal before transmission [29,30]. However, high-efficiency compression algorithms are generally compute-intensive, and hence consume significant amount of power. Therefore, under an additional power constraint, the aforementioned approach loses its appeal. On the other hand, very low power ECG acquisition and monitoring systems have been developed for personalized healthcare applications, but such systems cannot handle the requisite communication range [31–33]. Such competing implications of various constraints render greedy approaches unattractive and prompt us to develop a new paradigm.

Accordingly, we propose a novel telecardiology framework, where resource constraints are met by compressively sampling ECG signals [34], and identifying and transmitting only anomalous signals. Specifically, we envisage a two-tier architecture, shown in Fig. 1b, where power-constrained users from a locality record ECG data in a compressive manner, and communicate those to a resource-rich local subcenter. Each such subcenter detects anomalous signals and transmits only those signals over a bandwidth-constrained link to the diagnostic center. We assume such center to be adequately equipped to make professional diagnosis, correct possible misclassifications in received signals, and initiate medical intervention (possibly via SMS) as required. Desirably, the experiences of both subjects and experts remain essentially unaltered (vis-à-vis traditional telecardiology), as a subject still collects the ECG signal using the same transducers, and an expert visualizes that signal at the diagnostic center at essentially the same quality (with R
                     2 score greater than 95%).

In this framework, system design involves a tradeoff among three quantities of generally descending importance: the fraction of unserved patients, which we take as the performance/quality criterion, user power, and transmission bandwidth. We would target missing no more than a small fraction of patients (e.g., no more than five patients in a thousand, requiring sensitivity greater than 99.5%), while reducing user power requirement with an aim of prolonging device life, and transmission bandwidth to lower operating cost. The aforementioned quantities are in turn functions of three parameters: effective downsampling factor resulting from compressive sampling, sensitivity, and specificity of the anomaly detector. Thus, towards realizing resource-constrained telecardiology, one needs to first study anomaly detection based on compressive samples.

The problem of classifying ECG signals into normal and anomalous categories has widely been investigated. For instance, ventricular arrhythmia detection has been attempted using Karhunen–Loève transform [35] and artificial neural network [36]. In the general context, wavelet-based estimation of the characteristic points of ECG signals (P, Q, R, S, and T) and anomaly detection using such points have been reported [37,38]. There have also been attempts based on fractal dimension and measures of self-similarity such as Hurst exponent [39]. However, the aforementioned anomaly detection algorithms generally set classifier design as the final goal, and attempt at neither compressive detection nor optimizing system reliability subject to resource constraints.

In this context, we take a holistic approach towards reliable resource-constrained telecardiology enabled by compressive anomaly detection. Specifically, taking inspiration from earlier work, we propose an anomaly detection scheme that uses two inherent properties of ECG signals, namely, self-similarity and periodicity. In particular, Hurst exponent, a measure of self-similarity, tends to be larger for abnormal signals [40,41]. Further, normal signals are approximately periodic [42]. Hence we propose an empirical measure, autocorrelation ratio (ACR), of closeness to such normal periodicity, thus segregating abnormal signals. Subsequently, we propose a composite classifier based on Hurst exponent and ACR that is found to perform better than those based on individual criterion. We then characterize and compare such classifiers using receiver operating characteristics (ROC), trading off sensitivity against specificity. Classifier design based on compressive samples poses further difficulty as Hurst exponent and ACR need now be estimated compressively. We overcome this difficulty by utilizing sparseness of ECG signals in wavelet basis [43,44]. Finally, we demonstrate, using the PhysioNet databases [45], a reliable telecardiology system, which even at a downsampling factor of five leaves no more that 0.5% patients unserved, and in the process saves user power by 80% and transmission bandwidth by 83.4%. This not only translates to a five-fold longer battery life, but also an average bandwidth cost of US$ 0.12, which is less than 10% of the target income level.

Our main contributions are summarized below:
                        
                           1.
                           Reliable resource-constrained telecardiology is conceptualized in a two-tier framework with high-sensitivity compressive anomaly detection at its core.

Various downsampling factors and patterns are investigated against reconstruction and detection fidelities.

Known Hurst-exponent-based classifiers are augmented with the proposed ACR measure to achieve higher accuracy in the targeted high-sensitivity regime.

A resource-constrained telecardiology system is realized, whose reliability is demonstrated using standard databases. Specifically, a five-fold increase in battery life, and a 83.4% reduction in bandwidth cost are achieved compared to classical telecardiology.

As alluded earlier, we seek to design telecardiology systems for a vast segment of the population living on about US$ 1.25 per day [24], having practically no access to local health workers [25], and facing severe scarcity of power and communication bandwidth [26]. To make matters worse, the available mobile network generally provides poor service quality [27]. As a counter, we propose to use the short message service (SMS), which is more robust than relying on dedicated links [46]. In this framework, a conventional telecardiology system, shown in Fig. 1a, transmitting an 8.2s ECG-segment sampled at 500Hz into 12-bit words, would require 44 messages upon ASCII coding. Those cost about US$ 0.7 (at the rate of US$ 0.016 per SMS, currently prevalent in India), amounting to more than half of the target daily income [24], which is unacceptably high.

In this setting, we envisage a low-power low-bandwidth-cost solution that does not require medical training to operate. To this end, we identify as key infrastructural element the ubiquitous mobile base station [27], which does not suffer from power and comuputational resource constraints. Specifically, we propose a two-tier telecardiology architecture with such base stations as local subcenters, where the user ECG is first communicated to the said subcenter, and after certain processing, is transmitted to the diagnostic center (Fig. 2). The power requirement at the user end is reduced by compressively collecting only one out of D usual samples, and sending it to the subcenter. Specifically, one needs an analog-to-digital converter (ADC), programed to sample according to preassigned compressive pattern, and a transmitter to communicate such samples to the local subcenter. We shall see that near perfect recovery of the full rate signal is possible from such downsampled data due to sparsity properties of ECG signals [40,43]. Thus, for example, an effective downsampling factor of D=5, without any further processing, cuts by 80% the power budget (prolonging the device battery life five fold), as well as the bandwidth budget. Further, we propose to make additional bandwidth savings by sending only abnormal signals, as normal signals need no medical intervention. As the attendant detection of abnormal signals could be compute-intensive (requiring additional power), in view of the user power constraint, such detection is performed only at the local subcenter. Assuming that the user only pays for communication between the subcenter and the diagnostic center, such savings in bandwidth translate to additional cost savings. However, a practical detection algorithm is expected to be imperfect, and one desires to miss only a small fraction of abnormal signals. In such scenario, a target maximum fraction of unattended/missed patients often serves as a reliability criterion [21]. In the present work, we set our target at five in thousand or less (requiring a classifier sensitivity greater than 99.5%).

Desirably, the proposed system does not require the subject to either possess medical training, or physically interact with health workers. Further, the local subcenter only needs to provide power, computational resources, and access to communication, but no health facility. Accordingly, the proposed framework realistically caters to the intended communities, and the subject pays for the bandwidth cost only when the ECG is deemed potentially abnormal. In the event the user ECG is transmitted, a suitable diagnostic advise is delivered to the subject from the diagnostic center, possibly via SMS. In this manner, we envisage bringing under a health cover, albeit rudimentary, various remote communities, which otherwise remain outside the purview of traditional health services.

The bandwidth requirement of the aforementioned telecardiology system is given by
                        
                           (1)
                           
                              B
                              =
                              {
                              Se
                              ×
                              α
                              +
                              (
                              1
                              −
                              Sp
                              )
                              ×
                              (
                              1
                              −
                              α
                              )
                              }
                              /
                              D
                              ,
                           
                        
                     where, D is the effective downsampling factor due to compressive sampling, Se and Sp respectively are the Sensitivity and Specificity of the classifier employed and α indicates the prevalence rate of CVDs, and the bandwidth requirement for the conventional system is taken as the unit. An ideal classifier (Se=1, Sp=1) would require a bandwidth of 
                        B
                        =
                        α
                        /
                        D
                     . Further, assuming power requirement P to be proportional to the number of samples, and taking the power requirement for original sampling as the unit, one has
                        
                           (2)
                           
                              P
                              =
                              1
                              /
                              D
                              .
                           
                        
                     Finally, we adopt as the performance/quality metric Q the fraction of subjects with anomalous ECG unattended by the system, i.e.
                        
                           (3)
                           
                              Q
                              =
                              1
                              −
                              Se
                              .
                           
                        
                     Thus, bandwidth (B), power (P) and quality (Q), the quantities defining a resource-constrained system, are all specified by three parameters, effective downsampling factor (D), sensitivity (Se) and specificity (Sp).

Now we pose compressive anomaly detection as a hypothesis testing problem. A downsampling pattern 
                        ϕ
                        ⊆
                        {
                        1
                        ,
                        2
                        ,
                        …
                        ,
                        N
                        }
                      with factor 
                        D
                        =
                        N
                        /
                        |
                        ϕ
                        |
                      retains the i-th sample of signal 
                        x
                        ∈
                        
                           
                              R
                           
                           
                              N
                           
                        
                     , 
                        i
                        ∈
                        ϕ
                     , to obtain the downsampled signal x
                     
                        ϕ
                     . Given ϕ, denote by 
                        
                           
                              Γ
                           
                           
                              ϕ
                           
                        
                        ⊆
                        
                           
                              R
                           
                           
                              N
                              /
                              D
                           
                        
                      the set of downsampled ECG signals x
                     
                        ϕ
                     . A classification rule for hypothesis H
                     1 (abnormal) versus H
                     0 (normal) partitions 
                        
                           
                              Γ
                           
                           
                              ϕ
                           
                        
                      into subsets Γ
                     0 and Γ
                     1 such that given any 
                        
                           
                              x
                           
                           
                              ϕ
                           
                        
                        ∈
                        
                           
                              Γ
                           
                           
                              ϕ
                           
                        
                     , we decide H
                     
                        j
                      if 
                        
                           
                              x
                           
                           
                              ϕ
                           
                        
                        ∈
                        
                           
                              Γ
                           
                           
                              j
                           
                        
                      (j=0 or 1). Ideally, Γ
                     0 and Γ
                     1 should, respectively, correspond to normal and abnormal signals only (i.e., Se=1, Sp=1). Practically, we aim at designing Neyman–Pearson classifiers: for a given value α, we maximize Sp subject to 
                        Q
                        =
                        1
                        −
                        Se
                        ≤
                        α
                      
                     [47]. We then seek to plot ROC by varying α.

Before proceeding with the design of compressive classifiers, we provide a brief account of compressive sampling and recovery.

We use compressed sensing (CS) to recover high dimensional sparse vectors based on few linear measurements [48]. Specifically, it deals with the problem of economical recovery of an unknown signal x from its linear measurements 
                           〈
                           <
                           x
                           ,
                           
                              
                                 ϕ
                              
                              
                                 j
                              
                           
                           〉
                        , where 
                           
                              
                                 ϕ
                              
                              
                                 j
                              
                           
                           ∈
                           
                              
                                 R
                              
                              
                                 n
                              
                           
                        , 
                           j
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           N
                        , and 
                           〈
                           x
                           ,
                           
                              
                                 ϕ
                              
                              
                                 j
                              
                           
                           〉
                         indicates the inner product of x and ϕ
                        
                           j
                        . Then signal recovery from such measurements is
                           
                              (4)
                              
                                 
                                    
                                       
                                          min
                                       
                                       
                                          x
                                       
                                    
                                 
                                 ∥
                                 x
                                 
                                    
                                       ∥
                                    
                                    
                                       0
                                    
                                 
                                 
                                 subject
                                 
                                 to
                                 
                                 Φ
                                 x
                                 =
                                 y
                                 ,
                              
                           
                        where 
                           ∥
                           x
                           
                              
                                 ∥
                              
                              
                                 0
                              
                           
                         stands for the number of nonzero components in x, that is, 
                           ∥
                           x
                           
                              
                                 ∥
                              
                              
                                 0
                              
                           
                           =
                           |
                           {
                           i
                           :
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                           ≠
                           0
                           }
                           |
                         and Φ is the matrix whose rows are ϕ
                        
                           j
                        . In general, (4) is intractable. Fortunately, under certain technical conditions, solution to (4) is equivalent to its l
                        1-norm based optimization problem [44]:
                           
                              (5)
                              
                                 
                                    
                                       
                                          min
                                       
                                       
                                          x
                                       
                                    
                                 
                                 ∥
                                 x
                                 
                                    
                                       ∥
                                    
                                    
                                       1
                                    
                                 
                                 
                                 subject
                                 
                                 to
                                 
                                 Φ
                                 x
                                 =
                                 y
                                 ,
                              
                           
                        the recovery of sparse solution from (5) is possible as long as the synthesis matrix Φ satisfies (i) Restricted Isometry Property (RIP) and (ii) smaller value for the coherence parameter (μ), which is the absolute of maximum off-diagonal entry in 
                           
                              
                                 Φ
                              
                              
                                 T
                              
                           
                           Φ
                         
                        [49].

Signal recovery when the number n of measurements is much smaller than signal length N is of particular interest. The special case of compressive sampling arises when the process of linear measurement reduces to keeping n nonuniformly spaced samples, and leaving out the rest (
                           N
                           −
                           n
                        ) ones. In this case, the measurement matrix Φ has rows with all entries zero except one entry of one, and the locations of those unity entries are distinct.

In actual applications, suppose the user produces a vector x of, say, N ECG samples at the original sampling rate. We retain only a subset x
                        
                           Φ
                         of elements of x according to a pattern Φ at a downsampling factor D. In the present work, we consider the following choices of Φ:
                           
                              1.
                              
                                 Uniform downsampling retains one sample and loses the next 
                                    D
                                    −
                                    1
                                 , and repeats;


                                 Random sampling from uniform bins retains one sample, randomly selected from uniformly divided bins of size D; and


                                 Unconstrained random downsampling retains 
                                    N
                                    /
                                    D
                                  samples, selected randomly without any constraint.

Naturally occurring signals can often be represented sparsely in some transform basis with little loss of information. In the context of ECG signals, wavelet transform is a natural candidate for sparse representation in ‘db4’ wavelet basis [43] (Fig. 3
                        b). This is apparently due to the inherent scaling property of ECG data sets [50]. Suppose Φ is a row restriction matrix that picks the rows of the wavelet reconstruction matrix W
                        
                           T
                        , that is, 
                           Φ
                           x
                           =
                           Φ
                           
                              
                                 W
                              
                              
                                 T
                              
                           
                           c
                        . The wavelet coefficients (c) may be recovered from the following optimization problem:
                           
                              (6)
                              
                                 
                                    
                                       c
                                    
                                    
                                       ^
                                    
                                 
                                 =
                                 argmin
                                 ∥
                                 c
                                 
                                    
                                       ∥
                                    
                                    
                                       1
                                    
                                 
                                 
                                 subject
                                 
                                 to
                                 
                                 ∥
                                 Φ
                                 x
                                 −
                                 Φ
                                 
                                    
                                       W
                                    
                                    
                                       T
                                    
                                 
                                 c
                                 
                                    
                                       ∥
                                    
                                    
                                       2
                                    
                                 
                                 ≤
                                 ϵ
                                 ,
                              
                           
                        provided c is sufficiently sparse, and 
                           Φ
                           
                              
                                 W
                              
                              
                                 T
                              
                           
                         and size of 
                           Φ
                           x
                         satisfy sparse recovery properties. The quantity 
                           ϵ
                           >
                           0
                         is a small quantity whose choice is to be made based on compressibility. In order to recover wavelet coefficients, one needs to solve (6), for which we make use of the widely used orthogonal matching pursuit (OMP) algorithm, an iterative greedy method, whose solution is obtained by calculating locally optimal solution at each iteration. Though such sequence of locally optimum solutions is not guaranteed to converge at globally optimum solution, OMP remains attractive for its simplicity and low computational complexity [51]. The pseudo code for OMP used in the present application is shown in algorithm 1.
                           Algorithm 1
                           Pseudo code for recovering wavelet coefficients from compressive samples. 
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           

We propose a compressive classifier based on two inherent properties, self-similarity and periodicity. From the wavelet coefficients recovered using OMP algorithm [44], we estimate Hurst exponent: a measure of self-similarity and autocorrelation ratio: an empirical measure indicating closeness to periodicity of normal signals to aid ECG signal classification.

Based on the scaling property of a self-similar function f, i.e., 
                           f
                           (
                           
                              
                                 2
                              
                              
                                 −
                                 n
                              
                           
                           t
                           )
                           =
                           
                              
                                 2
                              
                              
                                 −
                                 nH
                              
                           
                           f
                           (
                           t
                           )
                        , H being the Hurst exponent, one can estimate H, from its wavelet coefficients [52]. For a discrete signal x, wavelet coefficients at the same location k at different scales j and m are related via 
                           
                              
                                 c
                              
                              
                                 j
                                 ,
                                 k
                              
                           
                           =
                           
                              
                                 2
                              
                              
                                 −
                                 
                                    
                                       (
                                       j
                                       −
                                       m
                                       )
                                       (
                                       2
                                       H
                                       +
                                       1
                                       )
                                    
                                    
                                       2
                                    
                                 
                              
                           
                           
                              
                                 c
                              
                              
                                 m
                                 ,
                                 k
                              
                           
                         
                        [53]. Hence the energy E
                        
                           j
                         at scale j is related to energy E
                        
                           m
                         at scale m by (assuming N
                        
                           k
                         coefficients at location k)
                           
                              (7)
                              
                                 
                                    
                                       E
                                    
                                    
                                       j
                                    
                                 
                                 ≔
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             k
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                       
                                    
                                 
                                 |
                                 
                                    
                                       c
                                    
                                    
                                       j
                                       ,
                                       k
                                    
                                 
                                 
                                    
                                       |
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             2
                                          
                                          
                                             −
                                             (
                                             j
                                             −
                                             m
                                             )
                                             (
                                             2
                                             H
                                             +
                                             1
                                             )
                                          
                                       
                                    
                                    
                                       
                                          
                                             N
                                          
                                          
                                             k
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                       
                                    
                                 
                                 |
                                 
                                    
                                       c
                                    
                                    
                                       m
                                       ,
                                       k
                                    
                                 
                                 
                                    
                                       |
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       2
                                    
                                    
                                       −
                                       (
                                       j
                                       −
                                       m
                                       )
                                       (
                                       2
                                       H
                                       +
                                       1
                                       )
                                    
                                 
                                 
                                    
                                       E
                                    
                                    
                                       m
                                    
                                 
                                 ,
                              
                           
                        leading to the energy scale formula
                           
                              (8)
                              
                                 
                                    
                                       log
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       E
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 −
                                 j
                                 (
                                 2
                                 H
                                 +
                                 1
                                 )
                                 +
                                 
                                    
                                       log
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       E
                                    
                                    
                                       0
                                    
                                 
                                 .
                              
                           
                        Thus Hurst exponent H is estimated from the slope of linear fit to 
                           (
                           j
                           ,
                           log
                           
                              
                                 E
                              
                              
                                 j
                              
                           
                           )
                        .

The unbiased autocorrelation function (ACF) of signal x is defined by
                           
                              (9)
                              
                                 R
                                 (
                                 τ
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       N
                                       −
                                       τ
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       0
                                    
                                    
                                       N
                                       −
                                       1
                                    
                                 
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                                 
                                    
                                       x
                                    
                                    
                                       k
                                       +
                                       τ
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       N
                                       −
                                       τ
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       k
                                       =
                                       0
                                    
                                    
                                       N
                                       −
                                       1
                                    
                                 
                                 
                                    
                                       c
                                    
                                    
                                       k
                                    
                                 
                                 
                                    
                                       c
                                    
                                    
                                       k
                                       +
                                       τ
                                    
                                 
                                 ,
                              
                           
                        where set 
                           
                              
                                 x
                              
                              
                                 k
                              
                           
                           =
                           0
                           ,
                           k
                           ∉
                           {
                           0
                           ,
                           1
                           ,
                           …
                           ,
                           N
                           −
                           1
                           }
                        . The second inequality in (9) follows from the isometry and localization properties of wavelets. As seen in Fig. 3c, the ACF of normal ECG signal exhibits spikes at regular intervals due to inherent periodicity of ECG signals. Complicating matters, ACFs of certain anomalous signals are also nearly periodic; however, those tend to possess more dominant negative peaks compared to that of normal beats. Motivated by this observation, we define an autocorrelation ratio (ACR)
                           
                              (10)
                              
                                 ρ
                                 =
                                 |
                                 
                                    
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                ∈
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      pos
                                                   
                                                
                                             
                                          
                                          R
                                          (
                                          i
                                          )
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                ∈
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      neg
                                                   
                                                
                                             
                                          
                                          R
                                          (
                                          i
                                          )
                                       
                                    
                                 
                                 |
                                 ,
                              
                           
                        where index set I
                        
                           pos
                         (resp. I
                        
                           neg
                        ) collects indices corresponding to K (taken as 10) largest positive (resp. negative) values of ACF 
                           R
                           (
                           ·
                           )
                        . Of course, we expect ACR to be low for anomalous signals.

At the local subcenter, wavelet coefficients are recovered using either Nyquist reconstruction (uniform sampling) or OMP (otherwise) and estimates Hurst exponent H using (7) and ACR ρ by first estimating ACF via (9). Finally, as depicted in Fig. 4
                        , a signal is marked normal if 
                           H
                           <
                           
                              
                                 H
                              
                              
                                 th
                              
                           
                         and 
                           ρ
                           >
                           
                              
                                 ρ
                              
                              
                                 th
                              
                           
                         for suitable thresholds H
                        
                           th
                         and ρ
                        
                           th
                        , and anomalous otherwise. The latter signals are then transmitted to the diagnostic center. Clearly, the classifier performance is dictated by the choice of such thresholds. We compare three cases: (i) Hurst classifier, where ACR ρ plays no role, i.e., 
                           
                              
                                 ρ
                              
                              
                                 th
                              
                           
                           =
                           0
                        ; (ii) ACR classifier, where H is ignored, i.e., H
                        
                           th
                         is set to a large value; and (iii) Composite classifier, where both H
                        
                           th
                         and ρ
                        
                           th
                         are active. Using the proposed classifier, we seek to achieve reliable telecardiology (missing less than five patients per thousand, i.e., 
                           Q
                           ≤
                           0.5
                           %
                        , or 
                           Se
                           ≥
                           99.5
                           %
                        ), while lowering power and bandwidth budgets.

Before validating the proposed design, we provide a brief overview of ECG anomalies considered and standardization across different databases to generate signal vectors.

Anomaly in the ECG signal arises from abnormal electrical activity in the heart. A large heterogeneous group of conditions, where the heart beat is either too fast or too slow, and may be either regular or irregular, are described as cardiac arrhythmia [54]. Further, a subclass of conditions that start in the atria are called atrial or supraventricular (above the ventricles) arrhythmias. Analogously, ventricular arrhythmias begin in the ventricles. Arrhythmias originating in the atria are further sub-categorized as atrial fibrillations (AFIB), atrial flutter, supraventricular tachycardia, and those originating in ventricles as ventricular fibrillation (VFIB), ventricular tachycardia (VT) and ventricular flutter. Various other anomalous heart conditions exist; however, rather than taking all such conditions into account, we shall focus on three abnormal conditions, namely, AFIB, VFIB and VT, and attempt to distinguish those from the normal (NSR).

We now validate the proposed design using ECG signals from the PhysioNet databases [45]. Specifically, NSR, MVA and AFIB signals are taken from the MIT-BIH database, and VT signals from the Creighton University database. Note that the later three signal categories are anomalous. Baseline wander in each signal is removed, sampling frequency is standardized at 500Hz (via suitable upsampling), and a segment of 4096 samples (amounting to a duration of 8.2s) is taken as a signal vector [55]. Altogether, we consider 15 normal and 24 abnormal subjects, and 20 such segments from each, giving rise to 780 signal vectors.

@&#EXPERIMENTS AND RESULTS@&#

In this section, first we demonstrate the efficacy of composite classifier over Hurst and ACR classifiers, and then investigate the choice of downsampling factor using various patterns and illustrate the classification results from compressively sampled data.

We plot ROC curves for ACR, Hurst and composite classifiers operating at the original sampling rate (500Hz) by varying applicable thresholds (Fig. 5
                        a). It can be observed that, composite classifier has improved performance over each of ACR and Hurst classifiers. In fact, as depicted in Fig. 5b, the gain is more significant in the desired high-sensitivity regime. For example, refer to numerical values given in Table 1
                        , and note that the specificity gains of the composite classifier over Hurst and ACR classifiers are 283.3% and 557.1%, respectively, at a sensitivity of 99.5%.

We recover the wavelet coefficients from the compressed measurements of different down sampling factors using OMP (Algorithm 1), and compute the reconstruction fidelities using R-squared
                           1
                        
                        
                           1
                           R in R
                              2-statistics is not to be confused with 
                                 R
                                 (
                                 ·
                                 )
                               in ACF.
                         (R
                        2) statistics as an objective measure [56]:
                           
                              (11)
                              
                                 
                                    
                                       R
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 1
                                 −
                                 
                                    
                                       ∥
                                       x
                                       −
                                       
                                          
                                             x
                                          
                                          
                                             ˜
                                          
                                       
                                       
                                          
                                             ∥
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       ∥
                                       x
                                       
                                          
                                             ∥
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where, x and 
                           
                              
                                 x
                              
                              
                                 ˜
                              
                           
                         stand respectively for the original signal and the signal reconstructed from compressed measurements. One can interpret (11) as the fraction of energy available in the approximated signal. A perfect recovery leads to 100% R
                        2 accuracy. Fig. 7 indicates the averaged R
                        2 score for signals recovered from compressed measurements for an effective downsampling factors upto six, with various downsampling patterns. It is observed that the recovery from uniform downsampling pattern and random sampling from uniform bins have superior performance over an instance of random sampling pattern. Note that the number of possible patterns for random sampling is an extremely large number. For instance, a downsampling factor by 5, would have 
                           (
                           
                              
                                 
                                    
                                       4096
                                    
                                 
                                 
                                    
                                       820
                                    
                                 
                              
                           
                           )
                         (i.e., 
                           >
                           
                              
                                 10
                              
                              
                                 800
                              
                           
                        ) possible patterns, and a feasible subset for realizing practical compressive sampling could be achieved by randomly picking samples from uniform bins. Further, note the variation in the R
                        2 scores for an instance of uniform downsampling pattern. Though the recovery appears aberrant, it does not violate any mathematical principles as R
                        2 score of downsampling by two is better than four (which is a subset of two), while signal sets acquired using downsampling by three and four are independent, and provides similar approximation.

The present work assumes that diagnostic center has all the facility to correct the possible misclassification in the received signals, but such an assumption is valid only if the signal transmitted from the local subcenter has all the diagnostic content intact. Therefore it is desirable to ensure high R
                        2 score for signals recovered from compressively sampled data. Specifically, we choose 95% R
                        2 value as an acceptable measure to recover the signal faithfully (indicated by a dotted line in Fig. 7) [57]. Considering the recovery performance from all the downsampling patterns, a downsampling factor of 5 appears to be attractive. Fig. 6
                         represents the signals recovered from compressed measurements for an effective downsampling factor of five, using various choices of downsampling patterns.
                     

We now compare ROCs of the same classifiers, now operating on compressively sampled data (Fig. 8
                        ), resulting from both uniform downsampling and random downsampling from uniform bins at various downsampling factors, and observe in each case the same general order of performance. To aid performance comparison in the high sensitivity regime, we tabulate specificity and specificity gain in Table 2
                         for sensitivity of 99.5% and 99.8%. Apart from the aforementioned superiority of composite classifier, we also notice the following. At a downsampling factor of five, random downsampling from uniform bins outperforms uniform downsampling at both the high sensitivity levels. Interestingly, comparing various patterns with five as downsampling factor (Fig. 9
                        ), we observe the above behavior only at sufficiently high sensitivity levels. We also used two unconstrained random downsampling patterns; however, those perform significantly worse.

Next we present the overall system performance for the quality metric Q=0.5%, i.e., sensitivity 
                           Se
                           =
                           99.5
                           %
                         (see (3)). Further, we also choose a power savings of 80%, i.e., a downsampling factor of D=5 (see (2)). The corresponding classification performance is furnished in boldface in Table 2. Clearly, even without performing classification at the local subcenter, one has to send only 20% of the samples in view of downsampling factor D=5, i.e., achieves a bandwidth savings of 80%. The proposed classification allows us further bandwidth savings, the extent of which linearly depends on the prevalence rate α of CVD (see (1), and is plotted in Fig. 10
                        ). For example, for the CVD prevalence rate of 
                           α
                           =
                           11
                        % reported in 2012 for the USA [58], such bandwidth savings would be 83.4%. In other words, classification enables one to save an additional 17% of the bandwidth requirement if only downsampling but no classification is performed. This additional savings arises essentially because about Sp=19% of the normal signals are not transmitted. While the above could act as a guideline, to accurately estimate bandwidth savings for a specific target population, one needs to first reliably estimate the corresponding disease prevalence rate.

At this point, it is worthwhile to make a rough cost comparison between the proposed and the traditional system, which we provide in the Indian context. Note that 4096 ECG samples of 12 bits each (amounting to 8.2s of ECG signal sampled at 500Hz) is equivalent to 6144 ASCII characters of 8 bits each. Those in turn require 44 SMS׳s (at 140 characters per SMS) for transmission. Without any downsampling or classification, one incurs a transmission cost of INR (Indian rupees) 44 at the prevalent rate of INR 1 per SMS (i.e., US$ 0.016, assuming an exchange rate of US$ 1 = INR 62), which is equivalent to US$ 0.7. In comparison, the propose system requires to transmit only 1020 characters on the average (at a bandwidth savings of 83.4%), which amounts to about 7.23 SMS׳s, costing INR 7.23, i.e., US$ 0.12.

Note that our system is envisaged to operate in communities, where health-related advise, and hence screening facilities are unavailable. Further, due to minimal cost barrier and zero transportation expense, we assume a random subset of the population will participate, which should manifest the same prevalence rate as the general population. However, our system could still be used even if subjects are screened directly or indirectly. In such scenarios, the prevalence rate α among the participating subjects is expected to be higher, and in view of Fig. 10, the bandwidth savings would be less significant. For example, the Brazilian telecardiology system, mentioned earlier [2,59], reports 
                           α
                           =
                           58
                           %
                         among participating subjects at the primary care center. When compared to 
                           α
                           =
                           11
                           %
                         reported for the USA [58], the Brazilian rate, even allowing for geographical variation, strongly suggests that an indirect screening took place (possibly due to the attendant access and other costs). Nevertheless, in our framework, the Brazilian system would obtain a bandwidth savings of 81.65% (see Fig. 10), amounting to about 8.25% of additional savings over downsampling alone, which is still significant.

@&#DISCUSSION@&#

In this paper, we proposed a two-tier framework enabling reliable resource-constrained telecardiology. Stringent power and bandwidth constraints are met by compressive detection of anomaly at intermediate subcenters (located at mobile base stations), and communication of only anomalous signals to the diagnostic center. The proposed scheme would considerably reduce rural healthcare cost, movement of individuals (both subjects and health workers) and infrastructure-related investment. In other words, the proposed system delivers the desired benefits of classical telecardiology even with limited resources. Conveniently, the experiences of subjects and experts should remain essentially unaltered. A subject still gathers the ECG using the same transducers, and an expert visualizes that signal at the diagnostic center at essentially the same quality (
                        
                           
                              R
                           
                           
                              2
                           
                        
                        ≥
                        95
                        %
                     ). Of course, a minor difference does arise. ECG signals, which are automatically inferred as normal, are no longer conveyed to experts. Hence, there remains no opportunity for experts to correct a mistake in inferring a signal as normal. To limit consequent adverse effects, the proposed classifiers are operated at the high-sensitivity regime (
                        Se
                        ≥
                        99.5
                        %
                     , ensuring no more that 5 patients are missed in 1000).

Further, we make experimental demonstration using annotated PhysioNet databases [45]. In particular, we designed compressive classifiers based on self-similarity and periodicity, properties exhibited by ECG signals [39,42]. Finally, we reported performance of proposed classifiers in terms of ROC, and demonstrated reliable telecardiology at a substantial savings in power and bandwidth. Specifically, we detected anomalous signals, rather than anomalous beats (the latter may occur even in healthy subjects), as indicators of cardiac issues. Further, we maximized specificity subject to high sensitivity. Interestingly, an excellent ECG classifier, where sensitivity (Se) and specificity (Sp) are both maximized, keeping those nearly equal, e.g., 
                        Se
                        =
                        98.5
                        %
                      and 
                        Sp
                        =
                        97.2
                        %
                      
                     [35], could miss many patients (15 in 1000), leading to relatively unreliable telecardiology (
                        Q
                        =
                        1.5
                        %
                     ). In contrast, at a downsampling factor D=5, subject to our high-sensitivity constraint 
                        Se
                        =
                        99.5
                        %
                     , we achieve a specificity of only 
                        Sp
                        =
                        19
                        %
                     , while assuring that no more than five patients in a thousand are missed. However our low specificity is compensated by high downsampling factor D. Hence our system remains competitive in terms of bandwidth in view of (1). In particular, we calculate that, as opposed to a cost of US$ 0.7 for traditional telecardiology, one incurs only US$ 0.12 in the proposed framework.

At this point, note that our framework differs from that of accuracy-versus-computation tradeoff for remote monitoring [60]. Specifically, we (i) desire high sensitivity rather than high overall accuracy, as the diagnostic center corrects wrongly classified normal signal; and (ii) need not limit complexity at the resource-rich local subcenter. Above all, our method has the unique ability of operating on compressive samples, thus adapting to resource constraints. Interestingly, under severe constraints (e.g., at downsampling factor of five) random downsampling from uniform bins has been found to perform better than uniform downsampling.

In view of the demonstrated efficacy of the proposed system, we plan its practical deployment in the future. To this end, further research on certain issues is warranted. Firstly, our focus has so far been on demonstrating the tradeoff among reliability, power and bandwidth, and we make such demonstration using only one-lead ECG signal. In contrast, professional diagnosis requires 12 or more leads [61]. Thus, to attain the professional grade, our principles need to be applied to the 12-lead device. Since the various leads are known to be highly correlated, high reliability should be achievable at even higher effective downsampling factors. Secondly, to improve portability, 3-lead (generally, reduced-lead) ECG systems have been suggested such that the desired 12-lead signals can be faithfully reconstructed from the observed 3-lead signals [57]. In view of this, it would be worthwhile to develop portable devices that are reliable under resource constraints, by compressively sampling the aforementioned 3-lead signals. Thirdly, a comprehensive cost-benefit analysis of the proposed telecardiology system needs to be undertaken. We expect overhead costs to be minimal. Specifically, the widely unfilled rural physician positions could now be filled with telecardiology consultants at urban diagnostic centers without additional budgetary allocation. In addition, since we plan to use existing mobile networks, only minimal infrastructural investment should be necessary. Finally, practical aspects of the desired system, including privacy and information security, and effect of network congestion and packet loss, need to be studied, and taken into account.

Towards practical deployment and large-scale adoption, one needs to also develop appropriate quality models and standards. As alluded earlier, professional evaluations are generally made based on 12-lead ECG signals, which are sampled at a rate of 500Hz or greater [55,61], and such a system can ideally be taken as the standard. In other words, while evaluating a cardiology-related system (including ours), one would seek a clinical outcome that is statistically indistinguishable from the outcome based on the standard system. This point of view has been adopted in the aforementioned work, proposing reduction in number of leads [57], where a close approximation is reported. However, such a stringent criterion could be hard to meet under resource constraints. Also, given the dire medical infrastructure generally found in rural areas, expectation levels of various stakeholders could also be less stringent. Various quality of service models, including the one proposed by Kastania et al. [21], take such expectations into account. Thus, towards developing a gold standard for resource-constraint telecardiology, the expectation levels of patients, physicians and other stakeholders need to be estimated through scientifically reliable surveys and trials. Such an endeavor is generally intensive and needs time as well as participation of a multitude of individuals from diverse backgrounds. However, one should take heart from the fact that desired standards and guidelines have successfully evolved in related contexts [62,63].

None declared.

@&#ACKNOWLEDGMENTS@&#

Authors are thankful to Ashutosh Richhariya (L.V. Prasad Eye Institute, Hyderabad) for helpful discussions. This work was supported by the Department of Electronics and Information Technology (DeitY), Govt. of India, under the Cyber Physical Systems Innovation Project: 13(6)/2010-CC&BT.

@&#REFERENCES@&#


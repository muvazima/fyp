@&#MAIN-TITLE@&#Cost-sensitive decision tree ensembles for effective imbalanced classification 

@&#HIGHLIGHTS@&#

@&#KEYPHRASES@&#

Machine learning

Multiple classifier system

Ensemble classifier

Imbalanced classification

Cost-sensitive classification

Decision tree

Classifier selection

Evolutionary algorithms

Classifier fusion

@&#ABSTRACT@&#


               Abstract
               
                  Real-life datasets are often imbalanced, that is, there are significantly more training samples available for some classes than for others, and consequently the conventional aim of reducing overall classification accuracy is not appropriate when dealing with such problems. Various approaches have been introduced in the literature to deal with imbalanced datasets, and are typically based on oversampling, undersampling or cost-sensitive classification. In this paper, we introduce an effective ensemble of cost-sensitive decision trees for imbalanced classification. Base classifiers are constructed according to a given cost matrix, but are trained on random feature subspaces to ensure sufficient diversity of the ensemble members. We employ an evolutionary algorithm for simultaneous classifier selection and assignment of committee member weights for the fusion process. Our proposed algorithm is evaluated on a variety of benchmark datasets, and is confirmed to lead to improved recognition of the minority class, to be capable of outperforming other state-of-the-art algorithms, and hence to represent a useful and effective approach for dealing with imbalanced datasets.
               
            


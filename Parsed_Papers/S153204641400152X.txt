@&#MAIN-TITLE@&#Size matters: How population size influences genotype–phenotype association studies in anonymized data

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Anonymization of large-scale clinical codes allows for reliable genome–phenome analysis.


                        
                        
                           
                           Across various repository sizes full EMR most reliable.


                        
                        
                           
                           Preserves utility for finding genome–phenome associations.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Privacy

Anonymization

Clinical codes

Data publishing

@&#ABSTRACT@&#


               
               
                  Objective
                  Electronic medical records (EMRs) data is increasingly incorporated into genome–phenome association studies. Investigators hope to share data, but there are concerns it may be “re-identified” through the exploitation of various features, such as combinations of standardized clinical codes. Formal anonymization algorithms (e.g., k-anonymization) can prevent such violations, but prior studies suggest that the size of the population available for anonymization may influence the utility of the resulting data. We systematically investigate this issue using a large-scale biorepository and EMR system through which we evaluate the ability of researchers to learn from anonymized data for genome–phenome association studies under various conditions.
               
               
                  Methods
                  We use a k-anonymization strategy to simulate a data protection process (on data sets containing clinical codes) for resources of similar size to those found at nine academic medical institutions within the United States. Following the protection process, we replicate an existing genome–phenome association study and compare the discoveries using the protected data and the original data through the correlation (
                        
                           
                              
                                 r
                              
                              
                                 2
                              
                           
                        
                     ) of the p-values of association significance.
               
               
                  Results
                  Our investigation shows that anonymizing an entire dataset with respect to the population from which it is derived yields significantly more utility than small study-specific datasets anonymized unto themselves. When evaluated using the correlation of genome–phenome association strengths on anonymized data versus original data, all nine simulated sites, results from largest-scale anonymizations (population 
                        
                           ∼
                           100
                           ,
                           000
                        
                     ) retained better utility to those on smaller sizes (population 
                        
                           ∼
                           6000
                           –
                           75
                           ,
                           000
                        
                     ). We observed a general trend of increasing 
                        
                           
                              
                                 r
                              
                              
                                 2
                              
                           
                        
                      for larger data set sizes: 
                        
                           
                              
                                 r
                              
                              
                                 2
                              
                           
                           =
                           0.9481
                        
                      for small-sized datasets, 
                        
                           
                              
                                 r
                              
                              
                                 2
                              
                           
                           =
                           0.9493
                        
                      for moderately-sized datasets, 
                        
                           
                              
                                 r
                              
                              
                                 2
                              
                           
                           =
                           0.9934
                        
                      for large-sized datasets.
               
               
                  Conclusions
                  This research implies that regardless of the overall size of an institution’s data, there may be significant benefits to anonymization of the entire EMR, even if the institution is planning on releasing only data about a specific cohort of patients.
               
            

@&#INTRODUCTION@&#

Large-scale genotype–phenotype association studies have rapidly increased in prevalence, due to a combination of massively high-throughput technologies [1], lower cost computing platforms, and systems that make information more widely available (e.g., the Database of Genotypes and Phenotypes (dbGaP) [2]). At the same time, it has been shown that data residing in electronic medical records (EMRs) can enable such studies [3–6] finding, for instance, associations with atrioventricular conduction [7], white [8] and red [9] blood cell traits, hypothyroidism [10], and, more recently, the study of pharmacogenetic traits, including clopidogrel-response [11] and warfarin dose [12]. This is further notable because there are indications that learned associations can enable more effective and safe healthcare [13], with early gains in drug dosing [14].

Given the increased reliance upon EMRs for big data research projects, it is important for institutions to work towards data sharing strategies [15–17]. Beyond adhering to policy requirements [18], data sharing can support a wide range of activities [19], including validation of published findings and discovery of novel associations [20]. Despite the opportunities that biomedical data sharing holds, there are significant concerns over the privacy implications [21,22].

As part of a data protection plan, it is often suggested that biomedical data be disseminated in a manner, such that it is “de-identified” or devoid of explicit identifiers (e.g., personal names) [18,23]. Over the past decade a growing list of investigations have called into question the extent to which de-identification can guard research participants engaged in genomic studies from unsanctioned “re-identification” due to the very act of releasing genomic information itself [24–28]. While we admit that this is an area of concern [29], the likelihood that such attacks will be realized in practice is currently unknown. Thus, in this work, we focus upon linkage risks posed by information that, at the present moment, is more likely to be exploited in re-identification attacks [30].

For years, it has been known that certain common demographics, such as date of birth, gender, and 5-digit ZIP code, could be exploited to discern an individual’s identity [31–34]. And, even when demographics are appropriately protected, it may be possible to exploit other features, such as standardized clinical information. This is a concern because it has been illustrated that the set of insurance billing codes (e.g., International Classification of Diseases (ICD)) in a patient’s record are often unique [35]. And, while the abstraction of billing codes (e.g., changing of a code representing that a patient suffered from malignant neoplasm of thyroid gland (code 193) to that of neoplasm (codes 140–249)) can drastically reduce the identifiability of patients within a genome–phenome association studies, it can also have a detrimental impact on the underlying data. Ref. [36] proposed a method of clinical code anonymization that yielded data appropriate for validation of reported findings. However, the attack scenario invoked in that work assumed that an adversary has an almost-complete knowledge of the sample population that is being published (e.g., which individuals in a population were included in the study). While possible, the strength of this attacker may not be reasonable, such that instead, in a scenario where the institution publishing the data has a higher level of (but not complete) trust in the system and recipients of data, we consider a modified attacker with a more limited set of knowledge.

An initial examination of the ability to protect clinical data (in regards to re-identifiability) was provided in [37]. In that work, the effects of protection were examined at three naturally-occurring levels within a large academic healthcare system: (1) all patients in the EMR systems, (2) all patients with specimens in a biorepository (a subset of the EMR), and (3) a cohort of patients whose DNA and EMRs were studied to validate certain genotype–phenotype associations (a subset of the biorepository). In these scenarios, the attacker was an individual with knowledge of a patient’s visit to the healthcare institution, and their goal was to identify the patient within the published data. It was observed that by protecting a study’s cohort with respect to the entire group of patients within the system, the disclosed data could support the discovery of findings with significance that exactly match those of the association observed in the original system.

These findings suggested such a protection method is viable, but the study was limited because it was evaluated in a specific setting. In particular, it was not clear how these findings might translate to other institutions. For instance, at the time of this study, the biobank of the Vanderbilt University Medical Center (VUMC), contained on the order of 110,000 specimens; yet other institutions involved in the Electronic Medical Records and Genomics (eMERGE) network have considerably smaller biorepositories than VUMC which has approximately 110,000 records in its biorepository
                        1
                        These values correspond to the size of the biorepositories at the end of the first phase of the eMERGE network in 2011.
                     
                     
                        1
                      (e.g., Northwestern University has approximately 15,000 records, and the Mayo Clinic has approximately 20,000). Additionally, other repositories aim for a significant larger population, such as UK Biobank, which plans on over 500,000 participants [38].

Thus, in this paper, we examine the issue that other institutions may face when confronted with the prospect of sharing data – namely, that their overall EMR and biorepository may not be the same size or bias (as regards composition of patients in the biorepository versus in the more general hospital population) as was investigated in [37]. For example, two institutions may be developing a biorepository of a similar size. If, however, Institution A targets their development toward a specific phenotype (e.g., congestive heart failure) while Institution B develops a general-use repository, these biobanks will have different biases (e.g., the rate of appearance for ICD codes representative of CHF will be significantly greater in the former) and potentially even different repository sizes.

To perform this investigation, we conduct a large-scale sensitivity analysis between privacy (that is, “Can an individual patient be re-identified from published data?”) and utility (“Is the data usable in various genome–phenome association studies?”). We examine how anonymizing different quantities of electronic medical record data and biorepositories (from small groups of 1000 individuals up to a biorepository of 100,000 individuals and an EMR of over 1,000,000 individuals) affects the results of genome–phenome associations after application of a formal data anonymization algorithm.

The remainder of this paper is structured as follows: in Section 2, we discuss the relevant background to the anonymization approach. In Section 3, we review the anonymization algorithm, describe the experimental process, and detail the measures by which we analyze the algorithm. In Section 4, we highlight the results of the experiments and provide insight into their implications. In Section 5, we provide some intuition into the larger implications of this work and potential future directions of study.

@&#BACKGROUND@&#

The protection of data derived from EMRs for release happens at multiple levels (e.g., federal law, state law, and institutional policies). Within the United States, the Health Insurance Portability and Accountability Act (HIPAA) provides de-identification specifications at the federal level [39]. These guidelines seek to prevent the unique identification of individuals in published data (i.e., identity disclosure). The HIPAA Privacy Rule offers two alternative approaches to achieve de-identification: (1) Safe Harbor and (2) Expert Determination. When using the Safe Harbor policy, all explicit identifiers (e.g., patient names, Social Security numbers, and medical record numbers) are completely removed and quasi-identifiers (or QIDs) are either removed or abstracted to more general concepts. However, residual information contained within Safe Harbor-compliant data may be exploited by the users, provided they have sufficient background knowledge. For example, as alluded to earlier, it has been shown that even a few visits’ worth of ICD-9 codes uniquely identify individuals within an EMR system in [35]. Given such vulnerabilities, it has been suggested that more attention should be paid to the second method for de-identification [40]. In Expert Determination, data is said to be de-identified, when an expert deems that there is “very small” risk that the anticipated recipient of the data could uniquely identify the corresponding individual from which the data was derived. Here, we focus on a method of data protection within the Expert Determination scope.

Regulation does not say precisely what methods should be used to ensure very small risk, but a variety of techniques have been developed to mitigate risk when publishing data [41,42]. A first class corresponds to methods which inject noise into the disclosed records. One increasingly popular method along these lines is differential privacy [43]. This class of solutions focuses on the addition of a “small” amount of noise into a data set, within strict statistically-proven bounds. While differential privacy is a popular topic, the randomization has, in practice, made investigators hesitant to adopt it for wide-spread usage, particularly when the data is of high-dimensionality [44,45]. Moreover, differential privacy requires that the difference in relevant statistics be calculated prior to release of data, so that the released data is guaranteed to have results that are “close” to the original. With data sharing, however, all secondary studies may not be known at the time of study, which makes this technique difficult to apply in practice at this time.

With specific regards to differentially-private association studies, [46] has indicated that it may be possible to obtain reliable association results through differentially-private genomics (e.g., a genome-wide association study (GWAS) using single nucleotide polymorphisms (SNPs) which have been protected according to the definition of differential privacy [47]) in some situations. However, there are still several problems with this method of protection, including that a limited number of results may be returned. There is also a low-likelihood possibility that the returned results will be noisy (e.g., they implicate the wrong chromosome or the wrong region of the chromosome).

A second class, upon which our protection method is based, corresponds to k-type techniques. The most studied version of this technique is k-anonymization [48], which has been applied to the medical domain specifically [49]. k-anonymization requires equivalence classes – that is, groups of records which share the same values over a set of attributes (e.g., 5-digit ZIP codes and birth dates) – to have at least k members. To ensure that the principle of k-anonymity is met, many transformation strategies have been introduced [50] The most popular data transformation strategy to achieve k-anonymity involves the use of generalization and suppression. k-anonymization is, itself, known to be vulnerable to various methods of attacks [51,52]. These attacks, however, generally involve a separate style of attack model from identity disclosure called attribute disclosure. That is, even if a dataset is k-anonymous, information about those attributes could leak and thus violate those privacy guarantees. While this may be a matter of general concern and research, current regulation only addresses the issue of identifiability.

There have also been several investigations in the area of set-valued anonymization. Traditionally an attribute could consist of only one value – such as one’s birth date. Yet quasi-identifiers can consist of attributes which have variable-length fields, such as the set of diagnosis codes resulting from a hospital visit. Ref. [53] discusses the nature of the problem, as well as provides an optimal solution (under restricted conditions) which is inefficient in its run-time, as well as several greedy solutions to approximate the optimal. This work, however, does not include the concept of separate “visits” as a means to protection as we utilize in our threat models, and thus is an incomplete solution for this domain. Ref. [54] extended this work to adopt a heuristic to search for a reasonable approach for anonymization of set-valued data. Their approach, however, can result in a reduction in specificity of clinical codes which could hinder genome–phenome analysis.

These anonymization approaches operate under the assumption that the specific records to be published will be extracted and then anonymized. However, medical institutions have an additional option. If they want to release the data on a cohort of patients, say from a drug trial or a genome–phenome association, they can protect that cohort against a larger population of individuals who visited the hospital and from which the cohort was selected (e.g., hospital population or biorepository). Notice that when the smaller set, in this example the cohort, is extracted, we no longer guarantee that k records will be equivalent in the published data. Rather, we now refer the protection back to the larger population using a model called k-map [48]. In this scenario, while a data recipient looking at the released data may identify a unique individual within that release, there are at least 
                           
                              k
                              -
                              1
                           
                         identical people within the broader population, and the recipient does not know exactly which one we chose from the population to reveal.

The specific method of anonymization for clinical codes was described in detail in [37], to which we refer the reader for details of the process. Here, our goal is to further understand what this k-map anonymization can offer in terms of protection and data usability to other institutions who release data.

@&#METHODS@&#


                     Fig. 1
                      shows an example of the general changes that structured data in an EMR can undergo prior to release. At the left of the figure, we show the initial data set with a medical record number (MRN), patient name, date of admission, and resulting diagnosis. In the middle of the figure, the data has been de-identified according to an arbitrary policy. We assume that this process is performed independently from the anonymization, and the input data set for our algorithm is similar to what is shown here, because we note that even if data is de-identified according to demographics, there is still the possibility that a patient can be re-identified through their clinical codes [35]. The anonymization process results in a table similar to what is shown at the right of Fig. 1. Note that this is an example of a 2-anonymous solution, and uses the process described in [37].

Generally, the anonymization algorithm uses a single-visit security model. In this model, it is assumed that an attacker has full knowledge of a single patient visit (including the related ICD-9 billing codes). This means that we aim to prevent the attacker from gaining any further knowledge about the patient, such as other diagnosis codes or the genomic data associated with the entire set of diagnosis codes. This is accomplished through a process of generalizing codes which have a frequency below k times within the data set to obtain a more general code that has enough support to merit safe release.

This generalization means that some specificity in diagnosis codes will be lost. The extent to which this happens is controlled by expert knowledge. Here, expert knowledge is represented as a hierarchy, which is used to guide the anonymization by specifically allowing groups of codes to be generalized together. Through this restriction, we can prohibit codes such as 733.0 (osteoporosis) and 296.2 (Major depression, single episode) from being generalized together.

We use the anonymization process to enforce the following requirements: (1) for any visit, as defined by a group of ICD-9 codes generated by some event, at least 
                        
                           k
                           -
                           1
                        
                      other records must have all of these codes across any number of visits; (2) codes which do not have sufficient support to be released (e.g., occur in 
                        
                           ⩽
                           k
                        
                      records) can be generalized with another code that also has insufficient support to be released; (3) codes which still do not have sufficient frequency to be released and have no remaining codes with which to be generalized must be suppressed (that is, removed from the dataset).

An example of the generalization process can be seen in the third section of Fig. 1. Notice that codes 511.15 and 544.32 have been generalized to the code 
                        
                           〈
                        
                     511.15,544.32
                        
                           〉
                        
                      (which corresponds to 511.15 and/or 544.32). Also note that code 105.33 occurs only once in the data, and has no codes with which to generalize, and is thus suppressed.

To validate the data obtained from the anonymization, we use the phenome-wide association study (PheWAS) method in [55]. In a PheWAS, a statistical analysis is performed across a group of phenotypes – perhaps represented by ICD-9 billing codes [4] – in order to find potentially linked genetic associations with a specific region of the genome, such as a specific single nucleotide polymorphism (SNP).

To show the potential of our anonymization, we use the VUMC Synthetic Derivative (SD) [5] as an exemplar. The SD is a de-identified version of the Vanderbilt EMR which is restricted to Vanderbilt employees’ use for research purposes. The data set, at the time of experimentation, included 1,366,786 unique patient IDs. Of these records, biospecimens were also available for 104,904 patients. This set is referred to as BioVU. Of the records in BioVU, 5994 comprise a cohort used to demonstrate known genome–phenome associations [55]. For reference, this set is referred to as Demo.

@&#EXPERIMENTAL DESIGN@&#

We assume that an institution needs to release the data used in a PheWAS. This institution has the following data sets: (1) Demo (D): the cohort which is going to be released. (2) BioRepo (B): the institution’s biorepository. Since the underlying study is a genome–phenome association, it follows that 
                           
                              D
                              ⊂
                              B
                           
                        . Furthermore, 
                           
                              
                                 
                                    B
                                 
                                 
                                    ′
                                 
                              
                              =
                              B
                              ⧹
                              D
                           
                        . 
                           2
                           This notation refers to set exclusion, and means 
                                 
                                    
                                       
                                          B
                                       
                                       
                                          ′
                                       
                                    
                                 
                               is the biorepository (B) excluding all members of D.
                        
                        
                           2
                         Finally, (3) the institution’s full EMR (E). In this case, 
                           
                              B
                              ⊂
                              E
                           
                         and it further follows that 
                           
                              
                                 
                                    E
                                 
                                 
                                    ′
                                 
                              
                              =
                              E
                              ⧹
                              B
                           
                        . Note that this automatically excludes members of D from 
                           
                              
                                 
                                    E
                                 
                                 
                                    ′
                                 
                              
                           
                        .

To simulate data of a given size and the results of the anonymization process, we randomly select records from the corresponding VUMC dataset to build E at various sizes. These randomly selected records comprise our simulated data for each institution. For instance, to model an institution with a biorepository of 500 patients and an EMR of 5000 patients, we would select 500 records from BioVU and an additional 5000 from the SD. These sizes will represent the growth of the EMR as an institution increases its size and thus, the protective ability of its data. We make the observation that in a k-type protection model, the fidelity of the resulting dataset, as represented by the total number of generalizations required to release it, is linked with the frequency with which each code appears within the original dataset.

The general process of this selection is shown in Fig. 2
                        . But, in general, suppose that 
                           
                              |
                              E
                              |
                              =
                              15
                              ,
                              000
                           
                         records. D is required to be a subset of this data set, and in this case 
                           
                              |
                              
                                 
                                    B
                                 
                                 
                                    ′
                                 
                              
                              ∪
                              
                                 
                                    E
                                 
                                 
                                    ′
                                 
                              
                              |
                              =
                              9006
                           
                         records. Now, suppose that the institution’s biorepository has an additional 1000 records (i.e., 
                           
                              |
                              
                                 
                                    B
                                 
                                 
                                    ′
                                 
                              
                              |
                              =
                              1000
                           
                        ) and their EMR has the remainder (i.e., 
                           
                              |
                              
                                 
                                    E
                                 
                                 
                                    ′
                                 
                              
                              |
                              =
                              8006
                           
                        ). To model this scenario, we begin with D and add 1000 randomly selected records from BioVU. Next, we add 8006 randomly selected records from the SD, which comprise the entirety of E. Note that we specifically prevent overlap in record selection. Without this exclusion, a random selection could choose a record within D during selection for B or E, such that we have fewer records in the resulting anonymization than intended.

As mentioned previously, we assume that E has been de-identified, and the ICD-9 codes are anonymized with 
                           
                              k
                              =
                              5
                           
                        . Now, we select the records in D, which have also been anonymized.

Following this selection, we replicate the PheWAS [55] with the goal of measuring how much the anonymization process has changed the p-values associated with each SNP-phenotype pair. It is worth noting here that the described PheWAS is a validation of six genome–phenome association studies, and has results for six specific, independent SNPs: (1) rs1333049, (2) rs2200733, (3) rs2476601, (4) rs3135388, (5) rs6457620, and (6) rs17234657. We then compare the results to the expected, original version of D – that is, the results as initially reported.

To orient the reader, in Fig. 3
                        , we show a QQ-plot indicating the change in p-values for anonymization, based on results in [37]. The x-axis corresponds to the original, non-anonymized p-value for SNPs. The y-axis corresponds to the p-value subsequent to anonymization of only the Demo cohort. The basis line indicates how far from the expected value a specific SNP’s association was determined to be.

Since we are focused on how the anonymization method affects resulting analyses, we report the summarized values for this change (interested readers can find the values in the original report at [55]). The large number of these datasets, makes it infeasible to show all relevant graphs or data (e.g., individual p-values) within this manuscript. Instead, we report the information within these graphs as the 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         of the correlation between the anonymized and non-anonymized versions of the data. In this case, an 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         of 1 indicates a perfect match between the two data sets; i.e., when all p-values were exactly equal. An 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         of 0 indicates that there was no correlation between the two sets, and reliable results would not be obtained. The 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         for Fig. 3 is 0.90.

Additionally, for each result, we show the slope of the remaining points for the division (the specific point at which we change from patients from a biorepository to those from the general EMR). For example, if a data set has 50,000 records from BioVU, we show the 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         for the 50,000 point, but also show what happened when building up to that 50,000 (i.e., 1000 then 2000 and so forth) and what happens if the group of 50,000 is supplemented with additional EMR records (i.e., 50,000, then 70,000 and so forth). We provide an indication of the trend of these results by showing the slope of the regression line for these segments. Here, 
                           
                              
                                 
                                    m
                                 
                                 
                                    L
                                 
                              
                           
                         represents the slope of the former (i.e., sets of less than 50,000 records from BioVU) while 
                           
                              
                                 
                                    m
                                 
                                 
                                    R
                                 
                              
                           
                         represents the slope of the latter (i.e., supplementing the 50,000 records from BioVU with additional SD records).

We highlight datasets that represent the known sizes of those managed by members of the eMERGE network, as described in [3]. We have reprinted the site identifier and biobank size in Table 1
                         for these institutions. We show the 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                         for each of these sets, as well as those with additional EMR data, by using the biorepository size as a split point. In the left of the relevant graphs, all records are from BioVU (without the records in Demo); on the right, all records are from the SD (without the records in BioVU).

For our experiments, we assume that the biobank size represents the number of additional samples against which a publishable sample can be protected. For instance, Boston Children’s Hospital will have a total of approximately 9000 specimens in our example; 6000 from the Demonstration group and the additional 3000. Further, for notational purposes, we assign each site an experiment ID which we use to refer to the randomly-generated set which corresponds to a dataset of the related size. Due to the similar size of their datasets, Geisinger and Mayo are represented by the same dataset, referred to as 
                           
                              G
                              /
                              M
                           
                        .

Additionally, 
                           
                              CH
                              ≀
                              P
                           
                         reports two separately-obtained biorepositories: Internal and External. Their Internal biorepository refers to those biospecimens they have obtained directly, while their External biorepository refers to those obtained through collaborations with other institutions [3].

@&#EXPERIMENTS AND RESULTS@&#

In this section, we begin by discussing the results found within one specific SNP (rs1333049) for each of the simulated sites. Following that, we present some general comments regarding our findings for the remainder of the SNPs.

We begin by highlighting the results of Fig. 4
                        , where there is no additional biobank against which to protect the participants in the PheWAS. Here, we see that the initial accuracy of the PheWAS (as reported by the 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                           
                        ) is approximately 0.92, and that, while adding additional records from the EMR varies the resulting accuracy, the general bound is [0.89,0.93].


                        Fig. 5
                         shows the results for each of the institutions simulated. First, consider 
                           
                              B
                           
                         (Fig. 5a). Here, we observe that the inclusion of 3.000 records from members of a biobank improved the accuracy by a reasonable margin (0.94 with no additional EMR records). Moreover, the overall bound on the results including additional records from the EMR has also improved to [0.93,0.95].

For the remainder of sites, we present a summary of the findings in Table 2
                        . We see that, in general, accuracy increases as we include more individuals from the biorepository. This increase is shown in both the accuracy with no additional people and when we add additional individuals from the EMR. The results of 
                           
                              CH
                              ≀
                              P
                           
                         mirror what was shown in [37]. That is, the biorepository contains some bias which, when considered fully, decreases accuracy slightly. We know, however, from that work that including the entire EMR would compensate for this slight decline.

To show how the demonstration SNP relates to the remaining SNPs, we present results for the latter in Table 3
                        . In general, we see the same trend as was observed in the earlier example SNP. 
                           
                              B
                           
                         has an initial medium–high accuracy (
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                              =
                              0.9621
                           
                        ), but we see a decrease in accuracy with the next size set (
                           
                              G
                           
                        , 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                              =
                              0.9349
                           
                        ). After this, though, we generally see an increase in accuracy, all the way up to the 
                           
                              CH
                              ≀
                              P
                           
                         External data, (comparable in size to BioVU, 
                           
                              
                                 
                                    r
                                 
                                 
                                    2
                                 
                              
                              =
                              0.9967
                           
                        ).

We observe that one dataset has a significant negative 
                           
                              
                                 
                                    m
                                 
                                 
                                    R
                                 
                              
                           
                        , 
                           
                              C
                           
                         for rs17234657. This implies that the records chosen for larger datasets (which represents growth of the EMR without further growth in the biorepository) have an extremely negative impact on the post-anonymization accuracy. However, since this is by far the worst result (all other 
                           
                              
                                 
                                    m
                                 
                                 
                                    L
                                 
                              
                           
                         and 
                           
                              
                                 
                                    m
                                 
                                 
                                    R
                                 
                              
                           
                         for all SNP 
                           
                              >
                              -
                              0.0015
                           
                        ) we believe that this is an artifact of the randomized selection process.

@&#DISCUSSION AND CONCLUSIONS@&#

There are several important messages that have been shown in these results that should be highlighted. First, the accuracy of association significance does not necessarily increase through the addition of biorepository patients for the privacy protection of individuals involved in a study. This is because there are many factors which may potentially affect this overall quality. The main issue is that of an inherent selection bias within the biorepository, which could present in several ways. For example, only individuals with the same diagnosis code may have been recruited for the biobank. Alternatively, a biobank can bias selection of included patients towards those who visit an affiliated institution more frequently. Even a completely random selection can introduce biases of its own into the resulting data (e.g., rare codes are going to be less represented in the biobank). While avoiding these biases may prove difficult, it is important to investigate the impact they have upon the protection of data within the system in order to determine whether a particular method is well-suited for protection.

Second, the results further suggest that randomly selecting records for protection from the overall EMR (even a fairly substantial number when compared to the data to be released) is not sufficient to produce anonymized data with high utility. Instead, we reaffirm the conclusion offered in [37]. An institution can both release rich, useful data and protect the released records against the entirety of their dataset by performing a full-scale anonymization and releasing the needed, specific records. This, in general, provides better results than by trying to determine a “sufficient” number of records against which to protect the sample set.

Each simulated data set corresponded to a single randomized selection from our EMR. This may add noise to the results at different data points, which could be resolved with repeated randomization. However, we note that since each dataset was randomized independently, the trend observed across the points in the scalability plots is expected to correspond to the mean result.

Our work suggests that institutions should use the data on patients in their biobank (or the entire EMR population) to protect the privacy of those involved in a specific study. However, future work should test this method on additional datasets and report on the usability of subsequent data. Given that this genome–phenome associations frequently take the form of a pooled or meta-analysis, there may even be issues with data protection when the cohort is assembled across multiple, disjoint sites.

A second future direction is to consider the impact of time on anonymized releases. For example, if a particular patient is included in multiple study cohorts, it may be possible to track the patient through composition attacks across institutions that violate the principles of a k-type protection [56–58]. Despite such limitations, the presented results provide strong evidence that anonymization of EMR data can be accomplished with minimal impact on association studies and that such approaches benefit when large populations can be drawn upon for protection.

@&#ACKNOWLEDGMENTS@&#

This research was sponsored, in part, by Grants U01HG006385 and U01HG006378 from the National Human Genome Research Institute and Grants R01LM009989 and R01LM010685 from the National Library of Medicine. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#
               Lossy hyperspectral image compression based on intra-band prediction and inter-band fractal encoding
            

@&#HIGHLIGHTS@&#


               Hightlights
               
                  
                     
                        
                           
                           A lossy hyperspectral image compression scheme based on intra-band prediction and inter-band fractal is proposed.


                        
                        
                           
                           Intra-band prediction exploiting spatial correlation is applied to I-bands.


                        
                        
                           
                           Inter-band fractal encoding with a local search algorithm is applied to P-bands.


                        
                        
                           
                           SVM classification accuracy for the reconstructed image is slightly higher than that for the original one.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Hyperspectral image

Lossy compression

Fractal encoding

Prediction

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Hyperspectral image is a three-dimensional data cube, which has one dimensionality in spectrum and two dimensionalities in space. Generally, hyperspectral image contains hundreds of bands, resulting in an extreme huge data volume, which is not convenient for transmission, analysis and storage. Therefore, to find a highly efficient compression method for hyperspectral image has become an urgent issue. On the other hand, the coding complexity is also an important factor when designing the encoder. Hyperspectral image compression methods are classified as lossly compression and lossless compression. Lossless compression [1] methods can preserve the whole information of the original hyperspectral image but the compression ratio (CR) is very low, usually below 3:1, which cannot satisfy many practical applications. Actually, we do not need the whole information in some studies so that lossy compression methods with high CR and acceptable information loss have practical significance. What is more, it indicates that a higher CR might cause positive impact on the classification results for specific compression techniques [2,3].

Fractal encoding is a relatively novel idea for lossy image compression by utilizing the local self-similarity. It has advantages such as high CR, resolution independence and fast decoding. Therefore, it is considered as a promising compression method. The basic theory is to use a contractive transformation instead of the original image, and the fixed point of the transformation is close to the image. As the introduction of partitioned iterated function system (PIFS) by Jacquin, in which every mapping operates on a subset of the image rather than the entire image, fractal image compression became a practical reality, and the standard algorithm for fractal block coding is formed [4]. The image is firstly segmented into non-overlapping range blocks and overlapping domain blocks, the sizes of which are larger than the range blocks. The encoding of each range block consists of searching for the best affine mapping in the domain block pool. Thus the combined mappings make up a transformation on the image as a whole [5]. Such a system for the encoding of monochrome digital images without any entropy coding of the parameters of the fractal code can achieve a bit rate below 1bit/pixel, demonstrating that fractal encoding has a very high compression ratio. But the drawback exists in that the block matching procedure is very time-consuming. Therefore, many efforts in reducing the matching complexity have been done to speed it up. Among them, an effective approach is to do less searching by excluding many of the domain blocks because many of them are never used [6,7]. Some hybrid approaches to enhance fractal image rate-distortion performance are also introduced by combining it with predictive coding, transform coding or vector quantization [8–10].

Our objective is to design a lossy compression scheme for hyperspectral image with improved compression efficiency and low complexity. In a hyperspectral image cube, the pixel values of each band are the reflectance values of ground objects located in the same region for each band. As different bands contain the same ground targets, they have the same spatial topological structure. Therefore, adjacent bands are usually highly similar. We guess that extending the original fractal coding method in a two-dimensional digital image to different bands of hyperspectral image might produce high compression efficiency. And to our best knowledge, there are nearly no publications for hyperspectral image compression based on the fractal theory. We put forward an applicable lossy hyperspectral image compression scheme based on hybrid intra-band prediction and inter-band fractal encoding. Firstly, the hyperspectral image is partitioned into several groups of bands (GOBs), and intra-band prediction or inter-band fractal encoding is chosen for different bands. Nextly, the fractal parameters are signed Exp-Golomb entropy encoded. Finally, error compensation mechanism is used, i.e. the prediction error and fractal residual are transformed, quantized, reordered and entropy encoded. Experimental results suggest that the proposed scheme obtains higher compression efficiency compared with the existing well-known lossy compression methods and higher classification accuracy for the reconstructed image than the original uncompressed image.

This paper is structured as follows. Section 2 is an overview of the related work. The proposed lossy compression scheme for hyperspectral image is introduced in Section 3. Experimental results are shown in Section 4. Section 5 concludes the paper and presents the future work.

@&#RELATED WORK@&#

Hyperspectral image compression has attracted much attention. Several well-known or latest hyperspectral image compression methods are presented in this section before introducing our proposed compression scheme.

JPEG 2000 [11] and its extensions [12] have been used widely for lossy hyperspectral image compression. Qian Du et al. [13] applied principal component analysis to JPEG 2000 in order to reduce spectral dimensionality and spectral correlation. In [14] and [15], a low-complexity Karhunen–Loève transform (KLT) is proposed, and then it is integrated into the framework of JPEG 2000. They have a few drawbacks in spite of the superior decorrelation capabilities. For example, the coding overhead is heavy, and the computational process of transform matrix is very complex.

Three-dimensional Set Partitioning in Hierarchical Trees (3DSPIHT) algorithm and three-dimensional Set Partitioned Embedded block (3DSPECK) algorithm have been introduced in [16], and it shows that 3DSPECK has a little higher compression efficiency than 3DSPIHT. The 3DSPIHT and the 3DSPECK are both straightforward extensions using a conventional symmetric three-dimensional discrete wavelet transform (3D DWT). However, the symmetric tree is not the best for hyperspectral image compression for the reason that the hyperspectral image are asymmetric along the spatial-horizontal, spatial-vertical and spectral directions. So that some asymmetric three-dimensional wavelet transform based methods are proposed for hyperspectral image compression. Asymmetric three based 3DSPIHT (AT-3DSPIHT) and asymmetric transform 3DSPECK (AT-3DSPECK) algorithms were presented in [17] and [18], respectively, which obtain better compression performances than the corresponding symmetric ones.

A solution to decrease the complexity of hyperspectral image encoder is to employ distributed source coding principle which can shift the complexity from encoder to decoder. In [19], SW-SPIHT (set partitioning in hierarchical tree with Slepian–Wolf coding) based on DSC is proposed. Another DSC-based scheme with a low-complexity discrete cosine transform instead of wavelet transform is put forward in [20].

Recently, the state-of-the-art video coding standard H.264/AVC [21] which achieves a significant improvement in rate-distortion performance relative to previously existing standards is also applied for hyperspectral image compression. In [22], a performance evaluation of the H.264/AVC when applied to hyperspectral image compression is carried out, showing that this video coding standard is suitable for compressing hyperspectral images. In [23], it saves 80% encoding time compared to H.264/AVC with all the prediction modes, by using the fast reference band selection algorithm.

We put forward a new encoding architecture for lossy hyperspectral image compression based on intra-band prediction and inter-band fractal encoding as illustrated in Fig. 1
                     . In the first step, the hyperspectral image bands are partitioned into GOBs and each band is divided into non-overlapping range blocks of size 16×16. In a GOB, the first band is called “I-band” and the others are called “P-band”. In the second step, we choose either intra-band prediction or inter-band fractal encoding for the current range block according to whether the current range block is located in “I-band” or “P-band”. In the third step, the fractal parameters are signed Exp-Golomb entropy encoded. The last step is the error compensation procedure, i.e. the prediction error of “I-band” and the fractal residual of “P-band” are DCT transformed, quantized, reordered and CAVLC (Context Adaptive Variable Length Coding) entropy encoded. The details are presented below.

We define two types of bands, which are “I-band” and “P-band”. I-band is used for intra-band prediction, in which each pixel is predicted from the spatially neighboring decoded pixels in the same band. P-band is employed for inter-band fractal encoding, that is to say, each range block will search for its best matching domain block in the corresponding reference I-band or P-band, which has been decoded. And we only use the nearest past band to encode the current P-band, as shown in Fig. 2
                        . The I-band and its following P-bands before the next I-band form a GOB, and the size of GOB is determined at the encoding end. The reason for the design is that we can exploit spatial correlation by intra-band prediction and spectral correlation between adjacent bands by inter-band fractal encoding.

For each range block in I-band, we use its spatially neighboring encoded and reconstructed samples to predict it. Since hyperspectral images are generally texture abundant, the predictive error would be large by only one constant direction intra-band prediction. A better solution is to apply multi-direction prediction to improve compression efficiency. So we use for reference from multi-direction intra prediction of H.264/AVC. In H.264/AVC, the basic unit for prediction is 16×16 macroblock, and a macroblock can also be partitioned into 16 subblocks with the equal size of 4×4. There are four types of prediction modes for a 16×16 macroblock, and nine types of prediction modes for a 4×4 subblock. In H.264/AVC, all possible intra prediction modes are traversed for every block, and the best mode is selected by rate distortion optimization (RDO).

Considering that hyperspectral images contain more details, the 16×16 intra-band prediction would bring about larger prediction error than the 4×4 intra-band prediction. And we observed that the spatial correlation of two pixels at the 16 pixels distance decreased rapidly compared with that at a 4 pixels distance, as shown in Fig. 3
                        . Our scheme only uses the 4×4 prediction modes for intra-band prediction, which avoids using the low correlated pixels. Accordingly, only nine types of RDO costs in Fig. 4
                         are needed to calculate for one block. More details about RDO can be found in [21].

Fractal image coding is based on local self-similarity. That is to say, a partitioned range block has to search in the domain pool located in the same image for its best matching block. As shown in Fig. 5
                        (b), the range block R marked with yellow edge has to exhaustively search all the domain blocks with their extensions by eight isometric transformations, which is very time consuming.

In our scheme, we make the best of the spectral correlation and the fact that the two blocks located in the same position of two adjacent bands are highly similar. For example, Fig. 5 shows two adjacent bands of AVIRIS hyperspectral image Cuprite with band number 28 and 29 respectively. We can see that the R block in band 29 and the collocated R block in band 28 are almost the same. Consequently, we search in the former band instead of the same band. Besides, we design a local search algorithm getting rid of the isometric transformation operations and the exhaustive search. In our local search scheme, the current range block just needs to search in a local region in the past adjacent decoded band instead of a global region in the same band. As shown in Fig. 5(a), the D block centering on the collocated R block is called collocated D block. Our search region is centering on the collocated D block with ∆ shift in four directions and the domain pool is not extended by isometric transformations. Experiment proves that when ∆ equals to 3 pixels, the matching error can be small enough.

In our scheme, we adopt tree structure partition instead of quadtree partition, reducing the quantity of blocks [24]. The threshold γ to determine whether partition or not is context adaptive and it is calculated as follows:

                           
                              (1)
                              
                                 
                                    
                                       γ
                                       
                                          r
                                          o
                                          w
                                          ×
                                          v
                                          o
                                          l
                                       
                                    
                                    =
                                    t
                                    o
                                    
                                       l
                                       
                                          r
                                          o
                                          w
                                       
                                    
                                    ×
                                    t
                                    o
                                    
                                       l
                                       
                                          v
                                          o
                                          l
                                       
                                    
                                    ×
                                    N
                                 
                              
                           
                        Where, row, vol, and N represent the number of pixels in a row of the block, in a volume of the block, and in the entire block, respectively.

The detailed inter-band fractal encoding process with local search algorithm for a current P-band is summarized as follows:

                           
                              1)
                              Divide the current P-band into non-overlapping R blocks of size 16×16.

Code each R block.

For each R block, we search for its matching D block in the corresponding local region centering on the collocated D block with ∆ shift in four directions in the former adjacent decoded band with minimum mean square error (MSE).

                           
                              (2)
                              
                                 
                                    
                                       
                                          
                                             M
                                             S
                                             E
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                1
                                                N
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                
                                                   
                                                      [
                                                      
                                                         r
                                                         
                                                            
                                                            i
                                                         
                                                         −
                                                         
                                                            (
                                                            s
                                                            ·
                                                            
                                                               d
                                                               i
                                                            
                                                            +
                                                            o
                                                            )
                                                         
                                                      
                                                      ]
                                                   
                                                
                                                2
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                1
                                                N
                                             
                                             
                                                [
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   N
                                                
                                                
                                                   r
                                                   i
                                                   2
                                                
                                                +
                                                s
                                                
                                                   (
                                                   s
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      d
                                                      i
                                                      2
                                                   
                                                   −
                                                   2
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      
                                                         r
                                                         i
                                                      
                                                      
                                                         d
                                                         i
                                                      
                                                   
                                                   +
                                                   2
                                                   o
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      d
                                                      i
                                                      2
                                                   
                                                   )
                                                
                                                +
                                                o
                                                
                                                   (
                                                   N
                                                   ·
                                                   o
                                                   −
                                                   2
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      r
                                                      i
                                                      2
                                                   
                                                   )
                                                
                                                ]
                                             
                                          
                                       
                                    
                                 
                              
                           
                        Where 
                           
                              r
                              
                                 
                                 i
                              
                              
                                 (
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 .
                                 .
                                 .
                                 N
                                 )
                              
                           
                         and 
                           
                              d
                              
                                 
                                 i
                              
                              
                                 (
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 ,
                                 .
                                 .
                                 .
                                 N
                                 )
                              
                           
                         represent the pixel value of R block and D block, respectively. N represent the number of pixels in R block. The scaling factor s and offset factor o are determined by

                           
                              (3)
                              
                                 
                                    s
                                    =
                                    
                                       
                                          N
                                          
                                             (
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                N
                                             
                                             
                                                
                                                   r
                                                   i
                                                
                                                
                                                   d
                                                   i
                                                
                                             
                                             )
                                          
                                          −
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             r
                                             i
                                          
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             d
                                             i
                                          
                                       
                                       
                                          N
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             N
                                          
                                          
                                             d
                                             i
                                             2
                                          
                                          −
                                          
                                             
                                                
                                                   (
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      N
                                                   
                                                   
                                                      d
                                                      i
                                                   
                                                   )
                                                
                                             
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    o
                                    =
                                    
                                       1
                                       N
                                    
                                    
                                       (
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          r
                                          i
                                       
                                       −
                                       s
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          N
                                       
                                       
                                          d
                                          i
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

If the minimum MSE is smaller than γ
                        16 × 16 (pre-calculated by formula 4), we can record the fractal parameters and continue to the next R block. Otherwise, we divide the R block into two 16×8 sub-R blocks, and for each sub-R block, we search in the same local region as R block for corresponding D block separately. If both of the minimum MSEs are smaller than γ
                        16 × 8, we can record the fractal parameters and continue to the next R block. Otherwise, we divide the R block into two 8×16 sub-R blocks, and for each sub-R block, we search for corresponding D block separately just like the procedure of 16×8 partition. If both of the minimum MSEs are smaller than γ
                        8 × 16, we can record the fractal parameters and continue to the next R block. Otherwise, we divide the R block into four 8×8 sub-R blocks, and for each sub-R block, we search for corresponding D block separately using the same procedure. If all of the four minimum MSEs are smaller than γ
                        8 × 8, we can record the fractal parameters and continue to the next R block. Otherwise, we can divide the 8×8 sub-R block whose matching error is bigger than γ
                        8 × 8 in a further four ways either as two 4×8 partitions, two 8×4 partitions, or four 4×4 partitions in the same way to find the final fractal parameters.

                           
                              3)
                              Save the following fractal parameters:

                                    
                                       •
                                       The location of the best matching D block;

Scaling factor;

Offset factor.

Continue doing the same for the rest of the R blocks until the last one is encoded.

The fractal parameters comprise the location of D block, scaling factor and offset factor. And they are encoded as follows:

                           
                              1)
                              If the current R block is located in the first P-band after I-band and it is the first block in the P-band as well, then the fractal parameters of the current R block are encoded by signed Exp-Golomb entropy coding.

If the current R block is located in the first P-band after I-band and it is not the first block in the P-band, then the fractal parameters’ differences of the current R block and the spatially prior R block are encoded by signed Exp-Golomb entropy coding.

If the current R block is located in other P-bands, then the fractal parameters’ differences of the current R block and the collocated R block in the past adjacent band are encoded by signed Exp-Golomb entropy coding.

In this way, the fractal parameters can be encoded by fewer bits compared to traditional entropy coding method.

To improve decoded quality of hyperspectral images, we add error compensation procedure. The prediction error of intra-band prediction and fractal residual of inter-band fractal coding are further transformed, quantized, and entropy encoded. Residual R block in I-band can be obtained by subtracting the predicted block from the original one. Residual R block in P-band can be obtained by the following formula:

                           
                              (5)
                              
                                 
                                    R
                                    e
                                    s
                                    i
                                    d
                                    u
                                    a
                                    l
                                    =
                                    ∑
                                    
                                       (
                                       
                                          r
                                          i
                                       
                                       −
                                       
                                          (
                                          s
                                          ·
                                          
                                             d
                                             i
                                          
                                          +
                                          o
                                          )
                                       
                                       )
                                    
                                 
                              
                           
                        
                     

Then each residual R block is transformed and quantized, in which integral DCT is adopted, and quantization is combined with DCT. Hence, in the whole transformation and quantization process, we just need to execute additions, multiplications and bit-shifts. Subsequently, the quantization coefficients are reordered by zig-zag scan, and then the reordered coefficients are entropy encoded by CAVLC.

Let X represent the 4×4 residual matrix, then the integral DCT is as follows:

                           
                              (6)
                              
                                 
                                    Y
                                    =
                                    C
                                    X
                                    
                                       C
                                       T
                                    
                                 
                              
                           
                        where

                           
                              (7)
                              
                                 
                                    C
                                    =
                                    
                                       [
                                       
                                          
                                             
                                                1
                                             
                                             
                                                1
                                             
                                             
                                                1
                                             
                                             
                                                1
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                1
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                             
                                                1
                                             
                                          
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                             
                                                2
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                          
                                       
                                       ]
                                    
                                 
                              
                           
                        
                     

The quantization formula is

                           
                              (8)
                              
                                 
                                    
                                       Z
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          
                                             Y
                                             
                                                i
                                                j
                                             
                                          
                                          ·
                                          Q
                                          
                                             (
                                             Q
                                             P
                                             %
                                             6
                                             ,
                                             i
                                             ,
                                             j
                                             )
                                          
                                          +
                                          
                                             
                                                2
                                                
                                                   15
                                                   +
                                                   
                                                      
                                                         Q
                                                         P
                                                      
                                                      /
                                                      6
                                                   
                                                
                                             
                                             /
                                             3
                                          
                                       
                                       
                                          2
                                          
                                             15
                                             +
                                             
                                                
                                                   Q
                                                   P
                                                
                                                /
                                                6
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

By inverse transformation, inverse quantization of the residual R block, and adding to the intra-band predicted R block or inter-band fractal iterated decoded R block, we can get the final decoded block.

The inverse quantization formula is

                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             Y
                                             
                                                i
                                                j
                                             
                                          
                                       
                                       ′
                                    
                                    =
                                    
                                       Z
                                       
                                          i
                                          j
                                       
                                    
                                    ·
                                    R
                                    
                                       (
                                       Q
                                       P
                                       %
                                       6
                                       ,
                                       i
                                       ,
                                       j
                                       )
                                    
                                    ·
                                    
                                       
                                          Q
                                          P
                                       
                                       /
                                       6
                                    
                                 
                              
                           
                        
                     

The inverse DCT is as follows:

                           
                              (10)
                              
                                 
                                    
                                       X
                                       ′
                                    
                                    =
                                    
                                       C
                                       i
                                    
                                    
                                       Y
                                       ′
                                    
                                    
                                       C
                                       i
                                       T
                                    
                                 
                              
                           
                        where

                           
                              (11)
                              
                                 
                                    
                                       C
                                       i
                                    
                                    =
                                    
                                       [
                                       
                                          
                                             
                                                2
                                             
                                             
                                                2
                                             
                                             
                                                2
                                             
                                             
                                                1
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                1
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                             
                                                2
                                             
                                          
                                          
                                             
                                                2
                                             
                                             
                                                
                                                   −
                                                   2
                                                
                                             
                                             
                                                2
                                             
                                             
                                                
                                                   −
                                                   1
                                                
                                             
                                          
                                       
                                       ]
                                    
                                 
                              
                           
                        
                     

Encoding experiments are applied to three commonly used AVIRIS images, namely Cuprite (754 samples×2776 lines×224 bands with the bit depth of 16), Jasper Ridge (737 samples×1593 lines×224 bands with the bit depth of 16) and Lunar Lake (781 samples×6955 lines×224 bands with the bit depth of 16), all of scene 1. They are all calibrated and can be downloaded from [25]. They are all cropped to the size of 512×512 in space for conveniently comparing with other well-known methods. We set the GOB size to 16, 32 and 48 successively to see the influence of GOB size on compression efficiency. Different GOB sizes can obtain different compression ratios and corresponding compression qualities. Here we use bits per pixel per band (bpppb) to represent compression ratio meaning the bit number needed for each pixel after compression. PSNR is used to evaluate the compression quality. The relation graphs among GOB size, bitrate and PSNR are shown in Fig. 6
                        . We can see that as the GOB size becomes larger, the proposed compression scheme tends to perform better. Analyzing the reason, it is because that our inter-band fractal encoding algorithm utilizes similarity between adjacent bands and this correlation characteristic is extremely strong in hyperspectral images while the spatially correlation is relatively weak.

We also compare our proposed scheme with the well-known lossy compression methods: JPEG2000, AT-3DSPECK [18] and AT-3DSPIHT [17] as well as F. Zhao's [23] algorithm. The rate-distortion (RD) curves are shown in Fig. 7
                        , in which three cases with GOB size set to 16, 32 and 48 in our proposed scheme are presented. We can achieve the coincident conclusion with Fig. 6 that the compression efficiency is higher for our compression scheme when the GOB size becomes larger. As we can see, JPEG2000, AT-3DSPECK and AT-3DSPIHT have almost the same RD performance; F. Zhao's algorithm outperforms these three methods while the PSNR gain is tiny. When the GOB size is 48, the RD performance of our proposed algorithm can get an obvious enhancement than all the other methods. An average bitrate reduction of 57.64%, 55.17%, 52.52%, 24.44% compared with JPEG2000, AT-3DSPECK, AT-3DSPIHT and F. Zhao's algorithm respectively can be achieved when the PSNR is 50dB. What's more, our proposed algorithm can obtain a very high PSNR value with a very low bitrate, which is a particular advantage. The main reason is that fractal encoding usually has a very high compression ratio than other compression algorithms.

The compression results with respect to SNR are shown in Fig. 8
                         for the Cuprite and Jasper Ridge scene, in which the GOB size is set to 48. The proposed method is compared with the following three ones: 1) the scheme of low complexity KLT+JPEG2000 (
                           
                              ρ
                              =
                              0.01
                           
                        ) proposed in [14]; 2) the DWT1D2D scheme applying 3D rate-distortion optimization to JPEG2000 proposed in [15]; 3) the distributed source coding (DSC) method proposed in [26]. For the Jasper Ridge scene, our proposed scheme has an overwhelming superiority than the other three methods. For the Cuprite scene, the superiority can be seen when the bitrate is no less than 0.2bpppb.

Another two scenes of AVIRIS (Yellowstone scene0 and scene3) are also utilized in our experiment to evaluate the PSNR performance. Both scenes have the size of 680 samples×512 lines×224 bands with the bit depth of 16. In this experiment, we set the GOB size to 24, so that we can achieve a bitrate comparable with N.-M. Cheung's [19] and X. Z. Pan's [20] algorithm. The PSNR comparison results are shown in Table 1
                        . Compared to N.-M. Cheung's algorithm and H.264/AVC, the proposed scheme has an evident PSNR gain at all the bitrates. H.264/AVC is carried out with reference software JM18.1 [27]. Compared to X. Z. Pan's algorithm, the proposed scheme has superiority at the bitrates exceeding 0.2bpppb. Totally, considering overall bitrates, the proposed scheme has a PSNR gain of 11.11dB, 3.94dB and 19.08dB on average compared with N.-M. Cheung's algorithm, X. Z. Pan's algorithm and H.264/AVC, respectively.

The encoding time comparisons of the proposed scheme using intra-band prediction and inter-band fractal encoding with H.264/AVC using intra prediction and inter motion compensation are shown in Fig. 9
                        . H.264/AVC is carried out with JM18.1. All experiments are carried out in a PC with Intel Core 2 Quad Q9300 @ 2.50GHz CPU and 4GB RAM. From these results, we can see that the inter-band fractal encoding with local search has lower complexity than intra-band prediction and our scheme saves total 94.1% encoding time on average.

Encoding time comparison results with other algorithms are shown in Fig. 10
                        . Compared with low complexity KLT+JPEG2000 algorithm [14], the encoding time is reduced by 47.15%. Compared with F. Zhao's algorithm [23], the encoding time has a little increase, but our algorithm has a higher encoding efficiency.

Washington DC data [28] are used in classification experiments. They were taken over the Washington DC Mall by HYDICE in August 1995. The data set includes 191 bands with 1208 scan lines in each band and 307 pixels in each scan line. In our experiments, it is cropped to the size of 256×256 spatially and six certain categories including Roof, Street, Path (graveled paths down the mall center), Grass, Tree and Water are considered. We evaluate classification performance by applying a SVM (Support Vector Machine) classifier to the cropped uncompressed image and the reconstructed image, respectively. Four different SVM kernel functions including linear kernel, polynomial kernel, RBF (Radial Basis Function), and Sigmoid kernel are used, which were implemented in the ENVI software with the default parameters as shown in Table 2
                        . Table 3
                         gives the classification accuracy in terms of overall accuracy (OA) and kappa coefficient (κ) for the uncompressed image and the reconstructed image at 0.1bpppb.

From Table 3, we can see that the classification accuracy for the reconstructed image is slightly higher than that for the original data set. The reason is that lossy compression can cause the local smoothing, and reduce noise effect. Consequently, the classification accuracy is improved. Our conclusion keeps consistent with [29] and [30].

This paper proposed a novel lossy compression scheme for hyperspectral image. It is a combination of intra-band prediction and inter-band fractal encoding. Only the 4×4 modes are employed in intra-band prediction for the reason that the spatial correlation of two pixels at the 16 pixels distance decreases rapidly compared with that at a 4 pixels distance. The inter-band fractal encoding exploits local similarity between adjacent bands instead of in the same band, and a local search algorithm getting rid of the isometric transformation operations and the exhaustive search is designed to decrease complexity. The compression experimental results for AVIRIS images indicate that it can produce very high compression efficiency with a low encoding complexity considering overall bitrates. The SVM classification experiments on the uncompressed HYDICE data set and the reconstructed image are carried out to evaluate the compression effect on classification. Classification results illustrate higher classification accuracy for the reconstructed image.

It is an attempt to apply fractal theory to hyperspectral image compression. Therefore, there are some limitations of our approach. When the bitrate is less than 0.2bpppb, our approach cannot achieve an ideal compression performance. In the future works, we aim to improve PSNR performance at bitrate lower than 0.2bpppb, for example by introducing DWT. Anyway, it has built a good foundation for the further research of fractal hyperspectral image compression.

@&#ACKNOWLEDGMENT@&#

This project is funded by the National Natural Science Foundation of China (NSFC) under grants No. 61375025, No. 61075011, and No. 60675018, also the Scientific Research Foundation for the Returned Overseas Chinese Scholars from the State Education Ministry of China. The authors would also like to express their appreciations to the reviewers for their thorough review and very helpful comments, which help improving this paper.

@&#REFERENCES@&#


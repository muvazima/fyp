@&#MAIN-TITLE@&#TSP Race: Minimizing completion time in time-sensitive applications

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Minimizing time from receipt to complete implementation is often the real goal.


                        
                        
                           
                           Parallelizing implementation with computation can significantly speed completion.


                        
                        
                           
                           Break-even speed ratios can be well-estimated.


                        
                        
                           
                           Simple heuristics used with CIP can beat direct application of complex heuristics.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Computation-implementation parallelization

Heuristic

TSP

TSP race

@&#ABSTRACT@&#


               
               
                  In this paper, we present an approach for parallelizing computation and implementation time for problems where the objective is to complete the solution as soon after receiving the problem instance as possible. We demonstrate the approach on the TSP. We define the TSP race problem, present a computation-implementation parallelized (CIP) approach for solving it, and demonstrate CIP’s effectiveness on TSP Race instances. We also demonstrate a method for determining a priori when CIP will be effective. Although in this paper we focus on TSP, our general CIP approach can be effective on other problems and applications with similar time sensitivity.
               
            

The classical traveling salesman problem (TSP) is to find the shortest tour through a set of points and back to the start; it is named after the situation of a traveling salesman who needs to visit a set of cities and then return home.

Consider a case where two traveling salesmen are given the same large set of points and are each challenged to finish a tour before the other. The first traveling salesman follows a traditional approach, computing an optimal tour upfront before starting to travel. The second one, on the other hand, makes a quick start. Each time he travels to a node, he simultaneously computes the next node to visit while traveling. One could imagine this traveling salesman driving from city to city with a laptop open on the passenger seat calculating where to go next. The second traveling salesman can be expected to travel longer due to the less-global nature of his decision-making; however he has the advantage of not investing much time in computing beforehand. Because of this trade-off, it might not be a trivial task to determine which traveling salesman will be the winner. We refer to this setting of TSP, with the objective of minimizing total completion time, as TSP Race. The statement of TSP Race is as follows: Given an instance of TSP, finish visiting all nodes and return to the start as soon as possible. In this paper, we introduce an approach to this problem exemplified by the second traveling salesman.

We refer to the approach of the second traveling salesman, who embeds part of his computation time into his travel time, as a computation-implementation parallelized (CIP) approach. The idea of CIP is generalizable to other problems where computation and implementation need not occur fully sequentially, and where it can be beneficial to compute later parts of a solution in parallel with implementing earlier parts. Most of the current literature on optimization problems focuses on minimizing the computation time to find an optimal (or heuristically good) solution, or on maximizing the quality of a solution (as measured by its implementation, e.g., the length of a TSP tour). However, if minimizing the time between receipt of the problem and completion of the solution is important and the computation time is comparable to the implementation time, conventional methods are not necessarily efficient. The reason is that the implementation resources stay idle during the computation phase, and vice versa.

In this paper, to introduce and show the effectiveness of CIP we implement it on the TSP Race problem. The rest of this paper is organized as follows. In Section 2, we discuss the TSP applications that are compatible with the TSP Race setting. We are unaware of any previous work on TSP Race, but in Section 3, we present a brief review of general solution approaches to TSP. In Section 4, a general procedure of computation-implementation parallelization is introduced for TSP Race. In Section 5, we discuss methods to partition the graph, present computational results to compare them, and demonstrate the effectiveness of our approach. In Section 6, we develop a parameter selection mechanism for the parallelization approach. In Section 7, we present some final remarks.

Our main motivation to design CIP approaches is to address time-sensitive applications in which total time from obtaining an instance to completing the implementation of a solution is an important objective to optimize. Among such applications, CIP is most appropriate for those where computation time is comparable to implementation time. (Otherwise, if computation time is relatively small then one could quickly compute the best solution and then implement it, and if implementation time is relatively short compared to computation time then one could compute a feasible solution as quickly as possible and then implement it.)

Because computation time (and sometimes implementation time) are a function of current technology, the exact set of problems where CIP is appropriate will necessarily vary over time. Currently, there are a variety of current optimization problems where we believe CIP can be a useful approach. Divisible load problems (Marchal, Yang, Casanova, and Robert, 2005; Veeravalli and Barlas, 2002) are well-fitted to CIP. One example is the scheduling of large-scale jobs to parallel processors in areas such as telecommunications and medical imaging (Davis and Burns, 2011), image processing and computer vision (Veeravalli and Barlas, 2002), etc. Minimizing the completion time in multiprocessor systems can help to increase the utilization of the workstations. Arc therapy in cancer treatment is another potential application for CIP. A patient is scanned (receipt of the instance), an optimized radiation treatment plan is created (computation), and then the solution is carried out (implementation), all while the patient lies on the table. In some specific methods, computation time constitutes a significant portion of the total completion time (Bzdusek et al., 2009; Otto, 2008; Zhang et al., 2010); moreover, because even small movements of a patient can create error in the radiation plan, minimizing the time between receipt of an instance and finishing the implementation of a solution is important. (Çavdar, 2014) describes a vehicle loading and routing problem in which heuristic solutions for a parcel delivery vehicle routing problem are heuristically computed, and then the corresponding packages are loaded onto each delivery truck. The time to compute heuristic solutions and the time to implement them at the facility (i.e., load the packages onto the trucks as determined by the heuristic) are comparable, and using a CIP approach can help improve the quality of the delivery routing solutions.

In this paper, we introduce CIP by focusing on applications of TSP where a TSP Race model is appropriate and a CIP approach could produce better overall solutions. The Traveling Salesman Problem: A Computational Study by Applegate, Bixby, Chvatal, and Cook (2007) gives an elaborate list of applications for TSP. Because of the current computation speed of fast processors combined with the quality of modern TSP algorithms, computation time to find good solutions can be small. Therefore, we suggest using our approach on problems where there are large number of nodes over a small area (so that optimization will take longer, and travel times will be shorter). Potential physical examples include small-scale manufacturing TSPs (e.g., producing customized chips), data management (e.g., unsorted database query retrieval), and laser and X-ray applications (crystallography, manufacturing of crystal art with a laser). Virtual TSPs may also provide examples where CIP is beneficial. For example, when simulating pick paths to determine the quality of potential warehouse designs, a simulation might repeatedly solve new TSPs to find a sequence of lines for every simulated order pick. The computation time of these TSPs is comparable to the implementation time (the time it takes to simulate the order pick), and the CIP approach could significantly speed up such simulations.

However, we need to note that although these applications are good candidates for implementing CIP, they may not necessarily benefit from this approach. As we show in Section 6, a break-even analysis that depends on the specific implementation and computation speeds of each system may be required to determine when using CIP would likely lead to an improvement.

@&#LITERATURE REVIEW@&#

TSP has a rich literature. Applegate et al. (2007) is a comprehensive guide to TSP’s history. Common exact algorithms for TSP and its variants include branch-and-cut, e.g., Ascheuer, Jünger, and Reinelt (2000), Baldacci, Hadjiconstantinou, and Mingozzi (2003), Cordeau, Dell’Amico, and Iori (2010), Jünger and Störmer (1995), Ascheuer, Fischetti, and Grötschel (2001) and branch-and-bound, e.g., Poremba and Toriello (2014), Volgenant and Jonker (1982), Gavish and Srikanth (1986), Carpaneto, Dell’Amico, Fischetti, and Toth (1989).

For most large TSP applications, running algorithms until completion may not be computationally feasible, even more so when the computation time is a part of the objective. In the traditional approach, to manage the tradeoff between the solution quality and the running time, the algorithms can be stopped before completion, and competitive solutions can still be obtained. As an alternative to exact methods, many heuristic algorithms have been developed over the years, to sacrifice travel time for decreased computation time, and many of these too can be stopped before completion to provide good solutions. These heuristics can be grouped into construction, local optimization, and metaheuristics (Johnson and McGeoch, 1997). High quality solutions can be obtained quickly by local optimization, simulated annealing and genetic algorithms; see, for example Nagata (2006), Tsai, Yang, Tsai, and Kao (2004), Applegate, Cook, and Rohe (2003), Neto (1999), Marinakis, Migdalas, and Pardalos (2005), Nguyen, Yoshihara, Yamamori, and Yasunaga (2007), Tsai, Yang, and Kao (2002). In this paper, we focus on local optimization methods. For very large graphs, these heuristics may be preferred to exact methods due to computational speed. However, their usage is the same as the exact algorithms, i.e., the computation is completed prior to starting to travel.

To our knowledge, the exact question of balancing computation and travel time by computing while traveling on a known set of nodes has not been studied in the literature. One related approach is online problems where the data is not all known when computation begins; algorithms optimize given the information they have, and update or extend their solutions as more information becomes available. An online algorithm is said to be ρ-competitive if the algorithm guarantees that the solution found by the algorithm does not take more than the ρ times the optimal solution when all input is known at the start (Allulli, Ausiello, and Laura, 2005). Although the lower bound on ρ for the TSP is found to be approximately 1.64 (Ausiello, Demange, Laura, and Paschos, 2004), we are not aware of any study which reports the performance of online algorithms on deterministic node sets in practice. Moreover, online algorithms use all the information available. For example, Ausiello et al. (2004) recomputes the TSP tour whenever new information is available. Since we begin with complete information about the graph, an online algorithm’s behavior will be the same as the compute-first implement-later approach. In this paper, we introduce a new approach aiming at minimizing the total completion time. To show its effectiveness, we demonstrate its use on the TSP with the 2opt  (Croes, 1958) and nearest neighbor (NN) (Johnson, 1990) heuristics.

Our approach is to decrease the total TSP completion time by making better use of the travel time. The main idea is to embed the computation into travel so as to have less computation-only time. Fig. 1
                      is a visual summary of our approach. We split the graph into subgraphs. Initially, we do one step of computation to choose a path through the first subgraph. While traveling on this path, we do a second computation to choose a path through the second subgraph, etc. Except for the first computation and the last travel, at each step a computation phase is embedded into a travel phase.

At each intermediate step, the elapsed time is the maximum of the travel time and the computation time. As shown in Fig. 1, since the second computation can be finished while traveling on the first subgraph, the completion time of that portion is equal to the first travel time. On the other hand, when we finish traveling on the second subgraph, we have to wait for the end of the computation to determine the next node to go to. So, the completion time of that portion is equal to the third computation time.

Before discussing the details of the approach, we first introduce some notation. While most of the notation is more general, for the remainder of this paper we assume a complete Euclidean graph on a plane.

                        Notation


                        
                           n
                        
                        
                           number of nodes in the graph

number of subgraphs

travel time on the ith subgraph (entire graph) using algorithm 
                                 A
                              ’s solution

computation time of algorithm 
                                 A
                               to find the path on the ith subgraph (entire graph)

time coefficient to express the ratio between the computation and the travel speed

length (width) of rectangular area containing the nodes

The expression on the left is the total completion time when the main algorithm 
                        A
                      is run on the entire graph. On the right is the completion time of the CIP approach. In practice, of course, each C and T will not be known exactly, and must be estimated.

In the rest of this paper, we will use the 2opt algorithm as the main algorithm 
                        A
                      and NN as the humble startup algorithm 
                        B
                     . We refer to this setup as CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                     . 2opt is one of the most commonly used tour improvement heuristics, and computational studies show that 2opt can find a tour which is in 6.4 percent of the Held-Karp bound on average (Johnson and McGeoch, 1997). However, the proposed approach can be implemented using any TSP algorithms, i.e., CIP
                        
                           
                              
                              
                                 B
                              
                              A
                           
                           ,
                        
                      with minor modifications.

The main contribution of the CIP approach is to decrease the total completion time in spite of a possible increase in both computation time and travel time. How we partition the graph plays an important role. We propose and test four different partitioning rules. In the first three partitioning methods, the nodes are partitioned based on their location, before any travel begins. In the last method, the partition is created on the fly by the initial fast algorithm. These methods are discussed in detail below.

                        
                           1.
                           
                              α
                              -Box. Draw a box with dimensions 
                                 
                                    h
                                    
                                       α
                                    
                                 
                               by 
                                 
                                    v
                                    
                                       α
                                    
                                 
                               in the corner of the graph, as shown in Fig. 2
                              . NN constructs a path through all the nodes in the α-box. While traveling on this path, NN constructs a tour on the nodes outside the box, and 2opt is run to improve the tour. When 2opt is finished and all the nodes in the box have been visited, travel continues on the remaining nodes using the sequence formed by 2opt.


                              α
                              -Strip. This method is similar to α-box method except that the first path is constructed on the nodes falling in the strip whose length is hα, as depicted in Fig. 3
                              .


                              Matrix-partitioning. We divide the rectangular graph into a grid of equal-dimension subgraphs. NN is run on the first subgraph to construct a path. On other subgraphs 2opt is run, and the subgraphs are visited in order of an optimal tour of the centers of the grid squares. Figs. 4–6
                              
                              
                               depict cases where we divide the graph into 4, 16, and 36 equal-area subgraphs respectively. Matrix-partitioning can provide a greater saving in the computation-only time, because we are not only embedding the computation into travel, but also decreasing the amount of computation done by each 2opt execution. However, the travel time can get larger.


                              Free-NN. In this method, the graph is divided into two subgraphs. Starting from the initial node s, NN is run to determine the next αn nodes to visit. While we are traveling on that path, a tour on the rest of the nodes is constructed by NN and improved by 2opt.

The α-box, α-strip and free-NN methods divide the graph into two subgraphs, so we call them two-partitioning methods, where NN is run on the first set of nodes and 2opt is run on the remaining nodes.

Having proposed four methods to partition the subgraphs, we performed computational experiments to compare the behavior of total completion time in different scenarios. In those experiments,

                        
                           •
                           the graphs are rectangular and the nodes are uniformly randomly distributed,


                              c is assumed to be 1, and

it is assumed that 1 unit of distance is traveled per second.

We tested the methods for different values of α, and performed computational experiments for different numbers of nodes, areas, and aspect ratios of the rectangles. In those experiments, we have run the algorithms until completion. One could also stop a computation as soon as the corresponding travel is completed. For brevity, we report only the results on 10,000-node graphs for the four partitioning methods on 1 unit square graphs (Figs. 7–10
                     
                     
                     
                     
                     ) and 100 unit square graphs (Figs. 11–14
                     
                     
                     ), since the behavior is similar in all cases.

In the figures, we show total net completion time (TNT) and total travel time (TTT). The difference between TNT and TTT is the total computation-only time (TCT), the computation that could not be embedded into travel. In the two-partitioning methods (Figs. 7, 8, 10) TTT is increasing in α. With increasing α, NN determines a bigger portion of the tour, preventing 2opt from making as many improvements. On the other hand, TCT is generally decreasing to the initial NN time with increasing α, because of the embedding of computation into travel. At some value of α, TNT nearly merges with TTT, because the length of the first path includes all the computation required to find the path on the second subgraph. As long as TNT at a specific α is less than the TNT when α = 0, which corresponds to running 2opt on the entire graph, parallelizing computation with travel performs better. For matrix-partitioning, we observe a similar pattern in TNT, TCT, and TTT.


                     Figs. 11 –14 display the results of the same experimental setting for the same node set, but the area of the graph is enlarged by a factor of 100. TNT, TCT, and TTT have similar patterns as before, but TNT and TTT merge earlier because travel time increases more quickly. When parallelizing the 2opt algorithm with NN, the key question is whether the CIP approach reduces the total completion time. Below we present computational results showing the reduction in total completion time achieved by using CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                     . To avoid the question of whether implementation quality could bias results in favor of the CIP approach, we used simple, naive implementations of both NN and 2opt, both coded in C. For example, to store the tour we used a basic array data structure, during 2opt the entire neighborhood is searched until there is no more improvement, etc. Runs are performed on a heterogeneous cluster of machines with Xeon E5645 processor or near equivalent.

In Table 1
                     , we compare CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      using each partitioning mechanism with running 2opt or NN on the entire graph. The numbers in the table show completion time scaled to where 2opt takes 1 second. For example, the completion time is 0.77 second if we run CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      instead of 2opt (1 second) on the 15,000-node, 16unit2 graph. None of the graph partitioning methods purely dominates the others, though free-NN is slightly better on average than other partitioning methods. More importantly, these computational results verify that there are settings in which our CIP method can achieve significant improvement in total completion time compared to its component methods.

As expected, NN can beat 2opt on graphs with small area and a large number of nodes, since in such cases the computation time of 2opt is too long to outweigh its advantage in implementation time. As the graph area increases, NN loses its advantage due to worse tour quality. However, we see that for each setting it is possible for 
                        
                           CIP
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      to beat both NN and 2opt in terms of completion time. Relative gains in the completion time using the CIP
                        
                           
                           NN
                           
                              2
                              opt
                           
                        
                      are significant when actual running time is comparable to total travel time, e.g. when there are large number of nodes in a small area.

One might also wonder how CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      compares to a high-quality TSP algorithm. On the same set of instances as in Table 1, we compared CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      with Applegate et al.’s (http://www.math.uwaterloo.ca/tsp/concorde/index.html
, November, 2013) implementation of the Lin − Kernighan algorithm (LK) (Lin and Kernighan, 1973). Even with our naive implementation of NN and 2opt, CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      gave up to 15 percent faster completion time than LK on instances with smaller areas. On instances with larger areas, LK was up to 7 percent better than CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                     ; and when the area is increased, LK would beat CIP
                        
                           
                           
                              NN
                           
                           
                              2
                              opt
                           
                        
                      even if we could entirely eliminate computation time from our algorithm. The bottom line is that for sufficiently large number of nodes in a small area, a CIP approach using naively-coded simple heuristics can beat a cleverly coded high-quality standard (i.e., non-CIP) heuristic, and as the number of nodes decreases and/or area increases, the opposite is true. However, we should also note that high-quality and computationally more demanding heuristics such as LK can also be implemented as part of a CIP approach, creating a CIP method that might give an even better result. In the next section, we discuss how to find break-even points between approaches.

Now that we have shown the CIP approach to be effective for TSP Race, we would like to characterize the break-even point beyond which the CIP
                        
                           
                           
                              B
                           
                           A
                        
                      approach should be used instead of its constituent algorithms 
                        A
                      and 
                        B
                     . The main factor affecting the performance of the CIP approach is the ratio of computation and travel speeds. In applications where the computation is already extremely fast relative to the travel, the CIP approach may not help. So, we would like to determine the smallest applicable time coefficient c, i.e., the fastest computation or the slowest travel, for which the CIP approach will decrease the total completion time. We first find the break-even c in terms of the other parameters, and then develop an estimation function so that we can determine which value of α should be used in different settings. Of course, this analysis depends not only on travel speed and processor speed, but also on the algorithms used and even of the efficiency on their specific implementations.

The following is the restatement of inequality (1) for the general algorithms 
                        A
                      and 
                        
                           B
                           ,
                        
                     
                     
                        
                           (2)
                           
                              
                                 c
                                 
                                    C
                                    A
                                 
                                 +
                                 
                                    T
                                    A
                                 
                                 ≥
                                 c
                                 
                                    C
                                    
                                       1
                                    
                                    B
                                 
                                 +
                                 max
                                 
                                    {
                                    
                                       T
                                       
                                          1
                                       
                                       B
                                    
                                    ,
                                    c
                                    
                                       C
                                       
                                          2
                                       
                                       A
                                    
                                    }
                                 
                                 +
                                 
                                    ∑
                                    
                                       i
                                       =
                                       2
                                    
                                    t
                                 
                                 max
                                 
                                    {
                                    
                                       T
                                       
                                          i
                                       
                                       A
                                    
                                    ,
                                    c
                                    
                                       C
                                       
                                          i
                                          +
                                          1
                                       
                                       A
                                    
                                    }
                                 
                                 +
                                 
                                    T
                                    
                                       t
                                       +
                                       1
                                    
                                    A
                                 
                              
                           
                        
                     
                  

We can express the changes in the computation speed or travel speed by modifying the time coefficient c in (2). For example, faster computation or slower travel can be translated by smaller values of c. Following this expression, we need

                        
                           (3)
                           
                              
                                 c
                                 ∈
                                 
                                    [
                                    
                                       
                                          
                                             T
                                             
                                                1
                                             
                                             B
                                          
                                          +
                                          
                                             ∑
                                             
                                                i
                                                =
                                                2
                                             
                                             
                                                t
                                                +
                                                1
                                             
                                          
                                          
                                             T
                                             
                                                i
                                             
                                             A
                                          
                                          −
                                          
                                             T
                                             A
                                          
                                       
                                       
                                          
                                             C
                                             A
                                          
                                          −
                                          
                                             C
                                             
                                                1
                                             
                                             B
                                          
                                       
                                    
                                    ,
                                    min
                                    
                                       {
                                       
                                          
                                             T
                                             
                                                1
                                             
                                             B
                                          
                                          
                                             C
                                             
                                                2
                                             
                                             A
                                          
                                       
                                       ,
                                       
                                          
                                             T
                                             
                                                2
                                             
                                             A
                                          
                                          
                                             C
                                             
                                                3
                                             
                                             A
                                          
                                       
                                       ,
                                       ⋯
                                       ,
                                       
                                          
                                             T
                                             
                                                t
                                             
                                             A
                                          
                                          
                                             C
                                             
                                                t
                                                +
                                                1
                                             
                                             A
                                          
                                       
                                       }
                                    
                                    ]
                                 
                              
                           
                        
                     to have less completion time than running algorithm 
                        A
                      on the entire graph with no computation-only time except for the initial computation performed by algorithm 
                        B
                     . We define the break-even c as the fastest computation or the slowest travel environment for which the computation-implementation parallelization is likely to be helpful, and this corresponds to the lower bound of the interval.

For example, by rewriting the expression (2) for the 2opt and NN algorithms for the two-partition case, i.e. t = 1, we obtain the following:

                        
                           (4)
                           
                              
                                 c
                                 
                                    C
                                    NN
                                 
                                 +
                                 c
                                 
                                    C
                                    
                                       2
                                       opt
                                    
                                 
                                 +
                                 
                                    T
                                    
                                       2
                                       opt
                                    
                                 
                                 ≥
                                 c
                                 
                                    C
                                    
                                       
                                          G
                                          1
                                       
                                    
                                    NN
                                 
                                 +
                                 max
                                 
                                    {
                                    c
                                    
                                       (
                                       
                                          C
                                          
                                             
                                                G
                                                2
                                             
                                          
                                          NN
                                       
                                       +
                                       
                                          C
                                          
                                             
                                                G
                                                2
                                             
                                          
                                          
                                             2
                                             opt
                                          
                                       
                                       )
                                    
                                    ,
                                    
                                       T
                                       
                                          
                                             G
                                             1
                                          
                                       
                                       NN
                                    
                                    }
                                 
                                 +
                                 
                                    T
                                    
                                       
                                          G
                                          2
                                       
                                    
                                    
                                       2
                                       opt
                                    
                                 
                                 .
                              
                           
                        
                     
                  

In this specific setting, the breakeven value of the computation-time coefficient c is computed as follows:

                        
                           (5)
                           
                              
                                 
                                    
                                       T
                                       
                                          
                                             G
                                             1
                                          
                                       
                                       NN
                                    
                                    +
                                    
                                       T
                                       
                                          
                                             G
                                             2
                                          
                                       
                                       
                                          2
                                          opt
                                       
                                    
                                    −
                                    
                                       T
                                       
                                          2
                                          opt
                                       
                                    
                                 
                                 
                                    
                                       C
                                       NN
                                    
                                    +
                                    
                                       C
                                       
                                          2
                                          opt
                                       
                                    
                                    −
                                    
                                       C
                                       
                                          
                                             G
                                             1
                                          
                                       
                                       NN
                                    
                                 
                              
                           
                        
                     Of course, none of these travel times and computation times is known, so we run computational tests to observe the behavior of c in practice.

Employing the same experimental design as in Section 5, we performed another set of computational studies to observe the break-even c for different parameters when we choose 2opt to be our algorithm A and NN as our algorithm B. Results on unit square graphs with 5000, 8000 and 10,000 nodes are demonstrated in Fig. 15
                     . The first plot shows the break-even c values for different values of α. As we can see, having more nodes in a graph gives more flexibility to the CIP approach in terms of the applicability. More specifically, when there are more nodes in the same area, CIP is more effective even if the computation is very fast or travel is slow. The second plot is another interpretation of the break-even c. It shows us how much we can deviate from the existing setting of our computational experiments and still do better in terms of the completion time. In a specific TSP application where the travel is ρ times slower than what we assume in the computational experiments, and the computation is ω times faster, as long as ρω is less than the tolerance factor in Fig. 15, CIP
                        
                           
                           NN
                           
                              2
                              opt
                           
                        
                      is still better than running 2opt itself.

The computational results are important to help us to develop a notion of the interaction between the break-even c and the influential factors. Prior to setting up the estimation model, we observed that break-even c
                     
                        
                           •
                           increases in α,

decreases in n,

increases in the area of the graph,

increases in the aspect ratio, v/h.

Guided by preliminary observations and the computational results, we used regression to find the following model to estimate the value of break-even time coefficient.

                        
                           (6)
                           
                              
                                 
                                    
                                       
                                          
                                             (
                                             
                                                c
                                                
                                                   A
                                                
                                             
                                             )
                                          
                                          
                                             0.12
                                          
                                       
                                    
                                    
                                       ≈
                                    
                                    
                                       
                                          
                                             x
                                             1
                                          
                                          α
                                          +
                                          
                                             x
                                             2
                                          
                                          
                                             α
                                             2
                                          
                                          +
                                          
                                             x
                                             3
                                          
                                          
                                             
                                                (
                                                α
                                                −
                                                0.5
                                                )
                                             
                                             2
                                          
                                          +
                                          
                                             x
                                             4
                                          
                                          n
                                       
                                    
                                 
                                 
                                    
                                    
                                    
                                       
                                          +
                                          
                                          
                                             x
                                             5
                                          
                                          
                                             n
                                             2
                                          
                                          +
                                          
                                             x
                                             6
                                          
                                          
                                             n
                                             3
                                          
                                          +
                                          
                                             x
                                             7
                                          
                                          
                                             v
                                             h
                                          
                                          +
                                          
                                             x
                                             8
                                          
                                          
                                             v
                                             h
                                          
                                          α
                                       
                                    
                                 
                              
                           
                        
                     
                  

The data set used to train estimation model (6) comes from a large pool of test instances. The parameters are the combinations of 
                        
                           (
                           n
                           ,
                           α
                           ,
                           A
                           ,
                           
                              v
                              h
                           
                           )
                        
                      generated from the following individual sets:

                        
                           •
                           
                              n ∈ {10k, 12k, …, 26k},


                              α ∈ {0.01, 0.02, …, 0.1, 0.2, …, 0.9, 0.99},


                              A ∈ {1, 16, 49, 64, 100, 196, 400, 900},


                              
                                 
                                    
                                       v
                                       h
                                    
                                    ∈
                                    
                                       {
                                       1
                                       ,
                                       4
                                       ,
                                       16
                                       ,
                                       64
                                       }
                                    
                                 
                              .

The coefficients x of the estimation model for the break-even time coefficient c in Eq. (6) are shown in Table 2
                     .

The model’s R
                     2 is 0.9987, and all the predictors are significant.

To validate the model we tested the estimation function on out-of-sample data and graphs different with sizes and areas. The parameters of the test set are combined with the following sets:

                        
                           •
                           
                              n ∈ {10k, 12k, …, 18k},


                              α ∈ {0.01, 0.02, …, 0.1, 0.2, …, 0.9},


                              A ∈ {1, 4, 16, 64, 324, 1024},


                              
                                 
                                    
                                       v
                                       h
                                    
                                    ∈
                                    
                                       {
                                       1
                                       ,
                                       4
                                       }
                                    
                                 
                              .

The testing procedure has two stages. In the first stage, we estimate the time coefficient c by Eq. (6). Then, this coefficient is used in computational experiments. For the same time coefficient c, we run both CIP
                        
                           
                           NN
                           
                              2
                              opt
                           
                        
                      (using the corresponding α) and 2opt on the same graph. We call these two runs conjugate runs. As it is implied by the definition of the break-even time coefficient, the TNTs of these runs should be approximately equal. In our test results, we observe that the ratios between the TNTs of the conjugate runs are very close to 1 in both tests, and they do not possess any systematic pattern, which provides empirical support for the predictive power of estimation model (6) for the break-even time coefficient. A summary of the results can be seen in Table 3
                     . The results are classified according to different areas, elongations and the number of nodes. Entries in the table are the averages of the ratios between TNTs of conjugate runs.

To use the CIP approach in a different scenario with a preferred α, we can use (6) to estimate the smallest applicable time coefficient, i.e., the fastest computation or slowest travel speed for which the CIP approach can still decrease the completion time. If the real time coefficient c′ falls in the interval

                        
                           (7)
                           
                              
                                 
                                    [
                                    
                                       
                                          
                                             T
                                             
                                                
                                                   G
                                                   1
                                                
                                             
                                             NN
                                          
                                          +
                                          
                                             T
                                             
                                                
                                                   G
                                                   2
                                                
                                             
                                             
                                                2
                                                opt
                                             
                                          
                                          −
                                          
                                             T
                                             
                                                2
                                                opt
                                             
                                          
                                       
                                       
                                          
                                             C
                                             NN
                                          
                                          +
                                          
                                             C
                                             
                                                2
                                                opt
                                             
                                          
                                          −
                                          
                                             C
                                             
                                                
                                                   G
                                                   1
                                                
                                             
                                             NN
                                          
                                       
                                    
                                    ,
                                    
                                       
                                          T
                                          
                                             
                                                G
                                                1
                                             
                                          
                                          NN
                                       
                                       
                                          
                                             C
                                             
                                                
                                                   G
                                                   2
                                                
                                             
                                             NN
                                          
                                          +
                                          
                                             C
                                             
                                                
                                                   G
                                                   2
                                                
                                             
                                             
                                                2
                                                opt
                                             
                                          
                                       
                                    
                                    ]
                                 
                                 ,
                              
                           
                        
                     then CIP decreases the total completion time by the factor

                        
                           (8)
                           
                              
                                 
                                    (
                                    
                                       
                                          
                                             c
                                             ′
                                          
                                          
                                             C
                                             NN
                                          
                                          +
                                          
                                             c
                                             ′
                                          
                                          
                                             C
                                             
                                                2
                                                opt
                                             
                                          
                                          +
                                          
                                             T
                                             
                                                2
                                                opt
                                             
                                          
                                       
                                       
                                          
                                             c
                                             ′
                                          
                                          
                                             C
                                             
                                                
                                                   G
                                                   1
                                                
                                             
                                             NN
                                          
                                          +
                                          
                                             T
                                             
                                                G
                                                1
                                             
                                          
                                          +
                                          
                                             T
                                             
                                                G
                                                2
                                             
                                          
                                       
                                    
                                    −
                                    1
                                    )
                                 
                                 100
                                 %
                                 .
                              
                           
                        
                     
                  

@&#CONCLUSION@&#

In this paper, we introduced a computation-implementation parallelization (CIP) approach to solving problems where the goal is to minimize the time from getting the problem instance to completing the implementation of its solution. By embedding computation into the implementation, we can decrease the total completion time. Focusing on a min-completion-time variant of TSP that we name TSP Race, we proposed and evaluated four methods of partitioning the graph for CIP, and verified that CIP is a beneficial approach in many instances. We then described a model for predicting a priori which instances would benefit from using CIP, and showed through computational testing that it has high accuracy.

The ideas presented in this paper are more generally applicable; for example in a forthcoming comparison paper, we use this approach to solve hard VRP instances that arise in parcel delivery.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank the anonymous reviewers for their helpful comments and suggestions that improved this paper.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Node discovery scheme of DDS for combat management system

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Modified counting Bloom filters as discovery scheme for data distribution service


                        
                        
                           
                           Combine SDPBloom discovery scheme with Fast Hash-table


                        
                        
                           
                           The proposed method is applied in naval combat system.


                        
                        
                           
                           Focus on discovery delay time and false positive probability


                        
                        
                           
                           The discovery scheme can also be applied in dynamic environment.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Discovery scheme

Real-time middleware

Combat management system

Counting Bloom filters

@&#ABSTRACT@&#


               
               
                  In this paper, a novel discovery scheme using modified counting Bloom filters is proposed for data distribution service (DDS) for real-time distributed system. In a large scale network for combat management system (CMS), a lot of memory is required to store all the information. In addition, high network traffic can become problematic. In many cases, most of the information stored is not needed by the DDS's endpoints but occupy memory storage. To reduce the size of information sent and stored, a discovery process combined with counting Bloom filters is proposed. This paper presents delay time for filters construction and total discovery time needed in DDS's discovery process. Simulation results show that the proposed method gives low delay time and zero false positive probability.
               
            

@&#INTRODUCTION@&#

Data distribution service (DDS) for real-time systems [1,2] is an Object Management Group (OMG) publish/subscribe (P/S) standard that aims to enable scalable, real-time, dependable, high performance, and interoperable data exchanges between publishers and subscribers. Since DDS is implemented as an infrastructure solution, it can be added as a communication interface to any software application.

The DDS is implemented using a data centric approach [3], which facilitates the interoperability of heterogeneous system by building a Global Data Space (GDS) [4]. The GDS enables all interested application to access all the accessible data in the GDS by providing a single and unified data space, and a transparent mapping of data models. Information published by some application to GDS can be subscribed by other applications without application-level bridging by accessing the GDS.

Combat management system (CMS) is used in naval combat systems (NCS) to manage all the sensors and weapons in a warship [5,6]. With the advancement of NCS, it continued to contain even more information and needed a dependable system to manage its data communication systems. The data distribution system (DDS) [7,8] was one of the information management systems that was developed.

NCS started with development of the combat system for naval surface ships, and have had many software applications through independent domestic R&D efforts. However, most of software application developed for a single system only cannot be used on heterogeneous naval ship combat system [6].

For the publisher and subscriber to communicate in DDS, they need to discover each other and obtain each other attributes such as domainID and topic name. To do so, a discovery scheme is needed. Discovery process is a time and resource consuming process that might not work in a scarce resources (such as memory and network bandwidth) environment. Therefore, an efficient discovery scheme is important to improve the scalability of DDS on large scale networks [9].

The OMG has standardized the interoperability of DDS using a real-time publish/subscribe (RTPS) protocol to transmit data over the network. A basic RTPS implementation must provide at least a basic discovery protocol to enable interoperability. The basic RTPS implementation for discovery protocol is called simple discovery protocol (SDP). The SDP has several limitations, for example, in a large network with thousands of endpoints, every participant needs to send and receive numerous discovery messages from all other participants in the same domain 
                     [10]. However, not all information is needed. If every endpoint was interested in just several of the endpoints, the message sent to uninterested endpoints would be wasted.

Inspired by the work in [11], this paper proposes an enhancement of the discovery protocol in DDS. The main goal of this study is to reduce the memory requirement in the discovery process. Using basic idea of applying Bloom filters to SDP (SDPBloom), this paper introduces a different approach to eliminate false positive probability from SDPBloom, by changing the SDPBloom by using extended counting Bloom filters.

The main idea of the proposed method is to eliminate duplicate information in the Bloom filters and to ensure that every piece of information has only one representative key. The proposed method uses a modified counting Bloom filters to make the key and store the information. By having only one key for each data item, the false positive probability can be eliminated [12]. Thus, in the following sections, the analytical and simulation results that demonstrate the benefits and contribution of the proposed method are presented.

The rest of the paper is organized as follows: related studies on discovery schemes are presented in Section 2. Section 3 introduces the basic concepts of the DDS. Section 3.1 introduces the naval combat system. Section 3.2 introduces and analyzes the SDP in DDS. The problem formulation is presented in Section 4. Section 5 presents the proposed method using a modified counting Bloom filters for DDS. Section 6 discusses the simulation results. Finally, Section 7 presents the conclusion.

The paper in [13] proposed a brief idea of an adaptive SDP for dynamic large-scale network systems, and described the quality of service supported by DDS. It defines the challenges in applying DDS for a large-scale distributed application, because the existing DDS implementation requires static pre-configuration of nodes to set up the overlay multicast network that the DDS infrastructure uses to distribute data efficiently.

Key requirements that need to be considered for the adaptive discovery service area are as follows:
                        
                           1.
                           Efficient association of DDS entities with shared mutual interest;

Support for robust communication hints;

Seamless integration with standards.

Based on their investigation, the existing RTPS-based DDS has significant scalability limitations for the number of participants (reader/writers), topics, joining and leaving the data exchange number, and message priority. A layered messaging protocol is more scalable and predictable although it imposes a slight overhead on each message delivery compared to an RTPS-based messaging protocol.

The study in [11] combines SDP for DDS and Bloom filters. It shows that the number of messages sent for the discovery process can be greatly reduced for a large number of endpoints per participant. The numbers of messages sent to the network for endpoint advertisement remained constant while the number of endpoints increased. However, there can be false positives in endpoint matching when using SDPBloom. In addition, the work in [11] does not consider information deletion from the table, though item addition and deletion in a database is common in a dynamic communication system. When an item/information is deleted from the Bloom filters' table that is, bit 1 is changed back to bit 0, a false negative will be produced in the case of other existing information that share the same bit of the Bloom filters. Although the proposed algorithm considers the existence of false positives, this consideration makes the algorithm non-deterministic and causes the execution time to vary. Some real-time systems need a fixed execution time and deterministic algorithms [14,15]. Therefore, this part of the algorithm is explored in this paper. And a method to improve the deterministic behavior of the Bloom filters for SDP is developed.

The DDS is a new OMG specification that creates a very simple architecture for data communication while enabling very complex data patterns. The DDS provides an API for sending and receiving data [8]. It relieves the developer from having to worry about any network programming. The DDS simply allows the distribution of data anywhere and anytime.

As a data and message management system, the DDS has several advantages compared to the other message management systems. The DDS has a low overhead, and it can be used in high performance systems [7]. The large number of configuration parameters gives developers a complete control of each message in the system.

The specification for DDS is divided into two distinct sections [2]. The first section covers data-centric publish/subscribe (DCPS) level, and the second section covers the data local reconstruction layer (DLRL).

DCPS is the lower layer API that applications can use to communicate with other DDS-enabled applications. DLRL is the upper layer of the specification that outlines how an application can interact with the DCPS data fields through their own object-oriented programming classes. DLRL is an optional layer in the DDS specification.

Data is sent and received from the data domain. Publishers and subscribers are used to manage single or multiple DataWriters and DataReaders, respectively. If data published by the DataWriter is to be received by the subscribing DataReader, the DataReader and the DataWriter must have the same topic as shown in Fig. 1
                        .

Basic DDS is resistant to many kinds of error, such as single point failure and network breakdown. DDS does not require special nodes, so it can be implemented without single point-of-failure that affects more than the actual lost nodes. The redundancy of publisher and subscribers is also considered. Transparent failover is a natural part of the model. Failover can be configured on a per-data-stream basis to satisfy a wide range of application scenarios. In addition, when properly implemented, DDS networks are self-healing. If the network is severed into two halves, each half will continue to work with the available nodes. When the network is repaired, it will quickly rediscover the new nodes, and once again function as a whole.

The discovery process is initiated from a list of known hosts [16,17], (a list of IP addresses to which a participant will announce his presence. If there are no IP addresses specified, the default unicast/multicast address is used to announce the participant in a network).

In order to start the publication/subscription communication, the DDS needs to check the topic name, data type name, and data type code of endpoint.

As shown in Fig. 2
                        , the DDS discovery protocol is divided into two consecutive processes:
                           
                              1.
                              Simple participant discovery protocol (SPDP): Discovers new participants in the same domain in a network.

Simple endpoint discovery protocol (SEDP): Starts the EDP process for exchanging local and remote endpoints information between two participants when a new participant is discovered.

The SPDP discovery is done in a best-effort manner, e.g., the participant announces his presence until it is approved [18]. The information of the discovered participants and the associated publications and subscriptions are stored in a local database on each participant. The SEDP protocol sends the endpoints' information for every participant in the local participant database and receives every discovered participant's endpoint information.

Once two participants discover each other, a reliable session is established. The information about each participant local DataWriters and DataReaders are exchanged. Participants end up with internal databases that contain lists of other participants and what each participant publishes or subscribes to.

The discovery process is never complete, it will always continue. Because newly created participants need to be discovered, and existing participants can be destroyed or disconnected, a discovery process is needed to ensure that the information is up-to-date.

For systems with 50 or more nodes, i.e., a large-scale system [10,13], the DomainParticipant in DDS may experience high network traffic and convergence time at start-up. The proposed idea is intended to be implemented for a naval warship that is a large-scale system and is likely to experience high network traffic and long convergence time. The convergence time is equal to the discovery time and therefore, it depends on the number of messages sent in the discovery process. Consequently, by reducing the information/message size, the proposed method can reduce the convergence time in the NCS.

In current SDPs for real-time middleware, each DDS participant sends his endpoint information to every participant, and receives endpoint information from all other participants. The CMS is used as the target example of this paper.

CMS is an example of distributed control system (DCS) for naval warships [6]. The CMS controls and manages all the information of the warship, e.g., weapons, artillery, and monitoring systems. To allow all devices to communicate accurately within the required time, a fast, robust network is required to connect all devices on the body of a naval combat system.

The CMS is adopted for the information management in the warship. As shown in Fig. 3
                        , the interface control units (ICUs) control the sensors and weapons in the CMS. All information is transferred through the combat system databus (CSDB) and controlled by the intelligence processing network (IPN) which works as the server of the system. Multi-function display control (MFC) is used as the monitoring system.

The CMS is categorized into four classes according to its nodes and participant number. The classes are small, medium, large, and huge. The smallest one, which has 25 nodes, is usually a patrol boat. A medium size CMS is a corvette ship with 50 nodes, while the large one is a frigate ship with 100 nodes, and the huge ship is a destroyer ship with 150 nodes. The details are presented in Table 1
                        .

In SDP, each participant sends his endpoint information to all other participants and receives endpoint information from all other participants. Each participant stores a full database of all of the endpoints in the system in order to check for a match if a new endpoint is added to it. If there is a new participant or endpoint, a message is sent to all other participants in the system. However, in a large network, most of these endpoints will not be needed by a given participant, thus unnecessary extra storage is used.

In SDP, each participant communicates directly with every other participant. Therefore, the number of messages sent or received by one participant is the number of messages sent and received during the SPDP multiplied by the number of the endpoints a participant has to inform another participant in the SEDP. This constitutes a huge number of messages, and it considerably increases the discovery time needed to discover all endpoints in the system. Therefore, to improve the performance of the discovery process in CMS using DDS, i.e., to reduce the discovery delay time, the number of messages sent and the message size in the discovery process need to be reduced.

As shown in Fig. 4
                        , the prototype model in CMS consists of a back-end system (BES), a front-end system (FES), and nodes. Here, the nodes in CMS can be considered as the endpoints of DDS; FES and BES as the participant. This system uses two BESs to ensure redundancy of the system in case one of the BESs is broken.

For this illustration, this paper used 30 FESs with an equal number of nodes for each FES and 2000 nodes/workstations for each FES. In other words, the system has 30 participants (P) with 2000 endpoints (E) for each participant (). Based on [11], the total number of endpoints can be calculated as
                           
                              (1)
                              
                                 
                                    
                                       N
                                       E
                                    
                                    =
                                    P
                                    ∗
                                    
                                       
                                          E
                                          /
                                          P
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

Using Eq. (1), the total number of endpoints becomes 30∗2000=60000 endpoints. If each time an endpoint sends or receives information counted as one message send and one message receive, then if all endpoints send and receive their information to all of the other endpoints, the total number of messages is given by
                           
                              (2)
                              
                                 
                                    
                                       N
                                       messages
                                    
                                    =
                                    2
                                    ∗
                                    
                                       
                                          E
                                          −
                                          1
                                       
                                    
                                    .
                                 
                              
                           
                        
                     

If a multicast network is used, the number of messages is calculated as,
                           
                              (3)
                              
                                 
                                    
                                       N
                                       
                                          m
                                          _
                                          messages
                                       
                                    
                                    =
                                    1
                                    +
                                    E
                                    .
                                 
                              
                           
                        
                     

By utilizing Eqs. (2) and (3), the total message number for unicast and multicast is approximately 120,000 and 60,000 (119,998 and 60,001 to be exact) respectively. Considering the sizes of all messages sent and received, these are a large number of messages to be sent and stored by each endpoint. Therefore, efficient information/message management scheme in the discovery process is needed.

This study combines the SDP process with the modified counting Bloom filter algorithm to reduce the number of messages sent and received in the discovery process. Detailed study on the Bloom filter and its applications are presented on citepref-0017, ref-0018, ref-0019, ref-0021, ref-0022, ref-0023, and ref-plus-2.

The proposed algorithm is shown as Algorithms 1–4. Algorithm 1 describes the proposed participant discovery scheme. In the discovery process, as shown by Figs. 5 and 6
                     
                     , instead of sending endpoint information, the participant sends filtered keys to other participants. This way, the size of information transferred through the network is reduced significantly. At the receivers' end, the key is then processed to find its match. If there are no matching topics among those participants, therefore, there is no need to store information from sender participant. If a matching key is found, then the next step is to check whether the received information tries to publish or subscribe information. If it does not, it is probably a false positive created by the Bloom filters, and therefore, there is no need to store the information on the receiver. As described in Algorithm 2, if the received key tries to publish or subscribe, then it is the correct matching topic between those participants, and the received information is stored for further publication or subscription process. Algorithm 3 describes the modified CBF construction. And Algorithm 4 describes the process to search item in the modified CBF.
                        Algorithm 1
                        Proposed participant discovery scheme
                              
                                 
                              
                           
                        

If a node/endpoint wants to leave the network, it will send a delete/exit message to its participant. The participant deleted the endpoint from the list and multicasts the information to all other participants. If the topic of interest between two endpoints is changed, then in standard SDP, all endpoints need to update their information, because they store all information of other endpoints. This is not a desirable behavior as it can burden the network because the endpoint information tends to change over time, sometimes in a short-period of time.
                        Algorithm 2
                        Proposed endpoint discovery scheme
                              
                                 
                              
                           
                        

To reduce the number of messages that needed to be sent, [11] used Bloom filters to map each endpoint information. This method succeeded in reducing the number of messages that needed to be sent. This method is good and fast, but Bloom filters cannot handle item deletion when there is a change in the network.

A standard Bloom filter is a hash-based data structure representing set of elements [19,20]. Compared to the hash table, the Bloom filters can further reduce the space requirements and allows the use of simpler hash function which saves the computational cost in lookup-intensive operations [21,22].

In the proposed method (Fig. 5), each participant collects information for each of his endpoints, and maps the information using modified counting Bloom filters that called a fast hash table. Then, each participant searches for matching mapped keys in the network. These mapped messages are sent to or received by another participant/endpoint instead of the unmapped information of each endpoint. Using this method, the number of messages that needs to be sent can be reduced, from information of all endpoints to information of only the matched mapped keys.

In the counting Bloom filters, each bit of the filter is replaced by a counter. Using a counter instead of single bit 0 or 1 prevents the deletion of important information if one or more keys are deleted from the table [23,24–26]. For a normal Bloom filters, the deletion of the key of the table means changing bit 1 to 0. This will change the bit information on the other key that shares the same hash key. However, by using a counter instead of a single bit, this problem can be solved. When there is a new message to store, it simply increases the counter number. Moreover, when a key is deleted, it simply decreases the counter number. Thus, information loss can be prevented when topic deletion occurs, i.e., one or more pieces of information are no longer desired. One point of difference between the existing counting Bloom filter method [23,24,25] and proposed method is that in the proposed method, some of the duplicated information created and stored by the counting Bloom filters are deleted, so that there is no duplicate information in the table. The deletion process is described in Algorithm 3 and the result is shown in Fig. 7
                     . This prevents false positives when the algorithm searches for matching information in the table, i.e., changing from the Bloom filters back to hash table. Thus faster processing of Bloom filters and zero false positive results of the hash table are achieved.
                        Algorithm 3
                        Modified CBF construction
                              
                                 
                              
                           
                        

Modified CBF search
                              
                                 
                              
                           
                        

Major discovery load occurs during the initialization of the DDS. Therefore, the simulation was performed during the initialization and setting-up of the discovery process. Hash table setup time and message delivery time were used as the simulation parameters. The simulation was performed using C programming by modifying the OpenDDS open-source code. The simulation to test for false positives was performed using a static table of size 128kb. To keep balance between less complexity and hash distribution uniformly, optimal number of hash function is calculated using k
                     =(m/n)ln(2) (with k is the number of hash function, m is the number of bits, and n is estimated number of elements to be inserted). Therefore three hash functions are used for each hashing algorithm. The delay time between filter construction time and hash table construction in a participant to the message arrival time in the other participants until it is discovered, i.e., acknowledged as part of the network, was measured. Table 1 shows the number of endpoints that was simulated.


                     Fig. 8
                      presents a delay time comparison between standard and proposed SDP to demonstrate the advantages of the proposed discovery scheme. The figure shows that the proposed discovery method is considerably faster than the standard SDP.

As the number of endpoints increases, the number of messages sent also increases. Therefore, the number of keys that needed to be stored in the table also increases. Fig. 9
                      shows the construction delay comparison between proposed method and several other algorithms. From Fig. 9, it can be seen that in terms of delay, Bloom filters and the proposed method show better results than the basic and optimized hash table algorithm. The delay time for the proposed algorithm is almost the same as the delay time for the Bloom filters, which is considered a fast method for storing information/keys in the table.


                     Fig. 10
                      shows the endpoint discovery delay time of the proposed method compared with other methods. The PDP delay time which consists of table construction and message delivery is shown in Fig. 11
                     . The total discovery delay is displayed in Fig. 12
                     .

The results show that the proposed method was superior to the hash table method and had similar results as the Bloom filters, similar to the case represented in Fig. 9. However, the proposed method ensures that there are no false positives unlike the Bloom filters. Therefore, the proposed method is better than the hash table in that it also ensures no false positive probability.


                     Tables 2 and 3
                     
                      present the delay time comparison for PDP and EDP for different CMS sizes. The tables show the delay time according to the number of endpoints/messages that are used in CMS with different sizes.


                     Fig. 13
                      shows comparison of number of false positive between proposed method and other methods discussed in this paper. Additionally Fig. 14
                      shows the value in percentage. The figures show that the false positive probability using the proposed method is zero, unlike the Bloom filters where the probability increased as the number of messages increased.

This paper proposes a modified counting Bloom filters for optimizing service discovery protocol in CMS for naval warship. Discovery process is a time consuming and resource hungry process in the DDS, especially in a network with many participants and endpoints. Therefore by combining the proposed algorithm with existing SDP, a more efficient discovery scheme is constructed. This discovery scheme reduces the message size sent in the discovery process and reduces the need to store the whole information in each endpoint and participant in the network. Therefore network traffic, delivery delay, and memory requirement can be reduced.

The simulation was performed by modifying the message discovery process of the OpenDDS. Simulation results showed that the proposed method outperformed the hash table algorithm for the discovery process. The false positive probability using modified CBF was better than the Bloom filters. The modified CBF has no possibility for false positives unlike the Bloom filters. Therefore, this paper contribution is the improvement of the performance of the previous SDPBloom using modified CBF for the discovery process in CMS network topologies by eliminating the false positive probability. The improvements were significant in scenarios with large numbers of endpoints per participant. The number of messages sent to the network was the same as the number of participants. Hence, the increase in the number of endpoints did not increase the number of sent messages.

The proposed discovery process still has several limitations that need to be overcome for dynamic environments of CMS. If there is a new endpoint/participant or deletion of endpoint/participant occurs, the modified CBF needs to be rebuilt from scratch, which is impractical in a dynamic environment. This paper uses the same number of endpoints per participant for each participant, which is not the case in a real CMS. Therefore, to justify the potential of the proposed algorithm better, the proposed algorithm needs to be tested for variable numbers of endpoints per participant using CMS message structure in an actual combat test environment.

@&#REFERENCES@&#


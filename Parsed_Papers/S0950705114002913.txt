@&#MAIN-TITLE@&#A novel hybrid intelligent approach for contractor default status prediction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel contractor default prediction model is proposed.


                        
                        
                           
                           The model is developed based on the SMOTE, LS-SVM, and DE algorithms.


                        
                        
                           
                           Historical cases were collected to construct and verify the model.


                        
                        
                           
                           Experimental results show that the model can deliver superior performance.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Hybrid intelligence

Financial default prediction

Least Squares Support Vector Machine

Differential Evolution

Imbalanced classification

@&#ABSTRACT@&#


               
               
                  In the construction industry, evaluating the financial status of a contractor is a challenging task due to the myriad of the input data as well as the complexity of the working environment. This article presents a novel hybrid intelligent approach named as Evolutionary Least Squares Support Vector Machine Inference Model for Predicting Contractor Default Status (ELSIM-PCDS). The proposed ELSIM-PCDS is established by hybridizing the Synthetic Minority Over-sampling Technique (SMOTE), Least Squares Support Vector Machine (LS-SVM), and Differential Evolution (DE) algorithms. In this new paradigm, the SMOTE is specifically used to deal with the imbalanced classification problem. The LS-SVM acts as a supervised learning technique for learning the classification boundary that separates the default and non-default contractors. Additionally, the DE algorithm automatically searches for the optimal parameters of the classification model. Experimental results have demonstrated that the classification performance of the ELSIM-PCDS is better than that of other benchmark methods. Therefore, the proposed hybrid approach is a promising alternative for predicting contractor default status.
               
            

@&#INTRODUCTION@&#

Construction contractors are vulnerable to financial distress or bankruptcy due to the complex and uncertain nature of the construction industry. Hence, the failure rate among construction companies often reaches a high level [1,2]. One of the main reasons behind this high level of business failure is the construction managers’ inadequate knowledge of financial management.

Therefore, investigating business failures in construction industry is undoubtedly an important research area for comprehending financial health as well as forecasting the financial status of a construction company. In addition, it is necessary for governments, construction owners, lending institutions, surety underwriters, investors, prime contractors, and sub-contractors to early identify companies that have high risk of bankruptcy [3–5].

In practice, the increase of project scale and technical complexity often lead to the collaboration of many contractors to accomplish a construction project. Thus, the cooperation among stakeholders in the industry is very crucial for achieving the project goal. Within this context, assessing financial status can provide an early warning mechanism for monitoring contractors’ financial performances [6].

Some approaches have been applied to evaluate and forecast a company financial status. The previous methods include the multivariate discriminant analysis (MDA) [7], the logistic regression (LR) [8], etc. The market-based approaches were also used to model financial behaviors including the Merton model [9], the barrier option model [10], and other integrated methods [11]. Notably, those aforementioned approaches employ the managerial and economic variables, which are subjective and qualitative, for assessing the financial solvency of companies. Recently, artificial intelligence (AI) has been demonstrated to be a reliable approach for financial status appraisal. Artificial neural network (ANN) and support vector machine (SVM) have been utilized for financial distress forecasting [12–14]. Previous researches [4,13] have shown that the ANN and the SVM can outperform the conventional LR and MDA approaches.

Nevertheless, the implementations of the ANN and SVM algorithms are exposed to several drawbacks. The major disadvantage of the ANN approach is that its training process is achieved through a gradient descent algorithm on the error space, which can be very complex and may contain many local minima [15]. Meanwhile, SVM training process entails solving a quadratic programming problem subjected to inequality constraints. This means that the SVM training processes for large data sets require expensive computational costs [16].

To overcome the drawbacks of the ANN and the SVM, the LS-SVM has been recently proposed by Suykens et al. [17]. The LS-SVM can be considered as an improved version of the SVM to alleviate the burden of computational expenses. In the LS-SVM’s training process, a least squares cost function is proposed to obtain a linear set of equations in the dual space. Consequently, to derive the solution, it is needed to solve a set of linear equations, instead of a quadratic programming problem as in the standard SVM. Moreover, this linear system can be efficiently solved by iterative methods such as the conjugate gradient algorithm [18]. Studies have been carried out to demonstrate the excellent generalization, prediction accuracy, and fast computation of the LS-SVM approach [19–23]. Nevertheless, the application of the LS-SVM in financial default prediction has not been investigated.

Furthermore, it is worth noticing that the LS-SVM tuning parameters play an important role in the process of model establishment [17]. These parameters control the model’s complexity, and they should be determined properly. Herein, the main objective is to obtain a model that can explore the underlying input–output mapping relationship and is capable of yielding the best predictive performance on the new data [24]. In this study, the DE algorithm, a population-based stochastic search engine proposed by Storn and Price [25], is employed to achieve such objective.

In addition, previous studies on default prediction of construction firms typically used the sample match method, which matches a set of defaulted companies with the same number or some multiple of healthy firms [8,26]. However, the sample match method may result in biased predictive results [27]. These biased results will lead to the untrustworthy predictions of sample data. To avoid such biases, some researches abandon the sample match method and put all available firm-years data to represent the financial condition of construction companies [4,11,28]. Nevertheless, this approach leads to the circumstance in which the number of non-defaulted samples greatly exceeds the number of defaulted samples. This circumstance is widely known as the class imbalance problem. Thus, an oversampling technique of defaulted samples based on the Synthetic Minority Over-sampling Technique (SMOTE) [29] is employed in this study to alleviate the aforementioned problem.

Therefore, this study proposes to hybridize the SMOTE, LS-SVM, and DE algorithms to establish a novel contractor default status prediction model named as ELSIM-PCDS. The capability of the new model is compared with that of other AI approaches. The rest of this article is organized as follows. The second section reviews related literature on default status prediction, the LS-SVM, the DE, and the SMOTE. The third section presents the data collection process. The fourth section depicts the frameworks of the hybrid model. The fifth section reports the experimental result. The conclusion of this study is stated in the final section.

@&#LITERATURE REVIEW@&#

In various industries, many studies regarding business failure prediction have been conducted [4,30]. Those studies used several terms to define business failure of a company which are insolvency, bankruptcy, and default. In general, the term ‘business failure’ can be understood as an actual economic loss suffered on the part of the creditor [31]. However, business failure is a gradual process. Financial distress could pass through four stages of deterioration before the announcement of bankruptcy: incubation, cash shortage, financial insolvency, and total insolvency [32]. Therefore, it is desirable to recognize the potential bankruptcy of a company as early as possible.

Moreover, understanding the characteristic and mechanism of failure is essential for predicting business failures. Tserng et al. mentioned four characteristics of the construction industry which potentially lead to financial problems [4]: First, the construction industry is easily influenced by economic situations and strategies among contractors to win bid contracts; and it leans towards the poor financial stability of the contractor. Second, the contractor can suffer from the insufficient liquidity when the material inventory cannot be realized into cash because of contract disputes. Third, interest rates of long-term and short-term financial instruments in applying advanced payments and supplying materials/equipments are relatively high; and this fact can bring about capital instabilities. The last characteristic is the long completion time of a construction project which is used to assess the project revenue. Therefore, the combination of the construction industry’s risky nature and the over-optimism in revenue assessment may cause the liquidity insufficiency for contractors.

This section describes the formulation of the LS-SVM for solving classification problems. In the historical data, given a training dataset 
                           
                              
                                 
                                    {
                                    
                                       
                                          x
                                       
                                       
                                          k
                                       
                                    
                                    ,
                                    
                                       
                                          y
                                       
                                       
                                          k
                                       
                                    
                                    }
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 
                                    N
                                 
                              
                           
                         with input data xk
                        
                        ∈
                        Rn
                         where N is the number of training data points, n denotes the data dimension, and the corresponding class labels is defined as yk
                        
                        ∈{−1, +1} the LS-SVM formulation for classification is presented as follows [33,34]:
                           
                              (1)
                              
                                 Minimize
                                 
                                 
                                    
                                       J
                                    
                                    
                                       p
                                    
                                 
                                 (
                                 w
                                 ,
                                 e
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       w
                                    
                                    
                                       T
                                    
                                 
                                 w
                                 +
                                 γ
                                 
                                    
                                       1
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 
                                    
                                       e
                                    
                                    
                                       k
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 Subjected to
                                 
                                 
                                 
                                    
                                       y
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       w
                                    
                                    
                                       T
                                    
                                 
                                 ϕ
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                                 )
                                 +
                                 b
                                 )
                                 =
                                 1
                                 -
                                 
                                    
                                       e
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 
                                 k
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                              
                           
                        where w
                        ∈
                        Rn
                         is the normal vector to the classification hyperplane and b
                        ∈
                        R is the bias; ek
                        
                        ∈
                        R are error variables; γ
                        >0 denotes a regularization constant.

The Lagrangian is given by:
                           
                              (3)
                              
                                 L
                                 (
                                 w
                                 ,
                                 b
                                 ,
                                 e
                                 ,
                                 a
                                 )
                                 =
                                 
                                    
                                       J
                                    
                                    
                                       p
                                    
                                 
                                 (
                                 w
                                 ,
                                 e
                                 )
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          N
                                       
                                    
                                 
                                 
                                    
                                       α
                                    
                                    
                                       k
                                    
                                 
                                 {
                                 
                                    
                                       y
                                    
                                    
                                       k
                                    
                                 
                                 (
                                 
                                    
                                       w
                                    
                                    
                                       T
                                    
                                 
                                 ϕ
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                                 )
                                 +
                                 b
                                 )
                                 -
                                 1
                                 +
                                 
                                    
                                       e
                                    
                                    
                                       k
                                    
                                 
                                 }
                              
                           
                        where αk
                         are Lagrange multipliers; ϕ(xk
                        ) represents a kernel function. The conditions of optimality can be stated as follows:
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         L
                                                      
                                                      
                                                         ∂
                                                         w
                                                      
                                                   
                                                   =
                                                   0
                                                   →
                                                   w
                                                   =
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            k
                                                            =
                                                            1
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         α
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   ϕ
                                                   (
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   )
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         L
                                                      
                                                      
                                                         ∂
                                                         b
                                                      
                                                   
                                                   =
                                                   0
                                                   →
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            k
                                                            =
                                                            1
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         α
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   0
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         L
                                                      
                                                      
                                                         ∂
                                                         
                                                            
                                                               e
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                      
                                                   
                                                   =
                                                   0
                                                   →
                                                   
                                                      
                                                         α
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   γ
                                                   
                                                   
                                                      
                                                         e
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   ,
                                                   
                                                   k
                                                   =
                                                   1
                                                   ,
                                                   …
                                                   ,
                                                   N
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         ∂
                                                         L
                                                      
                                                      
                                                         ∂
                                                         
                                                            
                                                               α
                                                            
                                                            
                                                               k
                                                            
                                                         
                                                      
                                                   
                                                   =
                                                   0
                                                   →
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   (
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                   ϕ
                                                   (
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   )
                                                   +
                                                   b
                                                   )
                                                   -
                                                   1
                                                   +
                                                   
                                                      
                                                         e
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   =
                                                   0
                                                   ,
                                                   
                                                   k
                                                   =
                                                   1
                                                   ,
                                                   …
                                                   ,
                                                   N
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

The linear system below is obtained after the elimination of e and w:
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      
                                                         y
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   y
                                                
                                                
                                                   ω
                                                   +
                                                   
                                                      
                                                         γ
                                                      
                                                      
                                                         -
                                                         1
                                                      
                                                   
                                                   I
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   b
                                                
                                             
                                             
                                                
                                                   α
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         1
                                                      
                                                      
                                                         v
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        which y
                        =
                        y
                        1,…,
                        yN
                        ,1
                           v
                        
                        =[1;…; 1], and α
                        =[α
                        1;…; αN
                        ]. And the kernel function is applied as follows:
                           
                              (6)
                              
                                 ω
                                 =
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       y
                                    
                                    
                                       j
                                    
                                 
                                 ϕ
                                 
                                    
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             k
                                          
                                       
                                       )
                                    
                                    
                                       T
                                    
                                 
                                 ϕ
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       y
                                    
                                    
                                       j
                                    
                                 
                                 K
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 )
                              
                           
                        
                     

The resulting LS-SVM model is as follows:
                           
                              (7)
                              
                                 y
                                 (
                                 x
                                 )
                                 =
                                 sign
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   N
                                                
                                             
                                          
                                          
                                             
                                                α
                                             
                                             
                                                k
                                             
                                          
                                          
                                             
                                                y
                                             
                                             
                                                i
                                             
                                          
                                          K
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                k
                                             
                                          
                                          ,
                                          
                                             
                                                x
                                             
                                             
                                                1
                                             
                                          
                                          )
                                          +
                                          b
                                       
                                    
                                 
                              
                           
                        where αk
                         and b are the solution to the linear system (2.5). The kernel function that is commonly used is Radial Basis Function (RBF) kernel, which is described as follows:
                           
                              (8)
                              
                                 K
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       b
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 )
                                 =
                                 exp
                                 
                                    
                                       
                                          
                                             
                                                ‖
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      k
                                                   
                                                
                                                -
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      1
                                                   
                                                
                                                
                                                   
                                                      ‖
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                             
                                                2
                                                
                                                   
                                                      σ
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where σ is the kernel function parameter.

The DE, proposed by Storn and Price [35], is a population-based stochastic search engine that efficient and effective for global optimization in the continuous domain. The algorithm (see Fig. 1
                        ) is composed of from five main stages: mutation, crossover, and selection operators at each generation to move its population toward the global optimum, and stopping condition verification. Superior performance of the DE algorithm, in terms of accuracy and fast operation, has been verified in many reported research works [35–40]. Considering a problem of minimizing a cost function f(X), where the number of decision variables is D, we can describe each stages of the DE algorithm in details.

The DE starts its searching process by randomly generating NP number of D-dimensional parameter vectors Xi,g
                            where i
                           =1, 2, …, NP and g as the current generation. In the DE algorithm, NP does not change during the optimization process [36]. Moreover, the initial population (at g
                           =0) has to cover all of search space in a uniform manner. Therefore, the following random initialization can be used:
                              
                                 (9)
                                 
                                    
                                       
                                          X
                                       
                                       
                                          i
                                          ,
                                          0
                                       
                                    
                                    =
                                    LB
                                    +
                                    rand
                                    [
                                    0
                                    ,
                                    1
                                    ]
                                    ×
                                    (
                                    UB
                                    -
                                    LB
                                    )
                                 
                              
                           where Xi
                           
                           ,0 is the decision variable i at the first generation. rand[0,1] represents a uniformly distributed random number between 0 and 1. LB and UB are two vectors of lower bound and upper bound for any decision variable.

A vector in the current population (or parent) is defines as a target vector. The terms ‘parent vector’ and ‘target vector’ can be used interchangeably. For each target vector, a mutant vector is produced by the following equation:
                              
                                 (10)
                                 
                                    
                                       
                                          V
                                       
                                       
                                          i
                                          ,
                                          g
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          X
                                       
                                       
                                          r
                                          1
                                          ,
                                          g
                                       
                                    
                                    +
                                    F
                                    (
                                    
                                       
                                          X
                                       
                                       
                                          r
                                          2
                                          ,
                                          g
                                       
                                    
                                    -
                                    
                                       
                                          X
                                       
                                       
                                          r
                                          3
                                          ,
                                          g
                                       
                                    
                                    )
                                 
                              
                           where r1, r2, and r3 are three random indexes lying between 1 and NP. Xr
                           
                           1
                           
                              ,g
                           , Xr
                           
                           2,
                           
                              g
                            and Xr
                           
                           3,
                           
                              g
                            represent three random vectors in the current generation g. These three randomly chosen integers are also selected to be different from the index i of the target vector. F denotes the mutation scale factor, which controls the amplification of the differential variation between Xr2,g
                            and Xr
                           
                           3,
                           
                              g
                           . Vi,g
                           
                           +1 represents the newly created mutant vector.

The aim of the crossover stage is to diversify the current population by exchanging components of a target vector and a mutant vector. In this stage, a new vector, named as the trial vector, is created as in the following manner:
                              
                                 (11)
                                 
                                    
                                       
                                          U
                                       
                                       
                                          j
                                          ,
                                          i
                                          ,
                                          g
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            V
                                                         
                                                         
                                                            j
                                                            ,
                                                            i
                                                            ,
                                                            g
                                                            +
                                                            1
                                                         
                                                      
                                                      ,
                                                      
                                                      if
                                                      
                                                      
                                                         
                                                            rand
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ⩽
                                                      Cr
                                                      
                                                      or
                                                      
                                                      j
                                                      =
                                                      rnb
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            X
                                                         
                                                         
                                                            j
                                                            ,
                                                            i
                                                            ,
                                                            g
                                                            +
                                                            1
                                                         
                                                      
                                                      ,
                                                      
                                                      if
                                                      
                                                      
                                                         
                                                            rand
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      >
                                                      Cr
                                                      
                                                      or
                                                      
                                                      i
                                                      ≠
                                                      rnb
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where Uj,i,g
                           
                           +1 is the trial vector. j represents the index of element for any vector. randj
                            is a uniform random number lying between 0 and 1. Cr is the crossover probability, which is needed to be determined by the user. rnb(i) denotes a randomly chosen index of [1,2,…,
                           NP] which guarantees that at least one parameter from the mutant vector (Vj,i,g
                           
                           +1) is copied to the trial vector (Uj,i,g
                           
                           +1).

The trial vector is compared to the target vector. If the trial vector can yield a lower objective function value than that of its parent, the trial vector replaces the target vector. The selection operator is defines as follows:
                              
                                 (12)
                                 
                                    
                                       
                                          X
                                       
                                       
                                          j
                                          ,
                                          i
                                          ,
                                          g
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            U
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      
                                                      if
                                                      
                                                      f
                                                      (
                                                      
                                                         
                                                            U
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      )
                                                      ⩽
                                                      f
                                                      (
                                                      
                                                         
                                                            X
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      )
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            X
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      ,
                                                      
                                                      if
                                                      
                                                      f
                                                      (
                                                      
                                                         
                                                            U
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      )
                                                      >
                                                      f
                                                      (
                                                      
                                                         
                                                            X
                                                         
                                                         
                                                            i
                                                            ,
                                                            g
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where Xi,g
                            denotes the target vector in generation g; Xi,g
                           
                           +1 represents the target vector in the next generation g
                           +1; Ui,g
                            is the trial vector.

The optimization process terminates when the stopping criterion is achieved. The type of this condition can be specified by users. Generally, maximum generation (Gmax
                           ) can be used as the stopping condition. When the optimization process terminates, the final optimal solution can be attained.

In the field of data-mining, a dataset can be considered to be imbalanced if the classification categories are not approximately equally represented. In fact, many real-world classification problems are imbalanced problems in which small percentage of “abnormal” or “rare” cases dominated by a large number of normal cases (e.g., infrequent disease, fraudulent telephone calls, oil spills, structure collapses etc.) [41–43].

The SMOTE is an approach proposed by Chawla [41] to tackle classification problems with imbalanced datasets. The SMOTE re-samples the original dataset by creating synthetic samples of the minority class. The amount of synthetic samples depends on the number of nearest neighbors (k) and the required oversampled amount (N%). Each of k-points within the minority class is oversampled by matching with its nearest neighbors. When the nearest neighbors are randomly selected, the synthetic samples are generated along the segments line in each direction between original points of the minority class. The position of a synthetic sample is determined by a random number between 0 and 1 multiplied by the distance between the original minority sample and its nearest neighbor. Thus, this approach is capable of generalizing minority samples in the data space. An illustration of the SMOTE is provided in Fig. 2
                        . Additionally, a pseudo-code of the SMOTE is shown in the following section.
                           
                              
                                 
                                 
                                    
                                       
                                          Algorithm SMOTE (
                                             T; N; k
                                          )
                                    
                                    
                                       
                                          Input: Number of minority class samples T; Amount of SMOTE N%; Number of nearest neighbors k
                                       
                                    
                                    
                                       
                                          Output: (N/100)×
                                          T synthetic minority class samples
                                    
                                    
                                       # Set up initial parameter
                                    
                                    
                                       1. N
                                          =(int)(N
                                          =100) (The amount of SMOTE is assumed to be in integral multiples of 100)
                                    
                                    
                                       2. k
                                          =Number of nearest neighbors
                                    
                                    
                                       3. numattrs
                                          =Number of attributes
                                    
                                    
                                       4. Sample[ ][ ]: array for original minority class samples
                                    
                                    
                                       5. newindex: keeps a count of number of synthetic samples generated, initialized to 0
                                    
                                    
                                       6. Synthetic[ ][ ]: array for synthetic samples (Compute k nearest neighbors for each minority class sample only)
                                    
                                    
                                       # Select each of minority class and compute k nearest neighbors
                                    
                                    
                                       7. for 
                                          i
                                          ←1 to 
                                          T
                                       
                                    
                                    
                                       8.Compute k nearest neighbors for i, and save the indices in the nnarray
                                    
                                    
                                       9.Populate(N, i, nnarray)
                                    
                                    
                                       10. endfor
                                       
                                    
                                    
                                       # Generate the synthetic samples
                                    
                                    
                                       Populate(N; i; nnarray)
                                    
                                    
                                       11. while N <> 0
                                    
                                    
                                       12.Choose a random number between 1 and k, call it nn. This step chooses one of the k nearest neighbors of i.
                                    
                                    
                                       13.
                                          for attr ← 1 to numattrs
                                    
                                    
                                       14.
                                          Compute: dif
                                          =
                                          Sample[nnarray[nn]][attr] – Sample[i][attr]
                                    
                                    
                                       15.
                                          Compute: gap
                                          =random number between 0 and 1
                                    
                                    
                                       16.
                                          
                                          Synthetic[newindex][attr]=
                                          Sample[i][attr]+
                                          gap
                                          ×
                                          dif
                                       
                                    
                                    
                                       17.
                                          endfor
                                       
                                    
                                    
                                       18.
                                          newindex++
                                    
                                    
                                       19.
                                          N
                                          =
                                          N
                                          –1
                                    
                                    
                                       20. endwhile
                                       
                                    
                                    
                                       21. return (End of Populate)
                                    
                                 
                              
                           
                        
                     

This research utilizes a database of construction companies collected from the Wharton Research Data Services 2011. The selected companies were categorized by construction types defined in the Standard Industrial Classification (SIC) numerical codes which range from 1500 to 1799. In addition, it is noted that financial data is recorded at fiscal year-ends. The selected contractors include three construction categories: SIC code 1500–1599 (for building construction, general contractors, and operative builders), SIC code 1600–1699 (for heavy construction other than building construction contractors), and SIC code 1700–1799 (for construction special trade contractors) [44].

It is noted that all available financial firm data are considered in this research. The time period of available financial data ranges from 1970 to 2011. According to a previous research of Tserng et al. [4], several assumptions are considered when selecting data samples. The criteria of selecting samples can be stated as follows:
                        
                           •
                           First, contractors that do not have financial statements for at least two years are removed from the sample.

Second, the data must be available in the Center for Research in Securities Prices (CRSP) for at least two years prior to default time for data completeness.

Third, default is defined by the CRSP delisting code of 400 and 550 to 585. The defaulted firms are those de-listed because of bankruptcy, liquidation, or poor performance [10,45]. The definition of default in this research indicates a default event which leads to financial problem of construction contractor. The default company data in this study is addressed to predict the default status 1year before company goes to bankrupt. Therefore, financial data in the year before being de-listed are determined as default samples.

Financial items in database are listed in financial statements including balance sheets, income statements, and statements of cash flows. The financial ratios are then calculated from the financial statement. Financial ratios can be employed to describe financial characteristics and to evaluate performances of construction companies. Moreover, the selected financial items can serve as indicators for deriving financial ratios which later become input attributes of a default prediction model.

Twenty financial ratios are selected in this research as input attributes for default prediction. Financial ratios and their financial items can be seen in Table 1
                      and the detailed equations used for computing these ratios can be seen on Table 2
                     . These attributes were selected for the following reasons. First, all of the variables have been used in previous studies involving contractor default status prediction [4,8,26,46,47]. Second, these variables encompass a broad cross-section of accounting ratios; and these ratios describe a contractor’s liquidity, leverage, activity, and profitability [4].

Moreover, in order to select a limited number of variables, a Multivariate Discriminant Analysis (MDA) stepwise method [4,48] is employed in this research as a feature selection algorithm. The 7 variables selected by the MDA stepwise method are: (3) Net Working Capital to Total Assets, (12) Sales to Net Worth, (15) Turnover of Total Assets, (16) Revenues to Fixed Assets, (17) Return on Assets (ROA), (18) Return on Equity (ROE), and (20) Profits to Net Working Capital.

This section describes the proposed contractor default status prediction model named as ELSIM-PCDS in detail. The model (see Fig. 3
                     ) is established by an integration of the SMOTE, LS-SVM, and DE algorithms. The ELSIM-PCDS employs the SMOTE to cope with the imbalance classification problem. The LS-SVM acts as a supervised learning tool to handle complex input–output mapping. The DE optimization technique is deployed to simultaneously identify the optimal values of the LS-SVM’s tuning parameters: the regularization parameter (γ) and the RBF kernel parameter (σ). The architecture of the hybrid framework is shown in Fig. 3. The operation of the ELSIM-PCDS is described in the following section.
                        
                           (1)
                           
                              Data collection and data processing: In this stage, the original datasets are collected and preprocessed. This research investigates 76 construction contractors within which 63 contractors are non-defaulted and 13 contractors are defaulted. Financial data of each contractor are summarized and recorded yearly; in total, 958 firm-year observations have been collected. A statistical summary of input variables used for predicting default status is shown in Table 3
                              .


                              Imbalanced input data: It is noted that the dataset consists of 945 non-default and 13 default records. The ratio of non-default and default samples is 945:13. Thus, when considering all the firm-years data, the number of non-default samples greatly exceeds the number of default samples. This circumstance is known as the imbalanced classification problem.


                              Oversampling of minority data samples: Over-sampling technique by the SMOTE algorithm is used to obtain a balanced dataset. In this study, the number of nearest neighbors (k) depends on the number of minority class which is 13 samples. The oversampling amount (N) is selected to achieve the most balanced instances between the two classes: ‘default’ and ‘non-default’. Hence, the oversampling amount is selected to be 7300%.


                              Balanced input data: After being processed by the SMOTE, the number of samples in the minority class becomes 12×73=949. Therefore, the ratio of non-default and default samples becomes 945:949 and there are 1894 firm-year records used for analysis.


                              Data separation: The data obtained from the previous steps is randomly divided into data set 1 and data set 2. The data set 1 which is used to construct the prediction model is again separated into training set (80%) and validating set (20%). Meanwhile, data set 2 contains testing cases which are reserved for verifying the model performance.


                              Tuning parameter initialization: The aforementioned tuning parameters γ and σ of the LS-SVM are randomly generated within the range of lower and upper boundaries. The lower and upper boundaries of parameters are 10−5 and 105, respectively.


                              LSSVM training: In this step, the LS-SVM is deployed to learn the decision boundary to separate input data into two classes. The classes of default and non-default companies are denoted as the positive class (+1) and the negative class (−1), respectively.


                              DE searching: The DE search engine executes the mutation, crossover and selection processes at each generation to guide the population of model tuning parameters to the final optimal solution.


                              Fitness function evaluation: Herein, the objective is to determine the optimal set of tuning parameters. To evaluate the classification performance, the receiver operating characteristic (ROC) curve is employed [4,41,49]. Using this approach, the area under ROC curve, or the area under the curve (AUC), is calculated. Moreover, it is noted that a higher AUC value indicates a better predictive performance. Thus, the following objective function is used in the step of fitness evaluation:


                     
                        
                           (10)
                           
                              Stopping condition: The DE’s optimization process terminates when the maximum number of generation is achieved.


                              Optimal prediction model: When the program terminates, the optimal set of tuning parameters can be identified. The model is ready to forecast new input patterns.

In this section, the database consisting of 1894 records was used to train and test the prediction model. Moreover, to avoid the randomness when selecting testing cases, the fivefold cross validation is deployed to examine the prediction model performance. Using the cross validation procedure, the database is divided into five mutually exclusive data sets (see Fig. 4
                     ). In each run, one data set served as testing cases; meanwhile, the rest of data sets are used to train the model. The model performance can be appraised by the average predictive result of the five subsamples. Therefore, this approach can avoid bias in data sampling and accurately evaluate the performance of the prediction model. It is noted that the fivefold cross validation process is used to appraise the capability of the proposed ELSIM-PCDS as well as other benchmark approaches including the SVM and the ANN.

As aforementioned, this research utilizes the Receiver Operating Characteristic (ROC) curve to evaluate ELSIM-PCDS prediction capability. In addition, the SVM and the ANN are utilized as benchmark methods. It is noted that when using the ANN, the user needs to set the number of hidden layers, the number of neurons in the hidden layer, and the learning rate [50]. These parameters of the ANN are selected via repetitive trial-and-error processes. The network configuration is specified as follows: the number of hidden layers is 1; the number of neurons in the hidden layer is set to be equal to the dimension of the input variables; and the learning rate is 1. When using the SVM, there are two tuning parameters needed to be determined: the penalty parameter (C) and the kernel parameter (γ). As recommended by Hsu et al. [51], the parameter C and γ are set to be 1 and 1/D, respectively; herein, D denotes the dimension of the input variables.

For the purpose of result comparison, the area under the ROC curve, or the area under the curve (AUC), is computed. An AUC is a portion of the area of the unit squares, its value will always be between 0.0 and 1.0 [52]. It is worth noticing that higher the AUC value better is the model prediction performance. Generally, a classifier with perfect predictive ability has an AUC of 1; meanwhile, a classifier with random predictions has an AUC of 0.5 [4,53]. Moreover, an AUC of the range (0.7, 0.8) indicates an acceptable classification performance. If 0.8⩽AUC⩽0.9, an excellent classification performance is attained. And, if AUC⩾0.9, the classifier has achieved an outstanding performance.

In the first experiment, 958 data cases are randomly divided into training set (80%) and testing set (20%). Moreover, the data sets are divided so that each of the two sets contains approximately 50% of the default cases. It is noted that the SMOTE is not implemented in this experiment. The experimental results, for case 1 (using 20 variables) and case 2 (using 7 variables), are shown in Table 4
                     . In this experiment, the ELSIM is an integration of the LS-SVM and DE algorithms [22]; the LS-SVM acts as a classifier and the DE is used to optimize the LS-SVM’s tuning parameters. It can be seen that without the SMOTE, all of the three approaches (the ELSIM, the SVM, and the ANN) suffer from the imbalanced classification problem and deliver poor predictive performances (AUC=0.5 for testing data cases).

In the second experiment, the SMOTE is employed to deal with the problem of imbalance dataset. The experimental result of this experiment is summarized in Table 5
                     . The predictive performances in terms of AUC values of the ELSIM-PCDS, SVM, and ANN methods for training and testing data are provided. Table 5 illustrates that the prediction outcome of the ELSIM-PCDS is more accurate than that of the SVM and ANN approaches.

When using 20 input variables, the proposed method achieves the average AUC value of 0.985 for the testing data. Meanwhile, the average testing results of the SVM and the ANN are 0.917 and 0.750, respectively. In the case 2 of the second experiment which takes into account 7 input variables, the average AUC value for the testing data of the ELSIM-PCDS, SVM, and ANN models are 0.989, 0.922, and 0.752, respectively. These facts indicate a significant improvement of the new method over the two benchmark approaches. Furthermore, it can be concluded from the experiment that by applying the MDA stepwise method, the predictive performances of the machine learning models can be maintained with a smaller set of input variables.

In addition, verifying the prediction model with the real default company data is also conducted in the third experiment of this research. Predicting samples which belong to the minority class is performed by utilizing the real default samples in the testing data. In this experiment, all of the real default data cases are utilized as testing data. Meanwhile, the rest of the data cases (including data cases generated by the SMOTE) are employed as training data. The numbers of correctly predicted default cases obtained from the ELSIM-PCDS, SVM, and ANN methods are 12, 11, and 10 for the both cases of variable selection. It is worth reminding that the total number of real default cases in the database is 13. Thus, the prediction accuracy rates of the ELSIM-PCDS, SVM, and ANN approaches are 92.31%, 84.62%, and 76.92%, respectively. These facts convincingly prove that the proposed ELSIM-PCDS is an effective and reliable technique to help deal with the imbalance classification problem in contractor default status prediction.

@&#CONCLUSION@&#

This study has proposed a novel hybrid intelligence model, named as ELSIM-PCDS, for predicting construction contractor default status. This research has employed all available firm-year financial data to avoid the bias in sample selection. Moreover, the MDA stepwise method has been applied for feature selection and the SMOTE is integrated into the intelligence model to overcome the imbalanced classification problem. The proposed ELSIM-PCDS utilizes the LS-SVM for classifying data in high dimensional input space and the DE as a searching algorithm to identify the most appropriate tuning parameters of the LS-SVM.

Consequently, the newly developed approach can alleviate human intervention in parameter setting and it can be used by practitioners without AI domain knowledge. In addition, to evaluate and validate predicting ability of the new model, the SVM and the ANN are used as benchmark approaches. As shown in the empirical results, the ELSIM-PCDS has achieved the most desirable predictive performance. Therefore, the new hybrid method is a promising alternative to help decision makers in dealing with contractor financial status prediction.

Since the ELSIM-PCDS is a hybrid model, the approach can be quiet complex to establish. However, since the construction industry is inherently complicated and context-dependent, predicting financial health of a construction contractor is by no means an easy task. Therefore, it is virtually infeasible to construct a simple model that yields gratifying forecasting results. With a more effort on software engineering, a user-friendly interface can be developed and integrated into the ELSIM-PCDS, and this enables the hybrid intelligent model to be an easily operated tool for the practitioners to solve the problem at hand. Additionally, the future directions of this research may include the application of other advanced machine learning techniques and novel feature selection methods for predicting contractor default status.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Extending helicopter operations to meet future integrated transportation needs

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Work Domain Analysis was used for concept design.


                        
                        
                           
                           A Head Up Display (HUD) was developed to assist pilots landing in degraded visual conditions.


                        
                        
                           
                           The HUD increased awareness and reduced workload in degraded conditions.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Helicopters

Head up display

Cognitive work analysis

@&#ABSTRACT@&#


               
               
                  Helicopters have the potential to be an integral part of the future transport system. They offer a means of rapid transit in an overly populated transport environment. However, one of the biggest limitations on rotary wing flight is their inability to fly in degraded visual conditions in the critical phases of approach and landing. This paper presents a study that developed and evaluated a Head up Display (HUD) to assist rotary wing pilots by extending landing to degraded visual conditions. The HUD was developed with the assistance of the Cognitive Work Analysis method as an approach for analysing the cognitive work of landing the helicopter. The HUD was tested in a fixed based flight simulator with qualified helicopter pilots. A qualitative analysis to assess situation awareness and workload found that the HUD enabled safe landing in degraded conditions whilst simultaneously enhancing situation awareness and reducing workload. Continued development in this area has the potential to extend the operational capability of helicopters in the future.
               
            

@&#INTRODUCTION@&#

In most cities the dominant car-road transport system is already reaching a saturation point (Tibbs, 1998). This issue is going to be exacerbated when we consider that by 2040 the world's population is expected to reach nine billion, with 64% of the world living in urban areas (Ministry of Transport (2013)). Therefore, the future transport environment is an issue that concerns us all, whether a car owner or a regular user of public transport, increased demands on the current transport infrastructure means that the future transport system will look very different from today. Tibbs (1998) argued that scenarios for future transport systems need to address the likelihood of a fundamental shift away from the car-road system. In the 1950s it was predicted that rotorcraft would be essential in the transport systems of overly populated countries before the end of the 20th century, but they have not realised their full potential in industrialised countries (British Helicopter Association, BHA, 2014). There are more helicopters in military service than civilian operation and commercial passenger-carrying operations are generally confined to corporate or offshore domains. The unique characteristics of helicopters means that they have the potential to result in radical changes to the urban transport environment (Dodge and Brooks, 2013). Increased helicopter transport is already evident in a recent review by the National Transport Safety Board (NTSB, 2011) which reported that in relation to air taxi operations between 2004 and 2010 helicopter flight activities increased by 97 percent while fixed wing flight activity decreased by 28 percent. Currently, one of the biggest limitations on rotary wing flight is their inability to fly safely in degraded visual environments (DVE) during critical phases of flight (such as approach and landing). This paper presents a study that developed and evaluated a Head up Display (HUD) concept to assist rotary wing pilots landing in DVE. The HUD was developed with the assistance of Work Domain Analysis phase of the Cognitive Work Analysis method as an approach for analysing the cognitive work of landing the helicopter in order to identify the critical information requirements associated with this task.

The current operational environment for helicopters varies greatly with role, but helicopters generally operate outside of direct air traffic control, at low altitudes and under visual flying conditions (BHA, 2014). This means that helicopters are used in operational contexts that are not suitable for fixed wing aircraft, including medical rescue over land, search and rescue over water or mountains, rapid corporate passenger transfer, oil platform transfer, police search, television broadcasting and firefighting. Helicopters tend to perform take-off and landing manoeuvres that are unlike fixed wing aircraft, generally being steep and with greatly reduced landing distances at both managed and unmanaged landing sites (Dodge and Brook, 2013). This benefit of helicopter flight is also the helicopter's greatest hazard as these manoeuvres can be dangerous and in remote locations. So unless this phase can be made safer and more consistently enabled the risk has the potential to negate the benefit of helicopter flight (Nascimiento et al., 2014).

Helicopters are to aeroplanes, what motorcycles are to automobiles; there are fewer of them but they have disproportionately higher accident rates. Estimates suggest that accident rates for helicopters are ten times higher than for fixed wing operations (Nascimiento et al., 2014). A primary cause of rotary wing accidents is degraded visibility caused by poor weather. A DVE is one in which ocular visibility is reduced due to light levels (e.g. night), weather phenomena (e.g. fog) or atmospheric conditions (e.g. dust) (Hart, 1988). Baker et al. (2011) found that bad weather was the second most common precipitating factor (after mechanical failure) for fatal and nonfatal crashes in their analysis of 178 Gulf of Mexico helicopters accidents. Furthermore, the bad weather accidents resulted in the largest number of deaths (40 percent of all deaths). Due to the nature of helicopter operations, in remote locations and in emergency operational contexts, the likelihood of encountering DVE can be significant. Accident data has suggested that inadvertent Instrument Meteorological Conditions (IMC) flights (i.e. starting in visual flight conditions and unintentionally entering instrument flight rules) is one of the major causes of helicopter accidents, particularly when pilots are not trained to IMC level (Hart, 1988). These accidents are caused by spatial disorientation and subsequent loss of control and commonly lead to controlled flight into terrain. Aside from the increased safety risk, DVE presents one of the most disruptive factors in civil aviation and is a leading contributing factor to flight delays at major commercial airports (Allan et al., 2001; Pejovic et al., 2009).

The operational benefits afforded to helicopters and the associated contexts of use have driven an increased demand for their use in DVE in a civilian setting (Baker et al., 2011; BHA, 2014). Furthermore, the ability to fly at low altitudes makes rotary wing aircrafts more susceptible to issues arising from low visibility for greater proportions of flight, not just critical phases. A primary challenge in civil aviation is the creation of safe operational environments for rotary wing aircrafts to operate in DVE. If helicopters are going to become an increasingly viable mode in the future transport system there is a need to increase operational effectiveness and safety. The implementation of HUDs is one way of achieving this.

HUDs have been commonly used in military aviation for a number of years but are increasingly being used in commercial flight operations and for other applications such as driving (Harris, 2011; Jakus et al., 2014). A HUD interposes images on a transparent layer between the pilot and windshield, allowing the pilot to simultaneously look at the HUD symbology and the outside world. The images are focused at infinity which means that the pilot does not have to re-focus their eyes when transferring their gaze from HUD symbology to the outside environment. Generally, the content of the HUD includes primary flight information normally found on the primary flight display, additional flight path symbology (e.g. ‘Highway in the sky’) and conformal, graphical, representations of the outside environment (Alexander et al., 2003; Thomas and Wickens, 2004; Harris, 2011). A HUD allows the pilot to fly ‘eyes out’ rather than switching attention to head-down displays (HDD) inside the cockpit. The objective of a HUD is to replicate the operational benefits of clear-day flight operations regardless of the actual outside visibility condition, thus increasing operational capacity and reducing accidents caused by low visibility conditions.

One of the most important requirements of a helicopter cockpit is good visual characteristics (Lovesey, 1975). At low altitudes in good visibility, helicopter pilots use visual cues in the immediate surroundings to identify terrain features and determine their orientation, rate and direction of movement, height and distance. In low visibility the spatial and temporal resolution of visual cues are reduced and can result in diminished situation awareness and increased workload (Hart, 1988). The presentation of information via a HUD in a manner that does not require the pilot to divert visual attention and cognitive resources into the cockpit has the ability to optimise workload and enhance situation awareness (Snow & Reising, 1999; Fadden et al., 1998; Snow and French, 2002). Conformal symbology is often included on HUDs to increase the realism of the presented information. Conformal, or scene-linked, symbology allows information to be displayed at a static position relative to the real world; an example of this would be the outline of a helipad displayed on the HUD which remains overlaid on top of the view of the helipad in the outside world, regardless of what part of the HUD the pilot is looking at. Conformal symbology leads to faster detection of changes in symbology and improved flight path tracking accuracy (Fadden et al., 1998; Snow and French, 2002).

HUDs however may cause the detection of unexpected events to be degraded by attention capture when the pilot's attention shifts away from the outside environment and remains too focused on processing information presented by the HUD (Fadden et al., 1998; Thomas & Wickens, 2004; Jakus et al., 2014). An overly cluttered HUD can be detrimental to pilot situation awareness and the overlay of symbology can obscure objects and may disrupt effective scanning (Yeh et al., 2003; Harris, 2011). To optimize the benefits of HUDs, designers must preserve the most useful and unambiguous visual cues pilots naturally use so that information is processed intuitively by pilots (Foyle et al., 1992; Harris, 2011; Fadden et al., 1998).

Helicopter flight operations represents a complex socio-technical system made up of numerous interacting parts, both human and non-human, operating in dynamic, ambiguous and safety critical domains. The complexities in these systems present significant challenges for modelling and analysis. CWA is a structured framework for considering the development and analysis of these complex socio-technical systems (Jenkins et al., 2009; Vicente, 1999; Rasmussen, 1986). The framework guides the analyst through the process of answering the question of why the system exists, what activities can be conducted within the domain as well as how this activity can be achieved and who can perform them, identifying competencies required. CWA has been applied in a variety of domains including the military (Jenkins et al., 2008; McIlroy and Stanton, 2011; Stanton and Bessell, 2014), driving (Cornelissen et al., 2013, 2014), aviation (Ahlstrom, 2005; Stanton and Plant, 2010, 2011), rail (Stanton et al., 2013) and nuclear power plants (Walker et al., 2014) and has seen a range of applications including system modelling, training needs analysis, interface design and requirements specification (Walker et al., 2014).

CWA consists of five phases each modelling a different set of constraints. For a detailed description of each phase and the associated tools the reader is directed to additional texts including Vicente (1999), Jenkins et al. (2009) and Read et al. (2015). Whilst each phase of the analysis process builds upon the last, McIlroy and Stanton (2011) argued that not all phases are required to be used equally and it is down to the analyst to decide which phases are necessary to answer the research question under investigation. To address the research aims of this paper, the first phase of the CWA process, Work Domain Analysis (WDA) was utilised to analyse the cognitive work of landing a helicopter in DVE in order to identify the critical information requirements associated with this task.

WDA identifies the constraints on workers’ behaviour that are imposed by the physical context in which workers operate (Naikar et al., 2006). WDA is conducted at the functional, rather than behavioural level, defining the task environment in which activity is conducted. WDA was developed as a way of structuring information in terms of the means-ends links that form the relationships within a system (Rasmussen, 1985). The relationships capture the affordances of the system, what needs to be done and understanding the available means for completing these ends. Lintern (2006) has called this phase a design artefact because the systematic organisation of information supports the design process. Vicente (1999) recommends that the WDA phase is constructed using an Abstraction Decomposition Space and data are represented via an Abstraction Hierarchy (AH). The AH models a system at a number of levels of abstraction (see Fig. 1
                        ); at the highest level the overall Functional Purpose of the system is considered, followed by the Values and Priority Measures (criteria that the work system uses for measuring its progress towards the Functional Purpose). Next, the Purpose-Related Functions define the general functions of the work systems that are necessary for achieving the Functional Purpose, followed by the Object-Related Processes (functional capabilities and limitations of Physical Objects in the work systems that enable the Purpose-Related Functions). Finally, at the lowest level the Physical Objects describes the individual components within the system.

The analysis was conducted with the CWA software tool developed by the Human Factors Integration Defence Technology Centre. The AH was populated via consultation sessions with four Subject Matter Experts (SMEs) who were experienced helicopter pilots and had worked in various operational contexts including the military, private passenger transport, and search and rescue. These sessions involved the construction of AHs assisted by experienced Human Factors researchers. This information was supplemented with documentation to support domain familiarisation including flight manuals, simulator observations and videos of DVE landing. The individual AHs were amalgamated into one representative AH (see Fig. 1) and was verified by a test pilot. The functional purpose captures the reason why the system exists. Here, the functional purpose of the situation is to ‘establish hover and land’ this encompasses the purpose of the situation as it is the prerequisite to ensure you are ready to land. The next level down, values and priority measures, captures the criteria that can be used to determine how well the system is achieving its functional purpose. To ensure a successful approach and maintenance of hover is achieved the values and priority measures were defined as; ‘aircraft altitude decreased’, ‘maximise smooth transition of aircraft’, ‘minimise time to conduct approach and hover’ and ‘avoid collisions and impact with hazards/third parties’. The middle level, purpose related functions, lists the functions that have the ability to influence one or more of the values and priority measures. They link the purpose-independent processes of the physical objects (described in the next level) with the more abstract measure of system performance (in the values and priority measures), thus joining the AH together. In this analysis the purpose related functions include; ‘aircraft performance’, ‘external conditions’, ‘third party activity’ and ‘pilotage’. In the second level from the bottom, the object-related processes (O-RP) capture the affordances that are provided by the physical objects (described below) in order to perform the purpose related functions. For example, the physical object of environmental markers (grass, trees etc.) affords knowledge of maintaining position, awareness of groundspeed, wind direction and strength, image of world and localisation of position. The lowest level, physical objects, lists the physical components of the system. For this analysis, physical objects consisted of any piece of information, internal or external to the cockpit, which enables the pilot to achieve the functional purpose. Fundamental cockpit objects such as seats, harnesses and windows all provide important affordances to the cockpit; however the analysis needs to be kept as manageable as possible so the boundary was set to omit them. Example physical objects include; windsock, weather report, compass, surface, radio altimeter, flight controls and airframe world references.

Each level of the AH is linked together by means-ends links through the use of the how-what-why triad. Any node can be taken to answer the question of ‘what’ it does (e.g. ‘external conditions’ in the purpose related function level). The connected nodes in the level below answer the question of ‘how’ this can be achieved (e.g. ‘wind direction and strength’, ‘clearances’ ‘freedoms and constraints on flight’, ‘undercarriage motion feedback’ and ‘image of world’ in the object-related processes level). The level above the node answers the question of ‘why’ is it needed (e.g. ‘aircraft altitude decrease’, ‘maximise smooth transition of aircraft’, ‘minimise time to conduct approach and hover’ and ‘avoid collisions and impact with hazards/third parties’ in the values and priority measures).

As described in the introduction, one of the objectives of future helicopter transport is to increase all conditions operational capacity to allow helicopters to operate in DVE thus increasing their operational effectiveness and their potential utility in the future transport system. Foyle et al. (1992) has argued that the challenge for Human Factors engineers is to design visual displays that represent the most useful visual cues that pilots most naturally use. The WDA undertaken focused on the situation of coming into an approach to maintain a hover in preparation for landing in a DVE. The tasks required to achieve the functional purpose of the system are represented by the O-RP and these need to be represented on the HUD to ensure it adequately facilitates the task. The HUD concept consists of the physical objects necessary to achieve the functions defined in the AH and is presented in Fig. 2
                        . Table 1
                         depicts the mapping between the object-related processes level of the AH and the symbology included on the HUD.

The HUD contained the following 2D flight instruments: conformal compass, heading readout, airspeed indicator, conformal horizon line, attitude indicator, vertical speed indicator, air speed indicator, wind direction and strength indicator, and distance to go readout. To assist with the hover/landing task the HUD included the following elements:
                           
                              1.
                              Flight path vector (acts as a touch down indicator, this becomes visible to the pilot when losing altitude, it represents the point on the ground they will hit if the current velocity is maintained) (item 1 in Fig. 2)

3D augmented reality “tree” (these provide a visual reference point for the pilot when landing) (item 2 in Fig. 2)

Arrows against the trees provide the pilot with visual references for height and speed as the aircraft is descending (item 3 in Fig. 2)

Runway grid and runway markings (item 4 in Fig. 2)

Obstacles (3D augmented reality used to represent obstacles and hazards such as gas towers shown as item 5 in Fig. 2)

The HUD was intending to simulate the actual environment and therefore colours were chosen to reflect this, e.g. green for the trees and runway and blue for the horizon line. It is argued that traditional approaches to colour usage will be challenged in the next generation of aircraft cockpits because of the potential advances in technology (Biggin, 2011). However, in this HUD the use of colour was also aligned with accepted standards for the use of colour in cockpits, including keeping the colour palette as small as possible and conforming to colour stereotypes, such as red for warning and amber for caution (FAA, 2007). The descent arrows, obstacles and other indicators were magenta as this is a commonly used colour in the cockpit for this type of information symbology (Biggin, 2011).

The study employed a 2 × 2 within-subjects design. The independent variables were weather condition (clear sky or DVE/fog) and symbology used (with or without the HUD). The order of presentation of the conditions was counterbalanced between the participants.

Six male subjects aged 37–65 (mean = 51.00, SD = 10.29) were voluntarily recruited for the study via advertisement posters placed at local airfields and around the university campus. The sample size reflects the niche population that was selected from and recorded debrief sessions were conducted to maximise the data produced from a smaller sample size. All subjects were qualified, instrument rated, rotary wing pilots with varying amounts of experience; flying hours ranged between 108 and 8300 h (mean = 3804, SD = 3468). Pilots were recruited from a range of operational contexts including; Search and Rescue, private transport and the military. All participants had flown within a year of the study. The two military pilots (P1 and P6) had experienced using a HUD before, the other pilots had not. Ethical permission for this study was granted by the Research Ethics Committee at the University of Southampton and all subjects provided informed written consent. Participants were informed that simulator sickness was not likely to be an issue but they could stop the task at any point of they felt unwell. Simulator sickness was not explicitly monitored for, nor was it reported.

A fixed-based flight deck simulation facility at the University of Southampton was used in its rotary wing configuration. The simulator comprises a two-seater cockpit (including external cabin) with five multi-function display units. The external screen is projected onto three screens providing an 180° degree field of view. Participants were seated in the right-hand seat as which was configured for the rotary wing controls. The simulated environment runs on Prepar3D (previously Microsoft flight simulator software). The flight scenario was located over a runway at the Norfolk naval base, Virginia, USA, using the Bell 206 flight model. The Prepar3D software is highly customisable and allowed the required weather conditions to be simulated. In the clear sky condition the clear weather setting was selected and in the DVE the highest fog setting was used (approximately 300 m visibility).


                           Head down Display: The Head down display (HDD) was displayed to the pilots on the outer right multi-function display unit in the simulator. This was available to the pilots in all four conditions. The HDD was part of the Prepar3D software and consisted of analogue flight instruments for helicopters in a standard configuration, including: attitude indicator, airspeed indicator, a compass, heading indicator, altimeter, vertical speed indicator and torque indicator.


                           Head up Display: The HUD concept (described in Section 2.3) was created using GL Studio. This is a software tool specifically developed for interface display design and provides the ability for its display instruments to be controlled from external applications (e.g. Prepar3D). A two-way data interface was developed to allow flight data to be transferred from Prepar3D and synchronised symbology to be transferred from GL studio. During the flight conditions with the HUD, the concept was overlaid onto the simulated environment using a ghost window application that is freely downloadable from the internet.

Two questionnaires were administered after each experimental condition had been flown. The post-landing assessment (PLA) questionnaire was developed by an industry partner in the project funding this work. The questionnaire asks participants to rate their awareness of seven flight parameters (desired heading, desired rate of descent, desired groundspeed, power status, required landing point, drift and outside environment) from 1 (low) to 7 (high). These components represented different aspects of situation awareness under investigation. At the end of each flight a de-brief session was held so that the researchers could probe the pilots about reasons for their ratings on the PLA.

The Bedford Workload Rating scale (Roscoe and Ellis, 1990) is an uni-dimensional mental workload assessment technique developed to assess pilot workload. The technique involves a hierarchal decision tree to assess workload via an assessment of spare capacity whilst performing a task. Participants follow the decision tree to derive a workload rating for the task under analysis (Stanton et al., 2013). A scale of 1 (low workload – workload insignificant) to 10 (high workload – task abandoned) is used.

@&#PROCEDURE@&#

The participants were briefed about the study and asked to complete the consent form and a questionnaire to gather demographic information. The study lasted approximately 90 min. Participants were initially given an initial familiarisation session with the simulator which allowed them to get used to the flight model and flight controls. The participants were then familiarised with the HUD in a video talk through provided by the software developer to explain each instrument and the conformal symbology. Participants were then given time to practice flying with the HUD. The familiarisation session lasted approximately 25 min and this aligned with previous studies that used both classroom and simulator training for a similar amount of time when introducing new cockpit symbology (e.g. Snow and Reising, 1999). The participants then flew each of the four experimental conditions (clear, clear + HUD, DVE or DVE + HUD). For each condition participants began 5 nm out to sea, at a height of 1500 feet and a speed of 50 knots. They were instructed to land on the runway which was visible in the clear sky conditions and a heading was provided in the DVE conditions. Participants were instructed to fly to the runway and land the aircraft. After each condition was flown the PLA and Bedford workload questionnaires were administered and a de-brief session probed pilots about the reasons for their ratings (each flight condition including questionnaires took approximately 15 min). When answering the questionnaires, the participants were instructed to detach from any feelings associated with the simulated environment (e.g. fidelity of the flight controls and flight model) and base their ratings purely on the HUD symbology and scenario under evaluation. At the end of the study a longer debrief session was held to allow pilots to comment on the symbology in the HUD.

This study presents a preliminary assessment of the HUD concept with a sample of six qualified pilots. Based on various assertions in the literature it was not deemed appropriate to perform statistical analysis on data from this sample size (Donaldson, 1968; Vu Tran, 1997; Field, 2013). Instead, an in-depth qualitative analysis of the data was conducted using the ratings from the questionnaires and the associated de-brief sessions.

@&#RESULTS@&#


                     Table 2 
                      presents the pilot's ratings for the PLA and workload assessment in each of the four conditions. The PLA ratings are colour coded to represent high awareness (light grey), moderate awareness (mid-grey) and low awareness (dark grey). The ratings are supplemented with a summary of comments for each of the four conditions. This information is graphically represented in Fig. 3
                      which presents the average scores of pilot workload and the PLA parameters. Each parameter will be discussed in turn and related back to the development of the HUD via WDA.

Desired heading was rated higher in the two HUD conditions (see Fig. 3) because pilots were able to use the conformal compass, heading readout and runway grid presented on the HUD to facilitate the O-RP of ‘maintain heading’. Three pilots stated that they used the runway grid during the HUD condition to maintain heading. In the AH it was assumed that only the conformal compass and heading readout would assist the function of maintaining heading (see Table 1). The physical object of ‘surface’ was not connected to the O-RP of ‘maintain heading’ because without a HUD the surface does not provide a clear enough image for heading maintenance. However, the runway grid on the HUD was visible through the fog a couple of kilometres from the runway and assisted in achieving this O-RP. Even in the clear + HUD condition one pilot stated that “the combination of the HUD and full visual information was useful” (P1). Similarly, P6 gave a lower awareness of heading in the clear condition compared to the clear + HUD condition, stating that “having the information where I want to look [HUD] is much better than having to get it from somewhere I don't want to be looking at [HDD]”.

Awareness of desired rate of descent came from the vertical speed indicator and trees with associated descent arrows. Awareness of rate of descent was highest in the two HUD conditions (see Fig. 3 and Table 2). P6 stated that he was more aware of the rate of descent in the DVE + HUD condition compared to the clear + HUD and clear conditions. This can be attributed to the fact pilots said the HUD was more visible in the DVE condition than the clear + HUD condition. Pilots had some awareness of the rate of descent in the DVE condition from the instruments provided on the HDD, but awareness was consistently lower in this condition (see Table 2). This awareness parameter links to the O-RP of ‘descend’ and it is clear that the HUD was providing the pilot with enough information to achieve this function.

‘Awareness of groundspeed’ was an O-RP that related to the HUD symbology of the groundspeed indicator and runway grid (akin to the ‘surface’ in the physical objects of the AH). Fig. 3 shows that awareness of groundspeed was highest in the DVE + HUD condition, followed by clear + HUD, clear and finally DVE condition. In the clear condition pilots stated that awareness increased as they got closer to the ground, whereas in the DVE condition awareness was low because they couldn't monitor the ground-rush, i.e. speed of movement over the ground, this is why the runway grid proved so useful in the HUD conditions (particularly DVE + HUD). P2 gave some of the lowest ratings for groundspeed awareness in all conditions but stated “I didn't really look at this; it wasn't something I was interested in”.

Awareness of power status was low across all conditions and this was a failing of the HUD. Fig. 3 shows that awareness of power status was similar (at the lower end of moderate awareness) in three of the four experimental conditions; DVE + HUD, DVE and clear + HUD. Power status was marginally higher in the clear condition when pilots had the spare capacity to scan the HDD for information they could not glean from the outside environment. The HUD did not explicitly represent the power status of the aircraft and this demonstrates a flaw in designing an interface based solely on WDA, which is discussed in detail in Section 5.2. Whilst power was represented on the HDD, without exception, all pilots stated that they needed to have power represented on the HUD (N.B. the term power is used simultaneously with torque and a distinction was not made between these terms).

Awareness of required landing point is associated with the O-RP of ‘localisation of position’ and ‘angle of approach indication’, the HUD symbology used to achieve these functions was the runway grid, 3D augmented reality trees and descent arrows. Awareness of required landing point was high in the clear condition, at the high end of moderate in the clear + HUD and DVE + HUD conditions and at the lower end of moderate in the DVE condition (see Table 2 and Fig. 3). Awareness was not rated as low in the DVE condition because pilots were able to use the runway lights that were part of the simulated environment to assist their landing nearer the ground. In the DVE + HUD condition P1 stated that “the runway grid was very useful to reduce workload” and this was echoed by other pilots. However, it was noted that if the aircraft had been put into a position where the trees, descent arrows and runway grid were offset from the aircraft the HUD symbology would not have been as useful. Improvements to address this are discussed in Section 5.4 when we consider future iterations of the HUD.

As with power status, drift was not explicitly represented on the AH, the closest O-RP associated with drift was ‘maintain position’, the HUD symbology to achieve this function included; conformal compass, heading readout, attitude indicator, airspeed indicator and the trees with associated descent arrows (see Table 1). Specifically, the latter of these, the trees with descent arrows, was the symbology the pilots was using to assess drift as it is only of concern as the aircraft gets closer to the ground. Awareness of drift generally received moderate to high awareness scores in all conditions with five pilots agreeing that “the symbology helped to reduce drift” (P1) in the HUD conditions (see Table 2 and Fig. 3). However, P6 did not find the HUD display useful in helping his awareness of drift, stating that “I couldn't pick that up … close to the ground … I was able to see through the fog” and requested an indication of negative speed.

The outside environment was captured in the O-RP level of the AH as ‘image of the world’. The HUD symbology to achieve this function was defined as the runway grid, 3D augmented reality trees, descent arrows and obstacles. Awareness of this is particularly important in the DVE conditions. It is clear from Table 2 that awareness is low to low-moderate in the DVE condition, with pilots stating “it was very difficult to pick up” (P6) and “I was aware there was a lack of horizon” (P1). However, in the DVE + HUD condition awareness of outside environment was generally rated at the higher end of moderate and high; P3 expressed that “the HUD was very helpful”. Awareness of outside environment was rated as high in both clear conditions.


                        Fig. 4
                         clearly demonstrates that workload was highest in the DVE condition, averaging a rating of 6 which is defined on the Bedford Workload Scale as ‘little spare capacity, level of effort allows little attention to additional tasks’. However this did range from a rating of 3 for P1 (‘enough spare capacity for all additional tasks’) to a rating of 9 for P3 (‘extremely high workload, no spare capacity. Serious doubts on ability to maintain level of effort’). Fig. 4 shows that workload was lowest in clear + HUD condition, followed by clear (although they both averaged a rating of 2 ‘workload low’) and then DVE + HUD (average rating of 4 ‘insufficient spare capacity for easy attention of additional tasks’). Pilots stated that they felt they needed more training with the HUD to decrease workload in the DVE + HUD condition.

@&#DISCUSSION@&#

This paper presented a study that developed and evaluated a HUD concept to assist rotary wing pilots landing in DVE. The HUD was developed with the assistance of the WDA phase of the CWA method. The HUD was tested in a flight simulator with six qualified helicopter pilots. The qualitative analysis of the results from the post-flight situation awareness and workload ratings indicated that the HUD led to improvements in awareness and decreased workload. The results demonstrated that for three of the seven awareness parameters (rate of descent, heading and groundspeed) awareness was higher in the DVE + HUD condition compared to the clear condition. Compared to the DVE only condition, the HUD improved pilot's awareness in all seven parameters indicating that the HUD was providing sufficient external visual cues for flight. There was also a decrease in workload in the DVE + HUD condition, compared to the DVE only condition. This suggests that information on the HUD is being processed intuitively. However, workload in the DVE + HUD condition was still higher than in the clear conditions, with pilots stating that they needed more training time for workload to be significantly reduced as the DVE condition resulted in reduced capacity anyway. P1 and P6 were military pilots with previous HUD experience; their workload rating scores showed the least variation between the DVE + HUD condition and clear conditions (see Table 2), suggesting that experience with HUDs impacts workload.

The HUD was developed with the assistance of the WDA phase of the CWA method as an approach for analysing the cognitive work of landing the helicopter in order to identify the critical information requirements associated with this task. This method was chosen in order to formalise the development of the HUD and Vicente (1999) argued that focusing on the work domain is the most important part of the information environment and will enable systems to be designed around the relevant information requirements. The method has demonstrated previously utility in system design (e.g. Jansson et al., 2006; McIlroy and Stanton, 2011; Cornelissen et al., 2013; Read et al., 2015).

The HUD had to be capable of representing the tasks detailed in the O-RP level of the AH as these were the requirements that allowed the functional purpose of the system to be achieved. The advantage of designing the HUD around the AH was that it provided a structured knowledge base and rationale for symbology development. It was clear from the analysis of the results that the symbology elements with the clearest coupling to the AH (e.g. landing site, outside environment, rate of descent, heading and groundspeed) assisted the most in enhancing awareness during the HUD conditions. However, the limitations of the AH, and thus its contribution to design, are also evident. For example, power was only represented via the HDD and not on the HUD, this was a design omission because power was not listed as an O-RP in the AH and therefore not mapped across to the symbology via a torque indicator. This was reflected in the PLA results as awareness of power was low across all conditions (it was slightly higher in the clear condition when pilots had the spare capacity to scan the HDD instruments). In the debrief sessions all pilots stated that they would like to see power included on the HUD and it will therefore be included in future iterations of the HUD.

The other awareness parameter that could have been improved was drift. Although drift was somewhat represented via the trees and associated descent arrows, all pilots felt that this representation could be improved, for example P6 stated “there is currently no representation of negative speed, i.e. if I was drifting backwards I wouldn't know it”. As with power status, drift was not explicitly represented as an O-RP and the closest one associated with this was ‘maintain position’. It is clear that the functions not represented via the O-RP level in the AH and therefore not adequately represented on the HUD scored the lowest awareness ratings. This demonstrates that the PLA questionnaire is sensitive to the HUD symbology and highlights areas for improvement and is backed up by the comments from the pilots. It also demonstrates the utility of using the WDA phase of CWA as a basis for design.

The results demonstrated that the HUD in its current format improved situation awareness and reduced workload in degraded visual environments. However, enhancements can be made to the HUD to increase its utility even further. For example, many studies demonstrate the effectiveness of ‘Highway in the Sky’ (HITS) symbology (Williams et al., 2001; Alexander et al., 2003; Thomas and Wickens, 2004). This is usually in the form of a graphical flight path representation. Whilst there are concerns that HITS symbology can lead to cognitive capture or attentional tunnelling (Thomas and Wickens, 2004), including a HITS type element is worth exploring.

Enhancements could also be made by the use of a full terrain map. In this study a grid was displayed over the runway and the pilot's consistently commented on how useful it was, helping them to achieve awareness of groundspeed, required landing point and drift (see Section 4). Snow and Reising (1999) found substantial increases in situation awareness with the addition of a synthetic terrain grid in a HUD and this was associated with a reduction in ground impacts during low level flying, Bennett et al. (1988) found similar results with a virtual grid system attached under a helicopter simulation.

The representation of drift has already been raised as an area for improvement. One method to enhance awareness of drift is to provide a velocity vector which would show pilots whether they are moving forwards or backwards. However, a study by MacIsaac et al. (2005) found that a velocity vector did not adequately provide the pilots with lateral drift information because the angle of the vector only determines lateral velocity for large values and was hard to perceive for small values. Having an awareness of drift is essential for the pilots and was a concern raised by all of the pilots in the study and this will certainly be an area where re-design efforts are targeted.

It was also demonstrated that the HUD could be beneficial even in clear visual conditions. For example, awareness of heading, groundspeed, descent and outside environment was higher in clear + HUD condition compared to the clear only condition. Furthermore, although both the clear + HUD and clear conditions resulted in an average workload score of 2 (‘workload low’), Fig. 3 demonstrates that workload in the clear + HUD condition was marginally lower, compared to the clear only condition. Ververs and Wickens (1998) also found that presenting flight information in a HUD may be useful in clear visual conditions and attributed this to the ability of a HUD to allow different information forms to be integrated and the reduced visual scan it provided. This latter point was backed-up by the pilots in this study who stated that the utility in the HUD came from having the information in front of them, rather than having to change their visual focus when assimilating information from the HDD.

The driving forces of the current, car-dominant, transport system are freedom and control to travel how and when one wishes to. Frey (2011) warned that any future system that does not maintain or increase perceived freedom and control for the user will fail in the marketplace. The advantages afforded by helicopter flight include its speed and ability to traverse above road and rail traffic, offering a fast point-to-point journey that is not currently possible with any other mode of transport. As such, helicopters have the potential to offer increased freedom in the speed at which journeys are undertaken and the ability to rise above congested should increase, or at least maintain, perceived control. However, helicopter transport is only useful and effective if the infrastructure is in place to support it which results in planning considerations including; locating commercially viable sites on prime urban land, allowing for unobstructed approaches, reducing noise disturbances and optimising perceived operational safety (Plevin and Evans, 2011; Dodge and Brooks, 2013).

The perception of safety is an important issue to consider. In 1977 the skyscraper helipad located on top of the Pam Am building in New York was closed after a rotor blade broke off a stationary helicopter and killed a pedestrian on the street below. As recently as 2013 an AW109 helicopter flying in poor visibility in central London hit a crane that was part of a construction site, killing both the pilot and a pedestrian. The subsequent Air Accident Investigation Branch (AAIB, 2014) report identified the pilot's decision to continue with his intention to land at the London heliport, despite being unable to remain clear of cloud, as a contributory factor. This raises an interesting issue when it comes to the use of HUDs in these poor visibility conditions. Had the pilot been using a fully augmented HUD he would have known where the obstacles were and his distance from them. However, if HUDs were a standard part of the cockpit architecture then the pressure for pilots to ‘push-on’ in unsafe conditions may increase. It was reported that the AW109 pilot felt operational and commercial pressure to complete the flight as it was (AAIB, 2014). Whilst the report noted that that this was the only fatal crash in the city since records began in 1976, the image the public will remember is the smouldering wreck of a helicopter in a central London street. The public are going to have to be convinced of the safety case for widespread helicopter use if their potential is to be realised.

At present, the helicopter only has a marginal role in our lives and is still a socially exclusive mode of transport used for specialist tasks or niche environments. But there was once a time when fixed-wing transport was the same. With the advent of technological solutions to support the operational effectiveness and safety of helicopter flight coupled with the ever increasing need to radically change the urban transport system helicopters present a potential solution. Traditionally, pilots had two sources of flight information available to them; the cockpit instruments and out-of-the window visual references (Foyle et al., 1992). Technology today, primarily in the form of HUDs, allows these two sources of information to be amalgamated and integrated with the advantage of enabling the pilot to fly ‘eyes-out’ in a natural and intuitive manner. This paper applied the WDA phase of the CWA method to the problem of approach and landing in DVE in order to understand the task requirements. We are confident that, in general, the correct requirements were targeted which led to the development of a HUD to assist the task of landing in DVEs. It was demonstrated that the HUD enhanced situation awareness and had a positive impact on workload, although we have acknowledged that there are areas where the HUD can be enhanced to facilitate performance even further. The provision of HUDs has the potential to increase helicopter operations by allowing them to fly in DVEs and, as demonstrated here, may also have utility in good visual conditions in order to enhance the safety of helicopter operations. This may enable helicopters to realise their full potential in a future transport system where limited runway space will be heavily rationed and the road networks will become increasingly congested. Helicopters have the potential to fly over traffic jams and into airports or other landing sites with fewer air traffic restrictions than fixed wing aircraft. This unique capability means that helicopters can help solve the transport capacity problems facing the 21st century.

@&#ACKNOWLEDGEMENTS@&#

The work was supported by funding from the EU 7th Framework project Grant no. ACP8-GA-2009-233682 ALICIA: All Condition Operations and Innovative Cockpit Architecture. We would like to thank the pilots who gave their time to participate in the study.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Efficient data-parallel tree-traversal for BlobTrees
            

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We show how to improve BlobTree traversal time by one order of magnitude.


                        
                        
                           
                           We demonstrate how to incorporate Warp Transformations within the BlobTree into new traversal.


                        
                        
                           
                           The performance is measured on computer generated and hand built models.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

BlobTree

Tree traversal

Acceleration

@&#ABSTRACT@&#


               
               
                  The hierarchical implicit modelling paradigm, as exemplified by the BlobTree, makes it possible to support not only Boolean operations and affine transformations, but also various forms of blending and space warping. Typically, the resulting solid is converted to a boundary representation, a triangle mesh approximation, for rendering. These triangles are obtained by evaluating the corresponding implicit function (field) at the samples of a dense regular three-dimensional grid and by performing a local iso-surface extraction at each voxel. The performance bottleneck of this rendering process lies in the cost of the tree traversal (which typically must be executed hundreds of millions of times) and in the cost of applying the inverses of the space transformations associated with some of the nodes of the tree to the grid samples.
                  Tree pruning is commonly used to reduce the number of samples for which the field value must be computed. Here, we propose a complementary strategy, which reduces the costs of both the traversal and of applying the inverses of the blending and warping transformations that are associated with each evaluation.
                  Without blending or warping, a BlobTree can be reduced to a CSG tree only containing Boolean nodes and affine transformations, which can be reordered to increase memory coherence. Furthermore, the cumulative effects of the affine transformations can be precomputed via matrix multiplication. We propose extensions of these techniques from CSG trees to the fully general BlobTrees. These extensions are based on tree reordering, bottom-up traversal, and caching of the combined matrix for uninterrupted runs of affine transformations in the BlobTree.
                  We show that these new techniques result in an order of magnitude performance improvement for rendering large BlobTrees on modern Single Program Multiple Data (SPMD) devices.
               
            

@&#INTRODUCTION@&#

@&#MOTIVATION@&#

The BlobTree   [1] as a data-structure for Implicit models extends the CSG tree to include techniques such as warping and blending  [2], and is of sufficient generality that it is often used in implicit modelling systems, e.g.  [3–5]. Recently, a subset of the BlobTree has also been used to improve skinning  [6,7]. In order to visualize an implicit model, the value of the field function has to be found for many points in space. Each function evaluation requires a tree traversal, in which a significant proportion of the traversal time is spent calculating which node is next.

Several researchers have shown that visualization methods can indeed be fast enough to re-create a new mesh object from a BlobTree at interactive frame-rates (e.g.  [8,9]). Other approaches have shown that ray-tracing times can be reduced, for example using interval-arithmetic  [10] to find the intersection of a ray with the BlobTree surface. These approaches have in common that the speed up is achieved by reducing the number of implicit (BlobTree) evaluations at points in space, but little work has been done to improve the time for a tree evaluation.

Recent advances in BlobTree-modelling introduce more complex operators to expand the capabilities of the BlobTree   [2], solving four long-standing problems (bulging, blending at distance, small details are lost in blending and undesired filling of holes), and offer greater control to the user. Unfortunately, these advantages come at the cost of increased computation time compared with the standard operators. As a result, it is even more important that tree traversal time is reduced to preserve modelling interactivity. Even basic user interaction, such as calculating a point on the BlobTrees surface, will benefit from a faster BlobTree traversal.


                        BlobTree modelling is a derivative of Constructive Solid Geometry (CSG)  [11]. Much work has been done to improve CSG tree traversal  [12–14], as well as novel rendering techniques  [15]. Unfortunately, approaches improving tree traversal for CSG are not necessarily applicable to the BlobTree, due to its mathematical formulation. Depending on the application, CSG evaluation algorithms classify points, line segments, or surfaces, but always return point sets (possibly augmented with set membership maps for their neighbourhood), while BlobTree evaluation algorithms return a scalar value at a query point. Direct CSG classification algorithms classify (i.e., trim) these candidate sets against the leaves of the CSG tree (i.e., the primitive solids) and then merge the classified subsets up-the-tree, according to the Boolean operations  [16]. CSG trees that support such algorithms are limited to nodes that represent regularized Boolean set operators (Union, Intersection, Difference) and affine transformations. Offsetting, blending, and Minkowski operations require evaluating a boundary representation of the solids associated with the argument nodes of such operations and hence do not lend themselves to a direct CSG evaluation. In contrast, BlobTrees evaluate scalar values at the query point, one per BlobTree leaf (primitive) and then blend, filter and combine these values according to various formulae  [17,2], which may reproduce Boolean operations and also their blended versions. This includes bending, twisting, tapering and warping based on Free-Form Deformation approaches.

Typically, BlobTree field-values are calculated multiple times along one ray, where a large number of rays are cast, or along a dense grid of points (e.g. 323 for the use case presented in Section  7). The final object’s surface is placed where field-value samples cross a given iso-value. Whenever a BlobTree is traversed to create a field-value, the time of such an evaluation can be decomposed into time spent calculating field-values at leaves, combining field-values at operators, calculating the next node in the traversal, memory transfers loading node data and saving and loading the intermediate computation results. The first two measures depend on the primitives and operators used in the model and thus cannot be influenced by a BlobTree traversal change. In contrast, the last three measures are directly influenced by a traversal algorithm and are addressed in this work.

We show how to accelerate the tree traversal for the BlobTree using an approach that results in an 
                           O
                           
                              (
                              n
                              )
                           
                         traversal time (
                           n
                         nodes in the BlobTree), where every node in the tree is only accessed once, compared to three times for interior nodes and once for leaf nodes in the default recursive traversal. This allows us to exploit predictable memory access patterns, important for performance on modern SIMD and SPMD architectures, such as GPUs using OpenCL, or using vector instructions on multi-core CPUs. In our approach, the tree information is stored in a linear memory pattern, preferred by modern CPU/GPU architectures. This technique can improve traversal speed by as much as an order of magnitude, compared to previous approaches running on an SPMD architecture.

The remainder of the paper is structured as follows. Section  2 discusses related work in SPMD programming, as well as BlobTree and CSG acceleration. In Section  3, we summarize the most efficient CSG traversal accelerations and in Section  4, we describe how some of these changes can be applied to the BlobTree. The special handling of Warp transformations is introduced in Section  5 and our implementation is described in Section  6. We discuss our results in Section  7 and conclude the paper with future work in Section  8.

@&#RELATED WORK@&#

The publications related to this paper can be divided into three distinct topics: using the SPMD programming model to accelerate parallel calculations on the same data, accelerating BlobTree rendering and accelerating CSG rendering. Section  3 summarizes the CSG rendering accelerations based on optimized tree traversal in greater detail and forms the basis for this work.

Current computer architectures provide two main paths for accelerating floating-point heavy workloads: SIMD (Single Instruction Multiple Data) units, which evaluate the same floating point operator on multiple (typically 4, 8, or 16) elements of data; and GPUs, re-purposed to general computation using a large set of SIMD-like processors, with hardware predication for divergent control flow. This last model is better known as the Single Program Multiple Data (SPMD)  [18] programming model. In an SPMD program, a single execution stream is applied on a large number of independent data elements. Applying the SPMD model usually involves rethinking the algorithm with respect to optimal memory transfer and problem blocking  [19] to allow maximum data independence. Several high-level programming languages help the programmer to create code to run on SPMD architectures, such as OpenCL  [20] or CUDA  [21] for GPUs  [22], or ISPC  [23] for CPUs. Tree Traversal on GPUs in general, using the SPMD programming model has been discussed by  [24], who propose storing additional data (“Autoropes”) on a stack during traversal to accelerate the process. The traversal, however, is still done top-down, compared to our advocated bottom-up approach. In addition to autoropes, the paper also discusses interaction between GPU threads in order to optimize performance, something left to future work on our proposed approach.

The BlobTree   [1] is a hierarchical modelling approach with a unified structure, in which nodes can represent arbitrary combinations of operators and primitives. It builds on the notation of skeletal implicit surfaces  [25] as the primitives and exhibits operators that go beyond the classical CSG union, intersection and difference, starting with the widely known summation blend, the Ricci-blend  [11,26], as well as more complex operators  [17]. More generally, the BlobTree can have any 
                           3
                           D
                         scalar field as a leaf node, as long as the field and the used operators conform to the properties outlined in  [27]. All visualization approaches, including polygonization  [28–30] and ray tracing  [31,32], rely on iterative root-finding by sampling the field-value and gradient (based on differencing) functions.

Previous work on improving the traversal time of BlobTrees include work by  [33], which aggregates nodes in the tree to reduce the overall node count. Furthermore, a simple approach using spatial subdivision together with pruning the tree for each subdivision node is also suggested and explored further in  [3]. Caches within the tree structure were introduced by  [8] in order to reduce the number of field value calculations in favour of interpolation of field-values as soon as enough values are found within the cache structure. This work enabled interactive editing through fast polygonization; however, for edit operations, it still relied on polygonizing at a coarser resolution to allow for fast interactive feedback. Polygonization itself is an algorithm that lends itself to an implementation using SIMD  [9], which makes use of linearizing a tree structure into continuous memory and calculating multiple field-values in parallel, since each calculation is independent.

In all of the above approaches, rendering times were improved significantly, but none include methods to reduce the time a single tree traversal takes. It is not obvious that improving the time taken by the calculation of the field-values is possible. The formulas for primitives and operators are constant in that they cannot be altered without changing the resulting values. Any acceleration approach must not alter the result of the field-value calculation at a point in space. We will show that it is possible to accelerate the field calculations without modifying the underlying formulas by taking certain hardware properties, especially those of modern GPUs, into account.

In another GPU approach  [34], the model is built by altering the GLSL shader code, that renders models directly to the screen, but is less practical than our approach as a new shader is required whenever the model changes. Other approaches such as  [35], present a method to ray-trace meta-balls on the GPU. Neither of the above, however, deal with tree structures similar to the BlobTree, and thus these are not comparable systems.

Most of the current state-of-the-art GPU rendering techniques for CSG models are based on the formulation of a CSG tree as a Boolean list (Blist)   [36]. Blister   [13] and subsequently  [37] use the Blist formulation of a CSG tree in a rendering technique based on depth peeling. The depth peels are classified for each primitive based on stencil bit true/false values that are then combined using the Boolean expression given by the CSG tree. The optimization methods in these approaches resulted in the formulation of Ordered Boolean Lists   [14], which can evaluate a Boolean expression in 
                           O
                           
                              (
                              log
                              log
                              n
                              )
                           
                         space.

Other approaches to render CSG models on GPUs include  [15], where CSG objects are subdivided until each child is simple enough (one primitive or Boolean operator of two primitives) for rendering on the GPU. This subdivision is done on the CPU. It is also possible to use a face representation precomputed on the CPU to directly render the CSG objects using boundary representations  [38].

Using a tree structure efficiently in an SPMD context requires linearizing the tree into a continuous block of memory. Many approaches for linearizing tree structures store the tree nodes in top down order, with offset pointers used to do the traversal  [39,40]. Some approaches insert additional offset pointers so it is possible to directly go to the in-order predecessor or successor by one single offset pointer (threaded tree  [41]), instead of reading the parent pointer again in order to find the neighbouring child node. Linearizing and traversing trees has been important in the context of acceleration structures  [42,39,40,43,44]. Unfortunately, we cannot use these methods in our case, since these acceleration structures try to avoid traversing the entire tree, which is a requirement for a complete BlobTree traversal.

The most efficient methods to accelerate the traversal of CSG trees involve writing the tree as a Boolean expression. In such an expression, the leaves of the tree correspond to the literals, which at any 3D point either evaluate to true or false. The operators (notation as per Rossignac  [14]) in the expression can be of the limited set of union, expressed as a Boolean OR (“
                        +
                     ”), intersection as AND (“
                        •
                     ”) and the difference operator as AND NOT (“
                        •
                        !
                     ”), where “
                        !
                     ” denotes the complement. Operators that can create more complex transitions between surfaces, such as the ones described in  [45,46], are usually not considered in these approaches. Any tree only consisting of the three simple operators stated above can be described using such a Boolean expression, which can be evaluated in parallel for any input points and classifies this point against the CSG model surface.

A CSG tree that uses only these three operators (“
                        +
                     , 
                        •
                     , !”) and that has the “!” operator pushed to the literals using the de Morgan laws is called a Positive Form Expression (PFE). In this expression, which is the basis of the Blist wiring process for optimization, only the 
                        +
                      and 
                        •
                      operators exist; the “!”-operator being expressed as a parameter to the actual primitives. Both operators in this PFE are commutative, so they can often be swapped to make the tree left heavy, which can reduce the footprint of the expression (see Section  4.2 for a discussion on left heavy trees). The Blist wiring process  [14] uses the metaphor of an electrical circuit, where every literal is expressed as a switch reading its Boolean value. Each switch has a top output, representing result being true, and the bottom output, representing the result being false.

Two switches 
                        A
                        ,
                        B
                      can be connected to form either the expression 
                        A
                        +
                        B
                      or 
                        A
                        •
                        B
                      by altering the connections between input and output. This allows the introduction of connections that can skip the evaluation of nodes, e.g. in the expression of 
                        A
                        +
                        B
                     , the result is already set to true as soon as 
                        A
                      evaluates to true. There is no need to evaluate 
                        B
                      in this case. Similarly, in the 
                        A
                        •
                        B
                      case, if 
                        A
                      evaluates to false, the whole expression results in false, not requiring 
                        B
                      to be evaluated. In an Ordered Boolean List, the Blist structure is then stabilized (reducing the nodes width, as defined in  [14]) by continually swapping nodes to effectively re-order the tree resulting in the smallest memory footprint possible for each expression. This results in OBLs that can be created from any expression and can be evaluated in 
                        O
                        
                           (
                           log
                           log
                           n
                           )
                        
                      space.

Compared to CSG, which can be reduced to Boolean values, the BlobTrees skeletal implicit primitives are based on a modified distance field 
                        d
                        
                           (
                           P
                           )
                        
                      (for a set of points 
                        P
                     ) to a given skeleton (defined by a distance function). In order to bound the field to finite space, this distance 
                        d
                      is modified using a filter-fall-off-function, often defined as 
                        f
                        
                           (
                           d
                           )
                        
                        =
                        
                           
                              
                                 (
                                 1
                                 −
                                 
                                    
                                       d
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                           
                           
                              3
                           
                        
                        [26]. A surface is defined by the set of points, whose field-values match a given iso-value 
                        c
                     . Any binary operator node within the BlobTree is a function having two field-values 
                        
                           
                              f
                           
                           
                              1
                           
                        
                      and 
                        
                           
                              f
                           
                           
                              2
                           
                        
                      (calculated at the two child nodes for the same input coordinates) as a parameter, such as for the simplest operators  [11]: 
                        
                           •
                           union: the maximum of 
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                              
                           

intersection: the minimum of 
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                              
                           

difference: the minimum of 
                                 
                                    
                                       f
                                    
                                    
                                       1
                                    
                                 
                               and 
                                 1
                                 −
                                 
                                    
                                       f
                                    
                                    
                                       2
                                    
                                 
                              
                           

blend: a variation of the 
                                 ∑
                                 
                                    (
                                    
                                       
                                          f
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    
                                       
                                          f
                                       
                                       
                                          2
                                       
                                    
                                    )
                                 
                              .

Optimization approaches, which rely on the simplification of Boolean expressions, are not applicable to the BlobTree. Unlike Boolean CSG operators, both sides of a BlobTree operator have to be evaluated for blending, especially when blends are based on the child gradients  [2]. All nodes return scalar values that are combined as described above, potentially changing the inside/outside classification for a point 
                        P
                      based on its numerical value. For example using the Ricci operations, union is 
                        max
                        
                           (
                           
                              
                                 f
                              
                              
                                 1
                              
                           
                           ,
                           
                              
                                 f
                              
                              
                                 2
                              
                           
                           )
                        
                     . Even if 
                        
                           
                              f
                           
                           
                              1
                           
                        
                        >
                        c
                      (CSG-true), it still has to be evaluated as 
                        
                           
                              f
                           
                           
                              1
                           
                        
                      may be greater than 
                        
                           
                              f
                           
                           
                              2
                           
                        
                     .

Looking at the difference operator, we emphasize that pushing an invert operator to the leaf nodes, as done in OBL to simplify the expression, does not work for BlobTrees: Given that in the BlobTree the right child’s field-value is not just negated, but the complement is calculated using 
                        1
                        −
                        f
                     , an inversion at the child node level is not possible since 
                        f
                      can be the result of a non-associative operator. For these reasons, only a subset of the aforementioned CSG acceleration methods can actually be applied to the BlobTree.

Memory reads and writes can have a significant impact on the performance of modern processors, both for CPUs and GPUs, which accelerate applications using prefetching mechanisms and hardware caches. If the memory footprint of the BlobTree is very small, it might be possible to fit a large portion or all of it into the hardware cache, avoiding the more expensive read from main memory.

Because current GPUs make use of cache line aligned reads of memory, they prefer memory access patterns that are easier predictable (e.g. linear reads compared to random access). An example outlined by  [19] is that linear memory reads are hardware accelerated, whereas random access is not. Provided that the data-structures are stored in a way to support cache aligned reads and writes, a coherent memory access pattern can be achieved, resulting in a significant performance improvement. A good performing BlobTree traversal algorithm has a reduced and cache line size aligned memory footprint (see Section  4.2), a decreased number of reads/writes to the temporary storage (see Section  4.3) and (or) a reduced number of memory access direction changes (see Section  7).

In order to use a tree data structure efficiently on modern SPMD architectures (GPUs or CPU vector instruction sets), it is necessary to store the whole tree in contiguous blocks of memory. The usual implementation, where links in the tree are represented by pointers, can lead to bad performance, since memory reads are harder to predict for the hardware, and in many cases the pointers would not lead to a cache aligned memory distribution either. Previous approaches to improving tree traversal are based on linearizing the tree structure (information about parent–child relation) and data (information on the type of node) into arrays of contiguous memory  [41,39,40,42,9].

A simple application that traverses the tree top-down iteratively and stores child relations only in the parent node requires that the parent node is read after visiting the first child. More generally, any top-down traversal algorithm of a tree maintains two stacks of temporary memory: 
                           
                              •
                              the traversal state (information about the previous visited node), 
                                    m
                                 
                              

the temporary results at the nodes, to be used in the parents, 
                                    t
                                 .


                        Fig. 1
                         shows how memory is read (not including the temporary storage stack) in such an approach, resulting in 12 memory reads for the traversal, with 5 changes in the read direction for this small example. In this case, we make use of a tree storage optimization proposed by  [42] that stores child nodes in neighbouring array elements, removing the need to store 2 index offsets per parent node pointing to the children. Whenever our traversal moves deeper down the tree, the current node is pushed to our traversal stack 
                           m
                        . In case of a primitive, we compute the data with the corresponding primitive function for 
                           p
                         and store it in our temporary stack 
                           t
                        . If the current node is an operator, we have to check if both children have been visited and if a child is still to be processed, we push the current node to the stack and make the current node the child node. As soon as both children of an operator have been calculated, we can use their results stored on stack 
                           t
                         to calculate the data values of the operator, write it to the stack 
                           t
                         and use the information in 
                           m
                         to move back up the tree towards the root node.

Apart from the fact that the tree itself is read in a non predictable way (Fig. 1), both of our stacks are involved in a lot of reads and writes. Stack 
                           m
                         has the size 
                           
                              |
                              m
                              |
                           
                         of the maximum height found in the tree. In order to quantify the size of stack 
                           t
                        , we have to define the property right-branching depth 
                        
                           
                              
                                 r
                              
                              
                                 d
                              
                           
                        , which can be calculated recursively. If an interior node 
                           N
                         has two leaf nodes 
                           L
                        , its right-branching depth 
                           
                              
                                 r
                              
                              
                                 d
                              
                           
                         is 0. In the case that 
                           N
                        ’s right child is an operator node 
                           N
                        , the right-branching depth is 
                           max
                           
                              (
                              
                                 
                                    r
                                 
                                 
                                    d
                                 
                              
                              
                                 (
                                 L
                                 )
                              
                              ,
                              
                                 
                                    r
                                 
                                 
                                    d
                                 
                              
                              
                                 (
                                 N
                                 )
                              
                              +
                              1
                              )
                           
                        . The resulting value, incremented by 2, corresponds to the size of the temporary storage stack 
                           t
                        . For any tree 
                           
                              |
                              m
                              |
                           
                           ≥
                           
                              |
                              t
                              |
                           
                        .

We use this approach as our performance base line, in which every interior node 
                           N
                         is visited three times, every leaf 
                           L
                         visited once. Optimizing the tree storage itself, and as a result the number of stacks/stack frames needed, can lead to a much better tree traversal performance. The number of interior node 
                           N
                         visits can be reduced, as demonstrated below.

Much work has been done on how to represent parent–child relations of a tree in memory in order to avoid unnecessary memory reads, e.g. in theory it is not necessary to visit the parent 
                           N
                         node to change from child 
                           L
                         to child 
                           R
                        . As a result, a threaded tree stores this relation directly in every child node by saving the offset to the in-order predecessor and successor  [41]: 
                           
                              •
                              node 
                                    L
                                  stores an array offset to 
                                    N
                                  and to 
                                    R
                                 
                              

node 
                                    R
                                  stores an array offset to 
                                    L
                                  and 
                                    N
                                 .

Looking at the architecture of modern SPMD hardware, especially GPUs, non-cached reads from main memory can often be very slow. This makes finding an approach that does not need to store offset pointers to traverse the tree a desired goal. In fact, not having to store offsets for parent–child relations means that only the tree data is needed.

A BlobTree can be treated as a mathematical expression, with the literals being the leaf nodes that are combined using operators. Consequently, we can apply the same approach as already done in a Blist for CSG, as well as for abstract syntax trees in the context of compilers  [47]: rewriting the expression in reverse Polish notation. In this notation, both operands precede the corresponding operator. Thus, the expression 
                           A
                           ∘
                           B
                         would be rewritten as 
                           A
                           B
                           ∘
                        . This corresponds to a post-order/bottom-up tree traversal, shown in Fig. 3
                        . Compared to a top-down approach, the memory access pattern of the tree data is simpler, reads are only done in one memory direction, independent of tree size and structure, and, as a result, easier to predict for current hardware. This results in 6 reads from memory, compared to the 12 in the original approach. If a certain tree node is of a fraction of the size of a cache line, it can happen that if one node is read into memory, the following node is read as well.


                        
                           
                              
                           
                        
                     

For every field-value computation, we also need to store the intermediate calculation results, in order to combine them at operator nodes. In a recursive approach, storage for these intermediate results is implicitly given by the recursion stack, which the bottom-up approach does not require. Since the traversal is based on the reverse Polish notation of an expression, the storage layout for the temporary results is a stack, where every intermediate result is pushed on, and at an operator the two last results are popped from the stack so they can be combined. This results in Algorithm 1 (for a single thread/field-value calculation).

Given that our implementation targets SPMD architectures, and multiple field-values will be calculated in parallel, the temporary results stack 
                           t
                         is needed for every thread. The more threads are run, the more storage is needed. The maximum size of the stack depends on the structure of the tree.

A tree with 
                           
                              
                                 n
                              
                              
                                 l
                              
                           
                         leaf nodes can be classified as left heavy (Fig. 4
                        (a)), balanced (Fig. 4(b)) or right heavy (Fig. 4(c)), or any combination in between. Depending on this structure, trees with the same number of leaves (primitives) need a bigger or smaller stack to store the intermediate results. The best case for left-child first traversal is a left heavy tree, as shown below in Section  7, as the extreme left heavy example in Fig. 4(a) can be traversed with a constant stack size of 2, independent of the number of leaf nodes 
                           n
                        . Optimizing a tree so that it is as left heavy as possible is desired in order to reduce the size for the temporary variable stack. The basis of this optimization is that the height at every node in the tree is computed, which can be done when the tree is built, as shown by  [13]: 
                           
                              1.
                              A new primitive has height 0.

The height of a new internal node is the maximum of the height of its children, plus 1.

The process of swapping the tree nodes to produce a left heavy tree is integrated into the linearization of the tree into the reverse Polish memory layout. This process is only done once and sets up the tree ready for traversal for each field value query. If the height of the right child is bigger than the left, the algorithm has to traverse the right child first, otherwise the left one, essentially swapping left and right in this case. With the exception of the difference operator, all other operators in the BlobTree are commutative so that swapping has no effect on the resulting field value. A flag is set if a difference operator node is swapped and the algorithm assigns the child results in the opposite order.

This means that the absolute worst case arrangement, in terms of temporary storage, of 
                           
                              
                                 n
                              
                              
                                 l
                              
                           
                         leaf nodes (a perfectly right-heavy tree) can be transformed into the best case, resulting in the temporary storage stack 
                           t
                         of 2. In general, any right-heavy representation can be converted to a corresponding left heavy one, effectively making the previous average case, a balanced tree, to the new worst-case. A perfectly balanced tree has the 
                           t
                         stack size requirements (right-branching depth +2) of 
                           log
                           
                              (
                              
                                 
                                    n
                                 
                                 
                                    l
                                 
                              
                              )
                           
                           +
                           2
                        , where 
                           
                              
                                 n
                              
                              
                                 l
                              
                           
                         is the number of leaf nodes. Any other (already left-heavy transformed) tree with 
                           
                              
                                 n
                              
                              
                                 l
                              
                           
                         leaves needs a stack size that is in between and 2 and 
                           log
                           
                              (
                              
                                 
                                    n
                                 
                                 
                                    l
                                 
                              
                              )
                           
                           +
                           2
                        .

In some cases, the structure of the tree can be converted to a left-heavy version by reordering parent and child relations. This does not work for all combinations of operators, only for ones that are associative and commutative in limited arrangements. Algorithm 2, with the intermediate steps shown in Fig. 5
                        , starts at a node 
                           N
                         with children 
                           L
                         and 
                           R
                         that have been pivoted to be left-heavy. The leaves of 
                           L
                         and 
                           R
                         may be primitives or roots of subtrees with non-compatible operators. In addition, 
                           E
                         is the left most child of 
                           R
                        , 
                           F
                         the parent of 
                           E
                         and 
                           N
                         one child of 
                           P
                        .


                        
                           
                              
                           
                        
                     

This algorithm can only be applied when the path between 
                           N
                         and 
                           F
                         only consists of the same operator type supporting the pivot: the union, intersection and summation blend operators. The optimization steps described in this section need to be applied to the original BlobTree whenever a new linearization of the BlobTree is required. For the reasons given by  [42] in the context of acceleration structures, it is sufficient to optimize the BlobTree only before the linearization step, triggered by a change in the tree. Consequently, this optimization is only done once when needed, whereas Algorithm 1 is run many times and benefits from the optimizations.

In addition to affine transformations, the BlobTree also supports a series of warp transformation, such as the Barr Warps   [1] and more recently Warp Curves   [48] as a form of Free-Form Deformation. Like affine transformations, these warp transformations are represented in the BlobTree as unary nodes at any point in the tree, transforming the whole subtree underneath. Fig. 6
                      shows an example, where the blue nodes represent warp nodes. These nodes apply the inverse transformation to the specific input point coordinates, moving the input point according to the warp to its new location used for any further calculations. When the BlobTree is traversed top-down, the warps can be applied to the input point when encountered. The transformed input point will be used for the sub-tree of the warp node. In contrast, the bottom-up tree traversal, as proposed by this work, requires special handling of warp transformations in order to optimize their performance.

It has been shown by  [42] that pushing the affine transformations to the leaf nodes can cause a large performance improvement simply by reducing the number of matrix–vector calculations during a tree traversal (not limited to BlobTrees), independent of the traversal method used. Often, linearizing the tree and pushing the affine transformations to the leaf nodes, where the transformations are stored as properties, is done at the same time. This makes it possible that the input point coordinates can be transformed into every leaf node’s local coordinate system with only one matrix–vector multiplication done once at every leaf node. As a result, the input point does not have to be transformed along the path from the root to the leaf, a requirement of our bottom-up traversal.

As soon as one warp transformation that cannot be represented using a 
                        4
                        ×
                        4
                      matrix along the path from the root node to the leaf exists, all the affine transformations cannot be pushed to the leaf anymore. However, pushing affine transformations and aggregating them from the BlobTree root downwards until the first warp node is reached is possible. Similarly, pushing and aggregating all affine transformations below a warp transformation is possible until either another warp node or the leaf is reached. As a result, aggregated affine transformations can still be stored as parameters to the leaf instead of nodes within the BlobTree, with the addition that the warp nodes also store an affine transformation as additional property.

In a top-down tree traversal, this optimization would result in a BlobTree that contains unary warp nodes and leaf nodes, both with affine transformation properties and binary operator nodes. As mentioned above, the inverse of these (affine and warp) transformations is applied to the input points before the tree traversal continues until the leaf nodes are reached. Field values are calculated and then combined bottom up to produce the final traversal result.

Looking at this, a full BlobTree traversal in this situation consists of two steps: 
                        
                           1.
                           top-down tree traversal: transforming the input points

bottom-up tree traversal: combining the field-values and potentially gradients and colour.

It has already been shown that in the case of a BlobTree only containing affine transformation, leaving out step one can provide significant performance improvements, since the full traversal can be done only within the bottom-up part. Now that warp transformations are involved, a single leaf node does not have all the information in a bottom-up traversal situation to calculate the correct values yet. A simple solution can store a list of all affine and warp transformations encountered along the path from the root node at every leaf. Such a list of transformations, however, will store the same warp transformations multiple times and can potentially also transform the same input multiple times, resulting in unnecessary work.

For this reason, a subset of the original BlobTree, the Warp Tree, can be used as an optimization. It only contains the warp transformation nodes to simplify the top-down traversal and transforms the input points and stores their respective results. Every leaf node stores a reference (index, offset, etc. depending on the implementation) to its closest warp parent node. The result of this warp transformation is then used as the input point for the bottom-up tree traversal, done without changing the algorithm described above. Fig. 7
                      shows the tree of Fig. 6 split into its Warp Tree and the corresponding BlobTree. Their memory layouts are illustrated underneath, with memory traversals and lookups shown by arrows. The stippling of the arrows corresponds to Fig. 6.

In the same way, any warp node stores a reference to its closest warp parent in order to pick the right input values in the case that several warp transformations occur along the path to a leaf. Linearizing this reduced Warp Tree in depth-first-order into a contiguous array allows for a linear traversal algorithm. This traversal order ensures that at any node, the previous transformation node is already applied to the input points and the result can be read and used for the consecutive calculation. This is shown in Algorithm 3, where a point is transformed by the series of Warp-nodes, and the warped results are stored (at the location corresponding to the warp node) in an array. In order to integrate the warped input into Algorithm 1, a call to Algorithm 3 has to be placed at the start of the function and line 6 needs to read from the array containing the transformed inputs instead of using 
                        p
                     .

Applying the same data layout techniques described above to the bottom-up, field-value “gather” step will also result in a cache-efficient data layout to store the warp transformations, which, depending on their type, are more (Barr warps) or less (Warp Curves) trivial. In the same way, the metrics to optimize are memory usage, memory read direction and random memory access.


                     
                        
                           
                        
                     
                  

@&#IMPLEMENTATION@&#

The implementation of the algorithms use OpenCL 1.2 and are run on a GeForce GTX 780 M. We separate the tree into data and structure (Section  4.2). Only the tree data is needed for the bottom-up measurements, but the top-down ones also require the structure. To minimize the number of cycles it takes to load the nodes into variables, it is desirable that an integer number of tree nodes fit into a cache line (equivalent).

For the node data we store the type of the node and node-type specific data. Since our node types are mutually exclusive, but are very close in size, we decided to store them as a C-union of types to make memory allocation, cache line alignment and array handling easier. The current size of our nodes are 64 bytes (an integer fraction of the cache line equivalent on our GPU). When the tree is traversed, node-type specific functions are called depending on the node type using a switch-case statement. In the case of our base-line top-down traversal, we store the memory as suggested by Wald   [42], where child nodes are stored next to each other (see Fig. 1). This means that for storing the tree structure, we only need one index for the first child, and the second child can be found by incrementing this index, resulting in a 4 byte small value for every tree node. If needed, this approach can easily be extended to 
                        n
                     -ary tree nodes, but in this work we restrict our modelling tree to binary.

Since the field-value calculations are used in polygonization and ray-tracing to calculate surface points, a single field-value calculation also returns compressed, signed, gradients and 8-bit RGB colour values, for a total size of 16 bytes, stored for every intermediate calculation result. Given that gradient and colour calculations at a tree node depend on the field-value, this avoids re-calculating the same field value multiple times.

The number of intermediate results stored is dependent on the input model’s tree structure (see Fig. 4) and the chosen algorithm, and is, therefore, calculated during linearization. Temporary memory is allocated so that every thread is assigned a sub-block, and, consequently, each thread accesses its own region, offset in the larger block. According to GPU vendors, this is a desired memory access patterns  [19], resulting in better performance. The top down approach has access to two memory blocks, one for each stack, with the traversal stack 
                        m
                      having stack frames of size 4. For all the other approaches, the size of a 
                        t
                     -stack frame is 16 bytes (see 4.2).

In our implementation, the input values are stored in OpenCLs constant variable scope. Originally, we wanted to store the intermediate results (and the traversal stack when needed) in local scope since this is faster memory. However, we realized that for many large BlobTrees, the local memory per thread was not big enough. Given these limitations, all the cases store the stacks in global memory for consistency reasons.

@&#RESULTS@&#

We test and compare the performance on a variable sized computer generated test scene. It contains 
                        
                           
                              n
                           
                           
                              l
                           
                        
                      cylinder primitives, all combined with an advanced blend operator  [2]. The bounding volume of this object is sampled 323 times along a regular grid (representing polygonization), thus requiring that many stacks. Given the paper’s focus on tree traversal, we do not count the remaining time for the polygonization algorithm. We use the same resolution for all the models and algorithms so that every test case has the same constant OpenCL scheduling overhead and every performance result is calculated as the average of 32 runs to get rid of outliers due to other system operations.

The graphs for our computer generated test scene plot the average time in 
                           
                              μ
                           
                           
                              s
                           
                         for a single field-value calculation (the tree traversal, and the evaluation of the nodes) for increasing number of leaf nodes. This approach requires the two stacks 
                           m
                         and 
                           t
                        . Fig. 8
                         shows that the left tree and the right tree have similar performance characteristics, with the balanced case being slightly faster. Given that traversing the left and right heavy tree needs the same amount of memory, with the balanced case requiring less, the performance characteristics are not a surprise. This means that the balanced tree should be preferred for the top-down traversal.

Traversing the tree bottom-up creates a better memory access pattern, since every thread loads the tree array from start to end, potentially resulting in several memory load multicasts if threads try to access the same node at the same time. This approach does not require a stack 
                           m
                        ; only the stack 
                           t
                         for the temporary results is needed.


                        Fig. 9
                         includes the best case from Fig. 8 (balanced—shown as a solid line) for reference, and compares it to the run times for the bottom-up traversal. In all cases, bottom-up is faster than top-down. On the other hand, the left-heavy tree case only needs a constant temporary results stack of 2 and shows the best performance of all of them (dotted line with triangle marker). The second fastest case is the right-heavy one, using the largest 
                           t
                         stack of the tree. It seems that temporary memory size on this GPU does not affect performance significantly, and the downfalls of large memory needs can be compensated by a better memory access pattern. In the right heavy case, the 
                           t
                         stack (implemented as an array) is first filled from start to end, and then read from end to start, only changing the access direction once. We conclude that one should favour the production of left-heavy trees for efficient traversal, as already shown for CSG by  [13]. Fig. 9 shows a time difference of one order of magnitude between the best top-down case and the best bottom-up.

Based on work by  [33], we investigated the effect that two acceleration structures, Bounding Volume Hierarchy (BVH)  [49] and Binary Space Partition (BSP) trees  [50], have on the performance of a field-value calculation. In our top-down traversal case, it is very easy to add a BVH to the traversal algorithm, since only a point-in-bounding-volume check has to be added.

However, the early discard property of a BVH cannot be used efficiently in our bottom-up traversal. An acceleration structure that prunes the BlobTree for each space subdivision leaf is the BSP Tree, which has been used widely to improve the visualization times of mesh scenes, resulting in real-time speed for raytracing on the CPU  [43]. We use axis aligned BSP trees (kD trees), for the performance reasoning given by Wald in his thesis,  [42]. Since, in our case, we only need to find the kD node for a given point in space, we do not need to be able to backtrack into neighbouring kD nodes, as demonstrated by  [44]. To avoid storing duplicate nodes, we adapted the skip pointers from  [39], and created index arrays for each kD leaf that work on the array storing the full tree data.


                        Fig. 10
                         compares the four best cases of each algorithm(top-down, top-down plus BVH, bottom-up, bottom-up plus kD), showing two orders of magnitude difference between the worst–best algorithm and the absolute best. Adding an acceleration structure to any of the approaches changes the overall slope of the graph, whereas the pairs of accelerated and unaccelerated curves have approximately a parallel slope once the node count is higher than 16. In the worst case the difference in running time is even bigger. Fig. 11
                         shows that the worst case run time for the top-down approach for 1024 leaf nodes is close to 
                           30
                           
                           
                              μ
                           
                           
                              s
                           
                        . In comparison, the worst run-time for the bottom-up traversal using a kD-tree is 
                           0.15
                           
                           
                              μ
                           
                           
                              s
                           
                        , which is two orders of magnitude faster than top-down. Without the acceleration structures, we are still looking at one order of magnitude difference.

We are limited by GPU memory in the size of trees we can explore, but one can assume that the top-down traversal will continue to increase its run time exponentially, whereas our bottom-up version will grow much slower. We have shown that a top-down traversal of a solid model tree in SPMD is not the best performing algorithm. By modifying the traversal algorithm, including many approaches presented for CSG  [14], the traversal now works bottom up. This improves the memory access pattern and usage, and decreases the execution time of traversal algorithms significantly. With the top-down traversal, adding a BVH is fairly easy, and improves the algorithms run time; however, the trend of the performance still shows an almost exponential slope (linear in a log graph), with increasing leaf nodes. On the other hand, the slope of the graph is a lot shallower for the bottom-up and especially the accelerated bottom-up algorithm, showing that it will lead to better performance in most cases.

The synthetic test scenes are built so that primitives are distributed equally in space, a configuration very unlikely in the real-world. While the synthetic models have a constant distribution of primitives in the surrounding bounding box, real world models will have their primitives clustered and distributed arbitrarily. Consequently, four real world models (see ray-traced images in Fig. 12
                        ) of different sizes were used to investigate the performance of the Bottom-Up algorithm in a more realistic modelling scenario. The models were generated with an interactive modelling system that uses the Bottom-Up approach in the polygonizer. The performance graphs, as explained for the synthetic models, can be found in Fig. 13
                        . They show that the kD-tree is actually slightly slower than the basic bottom-up algorithm. One potential reason for this behaviour is that the median split strategy for the kD-tree is not the best, as proven by  [42]. Furthermore, since there is only a limited amount of splits (same maximum recursion as with the computer generated models), and all the objects are clustered at more or less the same point in space, the pruned trees contained in the leaf nodes will not be much more simplified than the original. As a result, more input data storage is needed without benefiting from the acceleration structure. It only adds traversal overhead to the running times.

Most of the trees used in the examples are very close to left-heavy; thus, adding this optimization did not add a significant performance impact to the models, especially the engine. The memory use for the left-heavy variants of the models stayed the same. Overall, the bottom-up traversal shows similar performance improvements with real-world models due to the reduced memory usage. Interestingly, these models do not benefit as much from the kD-tree as the synthetic BlobTrees.

These four models were chosen because of different distinct properties: 
                           
                              •
                              The donkey model is built from a small number of nodes, but most of them are based on sketched primitives, combined using the summation blend. While the size of the tree is small, the sketched primitives need more time to compute than the cylinder primitives in the synthetic models of the previous section, since they are dependent on the number of control points used to create the sketched field.

Compared to the donkey, they monkey model is built from more sketched primitives that are combined using the same Gradient Based Blend used in the synthetic case. There is a higher distribution of primitives in space compared to the donkey, which results in an improvement of the accelerated test cases, compared to the donkey model.

The robot model uses a wider variety of BlobTree primitives and operators, with the primitives having a good distribution in space. As a result, this model can benefit from an acceleration structure similar to the monkey.

Lastly, the engine model is the largest example. It contains four large parts that are copies of each other, just positioned and rotated differently. Each of the four sub-BlobTrees are largely left-heavy trees, which should show large performance improvements in the bottom-up case. Because these sub-BlobTrees are rotated, the axis-oriented bounding boxes used in the acceleration approaches occupy larger regions of space, resulting in a non-optimal space subdivision. The performance graph shows that the bottom-up approach is almost as fast as the accelerated approaches. Because of the four similar trees, the BVH case works very well at determining an early exit in the top-down traversal, whereas the kD-Tree case cannot improve performance as well.

The performance test case for the inclusion of warp transformations in the tree is fairly similar to the synthetic test scene, where the different traversal methods are compared more generally. In this case, only the Top-Down traversal and the Bottom-Up traversal are compared. Both approaches include the separation of the Warp Tree and the BlobTree. Comparing them to a non-separated version is not possible, since the OpenCL compiler is not able to properly unroll the required loops. The models to be used for testing are based on the number of leaf nodes (primitives in the tree) but only in the balanced tree case. Above every blend node within this balanced tree, a WarpCurve  [48] spanning the underlying model with three control points is inserted, where the middle one is displaced along the surface normal. The larger the number of leaf nodes, the larger the number of interior operator nodes, which is equal to the number of warp curve nodes.

Given that Disc primitives (slightly less expensive than the previously used Cylinder primitives) are combined using the Gradient Based Blend  [2] (see Fig. 14
                        ), the traversal times/calculation times for a single field value evaluation are fairly similar to the cases presented above. However, since each WarpCurve has to calculate its values based on three thin plate splines, and there are 
                           n
                           /
                           2
                         WarpCurves in the test object, most of the calculation time is spent on the warp calculation. The same WarpCurve calculations are done in both cases, so by looking at the difference in the traversal numbers (see Table 1
                        ), there is still a difference between the two traversal methods. As the warps need to be calculated for both cases, and the overhead of the warp calculation overshadows the traversal time in the first place, it can be seen that the difference between Top-Down and Bottom-Up traversal still exists. However, most of the time is spent on calculating the warp and not the tree traversal. Thus, the warp transformation case is computation bound, not memory bound as the previous cases were.

We have presented an accelerated tree traversal for the BlobTree using an approach that results in an 
                        O
                        
                           (
                           n
                           )
                        
                      traversal time. We have shown how to generate predictable memory access patterns, important for performance on modern SIMD architectures, such as GPUs using OpenCL, or using vector instructions on CPUs. By reinterpreting the BlobTree as a mathematical expression and rewriting it in reverse Polish notation, the corresponding bottom-up tree traversal results in a performance improvement of one order of magnitude. We investigated the memory usage of different tree structures, isolated the best performing structure for a given number of BlobTree leaf nodes 
                        
                           
                              n
                           
                           
                              l
                           
                        
                     , and showed how to transform an arbitrary BlobTree into a representation from which the best performance can be achieved. Changing the BlobTree traversal will, consequently, improve the visualization of traditional BlobTree modelling systems  [3] and sketch-based approaches  [5]. Additionally, applications using the BlobTree to improve mesh skinning  [7] also benefit from this traversal approach. Future work includes overcoming the memory limitations employed by current generation GPUs by further reducing the need for intermediate storage. This could require reordering the tree based on the operators to minimize temporary data stack push and pop operations. As a result, we should be able to make use of the smaller, but faster local memory found in current GPUs.

@&#ACKNOWLEDGEMENTS@&#

This work was partially supported by the Natural Sciences and Engineering Research Council of Canada (grant number 5544-2006), the GRAND NCE, Intel Inc., and nVidia Inc.
               

@&#REFERENCES@&#


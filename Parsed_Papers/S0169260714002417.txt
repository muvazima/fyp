@&#MAIN-TITLE@&#Discriminating protein structure classes by incorporating Pseudo Average Chemical Shift to Chou's general PseAAC and Support Vector Machine

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We develop an accurate and high throughput predictor for classification of protein structure classes.


                        
                        
                           
                           It is the combination of Pseudo Average Chemical Shift and SVM.


                        
                        
                           
                           Three datasets were evaluated using jackknife test.


                        
                        
                           
                           Best results are reported so far in the literature.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

SVM

Protein structure classes

PseAA composition

Pseudo Average Chemical Shift

@&#ABSTRACT@&#


               
               
                  Proteins control all biological functions in living species. Protein structure is comprised of four major classes including all-α class, all-β class, α+β, and α/β. Each class performs different function according to their nature. Owing to the large exploration of protein sequences in the databanks, the identification of protein structure classes is difficult through conventional methods with respect to cost and time. Looking at the importance of protein structure classes, it is thus highly desirable to develop a computational model for discriminating protein structure classes with high accuracy. For this purpose, we propose a silco method by incorporating Pseudo Average Chemical Shift and Support Vector Machine. Two feature extraction schemes namely Pseudo Amino Acid Composition and Pseudo Average Chemical Shift are used to explore valuable information from protein sequences. The performance of the proposed model is assessed using four benchmark datasets 25PDB, 1189, 640 and 399 employing jackknife test. The success rates of the proposed model are 84.2%, 85.0%, 86.4%, and 89.2%, respectively on the four datasets. The empirical results reveal that the performance of our proposed model compared to existing models is promising in the literature so far and might be useful for future research.
               
            

@&#INTRODUCTION@&#

Proteins perform various functions in living organisms. The functions of a protein are basically associated with its structure [4]. The structure of protein is constituted according to the behavior and spatial position of amino acids. However, protein structure prediction is totally based on the folding patterns of already existing protein structures. Protein structures are categorized into four main classes including all-α class, all-β class, α+β, and α/β according to the natures and organizations of their secondary structural elements. The all-α class comprises helices whereas all-β class contains strands. The other two classes are the combination of α helices and β strands. The α+β class is composed of anti-parallel β strands whereas the α/β class comprised of parallel β strands. The prediction of protein structure classes is very essential and is useful for studying and annotation of protein function, regulation, and interactions [6]. For this purpose, a lot of efforts have been carried out but still critical challenges exist in developing automated methods, which can determine protein structure fast and accurate. Therefore, a robust, reliable and computationally intelligent model is required for identifying the structural class of the novel protein from their primary sequences. Various algorithms and efforts have been carried out for prediction of protein structure classes since 1980s.

In this connection, numerous investigators have applied different protein sequence representation techniques for encoding protein sequences to extract distinct information. These include amino acid composition [17,67], dipeptide composition [61,78], Pseudo amino acid composition [19,55,85,93,94], function domain composition [22], amino acid sequence reverse encoding [27,64], Position Specific Scoring Matrix profile [44], evolutionary features, and PSI-Blast profiles [11]. Different learning algorithms were utilized in order to predict protein structure classes more accurately including artificial neural network [8], fuzzy clustering [75], Support Vector Machine [3,8,43,71], Bayesian classification [81], and ensemble classification [7,45,92]. Due to the presence of homologous protein sequences, the performance of classification algorithms is highly affected. However, in case of high similarity between training and testing datasets, the performance of classification algorithms is overestimated whereas in case of low similarity the performance of the classification algorithms is underestimated. Kurgan and Homaeian have addressed the problem of varying similarity using ensemble classification [50]. Further, a series of efforts have been carried out to enhance the prediction outcome of the classification algorithm using low similarity datasets. In order to develop a useful computational model various steps are essential, as mentioned in a comprehensive review [21] and other literature [14,58,72,84], the first step is to select a valid benchmark dataset, the second step is to represent the instances with an effective formula, the third step is to introduce a hypothesis for prediction, the four step is using statistical cross validation tests and finally establish a user friendly web server for public access.

In order to enhance the success rates of classification algorithms on low similarity datasets, we, therefore, propose an accurate and robust classification model for prediction of protein structure classes. The model is designed using SVM in conjunction with Pseudo Average Chemical Shift features. The performance of the learning algorithm is evaluated using one of the most rigorous and uniquely generated results known as cross validation jackknife test on four low similarity benchmark datasets.

The rest of the article is organized as follows. Section 1 represents materials and methods, Section 2 describes feature extraction methods, classification algorithm and evaluation methods, Section 3 presents results and discussion finally conclusion is drawn in the last section.

Domain related benchmark datasets are always required for developing a robust and intelligent prediction system. For this purpose, we have used four benchmark datasets with low-similarity, which were employed by many investigators for the evaluation of their automated models [49,64,88]. The datasets 25PDB and 1189 were downloaded from RCSB protein Data Bank [47,48,50]. Dataset 25PDB includes only those protein sequences, which have about 25% of sequence identity. It is comprised of 1673 protein sequences. The second dataset, 1189 dataset contains 1092 protein sequences possessing less than 40% of sequence identity. We have utilized a third dataset referred to as 640 [11], which contains 640 protein sequences with 25% of sequence identity. The number of instances in the datasets are mentioned in Table 1
                        . We have used forth dataset having 399 protein sequences have less than 15% sequence identity [53].

The primary structure of protein is a polymer of amino acids, which formatted and folded according to the attributes of amino acids. These attributes are very vital for the recognition of protein structure classes. Therefore, an efficient feature extraction method is required, in order to extract significant information from the segments of protein structure classes. For this purpose, we have used two feature extraction methods namely PseAA composition and Pseudo Average Chemical Shift.

The primary structure of proteins is a combination of 20 amino acids. So in simple amino acid composition only 20 numerical attributes are explored [15–17,67].
                           
                              (1)
                              
                                 
                                    P
                                    =
                                    
                                       
                                          [
                                          
                                             p
                                             1
                                          
                                          ,
                                          
                                             p
                                             2
                                          
                                          ,
                                          
                                             p
                                             3
                                          
                                          ,
                                          …
                                          
                                             p
                                             
                                                20
                                             
                                          
                                          ]
                                       
                                       T
                                    
                                 
                              
                           
                        where p
                        1 indicates the relative frequency of amino acid A, p
                        2 is the relative frequency of amino acid C, and p
                        20 represents the relative frequency of amino acid Y and P having composition of all amino acids and T is transpose. However, simple amino acid composition only computes the relative frequency of each amino acid but does not retain information regarding protein sequence order and length of sequence. Sometime, only frequency information is not adequate for identifying protein sequences. Therefore, to extract sequence order and many other essential information hidden in protein sequences, Chou has introduced the concept of Pseudo Amino Acid Composition (PseAAC) [18,20], which is the combination of frequency information as well as sequence arrangement information [18]. The concept PseAAC was intensively applied in almost all the fields of computational proteomics such as predicting GABA(A) receptor proteins [66], subcellular localizations [56], identifying bacterial virulent proteins [69], predicting supersecondary structure [97], predicting protein structural classes [73], predicting protein submitochondria locations [68], predicting membrane protein types [45]. In addition, a web-server is also developed for PseAAC [38] recently three powerful open access softwares were developed called ‘PseAAC-Builder’ [32], ‘propy’ [9], and ‘PseAA Composition-General’ [31] for generating various modes of Chou's special PseAA composition. Pseudo k-tuple nucleotide composition was also used for identifying recombination spots and nucleosome positioning sequences [13], identification of nucleosome positioning sequences [40]. Moreover, the application of PseAA composition such as the prediction of cell-wall lytic enzymes [30]. PseAA composition can be represented as
                           
                              (2)
                              
                                 
                                    P
                                    =
                                    
                                       
                                          [
                                          
                                             p
                                             1
                                          
                                          ,
                                          …
                                          
                                             p
                                             
                                                20
                                             
                                          
                                          ,
                                          
                                             p
                                             
                                                20
                                                +
                                                1
                                             
                                          
                                          ,
                                          …
                                          
                                             p
                                             
                                                20
                                                +
                                                λ
                                             
                                          
                                          ,
                                          …
                                          ]
                                       
                                       T
                                    
                                 
                              
                           
                        
                     

The first 20 components are the simple amino acid composition and the remaining are the correlation factors of amino acids determined on the basis of hydrophobicity and hydrophilicity [18].
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         τ
                                                         1
                                                      
                                                      =
                                                      
                                                         1
                                                         
                                                            L
                                                            −
                                                            1
                                                         
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            L
                                                            −
                                                            1
                                                         
                                                      
                                                      
                                                         
                                                            J
                                                            
                                                               i
                                                               ,
                                                               i
                                                               +
                                                               1
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         τ
                                                         2
                                                      
                                                      =
                                                      
                                                         1
                                                         
                                                            L
                                                            −
                                                            2
                                                         
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            L
                                                            −
                                                            2
                                                         
                                                      
                                                      
                                                         
                                                            J
                                                            
                                                               i
                                                               ,
                                                               i
                                                               +
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         τ
                                                         3
                                                      
                                                      =
                                                      
                                                         1
                                                         
                                                            L
                                                            −
                                                            3
                                                         
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            L
                                                            −
                                                            3
                                                         
                                                      
                                                      
                                                         
                                                            J
                                                            
                                                               i
                                                               ,
                                                               i
                                                               +
                                                               3
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   ⋮
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         τ
                                                         λ
                                                      
                                                      =
                                                      
                                                         1
                                                         
                                                            L
                                                            −
                                                            λ
                                                         
                                                      
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            L
                                                            −
                                                            λ
                                                         
                                                      
                                                      
                                                         
                                                            J
                                                            
                                                               i
                                                               ,
                                                               i
                                                               +
                                                               λ
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where L is the length of protein sequence τ
                        1 is the first rank of correlation factor, τ
                        2 is the second rank of correlation and τ
                        
                           λ
                         is the last rank of correlation illustrated in Fig. 1
                        . We have selected the value of λ
                        =30 means taking first 30 ranks of sequence-order correlations into consideration. In this work, we have utilized two physiochemical properties of amino acid hydrophobicity and hydrophilicity. Thus, dimension of the feature space is (20+60)D
                        =80D vector.

In molecules, the density of each electron varies according to the types of nuclei and bonds. However, protons are sensitive to their chemical atmosphere while electron are circulating around them and generates its own magnetic field, which vary the external field of the proton. Proton absorb slightly different frequencies and different magnetic fields in different chemical environments. Chemical shift is the resonant frequencies of the various protons relative to a standard. It is one of the most vital parameters, which is measured by NMR spectroscopy. It is also work as a good indicators of local conformations. The chemical shifts of backbone atoms in proteins are tightly coupled with backbone dihedral angles or secondary structure types [60,77,82]. Numerous researchers have revealed that the Average Chemical Shift of a specific nucleus in the protein backbone couples well to its secondary structure [63,76,95]. Information regarding protein structure is more essential for protein representation. Therefore, Average Chemical Shift can be an efficient parameter for expressing information regarding protein secondary structure and it has been utilized to enhance the discrimination power for various protein subcellular locations and other computational proteomics problems [33,34].

For calculating Pseudo Average Chemical Shift features, we have got protein's secondary structure using Porter [70], it can be accessed online by the following link: http://distill.ucd.ie/porter/. Let us assume A is a protein sequence of L residues long represented by P. Due to the availability of secondary structure of protein sequence A, each amino acid in A is substituted by the Average Chemical Shift. P can be represented as:
                           
                              (4)
                              
                                 
                                    P
                                    =
                                    [
                                    
                                       A
                                       1
                                       i
                                    
                                    ,
                                    
                                       A
                                       2
                                       i
                                    
                                    ,
                                    
                                       A
                                       3
                                       i
                                    
                                    ,
                                    …
                                    ,
                                    
                                       A
                                       L
                                       i
                                    
                                    ]
                                    (
                                    i
                                    =
                                    
                                       N
                                       
                                       
                                       
                                       
                                       
                                          15
                                       
                                    
                                    ,
                                    
                                       C
                                       α
                                       
                                       
                                       
                                       
                                          13
                                       
                                    
                                    ,
                                    
                                       H
                                       α
                                       
                                       
                                       
                                       1
                                    
                                    ,
                                    
                                       H
                                       N
                                       
                                       
                                       
                                       1
                                    
                                    )
                                 
                              
                           
                        where N stands for Nitrogen, C
                        
                           α
                         for alpha Carbon, H
                        
                           α
                         for alpha Hydrogen, and H
                        
                           N
                         for Hydrogen linked with Nitrogen.

After, substitution by Average Chemical Shift, the protein sequence is expressed as follows:
                           
                              (5)
                              
                                 
                                    
                                       P
                                       
                                          P
                                          s
                                          e
                                          A
                                          C
                                          S
                                       
                                    
                                    =
                                    [
                                    
                                       φ
                                       i
                                       0
                                    
                                    ,
                                    
                                       φ
                                       i
                                       1
                                    
                                    ,
                                    
                                       φ
                                       i
                                       2
                                    
                                    ,
                                    …
                                    ,
                                    
                                       φ
                                       i
                                       λ
                                    
                                    ]
                                    (
                                    i
                                    =
                                    
                                       N
                                       
                                       
                                       
                                       
                                       
                                          15
                                       
                                    
                                    ,
                                    
                                       C
                                       α
                                       
                                       
                                       
                                       
                                          13
                                       
                                    
                                    ,
                                    
                                       H
                                       α
                                       
                                       
                                       
                                       1
                                    
                                    ,
                                    
                                       H
                                       N
                                       
                                       
                                       
                                       1
                                    
                                    )
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    
                                       φ
                                       i
                                       λ
                                    
                                    =
                                    
                                       1
                                       
                                          L
                                          −
                                          λ
                                       
                                    
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          L
                                          −
                                          λ
                                       
                                    
                                    
                                       
                                          
                                             [
                                             
                                                A
                                                k
                                                i
                                             
                                             −
                                             
                                                A
                                                
                                                   k
                                                   +
                                                   λ
                                                
                                                i
                                             
                                             ]
                                          
                                          2
                                       
                                       (
                                       i
                                       =
                                       
                                          A
                                          α
                                       
                                       ,
                                       
                                          H
                                          N
                                          
                                          
                                          
                                          1
                                       
                                       ;
                                       λ
                                       <
                                       L
                                       )
                                    
                                 
                              
                           
                        where i indicate the backbone atom. We investigated all the combinations of backbone atom i and auto covariance length λ to find the optimal parameters for prediction. We found that λ
                        =25 and 
                           
                              i
                              =
                              
                                 C
                                 α
                              
                              
                                 H
                                 N
                                 
                                 
                                 
                                 1
                              
                           
                         are the suitable parameters for solving this problem.

After that, the obtained information is provided to the Pseudo Average Chemical Shift web server in conjunction with the original protein sequence to extract the Pseudo Average Chemical Shift features [34,63]. Pseudo Average Chemical Shift web server is accessible at: http://wlxy.imu.edu.cn/college/biostation/fuwu/acACS/index.asp.

Classification is the phase of machine learning where data is categorized into predefined classes. It is also called supervised learning where the targets of these classes are known in advance. In a classification process, classes are represented on the basis of features and characteristics of already known data for which these classes are defined. In this study, we utilized Support Vector Machine (SVM) for the classification of protein structure classes. Detailed discussion about SVM is as follows.


                        SVM is a statistical learning theory used for classification [62,80]. It was developed by Vipnik 1995 for binary classification problems. Later, it was utilized multiclass problems. SVM has been extensively applied in various area of bioinformatics, proteomics, pattern recognition and data mining such as for prediction of subcellular localization [79] for outer membrane protein discrimination [41] prediction of membrane protein types [42] mitochondrial protein prediction [2], and protein methylation sites [74]. SVM maps data into high dimensional space in order to maximize the margin between the two classes of instances. It draws a parallel line to the hyperplane that determines the distance between dividing line and the closest points in the training set to minimize classification errors; the points are called support vectors and the distance is called margin. Radial basis kernel function (RBF) was utilized for our SVM training. RBF is defined as given in the following equation.
                           
                              (7)
                              
                                 
                                    K
                                    (
                                    
                                       x
                                       i
                                    
                                    ,
                                    
                                       x
                                       j
                                    
                                    )
                                    =
                                    exp
                                    {
                                    −
                                    γ
                                    |
                                    |
                                    
                                       x
                                       i
                                    
                                    −
                                    
                                       x
                                       j
                                    
                                    |
                                    
                                       |
                                       2
                                    
                                    }
                                 
                              
                           
                        where the parameter gamma ‘γ’ represents the width of Gaussian function. The cost parameter ‘c’ controls the tradeoff between margin and classification error. Here, we have used the package of LIBSVM “libsvm-mat-2.88-1” and selected the parameters of Lib-SVM using optimization technique [10].

In statistical prediction, usually three cross validation tests namely jackknife, sub-sampling, and independent dataset tests are examined by many investigators for evaluating the effectiveness of their models [25]. Among the three cross-validation methods, jackknife test is deemed the least arbitrary and most rigorous one that can exclude the memory effects during the entire testing process and can always yield a unique result for a given benchmark dataset [24,28,37,39,43,45,46,65,73,84,96]. Accordingly, the jackknife test was also utilized here to examine the quality of the present predictor. It divides the dataset into N folds where one fold is used for testing and remaining N
                        −1 folds for training [5,12,29,38,51,52,54,90]. The evaluation process is repeated N times. The performance of the classification algorithm is measured through the following measures.
                           
                              (8)
                              
                                 
                                    Accuracy
                                    =
                                    
                                       
                                          T
                                          P
                                          +
                                          T
                                          N
                                       
                                       
                                          T
                                          P
                                          +
                                          F
                                          N
                                          +
                                          T
                                          N
                                          +
                                          F
                                          P
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        
                        
                           
                              (9)
                              
                                 
                                    Sensitivity
                                    =
                                    
                                       
                                          T
                                          P
                                       
                                       
                                          T
                                          P
                                          +
                                          F
                                          N
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        
                        
                           
                              (10)
                              
                                 
                                    Specificity
                                    =
                                    
                                       
                                          T
                                          N
                                       
                                       
                                          F
                                          P
                                          +
                                          T
                                          N
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        
                        
                           
                              (11)
                              
                                 
                                    M
                                    C
                                    C
                                    (
                                    i
                                    )
                                    =
                                    
                                       
                                          (
                                          T
                                          P
                                          ×
                                          T
                                          N
                                          −
                                          F
                                          P
                                          ×
                                          F
                                          N
                                          )
                                       
                                       
                                          (
                                          
                                             
                                                [
                                                T
                                                P
                                                +
                                                F
                                                P
                                                ]
                                                [
                                                T
                                                P
                                                +
                                                F
                                                N
                                                ]
                                                [
                                                T
                                                N
                                                +
                                                F
                                                P
                                                ]
                                                [
                                                T
                                                N
                                                +
                                                F
                                                N
                                                ]
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (12)
                              
                                 
                                    F
                                    −
                                    M
                                    =
                                    2
                                    ×
                                    
                                       
                                          Precision
                                          ×
                                          Recall
                                       
                                       
                                          Precision
                                          +
                                          Recall
                                       
                                    
                                 
                              
                           
                        where Precision=(TP/TP
                        +
                        FP) and Recall=(TP/TP
                        +
                        FN)


                        TP, FN, TN, and FP is the number of true positive, false negative, true negative and false positive protein sequences respectively.


                        MCC is a discrete version of Pearson's correlation coefficient that takes values in the interval of [−1, 1]. A value of 1 means the classifier never makes any mistakes and a value −1 means the classifier always makes mistake for more details Eqs. (9)–(13) in Ref. [86] or Eqs. (10)–(14) in Ref. [13].

@&#RESULTS AND DISCUSSION@&#

In this study, we have used two feature extraction strategies, PseAA composition and Pseudo Average Chemical Shift. SVM is used as classification algorithm. The performance of proposed system using each feature extraction strategy is mentioned below.

The success rates of SVM in conjunction with PseAA composition feature space using three benchmark datasets are listed in Table 2
                        . In case of 25PDB dataset, SVM achieved overall accuracy of 80.6% whereas the accuracy for individual protein structure classes is 86.0% for all-α, 82.2% for all-β, 79.6% for α/β, and 74.6% for α+β. Using another dataset 1189, SVM obtained overall accuracy of 82.7%, while the accuracy for each protein structure class is 90.8%, 83.4%, 85.9%, and 70.4%%, respectively for all-α, all-β, α/β, and α+β. Likewise, in case of 640 dataset, overall accuracy of SVM is 81.3% and individual accuracy for each protein structure class is 78.0% for all-α, 74.7% for all-β, 88.7% for α/β, and 81.9% for α+β. We have also evaluated the performance of the SVM through other performance measures including sensitivity, specificity, F-measure, and MCC are reported in Tables 3–5
                        
                        
                         for the three datasets. So, in case of first dataset 25PDB, the overall sensitivity, specificity, MCC and F-measure of the proposed model are 85.5%, 79.0%, 0.58 and 0.36, respectively. The overall and class wise sensitivity, specificity, MCC, and F-measure of the proposed model using 1189 dataset are reported in Table 4. The overall sensitivity, specificity, MCC and F-measure are 80.7%, 83.3%, 0.55, and 0.32, respectively. In case of 640 dataset, the overall and class wise sensitivity, specificity, MCC, and F-measure are listed in Table 5. The overall sensitivity is 80.4%, specificity is 83.3%, MCC 0.55 and F-measure is 0.32. The predicted outcome of proposed model using 399 dataset obtained 83.2% overall accuracy is reported in Table 7
                        .

The success rates of proposed model using Pseudo Average Chemical Shift based features are shown in Table 2. In case of first dataset 25PDB, the proposed model obtained the overall accuracy of 84.2% and likewise 92.2%, 85.4%, 82.2%, and 76.9% for all-α, all-β, α/β, and α+β, respectively. Using the second dataset 1189, the proposed model yielded overall accuracy of 85.0% whereas 92.2% for all-α, 84.0% for all-β, 88.6% for α/β, 74.6% for α+β. In case of third dataset 640, our proposed model achieved an accuracy of 85.0% for all-α, 83.0% for all-β, 86.3% α/β, and 83.2% for α+β where the overall accuracy is 86.4%. Apart from accuracy, we have also computed other performance measures including sensitivity, specificity, MCC, and F-measure in order to evaluate the discrimination power of the SVM as well as Pseudo Average Chemical Shift based features. In case of 25PDB dataset, the overall and class wise sensitivity, specificity, MCC, and F-measure are listed in Table 3. The overall sensitivity, specificity, MCC and F-measure are 90.0%, 82.3%, 0.65, and 0.37, respectively. Subsequently, sensitivity for each class is 92.2%, 88.8%, 91.5%, and 87.5% for all-α, all-β, α/β, and α+β, respectively. Whereas the specificity is 81.4%, 82.6%, 82.0%, and 83.2% for all-α, all-β, α/β, and α+β, respectively. Similarly the MCC and F-measure are 0.66, 0.65, 0.65, 0.64, 0.40, 0.39, 0.35, and 0.35 for all-α, all-β, α/β, and α+β, respectively. In Tables 4 and 5 overall and class wise sensitivity, specificity, MCC, and F-measure of 1189 and 640 datasets are shown. In case of 1189 the overall sensitivity, specificity, MCC and F-measure are 90.0%, 83.5%, 0.65, and 0.35, respectively. Similarly, in case of 640 the overall sensitivity is 85.8%, specificity is 83.3%, MCC is 0.61, and F-measure is 0.33. The success rates of proposed model using 399 dataset are listed in Table 7, whereas the overall accuracy is 89.2%. From the results above, we ascribe the excellent performance of our model to the novel feature vector called Pseudo Average Chemical Shift to construct the features of protein sequence. Pseudo Average Chemical Shift differs from composition-based methods such as amino acid composition and dipeptide composition and from order information-based extraction methods such as pseudo-amino acid composition and amphiphilic pseudo-amino acid composition [13,83,86,89]. Our method includes structure information and represents a different and satisfactory approach for distinguishing protein structural classes. We believe that Pseudo Average Chemical Shift is also a useful and efficient feature extraction tool for protein sequence feature extraction in other bioinformatics problems [33–36].

Owing to large exploration of protein sequences in protein databanks, the importance of computational methods is increased. In the last twenty years, several automated models were developed for prediction of protein structure classes. In each model, the aim of researchers is to enhance the success rate of their model. In this regard, we have made a comparison of our proposed model and already existing models in order to show the importance of our proposed model. The comparison between proposed model and existing models is listed in Table 6
                        . For protein structure classes prediction, the first model was carried out by Kurgan and Chen using two datasets including 25PDB and 1189. The proposed model of Kurgan and Chen have obtained an accuracy of 69.1% and 57.0% for all-α, 61.6% and 62.9% for all-β, 38.3% and 64.6% for α/β, 60.1% and 25.3% for α+β whereas the overall accuracy is 57.1% and 53.9% [48]. Yang et al. proposed model has achieved overall accuracy of 64.0% and 65.2%, respectively using 25PDB and 1189 datasets [87]. The recent approach developed by Zhang et al., for prediction of protein structure classes achieved accuracy of 92.8% and 89.2% for all-α, 83.3% and 86.7% for all-β, 85.8% and 82.6% for α/β, 70.1% and 65.6% for α+β, respectively [91]. Consequently, the overall accuracy is 82.9% and 81.3% correspondingly using datasets 25PDB and 1189. The predicted accuracies obtained by our proposed model are 92.2% for all-α, 85.4% for all-β, 82.2% for α/β, 76.9% for α+β, leading overall accuracy to 84.2% using 25PDB dataset. In case of 1189 dataset, the accuracies are 92.2% for all-α, 84.0% for all-β, 88.6% for α/β, and 74.6% for α+β, whereas the overall accuracy is 85%. The 640 dataset has only been used by Adl et al., for evaluating the performance of their model [1]. They have only reported the overall accuracy of 85.0%. Using this dataset, we have not only reported the overall accuracy but also individual class accuracies. The accuracy values for each class are 85.0%, 83.0%, 86.3%, and 83.2%, for all-α, all-β, α/β, α+β, respectively, and overall accuracy is 86.4%. We have also evaluated the performance of proposed model using 4th dataset. On this dataset, Lin et al., published approach yielded 88.0% overall accuracy [53]. Similarly, our proposed model obtained 89.2% overall accuracy on the same dataset shown in Table 7. So, the success rates of our proposed model are higher than that of the existing models reported in the literature. The empirical results reveal that our proposed model is promising compared to existing results. These results will play key roles in the enhancement of protein structure prediction. Since user-friendly and publicly accessible web-servers represent the future direction for developing practically more useful models, simulated methods, or predictors [23,57], we shall make efforts in our future work to provide a web-server for the method presented in this paper.

@&#CONCLUSIONS@&#

In this study, we proposed an efficient and reliable prediction model for discriminating protein structure classes. The model is based on SVM in conjunction with Pseudo Average Chemical Shift features. In this work, we have examined two feature extraction strategies including PseAA composition and Pseudo Average Chemical Shift. The performance of Pseudo Average Chemical Shift is the best compared to PseAA composition. The result exhibits that the discrimination power of Pseudo Average Chemical Shift is better compared to PseAA composition on the three datasets respectively. Jackknife test was applied to evaluate the performance of the proposed model using four low similarity benchmark datasets. Our proposed model has achieved 84.2% accuracy on 25DBP, 85.0% on 1189, 86.4% accuracy on 640, and 89.2% on 399 datasets. The predicted results reveal that the performance of our proposed model is enhanced as compared to the existing models reported in the literature. It is anticipated that our proposed model might be helpful in future research particularly in low similarity datasets.

The authors declare that they have no conflict of interest.

@&#REFERENCES@&#


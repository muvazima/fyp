@&#MAIN-TITLE@&#Aggregation of local parametric candidates with exemplar-based occlusion handling for optical flow

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An occlusion-aware optical flow estimation based on a discrete aggregation framework.


                        
                        
                           
                           Accurate parametric patch-based scheme for motion candidate computation with an efficient integration of feature matching.


                        
                        
                           
                           A generic exemplar-based approach for recovering motion in occluded regions.


                        
                        
                           
                           Joint motion field and occlusion map estimation guided by an occlusion confidence map obtained from motion candidates.


                        
                        
                           
                           State-of-the-art results on the challenging MPI Sintel dataset for large displacements and occlusions.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optical flow

Occlusion

Large displacement

Local parametric motion

Aggregation framework

@&#ABSTRACT@&#


               
               
                  Handling all together large displacements, motion details and occlusions remains an open issue for reliable computation of optical flow in a video sequence. We propose a two-step aggregation paradigm to address this problem. The idea is to supply local motion candidates at every pixel in a first step, and then to combine them to determine the global optical flow field in a second step. We exploit local parametric estimations combined with patch correspondences and we experimentally demonstrate that they are sufficient to produce highly accurate motion candidates. The aggregation step is designed as the discrete optimization of a global regularized energy. The occlusion map is estimated jointly with the flow field throughout the two steps. We propose a generic exemplar-based approach for occlusion filling with motion vectors. We achieve state-of-the-art results in the MPI-Sintel benchmark, with particularly significant improvements in the case of large displacements and occlusions.
               
            

@&#INTRODUCTION@&#

Optical flow is a key information when addressing important problems in computer vision such as moving object segmentation, object tracking, egomotion computation, obstacle detection or action recognition. The challenge for an optical flow estimation method is to deal with a large variety of image contents and motion types. Optical flow has been historically evaluated on sequences exhibiting small displacements and smooth motion fields, like in the Yosemite sequence [7]. Once initial issues were solved, other challenges were addressed [54], and new situations have been proposed by more recent benchmarks [4,22]. Various and sometimes opposite scene conditions must be handled together, as illumination changes, large areas of smooth motion, motion details, large displacements, motion discontinuities, occluded regions (i.e., points disappearing in the next image).

Optical flow methods first rely on a data constancy assumption, e.g., applied to image intensity or spatial intensity gradient. Then, it is combined with a spatial, or sometimes space-time, coherency constraint on the expected velocity field. Existing approaches can be broadly classified into local and global methods.

Local spatial coherency arises when considering a parametric motion model, e.g., local translation [52], 4-parameter sub-affine model, affine model, 8-parameter quadratic model [59], in a given neighborhood or an appropriate local region. Optimization requires that the neighborhood is sufficiently textured or contains interest points such as corners, to supply accurate and reliable velocity vectors.

In contrast, global methods express the flow field coherency by imposing a global smoothness constraint in addition to the data constancy term, known as the regularization term of the global energy as pioneered by Horn and Schunck [37]. Global methods overcome uncertainty yielded by local supports in uniform intensity regions by diffusing motion from informative to non informative regions via the global regularization constraint. The optimization problem of seminal model [37] was optimally solvable, but the estimation was affected by oversmoothing and was limited to small displacements.

Numerous modifications of this original model, starting with [10,36], have been designed to resolve these two crucial issues, namely, handling of large displacements and preservation of motion discontinuities. It was usually achieved by introducing a multi-resolution and incremental coarse-to-fine framework along with piecewise smoothing or robust estimation. A more recent attempt is to learn statistics of motion fields or motion bases as regularization means [42,57,65,66,82]. The data term of the global modeling has also received attention. Image features like image gradient [19], texture component [79], LDP (Local Directional Pattern) descriptor for illumination-robust data constancy [55], and matching criteria like Normalized Cross Correlation (NCC) [81] or Census transform [35], convey invariance properties to overcome limitations of the classical intensity constancy assumption. However, intricate optimization issues came with the increasing complexity of the modeling.

Although existing local methods are far from being able to compete with global models in terms of accuracy in computer vision benchmarks, several works based on joint estimation and segmentation of the motion field have shown that when appropriate segmented regions are found, affine models can be very accurate representations [71,77]. Yet, the alternate optimization schemes involved are sensitive to the initialization of the region supports.

In this paper, we describe an occlusion-aware optical flow method that we name AggregFlow. It relies on an aggregation framework which explicitly separates the motion candidate computation and the global motion field recovery.

Firstly, we advocate the systematic computation of affine motion models over a set of size-varying square patches, without segmentation step. To this end, we introduce a pre-defined collection of estimation windows to compute motion candidates, which allows us to seamlessly handle any configuration of piecewise continuous motions and a variety of motion scales. To handle large displacements, we combine affine estimation with patch-based matching. Differently from other methods exploiting feature matching as additional constraints [20,80] or coarse initialization [24,85], patch-based matching directly contributes to the computation of real-valued motion vector candidates at every pixel. We experimentally demonstrate that these sets of candidate motion vectors can potentially yield an accurate global flow field.

Secondly, we handle occlusion detection and occlusion filling with motion vectors in the two steps of AggregFlow. The set of motion candidates is in fact extended in two ways: exemplar-based search in occluded areas and use of the estimated parametric dominant motion. The local motion candidates are also exploited to build an occlusion confidence map which intervenes in the global aggregation model. We introduce a novel generic exemplar-based model for occlusion filling. It takes the form of an additional term in the global aggregation energy imposing non-local and image-based constraint on the motion of occluded pixels.

Thirdly, we resort to a discrete aggregation scheme. This kind of optimization approach has been little explored for optical flow computation so far [50], but it appears very promising. In coherence with the above observation about candidates accuracy, we define the aggregation as the selection of one motion candidate at each pixel, while ensuring smoothing of the resulting flow field and preservation of motion discontinuities. The aggregation is achieved with a discrete optimization algorithm, since motion candidates can be seen as labels. The occlusion confidence map enables to guide the joint occlusion and motion estimation, while decoupling the estimation of the two sets of unknown variables.

The main contributions of our method AggregFlow can be summarized as follows:

                        
                           •
                           An accurate parametric patch-based scheme for the motion candidate computation step with an efficient integration of feature matching,

A generic exemplar-based approach for recovering motion in occluded regions,

A joint motion field and occlusion map estimation guided by a local occlusion confidence map obtained from motion candidates.

We have carried out a comprehensive experimental evaluation. Specifically, state-of-the-art results have been obtained for large displacements and occlusions on the challenging MPI Sintel dataset. A preliminary approach without any occlusion handling and dedicated to a specific application was presented in [30].

The paper is organized as follows. Section 2 describes related work. In Section 3, we present the parametric computation of motion candidates and the local detection of occlusions. Section 4 is devoted to the aggregation stage. In Section 5, we report experimental results on three optic flow benchmarks, demonstrating the performance of AggregFlow. Section 6 contains concluding remarks.

@&#RELATED WORK@&#

Hereunder, we briefly review the literature on optical flow computation while focusing on issues related to our contributions. A recent comprehensive survey can be found in [31].

The integration of feature correspondences in dense motion estimation has been investigated in several recent works. A first class of methods integrates feature correspondences in a global energy model. Variational methods [18,20,80] include an additional term to a classical global energy to force the flow to be close to pre-computed correspondences. Giving a fixed weight to the correspondences, this approach is sensitive to matching errors. To overcome this problem, [18,64,75,80] focused on improving the matching step. Another class of methods use correspondences to reduce the search space for discrete optimization and provide a coarse initialization for subsequent refinement [24,56,85]. The main motivation of the attempts based on feature matching is to get rid of the drawbacks of the coarse-to-fine scheme imposed by variational optimization, in particular the loss of large displacements of small objects.

Our patch correspondence is related to [24,56,85] in the sense that it is used in the candidates generation process. However, our method does not produce coarse approximations to be refined in a continuous subsequent step and we do not perform any global variational optimization.

Occlusions play a crucial role for motion estimation [69], especially under large displacements, since no motion measurements are available in occluded areas. Therefore, a proper occlusion handling must distinguish between occlusion detection, segmenting the image into occluded and non-occluded regions, and occlusion filling, applying a specific treatment to motion estimation in occluded regions. Occlusion detection has been mostly undertaken as a subsequent operation to motion computation, by thresholding a consistency measure issued from the estimated motion field, like forward–backward motion mismatch [41], mapping unicity [85] or data constancy violation [83]. A distinctive geometric criterion is introduced in [44]. Occlusions can also be detected independently from motion estimation using image cues like spatiotemporal T-junctions [2]. In stereovision, other criteria like visibility [70] or ordering constraints [16] are also exploited. The main limitation of this sequential approach is that accuracy of occlusion detection is highly dependent on the quality of the initial motion estimation. Several flow and image criteria have been combined in a learning framework [40]. Other approaches estimate the occlusion map jointly with the motion or disparity field in an alternate optimization scheme, encoding one of the above-mentioned criterion in a global energy [3,41,61,70]. Our occlusion detection falls in the latter category.

The problem of filling occluded regions with estimated velocity vectors when the occlusion map is known is closely related to the image inpainting problem. Inpainting methods can be coarsely divided into two classes, diffusion-based methods [9,23] and exemplar-based methods [26,48]. A synthesis of these two approaches has been investigated in [21] in a variational framework. In exemplar-based image inpainting, the missing part is filled by copying pixels of the observed images. The framework is non local in the sense that similar pixels can be sought anywhere in the image. Occlusion filling is usually tackled by diffusion-based (or geometry-oriented) methods, propagating motion from non-occluded regions to occluded regions via partial derivative equation (PDE) resolution [3,8,41,49,61,85]. In stereovision, a weighted least-squares strategy exploits a local averaging of the disparities of non-occluded pixels, with image- or segmentation-based weights [39]. It can be viewed as the local counterpart of the diffusion-based approach. In contrast, we adopt an exemplar-based strategy for occlusion filling with motion vectors, which could be called motion inpainting in occluded regions as well.

Another strategy is to handle occlusion detection and filling simultaneously with layered motion estimation [13,72]. The depth information carried by the layered representation of motion encodes occlusions and disocclusions through relative displacements of overlapping layers.

The use of a parametric model has been widely investigated in motion estimation [11,25,30,38,53,59,71]. Applied on the whole image domain, affine or quadratic models are adequate to estimate the dominant image motion induced by the camera motion [59]. For accurate dense motion estimation, parametric approximations are only valid locally. Local regions are usually defined as square patches centered on each pixel [11,52], possibly with an adaptation of the patch size [68], or its position [43]. It has the merit of being easy to implement with a low computational cost, but it is clearly outperformed by sophisticated extensions of [37] introduced in modern global optical flow methods.

More complex region shapes can be estimated by joint motion segmentation and estimation. Existing approaches can be divided in two classes. A first class of methods relies on an independent image color segmentation and tries to fit parametric motion in each region [12,15,34,84,89], possibly with the help of an independent global variational estimation [12,84]. The drawback is that image color segmentation may lead to an over-segmentation of the motion field. The second class of methods jointly estimates supports of regions and parametric motion models for each region [25,60,71]. It is achieved by minimizing a global energy with respect to supports and motion parameters of the regions. However, the global energy is highly non-convex and particularly sensitive to the initialization of the optimization procedure.

The motion field produced by AggregFlow is composed of affine motion vectors estimated in square patches without any motion segmentation. AggregFlow implicitly selects the best patch size and position when selecting the best motion candidate for each pixel in the second step.

Discrete optimization is an alternative to variational methods and is able to handle more general, non differentiable and non-convex, energy functionals. To combine the subpixel accuracy of the continuous variational approach and the efficiency of discrete minimization, the authors of [50] built a discrete motion space from motion fields delivered by several global variational estimations with different parameter settings. An energy function is then optimized by successive fusions of global proposals, which is efficiently achieved with a graph-cut technique. In [29], we followed a similar approach but with a semi-local patch-based variational estimation of candidate motion vectors. Recent works [24,56] also exploit discrete graph-cut optimization in a two-step paradigm. However, the principle is different than ours. Indeed, the motion candidate generation step only aims to find dominant displacements and the aggregation provides a coarse initialization for a subsequent global refinement. In [32], belief propagation is used to minimize an energy with few candidates selected from a training set of image pairs chosen for their similarity with the input sequence. The dimensionality of the problem is further reduced by defining the graphical model over image patches rather than pixels. Discrete optimization is also associated with a variational framework in [85] as an intermediate stage between scales of a coarse-to-fine framework, in order to capture small objects lost in coarse scale levels. Aggregation in a variational framework has also been investigated in [1], where a set of candidate motion vectors is computed at each pixel using phase correlation in overlapping patches. The candidates are then linearly combined to create a global motion field. A similar approach has been explored for image colorization purposes in [62].

We describe in this section the first step of our method AggregFlow. It exploits local information to supply motion candidates and occlusion cues. A set of motion vector candidates is generated at every pixel by a combination of patch correspondences and local parametric motion model estimates. A specific treatment is applied to occluded regions by exemplar-based extension of the motion candidates set. We also exploit the dominant motion in the image due to camera motion. Motion candidates and occlusion cues form the input of the second stage of AggregFlow described in Section 4.

Our approach can be viewed as a new way to address the problem of choosing the local neighborhood for parametric estimation. Rather than adapting the regions a priori or jointly with the motion field, we operate in two steps: (1) estimation of motion candidates on several supports at every pixel, (2) implicit selection of the best support through the selection of the optimal candidate at each pixel within the aggregation step. In the sequel, we denote two consecutive image frames as 
                        
                           
                              I
                              1
                           
                           ,
                           
                              I
                              2
                           
                           :
                           Ω
                           →
                           R
                           ,
                        
                      with Ω denoting the image domain.

The local supports for motion candidate computation are overlapping square patches of different sizes. Let us denote 
                              
                                 P
                                 
                                    s
                                    ,
                                    α
                                 
                              
                            the patch set for a fixed patch size s and an overlapping ratio α ∈ [0, 1] indicating the proportion of surface shared by neighboring patches (see illustration of Fig. 1
                           ). Let 
                              
                                 S
                                 =
                                 {
                                 
                                    s
                                    1
                                 
                                 ,
                                 …
                                 ,
                                 
                                    s
                                    n
                                 
                                 }
                              
                            be a set of n patch sizes, we then define 
                              
                                 
                                    P
                                    
                                       S
                                       ,
                                       α
                                    
                                 
                                 =
                                 
                                    ⋃
                                    
                                       s
                                       ∈
                                       S
                                    
                                 
                                 
                                    P
                                    
                                       s
                                       ,
                                       α
                                    
                                 
                              
                           . Due to the overlap and the number of patch sizes (n > 1), one given pixel x ∈ Ω belongs to several patches. The motion vectors are estimated independently in each patch in two sub-steps described below: patch correspondences and affine motion estimations.

For each patch 
                              
                                 
                                    P
                                    1
                                 
                                 ∈
                                 
                                    P
                                    
                                       S
                                       ,
                                       α
                                    
                                 
                                 ,
                              
                            we first determine the set 
                              
                                 
                                    M
                                    N
                                 
                                 
                                    (
                                    
                                       P
                                       1
                                    
                                    )
                                 
                              
                            of the N patches in I
                           2 most similar to P
                           1, which allows us to cope with arbitrarily large displacements. Let us put forward that we do not aim at keeping at this stage the best correspondence only but at selecting N relevant correspondences to subsequently constitute motion candidates. The matching step is generic and could be achieved with any arbitrary feature matching algorithm. We use a combination of the saturation and value channels of the HSV color space to gain partial robustness to illumination changes [88] and we use the Sum of Absolute Distances (SAD) to compare patches. The size of the reference patch and of the patches in the search area are the same. For each established pair of corresponding patches 
                              
                                 
                                    P
                                    
                                       1
                                       ,
                                       2
                                    
                                 
                                 =
                                 
                                    (
                                    
                                       P
                                       1
                                    
                                    ,
                                    
                                       P
                                       2
                                    
                                    )
                                 
                              
                            with 
                              
                                 
                                    P
                                    2
                                 
                                 ∈
                                 
                                    M
                                    N
                                 
                                 
                                    (
                                    
                                       P
                                       1
                                    
                                    )
                                 
                                 ,
                              
                            we get the translation vector 
                              
                                 
                                    w
                                    
                                       P
                                       
                                          1
                                          ,
                                          2
                                       
                                    
                                 
                                 ∈
                                 
                                    Z
                                    2
                                 
                              
                            shifting P
                           1 onto P
                           2.

The shift vectors obtained by the patch correspondence step capture large displacements, but they are not accurate enough to constitute a satisfying motion candidate set. Firstly, they convey only integer-pixel accuracy, and secondly, they account for a local translation only inside each patch. To overcome these issues we refine the coarse displacement 
                              
                                 w
                                 
                                    P
                                    
                                       1
                                       ,
                                       2
                                    
                                 
                              
                            by estimating a continuous, affine motion field 
                              
                                 δ
                                 
                                    w
                                    
                                       P
                                       
                                          1
                                          ,
                                          2
                                       
                                    
                                 
                                 ,
                              
                            independently for each pair of patches P
                           1, 2. Denoting 
                              
                                 Ω
                                 
                                    P
                                    1
                                 
                              
                            the pixel sub-domain of P
                           1, the affine motion model 
                              
                                 δ
                                 
                                    w
                                    
                                       P
                                       
                                          1
                                          ,
                                          2
                                       
                                    
                                 
                                 :
                                 
                                    Ω
                                    
                                       P
                                       1
                                    
                                 
                                 →
                                 
                                    R
                                    2
                                 
                              
                            between patches P
                           1 and P
                           2, which have the same size by construction, is defined at pixel 
                              
                                 x
                                 =
                                 
                                    
                                       (
                                       
                                          x
                                          1
                                       
                                       ,
                                       
                                          x
                                          2
                                       
                                       )
                                    
                                    ⊤
                                 
                              
                            as:

                              
                                 (1)
                                 
                                    
                                       δ
                                       
                                          w
                                          
                                             P
                                             
                                                1
                                                ,
                                                2
                                             
                                          
                                       
                                       
                                          (
                                          x
                                          )
                                       
                                       =
                                       
                                          
                                             (
                                             
                                                a
                                                1
                                             
                                             +
                                             
                                                a
                                                2
                                             
                                             
                                                x
                                                1
                                             
                                             +
                                             
                                                a
                                                3
                                             
                                             
                                                x
                                                2
                                             
                                             ,
                                             
                                                a
                                                4
                                             
                                             +
                                             
                                                a
                                                5
                                             
                                             
                                                x
                                                1
                                             
                                             +
                                             
                                                a
                                                6
                                             
                                             
                                                x
                                                2
                                             
                                             )
                                          
                                          ⊤
                                       
                                       .
                                    
                                 
                              
                           The parameter vector 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       P
                                       
                                          1
                                          ,
                                          2
                                       
                                    
                                 
                                 =
                                 
                                    
                                       (
                                       
                                          a
                                          1
                                       
                                       ,
                                       
                                          a
                                          2
                                       
                                       ,
                                       
                                          a
                                          3
                                       
                                       ,
                                       
                                          a
                                          4
                                       
                                       ,
                                       
                                          a
                                          5
                                       
                                       ,
                                       
                                          a
                                          6
                                       
                                       )
                                    
                                    ⊤
                                 
                              
                            of the affine model is estimated assuming brightness constancy and applying first the coarse registration given by 
                              
                                 w
                                 
                                    P
                                    
                                       1
                                       ,
                                       2
                                    
                                 
                              
                           :

                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                θ
                                             
                                             ^
                                          
                                          
                                             P
                                             
                                                1
                                                ,
                                                2
                                             
                                          
                                       
                                       =
                                       
                                          
                                             arg
                                             
                                             min
                                          
                                          
                                             
                                                θ
                                             
                                             
                                                P
                                                
                                                   1
                                                   ,
                                                   2
                                                
                                             
                                          
                                       
                                       
                                          ∫
                                          
                                             Ω
                                             
                                                P
                                                1
                                             
                                          
                                       
                                       ψ
                                       
                                          (
                                          
                                             P
                                             2
                                          
                                          
                                             (
                                             x
                                             +
                                             
                                                w
                                                
                                                   P
                                                   
                                                      1
                                                      ,
                                                      2
                                                   
                                                
                                             
                                             +
                                             δ
                                             
                                                w
                                                
                                                   P
                                                   
                                                      1
                                                      ,
                                                      2
                                                   
                                                
                                             
                                             
                                                (
                                                x
                                                )
                                             
                                             )
                                          
                                          −
                                          
                                             P
                                             1
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          )
                                       
                                       d
                                       x
                                    
                                 
                              
                           where the penalty function ψ( · ) is chosen as the robust Tukey’s function. The problem (2) is solved with the publicly available Motion2D software
                              1
                           
                           
                              1
                              
                                 http://www.irisa.fr/vista/Motion2D/
                              
                            
                           [59], which implements a multi-resolution incremental minimization scheme involving an IRLS (Iteratively Reweighted Least Squares) technique. The algorithm is initialized by setting affine parameters to zero, and the non-convexity of the objective function in (2) is handled with a graduated non-convexity approach [14] iteratively adapting the parameter of the Tukey function.

The above described two-step estimation is repeated for every patch of 
                              
                                 P
                                 
                                    S
                                    ,
                                    α
                                 
                              
                            and generates a set of candidate motion vectors 
                              
                                 C
                                 (
                                 x
                                 )
                              
                            at each pixel x ∈ Ω defined as follows:

                              
                                 (3)
                                 
                                    
                                       
                                          
                                             
                                                C
                                                (
                                                x
                                                )
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                {
                                                
                                                   w
                                                   
                                                      P
                                                      
                                                         1
                                                         ,
                                                         2
                                                      
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                +
                                                δ
                                                
                                                   w
                                                   
                                                      P
                                                      
                                                         1
                                                         ,
                                                         2
                                                      
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                :
                                                
                                                   P
                                                   1
                                                
                                                ∈
                                                
                                                   P
                                                   
                                                      S
                                                      ,
                                                      α
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                ,
                                                
                                                   P
                                                   2
                                                
                                                ∈
                                                
                                                   M
                                                   N
                                                
                                                
                                                   (
                                                   
                                                      P
                                                      1
                                                   
                                                   )
                                                
                                                }
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    P
                                    
                                       S
                                       ,
                                       α
                                    
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 
                                    {
                                    P
                                    ∈
                                    
                                       P
                                       
                                          S
                                          ,
                                          α
                                       
                                    
                                    :
                                    x
                                    ∈
                                    P
                                    }
                                 
                              
                           .

Let us make a few comments on the estimation scheme for computing motion candidates. A coarse motion estimation followed by a refinement step has been investigated in several previous works [24,51,56], but it has always been dedicated to global motion fields. In our case, the refinement is local and adapted to each patch correspondence. Classical local motion estimation methods based on [52] also rely on square patches, but assign the computed motion vector only to the center point of each patch. On the opposite, parametric motion estimation in segmented regions as in [25] applies to regions of arbitrary shape. Our patch distribution can be considered as an intermediate level between these two extremes. Indeed, we use square patches as in [52] and thus avoid the complex segmentation step. However, we exploit the whole vector subfield issued from the affine model estimated in each patch. As a consequence, every pixel inherits several motion candidates from the affine motion estimations performed in patches of different positions and sizes containing this pixel. Finally, in contrast to several other methods using feature correspondences [20,24,80], we do not select one single patch correspondence but we keep the N best ones.

The advantages of the local sets of motion candidates supplied by AggregFlow are three-fold. First, the correspondence sub-step enables us to capture large displacements even for small patch sizes. Thus, it allows us to correctly deal with small structures undergoing large displacements in contrast to coarse-to-fine schemes. Second, by considering a large variety of patches, we get rid of the predefined choice of the local neighborhood encountered in parametric motion estimation. The selection of the proper patch via its corresponding motion candidate is transferred to the aggregation stage. Third, introducing patches of several sizes enables us to tackle motion of different scales.

The generation of motion candidates described in Section 3.1 does not differentiate between occluded and non-occluded pixels. For a given pixel x, if all the patches of 
                           
                              
                                 P
                                 
                                    S
                                    ,
                                    α
                                 
                              
                              
                                 (
                                 x
                                 )
                              
                           
                         mainly contain occluded pixels, there is no chance to correctly estimate a relevant motion candidate at x. Therefore, we compute additional motion candidates in occluded regions in a specific manner.

Let us define the occlusion map o: Ω → {0, 1}

                           
                              (4)
                              
                                 
                                    o
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   if
                                                   
                                                   x
                                                   
                                                   is
                                                   
                                                   occluded
                                                   ,
                                                
                                             
                                          
                                          
                                             
                                                0
                                             
                                             
                                                
                                                   otherwise
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        The occluded regions are denoted 
                           
                              O
                              =
                              {
                              x
                              ∈
                              Ω
                              :
                              o
                              (
                              x
                              )
                              =
                              1
                              }
                           
                        . The computation of map o will be addressed in Sections 3.4 and4, and we assume for now that o is known.

When occluded regions are known, occlusion filling with motion vectors is conceptually closely related to image inpainting, since it recovers motion in regions where motion is by definition not observable. The occluded pixels do not appear in the next image and consequently have no corresponding points. Classical methods for motion-based occlusion filling operate in a variational framework by canceling the data term and letting the diffusion process of the regularization propagate the optical flow in occluded regions [3,85]. The diffusion-based class of inpainting methods [9] acts similarly. They perform well in case of thin missing areas or cartoon-like images, but they are usually outperformed by exemplar-based inpainting methods [26] for large missing regions. In order to deal with large occlusions produced by large displacements, we follow the inpainting analogy and we overcome the problem of local motion candidates estimation in occluded areas by designing an exemplar-based scheme to recover relevant motion candidates. In the first step of AggregFlow, the motion candidates set is thus augmented by copy–paste operations.

We rely on the assumption that motion at an occluded pixel 
                              
                                 x
                                 ∈
                                 O
                              
                            is similar to the motion of a close non-occluded pixel 
                              
                                 
                                    m
                                    o
                                 
                                 
                                    
                                       (
                                       x
                                       )
                                    
                                    ∈
                                    Ω
                                    ∖
                                    O
                                 
                              
                            belonging to the same object or the same background part. To provide relevant motion candidates at x, we copy motion candidates from 
                              
                                 C
                                 (
                                 
                                    m
                                    o
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 )
                              
                            to 
                              
                                 C
                                 (
                                 x
                                 )
                              
                           . mo
                           (x) is sought in a domain 
                              
                                 
                                    V
                                    o
                                 
                                 
                                    ⊂
                                    Ω
                                    ∖
                                    O
                                 
                              
                            which is close to the occlusion boundaries. Fig. 2
                           (e) represents the occluded regions 
                              O
                            (in white) and the search domain 
                              
                                 V
                                 o
                              
                            (in red), and Fig. 2(f) superimposes the two sets on I
                           1. Searching for pixel mo
                           (x) for 
                              
                                 x
                                 ∈
                                 O
                              
                            is actually easier for occlusion filling than for image inpainting. Indeed, occluded regions are not completely uninformative, while inpainted regions are, since we have access to the information supplied by image I
                           1 even in 
                              O
                           . Thus, as mo
                           (x) is expected to belong to the same object as x, we use color similarity to find the match in I
                           1:

                              
                                 (5)
                                 
                                    
                                       
                                          m
                                          o
                                       
                                       
                                          (
                                          x
                                          )
                                       
                                       =
                                       
                                          
                                             arg
                                             
                                             min
                                          
                                          
                                             y
                                             ∈
                                             
                                                V
                                                o
                                             
                                          
                                       
                                       D
                                       
                                          (
                                          
                                             I
                                             1
                                          
                                          ,
                                          x
                                          ,
                                          y
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where D(I
                           1, x, y) is the distance between patches centered respectively in x and y. As in Section 3.1, we resort to a SAD in the HSV space.

An extended candidate set 
                              
                                 
                                    C
                                    +
                                 
                                 
                                    (
                                    x
                                    )
                                 
                              
                            is created for occluded pixels by adding to the initial set 
                              
                                 C
                                 (
                                 x
                                 )
                              
                            the motion candidates of their matched pixel mo
                           (x):

                              
                                 (6)
                                 
                                    
                                       
                                          C
                                          +
                                       
                                       
                                          (
                                          x
                                          )
                                       
                                       =
                                       C
                                       
                                          (
                                          x
                                          )
                                       
                                       ∪
                                       C
                                       
                                          (
                                          
                                             m
                                             o
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          )
                                       
                                       ,
                                       
                                       ∀
                                       x
                                       ∈
                                       O
                                       .
                                    
                                 
                              
                           A more sophisticated addition process could even be envisaged. We could take the velocity vectors provided at x by the parametric models corresponding to the motion candidates of mo
                           (x). By convention, 
                              
                                 ∀
                                 x
                                 ∈
                                 Ω
                                 ∖
                                 O
                                 ,
                              
                           
                           
                              
                                 
                                    C
                                    +
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 C
                                 
                                    (
                                    x
                                    )
                                 
                              
                           .

A particular class of occluded (or disappearing) regions occurs at image borders in the case of large camera motion (Fig. 3
                           ). We cope with this issue by estimating the dominant image motion due to camera motion. To do so, we use again the robust parametric estimation described in Section 3.1, but now, we apply it to the whole image [59], to retrieve the dominant motion. We found in our experiments that the quadratic model was more adequate to accurately cope with large and sometimes complex camera motion. The velocity vector supplied at x by the estimated parametric model of the dominant motion, 
                              
                                 
                                    w
                                    
                                       c
                                       a
                                       m
                                    
                                 
                                 :
                                 Ω
                                 →
                                 
                                    R
                                    2
                                 
                                 ,
                              
                            is added to the motion candidates of x.

We end up with the final overall set 
                              
                                 C
                                 f
                              
                            of motion candidates:

                              
                                 (7)
                                 
                                    
                                       
                                          C
                                          f
                                       
                                       =
                                       
                                          {
                                          
                                             C
                                             f
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          ,
                                          
                                          x
                                          ∈
                                          Ω
                                          }
                                       
                                       ,
                                    
                                 
                              
                           with 
                              
                                 
                                    C
                                    f
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 
                                    C
                                    +
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 ∪
                                 
                                    {
                                    
                                       w
                                       
                                          c
                                          a
                                          m
                                       
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    }
                                 
                              
                           . The camera motion candidates are mostly useful for occluded pixels, but it can sometimes provide relevant motion candidates in unoccluded regions of the background as well, so that we finally add it to all pixels in Ω.

To validate our method for computing motion candidates, we have processed sequences from MPI Sintel and Middlebury datasets [4,22] provided with ground truth. We create the Best Candidate Flow (BCF) by selecting at each pixel x the candidate motion vector of 
                           
                              
                                 C
                                 f
                              
                              
                                 (
                                 x
                                 )
                              
                           
                         closest to the ground-truth vector. In order to evaluate our occlusion module, we distinguish between the BCF determined with the candidates extension described in the preceding section (or full BCF) and the BCF without it. Parameters involved in the local motion computation are set to 
                           
                              S
                              =
                              {
                              16
                              ,
                              44
                              ,
                              104
                              }
                              ,
                           
                        
                        
                           
                              α
                              =
                              0.75
                              ,
                           
                        
                        
                           
                              N
                              =
                              2
                           
                        .

Illustrations of the contribution of motion candidate extensions are provided in Figs. 2 and3 on sequences of the MPI Sintel benchmark involving large occluded regions. The difference between BCF without any candidate extension and the full BCF is clearly visible for occluded pixels and testifies the importance of the exemplar-based and camera motion candidate extensions. Overall, the full BCF is very close to the ground-truth motion field revealing the performance of the local parametric motion computation in the first step of AggregFlow.

We report in Table 1
                         the objective evaluation given by the Endpoint Error (EPE) scores for the full BCF and BCF without candidate extensions, on the sequences provided with ground-truth in the datasets MPI Sintel and Middlebury. We also compare them with those of motion fields supplied by Revaud et al. [64], Weinzaepfel et al. [80] and Xu et al. [85], as obtained with publicly available code. Both BCFs outperform state-of-the-art methods [64,80,85] on the Sintel sequences with ground truth, and also performs better than these four methods on the Middlebury examples provided with ground truth. Accuracy is further significantly improved with full BCF, especially for the MPI Sintel sequences where large displacements and wide occluded regions are present. It demonstrates that the combination of local affine estimations in square patches with patch correspondences as described in Section 3.1, is quite relevant and sufficient to recover very accurate motion fields. The challenge now is to select the best velocity vector among the motion candidates at every pixel.

In Section 3.2, the occlusion map o was assumed to be known, and we addressed the motion-based occlusion filling problem by recovering motion candidates for occluded pixels from non-occluded areas. The occlusion detection task, that is the determination of o, will be performed through the two steps of AggregFlow. In the first step, we compute a coarse occlusion confidence map, which will be used in the aggregation to guide the estimation. Our procedure is simple and exploits the patch distribution 
                           
                              P
                              
                                 S
                                 ,
                                 α
                              
                           
                         and the correspondences used for motion candidates estimation. Nevertheless, from a more general point of view, the coarse occlusion confidence map could be designed differently, e.g., in the framework of [45].

We first perform a coarse occlusion detection at the patch level. We consider the smallest patch size s
                        1 of the set 
                           S
                         defined in Section 3.1 and detect the occluded patches of the set 
                           
                              P
                              
                                 
                                    s
                                    1
                                 
                                 ,
                                 α
                              
                           
                        . A common and simple occlusion detection consists in checking the consistency of forward and backward estimated motion vectors [40,41,56]. We apply the same principle to patches of 
                           
                              P
                              
                                 
                                    s
                                    1
                                 
                                 ,
                                 α
                              
                           
                        . Simplifying the notations of Section 3.1 for the sake of readability, let us denote 
                           
                              T
                              P
                              f
                           
                         the forward translation between a patch P ⊂ I
                        1 and its matched patch MP
                         ⊂ I
                        2, and 
                           
                              T
                              P
                              b
                           
                         the backward translation between MP
                         and its matched patch in I
                        1. The forward–backward consistency criterion states that the patch P is occluded if 
                           
                              
                                 ∥
                              
                              
                                 T
                                 P
                                 f
                              
                              +
                              
                                 T
                                 P
                                 b
                              
                              
                                 ∥
                                 >
                                 ν
                                 ,
                              
                           
                         where ν is a threshold. We then infer a patch-based occlusion map o
                        ℘ as follows:

                           
                              (8)
                              
                                 
                                    
                                       o
                                       ℘
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                1
                                             
                                             
                                                
                                                   if
                                                   
                                                   ∃
                                                   P
                                                   ∈
                                                   
                                                      P
                                                      
                                                         
                                                            s
                                                            1
                                                         
                                                         ,
                                                         α
                                                      
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   
                                                   such
                                                   
                                                   that
                                                   
                                                   P
                                                   
                                                   is
                                                   
                                                   occluded
                                                
                                             
                                          
                                          
                                             
                                                0
                                             
                                             
                                                otherwise.
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Let us now consider the point set 
                           
                              X
                              
                                 o
                                 ℘
                              
                           
                         composed of the centers of the occluded patches. We use the density of the point set as an indicator of the presence of occlusions. We apply a Parzen density estimation on 
                           
                              
                                 X
                                 
                                    o
                                    ℘
                                 
                              
                              =
                              
                                 {
                                 
                                    x
                                    1
                                 
                                 ,
                                 …
                                 ,
                                 
                                    x
                                    
                                       N
                                       ℘
                                    
                                 
                                 }
                              
                              ,
                           
                         with N
                        ℘ the number of occluded patches:

                           
                              (9)
                              
                                 
                                    
                                       ω
                                       o
                                    
                                    
                                       (
                                       x
                                       )
                                    
                                    =
                                    
                                       1
                                       
                                          N
                                          ℘
                                       
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          N
                                          ℘
                                       
                                    
                                    
                                       1
                                       
                                          s
                                          1
                                       
                                    
                                    K
                                    
                                       (
                                       
                                          
                                             x
                                             −
                                             
                                                x
                                                i
                                             
                                          
                                          
                                             s
                                             1
                                          
                                       
                                       )
                                    
                                    ,
                                 
                              
                           
                        where K is a Gaussian kernel. We take the bandwidth equal to s
                        1 to be coherent with the first step of motion candidate computation. The occlusion confidence map ωo
                         is thus built as a probability density of the occlusion state. The closer to 1 the value of ωo
                        (x) the more likely the presence of an occluded point at x. Fig. 4
                         shows an example of o
                        ℘ and ωo
                        . The preliminary occlusion map o
                        ℘ is precisely the map used in the first step of AggregFlow for the exemplar-based candidates extension in occluded regions as described in Section 3.2.2. The map ωo
                         is exploited in the aggregation stage to guide the sparsity-constrained occlusion reconstruction.

The output of the first step of AggregFlow are the overall set 
                           
                              C
                              f
                           
                         of motion candidates and the occlusion confidence map ωo
                        . Then, they are used as input of the second step of AggregFlow, that is, the aggregation, to recover the global motion and occlusion fields. It is described in the next section.

The set of motion candidates at a given pixel is formed by a finite (discrete) set of vectors, but the motion vectors themselves are computed in the continuous space 
                        
                           R
                           2
                        
                      with the affine motion refinement. The final motion vectors are selected among the motion candidates. Since the motion candidates set comprises a finite number of vectors, it can be seen as a discrete set of labels allowing for discrete optimization. The analysis of the Best Candidate Flow in Section 3.3 has shown that the set of candidates at each pixel generally contains at least one motion vector very close to the ground truth. Therefore, we view the aggregation as the selection of the best candidate at every pixel.

To this end, we formulate the aggregation as a discrete optimization problem, where the discrete finite motion vector space at each pixel x is composed of the motion candidates 
                        
                           
                              C
                              f
                           
                           
                              (
                              x
                              )
                           
                        
                     . The occlusion map will be estimated jointly with the motion field while exploiting the occlusion confidence map ωo
                     . The aggregation step amounts to minimizing the global energy function E(w, o):

                        
                           (10)
                           
                              
                                 
                                    
                                       
                                          {
                                          
                                             w
                                             ^
                                          
                                          ,
                                          
                                             o
                                             ^
                                          
                                          }
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             
                                                arg
                                                
                                                min
                                             
                                             
                                                {
                                                w
                                                ,
                                                o
                                                }
                                             
                                          
                                          E
                                          
                                             (
                                             w
                                             ,
                                             o
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                       
                                          
                                          s.t.
                                          
                                       
                                    
                                    
                                       
                                          w
                                          
                                             (
                                             x
                                             )
                                          
                                          ∈
                                          
                                             C
                                             f
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          ,
                                          o
                                          
                                             (
                                             x
                                             )
                                          
                                          ∈
                                          
                                             {
                                             0
                                             ,
                                             1
                                             }
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        
                     In the following, we detail the design of E(w, o) and the optimization strategy we have adopted.

The aggregation energy is composed of four terms:

                           
                              (11)
                              
                                 
                                    
                                       
                                          
                                             E
                                             (
                                             w
                                             ,
                                             o
                                             )
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                E
                                                
                                                   d
                                                   a
                                                   t
                                                   a
                                                
                                             
                                             
                                                (
                                                w
                                                ,
                                                o
                                                ,
                                                
                                                   I
                                                   1
                                                
                                                ,
                                                
                                                   I
                                                   2
                                                
                                                )
                                             
                                             
                                             +
                                             
                                             
                                                E
                                                
                                                   o
                                                   c
                                                   c
                                                
                                             
                                             
                                                (
                                                o
                                                ,
                                                
                                                   ω
                                                   o
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                             
                                                E
                                                
                                                   r
                                                   e
                                                   
                                                      g
                                                      w
                                                   
                                                
                                             
                                             
                                                (
                                                w
                                                )
                                             
                                             
                                             +
                                             
                                             
                                                E
                                                
                                                   r
                                                   e
                                                   
                                                      g
                                                      o
                                                   
                                                
                                             
                                             
                                                (
                                                o
                                                )
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        We now describe in turn each term of the energy function E(w, o).

The data term accounts for the relations between motion, occlusion and input images. At non-occluded pixels, i.e., 
                              
                                 o
                                 (
                                 x
                                 )
                                 =
                                 0
                                 ,
                              
                            we rely on the usual constancy assumption of image intensity and of spatial image gradient, and we robustly penalize the deviation from the data constraints. The potential ρvis
                            associated to non-occluded (or visible) pixels is given by:

                              
                                 (12)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ρ
                                                   
                                                      v
                                                      i
                                                      s
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   w
                                                   )
                                                
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                ϕ
                                                (
                                                
                                                   I
                                                   2
                                                
                                                
                                                   (
                                                   x
                                                   +
                                                   w
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                                −
                                                
                                                   I
                                                   1
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                )
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                +
                                                
                                                γ
                                                
                                                
                                                (
                                                ϕ
                                                
                                                   (
                                                   
                                                      ∇
                                                      
                                                         x
                                                         1
                                                      
                                                   
                                                   
                                                      I
                                                      2
                                                   
                                                   
                                                      (
                                                      x
                                                      +
                                                      w
                                                      
                                                         (
                                                         x
                                                         )
                                                      
                                                      )
                                                   
                                                   −
                                                   
                                                      ∇
                                                      
                                                         x
                                                         1
                                                      
                                                   
                                                   
                                                      I
                                                      1
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                +
                                                
                                                ϕ
                                                (
                                                
                                                   ∇
                                                   
                                                      x
                                                      2
                                                   
                                                
                                                
                                                   I
                                                   2
                                                
                                                
                                                   (
                                                   x
                                                   +
                                                   w
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                                −
                                                
                                                   ∇
                                                   
                                                      x
                                                      2
                                                   
                                                
                                                
                                                   I
                                                   1
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                )
                                                )
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where ϕ is the L
                           1 norm, γ balances intensity and gradient constancy potentials, and 
                              
                                 
                                    ∇
                                    
                                       x
                                       k
                                    
                                 
                                 
                                    I
                                    i
                                 
                              
                            denotes the partial derivative of each image 
                              
                                 
                                    I
                                    i
                                 
                                 ,
                                 i
                                 =
                                 1
                                 ,
                                 2
                                 ,
                              
                            w.r.t. each image coordinate 
                              
                                 
                                    x
                                    k
                                 
                                 ,
                                 k
                                 =
                                 1
                                 ,
                                 2
                              
                           . Resorting to discrete optimization allows us to use the non-linearized brightness constancy equation. Thus, coarse-to-fine scheme is not required to cope with large displacements, and we avoid drawbacks related to the loss of small objects with large displacements.

At occluded pixels, no correspondence can be established by definition, and consequently no image feature constancy constraint can be exploited. Therefore, consistently with the motion candidate extension of the first step, we define an exemplar-based data term for occluded pixels, encoded in the potential ρocc
                           :

                              
                                 (13)
                                 
                                    
                                       
                                          ρ
                                          
                                             o
                                             c
                                             c
                                          
                                       
                                       
                                          (
                                          x
                                          ,
                                          w
                                          ,
                                          m
                                          )
                                       
                                       
                                       =
                                       
                                       
                                          
                                             ∥
                                             w
                                             (
                                             x
                                             )
                                             −
                                             w
                                             (
                                             m
                                             (
                                             x
                                             )
                                             )
                                             ∥
                                          
                                          2
                                       
                                       ,
                                    
                                 
                              
                           where m(x) is the visible pixel matched with pixel x as obtained in (5). The selected motion vector at an occluded pixel is thus expected to be similar to the selected motion vector of its matched non-occluded pixel. The data term is finally formed by incorporating the selection of either the visible or the occlusion potential using the occlusion map:

                              
                                 (14)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   E
                                                   
                                                      d
                                                      a
                                                      t
                                                      a
                                                   
                                                
                                                
                                                   (
                                                   w
                                                   ,
                                                   o
                                                   ,
                                                   
                                                      I
                                                      1
                                                   
                                                   ,
                                                   
                                                      I
                                                      2
                                                   
                                                   )
                                                
                                             
                                          
                                          
                                             =
                                          
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      x
                                                      ∈
                                                      Ω
                                                   
                                                
                                                
                                                   (
                                                   1
                                                   −
                                                   o
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      v
                                                      i
                                                      s
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   w
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                +
                                                
                                                
                                                   λ
                                                   1
                                                
                                                
                                                o
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      o
                                                      c
                                                      c
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   w
                                                   ,
                                                   m
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           In contrast to other occlusion handling schemes in optical flow methods which only cancel the visibility term ρvis
                            in occluded areas and fill the occlusions with motion vectors by diffusion [3,61,85], ρocc
                            acts as a valid exemplar-based data term at occluded pixels.

Concerning the occlusion recovery (i.e., the optimization w.r.t. o), the data term favors the selection of the occluded label at pixels where the data constancy term is strongly violated. The continuous approach of Ayvaci et al. [3] operates in a similar way. In [3], the data constancy deviation is balanced by an estimated continuous residual intensity field, from which occluded points are retrieved by thresholding. In contrast, our occlusion map is binary by nature, and strongly prevents the influence of irrelevant data-constancy constraints on motion estimation in occluded areas.

The data term (14) favors the detection of occluded pixels and must be counterbalanced by another term penalizing occlusion occurrence defined by:

                              
                                 (15)
                                 
                                    
                                       
                                          E
                                          
                                             o
                                             c
                                             c
                                          
                                       
                                       
                                          (
                                          o
                                          ,
                                          
                                             ω
                                             o
                                          
                                          )
                                       
                                       =
                                       
                                          λ
                                          2
                                       
                                       
                                          ∑
                                          x
                                       
                                       
                                          (
                                          1
                                          −
                                          
                                             ω
                                             o
                                          
                                          
                                             (
                                             x
                                             )
                                          
                                          )
                                       
                                       o
                                       
                                          (
                                          x
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where ωo
                            is the occlusion confidence map computed in the first stage. The penalty of occlusion occurrence can be interpreted as a sparsity constraint on the binary occlusion field o. A sparsity constraint for occlusion detection was also proposed in [3] in a continuous setting, and in [61] for a binary occlusion variable, but without confidence map.

If we set 
                              
                                 ∀
                                 x
                                 ∈
                                 Ω
                                 ,
                                 
                                    ω
                                    o
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 0
                                 ,
                              
                            which would be similar to what is done in [3,61], the data-driven occlusion detection would boil down to the data term (14), while (15) would be a pure sparse prior constraint. The detection of the occlusion map would be then too tightly coupled with the currently estimated motion field. We would face a chicken-and-egg problem, where o is determined by w, which also depends on o. The consequence of the alternate optimization scheme would be a rapid trap into a local minimum. This issue and the benefits yielded by our weighting strategy are illustrated in Section 5.

The term 
                              
                                 
                                    E
                                    
                                       r
                                       e
                                       
                                          g
                                          w
                                       
                                    
                                 
                                 
                                    (
                                    w
                                    )
                                 
                              
                            enforces piecewise smoothness of the motion field:

                              
                                 (16)
                                 
                                    
                                       
                                          E
                                          
                                             r
                                             e
                                             
                                                g
                                                w
                                             
                                          
                                       
                                       
                                          (
                                          w
                                          )
                                       
                                       =
                                       
                                          λ
                                          3
                                       
                                       
                                          ∑
                                          
                                             〈
                                             x
                                             ,
                                             y
                                             〉
                                          
                                       
                                       β
                                       
                                          (
                                          x
                                          )
                                       
                                       ϕ
                                       
                                          (
                                          w
                                          
                                             (
                                             x
                                             )
                                          
                                          −
                                          w
                                          
                                             (
                                             y
                                             )
                                          
                                          )
                                       
                                    
                                 
                              
                           where ϕ is the L
                           1 norm, 〈x, y〉 denotes the two-site clique issued from the 8-neighborhood system. The weights β(x) are specified as 
                              
                                 β
                                 
                                    (
                                    x
                                    )
                                 
                                 =
                                 exp
                                 (
                                 −
                                 ∥
                                 ∇
                                 
                                    I
                                    1
                                 
                                 
                                    (
                                    x
                                    )
                                 
                                 
                                    ∥
                                    2
                                 
                                 /
                                 
                                    τ
                                    2
                                 
                                 )
                              
                            to modulate the regularization according to the intensity edge strength.

It is also important to impose smoothness of the occlusion map with the term 
                              
                                 E
                                 
                                    r
                                    e
                                    g
                                 
                                 o
                              
                           :

                              
                                 (17)
                                 
                                    
                                       
                                          E
                                          
                                             r
                                             e
                                             
                                                g
                                                o
                                             
                                          
                                       
                                       
                                          (
                                          o
                                          )
                                       
                                       =
                                       
                                          λ
                                          4
                                       
                                       
                                          ∑
                                          
                                             〈
                                             x
                                             ,
                                             y
                                             〉
                                          
                                       
                                       
                                          (
                                          1
                                          −
                                          δ
                                          
                                             (
                                             o
                                             
                                                (
                                                x
                                                )
                                             
                                             =
                                             o
                                             
                                                (
                                                y
                                                )
                                             
                                             )
                                          
                                          )
                                       
                                       ,
                                    
                                 
                              
                           where δ designates the Kronecker function equal to 1 if its argument is true.

The optimization problem (10) is solved by alternating minimization w.r.t. w and o. The initial value of o is given by the coarse patch-based occlusion detection o
                        ℘ defined in (8). The set m of matching points attached to the exemplar-based candidates extension is initialized with mo
                         defined in (5). It is recomputed after each update of the occlusion map. Table 2
                         gives an overview of AggregFlow method.

Hereafter, we give details on the minimization procedure concerning w and o. Once 
                              
                                 w
                                 ^
                              
                            is fixed, the energy to optimize w.r.t. o amounts to:

                              
                                 (18)
                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                   min
                                                   o
                                                
                                                
                                                   ∑
                                                   
                                                      x
                                                      ∈
                                                      Ω
                                                   
                                                
                                                
                                                   (
                                                   1
                                                   −
                                                   o
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      v
                                                      i
                                                      s
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   
                                                      w
                                                      ^
                                                   
                                                   )
                                                
                                                
                                                +
                                                
                                                
                                                   λ
                                                   1
                                                
                                                
                                                o
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      o
                                                      c
                                                      c
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   
                                                      w
                                                      ^
                                                   
                                                   ,
                                                   m
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                
                                                +
                                                
                                                
                                                   λ
                                                   2
                                                
                                                
                                                   ∑
                                                   x
                                                
                                                
                                                   ω
                                                   o
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                o
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                
                                                +
                                                
                                                
                                                   λ
                                                   4
                                                
                                                
                                                   ∑
                                                   
                                                      〈
                                                      x
                                                      ,
                                                      y
                                                      〉
                                                   
                                                
                                                
                                                   (
                                                   1
                                                   −
                                                   δ
                                                   
                                                      (
                                                      o
                                                      
                                                         (
                                                         x
                                                         )
                                                      
                                                      =
                                                      o
                                                      
                                                         (
                                                         y
                                                         )
                                                      
                                                      )
                                                   
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           Since the pairwise term is submodular, the problem (18) can be solved exactly with standard graph cut method [17].

The optimization w.r.t. w with 
                              
                                 o
                                 ^
                              
                            fixed is more difficult. The reduced energy function writes:

                              
                                 (19)
                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                   min
                                                   w
                                                
                                                
                                                   ∑
                                                   
                                                      x
                                                      ∈
                                                      Ω
                                                   
                                                
                                                
                                                   (
                                                   1
                                                   −
                                                   
                                                      o
                                                      ^
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      v
                                                      i
                                                      s
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   w
                                                   )
                                                
                                                
                                                +
                                                
                                                
                                                   λ
                                                   1
                                                
                                                
                                                
                                                   o
                                                   ^
                                                
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                
                                                
                                                   ρ
                                                   
                                                      o
                                                      c
                                                      c
                                                   
                                                
                                                
                                                   (
                                                   x
                                                   ,
                                                   w
                                                   ,
                                                   m
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                          
                                             
                                                
                                                +
                                                
                                                
                                                   λ
                                                   3
                                                
                                                
                                                   ∑
                                                   
                                                      〈
                                                      x
                                                      ,
                                                      y
                                                      〉
                                                   
                                                
                                                
                                                   
                                                      β
                                                      
                                                         (
                                                         x
                                                         )
                                                      
                                                      ϕ
                                                      (
                                                      ∥
                                                      w
                                                      
                                                         (
                                                         x
                                                         )
                                                      
                                                      −
                                                      w
                                                      
                                                         (
                                                         y
                                                         )
                                                      
                                                      ∥
                                                   
                                                   2
                                                
                                                
                                                   )
                                                   .
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           The global motion label space Cf
                            has the specificity to be huge and space-variant. Indeed, the size of each individual set 
                              
                                 
                                    C
                                    f
                                 
                                 
                                    (
                                    x
                                    )
                                 
                              
                            can already exceed 200, and by construction the content of 
                              
                                 
                                    C
                                    f
                                 
                                 
                                    (
                                    x
                                    )
                                 
                              
                            depends on x. Message passing methods like belief propagation [28] and TRW-S [47] can be applied to spatially varying label sets, as investigated in [78] for stereo, but we found these methods to be too slow for our minimization problem (19). An alternative is to resort to graph-cut move-making methods [17], generalized in [50] to spatially varying label sets. In this setting, each move is a binary optimization problem defined on an auxiliary variable selecting between two global proposals. Due to the spatial variability of the proposals and their independence, the submodularity of the regularization potential of (19) cannot be ensured, and only suboptimal moves can be achieved using QPBO [67].

Another issue arises from the non-local interaction involved in the exemplar-based term ρocc
                           (x, w, m). To make the optimization problem tractable, we transform ρocc
                           (x, w, m) to a pixel-wise term at each move-making iteration by fixing the exemplar-based constraint w(m(x)) to its value at the previous iteration. At a given move-making iteration i, denoting 
                              
                                 
                                    w
                                    ^
                                 
                                 
                                    (
                                    i
                                    −
                                    1
                                    )
                                 
                              
                            the value of w at iteration 
                              
                                 i
                                 −
                                 1
                                 ,
                              
                            the potential becomes:

                              
                                 (20)
                                 
                                    
                                       
                                          ρ
                                          
                                             o
                                             c
                                             c
                                          
                                       
                                       
                                          (
                                          x
                                          ,
                                          w
                                          ,
                                          m
                                          )
                                       
                                       =
                                       
                                          
                                             ∥
                                             w
                                             
                                                (
                                                x
                                                )
                                             
                                             −
                                             
                                                
                                                   w
                                                   ^
                                                
                                                
                                                   (
                                                   i
                                                   −
                                                   1
                                                   )
                                                
                                             
                                             
                                                (
                                                m
                                                
                                                   (
                                                   x
                                                   )
                                                
                                                )
                                             
                                             ∥
                                          
                                          2
                                       
                                       .
                                    
                                 
                              
                           
                        

Our aggregation problem differs from the one of [50] since our motion candidates are locally determined. In contrast, [50] exploits global flow fields that can be directly used as proposals in the move-making process. Thus, we have to build global flow field proposals at each iteration from the local motion candidates computed in patches. The important point is to ensure spatial smoothness of the proposals, in accordance with the regularization term of the model (19). Therefore, we build a global flow field proposal by considering a tiling of non-overlapping patches of a given size and by selecting at every pixel in each patch the motion candidate precisely issued from that patch. This construction maintains the spatial coherency of the local affine estimations. We build as many global proposals as necessary to reasonably explore the motion candidate space.

@&#EXPERIMENTAL RESULTS@&#

In this section, we assess the performance of AggregFlow with experiments on several optic flow benchmarks and we deeply analyze the contribution of AggregFlow in occlusion areas.

First, we provide information on implementation and parameterization issues.

All the patch correspondences involved in AggregFlow are computed with the PatchMatch algorithm [6] based on the minimal C++ code provided by the authors
                           2
                        
                        
                           2
                           
                              http://gfx.cs.princeton.edu/pubs/Barnes_2009_PAR/index.php
                           
                        . For the discrete minimization, we use available QPBO and max-flow code
                           3
                        
                        
                           3
                           
                              http://pub.ist.ac.at/~vnk/software.html
                           
                        .

The three datasets used for the experimental evaluation exhibit very different motion characteristics. The Middlebury dataset involves small displacements, and motion discontinuities often occur. The KITTI dataset only contains sequences acquired with a camera embedded in a moving car, which produces smooth and diverging motion fields. Finally, the MPI Sintel benchmark is the most challenging one, with very large displacements and occlusions, and a large variety of motion types, from complex smooth deformation to discontinuous piecewise constant motion. Therefore, the parameters of the method have to be adapted to obtain optimal results. Parameter λ
                        1 does not have a decisive influence since it aims to give comparable range to the data term at occluded and non-occluded pixels. Parameter λ
                        2 controls the amount of detected occluded pixels. In presence of large occluded regions, data conservation is often violated and λ
                        2 should be set large enough to counterbalance this effect. Parameter λ
                        3 is a classical regularization parameter on the motion field. Parameter λ
                        4 accounts for the strength of the regularization of the occlusion map, it should be high enough when occlusion regions are large. After extensive experimental tests, the aggregation parameters have been set to 
                           
                              
                                 λ
                                 1
                              
                              =
                              5
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 2
                              
                              =
                              50
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 3
                              
                              =
                              500
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 4
                              
                              =
                              20
                           
                         for for all the image sequences of the MPI Sintel benchmark, to 
                           
                              
                                 λ
                                 1
                              
                              =
                              2
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 2
                              
                              =
                              10
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 3
                              
                              =
                              250
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 4
                              
                              =
                              4.5
                           
                         for all the image sequences of the Middlebury dataset and to 
                           
                              
                                 λ
                                 1
                              
                              =
                              2
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 2
                              
                              =
                              10
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 3
                              
                              =
                              500
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 4
                              
                              =
                              30
                           
                         for the KITTI dataset. The determination of the corresponding visible points m(x) is performed with patches of size 11 × 11.

To capture different motion scales, the patch sizes must cover a sufficient range of values. In all our experiments, we will use 
                           
                              S
                              =
                              {
                              16
                              ,
                              44
                              ,
                              104
                              }
                           
                        . To avoid that the set 
                           
                              
                                 M
                                 N
                              
                              
                                 (
                                 
                                    P
                                    1
                                 
                                 )
                              
                           
                         uselessly contains too close patches, we impose a minimal distance between two patches of 
                           
                              
                                 M
                                 N
                              
                              
                                 (
                                 
                                    P
                                    1
                                 
                                 )
                              
                           
                        .

For the initial patch-based detection of occluded points, the threshold ν is set to 10. In the exemplar-based motion candidates extension, the domain 
                           
                              V
                              o
                           
                         is obtained by dilating the occluded regions by 20 pixels and by taking the band given by the dilated regions minus the original ones.

We fix the number of overall updates on the motion field w and the occlusion map o to 3 for all sequences to save computation time. Indeed, convergence was empirically observed after three iterations in most cases. A weighted median filtering with bilateral weights [86] is performed on the computed motion field as a post-processing step to enhance motion edges as advocated in [73].

As a representative example, the computation time for the Urban2 sequence of the Middlebury benchmark (640 × 480 pixels) is 27  min on a Intel Xeon laptop with 2.20 GHz clock speed and 64 Gb RAM. More precisely, the first step of candidates computation takes 10 minutes, the global optimization step 15 min, and the weighted median filter 2 min. Most of the computation time is consumed in the patch correspondence sub-step for the largest patch size (106 × 106 pixels). We have not dedicated specific effort to optimize the code so far. Computation time is higher than for most variational approaches, but it could be reduced by some simple implementation tricks. For instance, the first step of AggregFlow can be massively parallelized on GPU. The correspondence step could be handled in a different way for the largest patch size, by downsampling the patches for instance. Besides, the use of integral images for matching can significantly accelerate computation [27]. Alternative algorithms for parametric image registration could also be envisaged [74]. Fast weighted median filter [90] can also be exploited in the post-processing step. Another strategy to speed-up the aggregation step could be to reduce the size of the set 
                           
                              C
                              f
                           
                         by adding a pruning step based on a simple criterion like forward/backward consistency [41].

We have evaluated AggregFlow on three optical flow benchmarks: MPI Sintel flow dataset
                           4
                        
                        
                           4
                           
                              http://sintel.is.tue.mpg.de/
                           
                         
                        [22], Middlebury flow dataset
                           5
                        
                        
                           5
                           
                              http://vision.middlebury.edu/flow/
                           
                         
                        [4], and KITTI dataset
                           6
                        
                        
                           6
                           
                              http://www.cvlibs.net/datasets/kitti/
                           
                         
                        [33]. The MPI Sintel benchmark is the most relevant one to assess AggregFlow performance since it involves wide occlusion areas and large displacements, which are precisely the issues on which AggregFlow is claimed to bring significant contributions. The Middlebury benchmark offers other challenges as preservation of motion details. The KITTI dataset is not as generic as the two first datasets for evaluating optic flow methods. Indeed, it delivers very specific diverging motion fields since the camera is mounted on a moving vehicle and observes static street scenes. We have retained the Endpoint Error measure (EPE) for quantitative evaluation.


                        MPI Sintel flow dataset. Sequences of the MPI Sintel benchmark [22] are characterized by long-range motion, motion blur, non-rigid motion, and wide occluded areas. Methods are evaluated on two versions of the sequences named Clean and Final. The Final version adds motion and defocus blur along with atmospheric effects like fog on some sequences. We reproduce in Table 3
                         the top 12 published methods (including ours at paper submission date) in the MPI Sintel benchmark for the Clean set. Table 4
                         contains the performance of the same twelve methods for the Final set. Results are analyzed through several indicators: “EPE all” is the average EPE on all the sequences; “EPE matched” and “EPE unmatched” restrict the error measure respectively to regions that remain visible in adjacent frames (non-occluded pixels) and to regions that are visible only in one of two adjacent frames (occluded pixels); “d0-10” denotes EPE over regions closer than 10 pixels to the nearest occlusion boundary, and thus reveals the ability to recover motion discontinuities; “s40+” denotes EPE over regions with velocities larger than 40 pixels per frame. Methods are ranked regarding their EPE all.

We first conducted experiments on MPI Sintel sequences provided with ground truth. Results on four sample sequences are displayed both for motion field estimation and occlusion map determination in Fig. 5
                        . Visual comparison with motion fields estimated with the state-of-the-art methods [64,85] is also provided. They have been obtained with the public codes provided by the authors
                           7
                        
                        
                           7
                           
                              http://lear.inrialpes.fr/src/epicflow/
                           
                        
                        ,
                        
                           8
                        
                        
                           8
                           
                              http://www.cse.cuhk.edu.hk/~leojia/projects/flow/
                           
                        . These results will be commented hereunder within the discussion on Tables 3 and 4.

For the Clean set, our method AggregFlow ranks third over the published methods. The competitive performance on the unmatched category (ranked third) emphasizes the efficiency of our occlusion framework. AggregFlow is ranked sixth for the d0-10 metric (but very close to PH-Flow [87] ranked third), which demonstrates its capacity to recover motion discontinuities as confirmed by results displayed in Fig. 5. First, it is due to the robust affine estimation of the motion candidates able to capture locally dominant motion in case of two or more motions present inside patches. It is also made successful by the efficient occlusion module, which allows us to moderate the need for motion field regularization. Indeed, missing information in occluded regions is usually tackled by imposing high regularization, resulting in oversmoothing the rest of the motion field. In case of very large displacements (acknowledged by s40+ metric), all the first methods (AggregFlow, [5,51,64,80,85,87]) somehow integrate feature matching in their motion estimation process to capture the largest deformations. The high ranking of AggregFlow (ranked third) for this metric demonstrates the efficiency of the aggregation framework for integrating feature matching.

As for the Final set, AggregFlow is ranked fifth in terms of EPE-all. The slight decrease in performance compared to the Clean set is mainly due to errors caused by the added fog effect in the two ambush sequences. An even more pronounced performance decrease is also observed for PH-Flow [87]. As emphasized in [5], local intensity-based displacement computation tends to capture the motion of the fog rather than the movement of objects appearing in transparency. As our candidates estimation is local, it is subject to this limitation. Global variational approaches are able to diffuse motion estimates in these regions and are consequently better suited for this kind of situations. Despite this shortcoming, our method still yields significant improvement in unmatched regions and on motion discontinuities. One solution to improve results in fog regions would be to incorporate a more sophisticated feature correspondence technique as the ones proposed in [51,80].


                        Middlebury dataset. The Middlebury benchmark is composed of sequences with small displacements, where the main challenge is to be able to recover both complex smooth deformation, motion discontinuities and motion details. Table 5
                         reproduces results (if any) for the same methods as those listed for the MPI Sintel benchmark, since we consider that the latter is the prevailing benchmark, especially to evaluate methods on the currently most challenging issues, occlusion and large displacements. It can be observed that the average EPE-all values computed over the eight test sequences, together with the differences between methods, are much smaller than for the MPI Sintel dataset. The mean of the average EPE-all score computed over the compared methods in Table 4 is equal to 7.56 for the MPI Sintel Final subset and to 0.343 for the Middlebury dataset (from Table 5). We also provide the average rank over the 8 test sequences for each method which is the metric used for global ranking on the Middlebury website.

On the whole Middlebury benchmark, AggregFlow, at time of submission, is ranked 44 over 114 tested methods (which are not all published) in terms of average rank. The average rank is deduced from the ranks respectively obtained for the eight test sequences, each rank being established from the average endpoint error on the sequence. Let us emphasize that performances are very close in terms of average accuracy. For instance, the LSM method [42] ranked 25th, has an average EPE-all score of 0.316, which is only better than AggregFlow for 0.023. The difference between the EPE-all scores of AggregFlow and MDP-Flow2 [85] ranked second in the Middlebury benchmark is 0.094, whereas AggregFlow outperforms MDP-Flow2 with a difference of 1.093 in the MPI Sintel Clean beanchmark. Let us mention that the top ranked published method is OFLAF [46] which has an average rank of 8.1 and an average EPE-all of 0.197 (OFLAF method was not tested on the MPI Sintel benchmark).

A visual comparison with MDP-Flow2 [85] and EpicFlow [64] is provided in Fig. 6
                        . These sample results confirm the tightness of performance between methods on that dataset. Let us mention that the preservation of motion discontinuities with AggregFlow is more accurate than with the EpicFlow method and close to MDP-Flow2 performance. These results also show that AggregFlow is still competitive for recovering motion details in addition to the large velocities of the MPI Sintel benchmark.


                        KITTI dataset. The sequences of the KITTI dataset [33] are recorded by a camera mounted on a moving vehicle. The displacements are only due to camera motion, which results in very specific diverging motion fields as illustrated in Fig. 5.2
                        . The best performing methods in this benchmark are dedicated to this particular motion type and consider additional information like multi-views or epipolar constraint.

A typical artifact generated by AggregFlow for this kind of sequences comes from the block artifacts usually generated by graph cut optimization (already identified in [58]), particularly prominent in case of smooth variations of the motion field, as it is the case in the KITTI benchmark.

We summarize in Table 6
                         results, when available, of the methods introduced for comparison on the MPI Sintel benchmark (Tables 3 and 4). We give the average end-point error over the whole image (EPE-all) and the percentage of erroneous pixels in non-occluded areas (Out-noc). The latter is the score used for the main ranking in the KITTI benchmark. Clearly, AggregFlow is less competitive on that particular benchmark. It is also the case for the EPPM method [5]. Several methods use sophisticated matching method or data constancy constraints to cope with the frequent intensity changes in the benchmark image sequences, and these techniques could be integrated in our aggregation framework to improve results. Another major problem on KITTI comes from the patch matching step, particularly affected by the scale change due to the zooming effect generated by the vehicle movement along the camera axis of view. Scale invariant patch matching should be implemented to cope with this problem. The best performing method on the KITTI benchmark among the methods which exploit only two frames and no epipolar constraint is PH-Flow [87]. The second best one is NLTGV-SC [63], with EPE-all score of 3.8 px and Out-noc score of 5.93%). Performances of AggregFlow could be improved by adopting features of NLTGV-SC particularly well suited to the KITTI benchmark, like Total Generalized Variation reducing staircasing artifacts in smoothly varying motion fields, or scale invariant data conservation adapted to the zooming effect of the KITTI sequences.
                     

The occlusion issue is nowadays one of the few main obstacles, if not the main, to improve optic flow methods. As aforementioned the impact of our occlusion framework on optical flow estimation was demonstrated by the EPE unmatched metric scores obtained on the MPI Sintel benchmark (Tables 3 and 4). Recovered occlusion maps displayed in Figs. 5 and6 visually revealed the great ability of AggregFlow in coping with occluded regions. For the large occluded regions of Fig. 5 for which ground truth is available, the estimated occlusion map is correct in most cases. A specific behavior is noticeable in the market_5 example, where occlusions are overdetected. It is due to the modeling assumption stating that occluded regions correspond to large violations of the data constancy equation. Regions of illumination changes may thus be detected as occlusions. While it leads strictly speaking to wrong occlusion detection, it can still be beneficial to motion estimation by implicitly treating illumination changes.

To complete the experimental evaluation of AggregFlow, we want now to further explore the performance of AggregFlow related to the occlusion issue. Since the occlusion framework is composed of several elements, we detail the influence of each one in the following. The efficiency of the motion candidates extension in occluded regions has already been highlighted in Section 3.3 and Table 1 through the analysis of the Best Candidate Flow.

We first investigate the role of the occlusion confidence map involved in the sparsity constraint (15). Illustrations are given in Fig. 8
                        . The results of two variational methods, LDOF [20] and DeepFlow [80], are also displayed in Fig. 8 (e and f) for comparison. For these two methods, the motion subfield in the occluded region highlighted by the red bounding box, is wrongly estimated since no explicit occlusion detection is performed. If the occlusion map is initialized to 
                           
                              o
                              (
                              x
                              )
                              =
                              0
                              ,
                              
                              ∀
                              x
                              ∈
                              Ω
                              ,
                           
                         the occlusion terms of AggregFlow energy (11) are canceled in the very first iteration of the alternate optimization, which results in a similar behavior as the one of LDOF and DeepFlow methods [20,80]. If 
                           
                              ∀
                              x
                              ∈
                              Ω
                              ,
                              
                                 ω
                                 o
                              
                              
                                 (
                                 x
                                 )
                              
                              =
                              1
                              ,
                           
                         the convergence remains trapped in the initial local minimum, as displayed in Fig. 8 (g and h). The reason is that the occlusion map is strongly determined by the estimated motion field and cannot deviate from the output of the first iteration. The role of the confidence map ωo
                         is then to act as an additional evidence for occlusion detection, relaxing the coupling between w an o. The guidance of ωo
                         enables to deviate from the output of the first iteration and to converge to the result shown in Fig. 8 (i and j).

We now focus on the evaluation of the occlusion model of the aggregation step. For this purpose, we distinguish between the full AggregFlow method, and AggregFlow without the occlusion-related terms in (11) removed by setting 
                           
                              
                                 λ
                                 1
                              
                              =
                              0
                              ,
                           
                        
                        
                           
                              
                                 λ
                                 2
                              
                              =
                              0
                           
                         and 
                           
                              
                                 λ
                                 4
                              
                              =
                              0
                           
                        . Nevertheless, the occlusion handling in AggregFlow first step is still kept for the production of motion candidates in occluded regions. To assess the impact of the occlusion rate on the method performance, we have selected training sequences of the MPI Sintel dataset for the “clean” pass, with progressive occlusion rates from 11% to 20%. Comparative evaluation between the two versions of AggregFlow and competitors of Table 3 with available code (EpicFlow [64], DeepFlow [80], and MDP-Flow2 [85]) is reported in Table 7. The improvement due to the occlusion terms in AggregFlow energy is clearly significant on all examples when comparing with AggregFlow without occlusion terms. AggregFlow performance is the second best one for the first occlusion rates while being close to EpicFlow (apart from the temple-3 example), and is the best one for higher occlusion rates.

@&#CONCLUSION@&#

We have defined a two-step method for optical flow computation called AggregFlow which handles occlusion detection and occlusion filling with motion vectors in an original and efficient way. It yields accurate parametric motion candidates at every pixel in a first step, and resorts to a discrete optimization to aggregate sets of motion candidates into the global flow field. Our method can be viewed as a novel and efficient combination of local and global approaches for occlusion-aware optical flow computation. It articulates the computation of local motion candidates and their global aggregation while jointly recovering occlusion maps. The framework is generic, and both the local and global steps could be adapted for specific purposes.

We demonstrated the added value of combining patch correspondences and patch-based affine motion estimation to produce highly accurate motion candidates, advocating the relevance of patch-based parametric motion estimation, provided size and position of the patches are appropriately defined. The integration of multiple patch correspondences in the candidates generation process allows us to deal with local matching ambiguities. We formulated the aggregation step as a discrete optimization problem, selecting the best motion candidate at every pixel while preserving motion discontinuities and achieving occlusion recovery. The occlusion scheme acts in both steps of AggregFlow. An exemplar-based occlusion term is incorporated in the global aggregation energy. Incidentally, it could be integrated in other estimation paradigms as well, e.g., in variational approaches. Occlusion cues derived from the computed motion candidates are exploited in the sparse modeling of occlusions. Overall, AggregFlow achieves state-of-the-art results on the MPI Sintel benchmark. The most significant improvements are reached in occluded regions and for large displacements.

Extensions of the method could tackle remaining matching errors in the patch correspondence and in the exemplar search substeps. A more elaborate and discriminative distance than the pixel-based L
                     1 distance could be envisioned for patch matching. Future work could also deal with a GPU implementation to largely improve computation efficiency.

@&#ACKNOWLEDGMENTS@&#

This work was realized as part of the Quaero program, funded by OSEO, French State agency for innovation. It was also partly supported by the France-BioImaging project granted by the “Investissement d’Avenir” national program.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Mining a Persian–English comparable corpus for cross-language information retrieval

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose novel method for mining high quality translation from comparable corpus.


                        
                        
                           
                           We introduce Term Association Network (TAN) for mining Translation knowledge.


                        
                        
                           
                           We propose a new method for term translation validity using cross outlier detection.


                        
                        
                           
                           Results show that proposed methods significantly outperforms dictionary-based method.


                        
                        
                           
                           Our methods are specially effective in translating OOV terms by expanding query words.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Comparable corpora

Cross-language information retrieval

Term association network

Translation validity check

@&#ABSTRACT@&#


               
               
                  Knowledge acquisition and bilingual terminology extraction from multilingual corpora are challenging tasks for cross-language information retrieval. In this study, we propose a novel method for mining high quality translation knowledge from our constructed Persian–English comparable corpus, University of Tehran Persian–English Comparable Corpus (UTPECC). We extract translation knowledge based on Term Association Network (TAN) constructed from term co-occurrences in same language as well as term associations in different languages. We further propose a post-processing step to do term translation validity check by detecting the mistranslated terms as outliers. Evaluation results on two different data sets show that translating queries using UTPECC and using the proposed methods significantly outperform simple dictionary-based methods. Moreover, the experimental results show that our methods are especially effective in translating Out-Of-Vocabulary terms and also expanding query words based on their associated terms.
               
            

@&#INTRODUCTION@&#

The researches on Cross Language Information Retrieval (CLIR) have recently received much attention, due to the fast growth of the World Wide Web and the availability of information in different languages on the Web. One of the main issues in CLIR is where to obtain the translation knowledge (Oard & Diekema, 1998). Multilingual corpora are widely used for this purpose which are actually available in many language pairs and extracting translation knowledge from multilingual corpora has been extensively studied using various statistical methods. They can be either in the form of parallel or comparable corpora. However, there are limitations in obtaining parallel corpora in all domains and languages while comparable corpora are much easier resources to obtain. Thus, recently, there has been considerable interest in using comparable corpora as translation resources (e.g. Fung & Yee, 1998; Sadat, 2010b; Talvensaari, Laurikkala, Järvelin, Juhola, & Keskustalo, 2007; Tao & Zhai, 2005). In this paper we use a Persian–English comparable corpus, University of Tehran Persian–English Comparable Corpus (UTPECC) (Hashemi, Shakery, & Faili, 2010), to do English–Persian cross language information retrieval by extracting term associations from the comparable corpus. These association terms my contain both translations of a term, and terms that are actually related to its (correct) translations. In this paper, all selected translations and related terms for a term are referred to as its “translations”. As a basic method, we obtain term associations based on co-occurrence of terms in the alignments. We further propose a novel way of extracting translations in different languages based on Terms Association Network (TAN) which exploits term associations in monolingual data as well as bilingual term associations to better detect translation knowledge. TAN method uses a network of terms with implicit mutual information links between terms in the same language and term association links between terms in different languages. The main contribution of this paper lies in combining these term association links as a network, which in turn improves CLIR effectiveness. Basically, we use the neighborhoods of terms in this network to re-score the translation alternatives. Two terms are translations of each other if their neighborhoods in the same language are strongly connected and vice versa they are not likely to be translations if their neighborhoods are not strongly connected. Also, in order to discard misleading translation candidates, we do translation validity check using cross-outlier detection method. Intuitively, if the distribution of the weights of a term’s translations is different from that of its neighbors’ translations, the term is considered as an outlier.

We evaluated our methods on Hamshahri and INFILE data sets by doing cross-language information retrieval using the cross-lingual term associations extracted from the comparable corpus. We use the extracted translation knowledge to construct a query language model in the target language corresponding to each query in the source language and rank the documents based on the KL-divergence between the query language model and document language models. Experiments show promising results for extracting translation knowledge from the UTPECC by (1) translating Out Of Vocabulary (OOV) terms, such as proper nouns, which are not in our dictionaries, (2) expanding query words with their related terms and also (3) using probability scores of extracted translations. Also, using comparable corpora helps to complement dictionaries by translating OOV terms and finding related terms to expand query words.

The rest of the paper is organized as follows. We first present some previous work done on exploiting comparable corpora in Section 2. We then introduce our translation extraction and query translation methods in Sections 3 and 4. We present the experiment results in Section 5 and finally bring the conclusions and future work of our study in Section 6.

Using comparable corpora as a language resource has been studied extensively in the existing literature, in fields such as cross-language information retrieval (Picchi & Peters, 1996; Sadat, 2010a, 2010b; Sadat, Yoshikawa, & Uemura, 2003; Talvensaari et al., 2007), cross-lingual document association (Tao & Zhai, 2005; Vu, Aw, & Zhang, 2009), in extracting parallel sentences (Abdul-Rauf & Schwenk, 2009; Munteanu & Marcu, 2005) and extracting word translations (Fung, 1995; Fung & Yee, 1998; Hassan, Fahmy, & Hassan, 2007; Laroche & Langlais, 2010; Morin, Daille, Takeuchi, & Kageura, 2007; Morin, Daille, Takeuchi, & Kageura, 2010; Otero & Campos, 2010; Rapp, 1995; Rapp & Zock, 2010; Tanaka & Iwasaki, 1996; Tao & Zhai, 2005; Udupa, Saravanan, Kumaran, & Jagarlamudi, 2008; Yu & Tsujii, 2009). Most of the early work in extracting word translations employ an initial lexicon of seed words (e.g. Franz, McCarley, & Roukos, 1999; Fung & Yee, 1998; Picchi & Peters, 1996; Rapp & Zock, 2010; Sadat et al., 2003) and some of them are based on linguistic knowledge such as language morphologies (e.g. Sadat, 2010b; Yu & Tsujii, 2009). We follow the research on extracting word translations without requiring any additional linguistic resources (e.g. Talvensaari et al., 2007; Tao & Zhai, 2005) and use the extracted knowledge to translate queries for cross-language information retrieval. In order to do CLIR, we construct query language models based on scores of extracted related terms from the comparable corpus. Trieschnigg, Hiemstra, de Jong, and Kraaij (2010) use a similar approach to train their translation model in CLIR using a corpus.

The problem of exploring a comparable corpus and its combination with a dictionary to do CLIR has been studied before in Talvensaari et al. (2007) and Sadat (2010b). However, our methods in both extracting translation knowledge and constructing query translations are different from theirs. Talvensaari et al. (2007) have built a comparable corpus query translation program (Cocot) which we use as our baseline. They also combine the comparable corpus results with dictionary-based query translation (UTACLIR) and construct queries in the InQuery format, while we use a simple dictionary and construct query language models. Sadat (2010b) presents a two-stage corpus-based translation model which aims to find translations of a source word in the target language corpus and also translations of the target words in the source language corpus. The two stages contain bi-directional extraction of bilingual terminology from comparable corpora and selection of best translation alternatives based on a morphological analyzer. She has also exploited the linear combination of comparable corpus results with bilingual dictionaries. In both works, the impact of comparable corpora on cross-language information retrieval especially combining the extracted translations with dictionaries has been shown to be effectively positive.

In this section, we propose a process for learning cross-lingual term associations from comparable corpora. As a first step, we extract translation knowledge using term co-occurrences in the comparable corpus alignments. In the second step, we propose a method based on term association network which exploits term associations in monolingual data as well as bilingual term associations to better extract translation knowledge. We further propose to use cross-outlier detection to filter out misleading translation candidates which are detected as outliers. We will present each step in more detail in the rest of this section.

As the basic method, in order to extract term associations from the comparable corpus, we use the method used in Cocot, the comparable corpus query translation program which is proposed in Talvensaari, Pirkola, Järvelin, Juhola, and Laurikkala (2008). The intuition of this method is to use term co-occurrences in the alignments to extract term associations. The algorithm first calculates a weight m
                        
                           ik
                         for each term s
                        
                           i
                         in document d
                        
                           k
                         as:
                           
                              (1)
                              
                                 
                                    
                                       m
                                    
                                    
                                       ik
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0
                                                
                                                
                                                   if
                                                   
                                                   
                                                      
                                                         tf
                                                      
                                                      
                                                         ik
                                                      
                                                   
                                                   =
                                                   0
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            0.5
                                                            +
                                                            0.5
                                                            ×
                                                            
                                                               
                                                                  
                                                                     
                                                                        tf
                                                                     
                                                                     
                                                                        ik
                                                                     
                                                                  
                                                               
                                                               
                                                                  
                                                                     
                                                                        Maxtf
                                                                     
                                                                     
                                                                        k
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   ×
                                                   ln
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  NT
                                                               
                                                               
                                                                  
                                                                     
                                                                        dl
                                                                     
                                                                     
                                                                        k
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   otherwise
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where tf
                        
                           ik
                         is the frequency of s
                        
                           i
                         in document d
                        
                           k
                        , Maxtf
                        
                           k
                         is the largest term frequency in d
                        
                           k
                         and dl
                        
                           k
                         is the number of unique terms in the document. NT can be either the number of unique terms in the collection or its approximation. In our experiments, these frequencies are computed after stopword removal. This tf.idf modification is adopted from Sheridan and Ballerini (1996) who also used it in similarity thesaurus calculation. The weight of a target term t
                        
                           j
                         in a set of ranked target documents D is calculated as:
                           
                              (2)
                              
                                 
                                    
                                       M
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          r
                                          =
                                          1
                                       
                                       
                                          |
                                          D
                                          |
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             m
                                          
                                          
                                             jr
                                          
                                       
                                    
                                    
                                       ln
                                       (
                                       r
                                       +
                                       1
                                       )
                                    
                                 
                                 ,
                              
                           
                        where D is the set of target documents aligned with a source document containing t
                        
                           j
                        . The documents in D are ranked based on their alignment scores. Less similar documents, which appear lower in the list, are trusted less for translation and their weights are penalized. This penalization is achieved by ln(r
                        +1) in the denominator.

Finally, the similarity weight between a source term s
                        
                           i
                         and a target term t
                        
                           j
                         is calculated as
                           
                              (3)
                              
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 (
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                                 →
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             〈
                                             
                                                
                                                   d
                                                
                                                
                                                   k
                                                
                                             
                                             ,
                                             D
                                             〉
                                             ∈
                                             A
                                          
                                       
                                       
                                          
                                             m
                                          
                                          
                                             ik
                                          
                                       
                                       ×
                                       
                                          
                                             M
                                          
                                          
                                             j
                                          
                                       
                                    
                                    
                                       ‖
                                       
                                          
                                             s
                                          
                                          
                                             i
                                          
                                       
                                       ‖
                                       ×
                                       
                                          
                                             
                                                (
                                                1
                                                -
                                                α
                                                )
                                                +
                                                α
                                                ×
                                                
                                                   
                                                      ‖
                                                      
                                                         
                                                            t
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ‖
                                                   
                                                   
                                                      
                                                         
                                                            ‖
                                                            T
                                                            ‖
                                                         
                                                         
                                                            ‾
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where m
                        
                           ik
                         is the weight of source term s
                        
                           i
                         in the source document d
                        
                           k
                        , M
                        
                           j
                         is the weight of target term t
                        
                           j
                         in the set of target documents D which are aligned with the source document d
                        
                           k
                        , A is the set of all alignments, 
                           
                              ‖
                              
                                 
                                    s
                                 
                                 
                                    i
                                 
                              
                              ‖
                           
                         is s
                        
                           i
                        ’s norm vector, 
                           
                              
                                 
                                    ‖
                                    T
                                    ‖
                                 
                                 
                                    ‾
                                 
                              
                           
                         is the mean of the target term vector lengths, and α is a constant between 0 and 1 (we chose α
                        =0.2 same as (Talvensaari et al., 2008)). In this formula, we use pivoted vector normalization scheme, instead of standard cosine normalization, to prevent harsh penalization of long feature vectors (that is, words with high document frequency) (Hashemi et al., 2010).

Cocot only considers term co-occurrences in the alignments of source and target documents of the comparable corpus to extract translations, but we perceive that we can also consider term co-occurrences in the monolingual data to get better translation knowledge. Some terms in each language are about to happen in the same topics, such as ‘tennis’ and ‘Wimbledon’. We can use this information to improve the quality of extracted translations. Intuitively, two terms have a high chance of being translations of each other if the terms in their neighborhoods in the same language are highly correlated with each other. In other terms, if their neighborhoods are not correlated, they are less likely to be translations of each other even though they are obtained as translations. Thus, we propose to construct a network of related terms that consists of all the terms in the source language and all the terms in the target language. The edges between two terms in the same language are based on their co-occurrences in that language and the edges between terms in different languages are based on the mined associations. In our experiments we use mutual information as the links between terms in the same language and the normalized values extracted by the Cocot method as the links between terms in different languages. Fig. 1
                         shows the structure of the network. In this figure, the thickness of the lines shows the importance of the edges. Intuitively, if two terms are translations of each other, their neighborhoods are strongly connected and if their neighborhoods are not strongly connected, they are not likely to be translations.

As an example, in the extracted translations by Cocot in our experiments, the highest ranked translation for the term “Wimbledon” is not correct, and the correct translation is scored very low. This mistranslation can be because of the small number of aligned documents containing the term ‘Wimbledon’ in the comparable corpus. Our goal is to improve the translation quality of the list of terms extracted by the basic method by reranking the translation terms using the term network. As can be seen from Fig. 1 which is part of the network for the term ‘Wimbledon’, its neighborhood in its own language is more strongly connected to the neighborhood of its correct translation compared to the neighborhood of the incorrect translation. This observation leads us to rerank the list of translations based on the strength of the connection between their neighborhoods and the neighborhood of the source language term.

Using this network, we propose to update the weight of the translation link between source and target terms s and t using general function f as:
                           
                              (4)
                              
                                 w
                                 (
                                 s
                                 ,
                                 t
                                 )
                                 =
                                 f
                                 (
                                 
                                    
                                       w
                                    
                                    
                                       0
                                    
                                 
                                 (
                                 s
                                 ,
                                 t
                                 )
                                 ,
                                 sim
                                 (
                                 
                                    
                                       N
                                    
                                    
                                       S
                                    
                                 
                                 (
                                 s
                                 )
                                 ,
                                 
                                    
                                       N
                                    
                                    
                                       T
                                    
                                 
                                 (
                                 t
                                 )
                                 )
                                 )
                              
                           
                        where w
                        0(s,
                        t) is based on mined association between s and t, N
                        
                           S
                        (s) is the set of source language terms in the neighborhood of s, N
                        
                           T
                        (t) is the set of target language terms in the neighborhood of t and sim(N
                        
                           S
                        (s), N
                        
                           T
                        (t)) indicates the similarity of two neighborhoods, which can be computed based on the relevance scores of source language terms in N
                        
                           S
                        (s) and target language terms in N
                        
                           T
                        (t). In order to calculate the similarity of neighborhoods, we consider the paths between two terms (s and t) that go through their neighborhoods (N
                        
                           S
                        (s) and N
                        
                           T
                        (t)). The stronger the links between two neighborhoods, the more similar the neighborhoods will be.

In our experiments, we consider one specific case of this model which consists of weights of all the paths with length one, two or three between the two specified source and target terms. The updated translation weight between source and target terms s and t is calculated as:
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             w
                                             (
                                             s
                                             ,
                                             t
                                             )
                                             =
                                          
                                       
                                       
                                          
                                             
                                             f
                                             (
                                             
                                                
                                                   w
                                                
                                                
                                                   0
                                                
                                             
                                             (
                                             s
                                             ,
                                             t
                                             )
                                             ,
                                             sim
                                             (
                                             
                                                
                                                   N
                                                
                                                
                                                   S
                                                
                                             
                                             (
                                             s
                                             )
                                             ,
                                             
                                                
                                                   N
                                                
                                                
                                                   T
                                                
                                             
                                             (
                                             t
                                             )
                                             )
                                             )
                                          
                                       
                                    
                                    
                                       
                                          
                                             =
                                          
                                       
                                       
                                          
                                             
                                             α
                                             
                                                
                                                   w
                                                
                                                
                                                   0
                                                
                                             
                                             (
                                             s
                                             ,
                                             t
                                             )
                                          
                                       
                                    
                                    
                                       
                                          
                                             +
                                          
                                       
                                       
                                          
                                             
                                             β
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               ∑
                                                            
                                                            
                                                               
                                                                  
                                                                     s
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               ∈
                                                               
                                                                  
                                                                     N
                                                                  
                                                                  
                                                                     S
                                                                  
                                                               
                                                               (
                                                               s
                                                               )
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            MI
                                                         
                                                      
                                                      (
                                                      s
                                                      ,
                                                      
                                                         
                                                            s
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      )
                                                      ·
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            0
                                                         
                                                      
                                                      (
                                                      
                                                         
                                                            s
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      ,
                                                      t
                                                      )
                                                      +
                                                      
                                                         
                                                            
                                                               ∑
                                                            
                                                            
                                                               
                                                                  
                                                                     t
                                                                  
                                                                  
                                                                     j
                                                                  
                                                               
                                                               ∈
                                                               
                                                                  
                                                                     N
                                                                  
                                                                  
                                                                     T
                                                                  
                                                               
                                                               (
                                                               t
                                                               )
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            0
                                                         
                                                      
                                                      (
                                                      s
                                                      ,
                                                      
                                                         
                                                            t
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      )
                                                      ·
                                                      
                                                         
                                                            w
                                                         
                                                         
                                                            MI
                                                         
                                                      
                                                      (
                                                      
                                                         
                                                            t
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ,
                                                      t
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             +
                                          
                                       
                                       
                                          
                                             
                                             γ
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      
                                                         
                                                            s
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                      ∈
                                                      
                                                         
                                                            N
                                                         
                                                         
                                                            S
                                                         
                                                      
                                                      (
                                                      s
                                                      )
                                                      ,
                                                      
                                                         
                                                            t
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      ∈
                                                      
                                                         
                                                            N
                                                         
                                                         
                                                            T
                                                         
                                                      
                                                      (
                                                      t
                                                      )
                                                   
                                                
                                             
                                             
                                                
                                                   w
                                                
                                                
                                                   MI
                                                
                                             
                                             (
                                             s
                                             ,
                                             
                                                
                                                   s
                                                
                                                
                                                   i
                                                
                                             
                                             )
                                             ·
                                             
                                                
                                                   w
                                                
                                                
                                                   0
                                                
                                             
                                             (
                                             
                                                
                                                   s
                                                
                                                
                                                   i
                                                
                                             
                                             ,
                                             
                                                
                                                   t
                                                
                                                
                                                   j
                                                
                                             
                                             )
                                             ·
                                             
                                                
                                                   w
                                                
                                                
                                                   MI
                                                
                                             
                                             (
                                             
                                                
                                                   t
                                                
                                                
                                                   j
                                                
                                             
                                             ,
                                             t
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        where α, β and γ are the parameters that control the influence of paths with lengths one, two and three respectively. In our experiments, we have set α
                        =
                        β
                        =
                        γ
                        =1. w
                        
                           MI
                         is the normalized expected mutual information weight (Manning, Raghavan, & Schütze, 2008) of co-occurring terms in the same language. We considered confidence intervals of mutual information in our estimates to select trustworthy neighbors. w
                        0 is the normalized weight of the correlated terms in different languages. Using Cocot method, we calculate the similarity of source language term s to target language term t (i.e. w
                        
                           c
                        (s
                        →
                        t)). In addition, we observe that we can also consider the similarity of target and source language terms as well (i.e. w
                        
                           c
                        (t
                        →
                        s)). If term t is calculated as a translation for term s but s is not obtained as a translation for term t then they are unlikely to be translations of each other. So, we define w
                        0(t,
                        s) as the combined similarity of source and target language terms:
                           
                              (6)
                              
                                 
                                    
                                       w
                                    
                                    
                                       0
                                    
                                 
                                 (
                                 s
                                 ,
                                 t
                                 )
                                 =
                                 g
                                 (
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 (
                                 s
                                 →
                                 t
                                 )
                                 ,
                                 
                                    
                                       w
                                    
                                    
                                       c
                                    
                                 
                                 (
                                 t
                                 →
                                 s
                                 )
                                 )
                              
                           
                        In our experiments, we use the sum of normalized similarity weights as function g. We examined the product of the weights as function g as well, and the results were similar.

We normalize the mutual information scores between terms in the same language and raw translation association scores between terms in different languages before combining them using our proposed method. One basic normalization method is to use raw scores’ probability estimation, but one of its deficiencies is that it trusts low scores too much. Intuitively, high scores are more trustable than low ones, either in the extracted translations or terms co-occurring in the same language. So, the normalized value should drop sharply as the scores become smaller. To penalize low scores, we use exponential transformation in our experiments.

In our obtained term associations, there exist some terms whose extracted translations are not correct, which leads to decrease in the accuracy of the extracted translations. These terms may for instance be high frequency terms having high entropies in the comparable corpus or low entropy terms which have appeared in only few aligned documents. Intuitively, it sounds reasonable to detect these exceptions using outlier detection methods to enrich translations either by omitting them from the created thesaurus or by obtaining their translations from other resources such as dictionaries.

In this section, we introduce our approach to detect incorrectly translated terms (outliers) based on the distribution of term association weights in the same language and their related terms. We use a modified version of the method proposed by Papadimitriou and Faloutsos (2003) for cross-outlier detection using probabilistic criteria for automatic recognition of outliers.

We consider the problem of detecting outliers in one language (L
                        1) with respect to their extracted translations in the other language (L
                        2). Thus, our goal is to find terms in L
                        1 that “arouse suspicions” with respect to terms in L
                        2 (Papadimitriou & Faloutsos, 2003). Intuitively, if the weight distribution of a term’s translation is different from that of its neighbors’ translations, the term is considered as an outlier. For instance, Fig. 2
                         shows two sample terms and their neighborhood distributions and their translation relations. As can be seen, this method can detect the term ‘Persian’ as an outlier based on its neighborhood and on the other hand the term ‘Tehran’ is not detected as an outlier since it has a similar distribution with its neighborhood.

Considering term t in language L
                        1, we first collect its neighborhood of radius r in L
                        1 (i.e. 
                           
                              
                                 
                                    N
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              (
                              t
                              ,
                              r
                              )
                           
                        ). For each term in the neighborhood of t, we define a locality neighborhood with radius α over its extracted translations in language L
                        2 (see also Fig. 2). Then we calculate 
                           
                              
                                 
                                    
                                       
                                          w
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    
                                       
                                          L
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              (
                              t
                              ,
                              r
                              ,
                              α
                              )
                           
                         which is the average of locality weights over all terms in the neighborhood as:
                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             w
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             L
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 t
                                 ,
                                 r
                                 ,
                                 α
                                 )
                                 ≔
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             q
                                             ∈
                                             
                                                
                                                   N
                                                
                                                
                                                   
                                                      
                                                         L
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                
                                             
                                             (
                                             t
                                             ,
                                             r
                                             )
                                          
                                       
                                       
                                          
                                             w
                                          
                                          
                                             
                                                
                                                   L
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                       (
                                       q
                                       ,
                                       α
                                       )
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             
                                                
                                                   L
                                                
                                                
                                                   1
                                                
                                             
                                          
                                       
                                       (
                                       t
                                       ,
                                       r
                                       )
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    w
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              (
                              q
                              ,
                              α
                              )
                           
                         is the sum of the weights of the extracted translations of term q in language L
                        2 in radius α and 
                           
                              
                                 
                                    n
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              (
                              t
                              ,
                              r
                              )
                           
                         is the number of members of 
                           
                              
                                 
                                    N
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                              (
                              t
                              ,
                              r
                              )
                           
                        . Our outlier detection method relies on standard deviation of the calculated weights of neighbors in radius α which are terms in language L
                        2. Thus, the standard deviation, 
                           
                              
                                 
                                    
                                       
                                          σ
                                       
                                       
                                          ˆ
                                       
                                    
                                 
                                 
                                    
                                       
                                          L
                                       
                                       
                                          1
                                       
                                    
                                    ,
                                    
                                       
                                          L
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                              (
                              t
                              ,
                              r
                              ,
                              α
                              )
                           
                        , for term t in L
                        1 with radius r and α is defined as:
                           
                              (8)
                              
                                 
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             L
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 t
                                 ,
                                 r
                                 ,
                                 α
                                 )
                                 
                                 ≔
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   q
                                                   ∈
                                                   
                                                      
                                                         N
                                                      
                                                      
                                                         
                                                            
                                                               L
                                                            
                                                            
                                                               1
                                                            
                                                         
                                                      
                                                   
                                                   (
                                                   t
                                                   ,
                                                   r
                                                   )
                                                
                                             
                                             
                                                
                                                   (
                                                   
                                                      
                                                         w
                                                      
                                                      
                                                         
                                                            
                                                               L
                                                            
                                                            
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                   (
                                                   q
                                                   ,
                                                   α
                                                   )
                                                   -
                                                   
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               ˆ
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               L
                                                            
                                                            
                                                               1
                                                            
                                                         
                                                         ,
                                                         
                                                            
                                                               L
                                                            
                                                            
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                   (
                                                   t
                                                   ,
                                                   r
                                                   ,
                                                   α
                                                   )
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          
                                             
                                                
                                                   n
                                                
                                                
                                                   
                                                      
                                                         L
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                
                                             
                                             (
                                             t
                                             ,
                                             r
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        Finally, a term t in L
                        1 is considered as an outlier at radius r with respect to the extracted translations in L
                        2 if:
                           
                              (9)
                              
                                 |
                                 
                                    
                                       
                                          
                                             w
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             L
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 t
                                 ,
                                 r
                                 ,
                                 α
                                 )
                                 -
                                 
                                    
                                       w
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 t
                                 ,
                                 α
                                 )
                                 |
                                 >
                                 
                                    
                                       k
                                    
                                    
                                       σ
                                    
                                 
                                 
                                    
                                       
                                          
                                             σ
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       
                                          
                                             L
                                          
                                          
                                             1
                                          
                                       
                                       ,
                                       
                                          
                                             L
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 (
                                 t
                                 ,
                                 r
                                 ,
                                 α
                                 )
                              
                           
                        where k
                        
                           σ
                         is a constant that determines what is a significant deviation. Typically k
                        
                           σ
                        
                        =3. It is noteworthy to mention that we only consider the left-hand side of Eq. (9) to sort terms based on how much they can be considered as outliers. So, considering only the left-hand side of the equation, we set k
                        
                           σ
                        
                        =3 and calculate the standard deviation for each term t in L
                        1 using Eq. (8). Next, all the terms in L
                        1 are sorted and the topmost terms are then selected as outliers. The two radii r and α are dynamically selected based on the neighborhoods or translations of each term (see Section 4.2). Our experiment results show that the average and standard deviation with respect to radius r give us useful information about the vicinity of the terms and therefore we can detect terms that could not be translated.

One of our main goals in this research is to do cross-language information retrieval using the obtained cross-lingual associations from the comparable corpus. To achieve this goad, we translate queries from the source language to the target language and obtain translation knowledge from our comparable corpus using the explained methods in Section 3. Since some terms’ translations may not be obtained from comparable corpus, we detect them as outliers and use bilingual dictionaries to obtain their translations.

In order to use the translation knowledge to do CLIR, we present three methods to translate queries by constructing their query language models in the target language. In the first two methods, we directly use the extracted translations to translate query words in L
                     1 to their corresponding terms in L
                     2. As the third method, we propose to use the extracted translation knowledge along with dictionary translations to construct the query language models. In the following, we present the details of the methods.

Given query Q in language L
                        1, for each query word, we use top k of its extracted associated terms in language L
                        2 as its translations and construct the query language model in L
                        2. In our proposed methods, we consider all query words to be equally important, so they will have equal weights in the query language model. Moreover, in the constructed query language model each translation term has a weight which is based on the weights of the extracted term associations.

We use the method proposed in Shakery (2008) to construct a basic translation of the query in L
                        2. Considering Q
                        =
                        q
                        1,…,
                        q
                        
                           n
                         in L
                        1 and 
                           
                              
                                 
                                    t
                                 
                                 
                                    1
                                 
                                 
                                    i
                                 
                              
                              …
                              
                                 
                                    t
                                 
                                 
                                    k
                                 
                                 
                                    i
                                 
                              
                           
                         as the top-k related terms in L
                        2 to the query word q
                        
                           i
                         (q
                        
                           i
                        
                        ∈
                        Q), the query language model in L
                        2 is constructed as:
                           
                              (10)
                              
                                 P
                                 (
                                 t
                                 |
                                 Q
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          n
                                       
                                    
                                 
                                 
                                    
                                       1
                                    
                                    
                                       n
                                    
                                 
                                 
                                    
                                       p
                                       (
                                       t
                                       |
                                       
                                          
                                             q
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             j
                                             =
                                             1
                                          
                                          
                                             k
                                          
                                       
                                       p
                                       (
                                       
                                          
                                             t
                                          
                                          
                                             j
                                          
                                       
                                       |
                                       
                                          
                                             q
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where p(t
                        
                           l
                        ∣q
                        
                           j
                        ) is the calculated weight using Eq. (5) and p(t
                        
                           l
                        ∣q
                        
                           j
                        )>0 if t
                        
                           l
                         is in the top k associated terms of q
                        
                           j
                         and p(t
                        
                           l
                        ∣q
                        
                           j
                        )=0 otherwise.

We use the same method in the case of omitting outliers. We just do not consider the query words that are detected as outlier when constructing query language model. For instance, if the query consists of three terms and one of them is an outlier, we construct the language model based only on two of query words without considering the outlier.

In the basic query translation method, for all the query words, we equally select the top k associated terms in L
                        2. But we observe that the quality of associated terms for each term is different. For instance, as can be seen from Fig. 3
                        , the translations of “sanction” could be found in the first position and the other next terms (“Iraq”, “Organization” and “US”) are not that much associated in meaning to “sanction”. On the other hand, considering the term “atomic”, we can see that the first few associated terms (“Agency”, “ElBaradei”, “Nucleus”, “Energy”, “Uranium” and “Rich”) are somehow related to “atomic” and can be used in the same context. So, they would be probably useful for query expansion. Thus, if we select k (e.g. k
                        =3) equally for all the terms then for some terms (e.g. “sanction”) the selected translated terms may not be correct and for some other terms (e.g. “atomic”) some useful information may be ignored mistakenly. Intuitively, we can use the weight distribution of the associated terms to select the number of related terms for each term dynamically.

We propose a method to select the best associated terms based on the knee point of the diagram as follows:
                           
                              (11)
                              
                                 
                                    
                                       ▵
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       I
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       I
                                    
                                    
                                       i
                                       +
                                       1
                                    
                                 
                              
                           
                        where I
                        
                           i
                         is the association weight and ▵
                           i
                         is difference of two consecutive association scores. We determine the point with the maximum slope as:
                           
                              (12)
                              
                                 
                                    
                                       k
                                    
                                    
                                       ˆ
                                    
                                 
                                 =
                                 
                                    
                                       argmax
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   
                                                      ▵
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             
                                                i
                                                +
                                                1
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    k
                                 
                                 
                                    ˆ
                                 
                              
                           
                         is the estimated cut off for the most related extracted translations. The presented method can also be used to dynamically select the most associated neighbors to a term in a same language when the scores are calculated based on mutual information. After dynamic selection of top 
                           
                              
                                 
                                    k
                                 
                                 
                                    ˆ
                                 
                              
                           
                         related terms for each query word, we construct the query language model using the method explained in Section 4.1.

We do not expect to extract suitable translation knowledge for all the terms from the comparable corpus. For instance, since we use distribution of term frequencies, translations for the high frequency terms could not be obtained. So, we construct query language model for several combined CLIR approaches based on dictionary-based query translations and extracted translations from comparable corpora.

In this combined method, in order to translate each query word, we use its dictionary translations as well as the extracted translations from comparable corpus. Since dictionaries are reliable translation resources, we give their translations higher weights compared to our extracted translations from comparable corpus. The weights of the dictionary translations are set to be the highest extracted translations from the comparable corpus for that term plus a small amount which is the difference between the highest and the second highest extracted translations from comparable corpus for that term multiplied by the factor 2. Afterwards, the query language model construction is based on the method presented in Section 4.1.

In this method, first the query words are translated using dictionary and then for those query words which could not be found in dictionary, we use their extracted translations from comparable corpus. Formally, let Q
                           =
                           q
                           1,…,
                           q
                           
                              n
                            be the query. Since each query word is translated either by dictionary or by comparable corpus, the query language model in L
                           2 is constructed as
                              
                                 (13)
                                 
                                    P
                                    (
                                    t
                                    |
                                    Q
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                         
                                                         
                                                            n
                                                            ×
                                                            k
                                                         
                                                      
                                                   
                                                   
                                                      if
                                                      
                                                      t
                                                      ∈
                                                      Dic
                                                   
                                                
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            p
                                                            (
                                                            t
                                                            |
                                                            
                                                               
                                                                  q
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                            )
                                                         
                                                         
                                                            
                                                               
                                                                  ∑
                                                               
                                                               
                                                                  j
                                                                  =
                                                                  1
                                                               
                                                               
                                                                  k
                                                               
                                                            
                                                            p
                                                            (
                                                            
                                                               
                                                                  t
                                                               
                                                               
                                                                  j
                                                               
                                                            
                                                            |
                                                            
                                                               
                                                                  q
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                            )
                                                         
                                                      
                                                   
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           in which k is the top translations for term t that can be calculated dynamically for comparable corpus extracted translations.

In this method, first the query words are translated using comparable corpora then those query words which are detected as outliers, are translated by dictionary. The query language model construction is the same as previous section.

@&#EXPERIMENTAL RESULTS@&#

In this section, we report our experiments on doing cross-language information retrieval by applying several techniques to extract translation knowledge from the comparable corpus. The presented methods to extract translation knowledge from comparable corpus are independent of the languages of the comparable corpus and they can also be applied on other languages. In our experiments, we use Hamshahri corpus and its bilingual queries to do CLIR. Since our created comparable corpus is constructed by the Hamshahri news articles, we also apply our proposed methods on another data set with different origin (i.e. INFILE corpus).

UTPECC consists of news articles in Persian and English. The English collection is composed of news articles published in BBC News and the Persian collection includes the news articles of Hamshahri newspaper. Five years of news articles, dated from January 2002 to December 2006 have been used. The Hamshahri articles are extracted from Hamshahri collection
                              1
                              
                                 http://ece.ut.ac.ir/dbrg/Hamshahri/.
                           
                           
                              1
                            and the BBC articles are crawled from the BBC News website
                              2
                              
                                 www.bbc.co.uk.
                           
                           
                              2
                            and preprocessed to clean the web pages, and also to omit local news of United Kingdom, which will not be aligned with any Persian news articles. The total of around 53,000 English documents are aligned with 190,000 Persian documents resulting a comparable corpus of more than 10,300 document pairs. The details of the collections are given in Table 1
                           .

To construct the comparable corpus, we first extract the keywords of each document in the source language and translate the keywords to the target language. These translations are considered as queries in the target language and are run against the target collection to retrieve a ranked list of related documents. The results are processed using the method explained in Hashemi et al. (2010) and tested with different document relevance score thresholds to create the document alignments and thus the comparable corpus. The main criterion for evaluating the quality of alignments was manually assessing the alignments of one month on a five-level relevance scale. Finally, the best high quality aligned documents are chosen as our comparable corpus which consists of 10,365 document alignments and 10% of the 53,697 source documents are aligned. Table 2
                            shows some statistics about our created comparable corpus. Since the source and target documents are very different, the relatively low number of alignments was expected. Moreover, the number of alignments can be increased with lowering the thresholds, but this can also affect the quality of the comparable corpus.

Most previous work on English–Persian CLIR used Hamshahri test collection at CLEF-2008
                              3
                              
                                 www.clef-campaign.org.
                           
                           
                              3
                            task: Retrieval of Persian documents from topics in English. The document collection for this task contains 166,774 news stories (578MB) that appeared in the Hamshahri newspaper between 1996 and 2002 (AleAhmad, Amiri, Darrudi, Rahgozar, & Oroumchian, 2009a). This collection overlaps with UTPECC comparable corpus in year 2002.

The CLEF-2008 task consists of 50 query descriptions in Persian and the English translations of these topics. We used these topics to compare our results to the best existing results. For the rest of the experiments, we used CLIR task of CLEF-2008 and 2009 together which contains 100 topics. Among them we used 85 queries, the other 15 omitted queries were too specific to Persian language, such as ‘Shajarian Concert’ and ‘reconstruction of Kandovan tunnel’. The Persian queries are used for monolingual retrieval.

The INFILE (INformation, Filtering, Evaluation) corpus is used in INFILE@CLEF 2008 and 2009 track on the evaluation of cross-language adaptive filtering systems and LREC2010 Workshop on Evaluation of Information Filtering Systems in a Competitive Intelligence Framework
                              4
                              
                                 http://www.infile.org.
                           
                           
                              4
                            (Besançon et al., 2009). The collection is composed of 300,000 newswires from Agence France Presse (AFP) covering the 2004–2006 period in three languages: Arabic, English and French, and a set of 50 topics in general and specific domains. In order to do CLIR task of retrieving English documents from topics in Persian, we translated the English queries to Persian. Too specific queries such as ‘The slam: poetry democratized’ which could not be translated to Persian were omitted from our experiments. Also, queries that had very few relevant documents (less than 4) were removed. Remaining was 42 refined queries. The titles of these queries were translated by two knowledgeable speakers and the most fluent translations were picked as the final translations. The Persian translation of topics are available at our research website.
                              5
                              
                                 http://ece.ut.ac.ir/IIS/resources.html.
                           
                           
                              5
                           
                        

We have studies the effect of applying various query translation techniques based on our created Persian–English comparable corpus. Naturally, the higher the quality of the comparable corpus, the more precise the term associations will be and also as a consequence the better the performance of CLIR systems would be. In our experiments, we first extract translation knowledge from the comparable corpus and then assess the quality of the obtained associations by doing CLIR with different retrieval models. We used two different collections to evaluate the efficiency of English–Persian and Persian–English CLIR tasks in several experiments. We have done experiments using Okapi with pseudo relevance feedback (Robertson & Walker, 1994) and KL-divergence retrieval model (Lafferty & Zhai (2001)), but since the results of KL-divergence retrieval model are generally better, we have only reported these results.

We have used the Lemur toolkit
                           6
                           
                              www.lemurproject.org/.
                        
                        
                           6
                         as our retrieval system. Also, we used Porter stemmer for stemming the English terms and Inquery’s stopword list (418 words). The Persian collection is only preprocessed using Neuchatel’s stopword list
                           7
                           
                              www.unine.ch/info/clef/.
                        
                        
                           7
                         (332 words). Although we applied some Persian stemmers, none of the results were promising (Dolamic & Savoy, 2009). Therefore, we decided not to use any stemmer for Persian language. Also, in our experiments, as a dictionary resource, we have used Farsidic
                           8
                           
                              www.farsidic.com/.
                        
                        
                           8
                         online dictionary as our English–Persian and Persian–English dictionary. Farsidic is a general dictionary and provides more common translations first.

We use monolingual Persian–Persian retrieval of Hamshahri collection as one of our baselines to which we compare the cross-language results. In our monolingual runs we only consider title fields. We did two monolingual runs, one using KL-divergence retrieval model without query expansion and one using query expansion with pseudo relevance feedback. For the pseudo relevance feedback run, we used the mixture model approach implemented in the Lemur toolkit (Lemur, 2013) using top 10 retrieved documents to perform feedback. As the parameters, we used 100 terms for expanding the query model and 0.8 for the feedback coefficient. Table 3
                            shows the mean average precision, precision at 5 documents and precision at 10 documents of our monolingual runs, along with the performance of the existing monolingual Persian runs over CLEF-2008 test collection that used title field only. As the table shows, our results are comparable to the existing monolingual results and form a reasonable baseline to which we can compare our cross-language results.

For the rest of the experiments, we have put all the queries of CLEF-2008 and 2009 together and have omitted the queries which were too language specific. Table 4
                            shows the mean average precision, precision at 5 documents and precision at 10 documents of our monolingual runs over the 85 remaining queries.

In our first set of experiments, we tried to extract term associations from the comparable corpus using Cocot as our basic translation extraction method which is explained in Section 3.1. Fig. 4
                            shows the results of CLIR using Cocot approach based on top k (top-1 to top-20) related terms for each query word in the Hamshahri corpus. We used the top k mined correlated terms to construct the query language models (see Section 4.1). The Cocot performance for top 2 is 0.130 in mean average precision, 0.233 in precision at 5 documents and 0.205 in precision at 10 documents. It means that using only comparable corpus as the translation method and compared to the monolingual baseline, we can achieve up to 32% of mean average precision, 36.2% of precision at 5 documents and 34.8% of precision at 10 documents.

In our next set of experiments, we applied our proposed translation method based on the network of terms to do CLIR. To implement this idea, we first construct the network of terms in English and Persian languages where the links in the same language represent the mutual information between terms and the links between terms in different languages show their normalized Cocot similarities. Two terms in different languages have a high chance of being translations of each other if their neighborhoods are strongly connected and similar. In order to calculate the similarity of two terms’ neighborhoods, we consider the paths between those two terms which come across their neighborhoods. All the 100 nearest terms around each term are considered as its neighborhood. We compare two cases here: ∊
                           =0, only taking into account direct paths with length one between two terms and not considering their neighborhoods, and ∊
                           >0 considering the neighbors of the terms and taking into account all the paths with length one, two or three between two terms. Fig. 4 shows the results with different values of top k for ∊
                           =0 and ∊
                           >0 compared to the Cocot method.

As can be seen from the figure, there are promising improvements in the mean average precision of the proposed methods. The stable results of ∊
                           >0 according to the values of k shows that the correct translations have got higher weights and likewise the incorrect translations have obtained lower weights and have been sent to lower ranks in the translation lists. Also, the lower mean average precisions of ∊
                           =0 compared to the case where ∊
                           >0 shows that the neighborhood information of terms could help to obtained more accurate related terms from comparable corpus.

In this set of experiments, we use our proposed method in Section 4.2 to select dynamic number of translations for each query word based on the observation that the extracted translation quality limit for each query word is different. Table 5
                            shows the results of dynamic related term selection in comparison with monolingual retrieval, basic Cocot method and the best results of static top-k selection of translation terms in collection. As can be seen from the table, dynamic related term selection can achieve the best results among the other CLIR methods. Using this method compared to the Cocot method, we can achieve up to 36.1% improvement of mean average precision in Hamshahri corpus.

From now on, we will use the extracted translations from the TAN method with dynamic related term selection as the comparable corpora approach of query translation.

In our next set of experiments, we try to detect terms which could not be translated based on our comparable corpus methods. These mistranslated terms may be either too general terms with high entropies or too specific terms with low frequencies in the aligned documents. Using the presented method in Section 3.3, we can obtain a sorted list of query words based on their outlier coefficient score. Some examples of query terms that were deemed outliers are: road, stress, celebration, kidney, carpet and persian. We observed that the number of outliers with low document frequencies are 10 times higher than number of outliers with high document frequencies.


                           Fig. 5
                            shows the performance of the method in two cases: when we omit the outlier query words from the queries, and when we translate these outlier query words using a dictionary. The increasing slope of diagram in the omit outlier run shows that even only by omitting a few number of outliers (in this run 10), we can achieve slightly better mean average precision compared to the case when we keep all the query terms. It shows improvements, although the improvement is not significant. In the other set of experiments, we translate the outlier query words using a reliable resource such as a dictionary. The results show that only by translating a limited number of terms, for example 5 query words across all queries (which are youth, carpet, casualty, rug and television), using a simple dictionary, we can achieve 0.187 in mean average precision which is up to 45.8% of the monolingual baseline. These results show our relative success in detecting outliers.

In the next set of experiments, we use the extracted translations from comparable corpus to improve dictionary-based CLIR. We combine comparable corpus with the dictionary in two different ways. In the first approach which is called Dic-CC, the query words are first translated with dictionary. The terms that are not found in dictionary (generally proper nouns) are then translated with comparable corpus. In the second approach, Dic&CC, queries are translated with both dictionary and comparable corpus. Fig. 6
                            shows the mean average precision of dictionary-based translation CLIR based on different number of translation terms (1–10) for each query word.

In this figure, the results of using only dictionary and only comparable corpus is shown as Dic and CC runs respectively. In our experiments, we use Pirkola’s structured query method (Pirkola (1998)) as the dictionary only method. As can be seen, it does not suffer from injecting many translations. The poor performance of using dictionary alone for retrieval was expectable because of lack of proper nouns which are essential query keywords. Thus, one of the success reasons of comparable corpus is the ability to translate these OOV terms such as Khatami, internet and NATO. Another advantage of comparable corpus is finding good query expansion terms. The increasing slope of some parts of diagrams confirm this hypothesis. Furthermore, as the figure shows, combing dictionary with comparable corpus is beneficial and Dic&CC approach outperforms the other methods. Wilcoxon signed rank test at 0.05 level of significance determines that the improvement of using comparable corpora over dictionary is statistically significant.


                           Table 6
                            shows our main experimental results. The first three rows specify reference comparisons which are monolingual, Cocot and dictionary baselines. Since the dictionary we have used is kind of a sorted dictionary, we used top-4 translations of all query terms for the experiments using dictionary. As the table shows, using comparable corpus with TAN method, we can improve the results over the baselines and achieve up to 43.3% of mean average precision compared to the monolingual retrieval. In addition, perhaps not surprisingly, Dic-CC and Dic&CC methods which combine two translation resources as described, appear to be our best performing methods. They expand the vocabulary of the dictionary by adding the extracted translations from comparable corpus. In the best case, we can achieve up to 52.3% of mean average precision of monolingual baseline. The CC-Dic method indicates our translation validity check using outlier detection method. The table only presents the best results of translating outlier terms with dictionary where the number of outliers is five terms. It is interesting to note that the mean average precision of translating only five terms from dictionary and others with comparable corpus is 45.2% of monolingual baseline which is a big improvement over dictionary only translation.

The best obtained mean average precision using dictionary translations is 0.157 which is only 38% of monolingual. This shows that the poor performance of dictionary only method is not because of the specific method we used. Also, the reported results using dictionary in CLEF-2008 have shown poor performance of dictionary (For example, AleAhmad, Kamalloo, Zareh, Rahgozar, & Oroumchian (2009b) has reported MAP=0.124 with top-1 translation of dictionary and MAP=0.102 with top-5 translations on CLEF-2008 data). The poor performance of the dictionary only method on Persian compared to the similar methods in other languages could be because of the specific characteristics of Persian, which should be investigated more in the future.

In our experiments, we observe that the improvements of precisions at top 5 and 10 documents are more considerable than the mean average precisions. Intuitively, when the precision at top documents are high, pseudo relevance feedback can help to improve the mean average precision. So, in another set of experiments, we repeat our experiments using post-translation query expansion with pseudo relevance feedback. Table 7
                            shows the results of query expansion of monolingual, CC method and the best CLIR run of using dictionary with comparable corpus. As the table shows, doing query expansion and compared to the monolingual baseline, we can achieve up to 45.7% of mean average precision, 48.2% of precision at 5 documents and 46.1% of precision at 10 documents using only comparable corpus as a translation resource and about 61.8% of mean average precision, 58.6% of precision at 5 documents and 61% of precision at 10 documents using dictionary and comparable corpus.

Furthermore, in another set of experiments, we did pre-translation query expansion using blind relevance feedback which is the best known approach for using unlinked comparable corpora (Ballesteros & Croft, 1997; Ballesteros & Croft, 1998; McNamee & Mayfield, 2002). We did pre-translation expansion using the top 20 documents and 5 expanded terms (the same as the best setting reported at (McNamee & Mayfield, 2002)). Also, we did various experiments to translate the expanded terms using comparable corpus and/or dictionary. But, none of the results were better than our previous obtained results. Analyzing the results show that pre-translation expansion will improve the precision for some of the queries, but the other queries suffer from newly added unrelated terms. A deeper research over pre-translation expansion to analyze the results is left as one of our future work.

In order to compare our results with the best reported results at CLEF, we repeat our experiments using only the 50 topics of CLEF-2008. Table 8
                            shows our main experimental results over CLEF-2008 task. To the best of our knowledge, the best reported mean average precision at CLEF-2008 task is 0.1446 (Besançon et al., 2009). As can be seen from the table, our results using only comparable corpus and dictionary is sufficiently better than the best reported result. Rahimi and Shakery (2011) have also done some experiments on CLEF-2008 data. Their main focus is to construct a high quality comparable corpus from which they expect to extract high quality translation knowledge. They have used the translation knowledge extracted from the comparable corpus along with two other translation resources, namely dictionary and translation knowledge extracted from Wikipedia, to do CLIR.

In our experiments, we used Hamshahri corpus and its bilingual queries to do CLIR. Since the Hamshahri news articles are also used in constructing our comparable corpus, as another interesting research direction, we try to apply our presented methods on a corpus other than Hamshahri to see how our methods perform in another cross-language information retrieval task. We chose INFILE corpus (Besançon et al., 2009) which consists of Agence France Presse (AFP)’s newswires as our evaluation data set. Using INFILE corpus, our cross-language information retrieval task is to retrieve English documents in response to Persian queries. The results of applying different query translation methods on the INFILE data set are shown in Table 9
                           . Since the results of monolingual query expansion with pseudo relevance feedback were not substantially better than the results without query expansion, we did not report them. As can be seen from the table, same as Hamshahri results in Table 6, combining comparable corpus with dictionary can achieve the best results that in the best case is about 51.5% of mean average precision compared to monolingual baseline. Translating 12 terms with dictionary in the CC-Dic method could achieve up to 50.4% of mean average precision compared to monolingual baseline.

As can be seen from Tables 6 and 9, the relative effectiveness of Dic&CC compared to Dic-CC and CC-Dic changed from one test collection to another test collection. Following are some of our observations on the results of INFILE collection: (1) The difference of Dic&CC and Dic-CC is not statistically significant in INFILE collection. (2) Among all 42 queries, only 8 queries perform very differently on Dic&CC compared to Dic-CC. (3) Another important factor of the difference between effectiveness of Dic&CC on Hamshahri and INFILE collections is the number of judged relevant documents in these datasets. There are some topics on INFILE collections that have very few relevant documents. So, the failure of retrieving one of them may have an enormous impact on the final results. As a brief analysis, the average of number of judged relevant documents in Hamshahri collection is 102, but in INFILE collection is 38.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this work, we presented methods to mine translation knowledge from comparable corpora. The most notable presented method was based on network of terms (TAN) which consists of correlations of terms and their neighborhoods. Cross-language information retrieval experiments show that using TAN method and selecting dynamic number of translation terms for each query word significantly outperforms the basic translation extraction method. Therefore, neighborhood information of terms could help to obtain more accurate translation terms from comparable corpus.

Furthermore, we have done translation validity check using our proposed outlier detection method and have shown that we can detect mistranslated terms by their neighborhoods. The results show that detecting good outliers and translating only a few number of them with dictionary or even omitting them from the query words improves the retrieval performance. Also, our experiments in combining extracted translations from comparable corpus with the dictionary translations show that using only dictionary performs poorly, because of lack of proper nouns which are essential query keywords. Thus, one of the success reasons of comparable corpus is the ability to translate these OOV terms. Another advantage of comparable corpus is finding good query expansion terms.

In our future work, it will be interesting to use the extracted translation knowledge to improve the quality of the created corpus, by using the extracted term associations as an additional resource to translate source language keywords and also improving its quality through an iterative construction process. In this research we present the TAN method and calculate the similarity of neighborhoods by the paths of lengths one, two and three. Thus as an interesting future direction, we are going to test more complex methods to compare terms’ neighborhoods in the TAN model and run the experiments based on the new extracted translations. Also, we will tune the parameters of the created network to investigate the importance of each source of evidence for reranking the translations.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Situated incremental natural language understanding using Markov Logic Networks

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We use situation, discourse, words, linguistics to infer interpretation.


                        
                        
                           
                           We use Markov Logic Networks to jointly use information sources.


                        
                        
                           
                           We show that our model works well with speech and hand-annotated data.


                        
                        
                           
                           We offer some interesting analysis of the model and how it works incrementally.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Incremental

Situated

Natural language understanding

Dialog systems

Markov Logic Networks

@&#ABSTRACT@&#


               
               
                  We present work on understanding natural language in a situated domain in an incremental, word-by-word fashion. We explore a set of models specified as Markov Logic Networks and show that a model that has access to information about the visual context during an utterance, its discourse context, the words of the utterance, as well as the linguistic structure of the utterance performs best and is robust to noisy speech input. We explore the incremental properties of the models and offer some analysis. We conclude that mlns provide a promising framework for specifying such models in a general, possibly domain-independent way.
               
            

@&#INTRODUCTION@&#

Spoken conversation is situated in time and space. Speech by necessity unfolds sequentially in time; and in a conversation, all speech but that of the opening utterance is preceded by other speech belonging to the same conversation. In many, if not most, conversational situations, speaker and addressee are co-located in space and their speech may refer to their shared situation. Most current spoken dialogue systems attempt to abstract from this fact, however. They work in domains where physical co-location is not necessary, such as information look-up, and they quantize time into discrete turn units by endpointing utterances (see discussion in Aist et al., 2007; Schlangen and Skantze, 2009).

In this paper we present our current work on overcoming this abstraction for the task of natural language understanding (nlu).
                        2
                     
                     
                        2
                        This paper follows from and extends Kennington and Schlangen (2012).
                      We have created a statistical model that can be trained on conversational data and which can be used as an nlu module for an incremental, situated dialogue system (such as that described in Buß et al., 2010a). We show that this model outperforms baseline approaches by a wide margin, and that making available the full set of information comprising visual context, discourse context, words of the utterance, and linguistic structure gives significantly better results than when one of those information sources is ignored. We further show promising results from noisier input, as coming out of an automatic speech recogniser (asr).

The paper is structured as follows: we first discuss related work and introduce some background, then describe in detail our set of experiments, and present and analyse our results, including some analysis of our model. We close with a general discussion of this work and possible future extensions.

In this section, we will briefly introduce statistical nlu. We explain that the nlu we focus on is situated and incremental, and give a notion of what “good” incremental nlu is. This section then finishes with a very brief overview of Markov Logic Networks (mln), the particular machine learning approach we use in this paper.

An important part of a dialogue system is the nlu component. This component is the point where input from any modality (asr, visual context, gestures, etc.) is combined and used to infer the meaning of an utterance and the intent of the speaker. One popular approach to representing meanings and intentions is to use semantic frames (inspired by Fillmore and Baker, 2001), and we follow this tradition here. A frame is an attribute-value matrix where the attributes classify aspects of the overall meaning, and their values the concrete instantiations of these aspects. An example frame is given in Fig. 1
                        .

Traditional statistical nlu (snlu) focuses on predicting a meaning representation (slot attributes), where the intention (slot values) are words as extracted directly from the utterance. snlu has often been treated as a simple tagging task; specifically concept tagging, where the concept tags that are predicted become the slot attributes. Meurs et al. (2008) apply mln as a way to predict the concept tag sequence. Their more recent work, Meurs et al. (2009), applies dynamic Bayesian networks (dbn). Hahn et al. (2008) compared various machine-learning techniques used for concept tagging; namely, log-linear models, stochastic finite state transducers, conditional random fields, support vector machines, as well as an approach taken from machine translation. This comparison was more recently extended into multiple languages in Hahn et al. (2011), which also compared dbns.

Other approaches to slu that do not use frames as a meaning representation also exist; Zettlemoyer and Collins (2007) and Zettlemoyer and Collins (2009) used a semantic representation to infer a meaning, Liang et al. (2011) created dependency-based compositional semantics, and Huang and Er (2010) made use of neural networks as a meaning representation. All of these approaches stop at predicting a meaning representation; they do not infer a user intention that is represented by anything beyond the words of the utterance, that is, they do not ground these representations in their context of use.

Our approach to snlu differs from previous approaches in that we work in a situated domain and cannot make the assumption that the slot fillers are sufficiently specified by the words of the utterance (in the way that the city New York may be by the words “New York”). For example, if an object in a shared context is referred, it is not enough to fill a slot with the words that contributed to that object description (i.e., the red ball on the left); what's required is to actually resolve the object, that is, identify it from other objects (i.e., by an identifier object5). Fig. 1 represents a frame where the argument slot represents an inferred entity rather than extracted words. In order to effectively resolve this kind of object in a visual space, information from various sources need to be incorporated, which is another difference in our work to that of previous snlu work; predicting a speaker intention (i.e., a referred object) requires some level of grounding where the utterance and visual world are somehow connected (as in Roy, 2005). For example, an effective model would learn that the word red would give more credence to an rgb value that represents the color red, rather than green. These kinds of object descriptions are sufficiently complex such that they require incorporating linguistic information to some degree (also often ignored), and many references are resolved using pronouns, something which requires incorporation of previous discourse context, which is also often unnecessary in snlu. This paper represents work that incorporates visual, linguistic, and context information to infer a speaker intention, represented as slot values, as in Fig. 2
                        .

Dialogue systems that process input incrementally produce behavior that is perceived by human users to be more natural than systems that end-point on larger sentence-length segments or use a turn-based approach (see Aist et al., 2006; Skantze and Schlangen, 2009; Buß et al., 2010b; Skantze and Hjalmarsson, 2010). There have been many recent advancements in incremental dialogue in various areas such as speech recognition (Baumann et al., 2009), speech synthesis (Buschmeier et al., 2012), and dialogue management (Buß and Schlangen, 2011; Selfridge et al., 2012). Furthermore, architectures for incremental dialogue systems have been proposed (Schlangen and Skantze, 2009), and various incremental toolkits are available like InproTK (which we use in this paper) (Baumann and Schlangen, 2012).
                           3
                        
                        
                           3
                           
                              http://sourceforge.net/projects/inprotk.
                        
                     

If nlu is concerned with filling a frame, then incremental nlu (inlu), attempts to fill as much of the frame as it can, as early as possible, contingent upon the incremental input of the ongoing utterance. This is important in dialogue systems that are responsive and work better in real-time. Fig. 3
                         shows how an utterance, rotate the gray piece below the yellow piece clockwise, incrementally fills the slots, where the utterance has reference to the shared visual context in Fig. 4
                        . By the time the word piece in step 4 is uttered, it interprets the argument as the object identifiers of the gray pieces on the board, distinguishing them from the non-gray pieces as the possibly referred objects. As the utterance continues, one gray piece is singled out as the referred object (the object in A:4), which is an example of the task of reference resolution.

There are various ways to approach inlu. We follow the view given by Heintze et al. (2010) that inlu has a continuum with two end points, where on one extreme the input into the nlu component is incremental and the output is also incremental (which we will denote as fully incremental), meaning slots are only predicted when there is sufficient input to contribute to that slot. On the other extreme, the input is incremental, but a full frame is always predicted and so the output of nlu is not incremental (which we will denote as predictive). Fig. 5
                         illustrates the two extremes: fully incremental is represented on the top; the predictive, full frame output extreme is on the bottom for the utterance rotate the gray stairs clockwise. Slots that have bold-faced values denote a change in the prediction for that slot. Note that a predicted value can change at each increment, even if it was correct at an earlier step.

Arguably, an ideal incremental system would follow the fully incremental strategy, where a meaning hypothesis is incremented in lockstep with incremental recognition of the utterance, and links between the words of the utterance and their contribution to the utterance meaning would be recorded. There are ways, however, to move the technically more straightforward prediction approach where possibly incomplete utterances (or utterance prefixes) are classified more towards that ideal. DeVault et al. (2009) use a second classifier to determine when to trust the (full frame) prediction of the first one, and so deal to an extent with the problem of instability of early hypotheses. Another approach, discussed in Heintze et al. (2010) and followed here as well is to predict the frame elements separately (but constrained by global considerations), allowing for an additional unknown class. This has the effect of letting the frame ‘grow’ incrementally, even if no direct link between words and parts of the semantic representation is kept.

In summary, our approach in this paper differs from previous nlu approaches in that the model we work with is incremental, can use linguistic structure, and learns from conversational data a semantics that connects the utterance to its visual and discourse context. We have looked at individual components of this before (grounded semantics in Siebert and Schlangen, 2008; incremental reference resolution in Schlangen et al., 2009; incremental general nlu in Heintze et al., 2010; interaction between incremental parsing and reference resolution in Peldszus et al., 2012), but use a more sophisticated model in this work and show that tackling these tasks jointly improves performance. Furthermore, previous contributions to inlu (such as DeVault et al., 2009, 2011; Aist et al., 2007; Schlangen and Skantze, 2009) have not dealt with learned grounded semantics.

We apply Markov Logic Networks (mln; Richardson and Domingos, 2006) as the machine learning technique in our experiments. mlns have recently received attention in language processing fields like co-reference resolution, Chen (2009), semantic role labeling, Meza-Ruiz and Riedel (2009), spoken (albeit neither situational nor incremental) nlu, Meurs et al. (2008), and web information extraction, Satpal et al. (2011).

Markov Logic is a statistical relational learning language based on First Order Logic (fol) and Markov Networks. Markov Logic can extend fol to allow formulae to be weighted rather than be strictly true or false; that is, a fol formula can be violated with a penalty.
                           4
                        
                        
                           4
                           We follow the succinct presentation of Meza-Ruiz and Riedel (2009) here.
                         From another viewpoint, Markov Logic is an expressive template language that uses fol formulae to instantiate Markov Networks of repetitive structure. A mln, then, is a set of these weighted fol formulae. Formally, a mln 
                        M is a set of pairs (ϕ, ω) where ϕ is a first order formula and ω a real weight. M assigns the probability given in (1) to a possible world y.


                        
                           
                              (1)
                              
                                 p
                                 (
                                 
                                    
                                       y
                                    
                                 
                                 )
                                 =
                                 
                                    1
                                    Z
                                 
                                 exp
                                 
                                    
                                       
                                          
                                             ∑
                                             
                                                (
                                                ϕ
                                                ,
                                                ω
                                                )
                                                ∈
                                                M
                                             
                                          
                                          ω
                                          
                                             ∑
                                             
                                                
                                                   
                                                      c
                                                   
                                                
                                                ∈
                                                
                                                   C
                                                   ϕ
                                                
                                             
                                          
                                          
                                             f
                                             
                                                
                                                   
                                                      c
                                                   
                                                
                                             
                                             ϕ
                                          
                                          (
                                          
                                             
                                                y
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        
                        C
                        
                           ϕ
                         is the set of all possible bindings of the free variables in ϕ with the constants of the given domain. 
                           
                              f
                              
                                 
                                    
                                       c
                                    
                                 
                              
                              ϕ
                           
                         is a feature function that returns 1 if in the possible world y the ground formula we get by replacing the free variables in ϕ by the constants in c is true, and 0 otherwise. Z is a normalization constant. Thus, the mln framework offers a convenient way of specifying factor functions on sets of random variables for undirected graphical models in such a way that the factors correspond to the weighted, grounded fol formulae.

We apply mln here by specifying our models using fol formulae (see below) such that the grounding of constants that takes place in the mln learning and inference steps corresponds to grounding language with the visual world. The model we specify equates to using a single log-linear classifier for each slot that is to be predicted.

@&#EXPERIMENTS@&#

We will now describe our experiments using mln for situated inlu, give the results of our experiments, and offer some model analysis.

For our experiments, we used task-oriented conversational data from the Pentomino domain, as in Fernández et al. (2007); more specifically, we worked with the corpus also used recently in Heintze et al. (2010) and Peldszus et al. (2012). This corpus was collected in a Wizard-of-Oz study, where the user goal was to instruct the computer to pick up, place, delete, rotate or mirror puzzle tiles on a rectangular board (as in Fig. 4), and place them onto another similar board. For each utterance, the corpus records the state of the game board before the utterance, the immediately preceding system action, and the intended interpretation of the utterance (as understood by the Wizard) in the form of a semantic frame specifying action-type and arguments, where those arguments are objects occurring in the description of the state of the board (as in Fig. 1). The language of the corpus is German.

Each utterance was annotated with a semantic frame with the three mentioned slots. There are 965 distinct frames and 775 unique frames. The action slot has 5 possible values, with the most common one occurring 29% of the time, argument has 6 possible values occurring with equal probability, and option has 19 possible values, the most likely one occurring 14.1% of the time.

For this paper, we were interested in the potential contribution of linguistic structure to the nlu task. To this end, we produced for each utterance an incremental sequence of parses and corresponding semantic representations as structures of Robust Minimal Recursion Semantics (rmrs, Copestake, 2007, i.e., under specified semantic representations), using the parser described in Peldszus et al. (2012). These representations were not further manually checked for appropriateness, and hence do not necessarily represent ground truth. The rmrs representation begins with elementary predications (ep), which is a predicate that has a word as an argument and the other arguments relate the word to other predicates. Other rmrs predicates deal with how eps are related to each other (e.g., one ep may be a verb with two arguments, so it would have a arg1 and arg2 relation to two other eps).

As in Peldszus et al. (2012), we discarded utterances where the automatic process of converting Wizard actions into semantic alignments flagged problems, but unlike them, we also include the 681 utterances that used pronouns to refer to pieces. Our corpus hence totals 1687 utterances, with an average of 5.43 words per utterance (sd 2.36), and a vocabulary of 237 distinct words. We performed the experiments reported below both with manual transcriptions of the utterances as well as with asr transcriptions (for which we used the version of Sphinx4 described in Baumann et al., 2009, with models fine-tuned to this domain, achieving a word error rate of 0.24).

The task that we wanted our model to tackle can then be stated as follows: given information about the current state of the world (i.e., the game board), the previous system action, and about the (possibly still not-yet completed) utterance, predict an interpretation for the utterance, in the form of such a frame. Fig. 3 illustrates such a desired output from the model. In more general terms, what we want our model to learn then is how, in a given discourse context, language, as it unfolds, connects to the world. We use combinations of situated context, previous context, words of the utterance, and linguistic information as evidence to a mln, and infer what action is to be taken, what object is to be acted upon, and specifications of the manner of execution (as in Fig. 2).

As mentioned above, Markov Logic allows the specification of knowledge bases through first order formulae. A straightforward representation of the game board would simply assert salient properties of the individual objects such as their colour, shape, and position; for the topmost object (B:1) in Fig. 4 this could be colour(yellow)∧
                        shape(g)∧
                        pos(b, 1). However, in pre-experiments on held-out data, we found that a more parsimonious representation worked with the same results, in which there is only one abstract property that only implicitly does a typing into different features of the objects (by the Property() predicate); again, for the topmost piece (B:1) from the figure this would be piece(p)∧
                        property(p, yellow)∧
                        property(p, g)∧
                        property(p, row1)∧
                        property(p, col2). This representation follows a Davidsonian form of representing the relations between predicates and allows the mln to learn the individual mappings of the utterance and the world (i.e., words and constructions to perceptual properties) on its own.

The properties of the objects that we represented in this way were colour, shape, its row and column, horizontal and vertical percentage from the center, and several global spatial properties that denote where a piece is on the board: top, bottom, center, corner, left, right.

Relationships between objects were represented in a spatial relation predicate, SpatialRelation(), where the spatial relations were: above, below, next to, left of, right of, and near. All possible relations between objects were included, given the layout of the board and distribution of pieces on the board. The global properties and spatial relations between pieces were computed symbolically given the state of the board and pieces; we assume that computer vision processing would be able to provide these kinds of symbolic spatial properties of objects.

The utterance itself forms another source of information about the situation. In the simplest form, it could be represented just through assertions of the words which are part of it, e.g., word(rotate)∧
                        word(the)∧
                        word(yellow)∧… As mentioned above, we were interested in whether a more detailed linguistic analysis could provide more useful information to a model of situated semantics; we represented this information by extracting some of the relations of the rmrs representation for each utterance (-prefix) and converting them to a slightly simpler form. Words are represented as rmrs eps (elementary predications); that is, by their lemma and with additional identifiers as arguments, which can be used to relate the ep to other rmrs structure (represented using EP() and RMRS() predicates). In the variants of the model that only look at words, the other arguments can simply be ignored in the mln template. Two other Modifier() (or Mod() in figures to save space) predicates extract relations from the rmrs representation and are added as a simpler representation of relations between words.

The discourse context can be easily represented by a predicate for each previous slot that was predicted. This is precisely how the previous action and previous option slots were included (via PrevAction() and PrevOption() predicates, respectively. The previous argument was used to determine which piece had a visually represented “selected” outline around a piece in the visual world, which resulted in a corresponding selected property for that piece. For example, if the previous utterance was take the red cross, then the red cross that was denoted (by the Wizard) would be visually selected by an outline, indicating that the action was understood (take=select). In the next utterance, that piece would have the selected property in its set of properties, which was a very important distinguishing property for pronouns, as will be shown later.

Finally, the interpretation that is to be predicted needs to be represented. This is done through predicates Action(), Argument() and Option(). These predicates each have an argument that can range over the possible values of the slots.

An example of how the predicates are represented and formatted for mln is shown in Fig. 6
                        . This only shows part of an utterance and part of two pieces to save space. The EP predicates in the top section contain the words and corresponding identifiers to connect those words with the RMRS predicates. The middle section represents two pieces and their corresponding properties. The previous context is represented by the predicates denoted by an asterisk, the first two map directly to their corresponding frame elements from the previous utterance, whereas the argument frame element is represented by the selected property of a piece, as explained. The bottom section represents the three frame elements for this state of the board and corresponding utterance; these are given during training, and are the hidden variables during inference. The final argument in each predicate represents a board identifier, a way of denoting that a state of the four sources of information and what they jointly infer all belong together.

To summarise, each problem instance is represented as a conjunction of predicates encoding (a) the (world) situational context (the state of the game board), (b) the discourse context (in the form of the previous action), (c) the (possibly as-yet partial) utterance comprising words and (d) the corresponding linguistic representation.

The actual model is now formed by the mln templates that specify the relations between the predicates (the actual template that defines our mln is shown in Fig. 7
                        ); in particular those between those representing the available information (evidence) and the predicates that represent the information that is to be predicted (or, in mln terminology, whose most likely values are to be inferred). Fig. 8
                         illustrates graphically how our model makes these connections, separately for each slot, that is to be predicted.


                        Figs. 7 and 8 show that for action and option, we assume an influence both of the words present in the utterance (denoted by ep; see above) and of the previous value of these slots on the current one. The previous context that is used for training and evaluation is taken from the corpus annotation files. The structure for argument is somewhat more complicated; this is where the linguistic information coming from the RMRS() and Modifier() predicates comes into play, and also where the connection between language and properties of the visual scene is made. All formulas infer a slot in the nlu frame. The mln system gives us probability distributions over all possible groundings of the frame element predicates, but as we are interested in a more fully incremental processing model (as described above), we applied an additional decision rule to the output of the mln component. If the probability of the highest candidate is below a threshold, unknown is returned, otherwise that candidate is returned. Ties are broken by random selection. The thresholds for each frame element/predicate were determined empirically on held-out data so that a satisfactory trade-off between letting through wrong predictions and changing correct results to unknown was achieved.

We pause to note that our model is not very complicated, at least not in terms of what mlns are able to handle; the formulae are mostly made up of predicates that have an observed variable as an argument and other arguments represent relations to other predicates. This makes our task one of simple classification which could be tackled using other existing classifiers; we choose mln here for the following reasons: the relations between predicates can be defined (via the template) with particular ease in this formalism; even though we do separate queries, we only need to build a network once (that is, it handles the task of multiple classifiers in a single model); and finally for the inherent ability of mln for grounding, which is particularly important for the argument slot, as the desired value that fills the slot is not itself a grounded value, but is inferred by the grounded evidence as an identifier for a real-world object.

All results reported below were obtained by averaging results of a 10-fold validation on 1489 Pento boards (i.e., utterances+context). We used a separate set of 168 boards for small-scale, held-out experiments. For learning and inference we used the Alchemy system, Domingos et al. (2006), using the discriminative training option (see Singla and Domingos, 2005).
                           5
                        
                        
                           5
                           
                              http://alchemy.cs.washington.edu/.
                         Inference was performed on the Action, Argument, and Option predicates; a single answer was derived from the distributions delivered by Alchemy in the way described in the previous section.

To be able to assess our results, we devised two kinds of baselines for the full utterance. The simplest is just the majority class. Table 1
                         shows the accuracy when choosing the majority class, both for the frame elements individually (where this baseline is quite high) and for the most frequent full frame (which, unsurprisingly, only reaches a very low accuracy). In other words, in the corpus there were some actions that were performed more often than others, and some pieces on which actions were performed occurred more often, but the combination of that action and piece was not necessarily most frequent. For Action, a higher baseline can be achieved by choosing the most frequent value condition on the immediately preceding one; as for example a take action was often followed by a put action, or a take action would not typically occur twice in a row). The accuracy for this method, where the conditional distribution was determined on the 1489 boards and tested on the remaining 168 boards, is shown in the table under “action contextual”.

We give our results below as f-score, slot accuracy and frame accuracy based on comparison to a gold representation. We also include the individual slot accuracies for completeness. To compute the f-score, we count a prediction of unknown as a false negative (since for our test utterance a value should always have been predicted) and a wrong prediction as a false positive; i.e., a frame with one correct slot and the rest as unknown has perfect precision, but only 1/3 recall. Slot accuracy counts the number of slots that are correct, and frame accuracy only counts fully correct frames. Hence, these metrics are successively more strict. We also give accuracies for each of the three slots. Which metric most accurately predicts performance of the model in the context of a dialogue system depends on properties of the further components: if they can act on partial frames, then an f-score that starts high and continually improves as the utterance goes on is desired; if not, then what's relevant is high frame accuracy.

On the incremental level, we followed (Schlangen et al., 2009) by using a subset of their incremental metrics, with a modification on the edit overhead:
                           
                              •
                              
                                 first correct: how deep into the utterance is the first correct guess made?


                                 first final: how deep into the utterance is the correct guess made, and subsequently not changed?


                                 edit overhead: what is the ratio of unnecessary edits divided by sentence length, where the only necessary edit is that going from unknown to the final, correct result anywhere in the sentence)?

The procedure on the incremental level is similar to the full utterance procedure, except that for incremental evaluation the f-score, slot accuracy, and frame accuracies were calculated word for word against the final gold representation.

@&#RESULTS@&#

We now move to results of our experiments, beginning with sentence-level results. We then show the incremental results, and then move to a model analysis.


                           Table 2
                            compares the results for the 8 different experiments; the first four rows show results for models with discourse context, the last four for models that ignore discourse context. Training and evaluation data was either hand-transcribed (H), or automatically recognized speech (S). The results are given in f-score, item accuracy, and frame accuracy, as explained, with individual slot accuracies.

Each row in Table 2 is ordered by its rank in the results based on frame accuracy (the tie between the final two was resolved using item accuracy). Unsurprisingly, the highest ranking row uses hand-transcribed data for training and evaluation, with discourse context. However, the second ranking row uses asr output for training. Even more interesting is the third ranking row uses asr for training and testing, and the results handily beat using hand-annotated data for training (rank 4). This is a welcome result as typically of course asr-trained models perform worse compared to hand-transcribed input. Our initial explanation is that the asr-trained model puts more stock in non-word resources like the visual world and semantic structure, but still does not ignore the words completely (compare rows 2 and 3; evaluation on hand-annotated data performs better). This is evidenced by the large changes in the action and option slots, which are completely tied to the words and the previous corresponding slot. The argument slot, on the other hand, has less drastic change between rows because it takes the visual context, which is more stable, into account. Further investigation is left as future work.

When discourse context is ignored, all scores take a big hit. The same trend as before occurs where the row with rank 7 which uses asr for training and testing outperforms the row with hand-annotated training data. Why it is the case that discourse context takes such a huge hit is mostly due to the inability to infer the argument frame element correctly, due to a lack of pronoun resolution. This is discussed in further detail in Section 3.6.2.

When all sources of information are included, the model performs well above baselines and compared to previous approaches (Peldszus et al., 2012 achieved 64.3% in argument accuracy (as a reference resolution task on non-pronoun utterances) and Heintze et al., 2010) achieved an FScore of 76.94 using conditional random fields), while making the desired connections between the real world, discourse context, the words, and the linguistic structure. As noted earlier, utterances in our corpus that had pronouns and ones that referred to pieces using descriptions (60% of the utterances referred to a piece using descriptions; 40% used pronouns), were included. The argument slot is well below the upper bound when ignoring discourse context (38.52% using hand-annotated for training and testing compared to an upped bound of 60%).


                           Table 3
                            shows the incremental results. Rows involving first correct and first final represent average percentage into the utterance, where the utterances were binned for lengths 1–6, 7–8, and 10–17 (“short”, “normal”, “long” utterances, respectively) so as to not let it vary too much on how many words are denoted by the percentage of a sentence (i.e., 25% of a 3-word sentence is the just first word, but in a 15-word sentence, it includes the first three words). The boundaries of the bins were determined by looking at the distribution of utterance lengths, which looked like a normal distribution with 7 and 8-word utterances having the highest representation. Our model makes very early predictions (low first correct), but those predictions do not always remain stable, and there is an edit overhead which leads to a final correct decision only later in the sentence (first final). For action and argument, the final decision is typically made within the first third of the utterance. For option, it comes later in the sentence; this reflects typical utterance structure, where the words that describe the option (“spiegle es horizontal”; mirror it horizontally, where horizontally is the option) usually appear towards the end of the sentence.

Another way to show incremental progress is in Figs. 9 and 10
                           
                            for sentences of “normal” length (7–8 words). These show how accurate the prediction was for each incremental step into the sentence, both for the model with and that without access to discourse context, respectively. For this graph each incremental step is compared with the gold result. Fig. 10, the model variant without access to discourse context, shows that there is little impact on prediction of action or option, but a significant and constant impact on the quality of predicting argument (i.e., of doing reference resolution); this is due to some extent to the presence of anaphoric references which simply cannot be resolved without access to context.

Taken together, the incremental statistics help determine an “operating point” for later modules that consume nlu output. Under the assumption that the ongoing utterance will be one of normal length (this of course cannot be known in advance), the strength with which a decision of the predictor can be believed at the current point into the utterance can be read off the graphs.

We begin by looking at how well the model learned spatial relations, and follow that with reference and co-reference resolution. This leads into a short discussion of grounded semantics, and how the groundings are realized incrementally. We then look more closely at the linguistic representation, rmrs, and how it contributed. We finish with a short note about the limitations of mln.

Looking at the errors that the models made, among the problematic utterances we find a high frequency of descriptions of pieces using landmarks, that is, using spatial relations between pieces, suggesting that our model did not successfully pick up on these constructions.

However, basic spatial expressions were learned successfully, as can be illustrated by Fig. 11
                           . It shows the probability distributions for the utterances left and bottom right, on a 3×4 board (the typical size of boards in the corpus) that were generated for analysis, where each field was filled with the same kind of piece of the same colour (thus making these properties non-distinguishing). The darker the gradient in the figure the higher the probability as predicted by the model, and an input of “left” (or “bottom right”). The figure shows that the model successfully marks the fields closer to the left (or bottom-right, respectively) as having higher probability. Interestingly, “left” seems to be confused slightly with “right” for the model (but not “top” or “bottom”), indicating perhaps that it picked up on the general type of description (“far side”). Further investigation of model properties as pertaining to spatial relations is left to future work, however.

In many cases in the corpus, an utterance was used once to identify the piece, then subsequent utterances contained references to the same piece by using pronouns. This brings us to a strand of research known as anaphora resolution which focuses on identifying what preceding entity a pronoun is referring to, either within or across sentence boundaries. Anaphora resolution is well-studied in natural language processing (Mitkov et al., 1999 provides a nice introduction).

In this paper, the referent is actually quite obvious: it is always the object of the previous utterance. The utterances make up commands, so the subject becomes the addressee, that is, the dialogue system, who performs the action, and other verb arguments are not referred to anaphorically. When coupled with the visual world, anaphora resolution takes on a new goal; the object being referred to is a noun phrase that existed in a previous utterance (co-reference resolution), but it is also an exophoric reference to an actual object (reference resolution).


                           Fig. 12
                            shows an example of how reference resolution occurs incrementally for the sentence dreh sie nach rechts (rotate it to the right). The first board shows that there is a piece on the bottom row which is selected, before the utterance even begins. It is selected because the previous utterance in the dialogue referred that piece (e.g., take the piece on the bottom in the middle). This piece receives the selected property in its set of Property predicates. Importantly, when the word dreh is uttered, there is no change in the probabilities of the pieces on the board as being intended to be selected. This means that the mln knows that this word does not contribute to the argument slot. When it comes to the next word, namely the pronoun sie, it immediately gives the selected piece (C:3) the highest probability by a large margin. Continuing into the utterance, the final nach and rechts, only show slight changes in the probability distribution over the pieces, actually ending in a stronger probability for the selected piece.

We now give an example of how a more complex utterance is incrementally resolved by the model. In Fig. 13
                           , the utterance nimm das gelbe kreuz ganz links oben (take the yellow cross completely left top – take the yellow cross on the top left) is shown. When gelbe (yellow) is uttered, there is not a yet very strong distinction between red and yellow pieces. A possible explanation is that the model relies on semantic information, words, and the visual world to infer the piece (previous discourse context does not play a role here). The semantic make up of this requires that gelbe, which is an adjective, have an argument, namely a noun which is used to denote the piece. Hence, an adjective is not as strong an indicator until the noun is uttered. This explains why the difference between colours becomes stark when kreuz is uttered; the yellow pieces have a higher probability (and they all happen to be crosses). Continuing into the utterance, ganz (fully or completely) indicates that the referred piece must be in an extreme position (top, bottom, left or right). This takes precedence over the colour because now the pieces in the extremes (all which happen to be crosses) get the highest probabilities. Once links (left) is uttered, it becomes clearer which one is intended: the only yellow one on the complete left. Here, as often in our corpus, redundant information is added (oben/top), which here adds weight to the other cross in the top row.

As this example nicely illustrates, resolution is still somewhat ‘local’, with the model getting distracted by the respective current word. The correct compositional meaning results only because at earlier steps pieces satisfying the other constraints (here, being a cross, being in an extreme position, being on the left side) had a higher ‘activation’. We leave the very interesting question of how this relates to classic semantic composition on the one hand and to evidence about actual cognitive processing to future work.

It was mentioned above that the rmrs representations used in training and evaluation were not checked for appropriateness and hence did not represent ground truth. Despite the obvious noise that this would produce, it was found to increase frame accuracy when included in the model.
                              6
                           
                           
                              6
                              The increase equates to an improvement in 61 utterances out of 1490, 41 of which resulted in a fully correct frame. Conversely, 37 utterances performed better when rmrs was not used.
                           
                        


                           Fig. 14
                            shows several randomly chosen utterances that had improved understanding (in terms of slot accuracy) when rmrs was present. These utterances represent non-standard command forms in German. This illustrates an added robustness when using the rmrs representations. When rmrs was not present in training or evaluation, utterances that had higher understanding were of the common command form type, which illustrates added confusion to some utterances when rmrs is present; but overall there is a significant net increase in accuracy when including rmrs.

We have shown that a mln can be used to represent rich relations between four sources of information and three frame elements. We have also shown that the way formulas are grounded to argument values corresponds very closely to the grounding of language with a visual environment. However, there are limitations to mln. There is a limit to the size of formulas, number of grounded variables in each formula, and number of constants that one can have in order to obtain exact counts (though that is not the case for this paper; exact counts were achieved for our small corpus and simple formulas). Formulas can be effectively factored, but that still requires that the satisfiability of each grounded formula needs to be determined, a problem which is NP-Hard (see Roth, 1996). Because of this, the expressiveness comes at the price of speed; inference (prediction/classification) in a mln is potentially very slow in comparison to other machine learning approaches.
                              7
                           
                           
                              7
                              We partially dealt with this; a version of Alchemy which can be invoked once and inferenced multiple times is available.
                            Even though our formulas were fairly simple and exact counts were computed during inference, we noticed mlns are sub-optimal in terms of speed when it comes to real-time interactive dialogue, which is our goal
                              8
                           
                           
                              8
                              On typical workstation computers, inference was consistently slower than the average length of a word; that is, a system using this would be slower than real-time.
                           ; particularly in incremental dialogue which requires calling inference at each word. Ongoing mln research attempts to overcome these speed and size limitations.

@&#CONCLUSIONS@&#

Markov Logic Networks are effective in expressing models for situated incremental natural language understanding in a domain like Pentomino. We have shown that various aspects of situated dialogue like previous context and the current state of the world all play a role in nlu. mlns are very well suited to grounding of language to a visual context, can act robustly to noisy input, and can implicitly learn how to handle spatial language and pronoun resolution to a certain extent. However, there is a trade-off in that mlns take some time to design, which still is an intellectual task. Furthermore, inference in mlns is still not as efficient as other methods in terms of speed, which can cause a slowdown in applications where very many inference steps are required, like inlu.

For future work, we will look at other ways of modeling the situation that provide more efficiency in terms of speed, but retain some of the expressiveness found in mln. Our focus will be on interactive systems that use real-time asr data, as well as other modalities.

@&#REFERENCES@&#


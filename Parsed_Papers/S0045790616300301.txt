@&#MAIN-TITLE@&#Diagnostically lossless coding of X-ray angiography images based on background suppression

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An automatic segmentation of the diagnostically relevant focal area of X-ray angiography images was developed.


                        
                        
                           
                           A background suppression coding strategy was proposed based on the accurate segmentation results.


                        
                        
                           
                           Our segmentation method identifies the Regions of Interest with an average Dice Similarity Coefficient of 0.98 with respect to manual segmentation.


                        
                        
                           
                           The coding performance improvement reaches 34%, compared to the case of coding with no background suppression.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

X-ray angiography images

Diagnostically lossless coding

Ray casting segmentation

Alpha-shapes filters

Region of interest compression

@&#ABSTRACT@&#


               
               
                  X-ray angiography images are widely used to identify irregularities in the vascular system. Because of their high spatial resolution and the large amount of images generated daily, coding of X-ray angiography images is becoming essential. This paper proposes a diagnostically lossless coding method based on automatic segmentation of the focal area using ray-casting and α-shapes. The diagnostically relevant Region of Interest is first identified by exploiting the inherent symmetrical features of the image. The background is then suppressed and the resulting images are encoded using lossless and progressive lossy-to-lossless methods, including JPEG-LS, JPEG2000, H.264 and HEVC. Experiments on a large set of X-ray angiography images suggest that our method correctly identifies the Region of Interest. When compared to the case of coding with no background suppression, the method achieves average bit-stream reductions of nearly 34% and improvements on the reconstruction quality of up to 20 dB-SNR for progressive decoding.
               
            

@&#INTRODUCTION@&#

X-ray medical imaging has become a popular non- or minimal- invasive modality in healthcare practice and research due to its low cost, high resolution and excellent capability to penetrate deep within tissue [1].

X-ray angiography, in particular, is a widespread tool that aids in visualizing and quantifying the human vascular system, which is an important pre-requisite for a number of clinical procedures [2]. X-ray angiography (angio) images are acquired by injecting a contrast agent into the blood vessels followed by X-ray fluoroscopic imaging. If several images are acquired at different time intervals, the resulting imaging data comprises a collection of frames describing the flow of the contrast agent through the vessels over a specific period of time [1]. Recent advances in telemedicine require that X-ray angio images be efficiently transmitted over networks of limited bandwidth. Moreover, a recent trend towards facilitating the general public on-line access to their own medical records has also become of significant interest to major companies and healthcare institutions [3]. X-ray angio images are, however, usually large in file size and thus pose heavy demands on storage and transmission resources, particularly if these images are to be managed through current picture archiving and communications systems (PACS) [4] with the associated digital imaging and communications in medicine (DICOM) standard [5]. The X-ray angio images used in this work are acquired from different human regions (e.g., knee, foot, arm, ankle, etc) and have much less frames than coronography and ventriculography image sequences. Yet, they produce large file sizes. As an example, a typical X-ray angio image sequence used in this work, comprising 5 frames, each with a spatial resolution of 1024 × 1024 pixels and a bit-depth of 16 bits per pixel, amounts to over 10 MB of data; in current practice, human vascular system studies involve up to ten X-ray angio images, with about 100 MB of imaging data per patient.

Lossless coding, and particularly diagnostically lossless coding, can reduce the storage and transmission burden of medical images, while avoiding any loss of valuable clinical data. Lossless coding usually exploits data redundancies to increase the coding efficiency while guaranteeing perfect reconstruction of the signal [6]. Diagnostically lossless coding, on the other hand, guarantees the perfect reconstruction of only those Regions of Interest (ROIs) that are used for diagnostic purposes. This is usually achieved by identifying the ROIs and applying lossless coding to only these regions and lossy coding to the background (BG) [7–10].

X-ray angiography image compression is an active topic of research. Recent published contributions are normally devised to a specific coding technique or to a particular compression strategy for angiography image. Depending on the compression strategy, contributions can be classified into lossy [11], lossless [6], or diagnostically lossless compression [8,10].

With regard to the recent diagnostically lossless coding methods developed for various medical images [7–10], most of them rely on segmentation to identify the ROI. Although these methods achieve competitive coding performances, they present two important drawbacks when applied to X-ray angio images. First, they employ either manual segmentation, which can be extremely time-consuming and prone to human errors, or automatic region-based segmentation[8], which may fail to identify the ROI accurately when the intensity values in the BG and ROI are very similar. Second, they are in general non DICOM-compliant, which renders them unsuitable for PACS.

In this paper, we focus on diagnostically lossless and progressive lossy-to-lossless coding of X-ray angio images through automatic segmentation. Specifically, we first remove the non-clinically relevant areas using a low-complexity segmentation method based on ray-casting and α-shapes [10]. The main difference with [10] is that the current manuscript explains with high detail all the parameters used in our proposal and justifies better the need for our approach, for instance presenting more segmentation results produced by more recent segmentation methods that do not work either. Further, the lossless compression performance is evaluated extensively using all coding techniques included in DICOM such as JPEG-LS, JPEG2000 and H.264 [12]. For JPEG-LS and JPEG2000, different multi-component transforms to exploit redundancy among component have been used. Also, results for a shape adaptive version of JPEG2000 [13] and for HEVC [14] video coding standard, considered the successor of H.264, are reported. Progressive lossy-to-lossless coding performance is investigated for JPEG2000 standard.

The rest of the paper is organized as follows. Our automatic segmentation technique is described in Section 2. Section 3 presents an extensive experimental evaluation for the cases of diagnostically lossless and progressive lossy-to-lossless coding. This section also discusses, in collaboration with physicians from Hospital Fundació Mútua de Terrassa, Spain, the accuracy of the proposed segmentation technique. Section 4 concludes this work.

The proposed coding method is based on the fact that improvements in coding efficiency may be achieved by exploiting some of the inherent symmetrical features of medical images. For example, in X-ray angio images, there are usually two distinguishable areas: the ROI, depicting skeleton and tissues, and the BG, depicting non-clinically relevant information, as shown in Fig. 1
                     . Note that in these sample frames, the ROI is located in the center of the image (i.e., the focal area) and the BG features radially symmetrical properties around the ROI. Based on this observation, we focus on exploiting these symmetrical features to attain automatic segmentation and thus increase coding efficiency.

Our method, as illustrated in Fig. 2
                     , consists of two main stages, the first stage deals with automatic ROI segmentation, while the second stage focuses on data coding. The automatic ROI segmentation is based on ray-casting and α-shapes, which provide a high level of accuracy with low computational complexity. After segmentation, our method suppresses the BG from the image to increase data redundancy. In the second stage, the method employs lossless or progressive lossy-to-lossless (PLL) coding on the BG-suppressed image. In the following sections, we describe in more detail these two stages.

The segmentation stage comprises four steps: (1) preprocessing; (2) boundary approximation; (3) boundary refinement; and (4) BG suppression.

This step reduces the amount of noise in the data and exploits correlations among frames. X-ray angio images contain random noise introduced by unblocked secondary radiation, poor film-developing and handling, or by the digitization process [15], which may affect the segmentation accuracy. To reduce this random noise, several techniques may be employed, such as low-pass filtering, neighbor average filtering, median filtering, non-local means [16] and 3D block matching [17]. In the algorithm, we employ anisotropic diffusion filtering in each frame as it is capable to efficiently reduce noise while preserving edge information [18].

Since X-ray angio images commonly consist of several frames that are usually highly correlated, a simple averaging operation may be used after noise reduction to generate a single frame that preserves the boundary between the ROI and BG. Here, we employ an averaging operation defined as 
                              
                                 
                                    I
                                    
                                       a
                                       v
                                       g
                                    
                                 
                                 
                                    (
                                    x
                                    ,
                                    y
                                    )
                                 
                                 =
                                 
                                    (
                                    
                                       
                                          ∑
                                          
                                             f
                                             =
                                             1
                                          
                                          F
                                       
                                       
                                          I
                                          f
                                       
                                       
                                          (
                                          x
                                          ,
                                          y
                                          )
                                       
                                    
                                    )
                                 
                                 /
                                 F
                                 ,
                              
                            where F is the number of frames in the X-ray angio image, and If
                           (x, y) and Iavg
                           (x, y) denote the intensity value of the spatial position (x, y) in frame f and the average frame Iavg
                           , respectively. By employing this simple averaging operation, we reduce the computational complexity of subsequent steps since segmentation can now be performed on the average frame and the results be used to identify the ROI in each frame.

This second step computes a coarse approximation of the location of the boundary between the ROI and BG on the average frame Iavg
                            by employing ray-casting and the image (pixel intensity) profiles computed along a set of rays. Let P denote the center of Iavg, Rn
                           (P, θn
                           ) denote ray n projected from P towards the periphery at an angle θn
                            (see Fig. 3
                           (a)), and An
                            denote the image profile along ray Rn
                           (P, θn
                           ) computed using nearest-neighbor interpolation (see Fig. 3(b)). The image profile An
                            provides information about important intensity changes along the ray Rn
                           (P, θn
                           ), which may be used to locate the position of the boundary between the ROI and BG. Due to the symmetrical properties of the ROI, important intensity changes along ray Rn
                           (P, θn
                           ) usually occur at a very similar Euclidean distance from P as in ray 
                              
                                 
                                    R
                                    n
                                 
                                 
                                    (
                                    P
                                    ,
                                    
                                       θ
                                       n
                                    
                                    +
                                    π
                                    )
                                 
                              
                           . We call such two rays, Rn
                           (P, θn
                           ) and 
                              
                                 
                                    R
                                    n
                                 
                                 
                                    (
                                    P
                                    ,
                                    
                                       θ
                                       n
                                    
                                    +
                                    π
                                    )
                                 
                                 ,
                              
                            symmetrical rays. Fig. 3(a) illustrates this concept by depicting rays R
                           1(P, θ
                           1) and R
                           2(P, θ
                           2), and their symmetrical rays 
                              
                                 
                                    R
                                    1
                                 
                                 
                                    (
                                    P
                                    ,
                                    
                                       θ
                                       1
                                    
                                    +
                                    π
                                    )
                                 
                              
                            and 
                              
                                 
                                    R
                                    2
                                 
                                 
                                    (
                                    P
                                    ,
                                    
                                       θ
                                       2
                                    
                                    +
                                    π
                                    )
                                 
                              
                           . Fig. 3(b)–(c) plots the corresponding image profiles A
                           1, 
                              
                                 A
                                 
                                    1
                                    +
                                    π
                                 
                              
                            and A
                           2, 
                              
                                 A
                                 
                                    2
                                    +
                                    π
                                 
                              
                           . Note that the first significant intensity changes along the image profile plot, moving from the periphery towards P, usually happen at the boundary between ROI and BG and therefore, may be used to approximate the location of this boundary.

Nevertheless, in many cases, the intensity values of ROI and BG tend to be very similar in the boundary region for some of the rays, making it challenging to approximate the boundary location by simply analyzing the image profile along such rays. To overcome this, we exploit the radially symmetrical properties of ROIs and estimate the location of the boundary along a challenging ray by using the location of the first significant intensity change along the corresponding symmetrical ray. This idea is illustrated in Fig. 4
                           . We follow the next procedure and criterion to identify the significant intensity changes and determine the location of the boundary along a pair of symmetrical rays:

                              
                                 1.
                                 For each pair of symmetrical rays, Rn
                                    (P, θn
                                    ) and 
                                       
                                          
                                             R
                                             n
                                          
                                          
                                             (
                                             P
                                             ,
                                             
                                                θ
                                                n
                                             
                                             +
                                             π
                                             )
                                          
                                          ,
                                       
                                     we compute the corresponding image profiles, An
                                     and 
                                       
                                          A
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                    .

For each pair An
                                     and 
                                       
                                          A
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                     , we compute the corresponding intensity-change sets, denoted by Cn
                                     and 
                                       
                                          
                                             C
                                             
                                                n
                                                +
                                                π
                                             
                                          
                                          ,
                                       
                                     respectively. An intensity-change set stores the largest intensity change within a small sliding window of size w
                                    1. Fig. 5
                                     depicts a sample computation of Cn
                                    . It is worth noting that, instead of computing the Cn
                                     and 
                                       
                                          C
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                     through the Intensity-change operator, we could also use first derivative of Gaussian, central moment of variance, or mean deviation, to obtain an equivalent representation of the intensity-change set in An
                                     and 
                                       
                                          A
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                    . The intensity change operator has been selected because it is more computationally efficient than the above mentioned operators and it provides the same accuracy in detecting the first significant change.

We compute the maximum value 
                                       
                                          M
                                          =
                                          m
                                          a
                                          x
                                          {
                                          
                                             C
                                             n
                                          
                                          ,
                                          
                                             C
                                             
                                                n
                                                +
                                                π
                                             
                                          
                                          }
                                       
                                     and threshold 
                                       
                                          T
                                          =
                                          M
                                          ×
                                          t
                                          ,
                                       
                                     where 0 < t < 1.

In the intensity-change set where M is found, we search for the first element larger than T, denoted by Bn
                                     (or 
                                       
                                          B
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                    ).

We estimate 
                                       
                                          B
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                     (or Bn
                                    ) in 
                                       
                                          C
                                          
                                             n
                                             +
                                             π
                                          
                                       
                                     (or Cn
                                    ) by searching for the largest element within a window of size w
                                    2 centered in 
                                       
                                          
                                             C
                                             
                                                n
                                                +
                                                π
                                             
                                          
                                          
                                             [
                                             
                                                B
                                                n
                                             
                                             ]
                                          
                                       
                                     (or 
                                       
                                          
                                             C
                                             n
                                          
                                          
                                             [
                                             
                                                B
                                                
                                                   n
                                                   +
                                                   π
                                                
                                             
                                             ]
                                          
                                       
                                    ) (see Fig. 6
                                    ). Positions An
                                    [Bn
                                    ] and 
                                       
                                          
                                             A
                                             
                                                n
                                                +
                                                π
                                             
                                          
                                          
                                             [
                                             
                                                B
                                                
                                                   n
                                                   +
                                                   π
                                                
                                             
                                             ]
                                          
                                       
                                     correspond to the position of the boundary along rays Rn
                                    (P, θn
                                    ) and 
                                       
                                          
                                             R
                                             n
                                          
                                          
                                             (
                                             P
                                             ,
                                             
                                                θ
                                                n
                                             
                                             +
                                             π
                                             )
                                          
                                          ,
                                       
                                     respectively.

We repeat steps 1–5 for all pairs of symmetrical rays.


                           Section 3 reports on the values for parameters t, w
                           1 and w
                           2 that result in the best performance for the data set used in the experimental evaluation.

The previous step results in a set of locations that approximates the position of the boundary between the ROI and BG. Fig. 7
                           (a)–(b) shows examples of such locations, depicted as white pixels over a black background, for an average frame Iavg
                           . Note that these pixels only provide a coarse approximation of the overall boundary, for instance in the zoom area in Fig. 7(b) we can see that several pixels are cluttered in a small area and disconnected with the other pixels. In order to refine the boundary location and compute a closed contour, we link these pixels by employing α-shapes [19]. The objective is to create a closed contour that accurately describes the boundary between ROI and BG, so that this contour can be used to create a binary mask.

Let us define a disk of radius r = 1/α pixels (thus, the unit of α is 
                              
                                 p
                                 i
                                 x
                                 e
                                 
                                    l
                                    
                                       −
                                       1
                                    
                                 
                              
                           ), such that if α > 0, we obtain a closed disk; if α = 0, we obtain a closed half-plane; and if α < 0, we obtain the closure of the complement of a closed disk. Let us assume that the set of pixels corresponding to the boundary location forms a set of points on a plane, where the location of each pixel i denotes the location of point Pi
                            in the point set. Based on this assumption, we compute a closed contour as follows:

                              
                                 1.
                                 For each point Pi
                                     in the point set, we create a vertex Vi
                                    .

We create an edge between two vertices Vi
                                     and Vj
                                     whenever there exists a disk of radius 
                                       
                                          r
                                          =
                                          1
                                          /
                                          α
                                       
                                     pixels containing the entire point set and which has the property that Pi
                                     and Pj
                                     lie on the disk boundary.

After employing α-shapes we obtain a closed contour with less distortion than those generated by simple morphological operations like closing or dilation. Fig. 7(c) shows those points –squared in red in the figure– where an edge can be traced for a closed disk of radius 
                              
                                 r
                                 =
                                 1
                                 /
                                 α
                              
                            pixels, with 
                              
                                 α
                                 =
                                 −
                                 0.01
                              
                           . Note that such small r values may result in additional closed contours inside the set of boundary points (see Fig. 7(e)). In such cases, we select the outermost contour as the ROI boundary to ensure that the whole ROI is inside the contour.

After computing the closed contour between the ROI and BG, we compute a binary mask by setting the intensity values of those points inside the contour to 1 (ROI) and those outside the contour to 0 (BG). We then achieve BG suppression by applying a logical AND operation between this mask and each frame of the X-ray angio image, which sets the BG to zero. There is no need to transmit this mask. Mask results and BG-suppressed images are reported in Section 3.

In this work, we focus on four coding techniques, JPEG-LS, JPEG2000, H.264 and HEVC. All of them support lossless coding and provide excellent coding performance. Note that only JPEG-LS, JPEG2000 and H.264 are included in DICOM. We are particularly interested in JPEG2000 as this coding standard offers a richer set of coding features than any other lossless coding method. These features include scalability by resolution and quality and the capability to exploit data redundancies among frames of X-ray angio image sequences through the use of a multi-component transform.

It is important to mention that BG-suppressed frames of X-ray angio image sequences usually contain sharp boundaries between BG and ROI that may generate a large amount of high frequencies responses during the spatial wavelet transform (WT) process of JPEG2000, penalizing the coding performance. The shape-adaptive version of JPEG2000 (SA-JPEG2000) [13] is designed to overcome this issue. SA-JPEG2000 modifies the spatial WT and bit-plane encoder of JPEG2000 so that only the ROI data is processed, without the need to encode the BG. SA-JPEG2000 also allows for the use of multi-component transforms but requires that the binary mask used to identify the ROI be encoded and transmitted. SA-JPEG2000 may then provide a theoretical optimal coding performance for ROI coding using JPEG2000. In our evaluation results we consider SA-JPEG2000 as the benchmark coding method.

We performed extensive performance evaluations to verify the accuracy and advantages of our proposed method. In particular, we carried out two different sets of evaluations aimed at assessing: (a) the segmentation stage, and (b) the coding stage, which includes diagnostically lossless and PLL coding.

Our test data set comprises 60 X-ray angio image sequences of various frames, each frame with a resolution of 1024 × 1024 pixels of 12 bits of unsigned precision. All the images were routinely acquired at Hospital Mútua de Terrassa, Spain, with a Siemens AXIOM-Artis system using iodine as the X-ray contrast agent. The segmentation stage of the proposed strategy has been implemented and run with MATLAB R2012a.

Supplementary materials for reproducing the experiments are provided at http://www.gici.uab.cat/GiciApps/SupplementaryMaterials.tar.gz 
                     
                        1
                     
                     
                        1
                        The material includes some of the X-ray images, segmentation and compression scripts. The total size of the file is 75.8 MB.
                     .

With the aim of providing quantitative results, we quantify the segmentation accuracy of one automatic segmentation method by comparing its results to the manual segmentation performed with the help of physicians from Hospital Mútua de Terrassa (Spain), using the following Dice Similarity Coefficient (DSC):

                              
                                 (1)
                                 
                                    
                                       
                                          DSC
                                          =
                                          
                                             
                                                2
                                                ×
                                                
                                                   ∑
                                                   
                                                      x
                                                      =
                                                      0
                                                   
                                                   
                                                      X
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   ∑
                                                   
                                                      y
                                                      =
                                                      0
                                                   
                                                   
                                                      Y
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   (
                                                   M
                                                   _
                                                   R
                                                   O
                                                   I
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                   ×
                                                   P
                                                   _
                                                   R
                                                   O
                                                   I
                                                   
                                                      (
                                                      x
                                                      ,
                                                      y
                                                      )
                                                   
                                                   )
                                                
                                             
                                             
                                                #
                                                M
                                                _
                                                R
                                                O
                                                I
                                                +
                                                #
                                                P
                                                _
                                                R
                                                O
                                                I
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           where 
                              
                                 M
                                 _
                                 R
                                 O
                                 I
                              
                            and 
                              
                                 P
                                 _
                                 R
                                 O
                                 I
                              
                            represent the binary masks detected, respectively, manually and automatically; 
                              
                                 #
                                 M
                                 _
                                 R
                                 O
                                 I
                              
                            and 
                              
                                 #
                                 P
                                 _
                                 R
                                 O
                                 I
                              
                            denotes the number of ROI samples in 
                              
                                 M
                                 _
                                 R
                                 O
                                 I
                              
                            and in 
                              
                                 P
                                 _
                                 R
                                 O
                                 I
                                 ,
                              
                            and X and Y are the number of rows and columns of the image. Note that 
                              
                                 DSC
                                 ∈
                                 [
                                 0
                                 ,
                                 1
                                 ]
                                 ,
                              
                            and higher DSC indicates higher similarity between 
                              
                                 M
                                 _
                                 R
                                 O
                                 I
                              
                            and 
                              
                                 P
                                 _
                                 R
                                 O
                                 I
                                 ,
                              
                            therefore indicates higher segmentation accuracy.

We studied the proposed segmentation algorithm using various parameters w
                           1, w
                           2, t and α. The influence of changing the number of casting rays is also reported.

With regard to the sliding window size w
                           1 and w
                           2, w
                           1 defines the range to find the steepest intensity change, as depicted in Fig. 5. When the steepest intensity change is located, the center pixel of the current sliding window will be defined as the boundary pixel. Therefore, a small w
                           1 will reduce the distance between the position of the real boundary pixel and the position found by our algorithm, Bn
                           . On the other hand, w
                           2 defines the range where the second boundary pixel position 
                              
                                 B
                                 
                                    n
                                    +
                                    π
                                 
                              
                            is placed, after Bn
                            has already been found, as depicted in Fig. 6. In order to find 
                              
                                 B
                                 
                                    n
                                    +
                                    π
                                 
                              
                            based on the position Bn
                           , it is required that 
                              
                                 
                                    w
                                    2
                                 
                                 /
                                 2
                                 >
                                 
                                    |
                                    
                                       B
                                       
                                          n
                                          +
                                          π
                                       
                                    
                                    −
                                    
                                       B
                                       n
                                    
                                    |
                                 
                                 ,
                              
                            i.e., the range w
                           2 should be large enough to include the intensity change belonging to the second boundary pixel; however, if w
                           2 is too large, another larger intensity change of a non-boundary edge could go inside the window, being mistakenly identified as the second boundary pixel.

Concerning t, it is employed to define threshold value T used for finding the most external significant intensity change. Consequently, the larger t is, the stepper significant change will be detected.

Finally, parameter α is employed to define the disks for the boundary refinement, which must have a small enough absolute value (i.e., |r| is large enough) to close all the disconnected points.

In practice, parameters w
                           1, w
                           2, t and α have been chosen after training our algorithm with 30 images. For the training, we test different values for w
                           1, w
                           2, t and α and the quantitative segmentation performance DSC is then computed. The parameters values have been set for those combinations that obtain the highest mean and the lowest Standard Deviation (Std) of DSC. Firstly, we set 
                              
                                 
                                    w
                                    1
                                 
                                 =
                                 10
                              
                            pixels and 
                              
                                 
                                    w
                                    2
                                 
                                 =
                                 50
                              
                            pixels, obtaining DSC results that yield the most accurate and stable segmentation when using 
                              
                                 t
                                 =
                                 0.7
                                 ,
                              
                            and 
                              
                                 α
                                 =
                                 −
                                 0.01
                              
                           . Secondly, we set 
                              
                                 t
                                 =
                                 0.7
                              
                            and 
                              
                                 α
                                 =
                                 −
                                 0.01
                                 ,
                              
                            and find that 
                              
                                 
                                    w
                                    1
                                 
                                 =
                                 10
                              
                            pixels and 
                              
                                 
                                    w
                                    2
                                 
                                 =
                                 50
                              
                            pixels obtain an appropriate accuracy. According to this training, in our experimental setting, we used parameters 
                              
                                 
                                    w
                                    1
                                 
                                 =
                                 10
                              
                            pixels, 
                              
                                 
                                    w
                                    2
                                 
                                 =
                                 50
                              
                            pixels, 
                              
                                 t
                                 =
                                 0.7
                              
                            and 
                              
                                 α
                                 =
                                 −
                                 0.01
                              
                            in our algorithm.

Note that, in order to detect the boundary using our technique, the number of casting rays influences the execution time of our segmentation algorithm, as presented in Table 1
                           . For instance, if the rays are cast every 0.1 or 6 °, the execution time is, respectively, 96 and 8.7 seconds. The mean and Std of the resulting DSC are 0.985 and 0.002 for rays cast every 0.1 ° and 0.983 and 0.003 for rays cast every 6 °. In our experimental results we have cast the rays every 2 deg, based on the trade off between boundary refinement accuracy and execution time.

We first compare our segmentation technique to several edge-based and region-based segmentation methods. In general, edge-based methods use exclusively edge information to identify the ROI, while region-based methods use texture, intensity or statistical features extracted from the image.


                           Fig. 8
                            (a)–(e) shows one average frame and its visual segmentation results using several edge-based methods; specifically Canny edge detector, Sobel edge detector [20], orthogonal projection [21] and our proposed boundary detection technique. It is important to mention that the average frame in Fig. 8(a) is one of the most challenging average frames in our test data set. As Canny, Sobel and orthogonal projection are developed to generate the edge representation of an image, they detect all the edges but do not distinguish the ROI boundary and the other edges in angio images; therefore, their edge results can hardly be used directly to identify the ROI and BG regions. Our proposed technique focus only on locating the unique and closed ROI contour of the angio image, benefiting from the radially symmetrical feature of these images, which then generates only the ROI boundary that can be used to define the ROI directly.


                           Fig. 8 (f)–(j) shows the binary masks for the average frame in Fig. 8(a) computed using state-of-the-art region-based methods. These methods are: Active Contour Without Edges (Active Contour WE) [22], Bias Correction Level Set (BC Level Set) [23], Adaptive Seeded Region Growing (Adaptive SRG) [24], and Marker-Controlled Watershed (MC Watershed) [25].

In Active Contour WE, the deformation process of the curve does not depend on the gradient of the image as in classical active contour models; instead, it depends on the difference of intensities inside and outside the contour, making these curves less sensitive to noise and the initial curve position. In our experiments, we set the most outside square boundary of Iavg
                            as the initial curve. Fig. 8(f) shows the result of Active contour WE, which fails to correctly detect the ROI boundary in those regions where the intensities between BG and ROI are very similar. BC Level Set is a region-based method capable of dealing with intensities inhomogeneities while using the well-known level-set formulation [23] based segmentation process. Adaptive SRG combines Otsu’s thresholding method and regular SRG, avoiding the “trial-and-error” threshold selection of SRG, which is commonly done with human supervision. In our experiments, for BC Level Set the initial curve is the most outside square boundary of Iavg
                           , while for Adaptive SRG the initial seeds are a selection of pixels belonging to the four corners of Iavg
                           . Fig. 8(g) and (h) shows results for BC Level Set and Adaptive SRG, both methods miss-classify dark bones and tissues areas as being part of the BG. MC Watershed is based on watershed transform; it employs predefined background-region marker pixels and foreground-region marker pixels to solve the embedded “over-segmentation” problem of regular watershed methods. Fig. 8(i) shows the result of MC Watershed. It is important to mention that in our experiments, after an extensive search to define good background-region markers, we were able to segment correctly 27 of the 60 images, which accounts for less than 50% of the images. In summary, all the region-based methods [22], [23], [24] and [25] classify the ROI and BG basically based on the the intensity differences. Without using the radially symmetrical feature of the angio image to help the identification, all of them can not avoid the misclassification of the ROI and BG regions when the intensity values in both areas are quite similar, as shown in the left-bottom area of the image in Fig. 8(a) .

For all the methods tested, the corresponding parameters were adjusted according to the values recommended by the authors and according to our evaluations in order to provide the most accurate segmentation results.

The mean and the standard deviation (Std) values of DSC are presented in Table 2
                            for the 60 X-ray angio image sequences. It can be seen from these results that the proposed method has not only the most accurate segmentation results (highest mean DSC), but also the most consistent performance (lowest Std of DSC).


                           Fig. 9
                            shows the BG-suppressed average frames for twelve different X-ray angio image sequences, with the boundary between ROI and BG enhanced in red. Note that our proposal distinguishes the ROI from the BG with high accuracy. For the rest of the images in the test data set, the results are equivalent.

We compare several lossless coding methods after applying our segmentation technique to the case of no BG suppression. To better understand the relationship between the amount of BG and the coding performance, the 60 tested images are divided into various subsets according to the amount of BG (in %). Our evaluations include lossless coding and PLL coding. The later is important in interactive telemedicine applications to access and display X-ray angio image sequences over channels of various capacities.

We first compare lossless JPEG2000, JPEG-LS, H.264 and HEVC to the case of coding after BG suppression using our segmentation technique, denoted by BGS-JPEG2000, BGS-JPEG-LS, BGS-H.264 and BGS-HEVC, respectively. In order to obtain a theoretical optimal rate for JPEG2000, SA-JPEG2000 is applied on the BG-suppressed images. We employ 5 levels of 5/3 reversible spatial WT and codeblocks of size 64 × 64 for JPEG2000 and SA-JPEG2000, using the BOI 
                           2
                        
                        
                           2
                           The implementation of BOI software can be downloaded from http://www.gici.uab.es/BOI
                           
                         software. For JPEG-LS, the reset interval to 64 and the line-interleaved mode for multi-component images are used within the HP implementation LOCO-I/JPEG-LS. For H.264, the reference software JM 16.2 is used, with FRExt Profile ”High 4:4:4” selected for Intra coding and QP and QP Offsets set to 0. For HEVC, the reference software HM 16.2 is used. Three coding modes of HEVC are tested: Intra mode, using the Intra main profile; Random Access (RA) mode, using the Random Access profile and RExt mode, which uses HM 16.2 software with the SCM 3.0 extension and the Random Access main RExt profile. For all these three modes, QP was set to 0 and both TransquantBypassEnableFlag and CUTransquantBypassFlagForce are set to 1, and in RExt mode, CostMode is set to lossless. Note that, in order to comply with the profiles used in H.264 and HEVC, all angio frames are coded using the colour space YUV 4:4:4 and YUV 4:0:0, respectively.


                        Table 3
                         reports the average coding results, in bits per pixel (bpp), for each image subset and for the whole test data set. When no BG suppression is used, the entire image is losslessly encoded. These results indicate that by employing BG suppression the coding performance improves by more than 28%, on average, for all coding methods compared to the case of no BG suppression. H.264 does not achieve as good coding performance as the other coding methods for the angio images. BGS-HEVC RExt attains the best coding performance, followed by BGS-JPEG-LS. BGS-JPEG2000 gets a similar coding performance as BGS-HEVC and BGS-JPEG-LS, while allowing accessing the coded data in a progressive manner. Note that SA-JPEG2000 is, on average, 0.1 bps better than BGS-JPEG2000 even though it requires that the ROI binary mask be encoded and included in the bit-stream. This improvement is mainly due to skipping all of the BG samples during spatial WT and bitplane coding.

As video coding standards H.264 and HEVC are developed with also exploiting the redundancy among frames, we also compare the lossless coding performance when the redundancy among frames is exploited through different multi-component transforms included in Part-2 of JPEG2000 [26], namely Reversible Haar Transform (RHAAR), Reversible Karhunen Loeve Transform (RKLT)[12], 5/3 Reversible Wavelet Transform (RWT) and Differential Pulse Code Modulation (DPCM) [12]. Although JPEG-LS does not include any multi-component transformation, we also introduce the use of a multi-component transform in JPEG-LS to provide a fair comparison. For RHAAR and RWT, the number of decomposition levels along frames is given by min(5, ⌊log2
                        F⌋). For RKLT, the side information is encoded with LZMA and included in the final bit-rate. Table 4
                         reports the average coding results for the same image subsets in Table 3 when multi-component transforms are employed. It is easy to see that JPEG2000 and JPEG-LS with multi-component transforms get closer or even better coding performance than HEVC, for X-ray angio image sequences. BGS-RKLT-JPEG-LS yields, on average, the best coding performance, closely followed by SA-RKLT-JPEG2000, and both are slightly better than BGS-HEVC RExt, while SA-RKLT-JPEG2000 also supports PLL coding.

For progressive coding, we only compare DICOM-compliant methods that support PLL coding. Fig. 10
                         shows the rate-distortion performances for BGS-RKLT-JPEG2000, BGS-RHAAR-JPEG2000, BGS-RWT-JPEG2000, BGS-JPEG2000 and

JPEG2000 for three images with various amounts of BG.

The rate-distortion performances are evaluated in terms of the Signal-to-Noise Ratio (SNR), which is defined as 
                           
                              10
                              
                                 log
                                 10
                              
                              
                                 
                                    σ
                                    2
                                 
                                 
                                    M
                                    S
                                    E
                                 
                              
                           
                        . The mean-squared error (MSE) is computed as 
                           
                              
                                 1
                                 F
                              
                              
                                 1
                                 X
                              
                              
                                 1
                                 Y
                              
                              
                                 ∑
                                 
                                    f
                                 
                                 F
                              
                              
                                 ∑
                                 
                                    x
                                 
                                 X
                              
                              
                                 ∑
                                 
                                    y
                                 
                                 Y
                              
                              
                                 
                                    (
                                    
                                       I
                                       f
                                    
                                    
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    −
                                    
                                       
                                          I
                                          ^
                                       
                                       f
                                    
                                    
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    )
                                 
                                 2
                              
                              ,
                           
                         where If
                        (x, y) and 
                           
                              
                                 
                                    I
                                    ^
                                 
                                 f
                              
                              
                                 (
                                 x
                                 ,
                                 y
                                 )
                              
                           
                         denote, respectively, the original frame and the recovered frame, and σ
                        2 denotes the variance of the original image. The distortion gains between JPEG2000 and the BG-suppression strategies vary according to the amount of BG, and are up to 4dB, 10dB and 20dB for images with a BG percentage of 10.40%, 31.31% and 58.97%, respectively. Note that, when multi-component transforms are used, the best results are achieved by BGS-RKLT-JPEG2000, and the distortion gain compared to BGS-JPEG2000 is on average 5dB.


                        Fig. 11
                         depicts a region of two sample frames decoded at 0.01 bpp after JPEG2000 and BGS-RKLT-JPEG2000 PLL coding. It can be observed that the visual quality attained by the latter is better. This is a useful feature that can be exploited in situations where physicians need to access and analyze X-ray angio image sequences in limited bandwidth network environments, e.g., using mobile phones.

To summarize, background suppression helps achieving significant bit-rate savings, and while JPEG-LS with RKLT multi-component is the best lossless coding technique for the tested images, JPEG2000 with RKLT multi-component transform becomes the best alternative when different types of scalability are needed.

@&#CONCLUSIONS@&#

X-ray angio images have been commonly used in hospitals and clinics. However, the large file sizes of these images pose heavy demands on storage and transmission resources. Therefore, developing an efficient diagnostically lossless coding methods for this type of images without affecting the sensitive clinical-relevant areas is important.

In this paper, we present a two-staged diagnostically lossless coding method for X-ray angio images. The first stage performs automatic segmentation by employing ray-casting and α-shapes to distinguish the clinically relevant ROI from the BG. The second stage performs lossless or progressive lossy-to-lossless coding on the BG-suppressed images by using JPEG-LS, JPEG2000, H.264 and HEVC.

Experimental results suggest that our segmentation technique identifies the ROI with an average Dice Similarity Coefficient of 0.98 with respect to manual segmentation. When our proposal is combined with lossless coding methods, the coding performance is improved by more than 28%, on average. In addition, when a multi-component transforms is applied to exploit the component redundancy, the coding performance improvement reaches 34%. JPEG-LS technique with multi-component transform has the best coding results, closely followed by JPEG2000 with multi-component transform and HEVC. In addition, evaluations of JPEG2000 with multi-component transform and progressive lossy-to-lossless coding also indicate that, by employing BG suppression, significant improvements on the reconstruction quality of the images may be attained at all bit-rates.

@&#ACKNOWLEDGMENTS@&#

This work has been partially supported by the China Scholarship Council Program, FEDER, the Spanish Ministry of Economy and Competitiveness (MINECO), the Catalan Government and the Natural Sciences and Engineering Research Council of Canada (NSERC), under grants TIN2015-71126-R, TIN2012-38102-C03-03 (LIFE-VISION) and 2014SGR-691.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Effect of thesaurus size on schema matching quality

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We study the effect of thesaurus size on the outcome of schema matching.


                        
                        
                           
                           We utilize thesaurus to perform the mapping based on textual analysis.


                        
                        
                           
                           An enhanced search algorithm for applying thesaurus on texts was used.


                        
                        
                           
                           A new method of vector similarity was proposed and compared with cosine similarity.


                        
                        
                           
                           An increment in the average of similarity with distinctive values when using different thesauri was recorded.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Schema matching

Thesaurus

Information Retrieval

Searching

Performance

Text similarity

Structured vocabulary

@&#ABSTRACT@&#


               
               
                  Thesaurus is used in many Information Retrieval (IR) applications such as data integration, data warehousing, semantic query processing and schema matching. Schema matching or mapping is one of the most important basic steps in data integration. It is the process of identifying the semantic correspondence or equivalent between two or more schemas. Considering the fact of the existence of many thesauri for identical knowledge domain, the quality and the change in the results of schema matching when using different thesauri in specific knowledge field are not predictable. In this research, we studied the effect of thesaurus size on schema matching quality by conducting many experiments using different thesauri. In addition, a new method in calculating the similarity between vectors extracted from thesaurus database is proposed. The method is based on the ratio of individual shared elements to the elements in the compound set of the vectors. Moreover, we explained in details the efficient algorithm used in searching thesaurus database. After describing the experiments, results that show enhancement in the average of the similarity is presented. The completeness, effectiveness, and their harmonic mean measures were calculated to quantify the quality of matching. Experiments on two different thesauri show positive results with average Precision of 35% and a less value in the average of Recall. The effect of thesaurus size on the quality of matching was statically insignificant; however, other factors affecting the output and the exact value of change are still in the focus of our future study.
               
            

@&#INTRODUCTION@&#

For more than two decades, thesauri were exploited in many IR applications. For example, it were used in web document classification [1], summarization [2], indexing [3], and in calculating the semantic similarity of documents written in the same or in different languages [4]. Thesaurus was also utilized to solve the problem of schema matching [5–7]. Recently, thesaurus is used to predict query difficulty in medical domain. It was concluded that the performance of the predictor is influencing with many factors such as the coverage of thesaurus or query mapping quality [8]. Earlier studies assumed that there are no general thesauri such that sufficient coverage are available, so that the use and impact of thesaurus was not studied widely [8]. However, a high quality thesaurus is available for some specific domains, also many thesauri with different coverage abilities and sizes are found in the same domain.

Such as any other controlled vocabularies, thesaurus is reusable and replaceable (i.e. can be reused in many different applications and can be replaced by another compatible thesaurus). However, the quality of the thesaurus is crucially to be assessed before reuse or replacement. According to [9] the size of the vocabulary is one of the main quality issues considered in measuring the quality of the controlled vocabulary. This research is discuss the effect of the thesaurus size on the quality of schema matching, thus, measuring and assessing of the thesaurus quality is out of this research’s scope, details on thesaurus quality assessment can be found in [9,10].

Domain specific thesaurus are preferred to the common thesaurus such as WordNet in this research because of the common thesaurus are already used in this field as shown in the next paragraphs, moreover this research is studying the effect of the size of domain specific thesauri for single domain.

In information and database systems, schema is stands as the set of formulas (collection of meta-data) imposed on the data in the database. These formulas (also called integrity constraints) are applied to ensure the compatibility and describe the organization and the relations between database’s parts and entities [11].

The importance of studying the effect of thesaurus size is coming from the vital need of effective and complete automatic solutions, because of the rapid expansion of application areas in which thesaurus and other vocabulary tools can be utilized such as natural language processing and Information Retrieval. For instance, schema matching forms the first and the crucial step toward data integration, however, the multiplicity of the obtainable common and domain specific vocabulary and linguistics tools that can be used, makes it hard to prefer one tool over others since the influences of tool’s features such as size and coverage are not predetermined.

Schema matching, which is the process of identifyingthe semanticcorrespondence, orfinding the equivalentelements betweentwoormoreschemas, is still an open research area since more than two decades. This is not only because schema matching is one of the basic operations [12] in many applications such as data integration, data warehousing, and semantic query processing, but also because it is an increasingly important problem itself [13], and as well as the uncertainty in the results of schema matching techniques [14,15]. Many approaches and tools were used to solve the problem of schema matching such as Cupid [16], LSD [17], and Corpus [18]. In addition, many surveys and classifications were published [19,20]. Few features of matching process were not in the focus of proposed approaches, and aspects such as structural, element, linguistics, and data model were discussed widely. Following is a summarization of the techniques used in schema matching approaches.

Many techniques were employed to carry out matching process; Machine-learning techniques were used in [17], learner-based approaches contains learner modules and specific module to direct learners. These approaches use neural networks advantages to find out the similarity between data sources. In [21] the object-oriented characteristics were exploited to determine the mapping between data sources’ attributes. The problem of matching is not solved using this approach as well many proposed works using metadata; however, it is shifted into another problem, which is the problem of ontology mapping. Most of current schema matching tools use rules to carry out the matching, by using information such as elements names and descriptions, data types, hierarchy structure, and constraints. They are employed in determining the similarity at either element level or schema level [16,21,22].

Most effective rule-based schema matching methods usually consist of three phases; linguistic, constraint-based, and structural matching [23]. In linguistic phase, methods depend on string matching in general to find out the similarity between elements names. Current schema matchers usually use WordNet, a large lexical database of English [24] to consider the semantic relationships between elements labels [6]. However, it is common that algorithms in this category use combined methods to get high computed similarity, methods of label normalization to improve schema matching was also by [6,7]. Cupid matcher exploits linguistic matching in a comprehensively and efficiently manner to produce high similarity [16]. Incorrect results that are obtained from linguistic matching phase are usually adjusted in constraint-based matching phase. Data type constraint, data types’ compatibility measurement method are usually used as the initial solution of incorrect or ambiguous results of linguistic matching phase [25,16]. Structural matching phase is used to solve the problems of context similarity, these problems are generally appear in XML schema matching where the structure document and the constraints on nodes and edges differs from rational schemas [23] describes such problems in details.

Based on the conclusion of [8], this paper studies the effect of thesaurus size (in aspects of number of terms, number of lead-in terms, and number of cross relations) on the results of schema matching using thesaurus.

Although there are few exiting works in the thesaurus based schema matching field, the main contributions of this research encompass:
                           
                              •
                              Presenting an experimental study of the effect of thesaurus size on schema matching quality. Three agricultural thesaurus of different size are utilized and compared, and the results are evaluated through several objective functions.

A new method to compute the similarity between vectors extracted from the thesaurus is proposed.

Moreover, this paper explains in detail many of the technical aspects to be considered when using thesaurus.

The experimental results shows that the effect of thesaurus size in the quality of matching is statistically insignificant. However, an increment in the average of similarity with distinctive values are recorded.

This research is studying the effect of thesaurus size on the quality of schema matching, by utilizing three thesauri from the Agriculture domain to carry out the matching process on the element level, and the results are analyzed in many different perspectives. Therefore, some other perceptions such as thesaurus construction and evaluation, results (Precision, Recall, and F-measure) optimization, and the method complexity are not in the scope of this research.

In the rest of this paper, Section 2 explains the methodology. Section 3 presents the study setup. Section 4 shows the results as well as a discussion of these results. Finally, this work is concluded in Section 5.

This paper studied the impact of thesaurus size on the quality of schema matching. The applied methodology is based on exploiting thesaurus to carry out the matching process. Fig. 1
                      shows the methodology framework, and the next subsection explains it in details.

The method consists of three main phases as shown in Fig. 1. Numbers is circles 1, 2 and 3 represent these phases. In phase one, two schemas (Sx
                      and Sy
                     ) are part of the input of the (Apply Thesaurus) process, thesaurus is the other part of input for this process, and the output of (Apply Thesaurus) process are two sets of vectors of terms (Sx
                      mass and Sy
                      mass). These two sets of vectors will form the input of phase two, which is (Calculating Similarity Matrix) to produce the Similarity Matrix (SM) between the schemas’ elements; The third phase is (Extracting the Final Mapping) that uses SM as an input to generate the final mapping list. Algorithms and details of these phases are explained in following sub-sections.

@&#METHODOLOGY@&#

As shown in Fig. 1, thesaurus is utilized in solving the problem of schema matching at the element level based on textual analysis of elements’ descriptions (definitions) of input schemas (Schema One and Schema Two). Each input schema contains number of elements, for abbreviation and algorithms writing purposes these schemas are referred as Sx
                         where x
                        ∈{1,2}. Moreover, the number of elements in these schemas is referred as n and m. Following is a detailed description of the three phases of the method.

This phase includes many pre-processing steps such as removing stop words, removing numbers, and characters not matching with thesaurus language and content. The main process in this phase is (Applying Thesaurus). The output of this phase is two sets of vectors of terms (masses) where each vector represents one element in the schemas.


                        
                           Apply thesaurus process
                        : in this process, thesaurus is applied on elements’ textual descriptions, one by one for both schemas S
                        1 and S
                        2. Applying thesaurus means searching for every word from the text (i.e. element description) into thesaurus database and retrieving the related terms from thesaurus, to build up the mass of terms related to the word being processed; this mass is denoted by massw
                         in the Algorithm 1.
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          Algorithm 1. Applying thesaurus on element description algorithm
                                    
                                 
                                 
                                    
                                       
                                          1:
                                       
                                       
                                          Input: S1
                                          ={(e, desc)10,…, (e, desc)1n} // e: element name | desc: element description
                                    
                                    
                                       2:
                                       
                                          
                                          
                                          
                                          
                                          S2
                                          ={(e, desc)20,…,(e, desc)2m}
                                    
                                    
                                       
                                          3:
                                       
                                       
                                          For (Sj
                                             ∈{Sx, Sy}) loop // loop through the schemas
                                       
                                    
                                    
                                       
                                          4:
                                       
                                       
                                          
                                          
                                          
                                          Sjmass←{} // initialize set of schema element_masses’ set
                                    
                                    
                                       
                                          5:
                                       
                                       
                                          
                                          
                                          
                                          
                                          For (ek∈Sj) loop // loop through the elements in the schema, k= 0 .. n|m
                                       
                                    
                                    
                                       
                                          6:
                                       
                                       
                                          
                                          
                                          element_massk←{} // initialize element_mass (vector)
                                    
                                    
                                       
                                          7:
                                       
                                       
                                          
                                          
                                          
                                          
                                          
                                          For (word ∈ element sjk description) loop// loop through the words in the description
                                       
                                    
                                    
                                       
                                          8:
                                       
                                       
                                          
                                          
                                          
                                          
                                          
                                          
                                          If (word found in thesaurus Index)
                                       
                                    
                                    
                                       9:
                                       
                                          
                                          
                                          
                                          
                                          
                                          
                                          
                                          massw
                                          ← 
                                             get_related_terms
                                          (w) // retrieve all terms from thesaurus database related to term (w)
                                    
                                    
                                       10:
                                       element_massk ← ∪ massw
                                          
                                       
                                    
                                    
                                       11:
                                       
                                          
                                          
                                          
                                          
                                          
                                          
                                          End If //
                                       
                                    
                                    
                                       12:
                                       
                                          
                                          
                                          
                                          
                                          End loop// through the words in the description
                                       
                                    
                                    
                                       
                                          13:
                                       
                                       
                                          
                                          
                                          End loop // through the elements in the schema
                                       
                                    
                                    
                                       
                                          14:
                                       
                                       
                                          Sjmassk←(ek, element_massk)
                                    
                                    
                                       
                                          15:
                                       
                                       
                                          End loop // through the schemas
                                       
                                    
                                    
                                       
                                          16:
                                       
                                       
                                          Output: S1 mass ={(e, element _mass)10,…,(e, element _mass)1n}
                                    
                                    
                                       17:
                                       S2mass ={(e, element _mass)20,…,(e, element _mass)2m}
                                    
                                 
                              
                           
                        
                     

Different masses massw
                        (s) are then accumulated on the element level into one mass (element_mass) that represents the Result of Applying Thesaurus (RAT) on the element ei
                         of the schema (RATeiSx
                        ) as shows in Algorithm 1. This phase contains extensive searching processes because the process of Applying Thesaurus is done for every term in every description in both schemas, term may be one word or multiple word that is known also as Compound Term. The searching algorithm applied in this phase is explained in Section 2.5, and the function (get_related_terms(w)) which used to retrieve all terms related to term (w) from the database is explained in Section 2.6.

In this phase, the two vectors resulted from previous phase are used as the input of (Calculating Similarity Matrix) process. Similarity between Result of Applying Thesaurus (RAT) of each element from S
                        1 with all RATs of elements of S
                        2 were calculated to generate the similarity matrix; Algorithm used in calculating similarity matrix is shown in Algorithm 2.
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          Algorithm 2. Calculating similarity matrix algorithm
                                    
                                 
                                 
                                    
                                       
                                          1:
                                       
                                       
                                          Input:
                                          S1mass ={(e, RATe1S1)0,…,(e, RATenS1) n}
                                    
                                    
                                       2:
                                       
                                          S2mass ={(e, RATe1S2)0,…,(e, RATemS2)m}
                                    
                                    
                                       3:
                                       SimMatrix←Matrix[n][m]
                                    
                                    
                                       4:
                                       Initialize SimMatrix; // set all cells to 0
                                    
                                    
                                       
                                          5:
                                       
                                       
                                          for (ei ∈ Sxmass)// i = 0 .. n
                                    
                                    
                                       6:
                                       
                                          
                                          for (ej ∈ Smassy) // j = 0 .. m
                                    
                                    
                                       7:
                                       
                                          
                                          SimMatrixij ← 
                                             Similarity
                                          (RATeiSx, RATejSy)
                                    
                                    
                                       
                                          8:
                                       
                                       
                                          Output: SimilarityMatrix[n][m]
                                    
                                 
                              
                           
                        
                     

The 
                           Similarity
                         between two elements is defined based on the following equation:
                           
                              (1)
                              
                                 Similarity
                                 
                                 (
                                 
                                    
                                       e
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       S
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       e
                                    
                                    
                                       j
                                    
                                 
                                 
                                    
                                       S
                                    
                                    
                                       y
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                RAT
                                                (
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      i
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      x
                                                   
                                                
                                                )
                                                ∩
                                                RAT
                                                (
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      j
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      y
                                                   
                                                
                                                )
                                             
                                             
                                                RAT
                                                (
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      i
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      x
                                                   
                                                
                                                )
                                                ∪
                                                RAT
                                                (
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      j
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      y
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where RAT is Result of Applying Thesaurus on element. The similarity in Eq. (1) considers the vectors as sets of elements where duplicate elements is not allowed. Since the vectors represents all terms from thesaurus related to the element (ei
                        |ej
                        ) of schema (Sx
                        |Sy
                        ), then the frequency of terms is not considered since one term from thesaurus may appears in the results vector because it is related with many others terms with different relationships. Moreover, the interest of the similarity measure in Eq. (1) is the differences between the two masses of terms extracted from the thesaurus for certain text. Unlike some other similarity measurements such as cosine similarity where the frequency of terms is considered or the frequency of errors (mismatched elements) such as in hamming distance measurement, in our proposed similarity equation the existence or absence of the terms in the mass is the main concern of this measure because of the above mentioned reason.


                        Fig. 2
                         shows an example of calculating similarity between two elements.

Similarity is calculated between all possible elements pair’s combinations, and stored in the Similarity Matrix.

For evaluation purposes, the 
                           Similarity
                         between two element’s descriptions is also calculated using the common cosine similarity equation [26]. The cosine similarity between two vectors (eiSx
                        , ejSy
                        ) is defined as follows:
                           
                              (2)
                              
                                 cosine similarity
                                 
                                 (
                                 
                                    
                                       e
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       S
                                    
                                    
                                       x
                                    
                                 
                                 ,
                                 
                                    
                                       e
                                    
                                    
                                       j
                                    
                                 
                                 
                                    
                                       S
                                    
                                    
                                       y
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             e
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             S
                                          
                                          
                                             x
                                          
                                       
                                       ·
                                       
                                          
                                             e
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             S
                                          
                                          
                                             y
                                          
                                       
                                    
                                    
                                       ‖
                                       
                                          
                                             e
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             S
                                          
                                          
                                             x
                                          
                                       
                                       ‖
                                       ‖
                                       
                                          
                                             e
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             S
                                          
                                          
                                             y
                                          
                                       
                                       ‖
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      w
                                                      =
                                                      1
                                                   
                                                   
                                                      n
                                                   
                                                
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      wi
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      x
                                                   
                                                
                                                ×
                                                
                                                   
                                                      e
                                                   
                                                   
                                                      wj
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      y
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            w
                                                            =
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            e
                                                         
                                                         
                                                            wi
                                                         
                                                      
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            x
                                                         
                                                      
                                                   
                                                
                                                ×
                                                
                                                   
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            w
                                                            =
                                                            1
                                                         
                                                         
                                                            n
                                                         
                                                      
                                                      
                                                         
                                                            e
                                                         
                                                         
                                                            wj
                                                         
                                                      
                                                      
                                                         
                                                            S
                                                         
                                                         
                                                            y
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where eiSx
                        , ejSy
                         are the vectors resulting from Applying Thesaurus on element i of schema Sx
                        , and element j of schema Sy
                         respectively, and w is word in vector e.
                     

The values in similarity matrix were normalized based on the following linear transformation formula:
                           
                              
                                 
                                    
                                       X
                                    
                                    
                                       n
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             0
                                          
                                       
                                       -
                                       
                                          
                                             X
                                          
                                          
                                             min
                                          
                                       
                                    
                                    
                                       
                                          
                                             X
                                          
                                          
                                             max
                                          
                                       
                                       -
                                       
                                          
                                             X
                                          
                                          
                                             min
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where Xn
                        
                        =new X value (after normalization), X
                        0
                        =current value of X (before normalization), X
                        min
                        =minimum value of X in the similarity matrix, and X
                        max
                        =maximum value of X in the similarity matrix.

In this phase, the Similarity Matrix (SM) generated from phase two was used as an input for (Extract Final Mapping) process that generates the final mapping set. The maximum and second maximum value approach [27] was applied in extracting the final mapping as shown in Algorithm 3.
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          Algorithm 3. Calculating similarity matrix
                                    
                                 
                                 
                                    
                                       
                                          1:
                                       
                                       
                                          Input:
                                    
                                    
                                       2:
                                       
                                          S = SimilarityMatrix[n][m]
                                    
                                    
                                       
                                          3:
                                       
                                       
                                          Variables:
                                    
                                    
                                       4:
                                       
                                          cellIndex=[row,col]
                                    
                                    
                                       5:
                                       
                                          finalMapping={}// set of cell Indexes
                                    
                                    
                                       
                                          6:
                                       
                                       
                                          While S contains value > 0
                                       
                                    
                                    
                                       
                                          7:
                                       
                                       
                                          
                                          max ← getMaxValue(S) //get the maximum value in the matrix
                                    
                                    
                                       
                                          8:
                                       
                                       
                                          
                                          cellIndex(row,col) ← getRowCol(max) // get the x,y index of max value in the matrix
                                    
                                    
                                       
                                          9:
                                       
                                       
                                          
                                          If (max is unique) // check for uniqueness of the Max value
                                    
                                    
                                       
                                          10:
                                       
                                       
                                          
                                          
                                          FinalMapping ← U cellIndex(row,col) // append cell index to the final Mapping list
                                    
                                    
                                       
                                          11:
                                       
                                       
                                          
                                          
                                          S[row] ← 0 // set similarity value to zeros in the row
                                    
                                    
                                       
                                          12:
                                       
                                       
                                          
                                          
                                          S[col] ← 0 // set similarity value to zeros in the column
                                    
                                    
                                       
                                          13:
                                       
                                       
                                          
                                          
                                          S[row,col] ← −1 ∗ max // set max value to negative in the similarity matrix
                                    
                                    
                                       
                                          14:
                                       
                                       
                                          
                                          Else
                                       
                                    
                                    
                                       
                                          15:
                                       
                                       
                                          
                                          
                                          ∀ (S[row,col] = max): S[row,max]←0 // set all cells equals to max to zero
                                    
                                    
                                       
                                          16:
                                       
                                       
                                          
                                          End If
                                       
                                    
                                    
                                       
                                          17:
                                       
                                       
                                          Loop // while
                                       
                                    
                                    
                                       
                                          18:
                                       
                                       
                                          Output:
                                    
                                    
                                       19:
                                       
                                          finalMapping
                                    
                                 
                              
                           
                        
                     

In this algorithm, a matching (mapping) between two elements (one in the header of the row and other in the header of the column) is considered if the similarity value in the cross cell is the maximum value in the matrix. Then all values in the row and the column were set to zero. This process will be repeated until all similarity values in the matrix become zeroes or less than the threshold value. The problem of this criterion will come up when the maximum value is not unique in the similarity matrix and more than one of maximum value occurrences found in the same row or the same column, this case requires us to check the second maximum value of the matrix where the second maximum value is considered as the mapping.

Searching thesaurus database is one of the main processes performed in all applications that use thesauri either in the core or as an auxiliary tool. In this research thesaurus is used as the core of the matching process. Thesaurus was applied on all elements’ textual descriptions. The procedure 
                           get_related_terms
                         (mentioned in Algorithm 1) contains extensive searching processes in thesaurus database, because the need to search for every term from text into the thesaurus database. The term may be one word or multiple words (also called compound term), although the thesaurus contains one word terms and compound terms too. The direct approach to deal with such case is the brute force method in which the text is traversed by considering the term as one word in first round, and then the traversing is repeated by considering the term as double word, and so on. Traversing of the text will stop when the number of words in the term from the text exceeds the number of the words in the longest term in the thesaurus database. This brute force algorithm is the less efficient search algorithm [28]. An efficient searching algorithm [29] is applied to carry out this process. Algorithm 4 shows the applied algorithm used to reduce time required for searching text into thesaurus database. This algorithm is discussed in details [29].
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          Algorithm 4. Searching text into thesaurus database
                                    
                                 
                                 
                                    
                                       
                                          1:
                                       
                                       
                                          for (w ∈ text)
                                    
                                    
                                       2:
                                       
                                          
                                          if (w found in Index)
                                    
                                    
                                       3:
                                       
                                          
                                          termsLengths ← getTermsLengthsThatStartsWith(w)
                                    
                                    
                                       4:
                                       
                                          
                                          
                                          for (l ∈ termsLengths)
                                    
                                    
                                       5:
                                       
                                          
                                          
                                          compoundTerm = buildCompoundTermfromtextoflength(l)
                                    
                                    
                                       6:
                                       
                                          
                                          
                                          
                                          if (compoundTerm found in DB)
                                    
                                    
                                       7:
                                       
                                          
                                          
                                          
                                          addRelatedTermsToResultSet
                                    
                                    
                                       8:
                                       
                                          
                                          
                                          
                                          endif compoundTerm found in DB
                                    
                                    
                                       9:
                                       
                                          
                                          
                                          end for length
                                    
                                    
                                       10:
                                       
                                          
                                          end if w found in Index
                                    
                                    
                                       11:
                                       
                                          end for w
                                    
                                 
                              
                           
                        
                     

The main idea of Algorithm 4 is to search for the word (w) into the index vector of the thesaurus instead of search for the word (w) into the terms’ table of the thesaurus that surely contains many compound terms. Index vector of the thesaurus is a vector that contains the distinctive first token of terms or compound terms of the thesaurus. Two benefits are gained from this step: First, once (w) is found in the index, then for sure there is one or more raw (one word term or compound term) in thesaurus starts with that word. Otherwise, there is no need to look into thesaurus for any compound term that starts with the word (w); because for sure there is no compound term starts with that specific word. Second, as a result of finding (w) in the index, the set of lengths of the compound terms in thesaurus that starts with (w) – step number three in algorithm 3 – can be defined, so that the list of compound terms of the required lengths from the text starting from the word under consideration could be built up.

Finally, once the term is found in the thesaurus database, as mentioned in Algorithm 1, the function 
                           get_related_terms
                        (w) is called to retrieve the term mass from the thesaurus database by executing many hierarchical dynamic queries such the queries below. The term mass of a term is defined as all the terms in the database connected to the term with any of the thesaurus relations, which are Boarder terms, Narrow Terms, Related Terms, and the Preferred Terms.
                           
                              
                                 
                                 
                                 
                                    
                                       
                                          
                                             SELECT
                                           
                                          a.r_term_code, b.term, b.term_tokens_count, b.is_nonprefered_term
                                       
                                    
                                    
                                       
                                          
                                             FROM
                                           
                                          use_terms_relations a, terms b
                                       
                                    
                                    
                                       
                                          
                                             WHERE
                                           
                                          a.r_term_code = b.term_code and a.term_code = ?;
                                       
                                       … Query (1)
                                    
                                    
                                       
                                          
                                       
                                    
                                    
                                       
                                          
                                             SELECT
                                           
                                          a.term_code,x.term, a.r_term_code RT_Term_Code, y.term RT_Term
                                       
                                    
                                    
                                       
                                          
                                             FROM
                                           
                                          rt_terms_relations a, terms x, terms y
                                       
                                    
                                    
                                       
                                          
                                             WHERE
                                           
                                          a.term_code = x.term_code and a.r_term_code = y.term_code and a.term_code = ?”.
                                       
                                       … Query (2)
                                    
                                    
                                       
                                          
                                       
                                    
                                    
                                       
                                          
                                             SELECT
                                           
                                          a.term_code,x.term, a.r_term_code BT_Term_Code, y.term BT_Term, level
                                       
                                    
                                    
                                       
                                          
                                             FROM
                                           
                                          bt_terms_relations a, terms x, terms y
                                       
                                    
                                    
                                       
                                          
                                             WHERE
                                           
                                          a.term_code = x.term_code and a.r_term_code = y.term_code
                                       
                                    
                                    
                                       
                                          
                                             START WITH
                                           
                                          a.term_code = ?
                                       
                                    
                                    
                                       
                                          
                                             CONNECT BY PRIOR
                                           
                                          a.r_term_code = a.term_code”;
                                       
                                       … Query (3).
                                    
                                    
                                       
                                          
                                       
                                    
                                    
                                       
                                          
                                             SELECT
                                           
                                          a.term_code,x.term, a.r_term_code NT_Term_Code, y.term NT_Term, level
                                       
                                    
                                    
                                       
                                          
                                             FROM
                                           
                                          nt_terms_relations a, terms x, terms y
                                       
                                    
                                    
                                       
                                          
                                             WHERE
                                           
                                          a.term_code = x.term_code and a.r_term_code = y.term_code
                                       
                                    
                                    
                                       
                                          
                                             START WITH
                                           
                                          a.term_code = ?
                                       
                                    
                                    
                                       
                                          
                                             CONNECT BY PRIOR
                                           
                                          a.r_term_code = a.term_code”;
                                       
                                       … Query (4).
                                    
                                 
                              
                           
                        
                     

The queries (1) and (2) are used to retrieve the PREFERED and related terms respectively by using the ordinary SELECT statement structure, however the queries (3) and (4) are hierarchal
                           1
                           
                              http://docs.oracle.com/cd/B19306_01/server.102/b14200/queries003.htm
                           
                        
                        
                           1
                         (recursive) queries that retrieve the terms connected by the Boarder and Narrow relation.

The quality measures precision, recall, and F-measure as defined in [30] are used to evaluate the quality of schema matching with different thesauri. Precision, recall, and F-measure are used in IR domain, however it is commonly used to schema matching evaluation [6]. In addition, in the case of common matches between manual and automatic, the quality of overall similarity is compared based on two approaches; first, the comparison based on Maximum value, and second is the comparison based on the Average value to show the enhancement in the overall similarity of common matches among thesauri used.

To calculate precision, recall, and F-measure the manual matches generated be the domain expert as in [31] were considered, then for each experiment the set of true positives (TP), false positives (FP), and false negatives (FN) were determined. Based on these sets the quality measures were calculated as follows:
                           
                              
                                 Precision
                                 =
                                 
                                    
                                       |
                                       TP
                                       |
                                    
                                    
                                       |
                                       TP
                                       |
                                       +
                                       |
                                       FP
                                       |
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              
                                 Recall
                                 =
                                 
                                    
                                       |
                                       TP
                                       |
                                    
                                    
                                       |
                                       FN
                                       |
                                       +
                                       |
                                       TP
                                       |
                                    
                                 
                                 ,
                                 
                                 and
                              
                           
                        and
                           
                              
                                 F-measure
                                 =
                                 2
                                 *
                                 
                                    
                                       Precision
                                       *
                                       Recall
                                    
                                    
                                       Precision
                                       +
                                       Recall
                                    
                                 
                                 .
                              
                           
                        
                     

Many of previous studies on schema matching such as [16,32,33] use schemas from the domain of E-commerce. However there were many obstacles to use these schemas in this research; for example, these schemas do not include a textual description of its elements, and there are no thesauri available for E-commerce domain. So, data from agricultural domain were utilized as the dataset.

Agricultural knowledge domain has tremendously progressed for the past several decades.
                           2
                           
                              http://www.kfh.ch
                           
                        
                        
                           2
                         Less information on the exact size of this knowledge domain is found. However, the agricultural information are represented in many machine-readable formats by different global organizations. The National Agricultural Library Thesaurus
                           3
                           
                              http://agclass.nal.usda.gov/
                           
                        
                        
                           3
                         (NALT) is a thesaurus developed by the National Agricultural Library (NAL) of the United States Department of Agriculture. When it released for the first time it contains 42,326 descriptors and 25,985 non-descriptors organized into 17 subject categories. Currently it contains more than 98,000 term and available in two languages (English and Spanish). AGROVOC is a multilingual thesaurus designed in early 1980s by Food and Agriculture Organization of the United Nations (AGROVOC Thesaurus
                           4
                           
                              http://aims.fao.org/standards/agrovoc/about
                           
                        
                        
                           4
                        ) to cover the terminology of all subject fields in agriculture, forestry, fisheries, food and related domains. The latest edition of AGROVOC contains over 32,000 concepts. The Chinese Agricultural Thesaurus
                           5
                           
                              http://cat.aii.caas.cn/
                           
                        
                        
                           5
                         (CAT) is the largest agricultural thesaurus in China that maintained by AII of CAAS. It contains more than 63,000 concepts most of them have English translation.

The dataset used in these experiments consists of two schemas. Each schema represents a set of 23 courses offered by a university. The courses data is represented as XML schema files (.xsd). Fig. 3
                         shows a part of the schema file.

In the schema file, each (<xsd:element) node represents one element with the name mentioned in the (name) property, and the node (<xsd:documentation>) contains the textual description of the element. The two sets of courses were tested to find the equivalent courses between them. For experimental uses, sets were named as follows:
                           
                              Set one: Sx
                                 
                                 =(ex0
                                 , ex1
                                 , ex2
                                 ,...,
                                 ex22
                                 ), and

Set two: Sy
                                 
                                 =(ey0
                                 , ey1
                                 , ey2
                                 ,...,
                                 ey22
                                 ),

Courses’ descriptions in both sets were processed and analyzed using different thesauri in the same domain, subsequent section explains more about the used thesauri.

Three agricultural thesauri were used. Two of them are different versions of the same thesaurus. These thesauri are The National Agricultural Library Thesaurus 2008 Edition (referred as NAL2008), The National Agricultural Library Thesaurus 2012 Edition (referred as NAL2012), and the thesaurus presented by Food and Agriculture Organization of the United Nations (referred as AGROVOC). All thesauri were downloaded from the Internet, and processed by special tools to meet experiment’s environment.

NAL thesaurus as well as AGROVOC thesaurus are downloadable from their official websites in many different formats such as XML, RDF-SKOS, PDF, MARC, plain text for NAL Thesaurus and XML, SKOS, MYSQL, Protege DB, OWL and ISO2709 for AGROVOC thesaurus. The pre-processing of the thesauri depends on the used format accordingly, In This research the XML-SKOS format is used, a sample of thesaurus concept “Chamidae” is shown in Fig. 4
                            as it appear in the downloaded thesaurus of format XML-SKOS.

The thesaurus is transformed into rational database based on the British standards 8723 data model [34] and the extension of the model in [29]. Fig. 5
                            shows a part of the class diagram of thesaurus data model as in [34]:

The general steps of pre-processing are summarized in the following steps:
                              
                                 
                                    Step 1: Extract and save terms identifiers.


                                    Step 2: Extract and Save terms relations.


                                    Step 3: Interconnect terms with extracted relations.


                                    Step 4: Create terms index (for applying the efficient search method as in [29]).


                           Table 1
                            shows the main specifications of the thesauri used in the experiments of this research.

From Table 1, it seen that NAL2012 contains the largest number of terms, lead-in terms, and cross-relations, while AGROVOC has the least number of all specifications.

Other thesaurus specifications, such as the “Number of Words in Term” should also be considered in thesaurus performance measurement; this property influences the speed of calculating similarity. Fig. 6
                            shows the percentage of terms that contains one, two, three, and four or more words of terms in each thesaurus used in the experiments.

It can be seen from Fig. 6 that for all thesauri used, one word terms are less than 35% while the remaining terms are compound terms (i.e. terms consists of two or more words). As mentioned before the number of words in the term influences the speed of similarity calculating which means that an efficient algorithm is needed to carry out this job.

Whereas different versions of the NAL thesaurus and the AGROVOC thesaurus are used in this study, these thesauri overlap with each other. Fig. 7
                            shows the number of overlapped terms and the ratios relative to the total number of distinctive terms in all thesauri.

The total number of distinctive terms in all thesauri is 117,304 terms. As shown in Fig. 7, the largest ratio of overlapping occurs between NAL2008 and NAL2012, which are different versions of the same thesaurus. However, the conjoint terms between all thesauri is near to 10% of the total number of terms. This study consider less attention to the influence of overlapping.

To carry out the experiments, Oracle database with Java application developed especially for that purpose were installed. Fig. 8
                         shows the interface of the Java application.

The application has the facility to validate the loaded schemas, and to extract elements’ names and their textual descriptions in a tree format before starting the matching process. The similarity matrix and the final mapping can be also saved to the file system.

@&#RESULTS@&#

The two sets of courses used in the experiments were manually matched by an expert [31], results of manual and Automatic Matching of the experiments are shown in Table 2
                     .

In Table 2 the similarity values in are based on Eq. (1) discussed in Section 2.3. The sub-table (a) represents the manual matches by domain Expert, and sub-table (b) represents the automatic matches based on NAL2008 thesaurus, while sub-tables (c) and (d) represent the automatic matches based on NAL2012 and AGROVOC thesaurus respectively. The matching results can be visualized as in Fig. 9
                     .

In Fig. 9, the numbers on x-axis and y-axis represent the number of elements in schemas, while the bubbles represent the matches between elements, for example, there is a matching between element 5 from schema 1 and element 16 from schema 2 in manual matching. This matching is referred as pair (5,16) where the Pair stands for the two matched elements, and the numbers between brackets represents the number of elements in schema 1 and schema 2 respectively; the size of the bubble represents the value of similarity between the two elements. For matches that are common among manual matching and automatic ones, the bubbles appears to be over-lapping as for pairs (6,15) and (1,0) and others. The contingency table of the automatic results in relative to the manual matches are shown in Table 3
                     .


                     Table 3 shows the number of matches’ pairs distribution generated by each thesaurus relative to the manual matching. For example, in the experiment based on NAL2008, four pairs of matching elements are matched correctly by the automatic matcher, while 16 pairs are matched automatically incorrectly, and 6 pairs are incorrectly not matched. However, the number of pair in the cell of intersection of row total and column total represents the possible number of permutation of matches between schemas elements.

This subsection discusses the results from many point views.

Precision, recall, and F measure for each experiment were calculated relative to manual matches, using the contingency table (Table 3) where the TP, FP, and FN sets are as follows:
                              
                                 
                                    TP: the set of pairs matched manually and automatically.


                                    FP: the set of pairs matched manually but not automatically.


                                    FN: the set of pairs matched automatically but not manually.


                           Table 4
                            summarizes the results of Precision, recall, and F-measure for the experiments:

Two main remarks can be noticed from Table 4. One is the low precision, recall, and F-measure values. The proposed technique depends on searching for the words from elements’ descriptions in the thesaurus. In the experiments the exact words are searched and no text pre-processing were applied, so the abbreviations, misspelled words, numbers written as words, inappropriate punctuations contained by the text will not contribute to the outcome of searching. For example, line 4 in Fig. 3 contains the expression (horticulture.Emphasis) which is considered as one word (because of no space between words), however, it will be recognized as two search terms if punctuations replacement is applied. To overcome this issue, some techniques can be applied such as text pre-processing, dictionary validation, punctuations replacement, and text expansion based on vocabulary tools.

Second, it can be seen that the use of rich thesaurus (in features), which is NAL2012, does not lead to higher precision and recall results. However, the use of AGROVOC thesaurus that has fewer terms, lead-in terms, and cross-relations cause a law precision and recall values. Fig. 10
                            shows the precision, recall, and F measure and the number of terms in each thesaurus.

As seen from Fig. 10, the precision was the least in case of using AGROVOC thesaurus; AGROVOC has the least number of terms among thesauri used. However, in case of using NAL2008 the precision is the highest while the number of terms in NAL2008 is not the largest. In contrast, when using NAL2012, which has most number of terms, the precision was not the highest. Recall and F measure behave as the same as precision, which mean that the highest values of recall and F measure was recorded with NAL2008 and lowest values were recorded with AGROVOC thesaurus.

This sub-section discusses the results of common matches between different thesauri, as follows:


                              Table 5
                               shows the common matches between results of using NAL2008 Thesaurus and NAL2012 Thesaurus:

From Table 5, it is seen that the Similarity of matches when using NAL2012 Thesaurus was increased or stay constant in 70% of common matches. Common matches between NAL2008 and NAL2012 are more than 40% relative to the number of elements in Sx
                              . Fig. 11
                               shows the results of using NAL2008 and NAL2012, while Fig. 12
                               shows the average of absolute differences between similarity values.

It can be seen from Fig. 11 that the similarity when using NAL2012 was equal to or more than the similarity when using NAL2008 in 70% of common matches.

As seen from Fig. 11, Similarity is not increased for all common matches when using the thesaurus with more terms, lead-in terms, and cross relations. As mentioned in Section 2.6, two approaches are used to determine the value of overall similarity for each common group; these approaches are the Average similarity and the Maximum similarity value. It can be seen from Table 5 that the Maximum approach leads to an enhancement in the average of the similarity by 0.059 and 0.028 for experiment using NAL2008 and NAL2012 consecutively. Fig. 13
                               shows Average approach versus Maximum approach values, while Fig. 14
                               shows enhancement of Maximum approach over the Average approach.


                              Table 6
                               shows the common matches between results of using NAL2008 thesaurus and AGROVOC thesaurus.

From Table 6 it can be seen that the similarity of matches when using AGROVOC thesaurus, which is the least in terms, lead-in terms, and cross-relations was increased or stay constant in 50% of common matches. Shared matches are about 1% relative to the number of elements in Set 1. Fig. 15
                               shows the results of using NAL2008 and AGROVOC, while Fig. 16
                               shows the average of absolute differences between similarity values.


                              Table 6 shows that the similarity is not decreased for all common matches when using the thesaurus with fewer terms, lead-in terms, and cross relations. Using Max approach enhances the average of the similarity by 0.112 and 0.103 for experiment using NAL2008 and AGROVOC consecutively as shown in Table 6. Fig. 17
                               shows Average approach versus Max approach values, while Fig. 18
                               shows enhancement of Max approach over Average approach.


                              Table 7
                               shows the common matches between results of using NAL2012 thesaurus and AGROVOC thesaurus.


                              Table 7 shows that the similarity of matches when using NAL2012 Thesaurus which has more terms, lead-in terms, and cross-relations than AGROVOC, was increased or stay constant in 50% of common matches, common matches are about 1% relative to the number of elements in Set 1. Fig. 19
                               shows the results of using NAL2012 and AGROVOC, while Fig. 20
                               shows the average of absolute differences between similarity values:

It seen from Table 7 that the similarity is not decreased for all common matches when using thesaurus with less terms, lead-in terms, and cross relations (AGROVOC). Using Max approach enhances the average of similarity by 0.004 and 0.108 for experiment using NAL2012 and AGROVOC consecutively as shown in Table 7. Fig. 21
                               shows Average approach versus Max approach values, while Fig. 22
                               shows enhancement of Max approach over Average approach.

To evaluate the hypothesis that there is a significant difference between similarities of common matches when using different thesauri, the pair-wise two-sided T-Test using common matches among the experiments was performed. Table 8
                            shows the results of T-Test.

It can be seen from the results of T-Test that the difference in the similarity of common matches is statistically insignificant for each combination of used thesauri. These insignificant results are due to the small sample size, the limitation of sample size comes from the domain of the experiment. For the pair-wise combinations (NAL2008-AGROVOC and NAL2012-AGROVOC) the statistical T-Test is non-applicable because of the too small sample size (2 samples), however it can be seen form Tables 6 and 7 that the similarity average of the common matches between NAL2008 and AGROVOC is too much higher than those between NAL2012 and AGROVOC, as summarized in Table 9
                           .

This section presents the comparison between the similarity calculated based on the proposed similarity calculation method (i.e. Eq. (1) which was explained in Section 2.3) and the common cosine similarity measurement. Hence the differences in similarities calculated by every method direct to different final mapping results, because the application of the maximum and second maximum value approach [27]. In the following sub-sections, the similarity of common matches and the overall similarity average are compared and discussed.

To compare the similarity calculated using the proposed method and the cosine similarity, the common matches for each thesaurus were extracted. Fig. 23
                            shows the comparison.

From Fig. 23, it is seen that the cosine similarity value was higher for all common matches for all thesauri. The reason of this is that the cosine similarity consider the number occurrences of a word (term) in the vector, while the proposed method based on the union operation which eliminate the effect of the repeated words (terms) in the vector and consider each word once. Using cosine similarity in schema matching using thesaurus is leads to higher similarity ratios, however the in automatic schema matching the higher similarity between two elements may cause an incorrect matching since the highly similar elements will be paired as matching pair, and these elements will not be paired to any other elements. The proposed similarity measurement method as mentioned in Section 2.3 do not consider the occurrences of the term but just the existence.

The similarity average of final mappings for each thesaurus was compared; Fig. 24
                            shows that the average of cosine similarities was higher than the average of similarities calculated by the proposed method.

From Fig. 24, it can be seen that the similarity based on cosine method was higher than the similarity based on the equation discussed in Section 2.3. In cosine similarity, the number of occurrences of the term in the vector increases the similarity; however, the proposed method eliminates the effect of multiple occurrences of the term in the vectors, so that the calculated similarity was lower.

@&#CONCLUSION@&#

In this research, thesaurus was utilized to be the core of schema matching process; many experiments were conducted to study the effect of thesaurus size on schema matching quality. Results showed that different mappings were produced because of using different thesauri in the same domain. The common matches between those mappings also have different similarity values. An increment in the average of similarity with distinctive values was recorded. The use of the richest thesaurus (i.e. thesaurus with most number of terms, lead-in terms, and cross relations) does not result the highest precision, recall, and F measure values, whereas the lowest values of precision and recall were recorded when the thesaurus with the least number of terms, lead-in terms, and cross relations was used. The results of schema matching using thesaurus affected with thesaurus size (in aspects of the number of terms and number of cross relations), however the change was statically insignificant. Cosine similarity was also higher than the similarity calculated based on the proposed equation. Predicting the exact value of the change in outcome of schema matching using thesaurus or other thesaurus based applications when using different thesauri to solve the same problem, needs to be deeply studied. However, other factors related to the domain where thesauri are used also affect the results. Currently, we are studying how thesaurus specifications affect the outcome of other IR applications such as document classifiers. The main goal is to generate a mathematical model to predict the quality of the output of IR tools and applications that uses thesaurus as the core of its job, this prediction will depend on thesaurus specifications and domain specifications as parameters.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank our colleagues especially Mr. M. Sirajo, and the people of Software Engineering Research Group (SERG), Universiti Teknologi Malaysia who provided insight and expertise that greatly assisted the research. We also thank Ministry of Science, Technology and Innovation, Malaysia (MOSTI) for the research funding 4S062.

@&#REFERENCES@&#


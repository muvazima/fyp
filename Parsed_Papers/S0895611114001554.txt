@&#MAIN-TITLE@&#Interactive 3D medical data cutting using closed curve with arbitrary shape

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We mix octree and quad-tree to make cutting operation in real-time.


                        
                        
                           
                           2D mask image and coordinate transformation make users cut 3D volume data in 2D space.


                        
                        
                           
                           The cutting method could improve the accuracy of image segmentation algorithms.


                        
                        
                           
                           The cardiac images segmented results can be used to evaluate cardiac function quantitatively and be more conducive for diagnosis and treatment of cardiac disease.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Interactive 3D cutting

Binary mask image

Coordinate transformation

Octree decomposition

Image segmentation

@&#ABSTRACT@&#


               
               
                  Interactive 3D cutting is widely used as a flexible manual segmentation tool to extract medical data on regions of interest. A novel method for clipping 3D medical data is proposed to reveal the interior of volumetric data. The 3D cutting method retains or clips away selected voxels projected inside an arbitrary-shaped closed curve which is clipping geometry constructed by interactive tool to make cutting operation more flexible. Transformation between the world and screen coordinate frames is studied to project voxels of medical data onto the screen frame and avoid computing intersection of clipping geometry and volumetric data in 3D space. For facilitating the decision on whether the voxels should be retained, voxels through coordinate transformation are all projected onto a binary mask image on screen frame which the closed curve is also projected onto to conveniently obtain the voxels of intersection. The paper pays special attention to optimization algorithm of cutting process. The optimization algorithm that mixes octree with quad-tree decomposition is introduced to reduce computation complexity, save computation time, and match real time. The paper presents results obtained from raw and segmented medical volume datasets and the process time of cutting operation.
               
            

@&#INTRODUCTION@&#

Volume clipping is typically used in visualizing medical data, preparing surgical plans and processing images, because it conveniently clips away selected parts of volume data. Volume clipping is also a useful approach in exploring the interior details of volume data [1]. Accurate volume data clipping can meet users’ requirements to design more complicated volume model by cutting and pasting existing volume data [2]. Combined with image segmentation algorithms, clipping operation can be used as a pre-processing step to extract region of interest (ROI) in volume images, such as tumor organizations or important brain functional areas. Just because volume cutting plays an so important role to remove and carve the occluding materials and extract different regions of interest [4,9], we explore a 3D cutting tool in depth which can arbitrarily select volume data and cut them away in real-time. Moreover, the cutting algorithm introduced in the paper has been experimented to reveal hidden parts of brain volume data for surgical planning and extract cardiac chambers from heart volume images effectively.

Most volume clipping methods use common clipping geometry that can be structured by implicit functions to clip medical images. Many researchers had used a set of volumetric data clipping methods, including plane, bounding box, ball, and contour surface cutting [3]. Several methods based on volumetric textures and depth fields constructed various geometric primitives to cut unwanted volumetric data away [4]. However, depth-based clipping methods hardly handled concave geometry clipping. To solve the problem, Xie et al. [5] proposed a clipping method that uses the clipping distance field to represent clipping geometry and implement a clipping algorithm on the fragment shader. McGuffin et al. [6] presented a method for browsing the interior of volumetric data with interactive manipulation widgets. Some researchers also presented multifunctional tools to segment volume data flexibly. Huff et al. [7] exploited programmable hardware and proposed three tools (eraser, digger, and clipper) to uncover hidden structures in volume images. Correa et al. [8] proposed a collection of operators (peeler, retractors, pliers, and dilators) that can be placed anywhere on or within volume data. Chen et al. [9] utilized point radiation techniques and interactive parallel region growing algorithm to extract different regions of interest. There were also some researchers combine sketch-lines with subdivision surface to create novel envelops to cut unwanted region away [10]. Users needed to define the depth of penetration into the volume image before the cutting technique was implemented. The painting metaphor defined a selection tool that is similar to “brush strokes” to select voxels [11]. In some of the commercial medical image processing software, for example, zioTerm, similar cutting approaches based on closed curve were adopted to clip away or retain selected data. Industrial design software, such as AutoCAD, used mesh, curved surface or other 3D model to cut objects through intersecting them. Many approaches had been proposed to simulate the cutting process of deformable objects and mesh data. Zhang et al. [12] proposed a hybrid cutting method combining non-progressive cutting with progressive cutting for the real-time simulation of soft-tissue cutting. The method that dynamically modifying the mesh topology of deformable objects achieved better simulation effects [13]. Lenka et al. [14] used two synchronized geometrical models at different resolutions to simulate the interactive cutting of viscoelastic objects.

In this paper, a flexible and timesaving method adopting free closed curve is proposed to address two main issues in clipping 3D medical images, namely, (1) finding the correspondence between clipping geometries and volume data in 2D space, and (2) reducing computation complexity and saving computation time.

The proposed method differs from those using common clipping geometries, which mainly uses an interactive tool to draw an arbitrary closed curve to retain or clip away volume data. Thus, the clipping geometry can be convex or concave. A binary mask image with same size as the rendering window is built according to the closed curve to conveniently compute the coordinate relationship between the volume data and the closed curve in screen frame. The 2D screen coordinates of volume data are computed by the transformation from the world coordinate frame to the screen coordinate frame. To increase cutting speed and reduce computation complexity, the optimization algorithm mixing octree with quad-tree decomposition is introduced to decompose eligible volume data. Octree has been widely utilized as spatial data structure for organizing 2D or 3D data, such as in ray tracing [15], mesh simulation [16], mesh coding [17], and geometric modeling [18–20]. Eligible octants are decomposed to eight parts, and the other octants are clipped away or retained according to their coordinate relationship with the closed curve.

The rest of the paper is organized as follows: Section 2 introduces the proposed volume clipping algorithm, which includes filling the closed curve geometry, transforming the coordinate system, and using the optimization algorithm to decompose volumetric data. Section 3 describes how it can perform multiple cutting. Section 4 describes several experiments, including manually segment cardiac images, and Section 5 presents our conclusions.

@&#METHOD@&#

Selecting or surrounding arbitrarily shaped ROI in volumetric data in a simple and intuitive way and then representing the region with a geometric model, is a complex task [10]. A closed curve is usually drawn on screen to clip away or keep some regions of volume data. According to the coordinates of pixels on the closed curve, which voxels of volume data inside the curve and which ones outside would be decided. Unfortunately, the pixels on the curve are discontinuous. Thus, adjacent pixels as well as the starting and terminal points should be linked to construct a closed curve.

Next, a 2D image with the same size as the rendering window is created. To describe two statuses inside and outside the curve, the image is defined as binary type [9]. All pixels are initialized to 1. An interactive tool is used to plot an arbitrarily shaped curve in the rendering window as shown in Fig. 1
                        (a).

Pixels coordinates of the curve in Fig. 1(a) are extracted to construct the binary mask image in Fig. 1(b). Two containers of points (
                           P
                        , 
                           Q
                        ) are utilized to save the pixels coordinates. The pixels of the curve are set to 0, and all the discontinuous pixels coordinates are included in 
                           P
                        . The curve must be closed to fill the region inside the curve. Adjacent points, such as 
                           p
                        
                        
                           i
                        , 
                           p
                        
                        
                           i+1 and 
                           p
                        
                        
                           i+2, are often discontinuous and should thus be linked together, as shown in Fig. 1(c). Several points between 
                           p
                        
                        
                           i
                         and 
                           p
                        
                        
                           i+1 should be also linked to make the curve closed. Thus, all the pixels between 
                           p
                        
                        
                           i
                         and 
                           p
                        
                        
                           i+1 are filled with 0 (Fig. 1d), and the points between the starting and end points are also linked. The linked curve is shown in Fig. 1(d). The new continuous pixels coordinates are placed inside 
                           Q
                        . The 95 pixels in 
                           P
                         increase to 627 in 
                           Q
                        , as shown in Fig. 1(d).

To distinguish pixels inside and outside 
                           Q
                        , the area inside the closed curve should be filled with 1, and outside it with 0 pixels. The size of the rendering window is 500×500 (Fig. 1d). Introducing an iterating method to fill the outside region of the curve would be time consuming, because all the pixels in some rows or columns are located outside the curve. In such a case, the smallest bounding box of the closed curve should be defined first to speed up the filling process. Let x
                        
                           max
                         and y
                        
                           max
                         be the maximal coordinates in 
                           Q
                         along the x and y coordinate axes, respectively, and x
                        
                           min
                         and y
                        
                           min
                         be the minimal coordinates in 
                           Q
                         along the same coordinate axes. Thus, the smallest bounding box with four vertices 
                           p
                        (x
                        
                           min
                        , y
                        
                           min
                        ), 
                           p
                        (x
                        
                           min
                        , y
                        
                           max
                        ), 
                           p
                        (x
                        
                           max
                        , y
                        
                           min
                        ), and 
                           p
                        (x
                        
                           max
                        , y
                        
                           max
                        ) are obtained. The size of the bounding box is 207×235 (Fig. 1e). Compared with the rendering window, the bounding box significantly reduces the search range.

To fill the area between the box and the closed curve, pixels of four edges of the bounding box are placed in a list 
                           L
                        . The 4-connected neighborhoods searching algorithm [21] is introduced to determine whether pixels inside bounding box are set to 0. If 
                           p
                        
                        
                           i
                         ∈ 
                           L
                        , the four neighbors are searched for in the region inside the bounding box. If the value of a neighbor in the mask image is 1, this neighbor is added to 
                           L
                        . After all neighbors are checked, 
                           p
                        
                        
                           i
                         in the mask image is set to 0, and 
                           p
                        
                        
                           i
                         is removed from 
                           L
                        . This procedure is repeated until 
                           L
                         is empty. The pixels on the curve are previously set to 0; thus, the filling operation is finished until all the pixels between the bounding box and the curve are filled (Fig. 1e). The pixels outside the bounding box can easily be set to 0 according to 
                           p
                        (x
                        
                           min
                        , y
                        
                           min
                        ), 
                           p
                        (x
                        
                           min
                        , y
                        
                           max
                        ), 
                           p
                        (x
                        
                           max
                        , y
                        
                           min
                        ), and 
                           p
                        (x
                        
                           max
                        , y
                        
                           max
                        ). The filling result is shown in Fig. 1(f).

If the voxels in the volume data projected inside the closed curve require removal, the relationship between these voxels and the curve should be determined first. For convenience, five coordinate frames (i.e., the model coordinate frame 
                           F
                        
                        
                           m
                        , world coordinate frame 
                           F
                        
                        
                           w
                        , camera coordinate frame 
                           F
                        
                        
                           c
                        , normalized view coordinate frame 
                           F
                        
                        
                           n
                        , and screen coordinate frame 
                           F
                        
                        
                           s
                        ) are built to describe how the voxels in the volume data are projected onto the screen through a rendering pipeline. Each set of volume data has its own 
                           F
                        
                        
                           m
                         to describe the coordinates of each voxel. All volume data are located within an 
                           F
                        
                        
                           w
                        ; thus, the relationship between 
                           F
                        
                        
                           m
                         and 
                           F
                        
                        
                           w
                         should be determined. If we let 
                           v
                        
                        
                           m
                         and 
                           v
                        
                        
                           w
                         be the coordinates of an arbitrary voxel in 
                           F
                        
                        
                           m
                         and 
                           F
                        
                        
                           w
                        , respectively, then the rigid motion transformation is expressed as
                           
                              (1)
                              
                                 
                                    
                                       
                                          v
                                       
                                       w
                                    
                                    =
                                    
                                       
                                          R
                                       
                                       
                                          m
                                          w
                                       
                                    
                                    
                                       
                                          v
                                       
                                       m
                                    
                                    +
                                    
                                       
                                          T
                                       
                                       
                                          m
                                          w
                                       
                                    
                                 
                              
                           
                        where 
                           R
                        
                        
                           mw
                         represents a 3×3 rotation matrix and 
                           T
                        
                        
                           mw
                         is a 3×1 translation vector.

The camera model is described as a classical pinhole model having intrinsic 
                           A
                         with focal length, principal point, pixel skew factor, and extrinsic parameters, including a rotation matrix 
                           R
                        
                        
                           wc
                         and a translation vector 
                           T
                        
                        
                           wc
                        . In 
                           F
                        
                        
                           c
                        , the origin O
                        
                           c
                         is placed on the viewpoint of the camera, and Z
                        
                           c
                         aligns with the direction of the optical axis. X
                        
                           c
                         and Y
                        
                           c
                         are located along the X
                        
                           s
                         and Y
                        
                           s
                         directions of 
                           F
                        
                        
                           s
                        , respectively. The rendering result is produced by the position and orientation of the camera in 
                           F
                        
                        
                           w
                        . Thus, the relationship between 
                           F
                        
                        
                           c
                         and 
                           F
                        
                        
                           w
                         should be determined. This relationship is described as [22]
                        
                           
                              (2)
                              
                                 
                                    
                                       
                                          v
                                       
                                       c
                                    
                                    =
                                    
                                       
                                          R
                                       
                                       
                                          w
                                          c
                                       
                                    
                                    
                                       
                                          v
                                       
                                       w
                                    
                                    +
                                    
                                       
                                          T
                                       
                                       
                                          w
                                          c
                                       
                                    
                                 
                              
                           
                        
                     

Meanwhile, the coordinate of a point is expressed in 
                           F
                        
                        
                           c
                        , which may be projected onto the view plane through the intrinsic camera parameters. Perspective projection with pinhole camera geometry is used to transform 
                           p
                        
                        
                           c
                        (x
                        
                           c
                        ,y
                        
                           c
                        ,z
                        
                           c
                        ) in 
                           F
                        
                        
                           c
                         to 
                           p
                        
                        
                           n
                        (x
                        
                           n
                        ,y
                        
                           n
                        ) in 
                           F
                        
                        
                           n
                         
                        [23] and is expressed as
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                         n
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         y
                                                         n
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          
                                             z
                                             c
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                         c
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         y
                                                         c
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Given that the camera is ideal and has no radial and tangential distortion, the intrinsic parameters 
                           A
                         of the camera can be preset. Let 
                           p
                        
                        
                           s
                        (x
                        
                           s
                        ,y
                        
                           s
                        ) be the screen coordinates in 
                           F
                        
                        
                           s
                        . Thus,
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                         s
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         y
                                                         s
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   1
                                                
                                             
                                          
                                       
                                    
                                    =
                                    A
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                         n
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         y
                                                         n
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   1
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

According to Eqs. (1)–(4), each voxel in the volume data can be projected onto the screen so that the corresponding screen coordinates can thus be obtained, and vice versa [24].

Directly using Eqs. (1)–(4) to compute the screen coordinates of all voxels in volume data is time consuming and impossible to cut volume data away in real time. Therefore, optimization algorithm that mixes octree with quad-tree decomposition algorithm to subdivide volumetric data is introduced to save the computation time of cutting operation.

Octree is a hierarchical data structure that represents 3D volume data in an eight-way branching tree while quad-tree is the representation of octree in 2D space [25]. Original volume data is subdivided into eight cubes which are known as ‘octants’ by halving it along each axis direction (Fig. 2
                        a). The relationship among octants can be also viewed as a hierarchical tree structure (Fig. 2b) [26]. The octants are classified as full, empty, and partially full. The decomposition process that subdividing all partially full octants continues until all the octants are either full or empty and no partially full octants exist, or the decomposition level is equal to a previously set depth [27].

Volume data is recursively divided according to optimization algorithm and the coordinate relationship between eight vertices of the geometric primitives and the closed curve. The cube is an octant in volume data (Fig. 3
                        ). Every octant stores the eight vertices’ coordinates of corresponding volume data to provide condition for next subdividing. The eight vertices of the cube 
                           V
                        
                        ={v
                        
                           i
                        |i
                        =1,…,8} are projected onto the screen to obtain the corresponding coordinates 
                           U
                        
                        ={u
                        
                           i
                        |i
                        =1,…,8} in 
                           F
                        
                        
                           s
                         according to Eqs. (1)–(4). The convex hull 
                           H
                         and its vertices 
                           U
                        
                        
                           c
                         are then computed from 
                           U
                        . If a point 
                           p
                         is located inside the cube, the projected screen point 
                           p
                        ’ is also located inside 
                           H
                         according to Eqs. (1)–(4) and the relationship between 
                           p
                         and 
                           V
                        . Thus, whether the cube should be clipped away, completely preserved, or partially retained can be determined by the relationship between 
                           H
                         and the closed curve. These options introduce three types of nodes, namely, empty, full, and partially full, which also represent the relative relationship between the closed curve and 3D objects.

When the closed curve is located outside 
                           H
                         without intersection, the cube is defined as an empty node (Fig. 3a). In such case, all of voxels in the cube are projected outside the curve and thus, this cube is retained. By contrast, when the closed curve wholly surround 
                           H
                        , the cube is called as a full node (Fig. 3b), and all of voxels in the cube are clipped away. In some cases, 
                           H
                         intersects with the closed curve (Fig. 3c). Voxels in the cube with screen coordinates inside the closed curve should be clipped away. In Fig. 3(d), the closed curve is located inside 
                           H
                        . In this case, part of the voxels in the cube with screen coordinates inside the closed curve should be removed, too. Fig. 3(c) and (d) shows what are known as partially full node. During the process, all the empty nodes are retained, whereas the full nodes are removed. Decomposition continues to subdivide all partially full nodes until all sub nodes are either full or empty nodes and no partially full nodes exist. In each step, all cube vertices are kept for further decomposition. The decomposition process can be also controlled by different criteria, such as the maximum level of decomposition and the minimum size of the octants.

According to above octree representation, each partially full node is theoretically subdivided into eight sub cubes by halving it along each axis direction.
                           
                              (5)
                              
                                 
                                    S
                                    =
                                    
                                       V
                                       
                                          
                                             
                                                8
                                             
                                             l
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           S
                         is size of node, 
                           V
                         is dimension of original volume data and l is level of decomposition. On the basis of each node's vertices coordinates in pixel coordinate system, nodes can be encoded and divided into eight sub nodes conveniently. The vertices coordinates of first node 
                           V
                        
                        
                           11
                         in level 1 (Table 1
                        ) which is partially full node are (0,0,0), (0,255,0), (255,255,0), (255,0,0), (0,0,59), (0,255,59), (255,255,59) and (255,0,59). Then the sub nodes 
                           V
                        
                        
                           21
                        –
                           V
                        
                        
                           28
                         in level 2 can be computed based on 
                           V
                        
                        
                           11
                        's vertices’ coordinates; for instance, the vertices coordinates of 
                           V
                        
                        
                           22
                         are (0,128,0), (0,255,0), (127,255,0), (127,128,0), (0,128,29), (0,255,29), (127,255,29) and (127,128,29) respectively. In fact, we cannot equally decompose all partially full nodes into 8 parts. Different size of nodes should be decomposed in different ways. In some cases, the size of node along axis direction may be odd, so it cannot be equally divided. For example, the nodes in level 3 with size of 64×64×15 will be subdivided into sub cubes in level 4 with different size of 32×32×7 and 32×32×8, respectively (Table 1). Considering the size of node along axis direction would be 1 at the end of decomposition process, e.g. the node's size is 4×4×1 in level 7 (Table 1), octree cannot be used to divide it. Then such nodes would be divided into 4 parts based on quad-tree decomposition algorithm, e.g. the child nodes’ size is 2×2×1 in level 8 (Table 1). When the size of octant is less than 4, it is unnecessary to subdivide the node. Directly dealing with all voxels of the node is suggested.

Different value of octree's parameters could influence algorithm performance to a great extent. As an example consider the original volume data 
                           V
                        
                        
                           0
                         (512×512×120) in Table 1. When the decomposition depth is 0, that means the octree algorithm is not applied, completing the cutting process would spend 133,177ms. With the decomposition depth constantly growing from 1 to 8, computation time correspondingly reduce from 66,645 to 1599. It is noteworthy that when cube's size is not more than the number of vertices that algorithm need to split the node, further decomposition process is redundant and will expand computation time. The experiment in Table 1 that computation time in level 9 (1960) is greater than level 8 (1599) could also explain it.

In volumetric data cutting process, vertices coordinates of the cube are stored in node of octree. This node is removed if full, retained if empty, or further decomposed if partially full node. Therefore, the region 
                        V
                     
                     
                        i
                     
                     
                        c
                      projected inside the closed curve is clipped. If we let 
                        V
                      be the original volume data, then the retained region 
                        V
                     
                     
                        i
                      can thus be written as
                        
                           (6)
                           
                              
                                 
                                    V
                                    i
                                 
                                 =
                                 V
                                 −
                                 
                                    V
                                    i
                                    c
                                 
                              
                           
                        
                     
                  

In most applications, the original volume data require multiple cutting. If the volumetric data are cut for N times, the retained data are given as
                        
                           (7)
                           
                              
                                 
                                    V
                                    N
                                 
                                 =
                                 V
                                 −
                                 
                                    ⋃
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    
                                       V
                                       i
                                       c
                                    
                                 
                              
                           
                        
                     
                  

Conversely, if the clipped data should be retained, the retained data are given as
                        
                           (8)
                           
                              
                                 
                                    V
                                    N
                                    c
                                 
                                 =
                                 
                                    ⋃
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    
                                       V
                                       i
                                       c
                                    
                                 
                              
                           
                        
                     
                  

Therefore, we can cut volume data of any shape according to Eqs. (6)–(8).

@&#RESULTS AND DISCUSSION@&#

Performance of the proposed cutting method is evaluated with two series brain MRIs acquired through GE Magnetron performed at the Guangzhou General Hospital of the People's Liberation Army. The two volume MRIs have in-plane resolutions of 512×512×120 and 512×512×119 and voxel sizes of 0.468×0.468×1.200 and 0.449×0.449×1.500mm, respectively (Fig. 4
                     a–4g).


                     Fig. 4 shows the original, clipped, and remaining volume data cut by the free closed curves with different shapes, including concave and convex curves. The two MRI datasets intersect with closed curve in screen coordinate system, so they are partially full nodes according to Section 2.3. All volume data are rendered by ray casting algorithm. Images of top line in Fig. 4 show the cutting results of single curve. Fig. 4(b) shows the remaining volume data, whereas Fig. 4(c) shows the clipped data, from which interior brain tissues can be observed. Images of middle line show the cutting results of multiple curves according to Eqs. (6)–(8). The retained volume data are cut by one concave and two convex curves (Fig. 4e); the clipped data are shown in Fig. 4(f). Images of bottom line show the results of another MRI series clipped by a concave curve.

Next, performance of the proposed method is compared with a method that does not use the optimization algorithm for making a comparison. The two volume datasets in Fig. 4 are used to test the cutting speed on a Windows 7 PC with an Intel Core i5-3740 at a 3.20GHz CPU and a 4.00GB RAM. The test results are shown in Table 2
                     . When the volume data in Fig. 4(a)–(f) are used and the mask image sizes are 300×300 to 600×600, 31,457,280 points require processing. The mean number of points calculated by proposed cutting method is 539,105, about 1.7% of those requiring calculation in the method that does not use the optimization algorithm. The mean calculation time of all the mask image sizes is reduced from 134,232ms to 2055ms, which is equivalent to 98.5% of mean time saved. With another volume data set, the proposed method calculates 495,219 points on the average compared with the 31,195,136 points of the method without using optimization algorithm. The smaller number saves 98.5% of the mean time. With increase of the mask image's size from 300×300 to 600×600, the computation of intersection of volume data and closed curve becomes more complex and cutting time correspondingly increase as a whole in Table 2. Hence, the processing speed of the proposed method is related to the shape of the closed curve and size of mask image (Table 2).

The cutting algorithm utilized to extract ROI has certain clinical value. The cutting algorithm is also utilized to segment DSCT cardiac images manually (Fig. 5
                     ). Firstly, we clip away organization outside heart by the cutting algorithm, for example, rib, diaphragm, to achieving heart images. Then we manually extract various cardiac chambers carefully combining with other manually segmented tools based on the heart image. For getting accurate results, three-dimensional Dilating, Eroding, Redo, and Undo operations are developed to assist manual segmentation. The results show that the proposed cutting algorithm could be applied in manual segmentation algorithm to extract regions of interest in medical data. The DSCT cardiac images segmented results by the cutting algorithm could be used to evaluate cardiac function quantitatively and be more conducive for diagnosis and treatment of cardiac disease.

The cutting algorithm introduced in the paper provides an interactive interface for creating cuts through 2D arbitrary-shaped curve. Fig. 4 demonstrates the freedom with which users can create arbitrary cuts. Flexible operation with the cutting algorithm could meet users’ more requirements in contrast to the method [3,7] utilized special shaped clipping geometry. By using mask image and coordinate transformation, all of cutting operations are computed in 2D space which has less space complexity than computing intersections between clipping geometries and volume data in 3D space [2,3,5]. Considering real-time operation, the cutting algorithm adopts optimization algorithm mixing octree with quad-tree decomposition algorithm to optimize computation process which spends less time than the methods computing all voxels in volume data [5,9].

@&#CONCLUSION@&#

In this paper, we introduce a novel interactive 3D approach to arbitrarily clipping medical images that data enclosed by closed curves are retained or clipped away.

To create clipping geometries with arbitrary shapes, we use an interactive tool to draw a free curve as a clipping geometry. This curve can be concave or convex, and can thus meet more requirements of users. We also discuss the issue of reducing computation complexity about the coordinate relationship between volume data and clipping geometries, which is computed in 2D space using coordinate transformations. A binary mask image is constructed to conveniently determine whether a voxel is projected inside the curve. Finally, the optimization algorithm mixing octree with quad-tree decomposition as a spatial decomposition algorithm is used to interactively cut volumetric data in real time.

The cutting algorithm can adjust and move the shape of the closed curve to achieve accurate results and convenient operation. Inappropriately cutting operations can also be revoked to ensure flexibility of the cutting algorithm. In the future, 3D image segmentation algorithms can be combined with this clipping algorithm to increase cutting accuracy and speed.

None declared.

@&#ACKNOWLEDGMENTS@&#

This study was partially supported by the National Natural Science Foundation of China (Grant No. 81101130), the Fundamental Research Funds for Central Universities of the South China University of Technology (Grant No. 2012ZZ0095), and the Guangdong Provincial Science and Technology Program (Grant No. 2012B031800026). We also wish to thank the Guangzhou General Hospital of the People's Liberation Army for providing the brain MR data.

@&#REFERENCES@&#


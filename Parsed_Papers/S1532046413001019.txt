@&#MAIN-TITLE@&#A comparative study of covariance selection models for the inference of gene regulatory networks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Three different models for inferring gene networks from microarray data are proposed.


                        
                        
                           
                           The most sensitive approach is selected by an exhaustive simulation study.


                        
                        
                           
                           The method reveals a cross-talk between the isoprenoid biosynthesis pathways in Arabidopsis thaliana.


                        
                        
                           
                           The method highlights 9 genes in HRAS signature regulated by the transcription factor RREB1.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gaussian graphical models

Gene networks

Pathway analysis

Covariance selection

@&#ABSTRACT@&#


               
               
                  Motivation
                  The inference, or ‘reverse-engineering’, of gene regulatory networks from expression data and the description of the complex dependency structures among genes are open issues in modern molecular biology.
               
               
                  Results
                  In this paper we compared three regularized methods of covariance selection for the inference of gene regulatory networks, developed to circumvent the problems raising when the number of observations n is smaller than the number of genes p. The examined approaches provided three alternative estimates of the inverse covariance matrix: (a) the ‘PINV’ method is based on the Moore–Penrose pseudoinverse, (b) the ‘RCM’ method performs correlation between regression residuals and (c) ‘ℓ2C
                     ’ method maximizes a properly regularized log-likelihood function. Our extensive simulation studies showed that ℓ2C
                      outperformed the other two methods having the most predictive partial correlation estimates and the highest values of sensitivity to infer conditional dependencies between genes even when a few number of observations was available. The application of this method for inferring gene networks of the isoprenoid biosynthesis pathways in Arabidopsis thaliana allowed to enlighten a negative partial correlation coefficient between the two hubs in the two isoprenoid pathways and, more importantly, provided an evidence of cross-talk between genes in the plastidial and the cytosolic pathways. When applied to gene expression data relative to a signature of HRAS oncogene in human cell cultures, the method revealed 9 genes (p-value<0.0005) directly interacting with HRAS, sharing the same Ras-responsive binding site for the transcription factor RREB1. This result suggests that the transcriptional activation of these genes is mediated by a common transcription factor downstream of Ras signaling.
               
               
                  Availability
                  Software implementing the methods in the form of Matlab scripts are available at: http://users.ba.cnr.it/issia/iesina18/CovSelModelsCodes.zip.
               
            

@&#INTRODUCTION@&#

A challenging goal of systems biology is to provide quantitative models for the study of complex interaction patterns among genes and their products that are the result of many biological processes in the cell, such as biochemical interactions and regulatory activities [23]. Among these models, gene regulatory networks (GRNs) are essential representations for the comprehension of the development, functioning and pathology of biological organisms. Indeed, it is widely believed that the GRNs embody the comprehensive information of the mechanisms that govern the expression of the genes in the cell [28]. In particular, the GRNs inferred by genome-wide expression data depend on environmental factors, tissue type, disease-state and experimental conditions. This condition-specificity of GRNs play a major role for the study of biological processes in distinct phenotypical conditions. Indeed, under different conditions, networks exhibit different interaction patterns that can enlighten the understanding of cell development and the identification of key drivers such as disease-related genes or altered biological processes [28,51,31].

One of the simplest and most popular approaches in bioinformatics is to compute the sample Pearson correlation between every pair of genes [7]. The resulting relevance network considers two genes ‘not-linked’ in the case of marginal independence. This method, although useful for unveiling co-expression of genes implicated in the same biological process, has important shortcomings for the investigation of GRNs. For assessing co-expression between two genes, the Pearson correlation does not take into account the activities of the remaining genes in the cell. Moreover, this method does not distinguish between direct and indirect interactions, and is not able to highlight regulations by a common gene.

These drawbacks may be overcome exploiting partial correlation, a more sophisticated statistical model which is able to infer relations of conditional dependences among random variables [10,47]. In this framework, Gaussian Graphical Models (GGMs) have been exploited to study and describe dependency structures between random variables [14,26]. In our context, partial correlation assesses association between two genes by removing the effects of a set of controlling genes. Moreover, in a GGM an edge uniquely indicates a direct interaction between a gene A and a gene B, that can be interpreted biologically as one of the following mechanisms [32]:
                        
                           •
                           
                              A and B are regulated by the same transcription factor (TF) which is not included in the network;


                              A encodes a TF which directly regulates B;


                              A encondes a TF which directly regulates an intermediate gene C which encodes a TF that in turn regulates gene B, and C is not included in the network;


                              A encodes a protein which interacts with the TF encoded by an intermediate gene, and modifies its action on the transcription of gene B.

In recent years, several reverse-engineering approaches have been proposed for inferring regulatory networks from gene expression data. The nature of the data makes this problem clearly ill-posed. Indeed, the genomic data are typically characterized by a huge number p of genes and by a small number n of samples. The simplest solution proposed to overcome this problem was to reduce the numbers of genes in order to reach the n
                     >
                     p regime [45]. Other solutions have been proposed to circumvent the problem of computing full partial correlation coefficients by using only zero and first order coefficients [48,8,19]. However, these approaches do not take into account all multi-gene effects on each pair of variables. More sophisticated approaches determine regularized estimates of the covariance matrix and its inverse [50,17,49]. A fundamental assumption usually adopted by these methods in n
                     <
                     p regime is the sparsity of biological networks: only a few edges are supposed to be present in the gene regulatory networks, so that reliable estimates of the graphical model can be inferred also in small sample case [8]. A regularized GGM method based on a Stein-type shrinkage has been applied to genomic data [13] and the network selection has been based on false discovery rate multiple testing. The same procedure to select the network has been adopted, with a Moore–Penrose pseudoinverse method to obtain the precision matrix [39]. Finally, the authors in [34] suggested an attractive and simple approach based on lasso-type regression to select the non-vanishing partial correlations, paving the way to a number of analysis and novel algorithms based on lasso ℓ1 regularizations [50,17,49,18].

To date, a comparative analysis of these methods is missing. In this work, we focus on recently proposed methods developed in the general framework of regularization and statistical learning theories which provide the state-of-art approaches for the study of ill-posed problems as the ones in which the signal is overwhelmed by the noise and the number of variables is much larger than the number of observations [46]. In particular, we focus on regularized methods for the estimation of the precision matrix in an undirected GGM. We present a comparative study of three methods in terms of AUC (area under the Receiving Operative Characteristic curve), mean square error (MSE), positive predictive values (PPV) and sensitivity (SE). The first method is based on Moore–Penrose pseudoinverse (PINV); the second one provides an estimate of the partial correlation coefficients based on Regularized Least Square regression (RCM); the third method determines an estimate of the precision matrix by maximizing a log-likelihood function properly regularized by an ℓ2 penalty term (ℓ2C
                     ). The conditional dependence between each pair of variables was assessed by using the Efron’s bootstrap method [22]. Due to the lack of a perfectly known ground truth related to real biological networks [4], we measured the performance of the three methods by generating simulated data based on golden standard interaction patterns, built according to biological inspired different topologies [18,40]. We found that the ℓ2C
                      method exhibited the most predictive partial correlation estimates. More importantly, this method had the highest values of sensitivity showing its ability to infer true conditional dependencies between genes also when a few number of observations is available.

We assessed the ability of the ℓ2C
                      method to infer GRNs in two real biological contexts: the isoprenoid biosynthesis pathways in Arabidopsis thaliana and the HRAS oncogenic signature in human cell cultures. In the first case, the method enlightened known relevant pathway properties. In particular, it revealed a negative partial correlation coefficient between the two hubs in the two isoprenoid pathways. This suggests a different response of the pathways to the several tested experimental conditions and, together with the high connectivity of the two hubs, provides an evidence of cross-talk between genes in the plastidial and the cytosolic pathways. In the second case, ℓ2C
                      method highlighted 34 genes directly interacting with HRAS. In particular, 9 of these genes (p-value<0.0005) shared the same Ras responsive transcription factor binding site, suggesting that their transcriptional activation is mediated by a common transcription factor downstream of Ras signaling.

@&#METHODS@&#

Let 
                        
                           X
                           =
                           (
                           
                              
                                 X
                              
                              
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 X
                              
                              
                                 p
                              
                           
                           )
                           ∈
                           
                              
                                 R
                              
                              
                                 p
                              
                           
                        
                      be a random vector distributed according a multivariate normal distribution 
                        
                           N
                           (
                           μ
                           ,
                           Σ
                           )
                        
                     . The interaction structure among these variables can be described by means of a graph G
                     = (V,E), where V is the vertex set and E is the edge set. If vertices of V identify the random variables X
                     1,…,
                     X
                     
                        p
                     , then the edges of E represent the conditional dependence between the vertices. In other words, the absence of an edge between the ith and jth vertex means a conditional independence between the associated variables X
                     
                        i
                      and X
                     
                        j
                     . The structure of a graph is properly described by a p
                     ×
                     p matrix, called adjacency matrix 
                        A
                     , with elements a
                     
                        ij
                     
                     =1 if the variables X
                     
                        i
                      and X
                     
                        j
                      (vertices) are connected by an edge and 0 otherwise.

In this study, we shall consider only undirected Gaussian graphs G with pairwise Markov property, such that for all (i,
                     j)∉
                     E one has
                        
                           (1)
                           
                              
                                 
                                    X
                                 
                                 
                                    i
                                 
                              
                              ⫫
                              
                                 
                                    X
                                 
                                 
                                    j
                                 
                              
                              |
                              
                                 
                                    X
                                 
                                 
                                    V
                                    ⧹
                                    {
                                    i
                                    ,
                                    j
                                    }
                                 
                              
                              
                              i
                              ,
                              j
                              =
                              1
                              ,
                              …
                              ,
                              p
                              ,
                           
                        
                     i.e. X
                     
                        i
                      and X
                     
                        j
                      are conditionally independent being fixed all other variables X
                     
                        V⧹{i,j}. Since X follows a p
                     −variate normal distribution, the condition (1) turns out to be ρ
                     
                        ij·V⧹{i,j}
                     =0, where ρ
                     
                        ij·V⧹{i,j} is the partial correlation coefficient between the ith and jth variable, being fixed all other variables. It has been shown [26] that partial correlation matrix elements are related to the precision matrix (or inverse covariance matrix) Θ
                     =
                     Σ
                     −1, as:
                        
                           (2)
                           
                              
                                 
                                    ρ
                                 
                                 
                                    ij
                                    ·
                                    V
                                    ⧹
                                    {
                                    i
                                    ,
                                    j
                                    }
                                 
                              
                              =
                              -
                              
                                 
                                    
                                       
                                          θ
                                       
                                       
                                          ij
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                                θ
                                             
                                             
                                                ii
                                             
                                          
                                          
                                             
                                                θ
                                             
                                             
                                                jj
                                             
                                          
                                       
                                    
                                 
                              
                              
                              i
                              
                              ≠
                              
                              j
                              ,
                           
                        
                     where θ
                     
                        ij
                      are elements of Θ. In general, when the number of observations n is greater than the number of variables p, it is straightforward to evaluate θ
                     
                        ij
                      in Eq. (2) by inverting the sample covariance matrix. Moreover, in this case, a simple parametric test exists for assessing the conditional independence between two variables [3]. Unfortunately, a typical genomic dataset is characterized by n
                     <
                     p, so that the sample covariance matrix becomes not invertible [11]. In the successive sections we analyze three regularized methods for estimating partial correlation matrixes and a simple non-parametric test based on Efron’s bootstrap method to use when n
                     <
                     p for assessing conditional independence [22].

For describing the three methods that we have analyzed, let us consider the n
                        ×
                        p data matrix
                           
                              
                                 X
                                 =
                                 (
                                 
                                    
                                       X
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       X
                                    
                                    
                                       p
                                    
                                 
                                 )
                              
                           
                        where each column 
                           
                              
                                 
                                    {
                                    
                                       
                                          X
                                       
                                       
                                          i
                                       
                                    
                                    }
                                 
                                 
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    p
                                 
                              
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    n
                                 
                              
                           
                         is a n
                        −dimensional vector, with n
                        <
                        p. Let S be the sample estimate of the covariance matrix Σ and 
                           
                              
                                 
                                    Θ
                                 
                                 
                                    ˆ
                                 
                              
                           
                         be the estimate of inverse covariance matrix Σ
                        −1.

The estimated precision matrix 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            can be obtained as pseudoinverse of S, by using the Singular Value Decomposition (SVD). Indeed, since S is a real and symmetric matrix, then its singular value decomposition reduces to S
                           =
                           UΛU
                           ⊤ where U is a p
                           ×
                           p unitary matrix whose columns are the eigenvectors of S and U
                           ⊤ is the transpose of U;Λ is p
                           ×
                           p diagonal matrix whose entries are the non-negative eigenvalues of S. Then, the pseudoinverse of S is S
                           +
                           =
                           UΛ
                           +
                           U
                           ⊤, where Λ
                           + is obtained by replacing each positive diagonal element of Λ with its reciprocal.

To improve the estimate of the partial correlation coefficients, we evaluated a bootstrap version of 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            
                           [39]. In particular, we generated B bootstrap replications X
                           
                              b
                            of the sample with b
                           =1,…,
                           B obtained by random sampling with replacement the raws of X. For each replication, we evaluated the bootstrap replication S
                           
                              b
                            of S and used these estimates for obtaining the bootstrap mean 
                              
                                 
                                    
                                       S
                                    
                                    
                                       B
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       B
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       b
                                       =
                                       1
                                    
                                    
                                       B
                                    
                                 
                                 
                                    
                                       S
                                    
                                    
                                       b
                                    
                                 
                              
                           . Then the bootstrap estimate of 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            was obtained as 
                              
                                 
                                    
                                       
                                          
                                             Θ
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       B
                                    
                                 
                                 =
                                 
                                    
                                       S
                                    
                                    
                                       B
                                    
                                    
                                       +
                                    
                                 
                              
                           .

Finally, we estimated the partial correlation matrix as
                              
                                 (3)
                                 
                                    
                                       
                                          ρ
                                       
                                       
                                          ˆ
                                       
                                    
                                    =
                                    -
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      Θ
                                                   
                                                   
                                                      ˆ
                                                   
                                                
                                             
                                             
                                                B
                                             
                                          
                                       
                                       
                                          
                                             
                                                diag
                                                
                                                   
                                                      
                                                         
                                                            Θ
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      B
                                                   
                                                
                                                diag
                                                
                                                   
                                                      
                                                         
                                                            Θ
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      B
                                                   
                                                   
                                                      ⊤
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Let us consider the loss function [3]
                           
                              
                                 (4)
                                 
                                    
                                       
                                          L
                                       
                                       
                                          l
                                       
                                    
                                    (
                                    S
                                    ,
                                    Θ
                                    )
                                    =
                                    Tr
                                    (
                                    S
                                    Θ
                                    )
                                    -
                                    log
                                    det
                                    (
                                    S
                                    Θ
                                    )
                                    -
                                    p
                                 
                              
                           that vanishes when SΘ
                           =
                           I and is positive when SΘ
                           ≠
                           I. Since we are dealing with the case of p
                           >
                           n, an estimate of Θ could be obtained minimizing with respect to Θ the ℓ2-penalized loss function:
                              
                                 (5)
                                 
                                    
                                       
                                          L
                                       
                                       
                                          p
                                       
                                    
                                    (
                                    S
                                    ,
                                    Θ
                                    ,
                                    λ
                                    )
                                    =
                                    
                                       
                                          L
                                       
                                       
                                          l
                                       
                                    
                                    (
                                    S
                                    ,
                                    Θ
                                    )
                                    +
                                    J
                                    (
                                    λ
                                    ,
                                    Θ
                                    )
                                    ,
                                 
                              
                           where
                              
                                 (6)
                                 
                                    J
                                    (
                                    λ
                                    ,
                                    Θ
                                    )
                                    =
                                    λ
                                    ‖
                                    Θ
                                    
                                       
                                          ‖
                                       
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                 
                              
                           with λ
                           >0 and 
                              
                                 ‖
                                 Θ
                                 
                                    
                                       ‖
                                    
                                    
                                       F
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 tr
                                 (
                                 
                                    
                                       Θ
                                    
                                    
                                       ⊤
                                    
                                 
                                 Θ
                                 )
                              
                            is the Frobenius norm of Θ.

Note that, the minimization of L
                           
                              p
                           (S,
                           Θ,
                           
                              λ
                           ) with respect to Θ is equivalent to the maximization of the penalized log-likelihood [49]:
                              
                                 (7)
                                 
                                    log
                                    det
                                    (
                                    Θ
                                    )
                                    -
                                    Tr
                                    (
                                    S
                                    Θ
                                    )
                                    -
                                    λ
                                    ‖
                                    Θ
                                    
                                       
                                          ‖
                                       
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                    .
                                 
                              
                           Differentiating with respect to Θ means to solve the following equation
                              
                                 (8)
                                 
                                    
                                       
                                          
                                             
                                                Θ
                                             
                                             
                                                ˆ
                                             
                                          
                                       
                                       
                                          -
                                          1
                                       
                                    
                                    -
                                    2
                                    λ
                                    
                                       
                                          Θ
                                       
                                       
                                          ˆ
                                       
                                    
                                    =
                                    S
                                    .
                                 
                              
                           
                        

Consequently, the problem turns out to be an eigenvalue problem. Indeed, if θ
                           
                              i
                            are eigenvalues of 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            with eigenvectors u
                           
                              i
                           ,
                              
                                 (9)
                                 
                                    
                                       
                                          Θ
                                       
                                       
                                          ˆ
                                       
                                    
                                    
                                       
                                          u
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          θ
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          u
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           then s
                           
                              i
                            are the eigenvalues of S with the same eigenvectors, and the relation between θ
                           
                              i
                            and s
                           
                              i
                            is 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       i
                                    
                                    
                                       -
                                       1
                                    
                                 
                                 -
                                 2
                                 λ
                                 
                                    
                                       θ
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       s
                                    
                                    
                                       i
                                    
                                 
                              
                           . Therefore the eigenvalues θ
                           
                              i
                            of 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            can be evaluated as function of the eigenvalues s
                           
                              i
                            of S:
                              
                                 (10)
                                 
                                    
                                       
                                          θ
                                       
                                       
                                          i
                                       
                                       
                                          ±
                                       
                                    
                                    =
                                    -
                                    
                                       
                                          
                                             
                                                s
                                             
                                             
                                                i
                                             
                                          
                                       
                                       
                                          4
                                          λ
                                       
                                    
                                    ±
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      s
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      2
                                                   
                                                
                                                +
                                                8
                                                λ
                                             
                                          
                                       
                                       
                                          4
                                          λ
                                       
                                    
                                    .
                                 
                              
                           
                        

Since precision matrix must be positive definite, the correct value of θ
                           
                              i
                            is 
                              
                                 
                                    
                                       θ
                                    
                                    
                                       i
                                    
                                    
                                       +
                                    
                                 
                              
                           . Then, for the spectral theorem, 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            is given by
                              
                                 (11)
                                 
                                    
                                       
                                          Θ
                                       
                                       
                                          ˆ
                                       
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             ℓ
                                          
                                       
                                    
                                    
                                       
                                          θ
                                       
                                       
                                          i
                                       
                                       
                                          +
                                       
                                    
                                    
                                       
                                          u
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          u
                                       
                                       
                                          i
                                       
                                       
                                          ⊤
                                       
                                    
                                    .
                                 
                              
                           
                        

The regularization parameter λ was selected by using the cross validation procedure. In particular, for each value of λ in a suitable range, we carried out 20 random splits of the dataset in training X
                           
                              t
                            and validation X
                           
                              v
                            sets and evaluated the corresponding sample covariance matrices S
                           
                              t
                            and S
                           
                              v
                           . Consequently, we estimated 
                              
                                 
                                    
                                       Θ
                                    
                                    
                                       t
                                    
                                    
                                       λ
                                    
                                 
                              
                            by minimizing the penalized loss function in Eq. (5) and evaluated the loss function in Eq. (4), averaged over the 20 splits, 
                              
                                 〈
                                 
                                    
                                       L
                                    
                                    
                                       l
                                    
                                 
                                 (
                                 
                                    
                                       S
                                    
                                    
                                       v
                                    
                                 
                                 ,
                                 
                                    
                                       Θ
                                    
                                    
                                       t
                                    
                                    
                                       λ
                                    
                                 
                                 )
                                 〉
                              
                           . The selected λ value was
                              
                                 (12)
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          ∗
                                       
                                    
                                    =
                                    arg
                                    
                                    
                                       
                                          min
                                       
                                       
                                          λ
                                       
                                    
                                    〈
                                    
                                       
                                          L
                                       
                                       
                                          l
                                       
                                    
                                    (
                                    
                                       
                                          S
                                       
                                       
                                          v
                                       
                                    
                                    ,
                                    
                                       
                                          Θ
                                       
                                       
                                          t
                                       
                                       
                                          λ
                                       
                                    
                                    )
                                    〉
                                    .
                                 
                              
                           This procedure selected the lambda minimizing the distance between the empirical inverse precision matrix computed on the training set X
                           
                              t
                            and the sample covariance matrix computed on the validation set X
                           
                              v
                           .

Let us consider a linear regression model for the variables X
                           
                              i
                            and X
                           
                              j
                            given all the p
                           −2 remaining variables:
                              
                                 (13)
                                 
                                    
                                       
                                          X
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          X
                                       
                                       
                                          ⧹
                                          i
                                          ⧹
                                          j
                                       
                                    
                                    
                                       
                                          β
                                       
                                       
                                          i
                                       
                                    
                                    
                                    
                                       
                                          X
                                       
                                       
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          X
                                       
                                       
                                          ⧹
                                          i
                                          ⧹
                                          j
                                       
                                    
                                    
                                       
                                          β
                                       
                                       
                                          j
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    
                                       β
                                    
                                    
                                       i
                                    
                                 
                                 ∈
                                 
                                    
                                       R
                                    
                                    
                                       p
                                       -
                                       2
                                    
                                 
                              
                            is the regression coefficient vector referred to the ith gene; X
                           
                              i
                            is the ith column of the matrix X and X
                           ⧹i⧹j
                            is X without the ith and jth column. Note that the bias term is implicitly present in our model. This is done by including a component constant and equal to one to the input vectors. The Regularized Least Square (RLS) [20,2] method evaluates the regression models (13) by solving
                              
                                 (14)
                                 
                                    
                                       
                                          min
                                       
                                       
                                          
                                             
                                                β
                                             
                                             
                                                i
                                             
                                          
                                          ∈
                                          
                                             
                                                R
                                             
                                             
                                                p
                                                -
                                                2
                                             
                                          
                                       
                                    
                                    
                                       
                                          1
                                       
                                       
                                          n
                                       
                                    
                                    ‖
                                    
                                       
                                          X
                                       
                                       
                                          i
                                       
                                    
                                    -
                                    
                                       
                                          X
                                       
                                       
                                          ⧹
                                          i
                                          ⧹
                                          j
                                       
                                    
                                    
                                       
                                          β
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          ‖
                                       
                                       
                                          2
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    μ
                                    ‖
                                    
                                       
                                          β
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          ‖
                                       
                                       
                                          2
                                       
                                       
                                          2
                                       
                                    
                                    .
                                 
                              
                           where μ
                           >0 is the regularization parameter. If 
                              
                                 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                              
                            are the RLS estimates of X
                           
                              i
                            and X
                           
                              j
                           , one can evaluate the residual vectors 
                              
                                 
                                    
                                       r
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       X
                                    
                                    
                                       i
                                    
                                 
                              
                            and 
                              
                                 
                                    
                                       r
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             X
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       j
                                    
                                 
                                 -
                                 
                                    
                                       X
                                    
                                    
                                       j
                                    
                                 
                              
                           . This allows to evaluate the partial correlation coefficient 
                              
                                 
                                    
                                       
                                          
                                             ρ
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       ij
                                       |
                                       p
                                       -
                                       2
                                    
                                 
                              
                            between the ith and jth variable being fixed all other (p
                           −2) variables as the Pearson correlation 
                              
                                 
                                    
                                       r
                                    
                                    
                                       
                                          
                                             r
                                          
                                          
                                             i
                                          
                                       
                                       
                                          
                                             r
                                          
                                          
                                             j
                                          
                                       
                                    
                                 
                              
                            between the residuals, i.e.
                              
                                 (15)
                                 
                                    
                                       
                                          
                                             
                                                ρ
                                             
                                             
                                                ˆ
                                             
                                          
                                       
                                       
                                          ij
                                          |
                                          (
                                          p
                                          -
                                          2
                                          )
                                       
                                    
                                    =
                                    
                                       
                                          r
                                       
                                       
                                          
                                             
                                                r
                                             
                                             
                                                i
                                             
                                          
                                          
                                             
                                                r
                                             
                                             
                                                j
                                             
                                          
                                       
                                    
                                    =
                                    
                                       
                                          cov
                                          (
                                          
                                             
                                                r
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                r
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                       
                                          
                                             
                                                var
                                                (
                                                
                                                   
                                                      r
                                                   
                                                   
                                                      i
                                                   
                                                
                                                )
                                                var
                                                (
                                                
                                                   
                                                      r
                                                   
                                                   
                                                      j
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

Finally, the μ parameter was chosen by minimizing the Leave-One-Out cross validation errors [30].

The conditional independence structure among variables and then the estimated graph 
                           
                              
                                 
                                    A
                                 
                                 
                                    ˆ
                                 
                              
                           
                         was inferred calculating a 95% confidence interval for each entry ρ
                        
                           ij
                        , by using Efron’s bootstrap method [22]. The graph selection procedure is as follows:
                           
                              (I)
                              Build B
                                 =100 bootstrap replications by drawing randomly with replacement n rows from X.

Evaluate 
                                    
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             b
                                          
                                       
                                    
                                  for each b
                                 =1,…,
                                 B.

Rank the bootstrap replications 
                                    
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                          
                                             (
                                             1
                                             )
                                          
                                       
                                       ⩽
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                          
                                             (
                                             2
                                             )
                                          
                                       
                                       ⩽
                                       …
                                       ⩽
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                          
                                             (
                                             B
                                             )
                                          
                                       
                                    
                                 .

Compute the 95% confidence interval 
                                    
                                       (
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             L
                                          
                                       
                                       ,
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             U
                                          
                                       
                                       )
                                    
                                  where 
                                    
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             L
                                          
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                          
                                             (
                                             k
                                             )
                                          
                                       
                                       ,
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             U
                                          
                                       
                                       =
                                       
                                          
                                             
                                                
                                                   ρ
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                          
                                             (
                                             B
                                             +
                                             1
                                             -
                                             k
                                             )
                                          
                                       
                                       ,
                                       k
                                       =
                                       B
                                       
                                          
                                             α
                                          
                                          
                                             2
                                          
                                       
                                    
                                  and α
                                 =0.05.

â
                                    ij
                                 
                                 =1 if 
                                    
                                       0
                                       
                                       ∉
                                       
                                       (
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             L
                                          
                                       
                                       ,
                                       
                                          
                                             ρ
                                          
                                          
                                             ij
                                          
                                          
                                             U
                                          
                                       
                                       )
                                       ,
                                       
                                          
                                             
                                                
                                                   a
                                                
                                                
                                                   ˆ
                                                
                                             
                                          
                                          
                                             ij
                                          
                                       
                                       =
                                       0
                                    
                                  otherwise.

We conducted an extensive simulation study for analyzing the performances of the three methods in terms of their ability to infer conditional dependency structures among variables in the case of n
                        ≪
                        p. In a nutshell, the simulation study was composed of three main steps: (a) building a graph with a well defined and biologically inspired structure and the corresponding precision matrix; (b) generating observations of the p random variables according to the dependency structure defined by the graph; and (c) comparing the inferred graph with the one used for generating the data in terms of estimated partial correlations and predicted edges.

We built gold standard graphs G
                           GoS by defining adjacency matrices A
                           GoS according to three different kinds of patterns [18,36]:
                              
                                 
                                    Random: A
                                    GoS is randomly generated by inserting approximately p nonzero entries;


                                    Hubs: the rows/columns of A
                                    GoS are partitioned into K disjoint groups of q variables. Each group consists of five hubs with high degree, and the other q
                                    −5 nodes with lower degrees. This setting is designed to simulate scale-free-like gene regulatory networks, which tipically contain a few hub genes plus many other nodes with only a few connections.


                                    Clique: the rows/columns of A
                                    GoS are partitioned into K disjoint groups of q variables fully connected, i. e. each group is a clique.

The density d of A
                           GoS is defined as:
                              
                                 (16)
                                 
                                    d
                                    =
                                    
                                       
                                          E
                                       
                                       
                                          p
                                          (
                                          p
                                          -
                                          1
                                          )
                                          /
                                          2
                                       
                                    
                                 
                              
                           where E is the number of edges of the graph and p(p
                           −1)/2 is the size of a complete graph with p nodes.

Given a gold standard graph defined by an adjacency matrix A
                           GoS, there exists a family of precision matrices ΘGoS, or equivalently of partial correlation matrices 
                              ρ
                           
                           GoS, associated to the graph constituted by all the real positive definite p
                           ×
                           p symmetric matrices having zeros in the same positions as A
                           GoS 
                           [8]. In order to simplify the simulation study, we decided to build partial correlation matrices having constant non-zero entries. In other words, the partial correlation between any pair of conditionally dependent variables was constant all over the graph. To this end, for a given adjacency matrix A
                           GoS, the associated concentration matrix ΘGoS was built as:
                              
                                 (17)
                                 
                                    
                                       
                                          Θ
                                       
                                       
                                          GoS
                                       
                                    
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          m
                                          +
                                          ∊
                                       
                                    
                                    
                                       
                                          A
                                       
                                       
                                          GoS
                                       
                                    
                                    +
                                    
                                       
                                          I
                                       
                                       
                                          p
                                       
                                    
                                 
                              
                           where 
                              
                                 m
                                 =
                                 
                                    
                                       max
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       j
                                    
                                 
                                 
                                    
                                       a
                                    
                                    
                                       ij
                                    
                                 
                                 ,
                                 ∊
                                 >
                                 0
                              
                            and I
                           
                              p
                            is the p order identity matrix. Since A
                           GoS is a symmetric matrix having diag (A
                           GoS)=
                           0 by definition, then diag (Θ
                           GoS)=
                           I
                           
                              p
                           . As a consequence, 
                              ρ
                           
                           GoS
                           =
                           −
                           Θ
                           GoS (see Eq. 2). Moreover, the precision matrix defined in Eq. (17) is strictly diagonally dominant and then is positive definite. Finally, the data set X was generated by sampling n times a p-variate normal distribution 
                              
                                 N
                                 (
                                 0
                                 ,
                                 
                                    
                                       Σ
                                    
                                    
                                       GoS
                                    
                                 
                                 )
                              
                           , with zero mean and covariance matrix Σ
                           GoS, where 
                              
                                 
                                    
                                       Σ
                                    
                                    
                                       GoS
                                    
                                 
                                 =
                                 
                                    
                                       Θ
                                    
                                    
                                       GoS
                                    
                                    
                                       -
                                       1
                                    
                                 
                              
                           .

The performances of the three methods were assessed by using different criteria. The first one aimed to quantify the accuracy of a method in estimating the partial correlation values. To this end, we evaluated the mean square error (MSE) between the estimated 
                              
                                 
                                    
                                       ρ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            and gold standard 
                              ρ
                           
                           GoS partial correlation matrices:
                              
                                 (18)
                                 
                                    MSE
                                    =
                                    
                                       
                                          
                                             
                                                2
                                             
                                             
                                                p
                                                (
                                                p
                                                -
                                                1
                                                )
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   j
                                                   >
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                (
                                                
                                                   
                                                      
                                                         
                                                            ρ
                                                         
                                                         
                                                            ˆ
                                                         
                                                      
                                                   
                                                   
                                                      ij
                                                   
                                                
                                                -
                                                
                                                   
                                                      ρ
                                                   
                                                   
                                                      ij
                                                   
                                                   
                                                      GoS
                                                   
                                                
                                                )
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

The second criterion aimed to assess a method in terms of prediction accuracy of the entries of A
                           GoS by using the estimated partial correlation values 
                              
                                 
                                    
                                       ρ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            as predictor variable. In particular, we wanted to quantify the prediction error of a binary classifier which predicts the entries of the gold standard adjacency matrix A
                           GoS as edge (
                              
                                 
                                    
                                       a
                                    
                                    
                                       ij
                                    
                                    
                                       GoS
                                    
                                 
                                 =
                                 1
                              
                           ) or non edge (
                              
                                 
                                    
                                       a
                                    
                                    
                                       ij
                                    
                                    
                                       GoS
                                    
                                 
                                 =
                                 0
                              
                           ) based upon 
                              
                                 
                                    
                                       
                                          
                                             ρ
                                          
                                          
                                             ˆ
                                          
                                       
                                    
                                    
                                       ij
                                    
                                 
                              
                           . To this end, we evaluated the Area Under the ROC Curve (AUC) which assesses the performances of a binary classifier as its discrimination threshold is varied. AUC is equal to the probability that a classifier will rank randomly a chosen positive instance higher than a randomly chosen negative one [15]. We chose AUC as measure of performance because it is not influenced by the prevalence of a class and it is independent from the selection rule used to infer the graph. The AUCs evaluated for the three methods were compared with the AUC measured for a random algorithm which assigns randomly and with the same probability 0 or 1 independently of the estimated partial correlation values [4]. The third criterion aimed to evaluate a method by comparing the estimated graph 
                              
                                 
                                    
                                       A
                                    
                                    
                                       ˆ
                                    
                                 
                              
                           , inferred by using 
                              
                                 
                                    
                                       ρ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                           , with the gold standard graph given by A
                           GoS. Positive Predicted Values (PPV) and sensitivity (SE) were evaluated for comparing 
                              
                                 
                                    
                                       A
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            and A
                           GoS. The last criteria consisted in measuring the computational time required for estimating the 
                              
                                 
                                    
                                       ρ
                                    
                                    
                                       ˆ
                                    
                                 
                              
                            matrix.

@&#RESULTS@&#

The performances of the three methods were analyzed keeping constant the number of variables to p
                        =400, while varying the number of samples n in the range [30] with step 30. For each value of n, the results were averaged over 20 repetitions. Moreover, for each value of n and for each generated graph structure (random, hubs, clique), all the methods were applied on the same simulated data sets.

The methods exhibited very different accuracies in the estimate of the true partial correlation values. The comparison was carried out keeping constant the graph density to d
                           =0.01 and evaluating MSE both globally on the whole partial correlation matrix 
                              ρ
                           
                           GoS, and evaluating MSE limitedly to the non null entries of 
                              ρ
                           
                           GoS corresponding to the true edges of the gold standard graph (see Fig. 1
                           ). We denote these two errors as MSE and edge-MSE. This choice was due to the fact that the true partial correlation matrices used in our simulations were generally sparse having only a few non-null entries. For small values of n, RCM method exhibited poor accuracy, showing the highest MSE and edge-MSE errors. The behavior of the two errors was comparable indicating that the method behaves uniformly on the whole graph. Although insufficient in accuracy, the method had performances invariant with respect to the graph topology and its accuracy increased with n.

A better accuracy was reached by PINV and ℓ2C
                            methods, specially for small values of n. The performances of PINV method were not influenced by the graph topology and the MSE and edge-MSE errors remained comparable in all the simulations. Nevertheless, we observed a “resonance effect” associated to this method for n
                           ≈
                           p, confirming a behavior well known in literature [37,39]. Increasing the number of observations n up to p the performance of the method got worse. For values of n larger than p, the error associated to PINV decreased by increasing n.

Contrarily to RCM and PINV, the accuracy of the ℓ2C
                            method was found different when evaluated on the whole graph or limitedly to the edges only (see Fig. 1). In particular, we measured MSE≈0.01 and edge-MSE≈0.04 for both random and hubs graphs, independently to n. A larger difference was found in clique graph topology. This discrepancy in accuracy is due to the regularization term introduced in the penalized loss function (see Eq. (7)). Indeed, ℓ2C
                            method selects precision matrices with small Frobenius norm and as a consequence, underestimates the partial correlation values. The important aspect of this method is that its accuracy is poorly influenced by the number of available observations and by the graph intrinsic topology.

The analysis of the performances in terms of AUC highlighted other interesting properties of the methods. While the MSE analysis evaluated the methods by comparing the true and the estimated partial correlation values, the AUC analysis assessed the methods by comparing the accuracy in the prediction of the gold standard graph by using the partial correlation estimates produced by the methods. The important aspect to underline is that AUC analysis is independent of the prediction rule and highlights properties of the variable used as predictor. The Fig. 2
                            depicts the behaviors of AUC evaluated for the three methods by varying n, for p
                           =400 and d
                           =0.01. All the three methods provided satisfactory results also for very small values of n because they outperformed significantly the performances of a random algorithm (see Supplemental Information). For example, in the case of random graph topology, ℓ2C
                            and RCM exhibited AUC=0.64 with 95% CI [0.59,0.67] for n
                           =30 observations; PINV showed AUC=0.61 with 95% CI [0.56,0.65] for n
                           =60 observations. In general, our simulations showed that ℓ2C
                            and RCM provided partial correlation estimates with a prediction accuracy higher than PINV. Moreover, for these two methods, it was sufficient to exploit a number of observations greater than the 15% of the number of the variables for having an AUC value greater than 0.7. The accuracy of the partial correlation values estimated by ℓ2C
                            and RCM methods improved by increasing the number of observations. On the contrary, the estimates produced by PINV method suffered for n
                           ≈
                           p of the same instability found in MSE analysis.

Another interesting property highlighted by the AUC analysis was the dependency of the accuracy on graph topology. In fact, as Fig. 2(a)–(c) show, the best accuracies were obtained for clique graphs and the worse for hub graphs. The reason of these different performances, obtained keeping constant the density d in all the simulations, resides in the degree distribution of the graph. With the degree term we mean the number of nodes connected to a given node, or equivalently, the number of variables conditionally dependent on a given variable. In fact, in the case of clique topology, the graph was composed of K
                           =80 disjoint cliques, each composed of q
                           =5 variables. In this case, the number of variables conditionally dependent on a given variable had a constant value of q
                           −1 and this number was also the maximum number of variables conditionally dependent. In the case of random graphs, the number of edges connected to a given node had a binomial distribution B(p
                           −1,
                           d). So, with a density of d
                           =0.01 and p
                           =400, we had a mean degree of pd
                           =4, with a range of [0,11]. This is equivalent to saying that 11 was the maximum number of variables conditionally dependent on a given variable. Finally, in the case of hub topology, the graph was composed of K
                           =10 disjoint groups each composed of q
                           =40 variables, giving a mean degree equal to 4 with a range of [0,19].

The dependency of the AUC on density and graph topology was confirmed by two different simulations (Fig. 3
                           ). In the first one, limitedly to the random graph topology, each method was analyzed by varying the density of the graph. In the second one, keeping the density fixed to d
                           =0.01, each method was analyzed by varying the graph topology. As the Fig. 3(a), (c) and (e) show, the lower the density, the more accurate the estimates for all the methods. Moreover, as the Fig. 3(b), (d) and (f) show, the accuracy of the estimates decreased going from clique to hub graphs for all the methods consistently.

The estimate of the partial correlation values is only the first step of any graph inference procedure and the accuracy of the estimates provided by the three methods was assessed in the two previous sections. With the sensitivity analysis addressed in this section, we assessed the whole graph inference procedure described in the Methods section, which exploited the estimates provided by the methods for inferring a graph. As performance measure we used PPV and sensitivity evaluated comparing the gold standard graph with the one inferred by the procedure. For each value of n, the values were averaged over 20 repetitions and evaluated for hub graph topology. Fig. 4
                            depicts the behaviors of PPV and sensitivity as a function of n. PINV was the only method that, for small values of n, had PPV and sensitivity values smaller than those provided by the random algorithm. RCM and ℓ2C
                           , on the contrary, showed PPV and sensitivity values greater than the random algorithm, even for a small number of observations. In particular, ℓ2C
                            method exhibited the best performances in terms of sensitivity, consistently for all the values of n, indicating that this method was able to infer true conditional dependences between variables also when a few number of observations is available. Note that the PPV and sensitivity values shown in Fig. 4 have not to be considered as absolute indicators of the performances of a method. On the contrary, they have to be considered as indicative of the relative performances of a method with respect to another one, because assessed for a specific experimental condition, equal for all the methods. More importantly, these values have to be significantly different from those obtained by random algorithms. Moreover, the values of PPV and sensitivity of a method heavily depend on the strength of the partial correlation existing among the variables. The partial correlation values used in our simulations were close to zero (see Eq. 17), so generating critical experimental conditions for the methods.

In the light of the simulation results described so far, and considering the computational time required by the three methods (see Fig. 2(d)), we choose ℓ2C
                            as the method to apply for inferring biological networks. This choice was motivated by the AUC behavior which outperformed the other two methods in all the considered graph topologies and, mainly, by the sensitivity of the method.

We applied ℓ2C
                         method for the inference of gene regulatory networks from DNA microarray data in two different contexts. The first concerned the cross-talk between the two isoprenoid pathways of the model system A. thaliana. In this case we applied the method to a well studied benchmark data set for the inference of gene networks [48,19] and compared our findings with the ones reported in literature. The second concerned the investigation of the genes interacting with the oncogene HRAS. In this case we applied the method to a gene expression data set with strong a priori biological knowledge [6]. In fact these data were used for inferring a signature of HRAS through its in vitro overexpression.

The isoprenoids are a large class of organic compounds derived from isoprene. They play various important roles in plants as: quinones in electron transport chains, structural components of membranes, photosynthetic pigments, hormones, defense compounds, attractants for pollinators and in subcellular targeting and regulation [21]. Isoprenoids are synthesized through condensation of the five-carbon intermediates isopentenyl diphosphate (IPP) and dimethylallyl diphosphate (DMAPP) [24]. In higher plants IPP and DMAPP are synthesized through two different routes that take place in two distinct cellular compartments. The cytosolic pathway, also called MVA pathway, starts from acetyl-CoA and moves through the intermediate mevalonate (MVA), providing the precursors for sterols, ubiquinone and sesquiterpenes [12]. An alternative pathway, called non-mevalonate pathway or MEP/DOXP pathway, is located in the chloroplast. It implicates the condensation of pyruvate and glyceraldehyde-3-phosphate via 1-deoxy-D-xylulose 5-phosphate (DOXP) and 2-C-methyl-D-erythritol 4-phosphate (MEP) and is used for the synthesis of isoprene, carotenoids, abscisic acid, and the side chains of chlorophylls and plastoquinone [29]. Although this subcellular compartmentation allows both pathways to work independently, there are several evidences that they can interact in some conditions [25,38,5]. Inhibition of the cytosolic MVA pathway in A. thaliana leds to an increase of levels of carotenoids and chlorophylls, demonstrating that the decreased working of MVA pathway can be in part compensated for by the MEP pathway. Inversely, inhibition of the MEP pathway in seedlings causes the reduction of carotenoids and chlorophylls levels, indicating a predominantly unidirectional transport of isoprenoid intermediates from the chloroplast to the cytosol. In order to investigate whether the transcriptional regulation is at the basis of the crosstalk between the cytosolic and the plastidial pathways, Laule et al. [25] studied this interaction by identifying the genes with expression levels changed as a response to the inhibition. They have shown that the inhibitor mediated changes in metabolite levels are not reflected in changes in gene expression levels, suggesting that alterations in the flux through the cytosolic and plastidial pathways of isoprenoid metabolism are not transcriptionally regulated. In order to clarify the interaction between the two pathways at the transcriptional level, Wille and Buhlmann [48] have explored the structural relationship between genes on the basis of their expression levels under different experimental conditions. This study aimed to infer the regulatory network of the genes in the isoprenoid pathways by incorporating the expression levels of 795 genes from other 56 metabolic pathways. Moving beyond the one-gene approach, the authors have found various connections between genes in the two different pathways, suggesting the existence of a crosstalk at the transcriptional level.

We applied the ℓ2C
                            method to the publicly available data set from [48]. The data consisted of expression measurements for 39 genes in the isoprenoid pathways and 795 in other 56 pathways assayed on 118 Affymetrix GeneChip microarrays. Among the 39 genes in the isoprenoid pathways, 15 are assigned to the cytosolic pathway, 19 to the plastidal pathway and 5 encode mitochondrial proteins involved in isoprenoid synthesis. We were interested in the construction of a gene network related to the two isoprenoid pathways considering also the effects of genes in the other pathways. To this end, we built 1000 bootstrap replications of the data set and used 95% confidence interval for inferring the network. The Fig. 5
                            depicts the inferred network with 44 edges. For each pathway we found a module with strongly interconnected and positively correlated genes. This enlightens the reliability of our method since genes within the same pathway are potentially jointly regulated [42]. Furthermore, we identified two strong candidate genes for the cross-talk between both pathways: HMGS and HDS. HMGS represents the hub of the cytosolic module since it is positively correlated to five genes of the same pathway: DPPS1, MDPC1, AACT2, HMGR2 and MK. It encodes a protein with hydroxymethylglutaryl-CoA synthase activity that catalyses the second step of the MVA pathway. HDS represents the hub of the plastidial module since it is positively correlated to five genes of the same pathway: DXPS1, MECPS, GGPPS12, IPPI1 and PPDS2. It encodes a chloroplast-localized hydroxy-2-methyl-2-(E)-butenyl 4-diphosphate synthase and catalyses the penultimate step of the biosynthesis of IPP and DMAPP via the MEP/DOXP pathway. The negative correlation between HMGS and HDS suggests that they respond differently to the tested experimental conditions. This, together with the high connectivity of the two hubs, provides an evidence of cross-talk between proteins in the plastidial and the cytosolic pathways. Other negative correlations between the two pathways are represented by the edges HMGR2∣MECPS, MPDC2∣PPDS2 and MPDC2∣DXPS2. Interestingly, the plastidial gene IPPI1 is found to be positively correlated to the module of connected genes in the MVA pathway (IPPI1∣MK, IPP1∣IPPI2). This evidence confirms the results of [19] where they guessed that the enzyme IPPI1 controls the steady-state levels of IPP and DMAPP in the chloroplast, when a high level of transfer of intermediates between the two cell compartments takes place. Moreover, our study showed three candidate mitochondrial genes for the cross-talk (DPPS2, GGPPS5 and UPPS1) which are in the plastidial module. Finally, it is interesting to note that the method used in [48] and in [19] included more cross-links between the two pathways with respect to the ℓ2C
                            method. Although it is known the existence of cross-links between the two pathways, we believe that these interactions should not be so numerous, as genes of the two pathways belong to two different cell compartments. A possible explanation of such a difference is that [48,19] constructed a network based on first-order conditional dependencies that are not able to capture all multi-gene effects on a given pair of genes.

Ras genes represent a GTPase superfamily composed by more than 150 distinct cellular members, among which the most representatives are HRAS, NRAS and KRAS. Up to 30% of all screened human tumors are found to carry some mutations in any of these genes. Ras signal transduction proceeds through activation of some signal transduction cascades, such that of Mitogen-Activated Protein Kinases (MAPKs), and culminates in the modulation of transcription of specific genes involved in many physiological processes including cell cycle progression, growth, migration, cytoskeletal changes, apoptosis, and senescence. The cross-talk among this plethora of actors creates a molecular network whose balance is crucial to determine normal cellular responses. Indeed, alterations of Ras signaling could break this balance and induce the onset of cancer and for this reason the inference and the analysis of Ras network is of fundamental importance [16].

In this context, we applied the ℓ2C
                            method for inferring genes directly interacting with HRAS. To this end, we used a data set with a controlled genetic perturbation of HRAS used to generate its oncogenic signature [6]. Such a signature was identified by infection of human primary mammary epithelial cell cultures (HMECs) with adenoviruses expressing activated HRAS. The signature was composed of those 276 genes for which the expression levels were mostly correlated with the classification of HMEC samples into HRAS-activated versus wild-type. The resulting data set used in our experiment was composed of 276 genes assayed in 10 samples relative to HRAS-activated and 10 samples relative to wild-type HRAS. Indeed, we considered that the RAS signature retrieved by Bild includes direct and indirect connections of the H-RAS gene with the others and, consequently, we applied L2C method in order to select only the direct interactions. Moreover, the conditional dependences were evaluated conditioning over only the genes in the signature because the study of Bild suggests that the interactions between the signature and the other genes on chip can be neglected.

The selection of the graph was performed by building 1000 bootstrap replications of the data and computing the 99,5% confidence interval of the statistics. The resulting network was composed of 2875 edges (see Additional file 4), where HRAS had 34 direct connections (Fig. 6
                           ).

We analyzed the 34 HRAS interacting genes with the TRANSFAC component of GATHER [9] to assess the significance of the presence of common potential transcription factor binding sites within their promoters. A very interesting finding was that the list of these 34 genes was enriched of the RREB1 (Ras responsive element binding protein 1) module with a p-value <0.0005. In fact, 9 of them (see Fig. 6) presented the RREB1 consensus binding site. On the contrary, the complete Ras signature did not exhibit enrichment for this module. RREB1 is a zinc finger transcription factor ubiquitously expressed in human tissues that binds to RAS-responsive elements (RREs) of gene promoters. Thiagalingam et al. [44] have demonstrated that RREB1 plays a role in Ras and Raf signal transduction in medullary thyroid cancer. In particular, they have shown that the binding of RREB1 to RRE of the calcitonin gene promoter during Ras- or Raf-induced differentiation increases expression of calcitonin in TT human medullary thyroid cancer cells. Our hypothesis is that the 9 genes directly connected to HRAS are involved in the downstream signaling of Ras through RREB1. One of them, EDG4, has been already found to be correlated to Ras signaling. EDG4 is the receptor for lysophosphatidic acid (LPA), a lipid growth factor and intracellular signaling molecule. It was demonstrated that the expression of a mutated form of Ras GTPase blocked LPA-induced cell migration [35]. This preliminary result suggests that our method is able to enlighten putative regulatory interactions that should be biochemically validated.

@&#CONCLUSIONS@&#

In the last few years many studies have highlighted the importance of analyzing direct as well as indirect interactions among genes and proteins for unveiling their roles in the onset and progression of complex and multifactorial diseases like tumors. This type of approach is alternative to the classical studies which address the problem of analyzing the association between genes and pathways with the phenotype [1,43]. To this end, many methods have been recently developed to infer gene regulatory networks by using gene expression data [4] in order to reveal putative dependencies among genes and their products. In this paper, we present a comparative study of three different methods to infer networks of conditional dependencies by estimating partial correlation coefficients in the typical situation when the number of observations n is small respect to the number p of variables. The methods and the procedures exploited for their comparison have been developed in the general frameworks of statistical learning theory and regularization theory [46], which constitute state-of-the-art approaches for the analysis and interpretation of data sets composed of a huge number of variables when only a few number of observations is available.

Methods which exploit partial correlation estimates for inferring gene regulatory networks from expression data offer a number of advantages with respect to methods based on mutual information (see for example [33]. In particular, although these methods provide a natural generalization of correlation since they take into account also non-linear dependences between variables, they are not able to assess conditional dependences between two variables in the case the number of conditioning variables is huge as in the context of gene regulatory networks [41].

In our simulation study, we limited our attention to methods which embody an L2 regularization term in their analytical formulation. Such methods, in general, offer more stable solutions with respect to Lasso methods which incorporate L1 regularization terms [27]. The main disadvantage of the adopted techniques for inferring conditional dependency graphs is that they provide non-sparse solutions. To circumvent this problem we have adopted a bootstrap technique which is able to reveal the conditional dependency between two variables with a given statistical significance.

The three analyzed methods were compared through an extensive and biologically inspired simulation study. This choice was adopted because the lack of a validated ground truth relative to biological networks prevents to compare methods by using real gene expression data. In particular, the need of simulated data arises from imperfect knowledge of real networks in cells, from the lack of suitable gene expression datasets, and of control of noise levels. In silico data enable one to check the performance of algorithm against a perfectly known ground truth [4].

Different measures were adopted for assessing the performances of the analyzed methods. Although we did not find a method which consistently outperformed the others in all the carried out simulations, we found that the ℓ2C
                      method provided the most predictive partial correlation estimates, as highlighted by the AUC analysis. More importantly, this method had the highest values of sensitivity showing its ability to infer true conditional dependencies between variables also when a few number of observations is available. Our study has shown that the ℓ2C
                      method is well suited for revealing conditional dependencies when the number of really conditioning variables is small if compared to p as in the case of genomic data.

The application of this method to real biological contexts allowed to infer gene networks with some known regulatory signals. In particular, it revealed a negative significant correlation between the expressions of HMGS and HDS, that we found to be the two hubs in the two isoprenoid pathways in A. thaliana.

This means that they respond differently to the several tested experimental conditions and, together with the high connectivity of the two hubs, provides an evidence of cross-talk between genes in the plastidial and the cytosolic pathways. This evidence did not result from studies at level of single gene. Moreover, studies that infer this network by using only low-order partial correlation coefficients find more interactions between the two pathways with respect to the ℓ2C
                      method. A reduced number of edges between the two pathways is plausible considering the different cell compartmentalization of the two isoprenoid biosynthesis pathways.

Moreover, the application of this method to a signature of HRAS oncogene permitted to reveal the presence of nine genes connected to HRAS, sharing the same Ras-responsive binding site for the transcription factor RREB1. This result suggests that the transcriptional activation of these genes is mediated by a common transcription factor downstream of Ras signaling.

In conclusion, our study has shown that the ℓ2C
                      method is able to infer GRNs with relevant putative interactions and to provide interesting biological hypotheses that should be biochemically validated.

NA, PFS, SM and FPS conceived the study. PFS, TMC and RA designed the algorithms and conduced the experiments; VCL analyzed the results from a biological point of view and, together with SM and NA they evaluated and compared the experimental results. All the authors read and approved the final manuscript.

@&#ACKNOWLEDGMENTS@&#

We thank Arturo Argentieri for his valuable technical support. This work has been supported in part by Grants from Regione Puglia PO FESR 2007–2013 Progetto BISIMANE (Cod. n. 44), Progetto FIRB RBAP11B2SX, Progetto di Ricerca Finalizzata 2009 RF/2009-1471624.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.jbi.2013.07.002.


                     
                        
                           Supplementary file 1
                           
                              AUC values and 95% confidence intervals for the clique pattern.
                           
                           
                        
                     
                  


                     
                        
                           Supplementary file 2
                           
                              AUC values and 95% confidence intervals for the hubs pattern.
                           
                           
                        
                     
                  


                     
                        
                           Supplementary file 3
                           
                              AUC values and 95% confidence intervals for the random pattern.
                           
                           
                        
                     
                  


                     
                        
                           Supplementary file 4
                           
                              List of the 2875 connections found for the HRAS signature.
                           
                           
                        
                     
                  

@&#REFERENCES@&#


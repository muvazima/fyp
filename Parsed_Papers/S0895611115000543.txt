@&#MAIN-TITLE@&#Multi-scale textural feature extraction and particle swarm optimization based model selection for false positive reduction in mammography

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Different multiscale textural descriptors are used to characterize breast tissue.


                        
                        
                           
                           Particle swarm optimization is used for selecting features and SVM parameters.


                        
                        
                           
                           Model selection fitness function incorporates performance and dimensionality reduction.


                        
                        
                           
                           The proposed methods are evaluated using both mini-MIAS and DDSM databases.


                        
                        
                           
                           Our results reveal the efficacy of PSO model selection for solving FPR problems.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

False positive reduction

Mammography

Multi-scale texture analysis

Model selection

Particle swarm optimization

Support vector machines

@&#ABSTRACT@&#


               
               
                  The high number of false positives and the resulting number of avoidable breast biopsies are the major problems faced by current mammography Computer Aided Detection (CAD) systems. False positive reduction is not only a requirement for mass but also for calcification CAD systems which are currently deployed for clinical use. This paper tackles two problems related to reducing the number of false positives in the detection of all lesions and masses, respectively. Firstly, textural patterns of breast tissue have been analyzed using several multi-scale textural descriptors based on wavelet and gray level co-occurrence matrix. The second problem addressed in this paper is the parameter selection and performance optimization. For this, we adopt a model selection procedure based on Particle Swarm Optimization (PSO) for selecting the most discriminative textural features and for strengthening the generalization capacity of the supervised learning stage based on a Support Vector Machine (SVM) classifier. For evaluating the proposed methods, two sets of suspicious mammogram regions have been used. The first one, obtained from Digital Database for Screening Mammography (DDSM), contains 1494 regions (1000 normal and 494 abnormal samples). The second set of suspicious regions was obtained from database of Mammographic Image Analysis Society (mini-MIAS) and contains 315 (207 normal and 108 abnormal) samples. Results from both datasets demonstrate the efficiency of using PSO based model selection for optimizing both classifier hyper-parameters and parameters, respectively. Furthermore, the obtained results indicate the promising performance of the proposed textural features and more specifically, those based on co-occurrence matrix of wavelet image representation technique.
               
            

@&#INTRODUCTION@&#

According to statistics provided by the World Health Organization (WHO) breast cancer was responsible for 458,000 deaths in 2008 worldwide and is a leading cause of women death around the world. Since the effective prevention of breast cancer occurrence is still impossible, the detection and diagnosis of the disease at its early stage is a significant step towards an increased breast cancer survival rate. Mammography, an X-ray based breast imaging modality, is currently the most effective tool for breast cancer screening. However, mammogram interpretation, even done by expert radiologists, is a difficult and error prone task due to the low contrast of the images and the subtle signs of breast cancer early stage. Such a misinterpretation of mammograms not only results in a low positive prediction value of mammography, which in turn leads to many unnecessary invasive biopsies and high recall rates [1], but also causes many life-threatening false negatives.

A double reading or second mammogram interpretation of the same data by another radiologist has shown a significant increase of cancer detection reducing the number of undiscovered lesions [2,3]. However, such a double reading procedure is not always feasible, since it has to be done by an expert radiologists. An alternative to a human double reading is the Computer Aided Diagnosis (CAD) technology, which is intended to provide radiologists with a second opinion by warning them about unnoticed breast abnormalities and by assisting in characterizing the malignancy of detected lesions. Several studies have shown that CAD technology has the potential to significantly improve the early detection of breast cancers [3]. Gromet et al. [4] reported that combining a CAD system with a single reading by radiologists has improved the detection sensitivity of breast cancer by 10% with small increase of the recall rate.

Due to the fact that the detection of breast masses, which resemble normal breast parenchyma, is more challenging than the detection of microcalcifications, some of the CAD systems have been clinically approved and are currently used for calcifications detection but not for masses. However, even for calcifications, the main drawback of existing CAD technology is the high number of false positives [3]. A false positive of mammogram interpretation occurs, when a normal breast region is marked suspicious and consequently an increase of unnecessary breast biopsies is encountered. Such a low detection specificity (or high false positives rate) is mostly the reason behind the argument concerning the role of CAD technology.

Rather than developing new mass detection algorithms which produce satisfactory cancer detection results, several studies [5–12], have recently devoted efforts to develop False Positive Reduction (FPR) methods that aim to improve the specificity of mass detection and the efficacy of CAD technology, and its potential as a mammography double reading stage. Generally, a FPR algorithm can be seen as post-processing or complementary stage, which is intended to reduce the false positive results produced by a predecessor computer aided detection system. Similar to most CAD systems, FPR algorithms solve the pattern recognition problem of discriminating a suspicious mammogram region as normal breast parenchyma or breast region with a benign or malignant lesion in three steps: feature extraction, dimensionality reduction by feature selection, and binary classification based on supervised learning. Methods and datasets used for implementing previous FPR systems are the key factors behind the achieved performance levels. A brief review of recent literature on FPR algorithms and methods used for implementation is given subsequently.

Angelini et al. [5] reduced false positive results of mass detection using a wavelet based image representation and SVM classifier with polynomial kernel. In this study, wavelet coefficients from discrete and over-complete (without the decimation step) wavelets based on Haar filters were used. Evaluating both pixel based and wavelet based approaches on 5000 mammograms (1000 regions depicting masses and 4000 representing normal breast tissue) they demonstrated the advantage of using pixel based representation over wavelet based method. Rashed et al. [6] used wavelet based image analysis of mammograms with a fraction of wavelet coefficients (the biggest coefficients) as a feature vector to classify different types of breast abnormalities including speculated lesions. Oliver et al. [7] used 2D Principal Component Analysis (2DPCA) image representation and combined decision tree and k-nearest neighbour classifier. Varela et al. [9] discriminated mammographic regions depicting true masses from normal regions using a combination of shape and texture features, and Back-Propagation Neural Network (BPNN) classifier. Local Binary Patterns (LBP) of gray-level image and SVMs with a polynomial kernel were used to improve the specificity of mass detection in [8]. Ramos et al. [10] evaluated and compared the performance of a small number of Haralick descriptors computed from co-occurrence matrices of gray level, wavelet, and ridgelet image representations. For the feature selection task they incorporated Genetic Algorithm (GA) and, in the ROIs classification stage, they suggested the random forest method. Hussain et al. [11] presented a FPR algorithm using texture features acquired through Multi-Scale Weber Law Descriptor (MSWLD) and SVM classifier. The obtained results proved better performance of MSWLD approach compared to LBP based technique used by Lladó et al. [8]. Recently, Braz et al. [12] used biologically inspired diversity indices as texture descriptors to discriminate mass from none-mass regions.

Although the low positive predictive value is a common problem for CAD systems supporting different breast lesions, existing FPR algorithms have focused on improving the specificity of mass detection only. However, even for this, existing algorithms require further improvements. Particularly, the feature extraction and parameter selection methods used for solving the FPR problem need several important steps to be done to achieve the desired performance. Some studies [5,6] used wavelet coefficients or a fraction of the coefficients as descriptors, or computed a few descriptors with one wavelet basis function to generate the multi-scale image analysis [10]. However, wavelet based feature extraction has not been well examined with respect to the techniques used for computing multi-scale textural descriptors and for the wavelet basis functions to produce multiresolution analysis.

In this paper, breast tissue is characterized using different multi-scale textural features based on first and second order statistics of gray level and wavelet image representations. More specifically, First Orders Statistics of Wavelet Coefficients (FOSWC) based on energy and entropy features, co-occurrence (or Haralick) descriptors of both image gray levels, and wavelet coefficients are introduced. Although the application of wavelet theory and co-occurrence matrices for texture analysis of mammograms is not new, this paper represents a substantial improvement of the existing studies [5,6]. That is, this work examines more wavelet functions for generating multiresolution image representation, evaluates different global descriptors [13–15] obtained from different scales rather than directly using wavelet coefficients as features [5] or even use a single wavelet function, and assesses a few Haralick descriptors [10]. Moreover, this work presents and appraises new multi-scale Gray-Level Co-occurrence Matrices (GLCM) descriptors by combining different pixel distances.

Good generalization capacity, low classification errors on different classes and low data over-fitting are required for an efficient FPR algorithm. Hence, proper methods for performing pattern classification, feature selection and classifier performance optimization need to be adopted. For accomplishing the classification stage along with the feature selection and classifier parameters tuning, PSO-SVM is an efficient alternative [16]. Further performance improvement and design flexibility can be achieved by extending PSO based parameter tuning to a full model selection process [17]. Another key and important contribution of this paper is the application of PSO based model selection to solve FPR problem. The proposed model selection improves the performance by optimizing the feature extraction process, accomplishing feature selection, and by choosing optimal hyper-parameters and parameters for the SVM classifier. Although there are several methods for accomplishing parameter selection, the ease of implementation and simplicity of PSO based heuristic search make it more attractive than GA, grid, and exhaustive search techniques [18,17]. The PSO algorithm, introduced by Eberhart and Kennedy in 1995, is a biologically and population-based heuristic search approach, where a group of individuals located in the parameter space of an objective function searches for the optimal solution. Since the introduction of the PSO algorithm several refinements [40,41] and applications [17,19,42–44] have been proposed. An ensemble particle swarm model selection was applied for the determination of leukaemia type using morphology of the bone marrow. Dheeba et al. [43] employed a PSO algorithm to optimize a neural network classifier that, subsequently, is used for textural-based detection of mammographic microcalcification. Guarniz et al. [44] proposed the modification of the wavelet analysis by applying PSO method to optimize the wavelet filter basis function and number of decomposition levels applied to an EEG signal. Adam et al. [45] also used PSO for accomplishing feature and classifier parameter selection stages associated with the EEG signals peak detection problem. To the best of our knowledge, PSO model selection has not been applied before for optimizing the performance of FPR algorithms in general and mass FPR in particular. It should be noted that PSO-SVM approach in [19] was used for optimizing the diagnosis of calcifications rather than for detection or false positive reduction. The last distinction from the existing literature is that this paper proposes solutions to false positive reduction problem associated with the detection of all breast abnormalities (masses and calcification) as well as mass detection.

The remaining sections of this paper are organized as follows: Section 2 presents the theoretical background of methods used in this paper. Section 3 provides the details of proposed texture feature extraction and model selection techniques. Results and Conclusions are discussed in Sections 4 and 5, respectively.

Image texture is described as the systematic local variation of pixels intensities [20]. In addition to applying image texture analysis to produce image features for pattern recognition, it can be also used to group image pixel into predefined regions. Such clustering or grouping can be further used for image segmentation. In literature, several metrics have been developed and applied to texture analysis of medical images [15,21]. Texture descriptors are derived from: (1) first order statistic of pixel intensity, (2) subband and multi-scale image representation using wavelet transforms, (3) Laws measures of textures, and (4) second order histogram or statistics of pixel intensities using GLCMs. In the following subsections, necessary details of texture descriptors derived from wavelet image decomposition and GLCM are provided.

A multiresolutional ability of wavelet transform has led to many successful applications in the digital image processing area. An efficient implementation of multi-scale analysis of 2D Discrete Wavelet Transform (DWT) of digital images is based on Mallat algorithm [22]. It decomposes a digital image into a complete set of scales (one approximate and several detail subbands) by means of high-pass and low-pass signal filtering based on separable one dimensional filter banks followed by a down sampling operation. From the wavelet transform theory, a set of time series f(t) can be represented by the sum [23]
                           
                              
                                 (1)
                                 
                                    f
                                    (
                                    t
                                    )
                                    =
                                    
                                       ∑
                                       k
                                    
                                    
                                       c
                                       
                                          
                                             J
                                             0
                                          
                                       
                                    
                                    (
                                    k
                                    )
                                    
                                       2
                                       
                                          
                                             
                                                
                                                   J
                                                   0
                                                
                                             
                                             2
                                          
                                       
                                    
                                    ϕ
                                    (
                                    
                                       2
                                       
                                          
                                             J
                                             0
                                          
                                       
                                    
                                    t
                                    −
                                    k
                                    )
                                    +
                                    
                                       ∑
                                       k
                                    
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          
                                             J
                                             0
                                          
                                       
                                    
                                    
                                       d
                                       j
                                    
                                    (
                                    k
                                    )
                                    
                                       2
                                       
                                          
                                             j
                                             2
                                          
                                       
                                    
                                    ψ
                                    (
                                    
                                       2
                                       j
                                    
                                    t
                                    −
                                    k
                                    )
                                    ,
                                 
                              
                           where ϕ(t) and ψ(t) are scaling and wavelet function, respectively, forming an orthogonal basis of the signal space. Given the basis, a signal f(t) can be represented by a set of scaling coefficients 
                              {
                              
                                 c
                                 
                                    
                                       J
                                       0
                                    
                                 
                              
                              (
                              k
                              )
                              }
                            and wavelet coefficients 
                              
                                 
                                    {
                                    
                                       d
                                       j
                                    
                                    (
                                    k
                                    )
                                    }
                                 
                                 1
                                 
                                    
                                       J
                                       0
                                    
                                 
                              
                           , where k is the time shift factor.

According to Mallats algorithm [22] both coefficient sets can be calculated by cascade Finite Impulse Response (FIR) filtering with a low-pass filter derived from the scaling function and a high-pass filter derived from the wavelet one. Assuming a N-level decomposition of a two-dimensional image I, the DWT can be defined for each dimension separately. Therefore, the image is decomposed into a pyramidal structure with one approximate (A) and a set of detail components D
                           
                              i
                           , i
                           =1, …, 3:
                              
                                 (2)
                                 
                                    I
                                    =
                                    
                                       A
                                       N
                                    
                                    +
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       N
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       3
                                    
                                    
                                       D
                                       i
                                    
                                    .
                                 
                              
                           
                        

In terms of wavelet function properties like orthonormal, compact support, and the number of vanishing moments several wavelet families have been introduced in literature [24,25]. A simple but useful approach to produce textural features from wavelet representation is computing a set of multi-scale global descriptors based on the first order statistic measures such as energy and entropy descriptors [14].

Haralick textural features [26], derived from GLCM, are common descriptors for image texture analysis and recognition. This approach is based on characterizing the second order histogram of image gray level values.

A GLCM of an image with L gray level values is a two-dimensional directional matrix that models the second order statistics of the image intensity by measuring the probability of occurrence of two gray level values (i, j), 1<
                           i, j
                           <
                           L apart by a predefined distance d and direction θ. For a digital image of the size N
                           ×
                           M pixels, the distance d separating two gray levels can take any value between 0 and L
                           −1. In accordance to the discrete nature of digital images only four directions θ
                           ∈{0°, 45°, 90°, 135°} are allowed. For a certain distance d, a group of four directional GLCMs of size L
                           ×
                           L is obtained. Using the method introduced by Haralick et al. [26], up to 14 texture measures can be derived from each co-occurrence matrix. Moreover, multi-scale second order statistics [15,27] can be obtained by constructing co-occurrence matrices from each image subbands of wavelet coefficients.

SVM is a learning technique based on the structural risk minimization principle able to solve two-group classification problems [28]. It permits an optimal hyperplane data separation. Let be a set of training samples X
                        ∈
                        x
                        1, x
                        2, …, x
                        
                           l
                         and their labels Y
                        ∈
                        y
                        1, y
                        2, …, y
                        
                           l
                         such that y
                        
                           i
                        
                        ∈{−1, 1}. The training data is linearly separable, if exists a vector w and scalar b fulfils the inequalities:
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   w
                                                
                                             
                                             T
                                          
                                          
                                             
                                                
                                                   x
                                                
                                             
                                             i
                                          
                                          +
                                          b
                                          ≥
                                          1
                                          ,
                                       
                                       
                                          if
                                             
                                          
                                             y
                                             i
                                          
                                          =
                                          1
                                          ,
                                       
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   w
                                                
                                             
                                             T
                                          
                                          
                                             
                                                
                                                   x
                                                
                                             
                                             i
                                          
                                          +
                                          b
                                          ≤
                                          −
                                          1
                                          ,
                                       
                                       
                                          if
                                             
                                          
                                             y
                                             i
                                          
                                          =
                                          −
                                          1
                                          .
                                       
                                       
                                    
                                 
                              
                           
                        
                     

The vector w and scalar b are called weight vector and bias or threshold, respectively. The separating hyperplane is then given by
                           
                              (4)
                              
                                 
                                    
                                       
                                          w
                                       
                                    
                                    T
                                 
                                 
                                    
                                       
                                          x
                                       
                                    
                                    i
                                 
                                 +
                                 b
                                 =
                                 0
                                 ,
                              
                           
                        and vectors x
                        
                           i
                         for which y
                        
                           i
                        (w
                        
                           T
                        
                        x
                        +
                        b)=1 are referred to as support vectors. The hyperplane parameters are computed by solving the quadratic programming problem 
                           min
                           :
                           
                              
                                 ∥
                                 
                                    
                                       w
                                    
                                 
                                 
                                    ∥
                                    2
                                 
                              
                              2
                           
                        , with following constraints: y
                        
                           i
                        (w
                        
                           T
                        
                        x
                        +
                        b)≥1; ∀
                        i
                        ∈{1, …, l}.

The method brings also an efficient solution for N-dimensional non-linear separable data, which are transformed into an N dimensional features space, where the linear classification is possible. The transformation is performed by replacing scalar product of the two transformed vectors (u, v) using kernel function K(u, v) [29].

PSO is a population based heuristic search approach inspired by the social behaviour of flocks of birds and schools of fish [30]. A group of individuals (particles) represents the problem candidate solutions, which are located in the parameter space of an objective function searching for the optimal solution. The fitness of an individual particle (or a candidate solution) is the value of the objective function computed for that particle. Similar to other evolutionary computation techniques, including GAs, PSO also optimizes the fitness of its particles using the experience and fitness so far achieved by the population. However, PSO uses a velocity operator rather than the cross-over and mutation to control and update location and search direction of individual particles.

During the PSO optimization process, records of the best fitness (or personal fitness) values achieved so far by each particle, which are denoted as pBest, and the best fitness value obtained by the entire population, referred to gBest are maintained. The locations of both the best personal fitness 
                           
                              x
                              ki
                              pBest
                           
                         achieved by kth particle and global fitness 
                           
                              x
                              i
                              gBest
                           
                         are used to compute ith dimension velocity (i
                        =1, 2, …, D) and the new position of kth particle as follows
                           
                              (5)
                              
                                 
                                    v
                                    ki
                                 
                                 (
                                 t
                                 +
                                 1
                                 )
                                 =
                                 
                                    wv
                                    ki
                                 
                                 (
                                 t
                                 )
                                 +
                                 
                                    c
                                    1
                                 
                                 
                                    r
                                    1
                                 
                                 (
                                 
                                    x
                                    ki
                                 
                                 (
                                 t
                                 )
                                 −
                                 
                                    x
                                    ki
                                    pBest
                                 
                                 )
                                 +
                                 
                                    c
                                    2
                                 
                                 
                                    r
                                    2
                                 
                                 (
                                 
                                    x
                                    ki
                                 
                                 (
                                 t
                                 )
                                 −
                                 
                                    x
                                    i
                                    gBest
                                 
                                 )
                                 ,
                              
                           
                        where D is the dimensionality of the kth particle, 
                           w
                         is the inertia weight of the movement intended to provide a compromise of the personal and global exploration [18], r
                        1 and r
                        2 are random numbers between [0,1], and c
                        1 and c
                        2 are non-negative constants representing the personal and social learning rates. To control the search speed, the ith velocity 
                           
                              v
                              ki
                           
                           (
                           t
                           )
                         is constrained by the user to be in the range 
                           [
                           
                              v
                              min
                           
                           ,
                           
                              v
                              max
                           
                           ]
                        .

Using the velocity computed in (5), the location of each particle i, i
                        =1, 2, …, D is updated as
                           
                              (6)
                              
                                 
                                    x
                                    ki
                                 
                                 (
                                 t
                                 +
                                 1
                                 )
                                 =
                                 
                                    x
                                    ki
                                 
                                 (
                                 t
                                 )
                                 +
                                 
                                    v
                                    ki
                                 
                                 (
                                 t
                                 +
                                 1
                                 )
                                 .
                              
                           
                        
                     

Extracting suitable features is one of the most important steps in the classification task. There exist different feature extraction methods described in literature [6,9,14,15], which are considered in mammography data analysis. In this work, both the first and second order statistics of wavelet coefficients as well as GLCM features and their combinations are used. Several studies [10,13,14] used Daubachies wavelet family to accomplish statistical texture analysis of digital mammograms.

In our approach four wavelet filters, namely, Db1 (Haar), Db3, Sym8, and Sym20 from Daubechies and Symlets wavelets families are used. Each image region representing an abnormal or normal class is analyzed using three-level DWT transform producing a multi-scale representation of 10 wavelet image subbands. From each subband with the size of M
                        ×
                        N coefficients, a set of two FOSWC descriptors, namely, the normalized energy E and entropy S are obtained as [14]:
                           
                              (7)
                              
                                 E
                                 =
                                 
                                    
                                       
                                          ∑
                                          i
                                       
                                       
                                          ∑
                                          j
                                       
                                       |
                                       
                                          x
                                          ij
                                       
                                       
                                          |
                                          2
                                       
                                    
                                    
                                       M
                                       ×
                                       N
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (8)
                              
                                 S
                                 =
                                 −
                                 
                                    
                                       
                                          ∑
                                          i
                                       
                                       
                                          ∑
                                          j
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      |
                                                      
                                                         x
                                                         ij
                                                      
                                                      
                                                         |
                                                         2
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               ∑
                                                               i
                                                            
                                                            
                                                               ∑
                                                               j
                                                            
                                                            |
                                                            
                                                               x
                                                               ij
                                                            
                                                            
                                                               |
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          log
                                          2
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      |
                                                      
                                                         x
                                                         ij
                                                      
                                                      
                                                         |
                                                         2
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               ∑
                                                               i
                                                            
                                                            
                                                               ∑
                                                               j
                                                            
                                                            |
                                                            
                                                               x
                                                               ij
                                                            
                                                            
                                                               |
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          log
                                          2
                                       
                                       (
                                       M
                                       ×
                                       N
                                       )
                                    
                                 
                                 ,
                              
                           
                        where x
                        
                           ij
                         is a wavelet coefficients within a subband image.

Applying this textural feature extraction process to each image region produces a set of 20 FOSWC descriptors. Computing energy and entropy descriptors from the multi-scale image representation, produced by the DWT, only characterizes the first order histogram of wavelet coefficients. Unlike energy and entropy features, GLCM texture features characterize the second order histogram of image values. The application of GLCM features to accomplish FPR in mammography is not new [10]. However, rather than using only a few GLCM descriptors that model the anisotropic properties of mammographic patterns, this work explores and computes more GLCM descriptors and combines the four directional values of each descriptor into one summary textural feature [14]. Besides using common GLCM features [14,15,26] we also propose a new multi-scale textural descriptor, obtained by concatenating GLCM textural features from different distances d, d
                        ∈{1, 3, 6, 9}.

To avoid producing sparse co-occurrence matrices and maintain a manageable computational complexity, the maximum number of gray levels is limited to 256 (or 8-bit pixel depth). After constructing a four-directional GLCM matrices from the image region, 14 GLCM textural descriptors are computed from each directional matrix. For accomplishing FPR task, a set of 14 Haralick descriptors are incorporated: entropy, energy, contrast, homogeneity, variance, sum average, difference variance, difference entropy, sum variance, correlation, sum entropy, normalized inverse difference, information measure of correlation I, and information measure of correlation II. Furthermore, GLCM textural descriptors used for classification, computed as the mean, standard deviation, and the range of the four values of each descriptor calculated from GLCMs corresponds to four directions. Using this step, a set of 42 GLCM texture features are extracted from each image region. This process was also used to generate GLCM features corresponding to different distances d, d
                        ∈{1, 3, 6, 9}.

To accomplish texture analysis of mammographic images in a more efficient way the combination of multi-scale properties of wavelet transform and the Haralik approach for modelling second order statistics is used. Instead of constructing a co-occurrence matrix from image (or gray level) values, in this study, a computation of the co-occurrence matrices from wavelet coefficients of different image subbands, produced by dyadic wavelet decomposition, is performed. Then, the Haralic approach is applied to analyze the second order statistic of wavelet coefficients in each image subbands and to compute the 14 textural features. Multi-scale textural descriptors that are produced using this methodology are called Second Order Statistics of Wavelet Coefficients (SOSWC). From the 10 image subbands of the three-level multi-scale image analysis, a set of 140 SOSWC texture features is computed and used to represent each mammographic region.

FPR algorithms are mainly intended to achieve a minimum or at least a balanced classification error level when classifying specious mammogram areas into normal (true negative) and abnormal (true positive) regions. Hence, a full model selection [17] can be an efficient solution for accomplishing the false positive reduction task and for improving the detection performance in mammography. A full model selection [17] is basically a framework that can simultaneously search and optimize the selection of data preprocessing techniques, feature extraction and selection method, classification algorithm, as well as hyper-parameters and control parameters of the classifiers. Furthermore, model selection can also be used to denote an optimization task that involves classifier parameter optimization and feature selection [16,17,19,31,32]. The process of model selection involves: creating a search pool or a set of potential feature extraction, feature ranking and selection, supervised learning techniques and a method for tuning the candidate solutions to achieve the desired result, and a criterion for evaluating the fitness of each solution. Using an exhaustive parameter search for selecting the best model is impractical and computationally expensive. Fortunately, population based heuristic suitable for handling such a model selection task. The proven performance of the PSO, the simplicity of the PSO search process as well as the ease of the PSO implementation with small number of variables to be adjusted during initialization and search process, make PSO technique more favourable for implementing model selection than GAs and other evolutionary algorithms [17,18]. The PSO algorithm accomplishes an optimization task without mutation and cross over operations, which are essential steps of GAs [18].

For this work, a model selection based on the PSO shown in Fig. 1
                        , is adopted for optimizing the performance of a texture based FPR algorithm. Fig. 1 demonstrates that the fitness of each candidate learning model is estimated using a K-fold cross-validation procedure, which through k-times of training and testing steps enables testing the candidate solution on the entire data available for cross-validation purpose. In the coming subsections, details of the model selection criterion are explained.

With the use of the PSO search algorithm for accomplishing the model selection, each PSO particle represents a candidate solution for the model selection task and it is characterized by its location in the parameter space. The location of each candidate solution or PSO particle is represented by a D-dimensional vector x
                           =[x
                           1, x
                           2, …, x
                           
                              D
                           ]
                              T
                           . During the search process some constraints or parameter space limitation may apply to some of the coordinates. They depend on the pre-assigned selection task (feature selection or parameter optimization for classification) for various coordinates. In this work, a continuous version of the PSO algorithm is used. It means, that most components of the parameter space and, thus, particle coordinates are real numbers.

For this study, the model selection search pool contains different feature extraction techniques and SVM classification approaches including linear and nonlinear methods. Depending on the selected classification method it includes different hyper-parameters and parameters search spaces.

The selected feature extraction method also determines dimensionality of search space to be used for the feature selection process. Based on this model selection problem and parameter search pool, each PSO particle, which is a candidate solution to model selection problem, is structured as follows:
                              
                                 (9)
                                 
                                    x
                                    =
                                    
                                       
                                          [
                                          
                                             x
                                             FE
                                          
                                          ,
                                          
                                             x
                                             SVM
                                          
                                          ,
                                          
                                             x
                                             
                                                Para
                                                1
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             x
                                             
                                                Para
                                                4
                                             
                                          
                                          ,
                                          
                                             x
                                             
                                                F
                                                1
                                             
                                          
                                          ,
                                          …
                                          ,
                                          
                                             x
                                             FN
                                          
                                          ]
                                       
                                       T
                                    
                                    ,
                                 
                              
                           where x
                           
                              FE
                            is the first coordinate assigned for selecting the feature extraction method, x
                           
                              SVM
                            is the second coordinate responsible for classifier selection by choosing among four SVM classifiers (one linear and three nonlinear or kernel based), x
                           
                              Para1 is used for SVM classifier parameters and particularly the SVM regularization constant applicable for both linear and nonlinear SVMs. The kernel control parameters are x
                           
                              Para2, x
                           
                              Para3, x
                           
                              Para4. The remaining N coordinates are used for classifier hyper-parameter selection and more specifically for feature selection.

Using particle presentation in (9), each candidate solution has a dimensionality of D
                           =6+
                           N
                           
                              max
                            with N
                           
                              max
                            representing the maximum size of the possible input feature spaces. In each iteration of the PSO based model selection, the solution represented by each particle is evaluated by computing its fitness value (10).

An efficient FPR algorithm must avoid producing a perfect false positive rate at the expense of an inadequate false negative level. Besides providing the best balanced classification error level (compromise between the false positive and false negative rates), the optimized models need to achieve the desired performance while maintaining low dimensionality of the feature space. According to these objectives, we have proposed a model selection optimization measure as in (10). The Fitness
                              CV
                            of candidate solutions is estimated using a k-fold cross-validation procedure:
                              
                                 (10)
                                 
                                    
                                       Fitness
                                       CV
                                    
                                    =
                                    max
                                    (
                                    FPF
                                    ,
                                    FNF
                                    )
                                    +
                                    β
                                    
                                       
                                          
                                             exp
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  (
                                                                  n
                                                                  −
                                                                  1
                                                                  )
                                                               
                                                               2
                                                            
                                                         
                                                         
                                                            
                                                               N
                                                               2
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             −
                                             1
                                          
                                       
                                    
                                    ,
                                 
                              
                           where FPF and FNF represent false positive and false negative fractions, which measure the classification error from both negative and positive classes, respectively. Next, n is the number of features selected by the candidate model, N represents the dimensionality of the original feature space, and β is a normalization constant.

@&#EXPERIMENTAL RESULTS@&#

Mammogram suspicious regions used for evaluating the proposed FPR algorithms are from the Digital Database for Screening Mammography (DDSM) [33] and Mammographic Image Analysis Society (mini-MIAS) database [34] or simply MIAS. Digitized mammograms from both DDSM and MIAS are diagnosed with a biopsy proven breast abnormality and accompanied with ground truth files that include annotation of breast lesions if present. In constructing the DDSM database, different scanners of pixel resolutions ranging from 42μm×42μm to 50μm×50μm were used. Mammogram images of this database are available in two formats: LJPEG compressed images with 12 bits per pixel and PNG format with 16 bit pixel depth [35] that is used in this paper. Radiologists annotations of abnormal DDSM cases were included in.ics file, which describe the lesion severity degree (malignant or benign), the lesion location, type (mass or calcification), mass shape and margin, and last of all the classification distribution according to the Breast Imaging Reporting and Data System (BI-RADS) lexicons [36]. On the other hand, MIAS data were originally built from mammography films digitized at 50 pixel resolution. Then, digitized mammograms were down-sampled to 200μm pixel resolution and 8 bit per pixel.

The scope of this work is developing a FPR algorithm that can validate suspicious regions marked by a user or a computer aided detection system. In this paper, suspicious regions used for evaluation were extracted from MIAS and DDSM databases similar to the approaches used in [38,39], respectively. That is, obtaining suspicious regions representing the true positive class was accomplished using the ground truth information of abnormal cases provided by the two databases. The size of abnormal (or true positive) region, in pixels, is a rectangular region of the bounding box that depicts the abnormal area (or lesion) using the provided annotation. Such an extraction process produces true positive regions of different sizes. On the other hand, the extraction of suspicious regions representing the true negative class was done by cropping both normal and abnormal mammograms to extract regions of 384×348 pixels. Indeed, the region size of 384×348 pixels is the average size of true positive regions. Moreover, for extracting the true negative regions, the cropping process was done such that they do not overlap abnormality (if the same mammogram is used to extract true negative and positive samples) and are not located within a background or in the pectrol muscle regions. Following these criteria, two datasets o regions are extracted from MIAS and DDSM databases. For MIAS, a set of 315 regions: 108 true positive regions (78 masses and 30 calcification clusters) and 207 true negative regions are obtained. Similarly, a set of 1494 suspicious regions, of which 494 regions (300 masses and 194 calcification clusters) are true positive samples and 1000 true negative regions, were extracted from the DDSM database. Examples of mammographic regions used in this work are shown in Fig. 2
                        .

The proposed FPR algorithms including the PSO model selection, textural feature extraction, and SVM based classification methods were all implemented or compiled [37] in Matlab. As for the settings of the PSO algorithm, the swarm size was set to 50 particles. The representation of each PSO particle followed the explanation discussed in Section 3.2. Further, the population of the swarm was initialized assuming that each parameter belongs to a random variable that is uniformly distributed in the corresponding search space. As for PSO parameters controlling the search process: c
                        1 and c
                        2 were both set to 2, inertia 
                           w
                         monotonically decreased from 1.2 to 0.4 as the number of iteration increased. The PSO search process was terminated, if a maximum number of iterations up to 50 was reached or a predefined fitness level of 0 was achieved, whichever criteria was met first. The maximum number of iterations and the population swarm size of 50 particulars used in this study, for performing the PSO-based model selection, were determined empirically. Our preliminary experimental work indicated that the use of a small population of just few numbers of particles (e.g. 10) or limiting the number of iterations to 10 produced inadequate performance in terms of the dimensionality of the optimized feature space and the attained false positive and false negative rates. Moreover, the use of a larger population size and a higher maximum number of iterations was avoided because of the high execution time required to perform a model selection run.

Mammogram regions used in this work were partitioned into 2/3 portion for training as well as cross-validation and 1/3 for testing purposes. Three training-test data sets have been constructed considering that no-overlap occurred between samples of each train-test set. The training data portion was further partitioned according to the k-fold CV procedure to accomplish the model selection and to produce cross-validation performance of the optimized models. The fitness of each PSO particle, that is a candidate solution to the model selection task, was estimated using 5- and 10-fold cross-validation procedures for DDSM and MIAS datasets, respectively. The difference in the number of folds for the cross-validation was due to the difference in the number of samples from the two databases, meaning the number of DDSM samples is about 5 times the size of MIAS samples.

For implementing all-lesion FPR algorithms, partitioning the DDSM data provided 996 samples for cross-validation and 498 for testing purposes. As for the MIAS data set, 207 samples were used for model selection and 108 for testing purposes. In case of mass FPR systems implementations on DDSM, regions with calcifications were excluded and previous data partitioning process was applied again. This produced 900 samples (600 true negatives and 300 true positives) with 600 (200 masses and 400 normal regions) samples used for cross-validation performance and 300 samples for testing. As for the evaluation of mass FPR methods on MIAS database, the cross-validation dataset that was only available, contained 59 masses and 118 normal regions. In all these experiments, the ratios of true positive to true-negative samples were 1/2.

@&#RESULTS@&#

The proposed PSO based model selection, wavelet and GLCM based textural features were used to optimize the classification of specious mammogram regions into negative samples and positive samples that depict true abnormalities. The experimental work, which will be presented subsequently, was intended to demonstrate the advantages of using PSO model selection of FPR algorithms and to evaluate different multi-scale texture feature sets. More specifically, this work has examined the effect of wavelet filter on the performance of multi-scale wavelet features (FOSWC and SOSWC) as well as the effects of varying the pixel distance d on the performance of corresponding GLCM textural descriptors. This work has also included results of FPR algorithms without feature selection and with the grid search used for optimizing SVM classifier parameters.

For the evaluation of all-lesion and mass-only FPR algorithms, the cross-validation and test performance were reported. However, in the evaluation of mass FPR algorithms using the MIAS dataset only cross-validation results were reported. This is due to the fact that available number of true positive regions with masses is insufficient to accomplish training and testing on two independent sets. The cross-validation performance, in terms of FPF
                           CV
                        , FNF
                           CV
                         and Accuracy
                        
                           CV
                        , of each single FPR algorithm (a combination of the feature extraction method and optimal classifier parameters) was obtained from the average results of all runs of three training sets. Similarly, the test performance using FPF
                           Test
                        , FNF
                           Test
                        , Accuracy
                        
                           Test
                         and Az
                        
                           Test
                         was obtained as the average of the best performance from three test sets. The average size of the optimized feature spaces for both cross-validation and testing phases were denoted as N
                        
                           CV
                         and N
                        
                           Test
                        , respectively.

The classification results of applying different all-lesion FPR algorithms to test data from MIAS and DDSM databases, were used to construct the receiver operating characteristics (ROC) curves shown in Figs. 3 and 4
                        
                        , respectively. Moreover, ROC curves for various mass FPR algorithms, applied to DDSM test data, were generated and presented in Fig. 5
                        . Although we have reported the test performance of various FPR algorithms in terms of FPF
                        
                           Test
                        , FNF
                        
                           Test
                        , and Az
                        
                           Test
                         value of corresponding ROC curve, only FPF
                        
                           Test
                         and FNF
                        
                           Test
                         metrics will be employed for results discussion and in comparing the performance of different textural feature sets. Performance in terms Az
                        
                           Test
                         est will be used for comparing with related studies from literature.

The experimental work of this study was started by applying the PSO based model selection with the search pool formed using all modalities. This means, that the search pool included 13 different sets of texture features obtained using three extraction techniques, namely, FOSWC, GLCM, and SOSWC method. The search pool also included four approaches for accomplishing supervised learning based on linear and nonlinear SVM classifiers. Results of these experiments on MIAS dataset demonstrated the effectiveness of model selection using PSO even with a small swarm size of 10 particles or candidate solutions with the best average FPF and FNF results obtained using SOSWC texture features in general and from Db3 in particular. As for accomplishing the supervised learning step, the nonlinear SVM with Radial Basis Function (RBF) kernel were more efficient than with polynomial and sigmoid kernels or the linear SVM. Besides these preliminary results, the RBF kernel function is generally a more favourable option than other kernels for implementing SVM classifiers and so for accomplishing the model selection task. Specifically, employing a sigmoid kernel may have a problem of producing none-positive definite kernel matrix, and the computation complexity of polynomial matrix tends to be challenging for larger polynomials order.

Moreover, having some feature sets dominating others by producing high classification performance in every run of PSO model selection approach did not allow fair evaluations of the other feature sets that provided inferior performances. For example, SOSWC (from DB3) textural features constantly outperformed other versions of SOSWC features as well as other methods (FOSWC and GLCM). Multi-scale GLCM (namely MDGLCM), were also better than other single-distance GLCM textural feature sets.

To evaluate the performance of each multi-scale texture feature extraction method exclusively, the model selection search pool was refined so, the search pool and corresponding parameter space was limited to one feature extraction technique at time. For the classification stage, for selecting SVM classifier kernel function and considering previous discussion, a nonlinear SVM with RBF kernel was used for accomplishing the classification stage while evaluating each feature extraction method. The results of these experiments are presented in the following subsections.

As explained in Section 3.1, each suspicious region was represented using 20 FOSWC textural features serving as energy and entropy of wavelet coefficients of 10 image subbands. These subband images were obtained from a three-level wavelet analysis of the region. The results of using FOSWC textural feature sets from four wavelet filters in accordance with the PSO model selection, which is applied to optimize the detection of all-lesion (masses and calcifications), are presented in Tables 1 and 2
                           
                           , while results of mass-only FPR algorithms are in Tables 3 and 4
                           
                           .


                           Performance of all-lesion FPR. Cross-validation results from Table 1 show that FOSWC features from Sym20 wavelet filter produced an average FPF
                              CV
                            of 0.163±0.023 (and FNF
                              CV
                            of 0.182±0.013) and 0.160±0.022 (and FNF
                              CV
                            of 0.171±0.023) on DDSM and MIAS datasets, respectively. These results of using Sym20 based FOSWC features are better than their counterparts from Sym8, Db3 and Haar filters. Results achieved with higher resolution mammograms from the DDSM database demonstrate that more features were needed in case of DDSM database to provide the best classification performance. On the test datasets, as shown by results from Table 2, the performance of different FOSWC feature sets almost follows the trend of cross-validation results from Table 1 where Sym20 features outperformed other feature sets.

On DDSM test data, Sym20 produced the best average FPF
                              Test
                            of 0.157±0.008 that was also the same to the one produced by Db3. However, Sym20 features still produced a better FNF
                              Test
                            of 0.174±0.022. For MIAS test data, Sym20 also achieved an average FPF
                              Test
                            of 0.145±0.038 that was better than other filters. Although FOSWC features from Haar and Db3 filters, on MIAS dataset, produced an average FNF
                              Test
                            of 0.157±0.058 and 0.176±0.07, which were better than 0.185±0.016 form Sym20, the latter still produced a superior FPF
                              Test
                            results and so a higher average accuracy.


                           Performance of mass FPR. As demonstrated by cross-validation and test results from Tables 3 and 4, the performance of various FOSWC textural feature sets, which are extracted from masses, are slightly different from their counterparts that are obtained from all lesions. For MIAS data set, the average cross-validation FPF
                              CV
                            and FNF
                              CV
                            obtained using Db3 were better than those from Sym20 as well as other filters. On DDSM cross-validation and test data sets both DB3 and Sym20 interchanged the superiority where FOSWC features form Db3 produced a better FNF
                              CV
                            of 0.191±0.028 and FNF
                              Tests
                            of 0.173±0.006. On the other hand, Sym20 features achieved superior FPF
                              CV
                            of 0.212±0.047 and FPF
                              Tests
                            of 0.190±0.025. However, these results still supported the conclusion that Sym20 is more suitable for accomplishing FPR of mass detection.

Second order statistics of image values (GLCMs) were also used to analyze texture of suspicious regions. For a specific displacement distance d and using GLCM texture feature extraction explained in Section 3.1, each suspicious region was modelled using 42 GLCM textural features. Different values of displacement distance d, d
                        ∈{1, 3, 6, 9} were tested to examine the role of the pixel distance d on the performance of GLCM features and to form an alternative and new multi-scale textural features (MDGLCM descriptors), which results from concatenating GLCM features of four different d values. Using this approach, each region was represented by 168 MDGLCM descriptors. Again, the PSO model selection approach was applied to optimize the performance of all-lesion and mass FPR with different groups of GLCM features. The obtained results are presented in Tables 5–8
                        
                        
                        
                        .


                        Performance of all-lesion FPR. Results presented in Tables 5 and 6 demonstrate that, compared to FOSWC features and for accomplishing all-lesion FPR, GLCM descriptors provided better performance than FOSWC textural features. On both tested datasets, the best cross-validation performance was produced by the new multi-scale GLCM (i.e. MDGLCM) textural features.

On DDSM data, this performance improvement was clearer in terms of FPF
                           CV
                        . For instance, MDGLCM features produced an average FPF
                           CV
                         of 0.151±0.009 compared to the best performance of 0.166±0.017 from single-distance (i.e. d
                        =9) GLCM features. The test performance of GLCM texture features on DDSM test data, as shown in Table 6, indicates that MDGLCM features also produced the best average FPF
                           Test
                         of 0.13±0.014 (and FNF
                           Test
                         of 0.117±0.036) compared to 0.157±0.012 (and FNF
                           Test
                         of 0.117±0.01) from GLCM features with d
                        =9. In case of MIAS test data, MDGLCM features provided a test performance FPF
                           Test
                         of 0.092±0.044, which was almost similar to those from single-distance feature sets with d
                        =1 and d
                        =6.


                        Performance of mass FPR. As shown by the cross-validation and test results presented in Tables 7 and 8, GLCM features significantly outperformed FOSWC features for accomplishing FPR of mass detection. For instance, on DDSM data, GLCM features with d
                        =9 achieved average FPF
                           Test
                         of 0.103±0.028 and FNF
                           Test
                         of 0.13±0.036 compared to 0.173±0.006 and 0.210±0.03 obtained from Db3 based FOSWC features. Moreover, the performance improvement using GLCM feature for mass detection was even more significant than that for the all lesions.

Results from Table 7 also demonstrate that MDGLCM descriptors provide cross-validation performance that is superior to the best result from single-distance GLCM features. For MIAS data set, MDGLCM features provided average FPF
                           CV
                         of 0.035±0.02 compared to 0.056±0.02 from GLCM with d
                        =6. In case of DDSM data, MDGLCM also achieved FPF
                           CV
                         of 0.123±0.013 that outperformed 0.147±0.023 from d
                        =9. On DDSM test data and as shown by results presented in Table 8, the average FPF
                           Test
                         of 0.115±0.036 from MDGLCM features is slightly inferior to the best FPF
                           Test
                         of 0.103±0.028 obtained using GLCM features with d
                        =9 but outperformed other single-distance GLCM feature sets. The size of textural patterns of breast tissue may significantly vary from one sample to another, which can be a challenge if a single-distance GLCM textural feature is used. However, the promising results of the proposed MDGLCM features make such approach a very convenient option.

Seeking a better performance and more efficient textural features, the power of wavelet multi-resolutional technique and the proven efficiency of GLCM for texture analysis was combined to obtain multi-scale textural features called SOSWC. As explained in Section 3.1, after accomplishing a three-level wavelet decomposition of the input image, fourteen GLCM descriptors were computed from each image subband. This produced in total 140 features. Aiming at finding a simple learning model (small number of features) with a good generalization ability, PSO model selection process was applied and the cross-validation, and test results of obtained learning model for all-lesion and mass FPR algorithms are presented in the subsequent Tables 9–12
                        
                        
                        
                        . Results of using SOSWC features demonstrated that the average cross-validation and test performances from different SOSWC feature sets using all wavelet filters were superior than those provided by FOSWC and GLCM textural features.


                        Performance of all-lesion FPR. As shown by the results from Tables 10 and 11, on MIAS data set, SOSWC features of short filters (i.e. implemented using a few coefficients) such as Db3 and Haar outperformed their counterpart features produced by Sym8 and Sym20 filters. That is SOSWC features from Db3 provided average FPF
                           CV
                         of 0.055±0.019 (FNF
                           CV
                         of 0.056±0.017). The best test performance of FNF
                           Test
                         of 0.074±0.016 was also obtained using Db3 while the best average of FPF
                           Test
                         0.029±0.029 was produced by SOSWC features of Haar filter. On the other hand, on DDSM data test, both Haar and Db3 filter were outperformed by other filters and the best FPF
                           CV
                         of 0.043±0.013 (FNF
                           CV
                         of 0.079±0.012) was produced by Sym8 features, which also produced the best FPF
                           Test
                         of 0.018±0.008 (FNF
                           Test
                         of 0.061±0.022).

Previous results indicate the superior performance of SOSWC features. Compared to FOSWC and GLCM features for accomplishing all-lesion FPR task, SOSWC features achieved a considerable improvement of the classification performance. For instance, in terms of the average classification accuracy, SOSWC texture features achieved performance gain of 13.2% and 6.4% on MIAS test data and 15.7% and 10.8% on DDSM test data. However, the higher dimensionality and computational complexity of SOSWC and GLCM feature sets, the higher is the price to achieve a better classification performance.


                        Performance of mass FPR. As shown by results from Tables 11 and 12, the performance of different SOSWC feature sets to improve mass detection is slightly different from previous experiments where SOSWC features from Db3 and Sym20 filters provide the best cross-validation results on MIAS and DDSM data, respectively. On the other hand, the test performance of Db3 features was inferior to other feature sets on DDSM data. Moreover, Haar SOSWC features achieve the best FPF
                           Test
                         of 0.027±0.006, which is slightly better than 0.028±0.013 and 0.032±0.013 form Sym8 and Sym20 filters, respectively. SOSWC textural features, in general, are obviously more effective than FOSWC and GLCM descriptors for mass-only FPR, which produce a classification gain, estimated using average classification accuracy on DDSM test data, of 20% and 7.9%, respectively.

The effectiveness of the proposed model selection hypothesis has been tested by examining the generalization capacity of optimized FPR algorithms and by comparing the results obtained using the proposed methods with those obtained using conventional optimization and parameter selection techniques. Obviously, results provided by this paper have supported this hypothesis. For example, FOSWC textural descriptors of Sym20 and new GLCM descriptors, MDGLCM, achieved the best FPF using test and training data from the two databases. SOSWC features using Sym8 also outperformed other sets on both training and testing data from DDSM. Previous results demonstrate the effectiveness of using PSO model selection for producing an outstanding classification performance by optimizing the input feature space, and by selecting the optimal hyper-parameters and parameters of the SVM classifier. The optimized feature spaces are characterized by having feature subsets of small dimensionality but more useful features. The dimensionality reduction attained was more significant in case of SOSWC and multi-distance GLCM feature extraction methods, where the input feature spaces are 140 and 168, respectively. For these feature sets, as demonstrated by cross-validation results of all-lesion FPR systems on DDSM data set (Tables 5 and 9), the average size of optimized feature spaces are about and 32.4±6.8 and 22.1±6.3 for MDGLCM and SOSWC (from Sym8 filter) methods, respectively. For the MIAS samples, the corresponding results are 15.7±3.9 and 13.0±4.2.

Compared to MIAS data set, DDSM data is larger with mammograms of higher pixel and bit resolutions and so more textural features are needed to effectively classify TN and TP regions from DDSM database. In addition to the significant reduction of the number of features required to implement FPR algorithm, PSO model selection has been successfully used to optimize hyper-parameters of the SVM classifier. With all features (i.e. no feature selection is used) presented to the SVM classifier with RBF kernel, a grid search was used to find the best values of the kernel control parameter γ and the classifier regularization constant C. We have tested the performance of grid search on methods that produced the best test performance. Results demonstrate that employing PSO model selection was very useful not only for accomplishing feature selection and dimensionality reduction but also for optimizing SVM parameters more efficiently and so producing a better classification performance. For instance, on DDSM data set and for all-lesion, features from FOSWC of Sym20, MDGLCM, and SOSWC of Sym8 produced FPF
                           Test
                         of 0.146±0.02 (FNF
                           Test
                         of 0.194±0.043), 0.33±0.005 (and 0.125±0.004) and 0.058±0.011 (and 0.172±0.035), respectively. In addition to the higher dimensionality of the input features spaces, these results are inferior to previous and corresponding results obtained from applying PSO model selection.

In (10) we have introduced a new measure to evaluate candidate learning models for the model selection purpose. It evaluates the fitness (or goodness) value of a given model by simultaneously encountering three attributes of the model, namely, FPF, FNF, and the feature space dimensionality. To demonstrate contribution of the new measure, we have compared the best results obtained using it with those obtained with a classical measure such as classification accuracy used as fitness function. For false positive reduction problems, where data from different classes are unbalanced, it is very common that the high classification accuracy will not necessarily reflect a balance and small error from both classes. To further elaborate on this issue, we have experimented all-lesion FPR on DDSM database and examined the cross-validation performance instead of test performance, because the former directly affected by the model selection criterion. Results of using accuracy measure as a model selection criterion instead of the fitness measure from (10) have produced learning models with relatively high dimensionality of the feature space and less balance between FNF and FPF performances, where a lower FPF was obtained with increase of FNF results. For example, in case of SOSWC (from sym8) the average number of features of the optimized models was 54.93±9.21 while it was 22.1±6.3 with the new measure used for optimization. Also, the average FPF
                           CV
                         and FNF
                           CV
                         were 0.085±0.015 and 0.03±0.006 compared to 0.079±0.012 and 0.043±0.013, which were produced using (10) and presented in Table 9. These advantages of using the new fitness function were also observed when FOSWC and GLCM feature methods were used.

Several studies have recently presented FPR methods for mass detection. Besides adopting various approaches for accomplishing mass false positive reduction, these studies not only differed in the databases, but also in the analyzed suspicious regions, number of regions, and the ratio of regions depicting masses to regions with normal breast tissue. Although this paper has addressed both all-lesion and mass-FPR algorithms and even used two databases for evaluation, only the results of mass-FPR system of one database (i.e. DDSM) have been considered for the comparison with relevant studies. The reason why the results of MIAS are not taken into consideration in the comparison is the fact that cross-validation performances have been obtained only from this data set. Using 1792 suspicious regions from DDSM data sets with 1/2 ratio, Oliver et al. [7] obtained Az of 0.83. On the same sets of suspicious regions and with 1:3 and 1:2, and 1:1, ratios, Lladó et al. [8] achieved Az of 0.94±0.02, 0.94±0.02, and 0.91±0.04, respectively. Ramos et al. [10] obtained Az of 0.9 on 120 suspicious regions, from DDSM, with region ratio of 1:1. Hussain et al. [11] obtained Az
                        =0.99±0.003 on 1024 regions (1/3 ratio) from DDSM database. Considering results from relevant studies, it is clear that the proposed mass FPR algorithms with SOSWC and MDGLCM textural descriptors are adequate and can be considered as one of the best methods and only outperformed by [11]. The superior performance of [11] is mostly due to the use of higher region ratio (i.e. 1/3) that was shown, even for the same FPR algorithm, to affect the classification performance [8] and the differences in the suspicious regions used for evaluation.

@&#CONCLUSIONS@&#

This paper addresses two problems related to FPR in mammography. The first one is focused on developing and evaluating different multi-scale textural feature sets. We also proposed and evaluated new multi-scale textural descriptors, called MDGLCM, which are obtained by concatenating GLCM features vectors corresponding to four pixel distances. The second problem, investigated in this paper, was finding the best learning model that concurrently achieves the best balance of FNF and FPF levels and reduces the dimensionality of the input feature space. Consequently, PSO model selection was employed to search for the best textural features and for selecting the optimal hyper-parameters, and parameters of an SVM classifier. Using DDSM and MIAS mammogram databases, which contain mammogram images of different pixel resolutions and bit depths, results demonstrate that the proposed PSO based model selection is a versatile tool for solving FPR problem adequately. Results also reveal the efficacy of the proposed textural features in general and those computed using co-occurrence matrices of wavelet image representation to improve the detection of all breast abnormalities as well as masses.

@&#ACKNOWLEDGEMENTS@&#

The work was funded by the German Research Foundation (DFG) through the research fund with Ref. GR 3721/3-1 and the research training group (RTG) 1564 “Imaging New Modalities”.

@&#REFERENCES@&#


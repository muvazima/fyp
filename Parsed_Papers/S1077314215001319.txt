@&#MAIN-TITLE@&#Recognising occluded multi-view actions using local nearest neighbour embedding

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a robust learning-free algorithm: local nearest neighbour embedding (LNNE).


                        
                        
                           
                           We introduce 3 multi-view fusion scenarios to test the LNNE method.


                        
                        
                           
                           We conduct extensive experiments on two multi-view action data sets with occlusions, where the LNNE method achieves significant performance improvements on all scenarios.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Occlusion

Action recognition

Multi-view fusion

Naive bayes

Local nearest neighbour

Embedding

@&#ABSTRACT@&#


               
               
                  The recent advancement of multi-sensor technologies and algorithms has boosted significant progress to human action recognition systems, especially for dealing with realistic scenarios. However, partial occlusion, as a major obstacle in real-world applications, has not received sufficient attention in the action recognition community. In this paper, we extensively investigate how occlusion can be addressed by multi-view fusion. Specifically, we propose a robust representation called local nearest neighbour embedding (LNNE). We then extend the LNNE method to 3 multi-view fusion scenarios. Additionally, we provide detailed analysis of the proposed voting strategy from the boosting point of view. We evaluate our approach on both synthetic and realistic occluded databases, and the LNNE method outperforms the state-of-the-art approaches in all tested scenarios.
               
            

@&#INTRODUCTION@&#

Human action recognition has received increasing attentions during the past decades. It has a wide range of applications such as medical surveillance [1], smart home [2] and human-machine interaction [3]. However, how to recognise multiple, complex human actions or activities remains a challenging problem [4]. So far, the majority of action recognition systems are only restricted to a finite number of well-defined action categories, and the performance is evaluated on actions cropped by detected bounding boxes [5,8]. For realistic applications, current methods are still very sensitive to trivial environmental variations, e.g., gender, body size, viewpoint and illumination variations, and occlusions [6,7]. Among these problems, view-variation and occlusion are two main inevitable hurdles of action recognition. As a pessimistic conclusion claimed in [9], the monocular computer vision systems are not competent enough for surveillance applications. Fortunately, the progressive visual technologies have made it possible to solve the action recognition problem using multi-view or range sensors [10,11]. Hence, extensive studies are conducted on view-invariance and transferable representations [6,13,14,16–20]. Other works also consider multi-descriptor fusion approaches [22,23]. Nonetheless, only few techniques such as [15] tackle the occlusion problem. Therefore, dealing with the occlusion problem remains an imminent research area to bridge the gap between existing action recognition algorithms and realistic applications [10].

Intuitively, the occlusion problem can be solved by a multi-view system, as shown in Fig. 1
                     . If actions captured from a viewpoint are occluded, the information loss can be compensated by data from other views which are not occluded, thus, the occlusion problem is transformed to a view-disparity problem. However, such a strategy leads to two main difficulties. The first one is how to suppress the intra-class distance caused by viewpoint variations. For this concern, it is widely acknowledged that local descriptors are less susceptible to intra-class variations [24–28], which are generally fused with holistic representations [29–31]. The second difficulty is that, in real-world applications, occlusions appear unpredictably in both training and testing data, and, as a result, break the consistency of the holistic models in the two datasets.

In order to overcome these problems, this paper is devoted to investigating multi-view methods that can incorporate local descriptors and are robust to occlusions in both training and testing action datasets. Specifically, we adopt the dense trajectories (DT) [24], which are further transformed to a robust higher-level representation and then used for multi-view fusion. We conclude our main contributions in the following 3 aspects: (1) we propose a robust learning-free algorithm: local nearest neighbour embedding (LNNE); (2) we introduce 3 multi-view fusion scenarios to test the LNNE method; (3)we conduct extensive experiments on two multi-view action data sets with occlusions, where the LNNE method achieves significant performance improvements on all scenarios.

The following sections are arranged as follows: We introduce related works in Section 2. In Section 3, we explicitly describe the LNNE method. We then illustrate the structures of the 3 fusion pipelines in the Section 4. Detailed experimental results are presented with analysis and discussions in Sections 5 and 6. Finally, we conclude our work in Section 7.

@&#BACKGROUND@&#

We review previous works from two main aspects. In the first aspect, we review the basis of feature embedding techniques, and we aim at providing an intuitive and generalised view of embedding. Also, we discuss their relations to our LNNE method. In the second aspect, we compare the proposed fusion scenarios with existing multi-view action recognition scenarios.

The primary motivation of feature embedding is inspired by the multi-sensor robotic control system [32]. The target of such a system is to dynamically determine the current state from coarse finite belief states (all of which form a belief space (BS)) under partially observable evidence. Each partial evidence is assumed achieving a proportional contribution to the overall probability distribution. Also, the control system assumes that accumulating the past likelihoods of the observation can result in one state with maximum likelihood in the belief space.

Accordingly, in a multi-view action recognition system, each individual sensor denotes a single camera viewpoint. The dimension of the BS is equivalent to the number of known query action categories. Each action category corresponds to one of the finite states of the belief space. Moreover, each local descriptor can be treated as a partial observation of the whole action sequence. Therefore, similar to the control system, we aim at finding a projection between the local feature space and the belief space in order to maximise the posterior probability. By accumulating the posterior probabilities of all local descriptors, the final static state can be determined as the overall recognition output. As a typical example, Weinland et al. [20,33] propose a class-to-query distance projection technique, where each action category 
                           
                              C
                              ∈
                              [
                              1
                              ,
                              …
                              ,
                              c
                              ]
                           
                         is represented by a set of exemplars: 
                           
                              
                                 
                                    X
                                    ˙
                                 
                                 C
                              
                              =
                              
                                 [
                                 
                                    x
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    x
                                    
                                       (
                                       n
                                       )
                                    
                                 
                                 ]
                              
                              ,
                           
                         where 
                           
                              X
                              ˙
                           
                         denotes the training set of the category. Each query action is represented by local descriptors: 
                           
                              
                                 x
                                 ^
                              
                              =
                              
                                 [
                                 
                                    
                                       d
                                       ^
                                    
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       d
                                       ^
                                    
                                    
                                       (
                                       t
                                       )
                                    
                                 
                                 ]
                              
                           
                        . The distance between each exemplar x
                        (i) and the nearest local descriptor 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 j
                                 )
                              
                           
                         of the query action is estimated. Then all estimated distances are concatenated into a long vector:

                           
                              
                                 
                                    
                                       
                                          
                                             D
                                             
                                                
                                                   (
                                                   
                                                      x
                                                      ^
                                                   
                                                   )
                                                
                                                C
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                (
                                                d
                                                i
                                                s
                                                
                                                   t
                                                   1
                                                
                                                
                                                   (
                                                   
                                                      x
                                                      ^
                                                   
                                                   )
                                                
                                                ,
                                                …
                                                ,
                                                d
                                                i
                                                s
                                                
                                                   t
                                                   n
                                                
                                                
                                                   (
                                                   
                                                      x
                                                      ^
                                                   
                                                   )
                                                
                                                )
                                             
                                             ∈
                                             
                                                R
                                                n
                                             
                                             
                                             w
                                             h
                                             e
                                             r
                                             e
                                             
                                             d
                                             i
                                             s
                                             
                                                t
                                                i
                                             
                                             
                                                (
                                                
                                                   x
                                                   ^
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                min
                                                j
                                             
                                             d
                                             i
                                             s
                                             t
                                             
                                                (
                                                
                                                   x
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                ,
                                                
                                                   
                                                      d
                                                      ^
                                                   
                                                   
                                                      (
                                                      j
                                                      )
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Note that D is an embedding procedure which maps the descriptors of the query action into an n-dimensional new representation for each category, each dimension of which accounts for the posterior probability of each exemplar in class C to the closest partial observation in the query 
                           
                              x
                              ^
                           
                        . Thus, the final static state can be determined by the typical maximum likelihood criterion:

                           
                              
                                 
                                    
                                       
                                          
                                             g
                                             
                                                (
                                                D
                                                )
                                             
                                             =
                                             arg
                                             
                                                max
                                                C
                                             
                                             p
                                             
                                                (
                                                D
                                                |
                                                C
                                                )
                                             
                                             p
                                             
                                                (
                                                C
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

On the other hand, such exemplar-based approaches also receive massive criticisms. Boiman et al. [41] emphasise that the quantisation error may decay the performance, which is inevitable in the exemplar-based methods because of clustering. They claim the importance of using the original local features. However, as a classical local feature-based approach, NBNN is also criticised by Timoftem et al. [44] for another two issues. The first issue is that the independence assumption of the descriptors may not hold. Secondly, the decision rule of NBNN is close to a hard-assignment of each category. A number of related methods attempt to extend NBNN [44]. These recent approaches try to improve the nearest neighbour formulas with more advanced solutions. kNN [43] expands the number of nearest neighbours and therefore makes the decision more fuzzy. LLE [35] aims at richer representations on l
                        1 constrained least squares so that the feature structure can be more discriminative. INN combines l
                        1-regularised least squares with LLE and adopts the simplicity of kNN. Besides, a number of related subspace learning methods are proposed, such as [34,36–40].

Nonetheless, most of the above approaches do not find an embedding from the original feature space directly to a belief space (which has an identical number of dimensions as the number of categories for query). In comparison, our method will directly achieve the predicted labels after embedding whereas other methods only focus on learning the data structure. Even though existing feature embedding techniques are equipped with strong theoretical supports, they also suffer from the above stated problems. In order to overcome these problems, we follow four principles to design our method: (1) we utilise soft-assignments so that some ambiguous local features can contribute to multiple categories; (2) we directly map from the feature space to the belief space in order to substantially utilise the supervision; (3) our method is training-free, and requires only one parameter; and (4) particularly concerning about the realistic scenarios, we adopt and modify the log-odds formula in the local NBNN [42] to deal with the noise caused by viewpoint variations and occlusions in both training set and test set.

Bag-of-Visual-Words is a widely used method for constructing holistic representations from local descriptors. However, this method does not consider the geometric relationships among the extracted local features [21]. In comparison, Cai et al. [31] study how different viewpoints in the multi-view system can be related to each other. However, these methods only focus on the representation without modifying the fusion schemes. In contrast, we regard each view as an independent observation, which can lead to further improvement by incorporating a Naive Bayes-based fusion method at the final decision. Even though the observation is the same action, each view of the multi-view system can be regarded as an independent representation, in terms of video capturing, feature extraction and embedding - this independence assumption is reasonable. Farhadi and Tabrizi [14] adopt a transfer learning-based fusion strategy, which learns from the instances in a single view and estimates how much they are benefiting from other views. A query action is first estimated and transferred to the standard viewpoint before further stages. Another transfer manner can be seen in [12] that different views of actions can be transferred onto a self-similarity matrix, which can possess view-invariant structure. Reddy et al. [23] apply a voting scheme based on the tree structure. In contrast, we suggest the voting scheme can also be achieved if each single view is robust and transferable to other views.

Another interesting branch of works is feature fusion, e.g., [6,22,40]. Different types of features are regarded as multiple views. The fused feature can possess different attributes rather than the relations of viewpoints. Nonetheless, these methods only focus on finding a single representation for different features. In contrast, we treat each feature point separately and pool them into several matrices according to their spatial properties of the viewpoints. Besides, in [13], they adopt an outlier detection method and only recognise confident instances. However, this does not substantially solve the problem. Only Weinland et al. in [15] consider both view-invariance and occlusion problems, but the performance remains to be improved.

In a typical action recognition task using local representations, an action sequence x
                     (i) can be consisted by an uncertain number mi
                      of extracted local descriptor 
                        
                           
                              x
                              
                                 (
                                 i
                                 )
                              
                           
                           =
                           
                              [
                              
                                 d
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 d
                                 
                                    (
                                    
                                       m
                                       i
                                    
                                    )
                                 
                              
                              ]
                           
                        
                     . The training set is represented by pooling the descriptors from all training action instances into one matrix. Suppose there are totally I instances, 
                        
                           X
                           =
                           
                              [
                              
                                 x
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 x
                                 
                                    (
                                    I
                                    )
                                 
                              
                              ]
                           
                           =
                           
                              [
                              
                                 d
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 d
                                 
                                    (
                                    n
                                    )
                                 
                              
                              ]
                           
                           ,
                        
                      where 
                        
                           n
                           =
                           
                              m
                              1
                           
                           +
                           ⋯
                           +
                           
                              m
                              I
                           
                        
                     . 
                        
                           Y
                           =
                           [
                           
                              y
                              
                                 (
                                 1
                                 )
                              
                           
                           ,
                           …
                           ,
                           
                              y
                              
                                 (
                                 n
                                 )
                              
                           
                           ]
                        
                      is a single column vector indexing the corresponding action label of each training local descriptor. This is a typical supervised system and suppose the task involves a finite number of known action categories c, then 
                        
                           
                              y
                              
                                 (
                                 i
                                 )
                              
                           
                           ∈
                           
                              [
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              c
                              ]
                           
                        
                     . So, our LNNE method aims at finding an embedding for every local feature point 
                        
                           
                              d
                              ^
                           
                           
                              (
                              
                                 M
                                 ^
                              
                              )
                           
                        
                      of the query action 
                        
                           
                              x
                              ^
                           
                           =
                           
                              [
                              
                                 
                                    d
                                    ^
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    d
                                    ^
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    d
                                    ^
                                 
                                 
                                    (
                                    
                                       m
                                       ^
                                    
                                    )
                                 
                              
                              ]
                           
                        
                     . Note that we differentiate the notations of the query action sequence with the hat symbol. In this section, we explain the scheme of LNNE and how it can be fitted to a maximum-likelihood classifier based on the Naive Bayes (NB) rule as shown in Fig. 2
                     . To intuitively understand the LNNE, the local feature points of the query action are embedded into the BS, each dimension of which denotes the probability to the corresponding category. And then each embedded point can be viewed as an partial observation with probabilistic representation. We generalise such representation for fusing multiple views of actions that we discuss in Section 4.

The LNNE method is a process of fuzzy max-pooling. The local features in the training set 
                           
                              X
                              =
                              [
                              
                                 d
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 d
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 d
                                 
                                    (
                                    n
                                    )
                                 
                              
                              ]
                           
                         can be treated as a pool of kernels, i.e., each of them accounts for a certain feature distribution for probability density estimation (PDE) of the query point. The term “Local” in LNNE refers to the location relationship between each query feature point and the training kernels in an abstract feature space, and we follow Gaussian distribution in this paper. This should be distinguished from the term of “Local feature” that emphasises the spatial or temporal location where the feature is extracted. Since hard assignment causes information loss, the proposed embedding method assigns each local point 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         of the query action 
                           
                              x
                              ^
                           
                         into a likelihood vector w
                        (M) in the belief space. The fuzzy max-pooling process is utilised so that the weights of a number of maximum responses can be updated simultaneously. Thus, the query action can be reformed and represented by a set of max-pooled likelihood vectors: 
                           
                              
                                 x
                                 ^
                              
                              =
                              
                                 [
                                 
                                    w
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    w
                                    
                                       (
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    w
                                    
                                       (
                                       
                                          m
                                          ^
                                       
                                       )
                                    
                                 
                                 ]
                              
                              ,
                           
                         which can be combined with the fusion scenarios afterwards to predict the query label.

Firstly, local features are extracted from all of the training videos, which are defined as X, where each local feature corresponds to an action category. Thus, the prior distribution of each action category can be estimated by a linear combination of a number nc
                         of training kernels:

                           
                              (1)
                              
                                 
                                    p
                                    
                                       (
                                       C
                                       )
                                    
                                    ∝
                                    
                                       θ
                                       0
                                    
                                    +
                                    
                                       ∑
                                       
                                          N
                                          =
                                          1
                                       
                                       
                                          n
                                          c
                                       
                                    
                                    
                                       θ
                                       N
                                    
                                    
                                       d
                                       
                                          (
                                          N
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

A query action can be represented as 
                           
                              
                                 x
                                 ^
                              
                              =
                              
                                 [
                                 
                                    
                                       d
                                       ^
                                    
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       d
                                       ^
                                    
                                    
                                       (
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       d
                                       ^
                                    
                                    
                                       (
                                       
                                          m
                                          ^
                                       
                                       )
                                    
                                 
                                 ]
                              
                              ,
                           
                         where 
                           
                              m
                              ^
                           
                         is the total number of descriptors in the query action. The target is to estimate the posterior probability by the prior probability using the Naive Bayes rule: 
                           
                              p
                              
                                 (
                                 C
                                 |
                                 
                                    x
                                    ^
                                 
                                 )
                              
                              =
                              p
                              
                                 (
                                 
                                    x
                                    ^
                                 
                                 |
                                 C
                                 )
                              
                              p
                              
                                 (
                                 C
                                 )
                              
                           
                        . The prior probabilities of all the categories are defined as (
                           
                              p
                              
                                 (
                                 
                                    C
                                    1
                                 
                                 )
                              
                              =
                              p
                              
                                 (
                                 
                                    C
                                    2
                                 
                                 )
                              
                              =
                              ⋯
                           
                        ). This is because there is an equal chance for all action categories to be assigned to the query instance. Therefore, the remaining term of posteriori probability 
                           
                              p
                              (
                              C
                              |
                              
                                 x
                                 ^
                              
                              )
                           
                         is proportional to the likelihood 
                           
                              p
                              (
                              
                                 x
                                 ^
                              
                              |
                              C
                              )
                              ,
                           
                         so that we can directly measure posterior probability of the query instance alternatively. As each feature point can be treated as an individual observation based on the central limit theorem, we assume the training data can be approximately fitted by a Gaussian distribution. According to Eq. (1), the likelihood distribution between each of the query feature points 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         with any category C can be measured by:

                           
                              (2)
                              
                                 
                                    p
                                    
                                       (
                                       
                                          
                                             d
                                             ^
                                          
                                          
                                             (
                                             M
                                             )
                                          
                                       
                                       |
                                       C
                                       )
                                    
                                    ≈
                                    
                                       ∏
                                       
                                          N
                                          =
                                          1
                                       
                                       
                                          n
                                          c
                                       
                                    
                                    
                                       [
                                       
                                          1
                                          
                                             
                                                
                                                   2
                                                   π
                                                
                                             
                                             
                                                σ
                                                N
                                             
                                          
                                       
                                       exp
                                       
                                          (
                                          
                                             
                                                −
                                                
                                                   θ
                                                   N
                                                
                                                
                                                   
                                                      ∥
                                                      
                                                         
                                                            d
                                                            ^
                                                         
                                                         
                                                            (
                                                            M
                                                            )
                                                         
                                                      
                                                      −
                                                      
                                                         d
                                                         
                                                            (
                                                            N
                                                            )
                                                         
                                                      
                                                      ∥
                                                   
                                                   2
                                                
                                             
                                             
                                                2
                                                
                                                   σ
                                                   N
                                                   2
                                                
                                             
                                          
                                          )
                                       
                                       ]
                                    
                                 
                              
                           
                        
                     

There are several drawbacks in Eq. (2): (1) since different local features can account for distinct parts of the action sequence, utilising the complete set of local features is not an optimal solution; (2) due to the long-tail property of the feature histogram, only few nearest kernels account for most of the density while the remaining kernels do not contribute to the estimation if the norm-2 distances are higher than a certain degree; and (3) in a realistic dataset, not all of the local feature points in the training set are reliable due to occlusion or viewpoint variation. In order to avoid the above 3 problems, we adopt the max-pooling-based embedding scheme, which only projects each query’s local descriptor to sampled training kernels while filtering out most irrelevant or unreliable kernels.

In the max-pooling scheme, each query feature point 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         is pooled by k kernels with the maximum likelihoods regardless which category they come from. Specifically, we assume the coefficient of each θ is 1 for a kernel which is found in the top k nearest neighbours to the query point 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                        . Whereas the remaining training kernels are assumed outside an effective range, and result in coefficients as 0. Also, because there is no prior knowledge to judge which kernel is more effective than the other, we simply assume a universal Gaussian distribution for each training kernel. Therefore, the σs for all kernels are assumed as 1 s. Under such an assumption, we explore that each query-to-class probability is inversely proportional to the distance between them. Therefore, we can rewrite Eq. (2) as Eq. (3), and achieve fuzzy max-pooling using a knn algorithm. Suppose the k nearest neighbours come from categories 
                           
                              
                                 C
                                 
                                    N
                                    N
                                 
                              
                              =
                              
                                 [
                                 
                                    C
                                    1
                                 
                                 ,
                                 
                                    C
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 
                                    C
                                    
                                       n
                                       n
                                    
                                 
                                 ]
                              
                              ,
                           
                         and the category C ∈ CNN
                         can be estimated through:

                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             p
                                             (
                                             
                                                
                                                   d
                                                   ^
                                                
                                                
                                                   (
                                                   M
                                                   )
                                                
                                             
                                             |
                                             C
                                             )
                                          
                                       
                                       
                                          ∝
                                       
                                       
                                          
                                             
                                                ∑
                                                
                                                   N
                                                   =
                                                   1
                                                
                                                
                                                   n
                                                   c
                                                
                                             
                                             log
                                             
                                                [
                                                
                                                   1
                                                   
                                                      
                                                         
                                                            2
                                                            π
                                                         
                                                      
                                                      σ
                                                   
                                                
                                                exp
                                                
                                                   (
                                                   
                                                      
                                                         
                                                            −
                                                            θ
                                                            ∥
                                                         
                                                         
                                                            
                                                               d
                                                               ^
                                                            
                                                            
                                                               (
                                                               M
                                                               )
                                                            
                                                         
                                                         −
                                                         
                                                            d
                                                            
                                                               (
                                                               N
                                                               )
                                                            
                                                         
                                                         
                                                            
                                                               ∥
                                                            
                                                            2
                                                         
                                                      
                                                      
                                                         2
                                                         
                                                            σ
                                                            2
                                                         
                                                      
                                                   
                                                   )
                                                
                                                ]
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                          ∝
                                       
                                       
                                          
                                             
                                                −
                                                ∥
                                             
                                             
                                                
                                                   d
                                                   ^
                                                
                                                
                                                   (
                                                   M
                                                   )
                                                
                                             
                                             −
                                             
                                                d
                                                
                                                   (
                                                   N
                                                   
                                                      N
                                                      C
                                                   
                                                   )
                                                
                                             
                                             
                                                
                                                   ∥
                                                
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Note that we take log operation from Eq. (2) and replace the production by summation. This is to prevent computational underflow. NNC
                         stands for the nearest neighbour in category C, which is assumed to maximise the query-to-class likelihood. Therefore, this forms an embedded approximation of the original representation 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         with a likelihood vector w
                        (M). Concretely, w
                        (M) is in c dimensional BS. Each dimension 
                           
                              w
                              C
                              
                                 (
                                 M
                                 )
                              
                           
                         (denoted by subscript) stands for an estimation of the probability likelihood between 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         and category C, which is simply approximated by the norm-2 distance. This can be expressed as Eq. (4).

                           
                              (4)
                              
                                 
                                    
                                       w
                                       C
                                       
                                          (
                                          M
                                          )
                                       
                                    
                                    =
                                    
                                       
                                          ∥
                                          
                                             
                                                d
                                                ^
                                             
                                             
                                                (
                                                M
                                                )
                                             
                                          
                                          −
                                          
                                             d
                                             
                                                (
                                                N
                                                
                                                   N
                                                   C
                                                
                                                )
                                             
                                          
                                          ∥
                                       
                                       2
                                    
                                 
                              
                           
                        
                     

Notice that a weight can be obtained only if C ∈ CNN
                        ; otherwise, irrelevant dimensions will be assigned with zeros instead. Since the number of weighted categories is not fixed, we consider such a max-pooling scheme as a fuzzy approach.

The estimation method stated in Eq. (4) can be susceptible to noise, i.e., same local patterns can be shared in both query samples and training samples from not only the same category but also other categories due to occlusion. As a solution, we modify Eq. (4) as Eq. (5). Specifically, once 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         has a high likelihood to a category, it must not be likely to the other categories. Otherwise, this mapping is not discriminative and the weights assigned to those categories should not be dominantly large. Such a scheme guarantees that only discriminative points can gain high weights after embedding and consequently improves the robustness in terms of occlusions.

                           
                              (5)
                              
                                 
                                    
                                       w
                                       C
                                       
                                          (
                                          M
                                          )
                                       
                                    
                                    
                                       =
                                       ∥
                                    
                                    
                                       
                                          d
                                          ^
                                       
                                       
                                          (
                                          M
                                          )
                                       
                                    
                                    −
                                    
                                       d
                                       
                                          (
                                          N
                                          
                                             N
                                             C
                                          
                                          )
                                       
                                    
                                    
                                       
                                          ∥
                                       
                                       2
                                    
                                    −
                                    
                                       
                                          ∥
                                          
                                             
                                                d
                                                ^
                                             
                                             
                                                (
                                                M
                                                )
                                             
                                          
                                          −
                                          
                                             d
                                             
                                                (
                                                N
                                                
                                                   N
                                                   
                                                      k
                                                      +
                                                      1
                                                   
                                                
                                                )
                                             
                                          
                                          ∥
                                       
                                       2
                                    
                                 
                              
                           
                        where 
                           
                              N
                              
                                 N
                                 
                                    k
                                    +
                                    1
                                 
                              
                           
                         denotes the 
                           
                              (
                              k
                              +
                              1
                              )
                           
                        th nearest training kernels of 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                        . For computational efficiency, instead of conducting kNN searching iteratively for each query descriptor, we suggest to find the nearest 
                           
                              (
                              k
                              +
                              1
                              )
                           
                         kernels in one time and save them into an index matrix 
                           
                              I
                              
                                 (
                                 
                                    m
                                    ^
                                 
                                 ×
                                 
                                    (
                                    k
                                    +
                                    1
                                    )
                                 
                                 )
                              
                           
                         ( 
                           
                              I
                              ∈
                              [
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              n
                              ]
                           
                         ) using a fast searching algorithms.

After embedding, each dimension of the new representation 
                           
                              w
                              C
                              
                                 (
                                 M
                                 )
                              
                           
                         stands for an estimation of the likelihood between 
                           
                              
                                 d
                                 ^
                              
                              
                                 (
                                 M
                                 )
                              
                           
                         and category C. Based on the maximum likelihood criterion, a simple Naive Bayes (NB) classifier can be done by accumulating all of the embedded descriptors. The classification is achieved by calculating the maximum likelihood, which is inversely proportional to the distance.

                           
                              (6)
                              
                                 
                                    
                                       C
                                       ^
                                    
                                    =
                                    arg
                                    
                                       min
                                       C
                                    
                                    
                                       ∑
                                       
                                          M
                                          =
                                          1
                                       
                                       
                                          m
                                          ^
                                       
                                    
                                    
                                       w
                                       
                                          (
                                          M
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

Based on the LNNE algorithm, we propose 3 multi-view fusion scenarios for action recognition according to Eq. (6). We discuss the advantages of each scenario and particularly explain how our methods can deal with occlusions. The problem of occlusion is demonstrated in Fig. 1. Note that we redefine the training set as a group of individual subsets: 
                        
                           [
                           
                              X
                              
                                 (
                                 1
                                 )
                              
                           
                           ,
                           
                              X
                              
                                 (
                                 2
                                 )
                              
                           
                           ,
                           …
                           ,
                           
                              X
                              
                                 (
                                 s
                                 )
                              
                           
                           ]
                        
                      with label vectors: 
                        
                           [
                           
                              Y
                              
                                 (
                                 1
                                 )
                              
                           
                           ,
                           
                              Y
                              
                                 (
                                 2
                                 )
                              
                           
                           ,
                           …
                           ,
                           
                              Y
                              
                                 (
                                 s
                                 )
                              
                           
                           ]
                        
                     . In correspondence, the query action is also represented as the same ordered views: 
                        
                           [
                           
                              
                                 x
                                 ^
                              
                              
                                 (
                                 1
                                 )
                              
                           
                           ,
                           
                              
                                 x
                                 ^
                              
                              
                                 (
                                 2
                                 )
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 x
                                 ^
                              
                              
                                 (
                                 s
                                 )
                              
                           
                           ]
                        
                     . Each view of X, Y and 
                        
                           x
                           ^
                        
                      is consistent to the notations in Section 3.

For LNNE accumulating (LNNEA), we simply combine action sequences from different views and follow the defined notions of X and Y above. Similarly, we put the subsets of the query action into one: 
                           
                              
                                 x
                                 ^
                              
                              =
                              
                                 [
                                 
                                    
                                       x
                                       ^
                                    
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                       ^
                                    
                                    
                                       (
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       x
                                       ^
                                    
                                    
                                       (
                                       s
                                       )
                                    
                                 
                                 ]
                              
                           
                        . Such a notation discards the temporal correspondence, even though the views of an action are simultaneously recorded in parallel. Rather, we represent each single view as an individual component of the whole model. By fusing local feature extracted from multiple views, we consider such a strategy as a compensation of the missing information of certain views. The notations in the proposed LNNE are consistent to this scenario and therefore can be directly applied.

Even though LNNEA looks quite simple, it is the most adaptable to address all kinds of settings of occluded action recognition. In LNNEA, the kNN algorithm applied in Eq. (5) searches for kernels from all possible viewpoints in the whole training set. For instance, suppose the multiple cameras are allocated in the front, back, left and right respectively in a room, and the training actions are done towards the front direction and the query actions are backwards. In such a case, local feature points from the front view of the query action will get high likelihood with the training kernels from the back viewpoint according to Eq. (5). Therefore, as we put all of the four views together, through the max-pooling scheme in LNNE, the LNNEA achieves view-point invariance.

LNNEA can also be competent to handle occlusions which exist in both the training set and the test set. For example, let one random view x
                        (N, S) of the Nth instance in the training set be occluded, where the Nth instance is denoted as: 
                           
                              
                                 x
                                 
                                    (
                                    N
                                    )
                                 
                              
                              =
                              
                                 [
                                 
                                    x
                                    
                                       (
                                       N
                                       ,
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    x
                                    
                                       (
                                       N
                                       ,
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    x
                                    
                                       (
                                       N
                                       ,
                                       s
                                       )
                                    
                                 
                                 ]
                              
                           
                        . As a result, all local features extracted from the view 
                           
                              
                                 x
                                 
                                    (
                                    N
                                    ,
                                    S
                                    )
                                 
                              
                              =
                              
                                 [
                                 
                                    d
                                    
                                       N
                                       S
                                    
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    d
                                    
                                       N
                                       S
                                    
                                    
                                       (
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    d
                                    
                                       N
                                       S
                                    
                                    
                                       (
                                       m
                                       )
                                    
                                 
                                 ]
                              
                           
                         are distorted due to the occlusion. To make it more challenging, let one random view 
                           
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    
                                       S
                                       ^
                                    
                                    )
                                 
                              
                              =
                              
                                 [
                                 
                                    
                                       d
                                       ^
                                    
                                    S
                                    
                                       (
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       d
                                       ^
                                    
                                    S
                                    
                                       (
                                       2
                                       )
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       d
                                       ^
                                    
                                    S
                                    
                                       (
                                       
                                          m
                                          ^
                                       
                                       )
                                    
                                 
                                 ]
                              
                           
                         of the query 
                           
                              x
                              ^
                           
                         be occluded as well. We differ the occluded view S in the training set and 
                           
                              S
                              ^
                           
                         in the query instance by the hat symbol so as to show that there is no guarantee that the occluded views in the training and test sets are consistent. Such a challenging scenario consequently breaks the consistency of the distribution between the training and query representations for the exemplar-based methods. In contrast, LNNE is a local-feature-based method and it only focuses on local points with high similarities. So, through the double pooling scheme, LNNE can search for more reliable training kernels and automatically filter out the distorted ones in the training set. Meanwhile, the odds-ratio algorithm prevents LNNE from being misled by the occlusion pattern, since the same pattern can also exhibit in the training data.

Rather than combining all viewpoints into one matrix in a complementary relationship, in LNNE Voting (LNNEV), action sequences are processed in a boosting manner. The training set is the same as in LNNEA, while for the query action, each single view is regarded as an independent instance. Specifically, one multi-view query task is divided by each single view and classification is conducted separately: 
                           
                              [
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    s
                                    )
                                 
                              
                              ]
                           
                        . A list of predictions are obtained through the NB classifier using Eq. (6): 
                           
                              [
                              
                                 
                                    C
                                    ^
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    C
                                    ^
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    C
                                    ^
                                 
                                 
                                    (
                                    s
                                    )
                                 
                              
                              ]
                           
                        . A majority voting scheme is applied to the predictions in order to obtain a final prediction 
                           
                              C
                              ^
                           
                        . The LNNEV scenario shows improved performance against occlusions particularly when the number of viewpoints is large.

However, LNNEV does not apply to all cases, because the final prediction of LNNEV is consistent with the prediction results of the majority views. Thus, if the average recognition rate of each single view is lower than 50%, or the number of occluded views are more than half, the overall performance cannot be guaranteed. We can quantitatively estimate whether the LNNEV can be applied. Assuming each camera view is independent, an average recognition rate ρ among all single views can be computed using cross-validation. If less than half of the views (round down of s/2 in Eq. (7)) are incorrectly predicted, the LNNE Voting algorithm can achieve an improved performance. The expected overall recognition rate Υ can be calculated using the permutation and combination equation:

                           
                              (7)
                              
                                 
                                    Υ
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          0
                                       
                                       
                                          ⌊
                                          s
                                          /
                                          2
                                          ⌋
                                       
                                    
                                    
                                       (
                                       
                                          C
                                          s
                                          
                                             s
                                             −
                                             i
                                          
                                       
                                       ×
                                       
                                          ρ
                                          
                                             s
                                             −
                                             i
                                          
                                       
                                       ×
                                       
                                          
                                             (
                                             1
                                             −
                                             ρ
                                             )
                                          
                                          i
                                       
                                       )
                                    
                                 
                              
                           
                        
                        Eq. (7) leads us to a novel strategy for improving the performance. If we are able to retain the average recognition rate of the single views, the overall performance can be boosted by simply increasing the number of camera views. This assumption is verified in Section 5. In addition, LNNEV adopts the same embedding technique using the whole training set while following different decision rules.

The drawback shared by LNNEA and LNNEV is that they have to search nearest neighbours through the whole training set of all views in order to find the optimal weights, which leads to high computational cost. To avoid this, we propose the Ordered LNNE (OLNNE) as an approximation of LNNEA. OLNNE is based on the assumption that camera views of both the training set and the query set are ordered. For instance, action A is carried out when the actor is facing camera view 1, and query action A is also facing view 1. Similarly, other camera views of query action A are also corresponding to the order of the training cameras. Thus, searching for nearest neighbours is no longer in the whole training set but restricted to a specific view of the training set. Consider s camera views, the searching complexity of the OLNNE method is reduced to 1/s of that in LNNEA and LNNEV.

Concretely, the multiple views of the training set are saved into separate matrices: 
                           
                              [
                              
                                 X
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 X
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 X
                                 
                                    (
                                    s
                                    )
                                 
                              
                              ]
                           
                        . In the same order, the form of a query action is formulated as: 
                           
                              [
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    1
                                    )
                                 
                              
                              ,
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    2
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    s
                                    )
                                 
                              
                              ]
                           
                        . Therefore, each pair of training and query subsets in the Sth view holds the requirement of LNNE: 
                           
                              X
                              =
                              
                                 X
                                 
                                    (
                                    S
                                    )
                                 
                              
                           
                         and 
                           
                              
                                 x
                                 ^
                              
                              =
                              
                                 
                                    x
                                    ^
                                 
                                 
                                    (
                                    S
                                    )
                                 
                              
                           
                        . Consequently, we apply LNNE on each pair of the training and query views. Because of the existence of the odds-ratio in Eq. (5), no categories will get large weights in occluded views. So, the voting scheme can hardly be applied to this case. Instead, we adopt a decision rule that is similar to LNNEA. After Embedding, the overall decision is made by average-pooling all the weight vectors from all views:

                           
                              (8)
                              
                                 
                                    
                                       C
                                       ^
                                    
                                    =
                                    arg
                                    
                                       min
                                       C
                                    
                                    
                                       ∑
                                       
                                          S
                                          =
                                          1
                                       
                                       s
                                    
                                    
                                       ∑
                                       
                                          M
                                          =
                                          1
                                       
                                       
                                          m
                                          ^
                                       
                                    
                                    
                                       
                                          (
                                          
                                             w
                                             
                                                (
                                                M
                                                )
                                             
                                          
                                          )
                                       
                                       
                                          (
                                          S
                                          )
                                       
                                    
                                 
                              
                           
                        
                     

Considering the order of views has both advantages and drawbacks. Except for the computational efficiency, OLNNE can be viewed as a spatial pooling method. Intuitively, when the training and query actions are well aligned, OLNNE can remove irrelevant variances from other viewpoints despite that the misleading shared patterns possess high likelihoods. However, if the training and query actions are not aligned, how to effectively select kernels in the same viewpoint becomes a problem. Therefore, the generalisation of OLNNE is restricted to specially aligned settings in this work.

@&#EXPERIMENTS AND RESULTS@&#

The first release of IXMAS is a multi-view action dataset. It consists of 11 daily action categories, each of which is performed by 11 actors and 3 times per action per person. As a result, there are totally 11 by 11 by 3 performed action examples. Particularly, each action is captured by 5 cameras simultaneously from different viewpoints. Fig. 3
                               provides an example of the “check-watch” action from 5 views.

In order to investigate the occlusion problem in action recognition, we evaluate our approaches on the well-cropped version of IXMAS. The Region of Interests (ROI)s are extracted with the provided bounding boxes in grey-scale. This results in 11 × 11 × 3 × 5 action clips in total, each of which is roughly in the length of 3 or 4 s. A synthetically occluded version is provided with each action clip (as show in Fig. 4).

We adopt the leave-one-person out verification in our experiments, i.e., 11 × 1 × 3 × 5 are querying while the remainiing constitutes the training set. Referring to our notations in Section 3, each query 
                                 
                                    x
                                    ^
                                 
                               has 5 views: cam0 → cam4. Similarly, each training action x is also in the format of 5 views. To simulate the unpredictable appearance of occlusion, we randomly replace one view of the query and each training action with the synthetically occluded versions so that the occluded parts are completely unknown between the training and test sets. As a result, one fifth of both training and querying actions are added with unpredictable occlusions.

The New IXMAS dataset is an extension of the originally released IXMAS dataset. Comparing to the original IXMAS dataset, the new dataset is smaller but more challenging. There are totally 6 actors performing the same 11 action categories, each of which is also repeated 3 times as before. Also, there are 5 camera views, but, they are located at different viewpoints. In total, there are 11 × 6 × 3 × 5 actions.

We also adopt the provided ROIs for our experiments. Two thirds of actions are captured in the real occluded environment, while only the first repeat of each person is captured with pure background. The objects are located around the actors, such as tables, shelves, etc. So, the number of occluded views and the degree of occlusion is uncertain. Some views are completely occluded while others four are clear. Or, some adjacent views are partially occluded by the shared object. Even when actors are not occluded, the existence of the objects can cause a cluttered background. A set of examples of the New IXMAS dataset are shown in the Fig. 5
                              
                              .

Again, we adopt the leave-one-person-out scheme for evaluation. For each person, 11 × 1 × 3 queries under 5 views are in turn recognised by the system with 11 × 5 × 3 × 5 training actions and output predictions. Experimental results are shown separately on all clean views (the first repeat of each action), and occluded views (the second and third repeats of each action).

For both databases, we firstly extract local feature points using the DT descriptor. The parameters adopted in this work are consistent with the original DT work [24]. In average, 10–20 local descriptors are extracted from each frame. The value of fuzzy parameter k in the LNNE algorithm is determined through cross-validation on the training data. We obtain an optimal value 5 for k in our experiments.

We compare our methods with the state-of-the-art methods on the original IXMAS dataset, and report the results in Table 1
                              . Even our setting is more challenging due to additional synthetic occlusions, all of our methods can still outperform the state-of-the-art approaches on the non-occluded dataset. It can be seen that most of the state-of-the-art methods are holistic that might not robust to partial occlusions. So, we attribute our high recognition rates to the effectiveness of fusing discriminative local features. The performance of LNNE validates its robustness in terms of dealing with occlusions. We can observe that LNNEA achieves the best performance, which supports that LNNEA is robust to both occlusions and viewpoint changes. LNNEV performs slightly worse than LNNEA. Such unsatisfying performance of LNNEV can be caused by the insufficiency of camera views (only 5 views available in our task). Referring to the hypothesis in Eq. (7), we notice that the average quality of each single view in Table 1 is 84.97, and the achieved voting result is 90.9, which is close to the expected value. So, we believe that the overall recognition rate can be higher if there are more camera views in the same recognition quality. The OLNNE performs 2% lower than LNNEA in average. Such degraded performance is due to the misalignments in the IXMAS dataset. The specified alignment degree is illustrated in Fig. 6
                              . In addition, all LNNE-based methods achieve 1 to 3 percent performance improvements over the NBNN-based methods in comparisons.

The average performances on the New IXMAS dataset is lower than that in the Original IXMAS dataset. Since only actions from 6 actors are available for training, the training examples are far fewer than that of the original IXMAS dataset, where actions from 11 actors are utilised. In addition, the viewpoint variation is larger. For example, in the 6th iteration (marked as purple in the Fig. 6), the second repeat of the whole 11 actions do not have the same direction of training examples in the remaining 5 people’s. Thirdly, realistic occlusions are considered in the New IXMAS dataset. As mentioned in Section 5.1, there is no guarantee that only one view is affected by occlusion. Table 2
                               illustrates the performance for both non-occlusion and occlusion scenarios. The average recognition rates on the clean views are close to the results in the synthetic database, while only Ordered NBNN dropped remarkably from 86.97% to 69.7%. However, under the same fusion scenario in comparison, the performance of OLNNE does not degrade too much (91.21–86.4%). This is because the odds-ratio we adopt can suppress the embedding weights from misaligned kernels. LNNEV achieves a recognition rate of 90.9% while the recognition accuracy of each single view is 79.7%. This result has satisfied the expectation in Eq. (7). Hence, we believe that, by increasing the number of views, LNNEV can perform better. The LNNEA approach remains the most robust fusion strategy, and all our proposed methods outperform the other methods in all 3 fusion scenarios.


                              Fig. 7
                               shows the confusion matrices of both our proposed methods and corresponding NBNN-based methods. Simple actions like sitting down, getting up and walking can be easily recognised by all methods. The LNNE methods generally produce more concentrated results (darker in colour) on the diagonals of the confusion matrices than compared NBNN methods. This is the most obvious in the ordered comparing pair. LNNEA and LNNEV achieve recognition rates of 100% on more categories because they use the whole training set for each view of query in comparison to the view-to-view scenario in OLNNE. In general, all of the 3 fusion methods of LNNE achieve satisfying performance on the synthetic database. In Fig. 8
                              , we further compare our best result of LNNEA with the published confusion matrices in [15], which illustrates the performances on clean and occluded data respectively. LNNEA achieves perfect recognition on almost all categories on the clean views except for a few queries of “check watch” and “punch”. For occluded views, LNNEA outperforms 8 of 11 of the compared results, and achieves 100% recognition rate on 4 categories (D, G, H, K). Interestingly, the accuracy of “punch” in occluded LNNEA is higher than that in clean LNNEA. We shown such abnormal cases in the Fig. 9, Algorithm 1
                              . Such phenomenon can also support that the LNNE is not sensitive to occlusion. Conversely, some occlusion can even benefit the performance. If confusing local silhouettes of “punch” that are similar to “wave” were occluded, the miss matching chance could be reduced accordingly.

Theoretically, the recognition speed of ordered methods is roughly 4 or 5 times faster than that of the other two methods. Table 3
                               demonstrates the efficiency comparison between the 3 scenarios. Their relative recognition speeds are close to our expectation. However, when increasing the matrix size, the Ordered LNNE is only 2–3 times faster than the other two since constructing an increased size of training matrix consumes more time in the kNN algorithm.

From the above results and analysis, our 3 methods demonstrate improved robustness for occluded multi-view action recognition compared to the published state-of-the-art methods. We particularly discuss the advantages and shortcomings for each of our methods in the following:

LNNE is the basis algorithm, and it can deal with both viewpoint variations and occlusions due to the odds-ratio adopted in Eq. (5). By subtracting the distance λ, misalignments and occluded responses are weighted down ultimately to zero, while only the most discriminative points can obtain large magnitudes, so that the inter-class distance is maximised.

This method demonstrates the best performance among all experiments. Such performance is achieved by pooling the local points of all views, so that the local points are complementary to each other. However, such a method is less efficient. In order to improve the efficiency, pre-processing is required to select the most representative local features so as to reduce the size of training set.

Both successful and failure cases are shown in Fig. 9. Since LNNE is based on nearest neighbour searching, if some of the local features in the training set are close to the query local features, misclassified dimensions may get a dominantly large weight and consequently affect the final decision. It can be seen that the occlusion can sometimes reduce the chance of misclassifying the query to particular class (Wave). As shown in the row of “Clean”, the query and misclassified actions have many similar postures. When some body parts are occluded or cluttered by surroundings, the remaining features could mainly come from the discriminative motion parts and therefore benefit the results.

The permutation and combination Eq. (7) is supported by our experimental results. The theoretically expected performance can be improved by increasing the number of independent views. However, in a realistic situation, it is required that the views are decorrelated to each other, otherwise, adding repeated voting is equivalent to weighting the views rather than equally boosting the weak classifiers in different views, and consequently, the performance guarantee does not hold.

A good balance between efficiency and effectiveness is achieved in the ordered scenario. However, it is restricted by the viewpoint variations. The results are lower than the other two due to existence of misaligned views in both databases. In addition, the superiority of LNNE over NBNN becomes more prominent in the ordered scenario. Especially on the New-IXMAS database, Ordered LNNE can withstand most of the interference of occlusions and disordered viewpoints, whereas the recognition rate of Ordered NBNN is degraded by roughly 20% compared to OLNNE.

In this paper, we have proposed an embedding algorithm, LNNE, and 3 fusion scenarios to deal with the occlusion problem in multi-view action recognition. We introduced an odds-ratio term in LNNE, and such a term can assign less weights to non-discriminative local features, which exist in both training and querying data. LNNE can also rectify misaligned views to a certain degree in order to fit itself to the fusion scenarios.

All 3 fusion methods outperform the state-of-the-art methods on both IXMAS and New IXMAS datasets. The LNNEA scenario is the most generalised approach. The LNNEV scenario fits a large number of independent views. On the other side, because LNNE is an on-line procedure, the above two methods are both computationally expensive due to the use of a large mixed training set of multiple views. In comparison, OLNNE is effective and efficient. However, OLNNE is not robust against severe variations of view orders.

In future work, we plan to improve the efficiency of the nearest neighbour-based searching technique. In addition, we will adapt the Ordered-LNNE approach to aligned data, and consequently investigate view alignment techniques for action recognition.

@&#REFERENCES@&#


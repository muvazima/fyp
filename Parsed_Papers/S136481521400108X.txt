@&#MAIN-TITLE@&#Serving many at once: How a database approach can create unity in dynamical ecosystem modelling

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Scientific and educational experience with the proposed Database Approach To Modelling (DATM) shows the following:


                        
                        
                           
                           It facilitated overview of and insight in the model by developers and users.


                        
                        
                           
                           Allowed for a much more dynamic scientific development of the model.


                        
                        
                           
                           Allowed for a direct implementation of these developments in multiple platforms.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Modelling framework

Programming language

Differential equation

Community-based modelling

Database approach to modelling

DATM

@&#ABSTRACT@&#


               
               
                  Simulation modelling in ecology is a field that is becoming increasingly compartmentalized. Here we propose a Database Approach To Modelling (DATM) to create unity in dynamical ecosystem modelling with differential equations. In this approach the storage of ecological knowledge is independent of the language and platform in which the model will be run. To create an instance of the model, the information in the database is translated and augmented with the language and platform specifics. This process is automated so that a new instance can be created each time the database is updated. We describe the approach using the simple Lotka–Volterra model and the complex ecosystem model for shallow lakes PCLake, which we automatically implement in the frameworks OSIRIS, GRIND for MATLAB, ACSL, R, DUFLOW and DELWAQ. A clear advantage of working in a database is the overview it provides. The simplicity of the approach only adds to its elegance.
               
            


                        
                           
                              
                           
                        
                     


                        
                           
                              
                           
                        
                     


                        
                           
                              
                           
                        
                     

@&#INTRODUCTION@&#

Since the onset of ecological simulation modelling based on differential equations – in the sixties and seventies of the last century – attempts have been made to bring conceptual unity through the development of modelling frameworks. In the field of aquatic ecology, such frameworks include the widely used DELWAQ – a library of water quality and ecology models developed by Delft Hydraulics (Delft Hydraulics, 1995; Deltares, 2013), as well as the Computational Aquatic Ecosystem Dynamics Model (CAEDYM) – a library of ecological process sub-models (Hipsey et al., 2007), AQUASIM (Reichert, 1994), the Dutch Waterboards' DUFLOW framework (Spaans et al., 1989) and the recently developed FABM – Framework for Aquatic Biogeochemical Models (http://fabm.sourceforge.net). Each of these frameworks is internally consistent, intuitive and well suited to answer the ecological questions it was designed for (Clemmens et al., 1993; Gal et al., 2004), and all are based on the same basic mathematical principles underlying the differential equations. Nonetheless, because these frameworks were developed independently, they all have their own sets of implementation requirements, language and coding specifications, spatial configuration options as well as boundary conditions and forcing function specifications, etc.

A user must therefore invest a considerable amount of effort to master any given framework, which in turn reduces the number of frameworks that any single user can master. The choice of framework to be used for any given project is thus primarily based on its availability, owned licenses, user experience and developer familiarity. This in turn leads to models being locked into their given frameworks, a narrowing-down of scientific expertise to the framework-scale and to the proverbial ‘re-invention of the wheel’ – i.e., the inefficient redevelopment of existing tools for each framework, rather than a more productive cross-pollination of approaches to analyze models across frameworks, institutions, disciplines and scientists (Leavesley et al., 2002; Mooij et al., 2010; Trolle et al., 2012). We are confronted with the paradoxical situation that, while there is unity within each framework, there is no unity at the level of the ecological models.

Here we propose a method to bring unity at the level of the ecological module, with the idea that many of the existing frameworks will continue to coexist, and that, taken together, they provide the user with a wide and rich array of tools for model analysis. We coin this method a ‘Database Approach To Modelling’ (DATM). We developed this approach for the ecosystem model for shallow lakes PCLake, and its twin model for linear waters PCDitch. However, our approach is in no way limited to these models. In fact, it applies to all models based on differential equations and probably even beyond. We here show how one can automatically link these models to a wide variety of frameworks, including OSIRIS (Mooij and Boersma, 1996), GRIND for MATLAB (available on http://www.sparcs-center.org/grind.html), ACSL (Mitchell and Gauthier, 1976), R (R Development Core Team, 2008), DUFLOW (Spaans et al., 1989) and DELWAQ (Deltares, 2013). Note that the latter two frameworks are spatially explicit and therefore are formulated in terms of partial differential equations (PDE's), whereas implementations of an ecological model (e.g. PCLake) in the general purpose frameworks are a set of ordinary differential equations (ODE's). We will show that with DATM we can overcome this difference, and translate a single code either in a set of ODE's in a general purpose framework or as the ecological component of a set of PDE's in these spatially explicit frameworks. In the latter case, these ecological components are then merged by the frameworks with the advective and diffusive transport of matter to get the full PDE. Please note that in its current form, DATM does not provide the spatial configuration of the model, this has still to be entered at the level of the framework.

To explain the principles of DATM, we use as an example the classical Lotka–Volterra equations. These equations represent the earliest use of coupled differential equations in ecology (Lotka, 1920; Volterra, 1926, 1931). With this example, we show how knowledge of quite a few framework-specific details is necessary to implement even this simplest of models in some of the most widely used mathematical frameworks. From experience, we have learned how implementing more complex models in more specific frameworks takes a considerable effort, which is why we propose to automate this process: an essential component of DATM is the set of translators developed to automatically convert the database definitions of a given model into a working implementation in a specific framework. Conceptually, we argue that the overview and insight that arises when the model definition is stored in the database, conveniently displayed in tables and accessed through queries, facilitates model development and understanding.

@&#METHODS@&#

DATM is based on the notion that ecological models are essentially rooted in mathematics. Here, we focus on models based on the mathematical concept of coupled differential equations. The dynamic systems represented by these equations have a universal mathematical notation. As an example, the Lotka–Volterra predator-prey equations can be read and understood by all in the following form:
                        
                           (1a)
                           
                              
                                 
                                    
                                       ⅆ
                                       V
                                    
                                    /
                                    
                                       ⅆ
                                       t
                                    
                                 
                                 =
                                 r
                                 
                                 V
                                 −
                                 a
                                 
                                 V
                                 
                                 P
                              
                           
                        
                     
                     
                        
                           (1b)
                           
                              
                                 
                                    
                                       ⅆ
                                       P
                                    
                                    /
                                    
                                       ⅆ
                                       t
                                    
                                 
                                 =
                                 a
                                 
                                 e
                                 
                                 V
                                 
                                 P
                                 −
                                 ⅆ
                                 P
                              
                           
                        
                     with state variables V for prey and P for predator; parameters r for autonomous growth rate of the prey; a the attack rate of the predator on the prey, e the conversion efficiency of the predator and d the autonomous death rate of the predator. This system is in this form fully defined and ready for simulation for a given set of parameters r, a, e and d and initial conditions V
                     
                        t=0 and P
                     
                        t=0. Our central point is that this mathematical notation for complex simulation models is sufficient to achieve unity and transparency in ecological modelling.

As shown in the above example, the set of coupled Equations (1a) and (1b) must be augmented with information on the interpretation of the various identifiers that are used in the model. As a minimum description, the identifiers must belong to a certain class (e.g. state variable, parameter); represent a specific component of the system (e.g. prey, predator); have units (e.g. biomass, number of individuals), and (initial) values. In scientific papers that document smaller models, such as the Lotka–Volterra model, this information is often organized in tables, with either a shared table for all identifiers or separate tables per class of identifiers. Given the number of identifiers in the more complex water quality models, we choose to work with separate tables for each class of identifiers. For the Lotka–Volterra model such tables could look like (note the ‘s’ prefix to identifiers of state variables):

for the states,

for the parameters and

for the derivatives. Extra columns with additional information, such as the references for the parameter values, can be added, of course, until all relevant information is stored in the tables. We thus reach a full documentation of the model in a set of linked tables; i.e., in a database.

To create an instance of the model for a certain framework, the information in the database of Tables 1–3
                     
                     
                      is translated and augmented to meet the specifications of running it in the chosen framework. For instance, a running version of the above model (Fig. 1
                     ) can be obtained by producing code for MATLAB (Box 1), Mathematica (Box 2), or R (Box 3).

Note that each of these implementations needs information that controls the simulation such as the integration method and time step (t-int) and the time interval over which the model is run (t-end). This essential information is specified in an additional table in the database (Table 4
                     ).

Additionally, tables can be included that hold input time series data for forcing functions, or data for calibration or validation. Simultaneously with the translation of the model code, the data are translated to the format needed by the different frameworks.

To apply the approach, we implemented the Tables 1–4 in a Microsoft Excel Workbook as Worksheets (see Section S1 of the online supplementary material). We would like to stress that any program that can hold tables could be used. We chose Excel because it is widely available, and most people are familiar with it. Microsoft Access is an alternative that might provide a more rigid control of the database, but fewer people have experience with it. A freeware alternative would be LibreOffice, which also has the advantage of being easily portable to Mac, Linux and Windows.

Using Excel Macros and Visual Basic for Applications (VBA), we wrote translators that turn the information provided in Tables 1–4 into the working scripts provided in Boxes 1–3
                     
                     
                      (the code of the translators can be found in Section S2 of the online supplementary material and the code they produce in Section S3 A–C of the online supplementary material). Again, these translators can be written in any language that easily handles tables, records, and text strings such as R, Python or PERL. We chose VBA because it is embedded in Excel. The validity of these translators can be checked by comparing the results of benchmark runs against each other. These not only show the (dis)similarity in model outcomes, but also give an indication of the performance of the model under study in each framework. Thereafter, the model can be analyzed with the tools provided by each framework (e.g. the “paranal” function for sensitivity analysis in GRIND for MATLAB). DATM therefore provides easy access to existing tools of analysis in various frameworks, without providing these tools itself.

We have applied the methodology described above to implement the ecosystem models for shallow lakes PCLake (Janse et al., 2008, 2010) and for shallow linear waters PCDitch (Janse, 1998; Van Liere et al., 2007) in the frameworks OSIRIS, ACSL, GRIND for MATLAB, R, DUFLOW and DELWAQ. PCLake and PCDitch are integrated ecological models to study the main nutrient and food web dynamics of shallow lakes and ditches in response to eutrophication and associated restoration measures (See Mooij et al., 2010 for a comparison with other water quality models). Both models are frequently used in both water quality management and for scientific investigations. For brevity, we will only refer to PCLake in the results, since its implementation is technically equivalent to that of PCDitch.

@&#RESULTS@&#

PCLake is about two orders of magnitude more complex than the Lotka–Volterra model. It has 104 state variables and approximately 400 parameters. Instead of calculating the right hand sides of the differential equations directly, it uses near 1500 intermediate variables to calculate components that are used in the 104 differential equations. PCLake also includes a set of equations that are calculated before running the simulation to make sure that the initial values of the states obey certain basic biological rules (e.g. stoichiometric constraints) when initial values are provided only for dry-weight values but not for N and P. These equations also set the initial composition of the sediment. The PCLake database therefore consists of five instead of four tables: 1) Simulation information, 2) States, 3) Parameters, 4) Initial equations, 5) Dynamic equations (calculation of auxiliaries and derivatives). The last table could have been split into two tables but with experience we find that we get a better model-overview when auxiliaries and the derivatives are in a single table. We refer to Section S4 of the online supplementary material for the definition of each table of the PCLake implementation in DATM and for a comparison with the Lotka–Volterra example.


                     Tables 1–4 show the minimal record structure for each table in the Lotka–Volterra example. For PCLake in DATM, we added a column to each table to number the identifiers, and a column to provide additional information per identifier. The table approach also allows one to enter multiple input vectors for initial values of states and of parameters. By adding variables to the simulation table that specify which input vector is used in a given simulation, one can compare model runs for various initial values and/or parameter sets. This approach can be extended to the column in which the model equations are specified. Different columns then characterize multiple versions of the model in a single table. The version of the equations to be used can then be specified in the simulation table. This allows for a straightforward comparison of runs for different model equations and even for different model structures where, for example, certain state variables and associated fluxes are added or switched off. DATM thus facilitates sensitivity analyses on both parameters and model structure.

The Lotka–Volterra example only contains the addition (+), multiplication (*) and equality (=) mathematical operators, but more complex models can include power (e.g. ^), relational operators (e.g. >) and logical operators (e.g. AND), as well as conditional statements (e.g. IF-THEN-ELSE). Operators and statements have distinct implementations in the dominant multi-purpose computer languages such as C++ and FORTRAN. The difference is usually in the syntax (e.g. ‘&&’ in C++ is ‘.and.’ in FORTRAN), though sometimes operators do not have their equivalent in all languages (e.g. the power-operator is missing in C++). Furthermore, some frameworks have their own computer languages, such as DUFLOW, where modules are written in the language DUPROL. Table 5
                      contains a complete list of translations used in PCLake and PCDitch.

All operators except ‘=’, ‘+’ and ‘*’ and all standard mathematical functions are given a unique text-based identifier in the database. These unique identifiers of operators and functions are then translated into an automated search-and-replace operation. For this reason, a correct translation into any specific language can only be guaranteed if operators cannot be confused with parts of names of other identifiers. In the same way, the names of identifiers, state variables, parameters or intermediate variables must be completely unique, i.e. they should not be contained in the name of any other identifier. Each identifier in the database is therefore preceded and followed by a unique symbol. We propose to use the underscore, since it has no specific meaning in mathematics and enhances the readability of the equations.

The database format prescribes that all the right hand terms for a given identifier are given on a single line; we therefore used the following style:
                        
                           
                        
                     
                  

Another small obstacle towards generality is the absence of a power operator in C-based languages. Power functions such ab are entered in the database with a combination of both styles: _POW_ (a _^_ b), which can easily be translated to C as pow(a, b), or to FORTRAN as (a ** b) (note the essential parenthesis).

As demonstrated in the implementations of the Lotka–Volterra model in MATLAB, R and Mathematica, the model code is preceded and followed by certain statements that bridge the code defining the model sensu stricto and the framework. What information should be provided – or omitted – depends on the specific framework; some frameworks make use of a graphical user interface that is difficult to circumvent (e.g. DUFLOW). The spatial capabilities of DELWAQ and DUFLOW prescribe that the corresponding simple single cell modules for hydrology and transport available in PCLake should be excluded during translation, as these processes are taken care of by these frameworks. Note that the integration between the ODE process formulations provided by DATM and the PDE process formulations of the framework is taken care of by the framework. To enable integration with an existing water quality model, process modules formulated as ODE's can be stored in a repository in both DUFLOW and DELWAQ. The DATM translator simply adds another model to these repositories. For spatially-explicit frameworks that lack such build-in facilities for the incorporation of water quality models formulated as ODE's, a more customized integration is necessary, given that any framework should have some formal entry point for these equations. As of yet, however, we do not have experience with such frameworks. Some details about the richer structure of the implementation of PCLake (and PCDitch) in the different frameworks can be found in Section S5 of the online supplementary material.

After solving the inevitable errors that are reported by the compiler or interpreter, it is essential to check that the newly translated code functions correctly. An effective first step is to calculate the value of each identifier (all parameters, initial states, intermediate variables and derivatives) at t = 0 and compare these values with a control set. This dump output at t = 0 is also very useful in studying the main and side effects of changes to the code and is therefore a standard asset of the approach that we advocate.

Secondly, benchmark simulations of varying complexity reveal the proper functioning of conditional statements and forcing functions. This is clearly shown as we overlay time plots from two different frameworks (Fig. 2
                     a, b). Of course, small differences remain because of machine rounding of errors and small differences arising from numerical integration. However, these differences are several orders of magnitude smaller than the ecological range of each state and therefore not visible when we plot the outcome of all frameworks for a given state against each other over this full range (Fig. 3
                     ). Such benchmark runs also demonstrate the runtime performance, which can be an important criterion for the choice of a framework. Obviously, one is limited in such runs to a model setup that can be handled by all the frameworks that participate in the test.

One should take into consideration that most platforms support different routines for numerical integration that do not need to be the same and thus influence both the accuracy of the model output and the runtime performance. Moreover, the difference between compiled languages (e.g. C++, FORTRAN) and scripting languages (e.g. R, MATLAB) can be misleading. While scripting languages generally have the advantage of supporting more compact code, powerful libraries, shorter interactive development cycle and interactive graphics and statistics, compiled languages are usually much faster and, in some sense, offer more freedom. For complex models a hybrid implementation is a sensible option, thereby making use of the advantages of both concepts. For example, for the current implementation of PCLake in the R environment, the model equations are not actually translated into R, instead they are solved in C++ (cf. Soetaert et al., 2010). To do so, R compiles the in C++ coded model equations into a .DLL and invokes this .DLL to numerically integrate the model. Note that while both the OSIRIS and the R implementation use C++ code, this is not exactly the same code because each framework has its own exact specification of the function call to the C++ routine with the ecological process formulations of PCLake. So, while the DATM translators for OSIRIS and R have much in common, there are subtle differences to meet the exact requirements of each framework.

@&#DISCUSSION@&#

The DATM approach we here present allows ecology to take precedence over informatics. We achieve this by formulating the model in the fundamental and universal language of mathematics, and by systematically complementing this mathematical notation with the necessary metadata. The translators create a seamless bridge between the mathematical formulation of the model in the database and the framework-specific implementations.

Experience gained during years of development of PCLake was the main driver behind the development of DATM. PCLake was initially developed in the ACSL framework (Mitchell and Gauthier, 1976), which served as an excellent platform for model development, but where license costs limited the distribution of the model. As this distribution-bottleneck hindered wider use of the model, version 4.08 of PCLake was translated to DUFLOW, a framework that also allows spatial configurations of the model (Jeuken et al., 1999). To further respond to user needs, this version was then translated into DELWAQ and OSIRIS (Mooij et al., 2010). Each translation involved first distinguishing model- from framework-code, and then translating the framework code. Although these translations were semi-automated, each translation represented a big time investment, in which only a few scientists, undaunted by the complexity of the model and specifics of the different frameworks, could effectively carry out the translations and verifications. These efforts monopolized energy away from further model application, analysis and development. The universal mathematical notation we here advocate greatly simplifies the translation process, and makes it much more dynamic and robust at the same time. This allows for direct translation of a new model version in the framework of choice, thereby greatly facilitating the process of model development. Typically, the time needed to develop and test a new translator varies between a few hours for a simple model like the Lotka–Volterra equations to a week for a complex model like PCLake for any given framework.

The erstwhile barriers to framework-switching have led to each framework developing more complex modules to accommodate the growing scope of simulation models. These developments not only make the underlying ecological processes and assumptions more difficult to access, but also require the user to select more options and provide more detail. These developments can in turn reduce the in-depth understanding of the model. Paradoxically, this form of model-framework co-evolution leads to a necessary simplification of a model to make it graspable and useful for ecological theory (Van Nes and Scheffer, 2005; Scheffer and Beets, 1994), whereas the purpose of adding complexity to the framework ought to be to uncover more complex processes in models.

The diversity of analysis tools available across frameworks can greatly enhance our scientific understanding of any given ecological model. In that sense, the database is used to specify where to go, while the different translators and associated frameworks represent ways to get there. One could take route-planning software as a metaphor: the user gives a final destination whereupon the route-planner proposes alternative routes depending on the type of transport one prefers (i.e. bus, train, car, walking, airplane etc.). To explore the ecological code in detail one should go ‘by foot’, (e.g. using GRIND for MATLAB), while for fast simulation runs an ‘airplane’ would be more convenient (e.g. OSIRIS). Before entering the territory of spatial complexity of the system with frameworks like DUFLOW and DELWAQ, it might be useful to perform an in-depth analysis of the ecological part of the model in a 0D context. Here, we can exploit the potential of DATM to translate a single code to either a set of ODE's for a general purpose framework of the required ecological component or the PDE's of a spatially explicit water quality modelling framework. To study the asymptotic behaviour of PCLake, translators for bifurcation programs such as MatCont (Dhooge et al., 2003) and AUTO (Doedel et al., 2007) are planned. For the most optimal use of the capabilities offered by the different frameworks, however, proper frameworks-specific user knowledge will always be a prerequisite. For the more simple analysis that are provided by most frameworks, however, DATM allows one to stick to the framework one is familiar with and is not forced to learn a new framework.

Experience teaches that DATM also facilitates model simplification by making use of the very existence of a database: providing a clear overview of all model equations and the possibility to label them (e.g. code for spatial dimensioning, hydrology, integration, or user-interface). By means of queries, groups of model equations can easily be identified, grouped and then switched off or simplified. Because columns can be easily duplicated, one can specify multiple versions of the model concurrently in a single table, and then specify which version of the equations is used in a specific simulation. For example, one can easily compare how different types of functional response functions affect model outcome. By “experiments in model structure”, DATM is a relatively straightforward tool for assessing model structural uncertainty in addition to input and parameter uncertainty, which is seldom examined (Mooij et al., 2010). DATM thus also potentially allows for model structure optimization, whereby different model structures can be rapidly assessed as part of an optimization process and the most optimal structure is selected (Recknagel et al., 2008). Completing the columns with the necessary meta-information has the additional advantage of contributing to ‘good modelling practice’ by improving communication among those working with the model (Scholten et al., 2007).

There is increased need for community-based approaches to ecosystem modelling, in order to bring together the knowledge and expertise of ecologists across fields and methodological approaches (Mooij et al., 2010; Trolle et al., 2012). The DATM approach we present here is ideal for building community based approaches: indeed, using a common language (mathematics) and grammar (DATM + translation platform) makes the cross-pollination of ideas and expertise between frameworks, institutes, disciplines and approaches both easier and more attractive. This is not restricted to the field of aquatic ecosystem modelling, as other scientific disciplines can also benefit from a standardized and easily understandable formulation of processes and equations (Jeltsch et al., 2013), allowing one to explore more complex questions in a multidisciplinary setting, and enhancing the interaction with environmental management (Scholten et al., 2007). Additionally, the structure provided allows for easy reuse of pieces of code and processes, thereby preventing ‘reinventions of the wheel’ (Mooij et al., 2010). To further promote model development, we strongly encourage DATM initiatives to be released under the GNU General Public License (http://www.gnu.org/licenses/gpl-3.0.txt), or the GNU Lesser General Public License (http://www.gnu.org/licenses/lgpl-3.0.txt) so that open sharing of common versions of models is guaranteed.

Emphasis on the model rather than on the framework has an added educational value: teachers can focus on the ecological principles of interest and students can rely on their existing mathematical knowledge to access these principles instead of being first subjected to an often superficial crash-course in a framework's implementation specifics. Our approach thus also makes the model more directly manipulatable by students, irrespective of their framework experiences, and ensures their understanding of model dynamics is based on the ecological model, rather than confounded by framework options. In fact, the Lotka–Volterra DATM example that we presented here and provide as a digital appendix can be of direct use in an educational context.

It is necessary to store the equations in the correct order in the database. With this we mean that each variable must be assigned a value before it is used in the assignment of another variable (in other words, it must first be used as a left hand term before it is used as a right hand term). Some frameworks such as GRIND for MATLAB and ASCL do this sorting automatically, but others do not have this facility. To stay compliant with the latter frameworks, the statements should be ordered already in the database. Fortunately, most compilers or interpreters do provide the user with warning messages accompanied by helpful information when the sequence is violated. Yet, one of the disadvantages of code generators (and other top-level structures which hide implementation details) is that they can make debugging difficult. This is remedied by an iterative procedure, where the user edits and tests the generated code temporarily and then goes back to the table, which gives just another argument for readable code and proper indentation.

We do not claim that our approach is unique in all respects. For instance, both the ECOBAS (http://www.ecobas.org/ecobas/index.html) and SED-ML (http://sed-ml.org/) initiative aim at creating unity in dynamical modelling. ECOBAS provides an overview of ecological models with their metadata and references to the models themselves. SED-ML provides a unifying language for the implementation of dynamical models. DATM balances between those approaches by providing the actual models, but with a focus on the mathematics of the model instead of the informatics. The idea to implement the complete model in a database resembles the design concept of the modelling framework SMART (Kramer and Scholten, 2001). The current version of SMART, however, does not allow translating and exporting models to other frameworks, whereas this is a key-feature of DATM. Automated code translators are already in use at the level of individual frameworks (e.g. SMILE, Muetzelfeldt and Massheder, 2003), although mostly for simpler models. Moreover, there are important advances in establishing a community-based framework for aquatic ecosystem models aiming at unity at the framework level, i.e. the Framework for Aquatic Biogeochemical Models (FABM) (Trolle et al., 2012). A number of the advantages mentioned here are also covered by FABM, such as easy inclusion of new variables and equations, and automatically incorporating different physical assumptions in 0D-3D. DATM complements such efforts – i.e., DATM may also translate models into the FABM framework – thereby providing unique abilities to address some of the challenges and opportunities that remain in the field of aquatic ecosystem modelling (Mooij et al., 2010).

At the onset of this project, our humble aim was to maintain long-term availability and use of PCLake and PCDitch. Happily, this work produced a remarkable and unexpected spin-off: with DATM we have acquired the ability to interactively use multiple frameworks in a single study and even within a single analysis. This dynamic shift in framework use, and more importantly in ecological simulation model analyses, will likely represent a cornerstone in the further development of ecological modelling. As illustrated with the Lotka–Volterra model and the use of Excel and VBA, the ingredients need not be exotic for the pudding to be tasty.

@&#ACKNOWLEDGEMENTS@&#

The development of DATM for PCLake and PCDitch was financed by the Netherlands Foundation for Applied Water Research (STOWA) project no. 443237, the China-Netherlands Joint Scientific Thematic Research Programme (JSTP) of the Netherlands Organisation for Scientific Research (NWO) project no. 842.00.009, the Netherlands Environmental Assessment Agency (PBL) and the Netherlands Institute of Ecology (NIOO-KNAW). This is manuscript 5609 of the Netherlands Institute of Ecology (NIOO-KNAW).

The following is the supplementary data related to this article:
                        
                           
                        
                     
                     
                        
                           
                        
                     
                  

Supplementary data related to this article can be found at http://dx.doi.org/10.1016/j.envsoft.2014.04.004.

@&#REFERENCES@&#


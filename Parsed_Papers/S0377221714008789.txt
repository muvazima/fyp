@&#MAIN-TITLE@&#The iPICEA-g: a new hybrid evolutionary multi-criteria decision making approach using the brushing technique

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a new method to model decision-maker preference, the brushing technique.


                        
                        
                           
                           Using the brushing technique, a new decision-making method iPICEA-g is proposed.


                        
                        
                           
                           Experimental results show iPICEA-g performs well.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Preference articulation

Decision making

Multi-objective optimization

Evolutionary algorithms

@&#ABSTRACT@&#


               
               
                  Various preference-based multi-objective evolutionary algorithms have been developed to help a decision-maker search for his/her preferred solutions to multi-objective problems. In most of the existing approaches the decision-maker preferences are formulated either by mathematical expressions such as the utility function or simply by numerical values such as aspiration levels and weights. However, in some sense a decision-maker may find it easier to specify preferences visually by drawing rather than using numbers. This paper introduces such a method, namely, the brushing technique. Using this technique the decision-maker can specify his/her preferences easily by drawing in the objective space. Combining the brushing technique with one existing algorithm PICEA-g, we present a novel approach named iPICEA-g for an interactive decision-making. The performance of iPICEA-g is tested on a set of benchmark problems and is shown to be good.
               
            

@&#INTRODUCTION@&#

Multi-objective problems (MOPs) regularly arise in many real-world decision problems, that is, the solutions are required to meet multiple performance criteria (or objectives) simultaneously. These objectives are often conflicting, wherein an improvement in one objective cannot be achieved without detriment to another objective. In this case, there is no single solution to a MOP that can be selected objectively; rather a set of solutions exists, representing different performance trade-offs between criteria. In this setting, the subjective preferences of a decision maker (DM) have to be considered so as to identify a single satisfied solution.

According to when decision maker preferences are incorporated, i.e. before, during or after the search, hybrid evolutionary multi-criteria decision making approaches can be divided into three classes – a priori, interactive and a posteriori, respectively. In an a priori decision making approach, the DM preferences are incorporated prior to the search process. When the DM preferences can be faithfully captured in a mathematical model, an a priori method would be effective and efficient. However, this is rarely the case. In an interactive decision making approach, the DM preferences are incorporated progressively during the optimization process. This enables a DM to learn about the problem and fine-tune his/her preferences if needed, effectively guiding the search towards regions of interest and away from exploring non-interesting solutions. The main limitation of this scheme is that the DM may need to be involved intensively during the search process. In an a posteriori decision making approach, the DM preferences are incorporated after the search; an approximation of the Pareto optimal front is found first followed by selection of a preferred solution by the DM from the set of trade-off solutions presented.

An a posteriori approach can be effective for MOPs with 2 or 3 objectives – a good approximation of the Pareto optimal front can be obtained and easily be presented to the DM, enabling him/her to confidently select a preferred solution. However, a posteriori schemes become less effective on MOPs with higher number of objectives, sometimes termed many-objective problems (MaOPs, Purshouse and Fleming, 2003). Not only does the computational burden for solving these problems become very expensive, the approaches become more inefficient since the DM often is only interested in particular regions of the Pareto front. Furthermore, the number of Pareto optimal solutions required for describing the entire Pareto optimal front of a MaOP is usually very large. Selecting one preferred solution from all these solutions is cognitively difficult. Thus, to facilitate the process of decision making, the alternative is to consider incorporating DM preferences a priori or interactively into the evolutionary multi-objective (EMO) approaches. Such hybrid approaches might take advantages of both EMO and multi-criteria decision making methods.

To date, considerable effort has been spent on developing efficient hybrid evolutionary multi-criteria decision making approaches, including, for example, MOGA (Fonseca and Fleming, 1998a), G-MOEA (Branke, 2001), reference point based NSGA-II (Deb and Sundar, 2006), reference direction based NSGA-II (Deb and Kumar, 2007a), utility function (pair wise comparison) based MOEA (Phelps and Köksalan, 2003). Amongst these methods, some elicit a direct model of preferences, e.g. reference point (aspirations), reference direction, and trade-off information. Other methods construct a preference model indirectly based on elicitation of some examples of holistic judgements, such as utility function.

Eliciting direct preference information from the DM requires a high cognitive effort, and so can be counter productive in real-world decision making situations. Eliciting indirect preferences (i.e., utility functions) tends to be less demanding in terms of cognitive effort. However, it is argued that constructing an appropriate utility function, e.g., via pair wise comparisons (Branke et al., 2009; 2010), may not be easy (Köksalan et al., 2013). This study proposes a new method called the brushing technique which enables a DM to specify his/her
                        1
                     
                     
                        1
                        Throughout this paper, we use he instead of he/she, and his instead of his/her for brevity.
                      preferences simply by drawing, that is, brushing his/her preferred region in the objective space, see Fig. 1
                     (a). According to the brushed region, the preference information is elicited and then is incorporated into an algorithm to search for solutions that are of interest to the DM, see Fig. 1(b). Combining the brushing technique with the preference-inspired co-evolutionary algorithm using goal vectors (PICEA-g) (Purshouse et al., 2011; Wang et al., 2013a), a new hybrid evolutionary multi-criteria decision making approach, denoted as iPICEA-g, is proposed, which provides users an alternative approach to conduct multi-criteria decision making.

The remainder of this paper is structured as follows: in Section 2 a review of hybrid evolutionary multi-criteria decision making approaches is provided. Following that, Section 3 elaborates the iPICEA-g. Section 4 empirically studies the performance of iPICEA-g on different problems. Section 5 concludes this paper.

This section reviews some representative hybrid evolutionary multi-criteria decision making approaches, classified as direct preference mode based, and indirect preference model based. There are other approaches to those presented here, such as the Interactive Surrogate Worth Trade-off method (Vira and Haimes, 1983), the NIMBUS approach (Miettinen and Mäkelä, 1995) and others proposed in Steuer and Choo (1983),Korhonen and Laakso (1986),Korhonen et al. (1984) and Köksalan and Sagala (1995). However they have yet to be combined with EMO approaches and are not reviewed here.

There is a large body of approaches using a direct preference model, including reference point (aspirations) based, weights related information based (e.g. lexicographical ordering, relative importance order, reference direction and light beam search), trade-off information based and other forms.

Perhaps MOGA developed by Fonseca and Fleming (1993) is the earliest such approach. The DM preference is specified as aspirations and the non-dominated ranking mechanism is extended to accommodate aspiration levels, enabling the search to be gradually guided towards the DM region of interest. MOGA was further extended by introducing a preferability operator, with which both goals and priorities can be accommodated in the ranking scheme (Fonseca and Fleming, 1998a). This new ranking scheme provides a unification of Pareto optimality, the lexicographic method, goal programming, constraint satisfaction and constrained optimization. MOGA has been successfully used in optimising a low-pressure spool-speed governor of a Pegasus gas turbine engine and many other applications (Fleming et al., 2005; Fonseca and Fleming, 1998b). The main weakness of this approach is that it requires a DM to know the ranges of objective values so as to initialize coherent aspiration levels.

Another representative approach that uses aspirations was proposed by Molina et al. (2009). A dominance relation called g-dominance (g refers to goals) is defined; solutions satisfying all the aspirations and solutions fulfilling none of the aspirations are preferred over solutions satisfying some aspirations. An approach called g-NSGA-II that combines g-dominance and NSGA-II is proposed to search for solutions satisfying the specified aspirations. This algorithm works regardless of whether the specified goal vector is feasible or infeasible. However, it is demonstrated in Said and Bechikh (2010) that g-NSGA-II faces difficulties when the provided goal vector is close to the true Pareto front (as the approach does not preserve a Pareto based ordering). Handling of multiple ROIs by g-NSGA-II is not considered. Intuitively, the g-dominance relation is not easy to extend to handle multiple ROIs as an individual can g-dominate one goal vector, and simultaneously, be g-dominated by another goal vector.


                           Deb and Sundar (2006) proposed a reference point based NSGA-II (R-NSGA-II) for searching for solutions close to a DM specified reference point. The reference point is not applied in a classical way, i.e. together with an achievement scalarizing function (Wierzbicki, 1980), but rather by establishing a biased crowding scheme. Solutions near reference points are emphasized by the selection mechanisms. The extent and the distribution of the solutions is maintained by a user defined parameter ɛ. The efficiency of R-NSGA-II is demonstrated on MOPs with up to ten objectives. R-NSGA-II can also handle multiple ROIs simply by using multiple reference points. In addition to the NSGA-II, (Allmendinger et al., 2008) hybridized the reference point approach with particle swarm optimization (PSO) approach.


                           Thiele et al. (2009) hybridized the reference point with an indicator based evolutionary algorithm (PBEA). The reference point is applied to an achievement scalarizing function and this is then incorporated into the binary indicator function, the ɛ-indicator (Zitzler et al., 2003) (which is Pareto dominance preserving). The spread range of the obtained solutions is controlled by an additional parameter which might be not easy to configure.


                           Said and Bechikh (2010) proposed another reference point based approach, the r-NSGA-II . In their study, the reference point is employed to modify the usual dominance principle, resulting in a new dominance relation, named r-dominance, which can be used to create a strict partial order over non-dominated solutions. The r-dominance relation prefers solutions that are closer to the specified reference point, and simultaneously preserves the order induced by Pareto dominance relation. The approach r-NSGA-II is derived from NSGA-II by replacing the Pareto dominance relation with the r-dominance relation. The algorithm has other two additional parameters δ and w. δ ∈ [0, 1] is used to control the range of the ROIs, and w expresses the bias of the DM. The performance of r-NSGA-II is assessed on a set of benchmarks ranging from 2 to 10-objective problems and is shown to be good in guiding the search towards both single and multiple ROIs. However, as pointed out by the authors, r-NSGA-II faces difficulties on multi-modal problems, such as ZDT4.


                           Deb and Kumar (2007a) combined the reference direction with NSGA-II. The reference direction is incorporated into an achievement scalarizing function which is used to guide the search towards a preferred region. Multiple ROIs are obtained by specifying multiple reference directions. The efficiency of this approach is demonstrated on MOPs with up to ten objectives. Again, the spread range of the ROI is controlled by a user defined parameter.


                           Deb and Kumar (2007b) also hybridized the light beam search method with NSGA-II. The hybridized approach is able to search for part(s) of Pareto optimal fronts illuminated by the light beam emanating from a starting point to the reference point with a span controlled by a threshold. This approach also performs well on MOPs with up to ten objectives. The light beam search is also hybridized with MSPSO algorithm (Wickramasinghe and Li, 2008; 2009). Again, the issue is how to appropriately control the spread range of the obtained solutions.


                           Branke (2001) proposed a guided evolutionary multi-objective optimization approach, denoted as G-MOEA. In G-MOEA the DM preferences are manifested through a modification of the dominance relation, specifying an maximally acceptable trade-off rate between objectives, i.e. one unit improvement in objective fi
                            is worth at most aij
                            units in objective fj
                           . G-MOEA works well for two objectives. However, providing all pair-wise information for a problem with many objectives is cognitively intensive and needs 
                              
                                 
                                    
                                       M
                                       2
                                    
                                    −
                                    M
                                 
                                 2
                              
                            comparisons.


                           Branke and Deb (2005) suggested a modified and controllable biased crowding approach. Their approach aims to search for a set of solutions that are parallel to an iso-utility function defined by a specified reference direction. Specifically, a parameter is applied to control the range of ROI along the Pareto optimal front. This parameter is defined as the ratio of the real distances between neighbouring solutions on the Pareto optimal front and the projected distance of the same solutions on a plane defined by a linear utility function.


                           Zitzler et al. (2007) integrated weight preferences in the calculation of hypervolume indicator. The weighted hypervolume indicator serves as a means of integrating the DM preferences. Auger et al. (2009) applied this idea to HypE and proposed the weighted hypervolume based HypE. W-HypE is demonstrated to perform well in searching for preferred solutions for both bi and many-objective problems. The only issue is that the spread range of the ROI is controlled by a deviation parameter in the weight distribution function. Defining a proper value for this parameter is not easy for a decision maker.


                           Karahan and Köksalan (2010) proposed a steady-state elitist evolutionary algorithm, named the territory defining evolutionary algorithm (TDEA). Similar to ɛ-MOEA (Deb et al., 2003), TDEA defines a territory around each individual so as to prevent crowding. A smaller territory corresponds to a denser coverage of solutions (i.e. more neighbouring solutions), and a larger territory corresponds to a sparser coverage of solutions. Based on TDEA, the authors developed an a priori approach, named prTDEA, in which the DM specifies his/her preferred region by a weight set. Solutions in the preferred region and non-interesting region are then assigned different territories such that more solutions are obtained in the preferred region(s).

Most of the previously mentioned methods (e.g. MOGA, R-NSGA-II, G-MOEA) can be turned into interactive approaches simply by allowing the DM to adjust preferences and continue the optimization interactively. For example, Köksalan and Karahan (2010) proposed iTDEA as an interactive extension of the TDEA. In the iTDEA, the DM is asked to choose his/her preferred solutions from a set of representative solutions at each interaction. A territory is then defined around those preferred solutions so as to obtain more solutions around them, obtaining denser coverage of these interesting regions. This procedure continues till the algorithm finds a satisfactory solution. The iTDEA is tested on three problems using three different utility function types to simulate the DM responses. Experimental results show that iTDEA converges well to the DM simulated preferred regions.

Indirect preference model in this study refers to that the DM preferences are not specified directly as numerical values like reference point, reference direction but are elicited by comparisons of solutions. Results of the comparison are then used to build a utility function to model the DM preference. In an indirect preference model based approach, the DM preferences are modelled based on obtained solutions. Thus, such approaches are often used interactively.


                        Phelps and Köksalan (2003) proposed to elicit the DM preference by pairwise comparisons of solutions. This preference information is further used to obtain a ‘most compatible weight vector via linear programming methods, resulting in a linearly weighted sum utility function. This aggregate objective is optimized in the subsequent generations using an evolutionary algorithm till new comparisons of solutions are provided. This approach is one of the earliest interactive evolutionary multi-objective algorithm which paved a way to current interactive EMO approaches. Similar to Phelps and Köksalan (2003),Fowler et al. (2010) used a more general quasi-concave utility function to form the DM preference as a preference cone consisting of inferior solutions. Their approach is tested on multi-objective knapsack problems and is found to perform well.


                        Jaszkiewicz (2007) also proposed to elicit the DM preference from pairwise comparison of solutions. However, this strategy does not aim to identify a single most likely utility function but, rather, simultaneously maintains a range of utility functions compatible with the elicited preferences. In other words, the preference information is not applied to create a single compatible weight vector but to reduce the set of possible weight vectors.


                        Greco et al. (2008a) proposed another utility function based approach in which a logical preference model is built using the Dominance-based Rough Set Approach (DRSA). DRSA (Greco et al., 2001; 2008b) is a methodology of multiple criteria decision analysis which is used for structuring the DM preferences in terms of the most general and understandable ‘if …, then …’ decision rules. Their approach works as follows: once an approximation of solutions is obtained, the DM is then asked to indicate those relatively good solutions. Having this information, a preference model structured in terms of ‘if …, then …’ decision rules is induced using DRSA. This preference model is then applied to refine the obtained solutions, cutting off non-interesting solutions. The procedure continues until a satisfactory solution is found. Following the study of Greco et al. (2008a), Two other approaches, called DRSA-EMO and DRSA-EMO-PCI, are proposed in Greco et al. (2010). In these two approaches, the DM preferences are elicited by sorting some solutions in the current population into ‘relatively good’ and ‘others’, or by pairwise comparison of solutions, respectively. The main advantage of these three approaches is that the preference model is composed of a set of user-friendly decision rules.

In Deb et al. (2010), the DM is asked to order a given set of alternatives from best to worst. This preference information is then used to model a strictly increasing polynomial value function (PVF). The constructed PVF is utilized to redefine the dominance principle, and drive the EMO approach (NSGA-II is applied in Deb et al., 2010) to search for preferred solutions for the subsequent iterations until the next ‘DM call’. Following the study of Deb et al. (2010),Sinha et al. (2010a) augmented the polynomial value function into a generalized polynomial value function that fits a wider variety of quasi-concave preference information. Also, in Sinha et al. (2010b), a polyhedral cone is used to construct the DM preference.

Having reviewed these approaches, we can observe that (i) in direct preference model based approaches, the DM has to articulate his/her preferences by numerical values which, in some sense, might not be cognitively easy, and (ii) in indirect preference model based approaches, instead of using numerical values, the DM preferences are elicited via comparisons of solutions. This can be effective for 2 and 3-objective problems. However, when applied to MaOPs, the number of comparisons times required for ranking the solutions may increase significantly. Based on these observations, this study proposes a new method, namely, the brushing technique. Instead of specifying the numerical values or performing comparisons of solutions, it allows a DM to express his preference simply via drawing, i.e., brushing his preferred region in the objective space.

This section describes our proposed method, wherein the brushing technique is used. Specifically, we elaborate how the PICEA-g, an EMO approach, can be turned into a hybrid evolutionary multi-criteria decision making approach, iPICEA-g, and how the brushing technique is used in iPICEA-g.

PICEA-g is a co-evolutionary approach in which the usual population of candidate solutions is co-evolved with a set of goal vectors during the search (Wang et al., 2013a; 2013b). In this algorithm, candidate solutions gain fitness by Pareto dominating a particular set of goal vectors in the objective space, but the fitness contribution is shared between other solutions that also satisfy those goals. Goal vectors only gain fitness by being Pareto dominated by a candidate solution, but the fitness is reduced the more times the goals are dominated by other solutions in the population. Please refer to Appendix A for more details on the fitness calculation mechanism in PICEA-g.

Inspired from this fitness assignment scheme, it is easy to imagine that if goal vectors are exclusively generated in an area, for example, the shaded region in Fig. 2
                     , then candidate solutions inside this area would be encouraged in the evolution. This is because that these candidate solutions can dominate more goal vectors and so are more likely to gain higher fitness, while candidate solutions outside this area can only dominate few goal vectors and so are likely to have lower fitness. Therefore, candidate solutions will exhibit a tendency to approach to the Pareto optimal front enclosed by this area. Having known this, we can simply generate goal vectors in appropriate areas so as to guide solutions towards a region of interest to a DM. Fig. 2 illustrates that different sets of goal vectors lead to different solutions.

Next we describe how the brushing technique is used in the iPICEA-g. Assuming that a set of solutions has been obtained, and is presented to the DM. Then, a region in the objective space is brushed by the DM. Fig. 3
                     (a) illustrates the brushed region (the shaded ellipse) in Cartesian coordinate system. As the Cartesian coordinate system is not suitable for displaying high-dimension data, parallel coordinate system is used in MaOPs. Fig. 3(b) illustrates how a brushed region (the shaded band) is in the parallel coordinate system.

From Fig. 3 shows that the brushing technique enables a DM to avoid the use of numerical values, instead, visually brush his preferred region. For bi- and tri-objective problems where solutions can be presented using the Cartesian coordinate system, the DM not only can visually express his preferences but also knows the location of his brushed region in objective space.
                        2
                     
                     
                        2
                        It is worth mentioning that brushing on the Cartesian coordinate system for tri-objective problems is not as straightforward as that is done for bi-objective problems due to the fact that we often do not use a three dimensional spherical display system, e.g., spherical computer monitor (Ritchey, 1992).
                      For solutions that are presented using the parallel coordinate system, although the DM cannot know the location of his brushed region in the objective space, he knows the location of the brushed region in comparison to other solutions. By knowing such information, the DM could feel more confident on his selected region.

Having obtained the brushed region, the next step is to build an area for generating goal vectors such that solutions can be guided towards the preferred region. For the convenience of illustration, this is discussed using a bi-objective case in the Cartesian coordinate system, see Fig. 4
                     . Assuming that the DM brushes a region A, goal vectors are to be generated in the shaded area enclosed by z* and g
                     
                        max
                      as shown in Fig. 4(a). z* is the estimated ideal point. g
                     
                        max
                      is a vector that is estimated based on the objective vectors of the current non-dominated solutions f(S*), where S* refers to the current non-dominated solutions. Specifically, g
                     
                        max
                      = β × f(S*), β > 1. β is suggested as 1.5 through a set of preliminary tests. In order to describe this shaded area, two other parameters– w and θ, are needed, see Fig. 4(b). w describes a reference direction from the z* to the centre of A. Parameter θ measures the angle between the reference direction and the direction from the ideal point to the extreme point. An extreme point is defined as an objective vector that has the largest value in one objective. For example, P
                     1 and P
                     2 are two extreme points of the region A. θ can be calculated by 
                        
                           arccos
                           (
                           
                              
                                 P
                                 
                                    
                                       z
                                    
                                    *
                                 
                              
                              →
                           
                           ·
                           
                              
                                 
                                    P
                                    1
                                    ′
                                 
                                 
                                    
                                       z
                                    
                                    *
                                 
                              
                              →
                           
                           )
                        
                     . It is easy to understand that in parallel coordinate systems, the reference direction w and parameter θ can be calculated the same way.

In addition, the area can also be constructed in other forms. For example, we can simply build the area as a rectangle (or a hyper-cube in MaOPs) using z* and g
                     
                        max
                     , see Fig. 5
                     . However, as this study focuses on illustrating the integration of the brushing technique and the PICEA-g, effects of different methods are not discussed specifically, and will be left as a future study.

Instead of using the Pareto dominance relation, the Pareto cone-dominance (Batista et al., 2011) is employed in iPICEA-g to determine whether a goal vector g is met by a candidate solution s or not. Specifically, g is said to be Pareto cone-dominated by s, if and only if the angle between the vector 
                        
                           
                              f
                              (
                              
                                 s
                              
                              )
                              
                                 g
                              
                           
                           →
                        
                      and the vector 
                        
                           
                              f
                              
                                 (
                                 
                                    s
                                 
                                 )
                              
                              
                                 
                                    z
                                 
                                 *
                              
                           
                           →
                        
                      is not larger than θ. For example, in Fig. 6
                     , g
                     1 is Pareto cone-dominated by candidate solution s
                     1 while g
                     2 is not Pareto cone-dominated by s
                     1. The mathematical definition of the Pareto cone-dominance is presented in Appendix B. Compared with Pareto dominance, the use of Pareto cone-dominance can further emphasise the solutions along the reference direction, w, i.e., assigning higher fitness to these solutions. For example, in terms of Pareto dominance, s
                     2 can satisfy some goal vectors and therefore might be retained in the evolution. However, s
                     2 is not in the ROI. When using Pareto cone-dominance, s
                     2 cannot satisfy any goal vector, having the lowest fitness and then would be more likely to be disregard in the evolution.

Intuitively, driving the search towards a narrow region at the beginning of optimization process will cause a lack of population diversity and result in low search efficiency or converge to a local optimum (Coello et al., 2007, pp. 131–143). In order to avoid this problem, we start the search with a large search range θ′ and gradually, decrease θ′ to the preferred θ gradually. The decrease process is set in Eq. (1)
                     
                        
                           (1)
                           
                              
                                 
                                    θ
                                    
                                       u
                                       s
                                       e
                                    
                                 
                                 =
                                 
                                    θ
                                    ′
                                 
                                 −
                                 
                                    (
                                    
                                       θ
                                       ′
                                    
                                    −
                                    θ
                                    )
                                 
                                 ×
                                 
                                    (
                                    
                                       
                                          g
                                          e
                                          n
                                       
                                       
                                          m
                                          a
                                          x
                                          G
                                          e
                                          n
                                       
                                    
                                    )
                                 
                                 ;
                              
                           
                        
                     where gen is the current generation, maxGen is the maximum generations, The benefits of this strategy will be illustrated in the subsequent section.

Finally, the interaction of the analyst and the DM when using iPICEA-g is as follows:
                        3
                     
                     
                        3
                        The source code of iPICEA-g is available at https://drive.google.com/folderview?id=0B1Tvn88FrkeFdXpOY1NDY2RscVE&usp=sharing.
                     
                     
                        
                           (i)
                           Run iPICEA-g without any preferences for a number of generations and to gain some basic information of the problem, e.g., the range of the Pareto front.

The analyst elicits the DM preferences by asking him to brush his preferred region(s). According to the brushed region(s), goal vectors are generated in an appropriate area.

Next, the algorithm sets the population size of candidate solutions and the number of goal vectors and the stopping criterion. Subsequently, iPICEA-g is performed till the stopping criterion is met.

The obtained solutions are presented to the DM. If the DM is satisfied with the provided solutions then stop the search process. Otherwise, ask the DM to brushes new region(s), then return to (ii).

@&#EXPERIMENTS@&#

This section examines the performance of iPICEA-g on searching for solutions in the region(s) of interest to a decision-maker. In all the experiments, the population size of candidate solutions and the number of goal vectors are set as 100. The simulated binary crossover (SBX, pc
                      = 1, ηc
                      = 15) and polynomial mutation (PM, pm
                      = 1/n per decision variable and ηm
                      = 20, where n is the number of decision variables) (Deb et al., 2002) are used as genetic operators.

Prior to presenting the experimental results, we demonstrate the effect of the adaptive management of θ described in Eq. (1). The 10-variable ZDT4 which features multi-modality is taken as test problem. Assuming the DM would like to obtain optimal solutions along the search direction w = (0.2, 0.8). Simultaneously, a relatively narrow spread range of ROI is required, i.e., 
                        
                           θ
                           =
                           
                              π
                              18
                           
                        
                      radians. We perform two runs of iPICEA-g. The first run uses the initial search range 
                        
                           
                              θ
                              ′
                           
                           =
                           
                              π
                              4
                           
                        
                      radians while the second run uses 
                        
                           
                              θ
                              ′
                           
                           =
                           
                              π
                              9
                           
                        
                      radians. The obtained results are shown in Fig. 7
                     . iPICEA-g with 
                        
                           
                              θ
                              ′
                           
                           =
                           
                              π
                              4
                           
                        
                      radians has obtained solutions close to the Pareto optimal front. However, the solutions obtained by iPICEA-g with 
                        
                           
                              θ
                              ′
                           
                           =
                           
                              π
                              9
                           
                        
                      radians are still far away from the Pareto optimal front. Such results clearly demonstrate the benefits of the adaptive process of θ. A large initial search range enables iPICEA-g to do more exploration in the early stage of the search, producing more diversified solutions. Therefore, the possibility of being trapped in a local optimum is reduced.

Assuming that the DM has brushed a preferred region, this section examines whether the iPICEA-g can find solutions in the region(s) of interest to the DM. To quantitatively measure the convergence of the obtained solutions, the generational distance (GD) (Van Veldhuizen and Lamont, 2000) is employed.
                           4
                        
                        
                           4
                           Readers can refer to Appendix C for a definition of the GD metric.
                         A small GD value indicates that the obtained solution set is close to the Pareto optimal front. The reported results are evaluated using 31 independent trials. The obtained Pareto front with the median GD value is shown. Unless otherwise specified, θ′ is set as 
                           
                              θ
                              +
                              
                                 π
                                 9
                              
                           
                         radians, parameters z* and g
                        
                           max
                         are set as (0, 0, …, 0), (1, 1, …, 1) in all the following experiments.

First, the bi-objective DTLZ4 problem is used as a test problem. According to the brushed region, the corresponding parameters are configured as w = (0.5, 0.5) and 
                              
                                 θ
                                 =
                                 
                                    π
                                    6
                                 
                              
                            radians. After running iPICEA-g for 250 generations a set of satisfied solutions is obtained shown in Fig. 8
                           (a). It is observed that all the obtained solutions are close to the Pareto optimal front.

Second, the 4-objective DTLZ4 problem is chosen as another test problem to examine the scalability of iPICEA-g. Assuming that the converted parameters are w = (0.25, 0.25, 0.25, 0.25) and 
                              
                                 θ
                                 =
                                 
                                    π
                                    36
                                 
                              
                            radians. After running iPICEA-g for 250 generations a set of solutions are obtained as shown in Fig. 8(b). All the obtained solutions are concentrated around the projected reference point 
                              
                                 
                                    z
                                 
                                 
                                    R
                                    ′
                                 
                              
                            shown as − ⋆ − (the white line in the middle). 
                              
                                 
                                    z
                                 
                                 
                                    R
                                    ′
                                 
                              
                            represents the Pareto optimal solution along the search direction (0.25, 0.25, 0.25, 0.25), namely it is the point of intersection of the ray emanating from the ideal point with the direction w. After computing 
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    4
                                 
                                 
                                    f
                                    i
                                    2
                                 
                                 
                                    (
                                    S
                                    )
                                 
                              
                            (S refers to all the obtained solutions), the values lie within the range [1.0391, 1.0903], therefore indicating that all solutions have converged to the true Pareto front.

Statistically, the mean ± standard deviation of the GD metric over the 31 independent runs are 0.0010 ± 0.0005 for DTLZ4-2 and 0.0041 ± 0.0012 for DTLZ4-4. Such results confirm that the obtained solutions converge well to the true Pareto front. Note that DTLZn-Y refers to the nth DTLZ problem with Y objectives.

Next we examine the performance of iPICEA-g on searching for multiple ROIs. The bi- and four-objective DTLZ2 problems are used as test problems. For the DTLZ2-2 problem, we assume the DM has brushed two regions and the corresponding parameters are configured as w = (0.2, 0.8), 
                              
                                 θ
                                 =
                                 
                                    π
                                    6
                                 
                              
                            radians and w = (0.8, 0.2), 
                              
                                 θ
                                 =
                                 
                                    π
                                    6
                                 
                              
                            radians, respectively. After running iPICEA-g for 250 generations two sets of solutions are obtained as shown in Fig. 9
                           (a). We can observe that all the obtained solutions are close to the Pareto optimal front. This is also confirmed by the GD metric, that is, the mean ± standard deviation of the GD values are 0.0006 ± 0.0003.

For the DTLZ2-4 problem we assume that the DM has brushed three regions and the related parameters are configured as (i) w = (0.1, 0.2, 0.3, 0.4) and 
                              
                                 θ
                                 =
                                 
                                    π
                                    20
                                 
                              
                            radians; (ii) w = (0.4, 0.3, 0.2, 0.1) and 
                              
                                 θ
                                 =
                                 
                                    π
                                    20
                                 
                              
                            radians; and (iii) w = (0.25, 0.25, 0.25, 0.25) and 
                              
                                 θ
                                 =
                                 
                                    π
                                    20
                                 
                              
                            radians. After running iPICEA-g for 250 generations three sets of solutions are obtained as shown in Fig. 9(b). It is observed that in each set solutions are concentrated around the projected reference point 
                              
                                 
                                    z
                                 
                                 
                                    R
                                    ′
                                 
                              
                            shown as − ⋆ − . After computing 
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    4
                                 
                                 
                                    f
                                    i
                                    2
                                 
                                 
                                    (
                                    S
                                    )
                                 
                              
                            (S refers to all the obtained solutions), the values lie within the range [1.0515, 1.1049], therefore indicating that all solutions have converged close to the true Pareto front. Statistically, the mean ± standard deviation of the GD values over the 31 independent runs are 0.0024 ± 0.0011 for DTLZ2-4. Such results further confirm that the obtained solutions converge well to the true Pareto front.

Overall, from the above results it is demonstrated that iPICEA-g is able to search for solutions that are of interest to the decision-maker. Also, the obtained solutions are close to the true Pareto front.

In order to further demonstrate the efficiency and effectiveness of iPICEA-g, we compare iPICEA-g with another powerful hybrid multi-criteria evolutionary decision-making approach, namely, iTDEA (see p. 8) on different test problems from the ZDT and DTLZ test suites. The reason for choosing iTDEA as the competitor algorithm is that iTDEA is reported to perform well both in terms of convergence to desired solutions and the cognitive practicality (Köksalan and Karahan, 2010).

To simplify the comparison process, we assume that the DM interacts with the search process only one time. That is, after running the algorithm, without incorporating any DM preference, for several generations, a set of solutions is presented to the DM. At this stage, the DM incorporates his preference into the algorithm. Such preference is used till the end of search.

The comparison contains two sets of experiments: (i) experiments of searching for a single ROI, and (ii) searching for multiple ROIs. Specifically, the selected ZDT and DTLZ test problems are shown in Table 1
                        . The number of decision variable for ZDT and DTLZ test problems are set to 20 and 50, respectively. In order to obtain similar ROIs for both algorithms, related parameters, w and θ in iPICEA-g and W
                        
                           p
                         in iTDEA, are configured specially, see Table 1. Parameters w and θ are used to describe a brushed region. Parameter W
                        
                           p
                         contains a set of Tchebycheff weights that is used to define a preferred region. Parameters τp
                         and τu
                         in iTDEA are used to control the density of the preferred region and the remaining region, respectively.

For statistical analysis, we replicate each test 31 times. In each test, both algorithms are run for 250 generations. we filter out the individuals of the two algorithms corresponding to the preference region and compute their GD and the Inverted Generational Distance (IGD) values. These metrics are computed against the true Pareto optimal front filtered with respect to the preference region of the test. The comparison results are summarized in Tables 2
                         and 3
                        . The non-parametric Wilcoxon-ranksum two-sided comparison (Hollander and Wolfe, 1999) procedure at the 95 percent confidence level is employed to test if the two algorithms performs comparably in terms of the selected performance metric. The symbol ‘ < ’, ‘ = ’ or ‘ > ’ means iPICEA-g performs statistically worse, equal or better than iTDEA at 95 percent confidence level.

From the GD results shown in Table 2, we can observe that (i) on searching a single ROI, iPICEA-g performs comparably with iTDEA on ZDT4, DTLZ2-2 and DTLZ1-3. For DTLZ1-2 iTDEA achieves a better convergence, while for DTLZ2-5 iPICEA-g performs better; (ii) on searching for multiply ROIs, the two algorithms have comparable convergence on the three bi-objective problems. On DTLZ1-3 and DTLZ2-5, iPICEA-g performs better than iTDEA. From the IGD results shown in Table 3, it is observed that, when searching for a single ROI, iPICEA-g and iTDEA perform comparably on all problems except for DTLZ2-5 where iPICEA-g performs better. When searching for multiple ROIs, the iPICEA-g outperforms iTDEA for DTLZ1-2, DTLZ1-3 and DTLZ2-5, and performs comparably with iTDEA on the remaining two problems.

Based on the experimental results, it is therefore concluded that iPICEA-g and iTDEA perform comparably on most of the test problems. However, on many-objective problems, e.g., DTLZ2-5, iPICEA-g performs better than iTDEA. One possible reason is that the territory value τp
                         is not appropriately configured. As described in Köksalan and Karahan (2010), the iTDEA shares some commons with the ɛ-EMOA (Deb et al., 2005). It has been demonstrated that the performance of ɛ-EMOA is influenced by the setting of ɛ value (Deb et al., 2005).

In this section we illustrate the use of the brushing technique. To describe the scenario, we solve the bi-objective ZDT1 and four-objective DTLZ4 problems by simulating an interactive search process. The population size of candidate solutions and the number of goal vectors is set to N = 200 and Ngoal = 200.

Firstly, iPICEA-g is run for 10 generations without incorporating any preferences. The aim is to roughly know the range of the objectives so as to inform the DM’s initial preferences. The obtained solutions are shown in Fig. 10
                           (a).

Secondly, the DM brushes his preferred region, i.e., ellipses A and B, see Fig. 10(a). The parameters of iPICEA-g are then configured based on the brushed solutions, which are w = (0.05, 0.95), 
                              
                                 θ
                                 =
                                 
                                    
                                       5
                                       π
                                    
                                    36
                                 
                              
                            radians and w = (0.45, 0.55), 
                              
                                 θ
                                 =
                                 
                                    π
                                    18
                                 
                              
                            radians for A and B, respectively. After running iPICEA-g for 50 more generations, two sets of improved solutions are found as shown in Fig. 10(b).

Thirdly, we assume that the DM is not satisfied with the obtained solutions. He again brushes a set of solutions that are of his interest, see Fig. 10(b), solutions in ellipse C. The related parameter settings are w = (0.76, 0.24), 
                              
                                 θ
                                 =
                                 
                                    π
                                    12
                                 
                              
                            radians. By running iPICEA-g for another 50 generations, a set of solutions are found, see Fig. 10(c).

Lastly, the DM remains dissatisfied, and, would like to focuses on a part of these solutions – a set of solutions that is of his interest is brushed (region D in Fig. 10(c)). iPICEA-g is run for 50 more generations. The related parameters are configured as w = (0.5, 0.5), 
                              
                                 θ
                                 =
                                 
                                    π
                                    18
                                 
                              
                            radians. A set of better solutions are found. The DM is now happy to choose a solution from this set, see Fig. 10(d).

Similarly, iPICEA-g is run without introducing any preference for 50 generations. A set of solutions are found as shown in Fig. 11
                           (a).

Next, the DM brushes the preferred region for each objective (see Fig. 11(a)). The selected solutions are shown in Fig. 11(b). Parameters w and θ are then calculated as (0.255, 0.255, 0.255, 0.255) and 
                              
                                 π
                                 6
                              
                            radians. iPICEA-g is run for 50 more generations. An improved set of solutions is obtained, see Fig. 11(c).

Thirdly, assuming DM is dissatisfied with the obtained solutions. He brushes some solutions that are of interest (see Fig. 11(d)). Based on the brushed solutions, two ROIs are identified. The related parameters are configured by w = (0.3986, 0.3500, 0.1105, 0.1409), 
                              
                                 θ
                                 =
                                 
                                    π
                                    12
                                 
                              
                            radians and w = (0.1124, 0.2249, 0.3498, 0.3128), 
                              
                                 θ
                                 =
                                 
                                    
                                       7
                                       π
                                    
                                    90
                                 
                              
                            radians. The brushed solutions are shown in Fig. 11(e). After running iPICEA-g for another 50 generations, more solutions are found, see Fig. 11(f).

Fourthly, the DM is still not satisfied with the obtained solutions. He decides to explore one set of the obtained solutions. Again, he brushes his preferred region shown as the grey band in Fig. 11(f). The existing solutions that are satisfied are extracted and presented in Fig. 12
                           (b). The iPICEA-g is run for 50 more generations. w is set to (0.3691, 0.2773, 0.1383, 0.2153), θ is set as 
                              
                                 π
                                 36
                              
                            radians. Seen from Fig. 12(c), a set of refined solutions are found in this preferred region. We compute 
                              
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    4
                                 
                                 
                                    f
                                    i
                                    2
                                 
                                 
                                    (
                                    S
                                    )
                                 
                              
                            for all the obtained solutions. The value lies within the range of [1.0190, 1.041] which indicates that the obtained solutions have converged well to the true Pareto front. The DM is now happy to choose a solution from this set. The solution shown as the white dash line is selected; see Fig. 12(d).

@&#CONCLUSIONS@&#

Incorporation of DM preference is an important part of a real-world decision support system. However, current methods for preference formulation are all based on numerical values, e.g., aspirations, reference direction/point or utility functions. This study proposes a method named the brushing technique which enhances the DM-friendliness by allowing preferences to be expressed simply via drawing, that is, the DM brushes his/her preferred regions directly in the objective space. Combining the brushing technique with an effective MOEA, i.e., the PICEA-g, a new hybrid evolutionarily multi-criteria decision-making approach, namely, iPICEA-g is proposed. The performance of iPICEA-g is examined on a set of test problems and is shown to be good.

We have also identified three potential directions for future research. First, since decision-making is often a group rather than individual activity, it would be useful to develop a methodology to support a group decision making process. Also, since the DM preferences are often expressed in fuzzy linguistic terms (Jin and Sendhoff, 2002; Rachmawati and Srinivasan, 2010), it would be interesting to investigate how fuzzy preferences can be incorporated in our method. Concluding, the application of iPICEA-g to a real-world decision-making problem would be interesting as it has the potential of revealing issues that can further foster improvement of our method. A user friendly interface for using iPICEA-g is currently under development.

@&#ACKNOWLEDGMENTS@&#

The research was conducted in Automatic Control and Systems Engineering, University of Sheffield and the first author is grateful for the facilities and support provided by the University. Also, the authors would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the manuscript. The first author would also like to thank the National Natural Science Foundation of China (No. 61403404) and the National University of Defense Technology (No. JC14-05-01) for their financial support.

The exact fitness calculation methods for candidate solutions, s and goal vectors, g are defined by formulas (A.1), (A.2) and (A.3) (Wang et al., 2013a):

                        
                           (A.1)
                           
                              
                                 
                                    F
                                    
                                       s
                                    
                                 
                                 =
                                 0
                                 +
                                 
                                    ∑
                                    
                                       {
                                       
                                          g
                                       
                                       ∈
                                       G
                                       ⊎
                                       
                                          G
                                          C
                                       
                                       
                                       |
                                       
                                       
                                          s
                                       
                                       ⪯
                                       
                                          g
                                       
                                       }
                                    
                                 
                                 
                                    1
                                    
                                       n
                                       g
                                    
                                 
                              
                           
                        
                     where ng
                      is the number of solutions that satisfy preference g. Note that if s does not satisfy any g then the Fs
                      of the s is defined as 0. and

                        
                           (A.2)
                           
                              
                                 
                                    F
                                    
                                       g
                                    
                                 
                                 =
                                 
                                    1
                                    
                                       1
                                       +
                                       α
                                    
                                 
                              
                           
                        
                     
                     
                        
                           (A.3)
                           
                              
                                 α
                                 =
                                 
                                    {
                                    
                                       
                                          
                                             1
                                          
                                          
                                             
                                                
                                                   n
                                                   g
                                                
                                                =
                                                0
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      n
                                                      g
                                                   
                                                   −
                                                   1
                                                
                                                
                                                   2
                                                   N
                                                   −
                                                   1
                                                
                                             
                                          
                                          
                                             
                                                o
                                                t
                                                h
                                                e
                                                r
                                                w
                                                i
                                                s
                                                e
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where N is the number of candidate solutions.

Mathematically, given two feasible vectors x, y we say x Pareto cone-dominates y, x⪯
                        cone
                     
                     y: if and only if 
                        
                           
                              y
                           
                           ∈
                           C
                           ,
                        
                      where 
                        C
                      is a generated cone by weight vector w
                     1, w
                     2, …, w
                     
                        M
                     , i.e. 
                        
                           C
                           =
                           {
                           
                              z
                           
                           :
                           
                           
                              z
                           
                           =
                           
                              λ
                              1
                           
                           
                              
                                 w
                                 1
                              
                           
                           +
                           
                              λ
                              2
                           
                           
                              
                                 w
                                 2
                              
                           
                           ,
                           …
                           ,
                           
                              λ
                              M
                           
                           
                              
                                 w
                                 M
                              
                           
                           ,
                           
                           ∀
                           
                              λ
                              i
                           
                           >
                           0
                           }
                        
                     . Fig. B1
                      illustrates the generated cone of x in bi-objective space.

The GD metric measures the mean distance from objective vectors in the approximation set to the nearest neighbour in the reference set, in our experiments this is a subset of the true Pareto front. Small values for the GD metric imply that the obtained solution set is close, in terms of the ℓ2-norm, to the Pareto optimal front. The GD metric is defined as follows:

                        
                           (C.1)
                           
                              
                                 G
                                 
                                    D
                                    p
                                 
                                 
                                    (
                                    S
                                    ,
                                    
                                       P
                                       *
                                    
                                    )
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             |
                                             S
                                             |
                                          
                                       
                                       
                                          d
                                          i
                                       
                                       
                                          (
                                          
                                             a
                                             i
                                          
                                          ,
                                          
                                             P
                                             *
                                          
                                          )
                                       
                                    
                                    
                                       |
                                       S
                                       |
                                    
                                 
                              
                           
                        
                     where P* is the reference set of representative Pareto optimal solutions, |S| is the cardinality of the set S, of obtained solutions and,

                        
                           (C.2)
                           
                              
                                 
                                    d
                                    i
                                 
                                 
                                    (
                                    
                                       
                                          a
                                       
                                       i
                                    
                                    ,
                                    
                                       P
                                       *
                                    
                                    )
                                 
                                 =
                                 
                                    min
                                    
                                       p
                                       ∈
                                       
                                          P
                                          *
                                       
                                    
                                 
                                 
                                    {
                                    ∥
                                 
                                 
                                    
                                       a
                                    
                                    i
                                 
                                 −
                                 
                                    p
                                 
                                 
                                    
                                       ∥
                                       2
                                    
                                    :
                                    
                                       
                                          a
                                       
                                       i
                                    
                                    ∈
                                    S
                                    }
                                 
                                 ,
                              
                           
                        
                     is the minimum Euclidean distance of an objective vector, a
                     
                        i
                      ∈ S, from the reference set P*.

The IGD metric measures the mean distance from objective vectors in the reference set to the nearest neighbour in the approximation set. Mathematically, the relation between the GD and IGD metrics are as follows:

                        
                           (C.3)
                           
                              
                                 I
                                 G
                                 
                                    D
                                    p
                                 
                                 
                                    (
                                    S
                                    ,
                                    
                                       P
                                       *
                                    
                                    )
                                 
                                 =
                                 G
                                 
                                    D
                                    p
                                 
                                 
                                    (
                                    
                                       P
                                       *
                                    
                                    ,
                                    S
                                    )
                                 
                              
                           
                        
                     
                  

@&#REFERENCES@&#


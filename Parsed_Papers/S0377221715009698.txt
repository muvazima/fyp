@&#MAIN-TITLE@&#A differential evolution algorithm with self-adaptive strategy and control parameters based on symmetric Latin hypercube design for unconstrained optimization problems

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose an adaptive DE algorithm for unconstrained optimization problems.


                        
                        
                           
                           Symmetric Latin hypercube design is employed to initialize the population.


                        
                        
                           
                           Trial vector generation strategy adaptation is introduced.


                        
                        
                           
                           Control parameters adaptation is introduced.


                        
                        
                           
                           Experimental results show that SLADE is better than other DE algorithms.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Evolutionary computations

Differential evolution

Parameter adaptation

Strategy adaptation

Symmetric Latin hypercube design

@&#ABSTRACT@&#


               
               
                  This paper presents a differential evolution (DE) algorithm, namely SLADE, with self-adaptive strategy and control parameters for unconstrained optimization problems. In SLADE, the population is initialized by symmetric Latin hypercube design (SLHD) to increase the diversity of the initial population. Moreover, the trial vector generation strategy assigned to each target individual is adaptively selected from the strategy candidate pool to match different stages of the evolution according to their previous successful experience. SLADE employs Cauchy distribution and normal distribution to update the control parameters CR and F to appropriate values during the evolutionary process. A large amount of simulation experiments and comparisons have been made by employing a set of 25 benchmark functions. Experimental results show that SLADE is better than, or at least comparable to, other classic or adaptive DE algorithms, and SLHD is effective for improving the performance of SLADE.
               
            

@&#INTRODUCTION@&#

The differential evolution (DE) algorithm is a population-based stochastic search technique proposed by Storn and Price (Storn & Price, 1997) for global optimization in real-world applications (Joshi & Sanderson, 1999; Price, Storn, & Lampinen, 2006; Zhang, Avasarala, Sanderson, & Mullen, 2008; Zhang, Avasarala, & Subbu, 2010). The DE algorithm has been applied in many domains, such as signal processing (Storn, 1996), pattern recognition (Ilonen, Kamarainen, & Lampinen, 2003), dynamic systems (Angira & Santosh, 2007), power dispatch (Varadarajan & Swarup, 2008), scheduling (Deng & Gu, 2012; Tsai, Fang, & Chou, 2013), nuclear safety (Di Maio, Baronchelli, & Zio, 2014), and continuous steel casting (Mlakar, Petelin, Tušar, & Filipič, 2015), and achieved better results than most evolutionary algorithms (EAs), including the GA algorithm (Gonçalves & Resende, 2015; Li et al., 2015; Zhang et al., 2014).

Like other evolutionary algorithms, DE repeats mutation, crossover, and selection operators generation by generation to evolve its solution toward the global optimum. There are many trial vector generation strategies, and different strategies have different search capabilities for different problems in different stages of the evolutionary process. Moreover, there are three crucial associated parameters, i.e., population size NP, scaling factor F, and crossover rate CR. They may seriously affect the performance of DE (Kovačević, Mladenović, Petrović, & Milošević, 2014; Qin, Huang, & Suganthan, 2009), such as convergence rate, robustness and searching precision. When using DE to solve optimization problems, the trial vector generation strategy and its associated control parameters that best fit a specific optimization problem should be determined by a time-consuming trial-and-error procedure. Several reports in the literatures have shown that some trial vector generation strategies and the associated parameter values of DE are good for global search (Gong, Cai, Ling, & Li, 2011; Price et al., 2006; Qin et al., 2009), while some others are good for local fine tuning (Gong et al., 2011; Mezura-Montes, Velázquez-Reyes, & Coello Coello, 2006; Zhang & Sanderson, 2009). The best trial vector generation strategy and the associated parameter values may be different during different stages of the search process (Brest, Greiner, Boskovic, Mernik, & Zumer, 2006).

Therefore, it is important to develop new DE variants with strategy adaptation and control parameters adaptation. Some different adaptation schemes have been proposed by many researchers to avoid the time-consuming trial-and-error procedure. Brest et al. (Brest et al., 2006) proposed a new DE algorithm for adaptively obtaining control parameter values. The control parameter values are encoded into each individual, and constantly updated along with the evolution. The proposed algorithm shows good performance on numerical benchmark problems. Qin et al. (Qin et al., 2009) proposed a self-adaptive differential evolution algorithm. Two mutation strategies are employed, and assigned to each individual according to a given probability. The probability of assigning each mutation strategy is updated according to the number of trial vectors surviving to the next generation. Zhang and Sanderson (Zhang & Sanderson, 2009) proposed an adaptive differential evolution called JADE. JADE implements a new mutation strategy, “DE/current-to-pbest”, with an external archive and automatically updates control parameters according to previously successful experiences. The external archive stores inferior solutions to provide a promising direction for the search process. These operations can not only avoid premature convergence but also diversify the population. Pan et al. (Pan, Suganthan, Wang, Gao, & Mallipeddi, 2011) proposed a self-adaptive differential evolution algorithm called SspDE. In this algorithm, mutation strategy and control parameters have been assigned to each individual. If the obtained offspring is better than its parent, the associated mutation strategy and control parameters will be stored in three winning lists, respectively. After a given number of iterations, the mutation strategy and control parameters will be reassigned to each individual by selecting from the winning lists according to a high probability or randomly generated values. In this way, both the mutation strategy and the control parameters can constantly be adjusted along with the evolution. Elsayed and Sarker et al. (Elsayed, Sarker, & Essam, 2013) proposed an improved differential evolution algorithm that introduces an ensemble of different mutation operators. Moreover, to improve the exploitation ability of the proposed algorithm, a covariance adaptation matrix evolution strategy algorithm is employed for a local search. Zou et al. (Zou, Wu, Gao, & Li, 2013) proposed a modified differential evolution algorithm called MDE. To increase the diversity of the entire population, MDE employs a Gaussian distribution and uniform distribution to generate control parameter values. An external archive is introduced to provide some high quality solutions for selection as candidate solutions. Two common mutation strategies are selected according to the present iteration number. Furthermore, a central solution generated by averaging all of the other candidate solutions provides a potential search direction. Asafuddoula et al. (Asafuddoula, Ray, & Sarker, 2014) proposed an adaptive hybrid DE algorithm. To balance the exploration and exploitation capacity of the algorithm, a binomial crossover is employed in the early stages of evolution, while an exponential crossover is employed in later stages. Moreover, the crossover rate is self-adaptive according to the success rate, which is updated based on the success or failure of the offspring generated. A gradient local search is invoked from the best solution to locate any better solution.

In this paper, we propose a differential evolution algorithm, namely, SLADE, with self-adaptive strategy and control parameters, which employs the symmetric Latin hypercube design (SLHD) to initialize the population. During the evolution, a suitable mutation strategy is selected from a candidate pool for each individual according to their previous experience in generating promising solutions. In addition, control parameters are generated according to normal distribution and Cauchy distribution for each individual by learning from previous experience. The experimental results and comparisons indicate that SLADE performs better than the state-of-the-art DE variants such as DE (Storn & Price, 1995), SADE (Brest et al., 2006), JADE (Zhang & Sanderson, 2009), SspDE (Pan et al., 2011) and MDE (Zou et al., 2013) for solving unconstrained optimization problems, and SLHD is effective for improving the performance of SLADE.

The remainder of this paper is organized as follows. Section 2 introduces the standard DE algorithms. Section 3 describes the SLADE algorithm in detail. Section 4 lists the benchmark functions from CEC2005(Suganthan et al., 2005). Section 5 introduces the experimental design, and experimental results for the comparisons of SLADE with the other algorithms. Finally, the conclusions are discussed in Section 6.

The differential evolution algorithm follows the general procedure of an evolutionary algorithm (Deb & Agrawal, 1994). The initial population PG
                      which consists of NP target individuals Xi,G, i =1,2,…,NP, is initialized randomly according to a uniform distribution between predefined search ranges [Xmin, Xmax
                     ]
                        D
                     , where D is the dimension of the problem and G is the current generation. Then, mutation, crossover and selection operations are employed, and the above process is repeated until a termination criterion is reached.

For each target vector Xi,G
                        , a mutation operation is employed to generate a mutant vector Vi,G
                        . There are many mutation strategies, such as the following five equations (Baatar, Zhang, & Koh, 2013; Chen et al., 2015; Gong & Cai, 2013; Lin et al., 2015; Wang, Cai, & Zhang, 2011):

                           
                              (1)
                              
                                 
                                    
                                       V
                                       
                                          i
                                          ,
                                          G
                                       
                                    
                                    =
                                    
                                       X
                                       
                                          r
                                          1
                                          ,
                                          G
                                       
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             2
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             3
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       V
                                       
                                          i
                                          ,
                                          G
                                       
                                    
                                    =
                                    
                                       X
                                       
                                          b
                                          e
                                          s
                                          t
                                          ,
                                          G
                                       
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             1
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             2
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             V
                                             
                                                i
                                                ,
                                                G
                                             
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                X
                                                
                                                   i
                                                   ,
                                                   G
                                                
                                             
                                             +
                                             F
                                             ×
                                             
                                                (
                                                
                                                   X
                                                   
                                                      b
                                                      e
                                                      s
                                                      t
                                                      ,
                                                      G
                                                   
                                                
                                                −
                                                
                                                   X
                                                   
                                                      i
                                                      ,
                                                      G
                                                   
                                                
                                                )
                                             
                                             +
                                             F
                                             ×
                                             
                                                (
                                                
                                                   X
                                                   
                                                      r
                                                      1
                                                      ,
                                                      G
                                                   
                                                
                                                −
                                                
                                                   X
                                                   
                                                      r
                                                      2
                                                      ,
                                                      G
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             F
                                             ×
                                             (
                                             
                                                X
                                                
                                                   r
                                                   3
                                                   ,
                                                   G
                                                
                                             
                                             −
                                             
                                                X
                                                
                                                   r
                                                   4
                                                   ,
                                                   G
                                                
                                             
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    
                                       V
                                       
                                          i
                                          ,
                                          G
                                       
                                    
                                    =
                                    
                                       X
                                       
                                          b
                                          e
                                          s
                                          t
                                          ,
                                          G
                                       
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             1
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             2
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             3
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             4
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        
                        
                           
                              (5)
                              
                                 
                                    
                                       V
                                       
                                          i
                                          ,
                                          G
                                       
                                    
                                    =
                                    
                                       X
                                       
                                          r
                                          5
                                          ,
                                          G
                                       
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             1
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             2
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                    +
                                    F
                                    ×
                                    
                                       (
                                       
                                          X
                                          
                                             r
                                             3
                                             ,
                                             G
                                          
                                       
                                       −
                                       
                                          X
                                          
                                             r
                                             4
                                             ,
                                             G
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where F is the mutation scale factor, which is a positive constant. Xbest,G
                         is the best solution at the current generation G. r1, r2, r3, r4 and r5 are different integers randomly generated within the range [1, NP], which are also different from index i. Furthermore, Eqs. (1)–(5) are known as DE/rand/1/bin, DE/best/1/bin, DE/rand-to-best/2/bin, DE/best/2/bin, and DE/rand/2/bin, respectively.

Following the mutation operation, a trial vector 
                           
                              
                                 U
                                 
                                    i
                                    ,
                                    G
                                 
                              
                              =
                              
                                 (
                                 
                                    u
                                    
                                       i
                                       ,
                                       G
                                    
                                    1
                                 
                                 ,
                                 
                                    u
                                    
                                       i
                                       ,
                                       g
                                    
                                    2
                                 
                                 ,
                                 …
                                 ,
                                 
                                    u
                                    
                                       i
                                       ,
                                       G
                                    
                                    D
                                 
                                 )
                              
                           
                         is generated from a mutant vector Vi,G
                         and its corresponding target vector Xi,G
                         by using a crossover operation. There are two commonly used crossover strategies. One is binomial crossover, and the other is exponential crossover. In this paper, the binomial crossover is selected for the proposed DE algorithm. The binomial crossover is defined as follows:

                           
                              (6)
                              
                                 
                                    
                                       u
                                       
                                          i
                                          ,
                                          G
                                       
                                       j
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      v
                                                      
                                                         i
                                                         ,
                                                         G
                                                      
                                                      j
                                                   
                                                   
                                                   i
                                                   f
                                                   
                                                   r
                                                   a
                                                   n
                                                   d
                                                   ≤
                                                   C
                                                   R
                                                   
                                                   o
                                                   r
                                                   
                                                   j
                                                   =
                                                   
                                                      n
                                                      j
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      x
                                                      
                                                         i
                                                         ,
                                                         G
                                                      
                                                      j
                                                   
                                                   
                                                   o
                                                   t
                                                   h
                                                   e
                                                   r
                                                   w
                                                   i
                                                   s
                                                   e
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where CR is the crossover rate which is a fixed constant within the range [0, 1). rand is a uniform random number in the range [0, 1], and nj
                         is randomly chosen from the set {1,2,…,D}, which is used to ensure that the trial individual Ui,G
                         gets at least one dimension from Vi.G
                        . If 
                           
                              u
                              
                                 i
                                 ,
                                 G
                              
                              j
                           
                         exceeds 
                           
                              [
                              
                                 x
                                 
                                    min
                                 
                                 j
                              
                              ,
                              
                                 x
                                 
                                    max
                                 
                                 j
                              
                              ]
                           
                        , it will be set to 
                           
                              x
                              
                                 min
                              
                              j
                           
                         or 
                           
                              x
                              
                                 max
                              
                              j
                           
                        .

In the
                         case of the selection operation, there is a competition between each target individual Xi,G
                         and its corresponding trial vector Ui,G
                        . The better of Xi,G
                         and Ui,G
                         is selected and inserted into the population of the next generation according to their fitness values f(). For minimization problems, this can be expressed as follows:

                           
                              (7)
                              
                                 
                                    
                                       X
                                       
                                          i
                                          ,
                                          G
                                          +
                                          1
                                       
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      U
                                                      
                                                         i
                                                         ,
                                                         G
                                                      
                                                   
                                                   
                                                   i
                                                   f
                                                   
                                                   f
                                                   
                                                      (
                                                      
                                                         U
                                                         
                                                            i
                                                            ,
                                                            G
                                                         
                                                      
                                                      )
                                                   
                                                   ≤
                                                   f
                                                   
                                                      (
                                                      
                                                         X
                                                         
                                                            i
                                                            ,
                                                            G
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      X
                                                      
                                                         i
                                                         ,
                                                         G
                                                      
                                                   
                                                   
                                                   o
                                                   t
                                                   h
                                                   e
                                                   r
                                                   w
                                                   i
                                                   s
                                                   e
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        Xi,G
                        
                        +1 is used as a parent vector in the next generation.

Because the performance of the DE algorithm is mainly affected by the trial vector generation strategy and its associated control parameters CR and F, a reasonable combination of trial vector generation strategy and associated parameter values should be selected when applying the DE algorithm to solve a specific problem. Generally, this reasonable combination is determined by a time-consuming trial-and-error procedure. Moreover, this combination can be different for different problems and even for the same problem during different stages of the search process. To address this problem, this paper presents a novel DE algorithm, called SLADE. First, the symmetric Latin hypercube design is introduced to initialize the population to increase the diversity of the population. Second, the trial vector generation strategy is adaptively selected from the strategy candidate pool according to previous successful experience. Finally, the control parameters CR and F are adaptively adjusted by using Cauchy distribution and normal distribution.

In the DE algorithm, the population is initialized randomly by a uniform distribution. The performance of the DE algorithm is seriously influenced by the diversity of initial population. Thus, in this paper, random symmetric Latin hypercube design (SLHD) is introduced to execute the population initialization (Regis & Shoemaker, 2004). All of the sample points of the symmetric Latin hypercube design are more uniformly distributed than those of the Latin hypercube design (LHD). Ye et al. illuminated how SLHD has more advantages over LHD regarding entropy and minimum intersite distance (Ye, Li, & Sudjianto, 2000). The pseudo code of SLHD is presented in Table 1.
                     

To verify the performance of SLHD sampling, a comparison with uniform sampling is made. Two groups of sample points are generated between predefined ranges [0, 1]
                           D
                         by using SLHD sampling and uniform sampling, respectively. To estimate the uniformity of the sample points, the distance between two adjacent points is calculated. The computation of the distance requires sorting the sample points according to the value of each dimension in ascending order. Thereafter, the distance is calculated as follows:

                           
                              (8)
                              
                                 
                                    D
                                    i
                                    s
                                    
                                       t
                                       i
                                    
                                    =
                                    
                                       ∑
                                       
                                          m
                                          =
                                          1
                                       
                                       D
                                    
                                    
                                       |
                                       
                                          U
                                          
                                             P
                                             
                                                i
                                                ,
                                                m
                                             
                                          
                                          −
                                          
                                             T
                                             
                                                i
                                                ,
                                                m
                                             
                                          
                                       
                                       |
                                    
                                 
                              
                           
                        where i = 1,…, NP-1. Ti,m
                         is the mth dimension of the ith sample point. UPi,m
                         is the mth dimension of one sample point, which is the upper adjacent point of ith sample point on the mth dimension. If there is no upper adjacent point of ith sample point on the mth dimension, set UPi,m
                         = Ti,m. D is the dimension of the sampling space.

Comparisons between SLHD sampling and uniform sampling with D = 10, 30, 50 and 100 are made. The number of sample points with D = 10, 30, 50 and 100 are 1000, 3000, 5000, and 10000, respectively. The average values of the means and standard deviations of the distance between two adjacent points over 30 runs are shown in Table 2. Although the means of the distance between two adjacent points generated by SLHD sampling are the same as those by uniform sampling, the standard deviations of the distance between two adjacent points generated by SLHD sampling are much smaller than those by uniform sampling. This means that sample points generated by SLHD sampling are much more uniform than those by uniform sampling. To more vividly illustrate the uniformity of the sample points, Fig. 1
                         is ploted by using experimental data with D = 10, 30, 50 and 100. The horizontal axis is sample points, and the vertical axis is the distance between two adjacent points. Obviously, the change in the distance between sample points generated by SLHD sampling is very small, but the distance between sample points generated by uniform sampling changes significantly. This also indicates that the uniformity of the sample points that generated by SLHD sampling is much better than that by uniform sampling. Hence, the diversity of the initial population has been greatly improved by introducing SLHD into SLADE.

The performances of different trial vector generation strategies are not the same when solving different optimization problems (Qin et al., 2009) and even when solving the same optimization problem during different stages of the search process. Some strategies have a better exploration capability, while others have a stronger exploitation capability. Instead of a time-consuming trial-and-error search for the most suitable strategy, a strategy candidate pool composed of several effective trial vector generation strategies is constructed. These effective trial vector generation strategies are introduced in Section 2.1, i.e., Eqs (1)–(5). They will be selected automatically during different stages of evolution. Adaptation of the trial vector generation strategies can be described as follows.

During initialization, for the initial population P
                        0, a trial vector generation strategy list named SL =(s1, s2
                        
                        ,…, sNP
                        ) is randomly generated by using a uniform distribution. s1, s2
                        
                        ,…, sNP
                         belong to the strategy candidate pool, where NP is the number of target individuals. In the mutation operation, each target vector Xi,G
                         and its associated trial vector generation strategy si
                         are used to produce a new trial vector Ui,G
                        . If Ui,G
                         is better than its target vector Xi,G
                        , then the associated si
                         will be stored in a winning list wSL. After each generation, a reassignment procedure for the list SL is invoked.

During the reassignment procedure, a probability γ is set to determine whether the new si
                         for each target vector Xi,G
                         of the next generation was randomly selected from the list wSL or randomly generated by using a uniform distribution. Note that the list wSL is reset to empty after the above operations are completed. If the list wSL is empty, then the reassignment procedure will not be invoked.

Obviously, the more successful a trial vector generation strategy in the current generation is, the greater is its probability of being selected in the next generation. As a result, SLADE can be self-adaptive to select an appropriate trial vector generation strategy to match the specific problem and the specific phase of the evolutionary process.

At each generation, the crossover rate CRi
                         of each target vector Xi,G
                         is separately generated using a Cauchy distribution with location parameter θCR
                         and a scale parameter of 0.1. It can be defined as follows:

                           
                              (9)
                              
                                 
                                    C
                                    
                                       R
                                       i
                                    
                                    =
                                    C
                                    a
                                    u
                                    c
                                    h
                                    y
                                    r
                                    a
                                    n
                                    d
                                    
                                       (
                                       
                                          θ
                                          
                                             C
                                             R
                                          
                                       
                                       ,
                                       0.1
                                       )
                                    
                                 
                              
                           
                        
                     

If CRi
                         exceeds (0, 1), then it will be regenerated. Each target vector Xi,G
                         and its associated CRi
                         are used to produce a new trial vector Ui,G
                        . If Ui,G
                         is better than its target vector Xi,G
                        , then the associated CRi
                         will enter a winning set wCR. The location parameter θCR
                         of the Cauchy distribution is initialized to be 0.5. After each generation, the location parameter θCR
                         is updated as follows:

                           
                              (10)
                              
                                 
                                    
                                       θ
                                       
                                          C
                                          R
                                       
                                    
                                    =
                                    a
                                    ·
                                    
                                       θ
                                       
                                          C
                                          R
                                       
                                    
                                    +
                                    
                                       (
                                       1
                                       −
                                       a
                                       )
                                    
                                    ·
                                    
                                       
                                          
                                             ∑
                                             
                                                C
                                                R
                                                ∈
                                                w
                                                C
                                                R
                                             
                                          
                                          
                                             C
                                             R
                                          
                                       
                                       
                                          N
                                          P
                                       
                                    
                                 
                              
                           
                        where a is a positive constant within the range (0, 1) and NP is the number of the population size. Note that if the set wCR is empty, then the last θCR
                         is used again.

Likewise, at each generation, the mutation scale factor Fi
                         of each target vector Xi,G
                         is separately generated by using a normal distribution with mean μF
                         and a standard deviation of 0.1. It can be defined as follows:

                           
                              (11)
                              
                                 
                                    
                                       F
                                       i
                                    
                                    =
                                    N
                                    o
                                    r
                                    m
                                    a
                                    l
                                    r
                                    a
                                    n
                                    d
                                    
                                       (
                                       
                                          μ
                                          F
                                       
                                       ,
                                       0.1
                                       )
                                    
                                 
                              
                           
                        
                     

If Fi
                         exceeds (0, 1), then it will be set to 1. Each target vector Xi,G
                         and its associated Fi
                         are used to produce a new trial vector Ui,G
                        . If Ui,G
                         is better than its target vector Xi,G
                        , then the associated Fi
                         will enter a winning set wF. The mean μF
                         of the normal distribution is initialized to be 0.5. After each generation, the mean μF
                         is updated as follows:

                           
                              (12)
                              
                                 
                                    
                                       μ
                                       F
                                    
                                    =
                                    a
                                    ·
                                    
                                       μ
                                       F
                                    
                                    +
                                    
                                       (
                                       1
                                       −
                                       a
                                       )
                                    
                                    ·
                                    
                                       
                                          
                                             ∑
                                             
                                                F
                                                ∈
                                                w
                                                F
                                             
                                          
                                          F
                                       
                                       
                                          N
                                          P
                                       
                                    
                                 
                              
                           
                        where a is a positive constant within the range (0, 1), and NP is the number of the population size. Note that if the set wF is empty, then the last θF
                         is used again.

Obviously, control parameter values that generate better individuals should be propagated to the following generations. The successful CRi
                         and Fi
                         of the current generation are archived and used to update the adaptive parameters θCR
                         and μF
                        . The new control parameters CRi
                         and Fi
                         generated by Eqs. (9) and (11) are more suitable for current phase of evolution, and can produce more successful individuals. Furthermore, both Cauchy distribution and normal distribution have randomness, and they are beneficial for diversifying the population. Note that sets wCR and wF are reset to empty after updating θCR
                         and
                         
                        μF
                        .

By incorporating the above-mentioned adaptation schemes into the traditional DE algorithm, a self-adaptive DE algorithm called SLADE is developed. During different phases of the search process, SLADE can adaptively
                        
                         determine the best trial vector generation strategy and the associated parameter values to get the best effect when solving the optimization problem. The pseudo code of SLADE is presented in Table 3.
                     

To verify the performance of SLADE, 25 benchmark functions in IEEE CEC2005 (Suganthan et al., 2005) are selected. Twenty-five benchmark functions with diverse characteristics are denoted by F1−F25. The characteristics and global optimums of F1-F25 are presented in Table 4. “Fun” denotes function. More details about the 25 benchmark functions can be found in (Suganthan et al., 2005).

@&#EXPERIMENTAL RESULTS@&#

To validate the capability of SLADE to solve the unconstrained optimization problems, SLADE is compared with five other DE algorithms including DE (Storn & Price, 1995), SADE (Brest et al., 2006), JADE (Zhang & Sanderson, 2009), SspDE (Pan et al., 2011) and MDE (Zou et al., 2013). The characteristics of the above six algorithms are listed in Table 5. “Alg” denotes algorithm.

Meanwhile, to investigate the effect of SLHD sampling, a version of SLADE without symmetric Latin hypercube design, namely, RADE, is proposed. RADE employs uniform distribution to initialize the population.

The control parameters of the seven DE algorithms are set as follows. The parameters of the DE are set to F = 0.5 and CR = 0.4, as previously proposed (Brest et al., 2006; Mezura-Montes et al., 2006; Storn & Price, 1997; Vesterstrom & Thomsen, 2004). The parameter settings of JADE, MDE, SADE and SspDE are set according to the original paper. For SADE, τ1
                         and τ2
                         are set to 0.5. For SLADE and RADE, a in Eqs. (10) and (12) is set to 0.9. All seven DE algorithms are conducted on the benchmark functions with dimensions D = 10, 30, 50 and 100. The population sizes NP of all of the DE algorithms are set to 40, 100, 100 and 100 in the case of dimensions D = 10, 30, 50 and 100, respectively. The maximal number of function evaluations for all of the DE algorithms is set to 40000 for 10D functions and 100000 for 30D, 50D and 100D functions. In the experiments, each benchmark function is executed for 30 independent runs.

To evaluate the performance of SLADE, a comparison with the other six DE algorithms is made based on the means and standard deviations of the best solutions over 30 runs on each benchmark function. The means and standard deviations of all seven algorithms over 30 runs on each benchmark function with dimensions D =10, 30 and 50 are reported in Table A.1–A.3 in the Appendix. The smallest means and standard deviations are marked in boldface. Table A.1–A.3 are summarized in Table 6. In Table 6, the value outside the parentheses is the number of the smallest mean, while the value within the parentheses is the number of the smallest standard deviation. The maximal numbers of smallest means and standard deviations of different dimensions are marked in boldface.

With regard to the unimodal functions F1–F5, the basic multimodal functions F6–F12 and the expanded multimodal functions F13–F14, the maximal numbers of the smallest means in all dimensions are obtained by SLADE. Obviously, the performance of SLADE is superior to the other six algorithms on these functions. The reason is that SLADE introduces adaptive mechanisms and symmetric Latin hypercube design technology. Compared with the other six algorithms on unimodal functions, SLADE obtains both the maximal numbers of the smallest means and standard deviations in all dimensions because it introduces a special mutation strategy, DE/best/1, which is very effective for unimodal functions and greatly improves the convergence speed. For hybrid composition functions F15–F25, the performance of SLADE is mediocre, while SspDE works well. For all 25 benchmark functions, SLADE still obtains maximal numbers of the smallest means in all dimensions. In other words, SLADE is much more effective and efficient than the other six algorithms for unconstrained optimization problems with dimensions D =10, 30 and 50.

To evaluate the statistical significance among all of the DE algorithms, a Wilcoxon signed-rank test (Derrac, García, Molina, & Herrera, 2011; Weber, Tirronen, & Neri, 2010; Wilcoxon, 1945) at the 5% significance level is performed to determine whether the best algorithm differs from the other algorithms. In this paper, the algorithm that has the smallest mean is defined as the best algorithm. If more than one algorithm has the same mean, the one with the smallest standard deviation is considered the best. The P-values between the best algorithm and each of the other algorithms obtained by the Wilcoxon signed-rank test are reported in Table A.4–A.6 of the Appendix. The P-values are marked in boldface if they are larger than 0.05. If the P-values are smaller than 0.05, the null hypothesis is rejected. In other words, the best algorithm is significant different from other algorithms. Otherwise, the null hypothesis is accepted. This means that there is no significant difference between the best algorithm and the other algorithms. Here, NA denotes the best algorithm.


                           Table A.4–A.6 are summarized in Table 7. In Table 7, NB denotes the number of the best algorithms, while NC denotes the number of the comparable algorithms compared with the best algorithm. The maximal number of the best algorithms is marked in boldface. If there is more than one maximal number, the one with the maximal number of the comparable algorithms will be marked in boldface. According to Table 7, SLADE obtains the maximal number of the best algorithms in all dimensions, indicating that SLADE is the best algorithm among all seven algorithms in a statistically significant way. Furthermore, the performance of DE is the worst because its control parameter values and trial vector generation strategy are fixed. JADE is the second worst algorithm, although it employs a self-adaptive mechanism of control parameters. The main reason is that it employs only one mutation strategy, DE/current-to-pbest/1. In this paper, p is set to 0.05 as in the original paper. If population size NP is not large enough, DE/current-to-pbest/1 is very close to DE/best/1 and it is easy to cause premature convergence. Obviously, SspDE is the second best algorithm. Especially for hybrid composition functions, SspDE performs best because of the usage of DE/current-to-rand/1, which is a rotation-invariant strategy. The performances of MDE and SADE are just acceptable, because their control parameter values are both randomly generated for each individual without adaptively adjusting
                            according to the previous successful experience.

To investigate the performance of SLADE on high dimensions, functions F1, F2, F4–F6, F9, F12 and F13 are chosen from the 25 benchmark functions. The remaining functions are not adopted because the highest dimension sizes of these functions are 50 (Zou et al., 2013). The means and standard deviations of the above eight functions over 30 runs are reported in Table 8. It is clear that SLADE can obtain the best means of F1, F2, F4, F6 and F12 among all of the DE algorithms, and it can obtain the best standard deviations of F1, F2, F6 and F12. Furthermore, SLADE can obtain the second best means for F5 and F9. For F9, the best means and standard deviations are provided by SspDE. MDE and JADE yield the best means for F13 and F5, respectively. These experimental results show that SLADE performs better than the other algorithms when solving unconstrained optimization functions with high dimensions.

The P-values of functions F1, F2, F4–F6, F9, F12 and F13 with D = 100 between the best algorithm and each of the remaining algorithms are reported in Table 9. SLADE can obtain statistically superior performance compared to the other six DE algorithms for F1, F2, F4, F6 and F12. MDE, JADE and SspDE can produce only one best result. But both DE and SADE fail to find the best result for any of the eight functions. In conclusion, the performance of SLADE is much better than the other six algorithms when solving unconstrained optimization problems with D = 100, while DE and JADE perform worse than the other five DE algorithms for all eight functions with D = 100.

For convenience of illustration, the convergence curves for eight functions with D = 100 over 30 independent runs are plotted in Figs. 2 and 3
                           . Figs. 2 and 3 have semi-logarithmic coordinates. The horizontal axis is the number of function evaluations, and the vertical axis is the logarithm of f(x)-f(x*). f(x) is the mean of function values over the 30 independent runs, while f(x*) is the global optimum of the functions. It is clear that SLADE achieves the best performance for F1, F2, F4, F6 and F12. For F5 and F9, SLADE achieves the second best performance. Conversely, DE performs worst among all of the DE algorithms for all eight functions. In short, SLADE has a fast convergence rate and strong exploitation ability for unconstrained optimization functions with high dimensions that are either unimodal or multimodal, clean or noisy, separable or non-separable.

To illustrate the distribution of best solutions obtained by the seven DE algorithms for functions F1, F2, F4–F6, F9, F12 and F13 with D = 100 over 30 independent runs, box plots were generated, as shown in Fig. 4
                           . A close observation of Fig. 4 reveals that the performance of SLADE is the best and second best for functions F1, F2, F4, F6, F12 and F5, F9. Furthermore, SLADE did not yield any outlier in all eight functions, and the distributions of the best solutions obtained by SLADE are centralized. All of these indicate that SLADE is very stable when solving unconstrained optimization functions with high dimensions.

SLADE employs SLHD to initialize the population, while RADE is a version of SLADE without SLHD. As listed in Table A.1–A.3 of the Appendix, SLADE can yield better means than RADE for all functions with D =10, 30 and 50 except for functions F10, F11 and F24. According to Table 8, SLADE can yield better means than RADE for all eight functions with D =100. Furthermore, the performance of SLADE is significantly better than RADE according to Table A.4–A.6 of the Appendix and Table 9. All of those indicate
                         that the performance of SLADE is improved by introducing SLHD to increase the diversity of the initial population.

In SLADE, each target vector is initially assigned a trial vector generation strategy selected randomly from the strategy candidate pool, and the associated control parameters CR and F are randomly generated by using the Cauchy distribution and normal distribution. As the evolutionary progress, both the trial vector generation strategy and control parameter values can be gradually self-adapted depending on the previous successful experiences in generating promising individuals. To illustrate the self-adaptive mechanisms of SLADE, functions F1, F2, F4–F6, F9, F12 and F13 with D = 100 are still selected to investigate the effect of the self-adaptive mechanisms when solving the unconstrained optimization problems.

In SLADE, the percentage usage of each trial vector generation strategy changes as the evolutionary process continues. The variations of average percentage over 30 independent runs are plotted in Figs. 5 and 6. The horizontal axis is the number of function evaluations, and the vertical axis is the average percentage of trial vector generation strategies over the 30 independent runs. It is obvious that DE/best/1 performs better for most functions, because it benefits from its fast convergence by incorporating the best solution information in the evolutionary search. As proposed by Pahner et al. (Pahner & Hameyer, 2000), DE/best/1 is suitable for most optimization problems. However, the best solution information may cause premature convergence due to the reducing of population diversity, especially when solving multimodal problems (Mendes, Rocha, Ferreira, & Rocha, 2006). SLADE performs well regarding avoiding premature convergence because a well-designed trial vector generation strategy adaptation scheme is adopted to enhance the robustness of SLADE. From Figs. 5 and 6, it can be observed that SLADE can self-adaptively select the suitable trial vector generation strategy to match different stages of the evolution.

In the traditional DE algorithm, the control parameters F and CR will be tuned by a time-consuming trial-and-error procedure for different optimization problems. In SLADE, F and CR are adaptively adjusted by the adaptive parameters θCR
                            and μF. θCR
                            and μF
                            both evolve according to previous experience as the search process continues. The mean curves of θCR
                            and μF
                            over 30 runs are plotted in Fig. 7. The horizontal axis is the number of function evaluations, and the vertical axis is the average value of θCR
                            and μF
                            over the 30 independent runs. For F1, θCR
                            and μF
                            change little because the shape of the landscape does not change during the evolutionary process. For F2, θCR
                            and μF
                            gradually stabilize after the obvious change at the beginning of the evolution. This is similar to the situation of F4, because F4 is F2 with noise in the fitness. For F5, the value of μF
                            is stable at approximately 0.53 after a small change at the beginning of the evolution, while the value of θCR
                            increases from 0.5 to 0.87 in the first 40,000 function evaluations and remains there until the end. For F6 and F12, the value of μF
                            increases from 0.5 to 0.55 over the whole process of evolution, while the value of θCR
                            increases from 0.5 to 0.79 over the whole process of evolution. For F9 and F13, the values of μF
                            gradually increase to a steady-state value, while the values of θCR
                            decrease rapidly to a steady-state value.


                           Fig. 7 indicates that SLADE can adaptively adjust F and CR to appropriate values to match different optimization problems and different stages of the evolutionary process and that there is no fixed F or CR that is suitable for solving all optimization problems.

@&#CONCLUSIONS@&#

This paper presents an adaptive differential evolution algorithm named SLADE for unconstrained optimization problems. SLADE incorporates a population initialization technology based on symmetric Latin hypercube design (SLHD), an adaptive selection mechanism of the trial vector generation strategies and an adaptive adjustment mechanism of control parameters based on Cauchy distribution and normal distribution. In SLADE, the trial vector generation strategy and control parameters are assigned to each target individual, and can be adaptively adjusted to match different stages of the evolution according to previous experience. The performance of SLADE is strictly evaluated using the set of benchmark functions from CEC2005. Experimental results demonstrate that SLADE shows better or at least competitive optimization performance compared to other classic and adaptive DE algorithms, and SLHD is effective for improving the performance of SLADE. Moreover, it is interesting to extend the current work to solve constraint and multi-objective optimization problems.

@&#ACKNOWLEDGMENTS@&#

Authors acknowledge the financial support offered by National Natural Science Foundation of China (Grant No. 61074099), Project supported by National Natural Science Foundation of China and Baosteel Group Co. Ltd. (Grant No. U1260203) and Cultivation Program Project for Leading Talent of innovation team in Colleges and universities of Hebei Province (No. LJRC013).

See Tables A.1–A.6
                     
                     
                     
                     
                     
                     .

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Collaborative part-based tracking using salient local predictors

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel part-based tracking algorithm is proposed.


                        
                        
                           
                           Reliable local features are identified through a saliency evaluation mechanism.


                        
                        
                           
                           Salient predictors collaborate to achieve a global prediction of the target state.


                        
                        
                           
                           We handle real-life difficulties such as occlusion and presence of distractors.


                        
                        
                           
                           The drastic decrease of the number of features does not destabilize the tracker.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Part-based tracking

Feature saliency

Keypoint

SIFT

Keypoint layout

@&#ABSTRACT@&#


               
               
                  This work proposes a novel part-based method for visual object tracking. In our model, keypoints are considered as elementary predictors localizing the target in a collaborative search strategy. While numerous methods have been proposed in the model-free tracking literature, finding the most relevant features to track remains a challenging problem. To distinguish reliable features from outliers and bad predictors, we evaluate feature saliency comprising three factors: the persistence, the spatial consistency, and the predictive power of a local feature. Saliency information is learned during tracking to be exploited in several algorithm components: local prediction, global localization, model update, and scale change estimation. By encoding the object structure via the spatial layout of the most salient features, the proposed method is able to accomplish successful tracking in difficult real life situations such as long-term occlusion, presence of distractors, and background clutter. The proposed method shows its robustness on challenging public video sequences, outperforming significantly recent state-of-the-art trackers. Our Salient Collaborating Features Tracker (SCFT) also demonstrated a high accuracy even if a few local features are available.
               
            

@&#INTRODUCTION@&#

Visual object tracking is a fundamental problem in computer vision with a wide range of applications including automated video monitoring systems [1,2], traffic monitoring [3,4], human action recognition [5], robot perception [6], etc. While significant progress has been made in designing sophisticated appearance models and effective target search methods, model-free tracking remains a difficult problem receiving a great interest. With model-free trackers, the only information available on the target appearance is the bounding box region in the first video frame. Tracking is thus a challenging task due to (1) the insufficient amount of information on object appearance, (2) the inaccuracy in distinguishing the target from the background, and (3) the target appearance change during tracking.

In this paper, we present a novel part-based tracker handling the aforementioned difficulties, including the lack of information on object appearance and features. This work demonstrates that an efficient way to maximize the knowledge on object appearance is to evaluate the tracked features. To achieve robust tracking in unconstrained environments, our Salient Collaborating Features Tracker (SCFT) discovers the most salient local features in an online manner. Every tracked local feature is considered as an elementary predictor having an individual reliability in encoding an object structural constraint, and collaborating with other features to predict the target state. To assess the reliability of a given feature, we define feature saliency as comprising three factors: persistence, spatial consistency, and predictive power. Thereby, the global target state prediction arises from the aggregation of all the local predictions considering individual feature saliency properties. Furthermore, the appearance change problem (which is a major issue causing drift [7]) is handled through a dynamic target model that continuously incorporates new structural properties while removing non-persistent features.

Generally, a tracking algorithm includes two main aspects: the target representation including the object characteristics, and the search strategy for object localization. The contributions of our work relate to both aspects. For target representation, our part-based model includes keypoint patches encoding object structural constraints with different levels of reliability. Part-based representations are proven to be robust to local appearance changes and partial occlusions [8–10]. Moreover, keypoint regions are more salient and stable than other types of patches (e.g. regular grid, random patches), increasing the distinctiveness of the appearance model [11,12]. Regarding the search strategy, the target state estimation is carried out via local features collaboration. Every detected local feature casts a local prediction expressing a constraint on the target structure according to the spatial layout, saliency information, detection scale, and dominant orientation of the feature. In this manner, feature collaboration preserves the object structure while handling pose and scale change without requiring to analyze the relationship between keypoints like in [9], neither calculating homographies such as in most keypoint matching works [13–15].

More specifically, the main contributions of this paper are:
                        
                           1.
                           A novel method for evaluating feature saliency to identify the most reliable features based on their persistence, spatial consistency, and predictive power.

The explicit exploitation of feature saliency information in several algorithmic steps: (1) local predictions, (2) feature collaboration for global localization, (3) scale change estimation, and (4) for local feature removal from the target model.

A dynamic appearance model where persistent local features are stored in a pool, to encode both recent and old structural properties of the target.

Extensive experimentation to evaluate the tracker performance against five recent state-of-the-art methods. The experimental work conducted on challenging videos shows the validity of the proposed tracker, outperforming the compared methods significantly.

The rest of this paper is organized as follows. In the next section, we review related part-based tracking works. Algorithm steps are presented in details in Section 3. Experimental results are provided and analyzed in Section 4, and Section 5 concludes the paper.

@&#RELATED WORKS@&#

Among various visual tracking algorithms, part-based trackers have attracted a great interest during the last decade. This is mainly due to the robustness of part-based models in handling partial changes, and to the efficiency of prediction methods in finding the whole target region given a subset of object parts. The fragment-based tracker of Adam et al. [16] is one of the pioneering methods in this trend. In their tracker, target parts correspond to arbitrary patches voting for object positions and scales in a competitive manner. The object patches are extracted according to a regular grid, and thus are inappropriate for articulated objects and significant in-plane rotations. Further, Erdem et al. demonstrated that the winning patch might not always provide reliable predictions [17]. This issue is addressed in [17] by differentiating the object patches based on their reliability. Therefore, every patch contributes to the target state prediction according to its reliability, allowing to achieve a better accuracy. Many other methods have been proposed for locating the object through parts tracking. The authors in [18] track object parts separately and predict the target state as a combination of multiple measurements. This method identifies inconsistent measurements in order to eliminate the false ones in the integration process. The method in [19] represents the shape of an articulated object with a small number of rectangular regions, while the appearance is represented by the corresponding intensity histograms. Tracking is then performed by matching local intensity histograms and by adjusting the locations of the blocks. Note that these last two trackers present the disadvantage of requiring manual initialization of object parts.

In [10], the appearance model includes a combination between holistic and local representations to increase the model distinctiveness. In this model, the spatial information of the object patches is encoded by a histogram representing the object structure. Similarly, Jia et al. sample a set of overlapped patches on the tracked object [8]. Their tracker includes an occlusion handling module allowing to locate the object using only visible patches. Kwon et al. [20] also used a set of local patches, updated during tracking, for target representation. The common shortcoming of the last three trackers is the model adaptation mechanism in which the dictionary is updated simply by adding new elements, without adapting existing items. Another approach for creating part-based representations is the superpixel over-segmentation [21,22]. In [21], Wang et al. use a discriminative method evaluating superpixels individually, in order to distinguish the target from the background and detect shape deformation and occlusion. Their tracker is limited to small displacements between consecutive frames, since over-segmentation is performed only for a region surrounding the target location in the last frame. Moreover, this method requires a training phase to learn superpixel features from the object and the background.

One of the major concerns in part-based tracking is to select the most significant and informative components for the appearance model. An interesting approach for defining informative components consists in using keypoint regions. Local keypoint regions (e.g. SIFT [23] and BRISK [24]) are more efficient than other types of patches in encoding object structure, as they correspond to salient and stable regions invariably detectable under various perturbation factors [25,12]. Based on this, Yang et al. model the target with a combination of random patches and keypoints [26]. Keypoints layout is used to encode the structure while random patches model other appearance properties via their LBP features and RGB histograms. The target is thus tracked by exploiting multiple object characteristics, but the structural model captures only recent properties, as the keypoint model contains only those detected on the last frame. In a later work, Guo et al. [14] used a set of keypoint manifolds organized as a graph to represent the target structure. Every manifold contains a set of synthetic keypoint descriptors simulating possible variations of the original feature under viewpoint and scale change. The target is found by detecting keypoints on the current frame and matching them with those of the manifold model. This tracker achieved stable tracking of dynamic objects, at the cost of calculating homographies with RANSAC, which may be inappropriate for non-planar objects as shown in [9].

Generalized Hough Transform (GHT)-based approaches have been recently presented as an alternative to homography calculation methods. GHT was initially used in context tracking [27], where the target position is predicted by analyzing the whole scene (context) and identifying features (not belonging to the target) that move in a way that is statistically related to the target’s motion. In later works, this technique has been applied to object features in order to reflect structural constraints of the target and cope with partial occlusion problems. Nebehay et al. [9] propose to combine votes of keypoints to predict the target center. Although every keypoint votes in an individual manner, the geometrical relationship is analyzed between each pair of keypoints in order to rotate and scale votes accordingly. Furthermore, the keypoint model is not adapted to object appearance changes, arising only from the first observation of the target. In [28], the authors used an adaptive feature reservoir updated online to learn keypoint properties during tracking. The tracker achieved robust tracking in situations of occlusion and against illumination and appearance changes. However, this method does not handle scale changes and suffers from sensitivity to large in-plane rotations. In this paper we propose a novel tracking algorithm that exploits the geometric constraints of salient local features in a way to handle perturbation factors related to the target movement (e.g. scale change, in-plane and out-of-plane rotations), as well as those originating from its environment (i.e. occlusion, background clutter, distractors).

@&#PROPOSED METHOD@&#

In our part-based model, object parts correspond to keypoint patches detected during tracking and stored in a feature pool. The pool is initialized with the features detected on the bounding box region defined in the first video frame, and updated dynamically by including and/or removing features to reflect appearance changes. Instead of detecting local features in a region with a fixed size around the target location (like in [21,14]), we eliminate the restriction of small displacements by using particle filtering to reduce the search space as proposed in [28]. This allows us to avoid computing local features on the entire image by limiting their extraction to most likely regions based on the target color distribution.

When performing target search on a given frame, features from the pool are matched with those detected on the reduced search space. Following the matching process, the geometrical constraints (of the matched features) are adapted to local scale and pose changes as explained in Section 3.3.1. Then all the matched features collaborate in a voting-based method (Section 3.3.2), to achieve global localization (Section 3.3.3) and estimate the global scale change (Section 3.3.4). Thus, the global prediction result corresponds to the aggregation of individual votes (elementary predictions). This method preserves the object structure and handles pose and scale changes, without requiring homography calculations such as in [14], neither analyzing the geometrical relationship between keypoints like in [9]. The Fig. 1
                         presents a visual summary of the main algorithm steps.

In order to keep the most relevant elements in the feature pool and exploit appropriately the most reliable predictors, each tracking iteration is followed by a saliency evaluation step. Saliency evaluation is performed to identify reliable features and determine the weights of their predictions accordingly, while eliminating irrelevant features from the appearance model. Our idea is inspired by the democratic integration framework of Triesch and von der Malsburg, where several cues contribute to a joint result with different levels of reliability [29]. In their approach, the elements that are consistent with the global result are considered as reliable and are assigned a higher weight in the future. This strategy has been adopted in other object tracking works to perform an adaptive integration of cues according to their reliability [17,30,31]. In our tracking method, the reliability is defined by the feature saliency including three factors: feature persistence, spatial consistency, and predictive power.
                           
                              •
                              The persistence value ω of a given feature is used to evaluate the degree of co-occurrence between the target and the keypoint, and to determine if the feature should be removed from the pool.

The spatial consistency matrix Σ reflects the motion correlation between the feature and the target center in the local prediction function.

The predictive power ψ indicates the accuracy of the past local predictions by comparison to the past global predictions. This value is used to weight the contribution of a local feature in the global localization function.

Note that both the spatial consistency and the predictive power are designed to assess the feature quality. On the other hand, the persistence value is related to the occurrence level, disregarding the usefulness of the feature. Fig. 2
                         illustrates situations where non-salient features can be identified through saliency evaluation. Non-salient features may correspond to outliers included erroneously to the object model in the initialization step or when updating it. Such a feature may originate from the background as seen in Fig. 2a or belong to an occluding object (Fig. 2b) causing incorrect prediction. Once a keypoint is considered as non-salient, the corresponding local prediction (vote) will not be significant in the voting space, and/or its contribution will be reduced in the global localization procedure. Moreover the feature is likely to be removed from the pool as soon as it becomes non-persistent.

It should be noted that inconsistent features belonging to the tracked object may remain in the object model if they co-occur frequently with the target. An example is illustrated in Fig. 2c. However, their local predictions hardly affect the overall localization, since their quality indicators (Σ and ψ) will be reduced. While bad predictors are penalized and/or removed from the model, target global localization is carried out via a collaboration mechanism, exploiting the local predictions of the most salient features. The proposed tracking algorithm is presented in Fig. 3 and detailed in the next sections.

In our tracker, the target is represented by a set of keypoint patches stored in a feature pool 
                           P
                        . The proposed method could use any type of scale/rotation invariant keypoint detector/descriptor. We used SIFT [23] as a keypoint detector/descriptor for its proven robustness [25]. We denote by f a feature from the pool 
                           P
                        . All the detected features are then stored under the form
                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             f
                                             =
                                             [
                                             d
                                             ,
                                             θ
                                             ,
                                             σ
                                             ,
                                             V
                                             ,
                                             Sal
                                             ]
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where d is the SIFT keypoint descriptor comprising 128 elements to describe the gradient information around the keypoint position; θ is the detection angle corresponding to the main orientation of the keypoint; σ is the detection scale of the keypoint; 
                           
                              V
                              =
                              [
                              
                                 δ
                                 x
                              
                              ,
                              
                                 δ
                                 y
                              
                              ]
                           
                         is a voting vector describing the target center location with respect to the keypoint location (see Fig. 4); and 
                           
                              Sal
                              =
                              [
                              ω
                              ,
                              Σ
                              ,
                              ψ
                              ]
                           
                         is the saliency information including persistence, spatial consistency, and predictive power indicators.

Note that all the detection properties (i.e. d,θ,σ, and V) are defined permanently the first time the feature is detected, whereas saliency information (i.e. ω,Σ, and ψ) is updated every time features are evaluated.

In order to limit keypoint detection at time t to the most likely image area, we apply the search space reduction method that we previously proposed in [28]. Detected features from the reduced search space are then matched with those in the target model 
                           P
                         in a nearest neighbor fashion. For matching a pair of features, we require that the ratio of the Euclidian distance from the closest neighbor to the distance of the second closest is less than an upper limit λ. The resulting subset 
                           
                              
                                 F
                                 t
                              
                              ⊆
                              P
                           
                         contains the matched target features at time t. After the matching process, the voting vectors (of the matched features) are adapted to local scale and pose changes as explained in the following.

Each feature 
                              
                                 f
                                 ∈
                                 
                                    F
                                    t
                                 
                              
                            encodes a structural property expressed through its voting vector. Before applying the structural constraint of f, the corresponding voting vector V should be scaled and rotated according to the current detection scale σt
                            and dominant orientation θt
                            at time t as shown in Fig. 4. This adaptation process produces the current voting vector 
                              
                                 
                                    V
                                    t
                                 
                                 =
                                 
                                    [
                                    
                                       δ
                                       
                                          x
                                          ,
                                          t
                                       
                                    
                                    ,
                                    
                                       δ
                                       
                                          y
                                          ,
                                          t
                                       
                                    
                                    ]
                                 
                              
                           , with
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   δ
                                                   
                                                      x
                                                      ,
                                                      t
                                                   
                                                
                                                =
                                                
                                                   ∥
                                                   V
                                                   ∥
                                                
                                                
                                                   ρ
                                                   t
                                                
                                                cos
                                                
                                                   (
                                                   
                                                      Δ
                                                      
                                                         θ
                                                         ,
                                                         t
                                                      
                                                   
                                                   +
                                                   sign
                                                   
                                                      (
                                                      
                                                         δ
                                                         y
                                                      
                                                      )
                                                   
                                                   arccos
                                                   
                                                      
                                                         δ
                                                         x
                                                      
                                                      
                                                         ∥
                                                         V
                                                         ∥
                                                      
                                                   
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (3)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   δ
                                                   
                                                      y
                                                      ,
                                                      t
                                                   
                                                
                                                =
                                                
                                                   ∥
                                                   V
                                                   ∥
                                                
                                                
                                                   ρ
                                                   t
                                                
                                                sin
                                                
                                                   (
                                                   
                                                      Δ
                                                      
                                                         θ
                                                         ,
                                                         t
                                                      
                                                   
                                                   +
                                                   sign
                                                   
                                                      (
                                                      
                                                         δ
                                                         y
                                                      
                                                      )
                                                   
                                                   arccos
                                                   
                                                      
                                                         δ
                                                         x
                                                      
                                                      
                                                         ∥
                                                         V
                                                         ∥
                                                      
                                                   
                                                   )
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where Δ
                           
                              θ,t
                            and ρt
                            are respectively the orientation angle difference and the scale ratio between the first and the current detection of f:
                              
                                 (4)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Δ
                                                   
                                                      θ
                                                      ,
                                                      t
                                                   
                                                
                                                =
                                                
                                                   θ
                                                   t
                                                
                                                −
                                                θ
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           
                           
                              
                                 (5)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ρ
                                                   t
                                                
                                                =
                                                
                                                   σ
                                                   t
                                                
                                                /
                                                σ
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

After adapting the voting vectors to the last local changes, we base local predictions on GHT to build a local likelihood (or prediction) map 
                              
                                 M
                                 l
                              
                            for every feature in 
                              
                                 F
                                 t
                              
                           . For f, the local likelihood map is built in the reduced search space for all the potential object positions x using their relative positions x
                           
                              f
                            with respect to the keypoint location. The local likelihood map is defined using a 2D Gaussian probability density function as
                              
                                 (6)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   M
                                                   l
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                =
                                                
                                                   1
                                                   
                                                      
                                                         2
                                                         π
                                                         |
                                                         Σ
                                                         |
                                                      
                                                   
                                                
                                                
                                                   
                                                      0.12
                                                      e
                                                      m
                                                   
                                                   
                                                      0
                                                      e
                                                      x
                                                   
                                                
                                                
                                                   
                                                      0.12
                                                      e
                                                      m
                                                   
                                                   
                                                      0
                                                      e
                                                      x
                                                   
                                                
                                                exp
                                                
                                                   
                                                      0.12
                                                      e
                                                      m
                                                   
                                                   
                                                      0
                                                      e
                                                      x
                                                   
                                                
                                                
                                                   (
                                                   −
                                                   0.5
                                                   
                                                      
                                                         0.12
                                                         e
                                                         m
                                                      
                                                      
                                                         0
                                                         e
                                                         x
                                                      
                                                   
                                                   
                                                      
                                                         (
                                                         
                                                            
                                                               x
                                                            
                                                            f
                                                         
                                                         −
                                                         
                                                            V
                                                            t
                                                         
                                                         )
                                                      
                                                      ⊤
                                                   
                                                   
                                                      
                                                         0.12
                                                         e
                                                         m
                                                      
                                                      
                                                         0
                                                         e
                                                         x
                                                      
                                                   
                                                   
                                                      
                                                         Σ
                                                      
                                                      
                                                         −
                                                         1
                                                      
                                                   
                                                   
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         f
                                                      
                                                      −
                                                      
                                                         V
                                                         t
                                                      
                                                      )
                                                   
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

To achieve global prediction of the target position, features in 
                              
                                 F
                                 t
                              
                            collaborate according to their saliency properties (persistence and predictive power). The global localization map 
                              
                                 M
                                 g
                              
                            is thus created at time t to represent the target center likelihood considering all the detected features. Concretely, the global map is computed by aggregating local maps according to the equation
                              
                                 (7)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   M
                                                   
                                                      g
                                                      ,
                                                      t
                                                   
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                =
                                                
                                                   ∑
                                                   
                                                      
                                                         
                                                            f
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                      ∈
                                                      
                                                         F
                                                         t
                                                      
                                                   
                                                   i
                                                
                                                
                                                   ω
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                
                                                   ψ
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                
                                                   M
                                                   
                                                      l
                                                      ,
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           The final target location 
                              
                                 
                                    x
                                 
                                 
                                    t
                                 
                                 *
                              
                            is then found as
                              
                                 (8)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      t
                                                   
                                                   *
                                                
                                                =
                                                
                                                   
                                                      arg
                                                      
                                                      max
                                                   
                                                   
                                                      x
                                                   
                                                
                                                
                                                   M
                                                   
                                                      g
                                                      ,
                                                      t
                                                   
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

We also exploit saliency information to determine the target size St
                            at time t. Scale change estimation is carried out by using the scale ratios of the most persistent keypoints. We denote by 
                              
                                 
                                    F
                                    
                                       t
                                    
                                    *
                                 
                                 ⊂
                                 
                                    F
                                    t
                                 
                              
                            the subset including 50% of the elements in 
                              
                                 F
                                 t
                              
                           , having the highest value of ωt
                           . Then we compute
                              
                                 (9)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   S
                                                   t
                                                
                                                =
                                                
                                                   1
                                                   
                                                      
                                                         |
                                                      
                                                      
                                                         F
                                                         
                                                            t
                                                         
                                                         *
                                                      
                                                      
                                                         |
                                                      
                                                   
                                                
                                                
                                                   ∑
                                                   
                                                      
                                                         
                                                            f
                                                         
                                                         
                                                            (
                                                            j
                                                            )
                                                         
                                                      
                                                      ∈
                                                      
                                                         F
                                                         
                                                            t
                                                         
                                                         *
                                                      
                                                   
                                                   j
                                                
                                                
                                                   ρ
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      j
                                                      )
                                                   
                                                
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      (
                                                      j
                                                      )
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           to estimate the current target size, taking into account the object size S
                           (j) when the jth
                            feature was detected the first time.

The saliency information is updated with the object model when a good tracking is achieved. Our definition of a good tracking at time t is that the matching rate τt
                         in the target region exceeds the minimum rate τ
                        
                           min 
                        . In this case saliency indicators are adapted and 
                           P
                         is updated by adding/removing features.

If the matching rate τt
                            shows a good tracking quality, the persistence value 
                              
                                 ω
                                 
                                    t
                                 
                                 
                                    (
                                    i
                                    )
                                 
                              
                            is updated for the next iteration with
                              
                                 (10)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ω
                                                   
                                                      t
                                                      +
                                                      1
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                =
                                                
                                                   (
                                                   1
                                                   −
                                                   β
                                                   )
                                                
                                                
                                                   ω
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                +
                                                β
                                                
                                                   1
                                                   
                                                      {
                                                      
                                                         
                                                            f
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                      ∈
                                                      
                                                         F
                                                         t
                                                      
                                                      }
                                                   
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where β is an adaptation factor and 
                              
                                 1
                                 
                                    {
                                    
                                       
                                          f
                                       
                                       
                                          (
                                          i
                                          )
                                       
                                    
                                    ∈
                                    
                                       F
                                       t
                                    
                                    }
                                 
                              
                            is an indicator function defined on 
                              P
                            to indicate if f
                           (i) belongs to 
                              
                                 F
                                 t
                              
                           . Following this update, we remove from 
                              P
                            the elements having a persistence value lower than ω
                           
                              min 
                           . On the other hand, the newly detected features (in the predicted target region) are added to 
                              P
                            with an initial value ωinit
                           .

The spatial consistency Σ is a 2×2 covariance matrix considered as a quality indicator and used in the local prediction function (Eq. (6)). Σ is initialized to Σinit
                            for a new feature. It is then updated to determine the spatial consistency between f
                           (i) and the target center by applying
                              
                                 (11)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Σ
                                                   
                                                      t
                                                      +
                                                      1
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                =
                                                
                                                   (
                                                   1
                                                   −
                                                   β
                                                   )
                                                
                                                
                                                   Σ
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                +
                                                β
                                                
                                                   Σ
                                                   
                                                      cur
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           where the current estimate of Σ is
                              
                                 (12)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Σ
                                                   
                                                      cur
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                =
                                                
                                                   (
                                                   
                                                      V
                                                      
                                                         cur
                                                      
                                                      
                                                         (
                                                         i
                                                         )
                                                      
                                                   
                                                   −
                                                   
                                                      V
                                                      
                                                         t
                                                      
                                                      
                                                         (
                                                         i
                                                         )
                                                      
                                                   
                                                   )
                                                
                                                
                                                   
                                                      (
                                                      
                                                         V
                                                         
                                                            cur
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                      −
                                                      
                                                         V
                                                         
                                                            t
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                      )
                                                   
                                                   ⊤
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           and 
                              
                                 V
                                 
                                    cur
                                 
                                 
                                    (
                                    i
                                    )
                                 
                              
                            is the offset vector measured at time t given the global localization result. As a result, Σ decreases for consistent features, causing the votes to be more concentrated in the local prediction map. By contrast, the more this value increases during tracking (for inconsistent features), the more the votes become scattered.

In this step, we evaluate the predictive power of every keypoint contributing to the current localization, considering the maxima of local prediction maps, and the global maximum corresponding to the final target position. This process, that we call prediction back-evaluation, aims to assess how good local predictions are. The local prediction for the ith feature is defined as the position
                              
                                 (13)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         x
                                                      
                                                      ^
                                                   
                                                   
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                =
                                                
                                                   
                                                      arg
                                                      
                                                      max
                                                   
                                                   
                                                      x
                                                   
                                                
                                                
                                                   M
                                                   
                                                      l
                                                      ,
                                                      t
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           The predictive power
                           
                              
                                 ψ
                                 
                                    t
                                    +
                                    1
                                 
                                 
                                    (
                                    i
                                    )
                                 
                              
                            of f
                           (i) at time 
                              
                                 t
                                 +
                                 1
                              
                            depends on the distances between its past predictions and the corresponding global predictions. We calculate 
                              
                                 ψ
                                 
                                    t
                                    +
                                    1
                                 
                                 
                                    (
                                    i
                                    )
                                 
                              
                            with the summation of a fuzzy membership function as
                              
                                 (14)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   ψ
                                                   
                                                      t
                                                      +
                                                      1
                                                   
                                                   
                                                      (
                                                      i
                                                      )
                                                   
                                                
                                                =
                                                
                                                   ∑
                                                   
                                                      k
                                                      =
                                                      1
                                                   
                                                   t
                                                
                                                exp
                                                
                                                   (
                                                   
                                                      
                                                         −
                                                         
                                                            
                                                               (
                                                               
                                                                  
                                                                     
                                                                        x
                                                                     
                                                                     ^
                                                                  
                                                                  
                                                                     k
                                                                  
                                                                  
                                                                     (
                                                                     i
                                                                     )
                                                                  
                                                               
                                                               −
                                                               
                                                                  
                                                                     x
                                                                  
                                                                  
                                                                     k
                                                                  
                                                                  *
                                                               
                                                               )
                                                            
                                                            2
                                                         
                                                      
                                                      
                                                         ∈
                                                         
                                                            S
                                                            
                                                               k
                                                            
                                                            2
                                                         
                                                      
                                                   
                                                   )
                                                
                                                
                                                   
                                                      0.12
                                                      e
                                                      m
                                                   
                                                   
                                                      0
                                                      e
                                                      x
                                                   
                                                
                                                
                                                   
                                                      0.12
                                                      e
                                                      m
                                                   
                                                   
                                                      0
                                                      e
                                                      x
                                                   
                                                
                                                
                                                   1
                                                   
                                                      {
                                                      
                                                         
                                                            f
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                      ∈
                                                      
                                                         F
                                                         k
                                                      
                                                      }
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           where ∈ is a constant set to 0.005. The predictive power ψ increases as long as the feature achieves good local predictions. Consequently, the feature is considered as a reliable predictor, and its contribution in the global localization function (Eq. (7)) becomes more prominent. We note that both Σ and ψ are designed to evaluate the feature quality. However, the former affects local predictions while the latter weights its contribution in the global localization. The overall tracking algorithm steps are presented in Algorithm 1.
                              Algorithm 1
                              Tracking algorithm 
                                    
                                       
                                          
                                          
                                          
                                             
                                                1:
                                                – initialize 
                                                      P
                                                   
                                                
                                             
                                             
                                                2:
                                                
                                                   for all 
                                                   
                                                   frames 
                                                   do
                                                
                                             
                                             
                                                3:
                                                
                                                   – Apply feature detector
                                             
                                             
                                                4:
                                                
                                                   – Match features to get 
                                                      
                                                         
                                                            F
                                                            t
                                                         
                                                         ⊆
                                                         P
                                                      
                                                   
                                                
                                             
                                             
                                                5:
                                                
                                                   
                                                   for all
                                                   
                                                   
                                                      
                                                         matched
                                                         _
                                                         features
                                                      
                                                   
                                                   
                                                      
                                                         (
                                                         
                                                            
                                                               f
                                                            
                                                            
                                                               (
                                                               i
                                                               )
                                                            
                                                         
                                                         ∈
                                                         
                                                            F
                                                            t
                                                         
                                                         )
                                                      
                                                    
                                                   do
                                                
                                             
                                             
                                                6:
                                                
                                                   
                                                   – Scale/rotate 
                                                      
                                                         
                                                            V
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                   : (Eqs. (2) and (3))
                                             
                                             
                                                7:
                                                
                                                   
                                                   – Compute local likelihood map 
                                                      
                                                         
                                                            M
                                                            
                                                               l
                                                               ,
                                                               t
                                                            
                                                            
                                                               (
                                                               i
                                                               )
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                            
                                                            )
                                                         
                                                      
                                                   : (Eq. (6))
                                             
                                             
                                                8:
                                                
                                                   
                                                   – Find local prediction result 
                                                      
                                                         
                                                            
                                                               x
                                                            
                                                            ^
                                                         
                                                         
                                                            t
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                   : (Eq. (13))
                                             
                                             
                                                9:
                                                
                                                   
                                                   end for
                                                
                                             
                                             
                                                10:
                                                
                                                   – Compute global likelihood map 
                                                      
                                                         
                                                            M
                                                            
                                                               g
                                                               ,
                                                               t
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               x
                                                            
                                                            )
                                                         
                                                      
                                                   : (Eq. (7))
                                             
                                             
                                                11:
                                                
                                                   – Find global location 
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            t
                                                         
                                                         *
                                                      
                                                   : (Eq. (8)) {output for frame t}
                                             
                                             
                                                12:
                                                
                                                   – Estimate target size 
                                                      
                                                         S
                                                         t
                                                      
                                                   : (Eq. (9)) {output for frame t}
                                             
                                             
                                                13:
                                                
                                                   
                                                   if
                                                   
                                                   
                                                      
                                                         (
                                                         
                                                            τ
                                                            t
                                                         
                                                         ≥
                                                         
                                                            τ
                                                            min
                                                         
                                                         )
                                                      
                                                   
                                                   
                                                   then
                                                
                                             
                                             
                                                14:
                                                
                                                   
                                                   – Update 
                                                      
                                                         ω
                                                         
                                                            t
                                                            +
                                                            1
                                                         
                                                      
                                                   : (Eq. (10))
                                             
                                             
                                                15:
                                                
                                                   
                                                   – Remove non-persistent features (i.e.
                                                   
                                                      
                                                         
                                                            ω
                                                            
                                                               t
                                                               +
                                                               1
                                                            
                                                         
                                                         ≤
                                                         
                                                            ω
                                                            min
                                                         
                                                      
                                                   )
                                             
                                             
                                                16:
                                                
                                                   
                                                   
                                                   for all
                                                   
                                                      
                                                         matched
                                                         _
                                                         features
                                                      
                                                   
                                                   
                                                      
                                                         (
                                                         
                                                            
                                                               f
                                                            
                                                            
                                                               (
                                                               i
                                                               )
                                                            
                                                         
                                                         ∈
                                                         
                                                            F
                                                            t
                                                         
                                                         )
                                                      
                                                    
                                                   do
                                                
                                             
                                             
                                                17:
                                                
                                                   
                                                   
                                                   – update 
                                                      
                                                         Σ
                                                         
                                                            t
                                                            +
                                                            1
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                    (Eq. (11)) and 
                                                      
                                                         ψ
                                                         
                                                            t
                                                            +
                                                            1
                                                         
                                                         
                                                            (
                                                            i
                                                            )
                                                         
                                                      
                                                    (Eq. (14))
                                             
                                             
                                                18:
                                                
                                                   
                                                   
                                                   end for
                                                
                                             
                                             
                                                19:
                                                
                                                   
                                                   – Add new features to 
                                                      P
                                                   
                                                
                                             
                                             
                                                20:
                                                
                                                   
                                                   – Initialize 
                                                      
                                                         V
                                                         ,
                                                         ω
                                                         ,
                                                         Σ
                                                      
                                                   , and 
                                                      ψ
                                                    for new features
                                             
                                             
                                                21:
                                                
                                                   
                                                   end if
                                                
                                             
                                             
                                                22:
                                                
                                                   end for
                                                
                                             
                                          
                                       
                                    
                                 
                              

@&#EXPERIMENTS@&#

We evaluated our Salient Collaborating Features Tracker (SCFT) by a comparison to recent state-of-the-art algorithms. Among the compared trackers, four are part-based methods already discussed in Section 2. These trackers are the SuperPixel Tracker (SPT) [21], the Sparsity-based Collaborative Model Tracker (SCMT) [10], the Adaptive Structural Tracker (AST) [8], and the Structure-Aware Tracker (SAT) [28]. The fifth one is the online Multiple Support Instance Tracker (MSIT) [32] using a holistic appearance model. The corresponding source codes are provided by the authors with several parameter combinations. In order to ensure a fair comparison, we tuned the parameters of their methods so that for every video sequence in our dataset, we always use the best parameter combination among the proposed ones.

We evaluate the trackers on 20 challenging video sequences. Sixteen of them are from an object tracking benchmark commonly used by the community [33]. The four other sequences jp1, jp2, wdesk, and wbook were captured in our laboratory room using a Sony SNC-RZ50N camera. The area was cluttered with desks, chairs, and technical video equipment in the background. The video frames are 320×240pixels recorded at 15fps. We manually created the corresponding ground truths for jp1, jp2, wdesk, and wbook with 608, 229, 709, and 581 frames respectively.
                              1
                              Our sequences are available at http://www.polymtl.ca/litiv/en/vid/.
                           
                           
                              1
                            
                           Fig. 5
                            presents the first frame of each of the sequences. In order to better figure out the quantitative results of our tracker, we categorized the video sequences according to the main difficulties that may occur in each sequence. The categorization of the sequences according to seven main properties is presented in Table 1. This allows us to construct subsets of videos in order to quantitatively evaluate the trackers in several situations. Note that one video sequence may present more than one difficulty.

In order to summarize a tracker’s performance on a video sequence, we use the success rate and the average location error. The success rate is measured by calculating for each frame the Overlap Ratio 
                                 
                                    OR
                                    =
                                    
                                       
                                          area
                                          (
                                          
                                             P
                                             r
                                          
                                          ∩
                                          
                                             G
                                             r
                                          
                                          )
                                       
                                       
                                          area
                                          (
                                          
                                             P
                                             r
                                          
                                          ∪
                                          
                                             G
                                             r
                                          
                                          )
                                       
                                    
                                 
                              , where Pr
                               is the predicted target region and Gr
                               is the ground truth target region. For a given frame, tracking is considered as a success if OR ≥ 0.5. The Center Location Error (CLE) for a given frame consists in the position error between the center of the tracking result and that of the ground truth. Tables 2 and 3 present respectively the success rates and the average center location errors for the compared methods.

While the average location error is known to be useful to summarize performance by calculating the mean error over the whole video sequence, this metric may fail to correctly reflect the tracker behavior. For example, the average location error for a tracker that tracks an object accurately for almost all the sequence before losing it on the last frames could be substantially affected by large CLEs on the last few frames. To address this issue, we adopt the precision plot used in [34,35]. This graphic shows the percentage of frames (precision) where the predicted target center is within the given threshold distance from the ground truth center.

By analogy to the precision plot that shows percentages of frames corresponding to several threshold distances of the ground truth, the authors in [33] argue that using one success rate value at an overlap ratio of 0.5 may not be representative. As suggested in [33], we use the success plot showing the percentages of successful frames at the ORs varied from 0 to 1.

Two other types of plots are used in our experiments to analyze in depth the compared methods: (1) the center location error versus the frame number presented in Fig. 6
                              , and (2) the overlap ratio versus the frame number presented in Fig. 7. These plots are useful for monitoring and comparing the behaviors of several trackers over time for a given video sequence. We finally note that we averaged the results over five runs in all our experiments.

The overall performance for several trackers is summarized by the average values in the Tables 2 and 3 (last rows), as well as the average precision and success plots for the whole dataset (Fig. 8). All the metrics used for overall performance evaluation demonstrate that our proposed method outperforms all the other trackers, achieving an average success rate of 91.31% and an average localization error lower than 10 pixels. A major advantage of using success and precision plots is to allow choosing the appropriate tracker for a specific situation given the application requirements (e.g. high, medium, or low accuracy). In our experiments, the success and precision curves show the robustness of SCFT for all application requirements. SCFT is also the only tracker to reach 80% in precision for an error threshold of 15pixels, and to produce a success rate exceeding 60% when the required OR is 80%. Except for SAT that realized the second best overall performance, and MSIT that had the last rank, the rankings of the other trackers are different depending on the considered metric. In the following subsections, the experimental results are discussed in details.

We evaluated the six methods in face tracking under long-term partial occlusion (up to 250 consecutive frames). In the faceocc and wbook, the tracked face remains partially occluded by an object several times for a long period. Some trackers drift away from the target to track the occluding object, which is mainly due to appearance model contamination by features belonging to the occluding object. Our method was able to track the faces successfully in almost all the frames under severe occlusion. The local predictions of a few detected features were sufficient for SCFT to achieve an accurate global prediction. Our target model may erroneously include features from the occluding object, but since we evaluate their motion consistency and predictive power, the corresponding local predictions will be scattered in the voting space and have small weights in the global localization function. The error plots for faceocc shows that SCMT and SAT also achieved good performances when the target was occluded (e.g. between frames 200 and 400). In fact, SCMT and SAT are also designed to handle occlusions, respectively through a scheme considering unoccluded patches, and a voting-based method that predicts the target center.

In the wdesk sequence, the tracked face undergoes severe partial occlusions while moving behind a desk. SCFT, SAT and SCMT track the target correctly until frame #400 where the person performs large displacements causing SCMT to drift away from the face. Both SCFT and SAT continue the tracking successfully while the tracked person hides behind a desk, and our method achieved the best success rate of 93.96%.

The success plots of long-term occlusion videos for SCFT and SAT show that both trackers can achieve more than 80% success rate as long as the required overlap ratio is lower than 0.5 (see Fig. 9). Both trackers also had the two best precision curves, but SCFT performed significantly better under high requirement in accuracy (i.e. location error threshold lower than 15pixels). As expected, the precision curve of MSIT is located below the others, since the holistic appearance model is not effective for a target undergoing severe occlusions.

The third and fourth rows of Fig. 10 present results of face tracking in moderately crowded scenes (four persons). In this experiments, our goal is to test the distinctiveness of the trackers. The success and precision plots for this category clearly show that SCFT and SAT are ranked respectively first and second regardless of the application requirements. This is mainly explained by the use of SIFT features that are proven to be effective in distinguishing a target face among a large number of other faces [36–38].

In the jp1 video, we aim to track a face in presence of three other distracting faces, moving around the target and partially occluding it several times. The corresponding OR and CLE plots show that the proposed SCFT method produces the most stable tracking at the lowest error during almost all the 608 video frames. Although the success rates of 89.14%, 84.38%, and 78.13% respectively for SAT, AST, and SCMT indicate good performances, the last two trackers drift twice (first at frame #530 and a second time at frame #570) to track distracting faces occluding or neighboring the target. We can also see in the OR and CLE plots that SAT drifts considerably three times, especially between frames #341 and #397 when the tracked face region (person with a black t-shirt in the middle of the scene) is mostly occluded. However, neither the presence of similar objects near the target nor partial occlusion situations affected our SCFT tracker. The high performance of the proposed method in these situations is due to the distinctiveness of SIFT keypoints, in addition to the reliance on local predictions of the most salient features, even if outliers (from the background, neighboring or occluding faces) can be present in the feature pool.

In the jp2 video, we track a walking person in the presence of four other randomly moving persons. The target crosses in front or behind distractors that may occlude it completely for a short period. All the five other methods confused the target with an occluding face, at least for a few frames after full occlusion. Nevertheless, SCFT is able to recover tracking correctly as soon as a small part of the target becomes visible. For both distractors sequences jp1 and jp2, SCFT produced simultaneously the highest success rate and the lowest average error.

The video sequence David is recorded using a moving camera, following a walking person. The scene illumination conditions change gradually as the person moves from a dark room to an illuminated area. The face also undergoes significant pose change during movement. All the trackers, except AST, were able to track the face successfully in more than 60% of the frames. Once again, SCFT achieved the best success rate and the lowest average error. This experiment shows the efficiency of our appearance model, allowing the tracker deal robustly with illumination variation. Our method is also not affected by large and continuous camera motion since features are detected wherever the space reduction method shows a significant likelihood of finding the target. On the other hand, in-plane rotations are handled efficiently in the global prediction function since we exploit the information on keypoint local orientation changes.
                        


                           
                        


                           
                        


                           
                           
                           
                        

The target person’s face in the girl video, exhibits pose change and out-of-plane rotations abruptly. SPT, SAT, and SCFT were able to track the face correctly in more than 80% of the frames. SCFT achieved the best success rate, handling efficiently pose change and partial occlusion. Our tracking was accurate as long as the girl’s face was at least partly visible. We lost the target when the face was turned away from the camera, but we were able to recover tracking quickly as soon as it partially reappeared.

The main difficulty with the cliffbar, tiger1, and tiger2 videos is the cluttered background whose the appearance may disrupt the tracker. For this category, the success and precision curves of SCFT are located above the others, showing the advantage of our method for all the tested thresholds of OR and CLE. Always based on the success and precision plots, we can see that SAT and SPT were ranked respectively second and third. It is noteworthy that both methods include discriminative aspects facilitating tracking under such conditions. In fact, SPT uses a discriminative appearance model based on superpixel segmentation while SAT utilizes information on the background color distribution to evaluate the tracking quality.

In the Cliffbar sequence, a book is used as a background having a similar texture to that of the target. SCFT outperformed significantly all the competing methods in both success rate and average location error. AST, SAT, and SPT also performed relatively well, taking into account the difficulty of the sequence. Indeed, the target undergoes abrupt in-plane rotations and drastic appearance change because of high motion blur. The proposed tracker is hardly affected by these difficulties since it continues adapting the appearance model by including/removing keypoints, and handling pose change through keypoint orientations.

In the tiger1 and tiger2 sequences, the target exhibits fast movements in a cluttered background with frequent occlusions. Owing to partial predictions that localize the target center using a few visible keypoints, SCFT had the highest percentages of correct tracks for both videos. SAT also overcomes the frequent occlusion problem via its voting mechanism that predicts the target position from available features. The other methods fail to locate the stuffed animal, but SPT had relatively better results due to its discriminative model facilitating the distinction between target superpixels and background superpixels. Note that the tracked object in tiger1 and tiger2 is a deformable stuffed animal. The predictions of features located on articulated parts are consequently inconsistent with the overall consensus, but this issue is efficiently handled by the use of spatial consistency and predictive power that reflect the predictors’ reliability. These features may remain in 
                              P
                            and continue predicting the target position without affecting the global result (because of low predictive power and spatial consistency). Our feature pool may also erroneously include outliers from the background, identified as non-persistent to be removed from the model.

One of the most challenging situations encountered in our dataset is the partial occlusion. The target faces in the faceocc, wdesk, and wbook videos undergo severe long-term occlusions causing the number of detected features to decrease drastically. Since local features detection represents a critical component for part-based trackers, we propose to study the impact of the number of features on SCFT’s performance. We considered the video sequences faceocc, wdesk, and wbook, and analyzed the number of detected features on every video frame. We computed the average CLE value for each subset of frames having their numbers of collaborating features within the same interval (spanning 10 values). This allows us to create a scatter plot representing the average CLE versus the number of collaborating features (Fig. 11
                           ). To investigate the relationship between the number of features and the CLE, we model the plot by fitting a fourth degree predictor function and a linear function. The plot shows that the smallest numbers of features produce an average CLE not exceeding nine pixels. After that, the fitted fourth degree function decreases before stabilizing around the mean value of four pixels when more than 30 features are detected. Regarding the linear function (
                              
                                 y
                                 =
                                 ax
                                 +
                                 b
                              
                           ), it is obvious to expect that the coefficient a would be negative since the CLE becomes lower when the number of features increases. However, a high absolute value for a would suggest that the algorithm requires a large number of features to achieve accurate tracking. In our case, the linear coefficients estimation (
                              
                                 a
                                 =
                                 −
                                 0.0064
                                 ;
                                 b
                                 =
                                 5.1107
                              
                           ) demonstrate that the error barely increases when the number of collaborating features diminishes from the maximum (i.e. 345 features) to one feature. This ascertainment confirms that the collaboration of a few number of unoccluded features is sufficient for our tracker to ensure accurate tracking.

In this section, we analyze the effect of the saliency factors separately on the tracking performance. We created three versions of SCFT:
                              
                                 •
                                 
                                    v–ω: the persistence indicator ω is not used in the global prediction function.


                                    v–ψ: the predictive power ψ is completely removed from the algorithm.


                                    v–Σ: the spatial consistency matrix is not updated, and is the same for all the features (
                                       
                                          Σ
                                          =
                                          
                                             Σ
                                             init
                                          
                                       
                                    ).


                           Tables 4 and 5 respectively present the percentages of correctly tracked frames and the average location errors for SCFT and the three other versions of the tracker on a subset of five video sequences. The selected sequences cover almost all the situations in Table 1, and each video includes several difficulties. The obtained results show that the tracking performance is more affected when the persistence indicator is not considered (version v–ω). In fact, v–ψ and v–Σ outperformed v–ω for all the five sequences. This result can be explained by the fact that with the removal of one factor among ψ and Σ, the remaining one continues to take into account the precision of the feature’s past predictions, since both the spatial consistency and the predictive power are designed to assess the feature quality. However, if the indicator ω is not considered, the prediction step no longer takes into account the occurence level of the keypoint. Furthermore, these experiments demonstrated the complementarity of the three saliency factors, as the best performance is obtained when the three indicators are evaluated and updated during tracking. We finally note that the saliency evaluation method proposed in this work can be adapted or applied directly to a wide range of tracking algorithms that are based on the voting of local features.
                           
                        

Most of the parameters of our algorithm were set to default values for all the video sequences. In our experimental work, only three parameters were tuned to optimize the performance of the tracker:
                              
                                 •
                                 
                                    N*: the number of particles defining the reduced search space, where keypoints are detected.


                                    τmin
                                    : the minimum matching rate that is required to update the appearance model.


                                    ωmin
                                    : the persistence threshold used to determine if the feature should be removed from the model.

In order to evaluate the sensitivity of SCFT to parameters, we considered the same subset of five sequences and ran our tracker multiple times on each video, using the optimized parameters of the other videos. The optimized parameter values for each video are shown in Table 6
                           .

The results of these runs are reported in Tables 7 and 8
                           
                           , where the A.D. column shows the Average Difference between the result obtained with the optimized set of parameters and those obtained with the parameter sets of the four other sequences. As we can see, 13.33% is the most significant average decrease in sucess rate (for the girl video), while the highest average increase in localization error is that of the David2 sequence (4.3pixels). On the other hand, parameter change had a very low impact on the video sequences deer (1.41% as average decrease in success rate) and boy (1.30pixels as average increase in localization error). In general, SCFT was able to achieve a stable tracking for all the runs and the performance of our tracker was not dramatically affected by the change of parameters.

The proposed tracker was implemented using Matlab on a PC with a Core i7-3770 CPU running at a 3.4GHz. Our algorithm is designed to maintain a reasonable computational complexity. In fact, keypoints are extracted in a limited image region determined by particle filtering to reduce the computational cost of feature detection and local descriptor creation. Moreover, the particle filter generates 
                              
                                 N
                                 =
                                 400
                              
                            particles, among which only a limited subset of N* particles is used as a reduced search space on the current frame, and for generating the N particles on the subsequent frame. In practice, the computation time of SCFT is determined mostly by the number of detected object keypoints voting for the target position, which mainly depends on the object size and texture. As an example, the video sequences tiger1 and tiger2, with a small target size, are processed at approximately 1.3s per frame. On the other hand, when the object size is larger such as in the faceocc sequence, our algorithm requires from 2 to 3s to find the target on a given frame. Table 9
                            provides a computation time comparison for the six trackers on the David2 sequence that represents a typical scenario of face tracking. According to the performed measures, our algorithm requires in average 1.2s to process one frame from the David2 sequence, which is the second best execution time. AST achieved the shortest time, processing one frame in 0.42s. Note that all the compared methods are implemented in Matlab by the authors and run on our described computer.

@&#CONCLUSION@&#

This paper proposes a novel and effective part-based tracking algorithm, based on the collaboration of salient local features. Feature collaboration is carried out through a voting method where keypoint patches impose local geometrical constraints, preserving the target structure while handling pose and scale changes. The proposed algorithm uses saliency evaluation as a key technique for identifying the most reliable and useful features. Our conception of feature saliency includes three elements: persistence, spatial consistency, and predictive power. The persistence indicator allows to eliminate outliers (e.g. from the background, or an occluding object) and expired features from the target model, while the spatial consistency and the predictive power indicators penalize predictors that do not agree with past consensus. The experiments on publicly available videos from standard benchmarks show that SCFT outperforms state-of-the-art trackers significantly. Moreover, our tracker is insensitive to the number of tracked features, achieving accurate and robust tracking even if most of the local predictors are undetectable.

@&#ACKNOWLEDGMENTS@&#

This work was supported by a scholarship from FRQNT and partially supported by NSERC discovery Grant No. 311869-2010.

Supplementary data associated with this article can be found, in the online version, at http://dx.doi.org/10.1016/j.cviu.2015.03.010.


                     
                        
                           Supplementary video 1
                           
                        
                     
                  

@&#REFERENCES@&#


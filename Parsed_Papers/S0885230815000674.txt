@&#MAIN-TITLE@&#Principal differential analysis for detection of bilabial closure gestures from articulatory data

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Electromagnetic articulographic data represented in task dynamics.


                        
                        
                           
                           Dynamics of lip movement represented by linear differential equations.


                        
                        
                           
                           Linear differential equations learned by principal differential analysis (PDA).


                        
                        
                           
                           Bilabial/non-bilabial classification using parameters of PDA with high accuracy.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Bilabial closure gesture

Principal differential analysis (PDA)

Articulatory data

Tract variables

Classification

@&#ABSTRACT@&#


               
               
                  In this paper, a new statistical method for detecting bilabial closure gestures is proposed based on articulatory data. This can be surprisingly challenging, since mere proximity of the lips does not imply their involvement in a directed phonological goal. This segment-based bilabial closure detection scheme uses principal differential analysis (PDA) to extract articulatory gestures. The dynamic patterns of the tract variables (TVs) lip aperture, lip protrusion, and their derivatives, are captured with PDA and used to detect and quantify bilabial closure gestures. The proposed feature sets, which are optimized using sequential forward floating selection (SFFS), are combined and used in binary classification. Experimental results using the articulatory database MOCHA-TIMIT show the effectiveness of the proposed method demonstrating promising performance in terms of high classification accuracy (95%), sensitivity (95%), and specificity (95%).
               
            

@&#INTRODUCTION@&#

Bilabial closure often precedes sudden airflow out of the mouth, as in the plosive onset in pie, buy, or is concurrent with airflow out of the nose, as in the nasal onset in my (Lofqvist and Gracco, 2010). In either case, the resulting acoustics can be fairly similar to other phones in the respective classes, which can affect speech recognition (Rudzicz, 2011). However, articulatory features are robust across speakers, share commonalities (in many cases) across languages, and are generally insensitive to situational changes (Zhao et al., 2013). We propose a new scheme for detecting articulatory gestures based on principal differential analysis (PDA) and articulatory data. Here, gestures are directed reconfigurations of the vocal tract to achieve a discrete phonologically relevant goal, such as lowering the velum. For this purpose, we have focused on directed bilabial gestures in the MOCHA-TIMIT database (Wrench, 2000), which consists of electromagnetic articulography (EMA) data tracking the positions and velocities of point-sensors affixed to the articulators.


                     Task dynamics is a combined model of skilled articulator motion and abstract vocal tract configuration (Saltzman and Munhall, 1989) that provides a coherent and biologically plausible model of speech production with consequences for phonology (Browman and Goldstein, 1986), neurolinguistics, and the evolution of speech and language (Goldstein et al., 2006). In this theory, tract variables (TVs) generally refer to the locations and degrees of vocal tract constrictions, as functions of time. Each gesture is a directed motion to complete some phonologically or acoustically relevant task within one of the following TVs: lip aperture (LA), lip protrusion (LP), tongue tip constriction location (TTCL) and degree (TTCD), tongue dorsum constriction location (TDCL) and degree (TDCD), velum (VEL), glottis (GLO), and lower tooth height (LTH). For instance, a gesture to close the lips would occur within the LA variable and would set that variable to zero. The dynamic influence of each gesture in time on the relevant tract variable is modeled by a non-homogeneous second-order linear differential equation mimicking a highly coupled spring-mass system. Typically, the coefficients of these systems have been set empirically by experts (Saltzman and Munhall, 1989), but with several exceptions. For example, McGowan (1994) used a genetic algorithm to recover task dynamic parameters from acoustic speech signals, and Lammert et al. (2013) use both artificial neural networks and locally-weighted regression to estimate kinematic relationships of speech production in task dynamics. Similarly, Howard and Huckvale (2005) train an inverse mapping between an articulatory synthesizer's control parameters and their auditory consequences, in a manner similar to work done with the DIVA system (Guenther and Perkell, 2004), and Nam et al. (2012) use an iterative analysis-by-synthesis procedure using time-warping in task dynamics to learn relevant parameters. Although clear differences exist between these efforts, in general their aims were to realistically estimate and simulate gestural dynamics given data. By contrast, our approach of using principal differential analysis (which is unique among this work) is primarily a means towards an end, namely the classification of articulatory features.

@&#PROPOSED METHOD@&#

The EMA data and their associated, time-aligned acoustics are segmented by phone annotations. These phone annotations allow us to simply extract phonological characteristics (Ali et al., 1999; Hosom, 2000; Ladefoged and Johnson, 2011), therefore all data are segmented by provided phone boundaries and labelled as either bilabial or non-bilabial. We note that, in this database, these phone boundaries have been determined using forced alignment on the acoustics, therefore some errors are possible. The raw EMA data are transformed to tract variables, as described in Section 3. Each tract variable is assumed to be governed by functional differential equations whose parameters must take into account the substantial variation inherrent in the articulators of speech (Rudzicz, 2012). Principal differential analysis optimizes the parameters of the following linear differential operator over a sample of functional data:
                        
                           (1)
                           
                              Ly
                              (
                              n
                              )
                              =
                              
                                 w
                                 0
                              
                              y
                              (
                              n
                              )
                              +
                              
                                 w
                                 1
                              
                              
                                 D
                                 1
                              
                              y
                              (
                              n
                              )
                              +
                              ⋯
                              +
                              
                                 w
                                 m
                              
                              
                                 D
                                 m
                              
                              y
                              (
                              n
                              )
                              ,
                           
                        
                     where D
                     
                        m
                      denotes the mth derivative and y(n) is an observed function. Specifically, m weighting functions 
                        
                           w
                           j
                        
                      are optimized with point-wise minimization computed with standard least-squares estimation (Ramsay and Silverman, 2002; Ramsay, 1996). This model simplifies as Ly
                     
                        n
                     
                     =
                     f
                     
                        n
                     , n
                     =1, …, N where the forcing function f
                     
                        n
                      corresponds to the residual term in regression analysis and reflects variation that cannot be explained by the linear homogeneous differential equation Ly
                     
                        n
                     
                     =0. This approach has been successful in reducing bias in other types of quasi-stationary signals with additive Gaussian noise (Jin et al., 2013).

Relevant features are extracted and selected prior to classification, given the articulatory data segmented by phone and labelled with the class, as described in the following subsections.

In this work, we use a second-order differential equation to capture the articulatory features in tract variables LA and LP and their derivatives, specifically:
                           
                              (2)
                              
                                 
                                    LTV
                                    n
                                 
                                 =
                                 
                                    w
                                    0
                                 
                                 
                                    TV
                                    n
                                 
                                 +
                                 
                                    w
                                    1
                                 
                                 
                                    D
                                    1
                                 
                                 
                                    TV
                                    n
                                 
                                 +
                                 
                                    w
                                    2
                                 
                                 
                                    D
                                    2
                                 
                                 
                                    TV
                                    n
                                 
                                 ,
                                 
                                 n
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                                 .
                              
                           
                        
                     

Given J observations where j, 1⋯
                        J, is the jth observation, we assume that each of the bilabial and non-bilabial groups can be described by uniquely parameterized differential equations of the form:
                           
                              (3)
                              
                                 −
                                 
                                    D
                                    2
                                 
                                 
                                    TV
                                    j
                                 
                                 (
                                 n
                                 )
                                 =
                                 
                                    w
                                    0
                                    j
                                 
                                 (
                                 n
                                 )
                                 
                                    TV
                                    j
                                 
                                 (
                                 n
                                 )
                                 +
                                 
                                    w
                                    1
                                    j
                                 
                                 (
                                 n
                                 )
                                 
                                    D
                                    1
                                 
                                 
                                    TV
                                    j
                                 
                                 (
                                 n
                                 )
                                 +
                                 
                                    r
                                    j
                                 
                                 (
                                 n
                                 )
                                 ,
                                 
                                 n
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                                 ;
                                    
                                 j
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 J
                                 ,
                              
                           
                        where r
                        
                           j
                        (n) is the jth random sample of Gaussian noise. Let H
                        
                           j
                        (n)=−
                        D
                        2
                        TV
                        
                           j
                        (n) and D(n) be a J
                        ×2 full column rank matrix with the pth (p
                        =0, 1) column given by 
                           
                              
                                 [
                                 
                                    D
                                    p
                                 
                                 
                                    TV
                                    1
                                 
                                 (
                                 n
                                 )
                                 ,
                                 …
                                 ,
                                 
                                    D
                                    p
                                 
                                 
                                    TV
                                    J
                                 
                                 (
                                 n
                                 )
                                 ]
                              
                              T
                           
                         and 
                           
                              w
                              j
                           
                           (
                           n
                           )
                           =
                           
                              
                                 [
                                 
                                    w
                                    o
                                    j
                                 
                                 (
                                 n
                                 )
                                 
                                    w
                                    1
                                    j
                                 
                                 (
                                 n
                                 )
                                 ]
                              
                              T
                           
                        , where T denotes the transpose. Then Eq. (3) can be expressed as
                           
                              (4)
                              
                                 
                                    H
                                    j
                                 
                                 (
                                 n
                                 )
                                 =
                                 D
                                 (
                                 n
                                 )
                                 
                                    w
                                    j
                                 
                                 (
                                 n
                                 )
                                 +
                                 
                                    r
                                    j
                                 
                                 (
                                 n
                                 )
                                 ,
                                 
                                 j
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 J
                                 .
                              
                           
                        Then the estimated weight functions (i.e., feature functions) are
                           
                              (5)
                              
                                 
                                    w
                                    j
                                 
                                 (
                                 n
                                 )
                                 =
                                 
                                    
                                       [
                                       D
                                       
                                          
                                             (
                                             n
                                             )
                                          
                                          T
                                       
                                       D
                                       (
                                       n
                                       )
                                       ]
                                    
                                    
                                       −
                                       1
                                    
                                 
                                 D
                                 
                                    
                                       (
                                       n
                                       )
                                    
                                    T
                                 
                                 
                                    H
                                    j
                                 
                                 (
                                 n
                                 )
                                 ,
                              
                           
                        at fixed n obtained by the least squares solution minimizing 
                           [
                           
                              H
                              j
                           
                           (
                           n
                           )
                           −
                           D
                           (
                           n
                           )
                           
                              w
                              j
                           
                           (
                           n
                           )
                           ]
                         with respect to 
                           
                              w
                              m
                              j
                           
                           (
                           m
                           =
                           0
                           ,
                           1
                           )
                        .

For quantification of bilabial closure gestures, we have considered the model fit given by the R-squared (RSQ) function ∈[0, 1]:
                           
                              (6)
                              
                                 RSQ
                                 (
                                 n
                                 )
                                 =
                                 
                                    
                                       
                                          E
                                          0
                                       
                                       (
                                       n
                                       )
                                       −
                                       
                                          E
                                          2
                                       
                                       (
                                       n
                                       )
                                    
                                    
                                       
                                          E
                                          0
                                       
                                       (
                                       n
                                       )
                                    
                                 
                                 ,
                              
                           
                        where
                           
                              (7)
                              
                                 
                                    
                                       
                                       
                                          
                                             E
                                             0
                                          
                                          (
                                          n
                                          )
                                          =
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             J
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         ∑
                                                         
                                                            p
                                                            =
                                                            0
                                                         
                                                         1
                                                      
                                                      (
                                                      
                                                         w
                                                         p
                                                      
                                                      (
                                                      n
                                                      )
                                                      
                                                         D
                                                         p
                                                      
                                                      
                                                         TV
                                                         j
                                                      
                                                      (
                                                      n
                                                      )
                                                      )
                                                      +
                                                      
                                                         D
                                                         2
                                                      
                                                      
                                                         TV
                                                         j
                                                      
                                                      (
                                                      n
                                                      )
                                                   
                                                
                                             
                                             2
                                          
                                          ,
                                       
                                    
                                    
                                       
                                       
                                          
                                             E
                                             2
                                          
                                          (
                                          n
                                          )
                                          =
                                          
                                             1
                                             J
                                          
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             J
                                          
                                          
                                             
                                                (
                                                
                                                   LTV
                                                   j
                                                
                                                (
                                                n
                                                )
                                                )
                                             
                                             2
                                          
                                          =
                                          
                                             1
                                             J
                                          
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             J
                                          
                                          
                                             
                                                (
                                                
                                                   f
                                                   j
                                                
                                                (
                                                n
                                                )
                                                )
                                             
                                             2
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where f
                        
                           j
                        (n) is the jth forcing function, corresponding to the response of the second-order system describing the behavior of the system. We have taken the mean value of the RSQ function to quantify the presence/absence of bilabial gestures for the directed closure. The mean value is chosen here as a threshold for making a decision considering the Gaussian process. Moreover, we have used the RSQ to incorporate the forcing functions as a ‘diagnostic’ tool since they estimate the lack of fit of a dynamic system on the scale of derivatives; RSQ increases with the structure variation with respect to the overall variation.

We have suggested another quantification measure 1/r based on the radius of curvature r for the phase-plane plot of the acceleration (ordinate) versus velocity (abscissa). Here, the parameter r is estimated by an osculating circle based on a curvature estimation method (Worring and Smeulders, 1993) of a contour c represented by ith x and y co-ordinates as follows:
                           
                              (8)
                              
                                 
                                    c
                                    i
                                 
                                 =
                                 (
                                 
                                    x
                                    i
                                 
                                 ,
                                 
                                    y
                                    i
                                 
                                 )
                                 ,
                                 
                                 i
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 N
                                 ,
                              
                           
                        where x
                        
                           i
                         and y
                        
                           i
                         represent the velocity and acceleration and N is the number of co-ordinates, as obtained using the input LA curves. The size of each original articulatory feature (AF) space is 51, which corresponds to the length of the weight functions.

Feature selection can improve classification by removing redundant information in high-dimensional spaces. The sequential floating forward selection (SFFS) algorithm (Pudil et al., 1994), finds an optimal subset of features by appending features to and discarding features from subsets of selected features and has been adopted to guide the search, as shown in Algorithm 1. A separation index based on distance and separability measures is considered in the SFFS algorithm as an objective function, which evaluates the candidate set by returning a measure of their ‘goodness’. This SFFS scheme automatically selects an optimized feature subset of articulatory features related to LA and LP gestures.


                        
                           Algorithm 1
                           The SFFS algorithm adopted for feature selection. 
                                 
                              
                           

Techniques for fusing multiple sources of evidence can be generally categorized into two types: fusion at the “feature level” and fusion at the “decision level” (Atrey et al., 2010). Feature-level fusion is performed by merging the calculated features from each source into a cumulative structure and feeding them to a classifier. In decision-level fusion, each feature set is first classified independently, and the final decision is made by fusing the output from the classification processes using the maximum, average, and product criteria. Here, we use feature-level fusion since it often gives better classification accuracy (Jain et al., 2005). Here, AFs derived from the LA and LP TVs and their derivatives (see Section 2.1) are simply concatenated into longer global feature vectors.

Detecting directed bilabial/non-bilabial closures, as in specific phones, is a binary classification problem, which is solved here by a least-squares support vector machine (LS-SVM) (Suykens and Vandewalle, 1999) which has fast convergence, high accuracy, and low computational complexity (Suykens et al., 2001). LS-SVMs apply linear least squares criteria to the minimization of the cost function instead of traditional quadratic programming. Suppose that the training set consists of N feature vectors 
                           
                              
                                 
                                    x
                                 
                              
                              i
                           
                           ∈
                           
                              R
                              d
                           
                           (
                           i
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           N
                           )
                         from the d-dimensional feature space X, namely, the space representing the features extracted from principal differential analysis. For each vector x
                        
                           i
                        , we associate a target y
                        
                           i
                        
                        ∈{−1, +1}. Linear SVM classification maximizes the margin of an optimal hyperplane separating the two cases in X. In our case, we use the nonlinear radial basis function (RBF) kernel to compare pairs of feature vectors in a higher-dimensional space:
                           
                              (9)
                              
                                 
                                    K
                                    RBF
                                    
                                       (
                                       σ
                                       )
                                    
                                 
                                 
                                    
                                       
                                          
                                             x
                                             1
                                          
                                          ,
                                          
                                             x
                                             2
                                          
                                       
                                    
                                 
                                 =
                                 exp
                                 
                                    
                                       
                                          −
                                          
                                             
                                                ∥
                                                
                                                   x
                                                   1
                                                
                                                −
                                                
                                                   x
                                                   2
                                                
                                                
                                                   ∥
                                                   2
                                                
                                             
                                             
                                                2
                                                
                                                   σ
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where σ is our empirical parameter and the RBF kernel has been chosen empirically (Keerthi and Lin, 2003).

This extends our previous work (Reimer and Rudzicz, 2010) where PDA was used to classify articulatory/phonological features by directly comparing coefficients of determination (i.e., comparing sums of squared second derivatives with sums of squared residuals). Although in a different domain, PDA has also recently been applied to the classification of blood fluid dynamics using a bivariate quadratic discriminant analysis based on the amplitudes of the exponential and sinusoidal components (Rosa et al., 2014).

@&#EXPERIMENTS@&#

In this study, we use 460 sentences uttered by a male British speaker, msak0, in the MOCHA-TIMIT database (Wrench, 2000) including acoustics temporally aligned with electromagnetic articulography (EMA, recorded at 500Hz). The EMA data consist of eight bivariate articulatory measurements, namely the upper lip (UL), lower lip (LL), upper incisor (UI), lower incisor (LI), tongue tip (TT), tongue blade (TB, 1cm from the tongue tip), tongue dorsum (TD, 1cm from the tongue blade), and velum (V). Each parameter is measured in the midsagittal plane.

We transform the midsagittal EMA articulatory data to tract variables using z-score normalized principal component analysis (Rudzicz, 2012). The normalized Euclidean distance between the upper lip (UL) and lower lip (LL) is used to estimate lip aperture (LA) and the second principal component of the motion of the centroid between UL and LL is used to determine lip protrusion (LP). The distributions of various bilabials and non-bilabials are shown for each LA and LP in Fig. 1
                     (a) and (b), respectively. Indeed, the mere value of LA is not sufficient to determine closure gestures, as approximately 55.3% of the phone sequences in non-bilabial cases have LA below the mean threshhold. The scatter of bilabials and non-bilabials in Fig. 1 shows correlation coefficients between LA and LP variables of only 0.2765 and 0.0066 for the bilabials and non-bilabials, respectively, which further emphasizes the challenges in classification.

The dynamics of the articulators over time are used in the detection of bilabial closure gestures. Here, we use 6th-order B-splines to obtain a reliable estimate of the first two derivatives of the TVs. Figs. 2–4
                        
                        
                         show the dynamics of LA across bilabial/non-bilabial pairs of voiced plosives, nasals, and unvoiced plosives, respectively. Specifically, we show the LA curves, corresponding forcing functions (see Section 2.1), and coefficient functions 
                           
                              w
                              o
                           
                         and 
                           
                              w
                              1
                           
                        . These functions are anti-phase for bilabial closures but in-phase for non-bilabial closures, which implies that the derivatives D
                        1 and D
                        2 are distinct for the former but similar for the latter. The phase-plane plots show distinct patterns of velocity (δ)-vs-acceleration (δδ) across bilabial closure gestures and non-bilabial closure gestures.


                        Table 1
                         shows the curvature values for the second half of the curves representing the phase-plane plots. The bilabial closure gestures can be quantified by the high curvature values (>1) compared to non-bilabial cases. Moreover, the mean values of the RSQ functions in bilabial cases are found to be smaller than those of the non-bilabial cases, as shown in Table 2
                         due to less structural variability in the former.

The proposed method is evaluated in terms of classification results for the articulatory data segments with and without bilabial closure gestures using speaker msak0's data from MOCHA-TIMIT. Results are obtained over 100 different runs in which the feature sets are split randomly by segment where 2/3 of the data are used for training and 1/3 of the data are retained for testing. In each case, the feature set is normalized to have zero mean and unit standard deviation. The classifier parameters (i.e., the regularization parameter C and the RBF kernel parameter σ) are estimated using cross-validation. Parameters are tuned in two steps. First, a modern global optimization technique, coupled simulated annealing (CSA), determines suitable parameters according to the mean-squared error (MSE) criterion. Second, these parameters are then given to a second optimization procedure (simplex or grid search) to perform a fine-tuning step. Table 3
                         shows the performance of the proposed scheme in terms of sensitivity, specificity, and classification accuracy given a feature set with size S, as derived from LA. Here, sensitivity increases with S before leveling off.

The results of each optimal feature set (using SFFS) are shown in Table 4
                        . The corresponding combined feature set consists of LA and LP, their velocity δ and acceleration δδ for a combined feature set size of 
                           
                              
                                 w
                                 0
                              
                           
                           +
                           
                              
                                 w
                                 1
                              
                           
                           =
                           (
                           25
                           ×
                           1
                           )
                           +
                           (
                           12
                           ×
                           1
                           )
                         which gives a mean sensitivity of 80.72% (σ
                        =2.44), a mean specificity of 90.95% (σ
                        =0.91), and a mean accuracy of 87.73% (σ
                        =0.87). The combined feature sets significantly out-perform the LA-only results, with one-sample, two-tailed t-tests for sensitivity (t(99)=330.41;
                        p
                        <0.05;
                        CI
                        =[80.2381.20]), specificity (t(99)=999.53;
                        p
                        <0.05;
                        CI
                        =[90.7791.13]), and accuracy (t(99)=1001;
                        p
                        <0.05;
                        CI
                        =[87.5587.90]).

In order to increase the sensitivity, we add random noise (i.e., 15dB Brownian noise) to the observation sequences, which is often added to the input sequence of the Σ−Δ modulator to improve performance by decorrelating the quantization noise, despite decreasing SNR (Chou, 1991; Yu, 2012). This ‘dithering’ effect, shown in Table 5
                        , significantly improves the sensitivity (t(99)=633.12;
                        p
                        <0.05;
                        CI
                        =[91.5492.12]) in comparison to the sensitivity results without dithering in Table 3 (t(99)=340.97;
                        p
                        ≤0.05;
                        CI
                        =[78.1579.07]).

A one-way analysis of variance (ANOVA) reveals that there is a significant effect between feature sizes and performance measures. Specifically, F
                        2
                        =68.45, p
                        <0.0001.

The performance of the individual optimum feature set with dither is shown in Table 6
                        . Here, sensitivity and accuracy have increased due to the influence of the low-frequency dither on the second-order dynamic system. This low-frequency dither increases the damping factor and gives a more compact feature set. Using the combined selected features with dither (LA and LP, their δ and δδ for a combined feature set size of 
                           
                              
                                 w
                                 0
                              
                           
                           +
                           
                              
                                 w
                                 1
                              
                           
                           =
                           (
                           12
                           ×
                           1
                           )
                           +
                           (
                           12
                           ×
                           1
                           )
                        ), we can achieve a significantly improved performance in terms of high mean sensitivity (95.40%, σ
                        =1.25, t(99)=762.39;
                        p
                        <0.05;
                        CI
                        =[95.1595.65]), specificity (95.37%, σ
                        =0.69, t(99)=1376;
                        p
                        <0.05;
                        CI
                        =[95.2395.51]), and accuracy (95.20%, σ
                        =0.58, t(99)=1637;
                        p
                        <0.05;
                        CI
                        =[95.0895.32]).

We validate our approach by evaluating our system with the female speaker fsew0 of the MOCHA-TIMIT database. The performance of the individual optimum feature set with and without dither is shown in Tables 7 and 8
                        
                        . Using the combined selected features with dither (LA and LP, their δ and δδ for a combined feature set size of 
                           
                              
                                 w
                                 0
                              
                           
                           +
                           
                              
                                 w
                                 1
                              
                           
                           =
                           (
                           17
                           ×
                           1
                           )
                           +
                           (
                           15
                           ×
                           1
                           )
                        ), we can obtain an improved performance in mean sensitivity (86.12%, σ
                        =4.86, t(99)=183.52;
                        p
                        <0.05;
                        CI
                        =[85.6486.60]), specificity (87.51%, σ
                        =4.91, t(99)=156.77;
                        p
                        <0.05;
                        CI
                        =[87.0088.02]), and accuracy (86.14%, σ
                        =4.95, t(99)=257.56;
                        p
                        <0.05;
                        CI
                        =[85.5886.70]).

We can estimate the differential equations directly from the dithered data with little bias and good precision. Adding a dither to a signal is an established technique for improving the accuracy of a subsequent quantizer output (West and Scheets, 2012). This takes advantage of bias reduction while increasing the linear separability as well as the classification accuracy (Maalouf and Trafalis, 2011; Samaniego, 2013). Also, the amplitude of the forcing function increases and the oscillations become random after dithering. This increases the damping factor and gives a more compact feature set as it enhances the sensitivity.

@&#DISCUSSION@&#

This paper presents a new statistical method for detecting bilabial gestures based on principal differential analysis (PDA) and support vector machines. Here, we use a second-order differential equation (DE) to capture the dynamic features in both functional articulatory data and their derivatives. PDA is used to estimate the coefficients in the DE by specifying the DE as the data-driven penalty in the B-spline smoothing. Estimated DE coefficients are then used to find the optimized low-dimensional features and imputed into a LS-SVM with the RBF kernel for binary classification. Promising accuracy, specificity, and sensitivity are achieved with additional improvements using a proposed dithering scheme.

Our work suggests that positional data alone is not sufficient to capture bilabial closures, which may require encoding differences between passive and active motions of the articulators. For instance, the lower lip moves up and down passively for alveolar consonants due to jaw movement, which is the active component, during tongue gestures; this may be differentiated from directed closure of the lips by acceleration or by a forcing function. Future work includes the detection of accidental articulatory gestures using additional tract variables and aligned acoustic features in concert. We are also interested in using context (e.g., triphone context) in identifying broader phonological goals, especially in the identification of tongue-related gestures as in vowels. The extension of this work to pathological speech, in particular to physical disorders such as cerebral palsy (Rudzicz, 2012) is of particular interest. Our current work also includes automatically learning, from data, the couplings between gestures in different tract variables, in accordance with the original theory (Saltzman and Munhall, 1989).

@&#ACKNOWLEDGEMENTS@&#

This research is funded by a startup grant from the Toronto Rehabilitation Institute – University Health Network, a Discovery grant from the Natural Sciences and Engineering Research Council of Canada (RGPIN 435874), and a grant from the Nuance Foundation. The authors also wish to thank the reviewers, whose tremendous feedback have improved this paper immensely.

@&#REFERENCES@&#


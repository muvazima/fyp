@&#MAIN-TITLE@&#Automatic classification of left ventricular wall segments in small animal ultrasound imaging

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A fully automatic processing pipeline is proposed for regional classification of the left ventricular wall in ultrasound images of small animals.


                        
                        
                           
                           The pipeline is implemented using state-of-the-art methods from computer vision and pattern classification.


                        
                        
                           
                           Good performance of the processing pipeline is demonstrated on ultrasound data of living mice before and after artificially induced myocardial infarction.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Classification

Tissue characterization

Shape prior segmentation

Optical flow

Echocardiography

Probabilistic relaxation

@&#ABSTRACT@&#


               
               
                  Multiple statistics show that heart diseases are one of the main causes of mortality in our highly developed societies today. These diseases lead to a change of the physiology of the heart, which gives useful information about characteristic and severity of the defect. A fast and reliable diagnosis is the base for successful therapy. As a first step towards recognition of such heart remodeling processes, this work proposes a fully automatic processing pipeline for regional classification of the left ventricular wall in ultrasound images of small animals. The pipeline is based on state-of-the-art methods from computer vision and pattern classification. The myocardial wall is segmented and its motion is estimated. A feature extraction using the segmented data is realized to automatically classify the image regions into normal and abnormal myocardial tissue. The performance of the proposed pipeline is evaluated and a comparison of common classification algorithms on ultrasound data of living mice before and after artificially induced myocardial infarction is given. It is shown that the results of this work, reaching a maximum accuracy of 91.46%, are an encouraging base for further investigation.
               
            

@&#INTRODUCTION@&#

According to the Framingham Heart Study, arterial hypertension, coronary artery disease, and chronic heart failure are the leading cardiovascular causes of mortality in the industrialized world reaching epidemic extent in the aging societies [11]. Heart failure hereby is caused by a vicious circle in which an original insult leading to mechanical cardiac dysfunction initiates multiple morphological, biochemical, and molecular pathological alterations of myocardial structure and function referred to as cardiac remodeling, which needs extensive clinical follow-up of original cardiac history and post-interventional changes by clinicians [5].

Echocardiography resembles the initial and most frequently used non-invasive diagnostic imaging modality for heart failure patients [14]. The frequent use of non-invasive ultrasound images for clinical decision making in cardio-vascular medicine on the one hand and the lack of highly trained, skilled sonographers under economic pressure in the healthcare system on the other hand demands for more sophisticated echocardiographic examination tools for minimal cardiac changes during the remodeling process [7].

Aiming for facilitated early identification of heart remodeling processes and trying to minimize inter-observer variability when interpreting regional and global heart pathologies, our goal is to develop standardized automated classification algorithms which provide parametric image encoding of left ventricular regional tissue properties.

In the field of ultrasound (US) tissue characterization it is of interest to differentiate between healthy and diseased tissue. Traditionally, the received radio frequency data of ultrasound imaging systems is analyzed. Features which are extracted from this data are used to characterize different classes of tissue, e.g., tumor tissue. Since these features are not directly correlated to certain diseases, classification techniques have to be employed. Tissue classification has already been investigated for different important anatomical subjects, i.e., breast, liver, heart, eyes, and skin. For a comprehensive review of tissue classification methods we refer to [13].

As said before, tissue characterization approaches are typically based on low-level features computed from radio frequency signals or image intensities in ultrasound B-mode images, e.g., the integrated backscatter coefficient or the attenuation coefficient [13]. To the best of our knowledge, the incorporation of higher order features derived from motion estimation or segmentation into regional tissue characterization of the left ventricular wall has not been investigated in the literature so far. For this reason, we propose in this work a novel processing pipeline for automatic classification and regional differentiation of the left ventricular wall, on the basis of features computed with robust segmentation and motion estimation methods from computer vision.

This paper is an extended version of [20] and represents an expansion in technical details, methodology and experimental work. From a methodological point of view the Bayes classifier already has been used in [20]. In this work we extend the methodology by exploring and comparing the potential of four other common classifiers. In addition, we introduce a relaxation postprocessing step to further enhance the classification performance.

The remainder of this paper is organized as follows. In Section 2.1 we give details about our ultrasound image acquisition setting. Section 2.2 describes a novel high-level segmentation method to perform accurate estimation of the left ventricular endocardial border in the presence of heavy noise perturbations. Subsequently, we shortly present a robust method for motion estimation between the end-diastolic and end-systolic phase of myocardial motion based on local statistics in Section 2.3. With the help of these information we are able to compute features for the classification of left ventricular segments introduced in Section 2.4, while for classification we utilize state-of-the-art classifiers as described in Section 2.5. After classification we propose the application of a relaxation process in Section 2.6. We show experimental results of the proposed processing pipeline and a comparison of the different classifiers in Section 3 and evaluate the methodology on real data of living mice. We conclude this work with a discussion in Section 4.

@&#METHODS@&#

In this section we present a fully automatic processing pipeline for regional classification of the left ventricular wall in small animals. The performed small animal experiment serves as a simplified model for human myocardial infarction of the left anterior descending coronary artery. Here, motion abnormalities after operatively induced myocardial infarction show up rapidly within a few minutes and subsequently alter to a paper thin dyskinetic aneurysm within two weeks depending on the size of the infarcted myocardium. The reproducibility of this well described process in mice gives the opportunity of scanning multiple equally old infarctions in parallel for bigger scan numbers. Evidently, this is not applicable for human patients. Furthermore, remodeling processes of the human heart can take between 90 days to 1 year which make them even harder to study. However, the cascade of wall motion abnormalities from hypokinesia to akinesia to dyskinesia proceeds equally in both models. Thus, observed alteration during these processes is transferable but develops much faster in the murine model of myocardial damage.

In the following we introduce each step of the proposed processing pipeline sequentially, starting from the initial data acquisition, continuing with segmentation, motion estimation, and the resulting feature extraction, and completing the pipeline with the classification and relaxation of the murine heart segments.

As training and test data we acquired 2D B-mode image sequences of the murine left ventricle in long axes (LAX) view by using a Philips/ATL HDI 5000 as ultrasound imaging platform. We imaged 14 wildtype laboratory mice in fully healthy state (d0), one day after surgically inducing myocardial infarction (d1), and again 14 days later (d14). For each image sequence echocardiographic experts selected two images corresponding to the end-diastolic and end-systolic phase of the myocardial cycle. Fig. 1
                        (a) and (b) illustrates these two phases in images of mice in healthy state (d0), respectively.

Segmentation is a fundamental task in ultrasound image processing. A huge number of US segmentation methods are known in the literature. Examples are [1,6,9] and an overview can be found in [12,13]. Some of these methods are limited in various aspects. For instance, the nature of dynamic programming as described in [6] only allows to detect contours between image boundaries (or more generally star-shaped contours in an extended algorithm variant). In clustering-based segmentation as exemplified by [9] it is not easy to integrate a priori knowledge like shape priors as needed in our work.

Level set based methods have become popular for medical image segmentation. Most of them, however, are not suitable for ultrasound images [22,24,26]. In this work we apply the region-based level set segmentation method recently proposed in [18]. The gain of this method is its robustness under the typical multiplicative noise of medical ultrasound imaging and the avoidance of many unwanted local minima. Many low-level segmentation techniques suffer from the characteristics of medical ultrasound images like speckle noise, scattering artifacts, and shadowing effects. Thus, one recent trend is towards integration of high-level information. In this work we utilize a priori knowledge about the shape of the left ventricular wall. We added this shape prior to the region-based level set segmentation method [18], see [17] for details. In the following we briefly introduce our overall segmentation approach.

Given the image domain 
                           Ω
                           ⊂
                           
                              
                                 
                                    ℝ
                                 
                              
                              2
                           
                         for an image 
                           f
                           :
                           Ω
                           →
                           
                              
                                 ℝ
                              
                           
                        , we denote with 
                           Φ
                           :
                           Ω
                           →
                           
                              
                                 ℝ
                              
                           
                         a level set function which implicitly induces a segmentation contour. Then, segmentation is performed by minimizing the energy functional
                           
                              (1)
                              
                                 E
                                 (
                                 Φ
                                 )
                                    
                                 =
                                    
                                 
                                    1
                                    2
                                 
                                 
                                 
                                    ∫
                                    Ω
                                 
                                 
                                 sgn
                                 (
                                 Φ
                                 )
                                 
                                 (
                                 f
                                 −
                                 
                                    t
                                    O
                                 
                                 )
                                 d
                                 
                                    
                                       x
                                       →
                                    
                                 
                                    
                                 +
                                    
                                 β
                                 
                                 
                                    ∫
                                    Ω
                                 
                                 
                                    δ
                                    0
                                 
                                 (
                                 Φ
                                 )
                                 
                                 |
                                 ∇
                                 Φ
                                 |
                                 d
                                 
                                    
                                       x
                                       →
                                    
                                 
                                    
                                 +
                                    
                                 γ
                                 
                                    R
                                    sh
                                 
                                 (
                                 H
                                 (
                                 Φ
                                 )
                                 )
                              
                           
                        where H is the Heavyside function, δ
                        0 is the δ-Dirac function in 0 and sgn stands for the signum function. The term t
                        
                           O
                         denotes an optimal intensity threshold, e.g., determined by discriminant analysis [18]. The attached shape prior term R
                        
                           sh
                         is realized as Gaussian mixture model, i.e.,
                           
                              (2)
                              
                                 
                                    R
                                    sh
                                 
                                 (
                                 H
                                 (
                                 Φ
                                 )
                                 )
                                 =
                                 −
                                 log
                                 
                                    
                                       
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          exp
                                          
                                             
                                                
                                                   −
                                                   
                                                   
                                                      
                                                         |
                                                         λ
                                                         (
                                                         H
                                                         (
                                                         Φ
                                                         )
                                                         )
                                                         
                                                         −
                                                         
                                                         λ
                                                         (
                                                         H
                                                         (
                                                         
                                                            Φ
                                                            k
                                                            ref
                                                         
                                                         )
                                                         )
                                                         
                                                            |
                                                            2
                                                         
                                                      
                                                      
                                                         2
                                                         
                                                            σ
                                                            2
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        and the trained shapes are given by 
                           
                              Φ
                              k
                              ref
                           
                           ,
                           k
                           =
                           1
                           ,
                           …
                           ,
                           n
                        . Furthermore, λ denotes the Legendre moment representation of a shape. We use a gradient descent method to minimize (1). Note that it is beneficial to minimize the shape prior energy in the space of computed Legendre moments as described in [23].


                        Fig. 1 shows exemplary segmentation results using the model in (1) for two different mice. In Fig. 1(a) and (b) one can observe the automatically delineated contour of the left ventricular lumen in the end-diastolic and end-systolic phase for a healthy heart (d0), respectively. Subsequently, we show the contours of end-diastolic and end-systolic phase of a mouse heart after myocardial infarction (d14) in Fig. 1(c) and (d), respectively. It can clearly be seen that after surgery the detected contour changes only little between the two phases, thus suggesting severe heart damage.

Motion analysis is an essential part of diagnostics in modern echocardiography [2]. As mentioned in Section 1, most heart diseases are accompanied with functional adaption of the myocardium and hence lead to changes in the motion of the myocardial cycle.

Since the focus in this work is on acute myocardial infarction we propose to use only two ultrasound images to estimate motion during the contraction of the heart: one image representing the end-diastolic phase of the myocardial cycle and the other image indicating the end-systolic phase (cf. Fig. 2
                        ). Note that for other myocardial diseases or identification of heart remodeling processes it might be advisable to use more images to capture the full dynamics of the myocardial cycle.

To obtain a dense vector field representing the myocardial motion we use an adapted optical flow technique. Instead of applying traditional optical flow methods known from computer vision, which are based on the fundamental assumption of intensity constancy, and which are more or less sensitive to noise, we use a recently proposed robust method that is designed to deal with the multiplicative speckle noise of US imaging. In [19] we introduced a histogram constancy constraint, which represents a generalization of the former intensity constraint based on local statistics. This novel constraint has been incorporated into a variational optical flow model given by,
                           
                              (3)
                              
                                 E
                                 (
                                 u
                                 ,
                                 v
                                 )
                                 =
                                 
                                    ∫
                                    Ω
                                 
                                 |
                                 H
                                 (
                                 x
                                 +
                                 u
                                 ,
                                 y
                                 +
                                 v
                                 ,
                                 t
                                 +
                                 1
                                 )
                                 
                                 −
                                 
                                 H
                                 (
                                 x
                                 ,
                                 y
                                 ,
                                 t
                                 )
                                 
                                    |
                                    2
                                 
                                 +
                                 α
                                 (
                                 |
                                 ∇
                                 u
                                 
                                    |
                                    2
                                 
                                 +
                                 |
                                 ∇
                                 v
                                 
                                    |
                                    2
                                 
                                 )
                                 d
                                 x
                                 d
                                 y
                                 .
                              
                           
                        
                     

Here, H(x, y) represents the local cumulative histogram in a small neighborhood around the pixel (x, y)∈Ω. The variable α is a regularization parameter controlling the smoothness of the resulting optical flow field. We compared in [19] the proposed histogram-based optical flow method with three state-of-the-art methods and the popular Horn–Schunck optical flow method on synthetic as well as real patient data. We observed an overall increase in motion estimation accuracy between 20 and 68% with respect to the average endpoint error measure during our experiments.


                        Fig. 2 shows two exemplary results of motion estimation using the model in (3) for one mouse in healthy state (d0) and two weeks after artificially induced myocardial infarction (d14). The yellow lines illustrate the estimated optical flow vectors for the pixels of the segmentation contour (cf. Section 2.2), which is indicated as green closed contour. As can be clearly seen in Fig. 2(a), all regions of the healthy left ventricle contract evenly to its center. In contrast, Fig. 2(b) shows the results of motion estimation for the same heart after acute myocardial infarction. One can observe that many regions of the left ventricle show only little or no motion at all. These regions represent scarred tissue after acute myocardial infarction and thus are not fully functional anymore. This phenomenon can also be observed in Fig. 1(c) and (d) for the computed segmentation contours.

As the major source of features for the classification (cf. Section 2.5) we propose motion information, which is a strong indicator for abnormal myocardial tissue. Normal and abnormal tissues might differ in their intensity of echo. Hence, to examine if the intensities of the specific regions in the ultrasound B-mode image have an influence on the classification result, we also compute statistical intensity features on this data. In addition, we incorporate the ratio of the global left ventricular volume between the end-diastolic and end-systolic phase to quantify not only the motion characteristics but also the change of volume. Obviously, it would be possible to directly use the optical flow field or the image intensities as features for classification. However, to achieve a higher robustness and in order to save processing costs we propose to compute representative features which statistically represent the latter ones, e.g., the regional mean vector.

As we will describe in next Section 2.5 the found left ventricular wall is divided automatically into several segments. For each segment, we compute four different features from the vector field given by the optical flow motion estimation. Two of these features (features 1–2) describe the velocity of the motion by computing the average and variance of the velocity in that segment. The other two shall characterize the influence of the orientation. On the one hand we compute the motion orientation in relation to the direction from the segment to the center of the left ventricular wall (feature 3), and on the other hand we measure the velocity component in direction to the center of the segment (feature 6). Additionally, we compute the average and the variance of the image intensities in each segment. As a global segment-independent feature we calculate the ratio of volume between end-systolic and end-diastolic phase. Note that these volumes are used in practice to determine the ejection fraction and therefore are common measurements for quantifying left ventricular function [14].

A detailed formulation of the features is given in the following. To simplify the notation the variables and equations are given for a single segment, where n represents the number of pixels. The motion vectors of the pixels are given by 
                           
                              
                                 v
                                 →
                              
                              k
                           
                           ,
                              
                           k
                           =
                           1
                           ,
                           …
                           ,
                           n
                        , with the velocity 
                           
                              v
                              k
                           
                              
                           (
                           
                              v
                              k
                           
                           =
                           |
                           |
                           
                              
                                 v
                                 →
                              
                              k
                           
                           |
                           |
                           )
                           ,
                              
                           k
                           =
                           1
                           ,
                           …
                           ,
                           n
                        , and the pixel intensity I
                        
                           k
                        , k
                        =1, …, n.


                        
                           
                              1.
                              Average velocity 
                                    v
                                  of the motion vectors
                                    
                                       (4)
                                       
                                          
                                             v
                                             ¯
                                          
                                          =
                                          
                                             1
                                             n
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             v
                                             k
                                          
                                       
                                    
                                 
                              

Variance of lengths 
                                    
                                       σ
                                       v
                                       2
                                    
                                  of the motion vectors
                                    
                                       (5)
                                       
                                          
                                             σ
                                             v
                                             2
                                          
                                          =
                                          
                                             1
                                             
                                                n
                                                −
                                                1
                                             
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                (
                                                
                                                   v
                                                   k
                                                
                                                −
                                                
                                                   v
                                                   ¯
                                                
                                                )
                                             
                                             2
                                          
                                       
                                    
                                 
                              

Angle α between the mean motion vector 
                                    
                                       v
                                       →
                                    
                                  and the directional vector 
                                    
                                       c
                                       →
                                    
                                  from the center of the segment to the center of the entire segmentation of the left ventricular lumen (cf. Fig. 3
                                 ).
                                    
                                       (6)
                                       
                                          α
                                          =
                                          
                                             cos
                                             
                                                −
                                                1
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               v
                                                               →
                                                            
                                                         
                                                         ·
                                                         
                                                            c
                                                            →
                                                         
                                                      
                                                      
                                                         
                                                            |
                                                            |
                                                            
                                                               
                                                                  v
                                                                  →
                                                               
                                                            
                                                            |
                                                            |
                                                         
                                                         ·
                                                         |
                                                         |
                                                         
                                                            
                                                               c
                                                               →
                                                            
                                                         
                                                         |
                                                         |
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Mean intensity 
                                    
                                       I
                                       ¯
                                    
                                 
                                 
                                    
                                       (7)
                                       
                                          
                                             I
                                             ¯
                                          
                                          =
                                          
                                             1
                                             n
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             I
                                             k
                                          
                                       
                                    
                                 
                              

Variance of intensities 
                                    
                                       σ
                                       I
                                       2
                                    
                                 
                                 
                                    
                                       (8)
                                       
                                          
                                             σ
                                             I
                                             2
                                          
                                          =
                                          
                                             1
                                             
                                                n
                                                −
                                                1
                                             
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                (
                                                
                                                   I
                                                   k
                                                
                                                −
                                                
                                                   I
                                                   ¯
                                                
                                                )
                                             
                                             2
                                          
                                       
                                    
                                 
                              

Average velocity 
                                    
                                       
                                          v
                                          ¯
                                       
                                       proj
                                    
                                  of vectors projected to the center of the segment
                                    
                                       (9)
                                       
                                          
                                             
                                                v
                                                ¯
                                             
                                             proj
                                          
                                          =
                                          
                                             1
                                             n
                                          
                                          
                                             ∑
                                             
                                                k
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                
                                                   cos
                                                   (
                                                   
                                                      β
                                                      k
                                                   
                                                   )
                                                   
                                                      v
                                                      k
                                                   
                                                
                                             
                                          
                                       
                                    
                                 with β
                                 
                                    k
                                  as the angle between the motion vector 
                                    
                                       
                                          v
                                          →
                                       
                                       k
                                    
                                  and the directional vector from the location of the motion vector to the center of the segment.

Ratio of volume V at end-systolic ESV and end-diastolic EDV phase
                                    
                                       (10)
                                       
                                          V
                                          =
                                          
                                             ESV
                                             EDV
                                          
                                       
                                    
                                 
                              

In summary, features 1–6 are evaluated for each local segment independently, whereas the last feature is of global nature. Features 1–3 and 6 are calculated from the motion vector field between end-systolic and end-diastolic phase, whereas features 4 and 5 represent the ultrasound intensities and feature 7 the left ventricular volume ratio between end-systolic and end-diastolic phase.

In one of the last steps of the proposed processing pipeline we use the obtained high-level features to perform an automatic classification of myocardial segments to distinguish between normal and abnormal heart tissue.

To perform regional classification of the left ventricular wall we propose to partition the automatically delineated endocardial border into several segments such that each segment corresponds to a separate classifier to be trained. This approach mimics methods for the assessment of cardiac function in practice. The American Heart Association (AHA) recommends a model [4] of dividing the heart into myocardial segments according to their function and coronary blood supply. The partitioning is realized by dividing the heart into three equal slices perpendicular to the long axis of the heart. According to that model in long axis view we would divide the shown part of the heart into seven segments (three myocardial segments on each side of the heart plus the apex). For technical reasons our approach currently divides the heart not perpendicular but in equal sectors from the center. To obtain a sufficient accuracy we propose as a starting point 18 segments, a multiple of the recommended count of segments of the AHA. In Section 3 we will vary the number of segments to see the influence on the classification results.

In this work we use and compare a number of standard classifiers, starting with naive Bayes due to its simplicity. We tested two variants of Bayes classification: standard normal Bayes and Bayes with kernel density estimation (KDE). The normal Bayes approach assumes a normal distribution as probability density function, whereas KDE is a method to perform a more accurate estimation of the probability density function p by a finite sum of kernel functions [15], i.e.,


                        
                           
                              (11)
                              
                                 p
                                 (
                                 x
                                 )
                                 =
                                 
                                    1
                                    
                                       n
                                       σ
                                    
                                 
                                 
                                    ∑
                                    
                                       k
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    K
                                    
                                       
                                          
                                             
                                                
                                                   x
                                                   −
                                                   
                                                      x
                                                      k
                                                   
                                                
                                                σ
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

One can interpret the estimated density function p as a continuous histogram. To obtain continuity from discrete data the points in between are estimated by applying a symmetric and continuous smoothing kernel 
                           K
                           :
                           
                              
                                 
                                    ℝ
                                 
                              
                              d
                           
                           ×
                           
                              
                                 
                                    ℝ
                                 
                              
                              d
                           
                           →
                           
                              
                                 ℝ
                              
                           
                        , which integrates to one and for which σ is the respective bandwidth. As kernel function K we apply the Gaussian kernel,
                           
                              (12)
                              
                                 K
                                 
                                    
                                       
                                          
                                             
                                                x
                                                −
                                                
                                                   x
                                                   k
                                                
                                             
                                             σ
                                          
                                       
                                    
                                 
                                 =
                                 
                                    1
                                    
                                       
                                          
                                             2
                                             π
                                          
                                       
                                       σ
                                    
                                 
                                 
                                    e
                                    
                                       −
                                       
                                          1
                                          2
                                       
                                       
                                          
                                             (
                                             
                                                x
                                                −
                                                
                                                   x
                                                   k
                                                
                                             
                                             /
                                             σ
                                             )
                                          
                                          2
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Note that by the choice of K in (12) the KDE in (11) becomes the well-known Gaussian mixture model. We use an adaptive method to estimate σ on the base of the given data (cf. [15] for technical details).

Like the two Bayes approaches, the classifiers LDA, decision tree and k-NN can incorporate prior knowledge, which is amongst others evaluated empirically from the training data or is set equally (uniform) to each class. Uniform probability means in our specific case of two classes that normal segments appear as likely as abnormal segments, so that the probability is 0.5 for normal and 0.5 for abnormal. Concerning the anatomic structure of the heart there are specific segments which have a higher potential to be corrupted by an infarction than others, hence have a higher prior probability to be abnormal. Considering this, it makes sense to incorporate empirical prior knowledge of the training data. Results which underline this observation are shown in Section 3 by comparing Tables 2 and 4.

Prior knowledge for LDA is incorporated similar to the Bayesian approaches through the Bayes’ theorem. Decision tree on the other hand uses prior knowledge at each node of the tree to support the decision, while k-NN includes prior probabilities for weighting the nearest neighbors according to their class membership.

For each classifier we did preceding parameter tests where we maximized the results of the specific classification, e.g., for k-NN, where we found that the application of 13 neighbors combined with Euclidean distance measure works best in this setting. Parameterization of SVM is realized by applying a Gaussian kernel to determine a non-linear class border (cf. [8] for technical details).

The aim of the relaxation is to correct classification results by considering class probabilities of the neighboring segments, i.e., each of the segment classification results shall get a score which describes how likely the segment is either normal or abnormal. This score (or in further explanations the posterior probability) is used for the examination of the influence of neighboring segments. For instance, a segment is classified as abnormal but with a low certainty. The two neighbors, which might be normal with a high likelihood, can in such cases help to correct that result. In other words, if the two neighbors are very likely normal it is more probable that the actual segment is normal, too. In practice, this implies first of all the need to determine the posterior probabilities, thus the likelihood of the correctness of the classification result.

In the case of the Bayes and the LDA classifiers the posterior probability is already evaluated to perform the classification (cf. Section 2.5). The posteriors of k-NN, SVM, and decision tree are also given by the architectures of the classifiers. The node structure of the decision tree for example obtains a posterior probability for each node. This node probability is determined by evaluating how likely the samples of the training dataset pass the specific node. Subsequently, the posterior of a classification result of a segment is then the posterior of the node this result was classified by. The posterior of k-NN is given by the proportion of neighbors which are normal or abnormal and the score of SVM is given by the distance to the hyperplane.

Our relaxation algorithm follows a general probabilistic relaxation approach described in [16]. Consider a number of segments S
                        
                           i
                        , i
                        =1, …, n, and a finite set of labels Ω={ω
                        1, ω
                        2, …, ω
                        
                           l
                        } for each segment. Every segment S
                        
                           i
                         shall have a number of neighboring segments S
                        
                           ij
                        , j
                        =1, …, m. The relaxation algorithm shall iterate until the subsequent Eq. (13) converges (note that index s indicates the sth step of the iteration):


                        
                           
                              (13)
                              
                                 
                                    P
                                    i
                                    
                                       (
                                       s
                                       +
                                       1
                                       )
                                    
                                 
                                 (
                                 ω
                                 )
                                 =
                                 
                                    
                                       
                                          P
                                          i
                                          
                                             (
                                             s
                                             )
                                          
                                       
                                       (
                                       ω
                                       )
                                       
                                          Q
                                          i
                                          
                                             (
                                             s
                                             )
                                          
                                       
                                       (
                                       ω
                                       )
                                    
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          l
                                       
                                       
                                          P
                                          i
                                          
                                             (
                                             s
                                             )
                                          
                                       
                                       (
                                       
                                          ω
                                          k
                                       
                                       )
                                       
                                          Q
                                          i
                                          
                                             (
                                             s
                                             )
                                          
                                       
                                       (
                                       
                                          ω
                                          k
                                       
                                       )
                                    
                                 
                                 ,
                              
                           
                        with P
                        
                           i
                         as the probability of a specific label ω of segment S
                        
                           i
                        , for which 
                           
                              ∑
                              
                                 k
                                 =
                                 1
                              
                              l
                           
                           
                              P
                              i
                           
                           (
                           
                              ω
                              k
                           
                           )
                           =
                           1
                         and P
                        
                           i
                        (ω
                        
                           k
                        )>0. The correction value Q
                        
                           i
                         is evaluated as follows:


                        
                           
                              (14)
                              
                                 
                                    Q
                                    i
                                    
                                       (
                                       s
                                       )
                                    
                                 
                                 (
                                 ω
                                 )
                                 =
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    m
                                 
                                 
                                    c
                                    ij
                                 
                                 
                                    ∑
                                    
                                       k
                                       =
                                       1
                                    
                                    l
                                 
                                 r
                                 (
                                 ω
                                 ,
                                 
                                    ω
                                    k
                                 
                                 )
                                 
                                    P
                                    ij
                                    
                                       (
                                       s
                                       )
                                    
                                 
                                 (
                                 
                                    ω
                                    k
                                 
                                 )
                                 .
                              
                           
                        
                     

The correction Q
                        
                           i
                         implies an interaction between the neighboring segments S
                        
                           i
                         and S
                        
                           ij
                        . This interaction is characterized by the compatibility function r which denotes the influence of the probability of the neighbor P
                        
                           ij
                         according to a specific label ω
                        
                           k
                        . The coefficient c
                        
                           ij
                         is a weighting parameter and represents the strength of the interaction between segment S
                        
                           i
                         and S
                        
                           ij
                        . In the special case of this work, Ω={normal, abnormal} and every segment S
                        
                           i
                         has the two neighbors S
                        
                           i1 and S
                        
                           i2. The compatibility function r is designed such that if the labels of the neighbors are equal, the probability increases, otherwise it stays the same.

@&#RESULTS@&#

In this section we summarize our experimental results of the proposed processing pipeline. The normal and abnormal regions of the left ventricular wall were manually marked by an echocardiographic expert for all 42 acquired datasets described in Section 2.1. Using this ground truth data we generated binary masks (0=
                     normal, 1=
                     abnormal) for the evaluation of the proposed classification methods in Section 2.5. We automatically divide the segmented endocardial border equally into a specific number of segments. The ground truth is then generated by determining whether the segment is marked as abnormal or not. Due to the automatic division, the boundary of the automatic generated segment is typically not the boundary of the manually marked region. A segment is thus covered by normal as well as abnormal marked labels. In this case the segment will be identified as abnormal if more than half of the segment is marked as abnormal by the expert, otherwise it will be identified as normal. This instance may generate an error in the ground truth itself which can be reduced by choosing a higher amount of segments.

In our preceding work in [20] we did a closer look at the different features and their performance by using Bayes classification. In particular, we compared each single feature with a combination of all seven features and some of their subsets. We found out that the feature subsets worked better than a classification on the basis of all seven features. Thus, at this point we just selected reasonable combinations (subsets) of three features to set focus on the comparison of the classifiers. The shown selection shall underline the observations of our former work and compare these results with the broader number of classifiers. The selection of feature combinations was done primarily by combining the different categories of features. To remember, in Section 2.4 we divided the features into three major groups. The motion features (1, 2, 3, 6), the intensity features (4, 5), and the volume feature (7). Thus, the feature selection here consists of combining these three categories. Additionally, we combined features 3, 5, and 6 as an example of a weak combination to show how important a good feature combination is.

For testing we chose the leave-one-out strategy due to the small amount of available ground truth data. Table 1
                      indicates a comparison of the mentioned feature combinations by using the various types of classifiers. The comparison of the classifiers obviously shows that the two Bayes approaches deliver the best results with 89.03% as the best result of normal Bayes and 90.28% as the best result of Bayes with KDE. These evaluations are followed by LDA and SVM with 88.06% and decision tree with 87.22%. In last place the k-NN classifier showed the lowest performance with 85.42% as best evaluation result.

It is notable that the best results over all classifiers are found when applying the feature combinations 1, 5, 7 or 2, 4, 7. These are combinations of the features describing the velocity of motion (1–2), the intensity (4–5), and the volume (7). The feature combination 3, 6, 7 in comparison to the former ones has a slightly inferior classification accuracy for all classifiers except decision tree, what leads to the assumption that the velocity is a slightly stronger indicator than the direction of the motion of the myocardial wall. This assumption is underlined by consulting the results of our preceding work [20], where we found that the best result could be obtained by combining features 2 and 7.

In our former work we also investigated that feature 3 and 6, as features representing the direction of motion, seem to be a little weaker than the velocity features. Likewise, the image intensities did not seem to play an important role for the identification of abnormal tissue in the proposed setting. This is shown by comparing the combination 3, 6, 7, where no intensity feature was used, to the former two combinations in Table 1.

The last feature combination presented in the table contains a combination of motion direction and intensity features. As mentioned before, the features 3 and 6 do not appear to be as strong indicators as the velocity features. However, more evident seems to be the absence of the volume feature 7. The feature combination 3, 5, 6 is clearly the worst choice leading to classification rates of about 83–84%. This observation is consistent with all the applied classifiers.


                     Table 2
                      illustrates the behavior of the classifiers dependent on the number of segments. Additionally, it compares the results before and after relaxation and shows the statistical significance of their difference by applying a paired two-tailed t-test. The table can be interpreted in two ways. First, the table shows classification rates for a variation of 17–26 segments and indicates if the number of segments has an influence on the rates before and after relaxation. Secondly, it is of interest to compare the classification results before and after relaxation and to question if the relaxation has a positive effect on the performance in general.

Examining the first point, the table at first sight indicates no clear taxonomy of the influence of the number of segments on the classification result. The best measure of the evaluation of 91.46% after relaxation can be observed by using 24 segments and is followed by 91.39% evaluated with 18 segments and 91.18% with 17 segments. Moreover, this behavior can be observed throughout the measures of all the classifiers. Having a closer look at the evaluations before relaxation, the performance of the results overall becomes slightly inferior if the number of segments increases from 17 to 26. The relaxation in turn seems to be able to balance this behavior so that in total comparable results are reached.

To summarize, when choosing a proper number of segments, it should be taken into account that too few segments can lead to a higher error in the ground truth. Even though this has no negative effect in this test setup, in future work this error should be quantitatively measured to see its impact on the accuracy. Furthermore, it should be noted that, the more segments we define, the more segments seem to be in an ambiguous state where the class membership is not clear so that a relaxation is more successful. Beside this, when choosing a reasonable number of segments it should be taken into account that a higher number of segments leads to an increase of processing costs. Thus, at least choosing a proper number of segments are a trade-off between sufficient accuracy and low processing costs.

It has been shown that the influence of selecting a specific number of segments has no evident effect on the final results. This could be explained through the application of relaxation, which seems to have a compensational influence on the results. Looking at the improvements after relaxation in detail, in almost all cases except SVM with 21 segments the rate rises. Nevertheless the table shows a division of the results into two parts. The Bayes approaches and LDA after relaxation show comparable results around 90% and more, while decision tree, k-NN, and SVM vary between 83.75% and 88.56%, a gap of 4.81%. Table 3
                      summarizes a significance measure of the results in Table 2 based on a paired two-tailed t-test applied to the differences between pairs of classifiers after relaxation. The table consolidated the finding above and shows that the differences of the results after relaxation between normal Bayes, Bayes KDE, and LDA are by the majority not significant. The same can be observed when comparing decision tree, k-NN and SVM. This gap might be explainable through the posterior probabilities used for relaxation, which are similar or equal for Bayes and LDA, whereas decision tree, k-NN, and SVM use different methods to determine their scores (cf. Section 2.6).

Comparing the improvement after relaxation of the single classifiers, the increase of accuracy is very considerable looking at normal Bayes. With an increase of about 2–3% after relaxation, normal Bayes holds with 91.39% the best evaluation result when applying 18 segments. By using LDA the relaxation has already less effect than for normal Bayes, but applying Bayes KDE the improvement is very low, in average about 0.5%. In the case of KDE the rates in comparison with normal Bayes or LDA are good anyhow so that the space for improvement might not be as high. On the other hand, the increase of the classification result with SVM after relaxation for all segments also is not very high and around 0.6%. Even though the classification results before relaxation in comparison are not so high, the rates after relaxation do not clearly increase, e.g., 87.64% (SVM with 18 segments) to 88.06%. A similar behavior can be observed for decision tree and k-NN. All above shown results were computed by the application of empirical prior knowledge to all classifiers except SVM (where priors are not incorporated). Table 4
                      indicates accuracy rates when using uniform priors in the specific classifiers. As stated in Section 2.5, the rates show that the application of empirical priors improves the accuracy compared with uniform priors.

The relaxation is designed such that isolated segments with a misclassified result can be corrected by considering the two neighboring segments. This effect is illustrated in Fig. 4
                     . The figure shows the results of the proposed processing pipeline in a parametric map indicating the classified tissue states in different segments of the left ventricular wall before and after relaxation. By comparing, e.g. images 4(a) and (d) one can see several erroneously classified normal segments in 4(a), which are corrected after relaxation in 4(d). Another effect of relaxation can be observed by looking at image 4(b) and (e). Misclassified segments in between are corrected, while segments at the boundary of abnormal to normal stay erroneously classified. This can also be examined in the image pairs 4(i) and (l). When the two neighbors of a misclassified segment belong to opposed classes it is imaginable that the relaxation is not able to correct this properly.

Probably also observable in those border segments might be the ground truth error mentioned in Section 2.5. If some segments at the boundary cannot be labeled clearly as abnormal or not, these segments might have a higher tendency to be misclassified.

Summarizing the results, we found that the estimated motion vectors are strong indicators of abnormal left ventricular segments. However, the vector length, representing the velocity, is slightly more significant for a good classification than the actual motion direction. Finally, as a quite simple but apparently strong feature the ratio of left ventricular volume between end-systolic and end-diastolic phase can be observed as a global indicator for the presence of heart diseases, which is consistent with findings in cardiology [2].

While the choice of a proper number of segments seems to be a trade-off between better accuracy against processing costs, the relaxation is a good possibility to correct the results in consideration that abnormal or normal segments are in most of the cases coherent.

Misclassifications which are not corrected by the relaxation are particularly prominent at the boundary segments where we found that already in ground truth data the segments at the boundary cannot always be clearly assigned to a specific class and thus probably lead to a higher rate of erroneous classification.

To close the circle and question how these results can provide information about application on humans, it is to be mentioned that the requirements for this task are difficult to predict. Normal human myocardial infarctions can develop in the three coronary territories of the heart: for the right coronary artery in the inferior heart wall, for the left anterior descending coronary artery in the anterior wall, and for the ramus circumflexus in the lateral wall. They can occur coincidently at the same time or subsequently at different times and thus they may differ in their respective process age. In general, a differentiation of these infarctions is a very hard task for a medical sonographer and it has not yet been tested how the proposed processing pipeline performs under such real life conditions in humans which show with more heterogeneous temporal and spatial wall motion abnormalities. Hence, this pipeline can be seen as a first step in that direction, although it is to be interpreted carefully especially when it comes to the application in humans. Certainly, the task of differentiating infarctions will necessitate several enhancements in future, but it is most likely that through an integration of the full motion dynamics of the cardiac cycle one is able to go a step further into that direction.

@&#CONCLUSION@&#

Pattern classification is an important task in biomedical applications [3,10,21,25]. In this work we proposed a processing pipeline for segment classification of the left ventricular wall based on high-level information derived from segmentation and motion estimation. As a first step we used a few relatively simple features as basis for a classification. In particular, the volume feature based on the ratio of left ventricular volumes at end-systolic and end-diastolic phase seems to play an important role for the automatic detection of heart diseases. The application of a relaxation algorithm further improves our results, where we obtain a maximum classification rate of 91.46%.

A comparison of all classifiers showed that the application of the simple Bayes classification seems to work best in this setup. Even though there is no classification method which goes completely out of line, there is a gap between the Bayes methods and LDA on the one hand and decision tree, k-NN, and SVM on the other hand. The reason for this observation and whether this might be due to parametrization remains an open question. Furthermore, in future work it is desirable to combine different classifiers using ensemble techniques.

Very evident in future will be the expansion of the data basis. Due to the application of empirical priors it is important to rely on data samples close to the real world. On the base of expanded data we plan the extension of our methodology to all images of the myocardial cycle in order to capture the full motion dynamics and hence deduce more specific features for classification in heart remodeling processes. Finally, it would be interesting to incorporate traditional features from tissue characterization when radio frequency data is available.

@&#ACKNOWLEDGMENTS@&#

We gratefully thank Michael Fieseler and Fabian Gigengack for fruitful discussions and shared ideas on this topic. Furthermore, we would like to thank Richard Holtmeier for the acquisition of the small animal US B-mode images and the provided manual segmentations. This study was supported by the Deutsche Forschungsgemeinschaft (DFG), SFB 656 MoBil, Münster, Germany (project B3, C3).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Brain activity detection by estimating the signal-to-noise ratio of fMRI time series using dynamic linear models

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a new interpretable model-based approach to detect brain activity in fMRI.


                        
                        
                           
                           The model makes no assumptions about the stimulation paradigm.


                        
                        
                           
                           We demonstrate the ability of the model to analyse resting-state fMRI studies.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Bayesian analysis

Dynamic linear models

fMRI

Resting-state

@&#ABSTRACT@&#


               
               
                  This work shows an example of the application of Bayesian dynamic linear models in fMRI analysis. Estimating the error variances of such a model, we are able to obtain samples from the posterior distribution of the signal-to-noise ratio for each voxel, which is used as a criterion for the detection of brain activity. The benefits of this approach are: (i) the reduced number of parameters, (ii) the model makes no assumptions about the stimulation paradigm, (iii) an interpretable model based approach, and (iv) flexibility. The performance of the proposed method is shown by simulations and further results are presented on the application of the model for the analysis of a real fMRI data set, in order to illustrate some practical issues and to compare with previously proposed techniques. The results obtained demonstrate the ability of the model to detect brain activity, even when the stimulus paradigm is unknown, constituting an alternative to data driven approaches when dealing with resting-state fMRI.
               
            

@&#INTRODUCTION@&#

During the last few decades, functional Magnetic Resonance Imaging (fMRI) has contributed to the development of a more profound knowledge of brain functioning in both neuroscience and disease by providing a measure of brain activation, observing hemodynamic response. This paper describes a new approach for determining which parts of the brain show activation in response to an endogenous or exogenous stimulus in blood oxygen level dependent (BOLD) contrast [26] fMRI data.

A fMRI study, which can be interpreted as a three dimensional movie of the brain, results in a vast amount of noisy data with a complicated spatiotemporal correlation structure. In BOLD fMRI statistical analysis, there are two main approaches: data driven and model driven. The former reduces the whole spatiotemporal data set into certain multivariate components with similar characteristics. By contrast, the latter fits a model to the observed data, taking into account the prior information provided by neuroscientific rationale or previous experiments. The two approaches are therefore fundamentally different in perspective and assumptions [20].

Data driven procedures include Independent Component Analysis (ICA) [24,1], principal component analysis [9] and cluster analysis [14,4], among others. These techniques attempt to characterise reliable patterns in the data, and relate those patterns to physiological activity post hoc. As stated in Lindquist [21], while these methods provide a fair amount of flexibility, not containing any model information, they capture regularities whatever the source, and, therefore, they are highly susceptible to noise and components are often dominated by artifacts.

Regarding model driven literature, inference about brain activity in fMRI data is commonly addressed through the General Linear Model (GLM) analysis, introduced by Friston et al. [10], in which a linear dependency of the BOLD signal and the hemodynamic response function (HRF) is assumed. Generally, the stimulus pattern is fit simply as a box-shaped wave, which is then convolved with an HRF template. Several kernels have been considered for the HRF template, including Poisson [11], Gaussian [10], and gamma [19,2]. The convolution approach is attractive for its simplicity. However, it imposes restrictions to the model, e.g. it forces antisymmetry and monotonicity on each half cycle, as mentioned by Crellin, Hastie and Johnstone in the published discussions of Lange and Zeger [19]. As stated by Lindquist and Wager [22], among others, using the canonical HRF in the general linear model can be a very restrictive assumption, commonly making model driven approaches unable to analyse studies in which the subject neither undergoes a controlled stimulation nor performs a precisely defined task, as it is the case of resting-state studies in physiology and pathology.

Here we propose a less restrictive model driven approach, which makes no assumptions on the shape of the HRF or the stimulation paradigm presented during the experiment. In fMRI time series analysis, an increase of signal followed by a slow decay to baseline (or inactivity level in the case of resting-state) is generally expected in the active regions of the brain. Hence, it is reasonable to assume that the SNR, defined as the ratio of the signal variance to the variance of the system noise, is larger for active than for non-active voxels, due to the signal fluctuations observed in the brain [8,3]. The estimation of the SNR for each voxel is therefore a key factor in the detection of brain activity, for which we propose the employment of dynamic linear models (DLM), under a Bayesian paradigm.

Taking into account the quantity of data and that, in most cases, we have prior information about activity, Bayesian statistics constitute an ideal framework to carry out signal and image processing, being a natural but rigorous theory for combining prior and experimental information, see for instance Fitzgerald et al. [7] and Fitzgerald [6]. As stated by Zhang et al. [35], who provide a review of the most relevant Bayesian models for fMRI data analysis developed in recent years, Bayesian approaches have great potential in fMRI applications, as they allow flexible modelling of spatial and temporal correlation in the data [34].

In addition, DLM provides a very rich class of models for the analysis of time series data: see West and Harrison [33], the overview by Migon et al. [25], and references therein. DLM considers a time series as the output of a dynamic system perturbed by random disturbances. They allow natural interpretation of a time series as the combination of several components, such as trend, seasonal or regressive components. Therefore, they are flexible enough to capture the main features of a wide range of different data. At the same time, they have a powerful probabilistic structure, allowing many of the relevant inferences to be carried out exactly using the Kalman filter [18]. Thus computations can be implemented by recursive algorithms, computing the conditional distribution of the quantities of interest, given the available information. In this sense, they are naturally treated within a Bayesian framework.

The rest of the paper is structured as follows: in Section 2 we formally state the model, Section 3 outlines the algorithm implemented to make inferences about the unknown parameters, Section 4 presents the results obtained for simulations from the model, simulated data, and a real data set and Section 5 is devoted to conclusions and future directions of research.

Let us assume that the time series for a voxel in a fMRI study, 
                        
                           
                              y
                           
                           
                              1
                              :
                              T
                           
                        
                        =
                        
                           
                              {
                              
                                 
                                    y
                                 
                                 
                                    t
                                 
                              
                              }
                           
                           
                              t
                              =
                              1
                              ,
                              …
                              ,
                              T
                           
                        
                     , follows a constant DLM defined by
                        
                           (1)
                           
                              
                                 
                                    y
                                 
                                 
                                    t
                                 
                              
                              =
                              
                                 
                                    μ
                                 
                                 
                                    t
                                 
                              
                              +
                              
                                 
                                    v
                                 
                                 
                                    t
                                 
                              
                              ,
                              
                              
                                 
                                    v
                                 
                                 
                                    t
                                 
                              
                              ∼
                              N
                              (
                              0
                              ,
                              V
                              )
                           
                        
                     
                     
                        
                           (2)
                           
                              
                                 
                                    μ
                                 
                                 
                                    t
                                 
                              
                              =
                              
                                 
                                    G
                                 
                                 
                                    t
                                 
                              
                              
                                 
                                    μ
                                 
                                 
                                    t
                                    −
                                    1
                                 
                              
                              +
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                              ,
                              
                              
                                 
                                    w
                                 
                                 
                                    t
                                 
                              
                              ∼
                              N
                              (
                              0
                              ,
                              W
                              =
                              r
                              V
                              )
                           
                        
                      where V and W are unknown constants and the error sequences are independent, both within and between them.

Equation (1) is called the observation equation for the model, defining the sampling distribution for 
                        
                           
                              y
                           
                           
                              t
                           
                        
                      conditional on the level, 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                     . Notice that, given 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                     , 
                        
                           
                              y
                           
                           
                              t
                           
                        
                      is independent of all the other observations and parameter values.

Equation (2) is the evolution, state or system equation, defining the time evolution of the signal level. The conditional independence property shows a one-step Markov evolution so that, given 
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                      and the values of 
                        
                           
                              G
                           
                           
                              t
                           
                        
                      and W, 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                      is independent of the past. That is, given 
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                     , the distribution of 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                      is fully determined independently of values of 
                        
                           
                              y
                           
                           
                              t
                              −
                              1
                           
                        
                      and the level values and observations prior to time 
                        t
                        −
                        1
                     . The deterministic component of the evolution is the transition from state 
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                      to 
                        
                           
                              G
                           
                           
                              t
                           
                        
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                     , a linear transformation of 
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                     . Here we assume that 
                        
                           
                              G
                           
                           
                              t
                           
                        
                      is known, and following the recommendations of Petris et al. [28] to optimise the performance of the algorithm used (see Section 3) for the model proposed, we define 
                        
                           
                              G
                           
                           
                              t
                           
                        
                        =
                        G
                        =
                        0.9
                     , leading to an autoregressive model for the level of the series.

The SNR for each voxel, defined as the ratio of the signal variance to the variance of the system noise, can be estimated using this DLM model as
                        
                           (3)
                           
                              r
                              =
                              
                                 W
                                 V
                              
                           
                        
                      which is a broadly accepted measure for comparing performance characteristics between different time series [33,28]. Two examples of time series with different SNR are shown in Fig. 1
                     . A low SNR, like in (a), leads to a typical locally constant level, whereas in (b) the SNR is 100 times larger, resulting in much greater variation in the level.

As we are interested in estimating the unknown parameters of the model – 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                     , V, W – a fully Bayesian analysis is developed. The model is then completed with the initial information about the level at time 
                        t
                        =
                        0
                      that describes our prior beliefs about 
                        
                           
                              μ
                           
                           
                              0
                           
                        
                     , V, and W. In particular, assume that prior information about the unknown parameters is available and summarised by a gamma distribution for 
                        ϕ
                        =
                        
                           
                              V
                           
                           
                              −
                              1
                           
                        
                     , a Gaussian distribution for 
                        
                           
                              μ
                           
                           
                              0
                           
                        
                      and, following the recommendations of Gelman [12], a log normal prior distribution for W. Formally, define prior distributions for 
                        
                           
                              μ
                           
                           
                              0
                           
                        
                     , V, and W by
                        
                           (4)
                           
                              
                                 
                                    μ
                                 
                                 
                                    0
                                 
                              
                              ∼
                              N
                              (
                              
                                 
                                    m
                                 
                                 
                                    0
                                 
                              
                              ,
                              
                                 
                                    C
                                 
                                 
                                    0
                                 
                              
                              )
                           
                        
                     
                     
                        
                           (5)
                           
                              ϕ
                              ∼
                              G
                              (
                              
                                 
                                    α
                                 
                                 
                                    V
                                 
                              
                              ,
                              
                                 
                                    β
                                 
                                 
                                    V
                                 
                              
                              )
                           
                        
                     
                     
                        
                           (6)
                           
                              W
                              ∼
                              log
                              ⁡
                              N
                              (
                              
                                 
                                    m
                                 
                                 
                                    W
                                 
                              
                              ,
                              
                                 
                                    σ
                                 
                                 
                                    W
                                 
                                 
                                    2
                                 
                              
                              )
                              .
                           
                        
                     
                  

Note that the flexibility of these prior distributions allows the incorporation of prior knowledge. In case that it is not available, we may use instead a non-informative version of the proposed prior distributions (i.e. with large variances). In our case, we use 
                        
                           
                              α
                           
                           
                              V
                           
                        
                        =
                        
                           
                              β
                           
                           
                              V
                           
                        
                        =
                        10
                     , 
                        
                           
                              m
                           
                           
                              0
                           
                        
                        =
                        
                           
                              m
                           
                           
                              W
                           
                        
                        =
                        0
                     , and 
                        
                           
                              C
                           
                           
                              0
                           
                        
                        =
                        
                           
                              σ
                           
                           
                              W
                           
                           
                              2
                           
                        
                        =
                        100
                     .

The choice of a conjugate prior distribution for V leads to a gamma posterior distribution of V conditional on 
                        
                           
                              y
                           
                           
                              1
                              :
                              T
                           
                        
                      and 
                        
                           
                              μ
                           
                           
                              0
                              :
                              T
                           
                        
                     ,
                        
                           (7)
                           
                              V
                              |
                              
                                 
                                    y
                                 
                                 
                                    1
                                    :
                                    T
                                 
                              
                              ,
                              
                                 
                                    μ
                                 
                                 
                                    0
                                    :
                                    T
                                 
                              
                              ∼
                              G
                              
                                 (
                                 
                                    
                                       α
                                    
                                    
                                       V
                                    
                                 
                                 +
                                 
                                    T
                                    2
                                 
                                 ,
                                 
                                    
                                       β
                                    
                                    
                                       V
                                    
                                 
                                 +
                                 
                                    1
                                    2
                                 
                                 
                                    ∑
                                    
                                       t
                                       =
                                       1
                                    
                                    T
                                 
                                 
                                    
                                       (
                                       
                                          
                                             y
                                          
                                          
                                             t
                                          
                                       
                                       −
                                       
                                          
                                             μ
                                          
                                          
                                             t
                                          
                                       
                                       )
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                              .
                           
                        
                     
                  

On the contrary, the posterior distribution of W conditional on 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                      and V does not have a known form,
                        
                           
                              W
                              |
                              
                                 
                                    μ
                                 
                                 
                                    0
                                    :
                                    T
                                 
                              
                              ∝
                              
                                 
                                    W
                                 
                                 
                                    −
                                    
                                       T
                                       2
                                    
                                    −
                                    1
                                 
                              
                              exp
                              ⁡
                              
                                 {
                                 −
                                 
                                    1
                                    
                                       2
                                       
                                          
                                             σ
                                          
                                          
                                             W
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 
                                    [
                                    
                                       
                                          (
                                          log
                                          ⁡
                                          (
                                          W
                                          )
                                          −
                                          
                                             
                                                m
                                             
                                             
                                                W
                                             
                                          
                                          )
                                       
                                       
                                          2
                                       
                                    
                                    ]
                                 
                                 }
                              
                              exp
                              ⁡
                              
                                 {
                                 −
                                 
                                    1
                                    
                                       2
                                       W
                                    
                                 
                                 
                                    ∑
                                    
                                       t
                                       =
                                       1
                                    
                                    T
                                 
                                 
                                    
                                       (
                                       
                                          
                                             μ
                                          
                                          
                                             t
                                          
                                       
                                       −
                                       
                                          
                                             G
                                          
                                          
                                             t
                                          
                                       
                                       
                                          
                                             μ
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       )
                                    
                                    
                                       2
                                    
                                 
                                 }
                              
                              .
                           
                        
                     
                  

Lastly, let 
                        
                           
                              R
                           
                           
                              t
                           
                        
                        =
                        
                           
                              G
                           
                           
                              2
                           
                        
                        
                           
                              C
                           
                           
                              t
                              −
                              1
                           
                        
                        +
                        W
                     , and 
                        
                           
                              Q
                           
                           
                              t
                           
                        
                        =
                        
                           
                              R
                           
                           
                              t
                           
                        
                        +
                        V
                     , then the posterior distribution of 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                      at time t is recursively defined by
                        
                           
                              
                                 
                                    μ
                                 
                                 
                                    t
                                 
                              
                              |
                              
                                 
                                    y
                                 
                                 
                                    t
                                 
                              
                              ,
                              
                                 
                                    μ
                                 
                                 
                                    t
                                    −
                                    1
                                 
                              
                              ,
                              V
                              ,
                              W
                              ∼
                              N
                              (
                              
                                 
                                    m
                                 
                                 
                                    t
                                 
                              
                              ,
                              
                                 
                                    C
                                 
                                 
                                    t
                                 
                              
                              )
                           
                        
                      with 
                        
                           
                              m
                           
                           
                              t
                           
                        
                        =
                        G
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                        +
                        
                           
                              
                                 R
                              
                              
                                 t
                              
                           
                           
                              
                                 Q
                              
                              
                                 t
                              
                           
                        
                        (
                        
                           
                              y
                           
                           
                              t
                           
                        
                        −
                        G
                        
                           
                              μ
                           
                           
                              t
                              −
                              1
                           
                        
                        )
                      and 
                        
                           
                              C
                           
                           
                              t
                           
                        
                        =
                        
                           
                              R
                           
                           
                              t
                           
                        
                        −
                        
                           
                              (
                              
                                 
                                    
                                       R
                                    
                                    
                                       t
                                    
                                 
                                 
                                    
                                       Q
                                    
                                    
                                       t
                                    
                                 
                              
                              )
                           
                           
                              2
                           
                        
                        
                           
                              Q
                           
                           
                              t
                           
                        
                      (see West and Harrison [33] for further details).

For each fMRI experiment, the analysis is performed on a slice-by-slice basis, and only those voxels inside the brain are analysed. Firstly, each voxel's time series is standardised so that its variance is 1 and its mean is 0.

When 
                        
                           
                              G
                           
                           
                              t
                           
                        
                     , V, and W are known, the Kalman filter [18] can be used to perform inference about the latent process 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                     . In practise these parameters are unknown and numerical integration methods, such as MCMC, are required for the Bayesian statistical analysis.

In our case, the set of unknown parameters can be partitioned in two blocks: V and W; and 
                        (
                        
                           
                              μ
                           
                           
                              1
                           
                        
                        ,
                        …
                        ,
                        
                           
                              μ
                           
                           
                              T
                           
                        
                        )
                     . In particular, following Petris et al. [28], we use a Gibbs sampling scheme for posterior inference, in four steps:
                        
                           (1)
                           Draw 
                                 
                                    
                                       V
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                               from 
                                 p
                                 (
                                 V
                                 |
                                 
                                    
                                       μ
                                    
                                    
                                       0
                                       :
                                       T
                                    
                                    
                                       (
                                       k
                                       −
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       1
                                       :
                                       T
                                    
                                 
                                 )
                              , as defined in equation (7);

Draw 
                                 
                                    
                                       μ
                                    
                                    
                                       0
                                       :
                                       T
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                               from 
                                 p
                                 (
                                 
                                    
                                       μ
                                    
                                    
                                       0
                                       :
                                       T
                                    
                                 
                                 |
                                 
                                    
                                       V
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       W
                                    
                                    
                                       (
                                       k
                                       −
                                       1
                                       )
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       1
                                       :
                                       T
                                    
                                 
                                 )
                              ;

Simulate 
                                 
                                    
                                       W
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                               from full conditional density of W given 
                                 
                                    
                                       μ
                                    
                                    
                                       0
                                       :
                                       T
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                              ,

Obtain 
                                 
                                    
                                       r
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                                 =
                                 
                                    
                                       
                                          W
                                       
                                       
                                          (
                                          k
                                          )
                                       
                                    
                                    
                                       
                                          V
                                       
                                       
                                          (
                                          k
                                          )
                                       
                                    
                                 
                              ,

It is important to note that using a Bayesian framework allows us to not only obtain a point estimation but to compute the posterior distribution of r, which also enables us to compute the probability of any event of interest. For instance, the probability that the SNR of a time series is above some threshold,
                        
                           (8)
                           
                              P
                              (
                              r
                              >
                              
                                 
                                    r
                                 
                                 
                                    0
                                 
                              
                              |
                              y
                              )
                              =
                              
                                 1
                                 K
                              
                              
                                 ∑
                                 k
                              
                              I
                              
                                 (
                                 
                                    
                                       r
                                    
                                    
                                       (
                                       k
                                       )
                                    
                                 
                                 >
                                 
                                    
                                       r
                                    
                                    
                                       0
                                    
                                 
                                 )
                              
                              .
                           
                        
                     
                  

We decide the value of this threshold, 
                        
                           
                              r
                           
                           
                              0
                           
                        
                     , based on the control of the false discovery rate, as explained in Genovese et al. [13]. For the N voxels being tested, the procedure is as follows: (i) select a bound, q, for the false discovery rate; (ii) order the probabilities, in our case, 
                        p
                        =
                        1
                        −
                        P
                        (
                        r
                        >
                        
                           
                              r
                           
                           
                              0
                           
                        
                        |
                        y
                        )
                     , and (iii) find the largest i for which 
                        
                           
                              p
                           
                           
                              (
                              i
                              )
                           
                        
                        ≤
                        
                           i
                           N
                        
                        
                           q
                           
                              c
                              (
                              V
                              )
                           
                        
                     , where (i) denotes the ordering index. In the discussion, Genovese et al. [13] give recommendations on the choice of q and 
                        c
                        (
                        V
                        )
                      in the framework of neuroimaging data analysis.

@&#RESULTS@&#

We simulate a data set from model equations (1) and (2), using different values for 
                           r
                           =
                           
                              W
                              V
                           
                        , ranging from 10 to 0.01. For each value of r, we simulated 10 time series of length 
                           T
                           =
                           50
                        . Table 1
                         shows the proportion of times that the model proposed recovered the value of r (included in the posterior 95% credible interval) and, for each value of r, a summary of the mean estimations of r and of the 95% credible intervals obtained for each simulated time series.


                        Fig. 2
                         shows two examples of the performance of the model for two different values of r.

As r is a measure of the SNR of the time series, it is expected that the algorithm fails to recover the signal the lower r is. When 
                           r
                           =
                           0.01
                        , we checked that, even if the true value is not included in the interval, values of the estimated r are small.

A robustness study with respect to the prior hyperparameters choice was performed observing that the procedure provides similar results with all the options considered. In particular, we assess the performance of the model by changing the values of 
                           
                              
                                 α
                              
                              
                                 V
                              
                           
                           =
                           
                              
                                 β
                              
                              
                                 V
                              
                           
                           =
                           1
                           ,
                           10
                           ,
                           100
                        . Choosing an informative prior, as defined by 
                           
                              
                                 α
                              
                              
                                 V
                              
                           
                           =
                           
                              
                                 β
                              
                              
                                 V
                              
                           
                           =
                           1
                        , leads to slightly poorer recovery for the lowest values of r.

In order to check the ability of the model of detecting activity, we simulate 10 active voxels and 10 non-active ones, using the fmri R library [31]. An example of each group of time series is shown in Fig. 3
                        .

We first standardise the time series, then fit the model to the data and finally save the samples of r for each simulated time series, from which we compute the mean and 95% credible interval and the 
                           P
                           (
                           r
                           >
                           
                              
                                 r
                              
                              
                                 0
                              
                           
                           )
                        . The threshold 
                           
                              
                                 r
                              
                              
                                 0
                              
                           
                         is computed as explained at the end of Section 3. The results obtained can be checked in Fig. 4
                         and in Table 2
                        .

From these results, we can conclude that the model gives rise to higher values of r in active voxels, showing its ability to distinguish between active and non-active voxels.

With the aim of illustrating that the model proposed can be used for analysing challenging real fMRI data, we apply the model to a study previously analysed in Solana et al. [30]. In that work, two cryptogenic generalised epileptic (CGE) Fixation-off Sensitivity (FoS) females (32 and 18 years) underwent a simultaneous EEG-fMRI scan session. Based on the previous knowledge about FoS and on previous clinical studies, the hypothesis of that work was that the altered brain rhythms (EEG) in these epileptic patients affect the organisation of their resting-state networks (fMRI), when closing the eyes or losing fixation. In order to estimate the resting-state networks, two fMRI series were performed: resting-state under (A) open-eyes and (B) closed-eyes (120 images each) conditions, as these type of patients are expected to behave normally when their eyes are open. In Solana et al. [30] ICA on the resting-state fMRI series was applied using the MELODIC toolbox [1] in FSL, which is considered the gold standard technique for analysing resting-state fMRI time series. It is important to note that, although the condition of interest was closed-eyes, the open-eyes study was required by the used ICA methodology as the control condition.

In this work, we apply the model to the closed-eyes resting-state study of one of the patients presented in Solana et al. [30]. The MRI data were collected at the Research Center for Neurological Diseases Foundation using a General Electric Signa 3.0 T MR scanner (General Electric Healthcare, Milwaukee, WI) using a whole-body radiofrequency (RF) coil signal excitation and a 8-channel brain coil for reception. fMRI data were acquired with continuous Gradient-Echo EPI sequence (2.4 mm slice thickness, gap between slices = 0.3 mm, 96 × 96 matrix, FoV = 22 cm, TE = 28.4 ms, TR = 2.88 s, flip angle = 83°, complete frame 36 slices). The subject was instructed to be relaxed without moving the eyes and not to fall asleep during the closed-eyes condition. The MR structural images were acquired through a high-resolution 3D T1-weighted SPGR (Spoiled Gradient Recalled echo) sequence.

As in Solana et al. [30], the preprocessing of the data was performed using FSL software package [17]. The EPI were slice-timing corrected, realigned to the middle volume of the fMRI series using McFLIRT algorithm [16], and high-pass filtered (100 seconds), and the skull was subtracted using the BET tool [29]. Next, images were coregistered to the individual 3D T1 structural image, normalised to MNI152 2 mm template and smoothed using a 6 mm FWHM. Note that the same preprocessing was used in both analysis, although the normalisation to MNI is not required for a single-subject analysis.

@&#RESULTS@&#

In order to obtain a map of activity we follow the recommendations in Genovese et al. [13], defining 
                              c
                              (
                              V
                              )
                              =
                              1
                            and 
                              q
                              =
                              0.05
                            and control that the expected false discovery rate is lower than q. Therefore, we calculate the posterior probability that r is greater than 0.25, and depict only those voxels where that probability is greater than 0.995. Fig. 5
                            presents this posterior probability map. As stated previously, this permits a numerical quantification and characterisation of the activation pattern. As expected, the activation map is mainly composed by temporo-frontal areas, as well as by parietal areas, brain regions related to attentional processes.

The result shown in Fig. 5 is similar to the network obtained by ICA analysis in Solana et al. [30] for the same data (Fig. 6
                           ). Fig. 6 shows the independent component explaining 5% of the variance of the time series that was identified as biologically plausible network with the highest amplitude resting low-frequency fluctuation (seventh component ordering from highest explained variance to lowest variance). In these figures, it can be appreciated that both techniques lead to the same activity map. This is not surprising as the activity maps provided by ICA are a measure of the SNR (see McKeown et al. [24] for a detailed description or Martínez et al. [23] for a brief explanation).

The method presented achieves similar results to those of ICA, using a simpler approach that does not require human interaction and advanced expertise of the final user and, in addition, using only one of the two fMRI series required by ICA. On the other hand, ICA methodology is able to detect other resting-state networks. Nevertheless, with the approach presented here, we are able to directly estimate the most clinically relevant resting-state network, which is similar to that identified by clinicians using ICA – under the point of view of the studied pathology.

@&#CONCLUSIONS@&#

This research describes the employment of DLM to analyse the time series for a voxel in a fMRI experiment. Estimating the error variances of such a model and using Bayesian inference, we are able to obtain samples from the posterior distribution of the SNR for that voxel. This enables us to provide not just a point estimate of the SNR for each voxel but also to compute the probability of any event of interest. The results obtained demonstrate the ability of the model to detect brain activity.

The benefits of this approach are: (i) the reduced number of parameters in the DLM, (ii) the model makes no assumptions about the stimulation paradigm, (iii) a model based approach, hence more interpretable than a data driven one, and (iv) potential of including a wide range of other features like spatial dependencies, linear or seasonal trends, etc., due to the flexibility of DLM.

In model driven approaches like the GLM, a canonical HRF is often used. According to Lindquist and Wager [22], this can be a restrictive assumption. As the model proposed makes no assumptions on the shape of the HRF and allows a dynamic temporal modelling, it does not suffer from most of the issues that model based approaches have.

It is also important to emphasise here that the model makes no assumptions about the stimulation paradigm presented during the experiment. As stated in Lindquist [21], in many areas of physiological inquiry – including studies on memory, motivation and emotion – or in resting-state experiments, it may not be reasonable to assume that the experimental paradigm is known. Therefore, the GLM cannot be directly applied to these data sets and alternative methods are needed. Typically, researchers adopt a data driven approach like ICA, with the main drawback of a more complicated interpretation of the results. Therefore, this new approach, being model based, is able to deal with experiments with endogenous brain activity, such as resting-state fMRI data, as demonstrated.

Although HRF estimation is out of the scope of this work, which aims at addressing the activity detection problem, it is important to note that the level, 
                        
                           
                              μ
                           
                           
                              t
                           
                        
                     , contains all the information about the HRF for each voxel. This allows us to compute any estimate of interest, as for example the magnitude of the response, the time-to-peak, or the duration of activation.

DLM is a powerful tool, unexplored in the analysis of fMRI data. In order to deal with HRF estimation, other DLM can be explored as, for example, dynamic regression or seasonal models [32].

This work has several limitations. Firstly, this method relies on the identification of voxels with high SNR which, apart from neuronal activity, might in some cases carry SNR spatial dependency [5], or physiological noise [15]. It is thus important to count on a neuroscientist for the clinical interpretation of the results. Secondly, detection of active voxels may be improved by considering spatial dependencies in the model. Future versions of our model will include spatial prior information in order to perform a fully Bayesian spatiotemporal analysis of the whole brain. Thirdly, the model is concerned with single subject data. It is a matter of future work to extend it in order to incorporate information from a group of subjects. Multi-subject fMRI data is intrinsically hierarchical in nature and, therefore, Bayesian inference is an ideal framework for performing it. Lastly, the model is applied to a dataset acquired with a 3T MR scanner. Further work is needed on the applicability of the method to scanners with other magnetic fields or its dependence on fMRI acquisition parameters, if it is to be applied for supporting clinical decisions. It is important to remark again that, in the interpretation of the results obtained, it is the job of the neuroscientist to recognise those patterns that are genuinely neuronal and relevant for the patient under study.

@&#ACKNOWLEDGEMENTS@&#

This work was funded by the grant Tec2012-39095-C03-01 from the Ministry of Economy and Competitiveness (Spanish Government) and by the Trinity College Dublin Visiting Professors Fund and by Insight Centre for Data Analytics, Grant Number SFI/12/RC/2289. The authors would like to thank J. Álvarez Linera (Neuroradiology, Hospital Ruber International, Madrid, Spain), and A. Gil-Nagel, R. Toledano, I. García Morales, and V. San Antonio-Arce (Epilepsy Program, Hospital Ruber International, Madrid, Spain) for fMRI acquisition and epileptic patient recruitment and discussion.

@&#REFERENCES@&#


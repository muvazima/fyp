@&#MAIN-TITLE@&#Analyzing operational risk-reward trade-offs for start-ups

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We model the advertising and inventory decisions of a start-up.


                        
                        
                           
                           We develop a novel methodology to track variance as well as expected rewards of the operational decisions.


                        
                        
                           
                           We call this methodology Variance Retentive Stochastic Dynamic Programming.


                        
                        
                           
                           We develop a heuristic (RiskTrackr) to construct risk-reward efficient frontiers.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Risk-reward

Efficient frontiers

Heuristic

Start-up operations

Variance Retentive Stochastic Programming

@&#ABSTRACT@&#


               
               
                  In many managerial situations it is important to consider both risk and reward simultaneously. This is a challenging task using standard techniques that are applied for solving sequential stochastic optimization problems since these techniques are designed to consider only one objective at a time—either maximizing reward or minimizing risk. In applications such as operational decisions for start-ups, this can be particularly restricting, since managers need to make trade-offs between profitability driven growth and the risk of bankruptcy. We extend in several ways prior work that has addressed the inventory issue for start-ups to minimize the risk of bankruptcy. The primary contribution of this paper is to present a novel approach to track mean as well as variance of a set of policies in a dynamic stochastic programming model and using the mean-variance solutions in a simple heuristic for creating efficient risk-reward frontiers. This is a challenging task from an implementation standpoint, since this requires carrying information on both risk and reward simultaneously for each state, which standard stochastic programming solution methods are not designed to do. We also illustrate the use of our methodology in a richer model of start-up operations where, in addition to inventory issues, advertising decisions are also considered.
               
            

@&#INTRODUCTION@&#

Start-ups are critical to the economic well-being of a nation. They are newly created firms that are in a phase of development and growth. Often start-ups act as incubators of new technology and innovation. They also contribute immensely in job creation. According to data from the Kauffman Foundation and the US Census Bureau (Weitekamp & Pruitt, 2009), without the jobs start-ups create, yearly employment growth would be negative. However, the startling reality about start-ups is that more than 50 percent of all new ventures fail within the first five years of inception (Shane, 2008, 2012; US Bureau of Labor Statistics, 2010). Start-ups often lack vital resources and have to compete against established companies for market share. These capital-constrained firms face challenges that are quite distinct. Thus, it is imperative to identify strategies that assist these start-ups in sustaining their growth endeavors.


                     Archibald, Thomas, Bates, and Johnston (2002) addressed the inventory issue for start-ups, and the importance of synchronizing inventory decisions with cash on hand to avoid bankruptcy. In this paper, we extend this work in several ways. We focus on two other extremely important operational issues for a start-up, namely the importance of risk-reward tradeoffs, and the need for them to consider both inventory and advertising decisions simultaneously. Most models in literature optimize for one decision alone—either maximize reward (most models) or minimize bankruptcy risk (as done by Archibald et al., 2002). Considering risk and reward simultaneously makes solving these problems by techniques used for solving sequential stochastic optimization problems very difficult. Modeling the problems using mathematical programming in the standard portfolio optimization way of minimizing risk subject to some level of reward is also not practical here because these dynamic and stochastic problems can become extremely large very quickly as there could be innumerable states traversed by the problem based on the actions sets and probability branches. In any real-life problem involving several stages with considerable number of possible actions and probability branches at any stage, the problem size grows exponentially. Therefore, the primary contribution of this paper is to present a simple way of tracking both risk and reward in a stochastic programming framework and creating efficient frontiers based on the risk-reward solutions. This is a challenging task from an implementation standpoint, since this requires carrying information on both risk and reward for each state, and standard solution methodologies such as dynamic programming carry only one piece of information, either risk or reward on the basis of which the functional value is computed. The extension of Archibald et al. (2002) to include consideration of advertising is an important secondary contribution.

Risk exposure is a critical aspect of start-up operations. For start-ups the risk of bankruptcy is a reality. Without strong financial controls supplementing growth, start-ups often lose their foundation and are left on shaky grounds. Often managers tend to focus just on the expected returns of a set of decisions ignoring the associated risks. It is critical to look beyond the expected returns of a set of decisions and weigh the variability induced by the outcomes. Maximizing profits can lead to outcomes with high variability that can be unacceptable to a risk-sensitive decision maker. On the other hand, being too conservative can also be dangerous for the profitability of the firm. Archibald et al. (2002) hypothesize that start-ups maximize the probability of their survival rather than their profitability. Survival is no doubt an important objective for a start-up. However, maximizing survival probability might be too conservative from the start-up's perspective and it might forego certain growth opportunities which can hurt the firm adversely. In our analysis, we focus not only on the expected profitability of the optimal inventory and advertising decisions but also explore the risks involved in those decisions.

We define risk as the variability associated with the outcomes of each of the policies and measure risk by the variance of the possible outcomes. Variance of the outcomes about the expected value is a widely used measure of risk in portfolio theory. Variance is used by investors to measure the risk of a portfolio of stocks. Portfolios of financial instruments are chosen to minimize the variance of the returns subject to a level of expected return or vice versa to maximize expected return subject to a level of variance of the return. This paradigm was first introduced by Markowitz's (1952, 1959) mean-variance analysis for which contribution he was honored with the Nobel Prize in Economics. In Fig. 1
                     , we present the risk-reward associated with the optimal policies of a start-up under both maximizing profitability and maximizing survival probability. As expected the risk for a start-up that maximizes survival probability (Archibald et al., 2002) is lower but at the same time the expected return is also much less. On the other hand, if the start-up maximizes its profitability, the expected return increases but it exposes the firm to greater risks. From a start-up's point of view, it is important to measure and perceive the risks associated with any managerial decision rather than focus on just the expected return. Based on their risk tolerance managers might be interested in policies that expose the firm to less risk compared to the risks involved in a policy that maximizes expected reward. Therefore, decisions that result in the efficient risk-reward frontier are extremely beneficial to risk-sensitive managers.

In this paper, we present a heuristic that utilizes the information about the variance of a set of decisions and provides a mechanism to construct efficient mean-variance curves. In Fig. 1, the dotted line is the risk-reward frontier obtained by implementing our heuristic. The main theoretical contributions of this paper are three-fold. Firstly, we propose a methodology for tracking the variance of the possible outcomes at each stage and state of a multi-period stochastic program. We call our methodology Variance-Retentive Stochastic Programming (Variance-Retentive SP). At each state in the Variance-Retentive SP, we capture the risk and reward for each action given the probability of reaching any state in the next period for which the risk and reward is known. Secondly, our proposed Variance-Retentive SP provides a methodology for solving stochastic programming problems where the optimization is done over two metrics, mean and variance, instead of the usual one. Thirdly, given the popularity of efficient frontier approaches in finance, we develop a heuristic to identify such mean-variance frontiers in the startup context using our Variance-Retentive SP. We also specify the limitations of this heuristic to problems where the action space is limited.

Our heuristic is easy to use and gives managers a useful tool with which they can figure out a set of decisions that maximizes profit at different levels of risk. In a standard finite-horizon stochastic programming problem, information about the expected reward of a set of decisions is carried along and is used to solve the problem by backward or forward induction. In our proposed Variance-Retentive SP we carry information about the variance of a set of decisions in addition to expected rewards and this information about the variance is used in selecting the optimal actions. The risk-reward solutions obtained by solving the Variance-Retentive SP are used in our heuristic to obtain mean-variance efficient frontiers.

Next we illustrate the utility of ascertaining the variance of a set of outcomes in a stochastic dynamic setting through a small numerical example.


                     Motivating example: Consider a simple two-period stochastic programming model shown in Fig. 2
                     , where the rectangles are decision nodes and the circles are probability nodes (with probabilities shown on the arcs). The possible actions at the decision nodes are denoted by aij
                     . The terminal rewards are shown in parenthesis in the rectangles on the far right. There are exactly 16 sample paths in this problem, and each has a risk and reward, resulting in an expected reward and variance.


                     Fig. 3 presents the efficient risk-reward frontier based on the solutions of this simple problem. The variance of the possible outcomes for a policy is calculated using Eq. (5), which is derived later in Section 4. The maximum expected reward in this problem is 19, with a variance of 425. This solution lies on the efficient frontier; however this solution may be unacceptable to a risk-sensitive decision-maker for whom the variance of 425 units may be too risky. The solutions having variance of 336 and expected reward of 17, variance of 127 and expected reward of 11 and variance of 0 and expected reward of 2 are the other solutions that are on the efficient frontier whereas solutions with variance 756 and expected reward of 3 or variance of 887 and expected reward of 5 are not on the efficient frontier. The solutions on this efficient frontier provide the maximum expected reward at different levels of variance. So depending on their risk tolerance, managers can pick policies that provide them solutions on this frontier assuring them maximum expected rewards at different levels of variance or risk.

Algorithms such as the critical line method introduced by Markowitz (1952, 1959) are used for the identification of the optimal mean-variance portfolios. These algorithms work by solving quadratic or non-linear programs when the investment horizon is of one period. However, in a dynamic stochastic programming setting we require decisions that are spread over different time-periods. Rather than a one-shot model as is solved through critical line algorithm, dynamic stochastic programs sequentially determine the optimal set of actions taking into consideration the impact of present actions on future rewards. The problem size of these stochastic programs grows exponentially with innumerable state spaces and actions. Converting these multi-period stochastic problems into quadratic or non-linear programs becomes computationally complex and intractable. In addition, as state space and probability intervals increase it is impossible to enumerate all the sample paths and then trace out the efficient frontier because the policy table and the sample paths increase dramatically. The start-up model we present in Sections 5 and 6 has 106 possible state spaces and in each state there are 320 possible actions. This problem has millions of possible policies and even higher number of sample paths. In problems of such dimension it is impossible to enumerate all the possible sample paths and policy tables. Variance-Retentive SP, on the other hand, systematically tracks the variance and the average reward for a set of policies and uses the solutions in a heuristic where instead of identifying one policy to achieve the stated objective, we find the set of policies that form the efficient frontier.

The remainder of the paper is organized as follows: Section 2 provides literature review. Section 3 develops the analytical models. We present heuristics for obtaining risk-reward curves in Section 4. Managerial insights are given in Section 5 with concluding remarks in Section 6.

@&#LITERATURE REVIEW@&#

The issues of joint operational and financial decisions have not been studied extensively in the literature. In a start-up the coordination between operations and finances is extremely critical as these firms have to operate under stringent capital budgets. Out of the very few papers that examine operational decisions under limited financing options significant work is done by Babich and Sobel (2004), Buzacott and Zhang (2004) and Archibald et al. (2002). Buzacott and Zhang develop a mathematical programming model to analyze inventory policies under deterministic demand with asset-based financing options. Babich and Sobel consider a start-up whose owners view an initial public offering (IPO) as a cash-out opportunity. Archibald et al. analyze the inventory policies of a start-up that tries to maximize its survival probability. However, these papers overlook a very important aspect of start-up operations namely the growth ventures.

Growth is extremely critical for start-ups. Stagnation is a proposition that can propel a start-up toward termination. In this paper, we incorporate advertising investments along with inventory policies of a start-up. Advertising is a promotional tool that stimulates market demand and helps a start-up to grow. There is a rich body of literature in marketing on advertising. Little (1979) and Feichtinger, Hartl, and Sethi (1994) provide detailed review of the developments in aggregate advertising models. One of the main issues in these models is to ascertain the impact of advertisement on demand. Two of the seminal works in modeling the dynamic nature of advertising response are by Vidale and Wolfe (1957) and Nerlove and Arrow (1962). The Vidale–Wolfe model proposes that advertising directly persuades potential customers not currently buying from a firm while at the same time those who are currently buying tend to forget and buy less over time. The Nerlove–Arrow model formalizes the idea that consumers build up goodwill toward a firm through protracted exposure to the firm's advertising. This goodwill dynamically influences market demand. The model we present in this paper is in line with the Nerlove–Arrow model and is a generalization of an advertising model presented by Heyman and Sobel (1983) and Monahan (1983). Recent papers by Sonnier, McAlister, and Rutz (2011), Xie and Wei (2009) and Lévesque, Joglekar, and Davies (2012) have used the Nerlove–Arrow paradigm to model the impact of advertising on consumers.

Moreover, in our model, we consider the interplay of inventory and advertising decisions. Next we look at the extant literature that focuses on inventory and advertising policies. Sethi and Zhang (1995) examine a production-advertising model with unreliable machines and random demand influenced by the level of advertising via a Markov process. Cheng and Sethi (1999) deduce optimal inventory and promotion decision policies in the finite horizon problem by dynamic programming. Kamrad, Lele, Siddique, and Thomas (2005) analyze a stochastic model of innovation diffusion where market demand is influenced by price, word-of-mouth and advertising efforts. Strack and Pochet (2010) present an integrated warehouse and inventory control model. However, none of the above papers consider the impact of financial policies on the inventory/advertising decision. Here, we analyze the coordination between inventory and advertising decisions of a start-up firm under limited capital resources. This distinguishes our model from the existing literature.

In this paper, we also contribute theoretically by providing a methodology for capturing risk-reward trade-offs in a multi-period stochastic programming framework. There has been some limited research in the field of risk-sensitive decision-making where mean-variance trade-offs are considered in sequential stochastic programming problems. Variance sensitive Markov Decision Processes (MDP) have been studied by Howard and Matheson (1972), Filar, Kallenberg, and Lee (1989), Sobel (1982, 1994), Baykal-Gursoy and Ross (1992), and Chung (1994). The variance-penalized MDPs are formulated as mathematical programs with linear constraints and nonlinear objective function. Kawai (1987) analyzed randomized policies that minimize the variance of the reward with the mean not less than a specified value in the steady state of a discrete time MDP. Wu and Lin (1999) developed an MDP model with countable state space and reward set with the objective of finding a policy which minimizes the probability (risk) that the total discounted rewards do not exceed a specified target value. We refer the reader to a survey done by White (1988) for a review in risk-sensitive optimization of MDP. Recently risk-averse stochastic programming has attracted renewed attention. Notable contribution has come from Borkar and Meyn (2002), Artzner, Delban, Eber, Heath, and Ku (2007), Shapiro (2009) and Ruszczynski (2010). Borkar and Meyn analyzed risk-sensitive optimal control for MDPs under monotone cost function. Artzner et al. studied coherent risk measures which were extended by Shapiro to multi-stage risk-averse stochastic programming problem. Ruszczynski introduced the concept of Markov risk measure and applied it to risk-averse Markov decision models. However as Filar et al. (1989) and Sobel (1982) point out one of the drawbacks of these formulations is that they lead to formidable mathematical difficulties that are cumbersome and difficult to implement for practical purposes.

Another approach that is used to model the risk attitude in a multi-period stochastic setting is maximizing the expected utility of the decision-maker. Rather than treating risk and reward of the possible outcomes separately, a single quantity, the expected utility of the terminal reward, is considered instead. The utility function of the decision-maker maps the preferences for the pay-offs at different levels of risks and maximizing the expected utility captures the preferred outcome under uncertain and risky events. We refer the reader to Samuelson (1969), Fama (1970), Kreps (1977, 1997), Nguyen (1997), Chen, Sim, Simchi-Levi, and Sun (2007) and Fleming and Sheu (1999) for significant work in this line of research. Even though expected utility is used as decision-making criteria under risk there are certain limitations of this approach. First of all it is difficult to specify a utility function of a decision-maker and even more difficult when a group of decision-makers are involved (Hershey, Kunreuther, & Schoemaker, 1982; Karmarkar, 1978). In the utility approach, the relationship between risk and reward is contained only implicitly in the utility function; hence the general relationship between risk and reward is not always clear (Li & Ng, 2000; Zhou & Li, 2000; Zhou & Yin, 2003). Shoemaker (1982) provides an in-depth analysis of the limitations of expected utility approach. The mean-variance approach to model risk-reward trade-offs, on the other hand, does not depend on the axiomatic framework of utility theory and is much more intuitive and easier to apply for practical purposes. Papers by Levy and Markowitz (1979), Pulley (1981) and Kroll, Levy, and Markowitz (1984) have shown empirically that the ordering of portfolios by the mean-variance approach is almost identical to the order obtained by using expected utility for various utility functions and historical distributions of returns. The mean-variance approach for tracking risk-reward of optimal portfolio choices is extremely popular in the finance literature. We refer the reader to the works of Sharpe (1992), Todd (2000), Steinbach (2001) and Joro and Na (2006) for an extensive review of this methodology and its applications. Mean-variance trade-offs have been analyzed in different operational decisions by Chen and Federgruen (2000), Martinez-de-Albeniz and Simchi-Levi (2003), Choi, Li, and Yan (2008), Wu, Li, Wang, and Cheng (2009), Wei and Choi (2010), and Choi et al. (2012). We also refer the reader to a recent paper by Markowitz (2014) in which the author clearly identifies the advantages of using the mean-variance framework over the expected utility criteria for modeling risk-reward trade-offs. Markowitz (2014) asserts that a careful choice from a mean-variance efficient frontier will approximately maximize expected utility for a wide variety of utility functions. In this paper, we follow the mean-variance approach mainly because of its intuitive nature and ease of use. Our methodology is independent of the functional form of the utility of the decision-maker and gives mean-variance solutions at different levels of risk-tolerance.

Next, we present stochastic programming model for start-up operations namely its inventory and advertising policies.

We develop a finite horizon stochastic programming model to capture the uncertainty and the inter-temporal aspect of start-up operations. Our problem is motivated by a start-up involved in online retailing for electronic gadgets. The firms use an e-commerce website to sell items that it obtains from the manufacturer. To promote the items that it sells, the firm invests in keyword and banner advertising such as Google Adwords and Yahoo Search Marketing. Our model, however, is much more general in nature and can also be used for start-ups in manufacturing operations as discussed in Archibald et al. (2002).

We focus on two important decisions for the start-up namely its inventory policies and advertising investments. As we have discussed earlier due to constricted access to capital it is extremely important that the start-up balance its inventory policies with advertisement decisions. We assume that the start-up sells only one type of product that it obtains from the manufacturer. There is a fixed lead time of one time period for the delivery of products. In order to manage the inventory optimally the start-up has to decide each period how many items to order. Because of limited capital availability the start-up does not want to tie up excessive amount of cash in inventory. It needs to invest strategically in other important growth ventures. Advertising is a marketing endeavor that impacts demand and helps the start-up maintain its growth trajectory. In our model we study the interplay of inventory and advertising decisions. So apart from the ordering decision, each period the start-up also decides on how much to invest in advertising. At the beginning of each time-period the start-up orders qt
                      components which arrive at the start of the next time period. The second decision that the start-up takes each period is the advertising investment which we denote by it
                     . With limited access to capital, start-up needs to coordinate its ordering and advertising decisions. Investing exorbitantly in advertising without building up adequate inventory can be damaging. Similarly carrying too much inventory without generating substantial demand can lead to excessive costs.

We assume that demand in each period is influenced by an aggregate measure of past and present advertising expenditure that we define as advertising goodwill. This is in accordance with the well-known Nerlove and Arrow (1962) model in advertising which states that a firm builds goodwill among its consumers through advertising and this acquired goodwill dynamically influences the market demand. Heyman and Sobel (1983) extended the Nerlove and Arrow model to a discrete time dynamic setting. Our present model is a generalization of the Heyman and Sobel advertising model with which we incorporate the inventory policies of a cash-constrained start-up. We define ωt
                      as the level of goodwill at the beginning of period t that the start-up acquires through its present and past advertising investments. Demand in any period denoted by dt
                      depends only on ωt
                     .

In marketing literature, it is well established that there is a positive relationship between present period advertising and present as well as future period sales which support goodwill building mechanism of advertising. Empirical research on the impact of advertising on sales has provided evidence of this goodwill effect (Chintagunta & Vilcassim, 1992; Lambin, 1976). However if no advertising is done in the future, then the impact of present period advertising on future sales diminishes with time. We model the above diminishing trend by assuming that sales effect of advertising depreciates at a constant rate of 
                        
                           1
                           −
                           θ
                        
                      per time period where 0 ≤ θ < 1. This implies that itθj
                      is the impact of an investment of it
                      on demand in period 
                        
                           j
                           +
                           t
                        
                     . Therefore ωt
                     , the goodwill in period t, is denoted by:

                        
                           (1)
                           
                              
                                 
                                    ω
                                    t
                                 
                                 =
                                 
                                    i
                                    1
                                 
                                 
                                    θ
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 +
                                 
                                    i
                                    2
                                 
                                 
                                    θ
                                    
                                       t
                                       −
                                       2
                                    
                                 
                                 +
                                 ⋯
                                 +
                                 
                                    i
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 θ
                                 +
                                 
                                    i
                                    t
                                 
                                 =
                                 
                                    ∑
                                    
                                       x
                                       =
                                       0
                                    
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 
                                    i
                                    
                                       t
                                       −
                                       x
                                    
                                 
                                 
                                    θ
                                    x
                                 
                                 =
                                 
                                    i
                                    t
                                 
                                 +
                                 θ
                                 
                                    ω
                                    
                                       t
                                       −
                                       1
                                    
                                 
                              
                           
                        
                     
                  

Every time-period the start-up needs to cover for a fixed amount of overhead denoted by H. This includes the cost of staff and infrastructure. The unit cost of buying the items is u and the selling price that the start-up charges per item is s. Demand at a particular time period, t depends on the advertising goodwill ωt
                     . So the different demand possibilities are functions of advertising goodwill values. We denote this relationship by 
                        
                           
                              d
                              t
                           
                           
                              |
                           
                           
                              ω
                              t
                           
                           =
                           ω
                        
                      which implies the demand value dt
                      corresponding to the goodwill value of 
                        
                           
                              ω
                              t
                           
                           =
                           ω
                        
                     . 
                        
                           p
                           (
                           
                              d
                              t
                           
                           |
                           
                              ω
                              t
                           
                           =
                           ω
                           )
                        
                      is the probability that the demand in period t is dt
                      given that the current goodwill is ω. Let Lω
                      denote the maximum possible demand realization corresponding to a goodwill level of ω and the maximum possible goodwill that can be reached is 
                        
                           ω
                           ^
                        
                     . The start-up tries to maximize its profit by coordinating its inventory and advertising strategies. For notational simplicity from here onward we drop the subscript t. With limited access to capital the start-up's decisions at any period are constrained by its cash on hand, c. The inventory on hand at the beginning of each period is denoted by z. We assume that if the demand exceeds the stock on hand then the excess demand is lost.

Start-up operations are fraught with bankruptcy risks. It is extremely important that the firm refrain from decisions that involve exposure to bankruptcy. Therefore, the overall objective of the start-up is to maximize profit but at the same time avoid risky decisions that can lead to bankruptcy. We assume that whenever the current cash on hand c, is negative the firm is driven to bankruptcy. To ensure that the stochastic programming solution avoids decisions that lead to states where cash on hand is negative we penalize them by assuming that whenever cash on hand is negative the firm cannot take any operational decisions, i.e., it is bankrupt and the value for those states are the current negative cash on hand. Let T be the time horizon for the problem. We assume that the inventory at the end of the horizon can be salvaged at a price λ per item (λ < u) and the terminal value for goodwill is zero. Then the state of the system in a time period t can be specified by (c, z, ω). The notations used in the model are presented in Table 1. Let 
                        
                           
                              f
                              t
                              T
                           
                           
                              (
                              c
                              ,
                              z
                              ,
                              ω
                              )
                           
                        
                      be the maximal net present value of being in state (c, z, ω) when optimal actions are taken in each time period from period t to T. The following recursive functional equations specify the model:

If c ≥ 0:

                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             f
                                             t
                                             T
                                          
                                          
                                             (
                                             c
                                             ,
                                             z
                                             ,
                                             ω
                                             )
                                          
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             Max
                                             
                                                q
                                                ,
                                                i
                                             
                                          
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             (
                                             d
                                             |
                                             ω
                                          
                                          
                                             )
                                             
                                                f
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                             (
                                          
                                          c
                                          −
                                          H
                                          −
                                          u
                                          q
                                          −
                                          i
                                          +
                                          s
                                          
                                             d
                                             ˜
                                          
                                          ,
                                          z
                                       
                                    
                                 
                                 
                                    
                                    
                                    
                                       
                                          −
                                          
                                          
                                             d
                                             ˜
                                          
                                          
                                             +
                                             q
                                             ,
                                             θ
                                             ω
                                             +
                                             i
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           
                              d
                              ˜
                           
                           =
                           Minimum
                           
                              (
                              d
                              ,
                              z
                              )
                           
                        
                     
                  

If c < 0:

                        
                           (3)
                           
                              
                                 
                                    f
                                    t
                                    T
                                 
                                 
                                    (
                                    c
                                    ,
                                    z
                                    ,
                                    ω
                                    )
                                 
                                 =
                                 c
                              
                           
                        
                     
                  

The boundary condition is given by:

                        
                           (4)
                           
                              
                                 
                                    f
                                    t
                                    T
                                 
                                 
                                    (
                                    c
                                    ,
                                    z
                                    ,
                                    ω
                                    )
                                 
                                 =
                                 c
                                 +
                                 λ
                                 z
                              
                           
                        
                     
                  

Risk exposure is a critical element of start-up operations. In the next section, we develop a heuristic that can be used to construct efficient risk-reward frontiers for the start-up model.

In this section, we derive a simple easy-to-use methodology to track expected reward as well as variance of a set of possible actions by our Variance-Retentive SP approach and then use the mean-variance solutions in a heuristic to construct near-optimal risk-reward curves. The heuristic is not specific to the start-up model developed in this paper, but can also be applied to many finite-horizon stochastic programming models such as inventory management, capacity expansion, dynamic portfolio management models and so on.

In dynamic stochastic programs, the maximum expected reward for being in any state (c, z, ω) is captured by the functional value 
                        
                           
                              f
                              t
                              T
                           
                           
                              (
                              c
                              ,
                              z
                              ,
                              ω
                              )
                           
                        
                     . To obtain the risk-reward curve we need additional information about the risk associated with each action at each decision epoch. This is a challenging task from an implementation standpoint, since this requires carrying information on both risk and reward for each state. Minimizing variance directly in the objective function is also non-separable in the sense of dynamic programming and hence, we cannot have an objective function that tracks both the mean and the variance of the different actions optimally. In a finite-horizon discrete-time stochastic programming problem, the information about the average reward for a set of optimal actions is carried at each state. This information is then used to compute the average reward at a subsequent state by backward induction. In the RiskTrackr algorithm, we use stochastic programming but with the difference that in addition to carrying information about the average reward, we also keep track of the variance of a set of policies at each state. Here we use two arrays viz. 
                        
                           
                              F
                              t
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      and 
                        
                           
                              V
                              t
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      to capture the values of the average reward and variance at each state of the stochastic program corresponding to the optimal actions q*, i*. In order to figure out the optimal actions at each state we develop a ratio based on average reward to the variance for each of the possible actions. We call this ratio the risk-reward criteria, or “criteria” for short, and denote it by K
                     
                        q, i
                     [c, z, ω]. We denote the variance of the possible outcomes for a set of actions (q, i), at any state (c, z, ω), by γ
                     
                        q, i
                     [c, z, ω] and it is calculated as follows:

                        
                           (5)
                           
                              
                                 
                                    
                                       
                                          
                                             γ
                                             
                                                q
                                                ,
                                                i
                                             
                                          
                                          
                                             [
                                             c
                                             ,
                                             z
                                             ,
                                             ω
                                             ]
                                          
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                V
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                          +
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                F
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             
                                                [
                                                
                                                   c
                                                   ˜
                                                
                                                ,
                                                
                                                   z
                                                   ˜
                                                
                                                ,
                                                
                                                   ω
                                                   ˜
                                                
                                                ]
                                             
                                             2
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                    
                                       
                                          −
                                          
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                F
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                          
                                             μ
                                             
                                                t
                                                +
                                                1
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                       
                                    
                                 
                              
                           
                        
                     where,

                        
                           
                              
                                 
                                    μ
                                    
                                       t
                                       +
                                       1
                                    
                                 
                                 
                                    [
                                    
                                       c
                                       ˜
                                    
                                    ,
                                    
                                       z
                                       ˜
                                    
                                    ,
                                    
                                       ω
                                       ˜
                                    
                                    ]
                                 
                                 =
                                 
                                    ∑
                                    
                                       d
                                       |
                                       ω
                                    
                                 
                                 
                                    p
                                    
                                       (
                                       d
                                       |
                                       ω
                                       )
                                    
                                    
                                       F
                                       
                                          t
                                          +
                                          1
                                       
                                       T
                                    
                                 
                                 
                                    [
                                    
                                       c
                                       ˜
                                    
                                    ,
                                    
                                       z
                                       ˜
                                    
                                    ,
                                    
                                       ω
                                       ˜
                                    
                                    ]
                                 
                              
                           
                        
                     and 
                        
                           
                              c
                              ˜
                           
                           =
                           c
                           −
                           H
                           −
                           u
                           q
                           −
                           i
                           +
                           s
                           
                              d
                              ˜
                           
                           ,
                           
                              z
                              ˜
                           
                           =
                           z
                           −
                           
                              d
                              ˜
                           
                           +
                           q
                           ,
                           
                              ω
                              ˜
                           
                           =
                           θ
                           ω
                           +
                           i
                        
                      are the cash-on-hand, inventory and goodwill at 
                        
                           t
                           +
                           1
                        
                      respectively. The details of the derivation of Eq. (5) are given in Appendix A [1]. Since we are capturing the variance of each action at each stage and state of the stochastic program we call this methodology Variance-Retentive SP.

We calculate the criteria at each state K
                     
                        q, i
                     [c, z, ω] for each possible action (q, i) in the following manner:

                        
                           (6)
                           
                              
                                 
                                    K
                                    
                                       q
                                       ,
                                       i
                                    
                                 
                                 
                                    [
                                    c
                                    ,
                                    z
                                    ,
                                    ω
                                    ]
                                 
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             d
                                             |
                                             ω
                                          
                                       
                                       
                                          p
                                          
                                             (
                                             d
                                             |
                                             ω
                                             )
                                          
                                          
                                             F
                                             
                                                t
                                                +
                                                1
                                             
                                             T
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                       
                                    
                                    
                                       
                                          γ
                                          
                                             q
                                             ,
                                             i
                                          
                                       
                                       
                                          [
                                          c
                                          ,
                                          z
                                          ,
                                          ω
                                          ]
                                       
                                    
                                 
                              
                           
                        
                     
                  

The criteria is similar to the Sharpe ratio (Sharpe, 1994) used in investment analysis. Sharpe ratio is a reward-to-variability ratio that measures the return (or risk premium) per unit of deviation in an investment. We use the criteria value to determine the optimal action i.e. order size and the advertising investment at each decision epoch. At 
                        
                           t
                           =
                           T
                           ,
                        
                      i.e., at the boundary, the variance at any state is zero since no actions are taken, and the reward is given by (4). Then at any preceding decision epoch 
                        
                           (
                           t
                           =
                           T
                           −
                           1
                           ,
                           T
                           −
                           2
                           …
                           ,
                           0
                           )
                        
                      the variance at any state for each of the possible actions is calculated using Eq. (5).

In RiskTrackr, we solve the model (1)–(4) iteratively and at each iteration we sequentially increase the possible actions at any decision epoch i.e. order sizes and advertisement investments that we consider while determining the optimal action. The possible actions that come under consideration at each iteration are determined based on their corresponding criteria values. The number of actions that are considered at each state is denoted by j and the value of j is sequentially incremented by one at each iteration of the heuristic; X denotes the number of all the possible actions in any stage. We first solve the model (1)–(4) by backward recursion for 
                        
                           j
                           =
                           1
                        
                     , i.e., at each state we pick the action that gives the highest criteria value. As we solve the model repeatedly, at each state we rank all the actions in a descending order based on their criteria values. For example, in the kth run of the model we consider the top k actions in each state based on their criteria values and pick the one that corresponds to the maximum average reward. The average reward and variance for the optimal action at any state (c, z, ω) are stored in 
                        
                           
                              F
                              t
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      and 
                        
                           
                              V
                              t
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      respectively. In this process, at any state, we are ranking the actions in descending order based on the criteria values and then we are picking the top j actions. Then out of the top j actions, we are picking the action that gives the maximum reward.

At 
                        
                           t
                           =
                           0
                        
                      for each of the j runs of the Variance-Retentive SP model, 
                        
                           
                              F
                              0
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      and 
                        
                           
                              V
                              0
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      give the average reward and variance for a sequence of optimal actions executed at each of the time periods, 
                        
                           t
                           =
                           0
                           ,
                           …
                           ,
                           T
                           ,
                        
                      based on the top j criteria values. We store the average reward and variance values at 
                        
                           t
                           =
                           0
                        
                     , i.e., 
                        
                           
                              F
                              0
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      and 
                        
                           
                              V
                              0
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      for each of the j runs in E[j] and Var[j] respectively. We continue the above process until 
                        
                           j
                           =
                           X
                           .
                        
                      
                     E[j] and Var[j] 
                        
                           ∀
                           j
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           X
                        
                      are then used to construct the efficient risk-reward curve. The algorithm for the RiskTrackr heuristic is given in Fig. 4
                     . The computational complexity of the stochastic dynamic programming model (1)–(4) is given by O(czωTX) where c, z, ω are the possible state values and c denotes the possible values of cash-on-hand, z denotes the inventory levels and ω denotes the possible advertising goodwill values, T is the number of time-periods in the finite horizon stochastic dynamic programming model and X denotes the number of the possible actions. In the RiskTrackr heuristic the stochastic dynamic programming model (1)–(4) is solved iteratively and at each iteration the possible actions are increased sequentially until all the possible actions have been evaluated. Therefore, the computational complexity of the RiskTrackr heuristic is O(czωTX
                     2).

Solving the start-up model repeatedly for 
                        
                           j
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           X
                        
                      using the Variance-Retentive SP methodology and the RiskTrackr heuristic give us a set of policies for which we have identified average reward as well as variance. Since at each state the actions that lead to maximum average reward over variance (i.e. the criteria value) are being considered for determining the optimal action, we are focusing on the actions that are most efficient at each state and then out of those efficient actions we are picking the one that has the maximum expected reward. Therefore, out of all the possible order sizes and advertising investments the ones that are the most efficient are being picked, i.e., the ones that give the highest average reward with respect to variance. Hence as j is increased the risk exposure of the model is also increased and at a higher risk exposure the action that has the maximum average reward is being picked. This process in turn leads to outcomes starting from very low risk-exposure and increasing to the maximum risk-exposure. Therefore, the curve obtained by the plotting the values of E[j] and Var[j] 
                        
                           ∀
                           j
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           X
                        
                      provides efficient risk-reward frontiers. Managers, using this heuristic, can pick the policies that are on the risk-reward frontier based on their risk tolerance.

We now explain the RiskTrackr heuristic using a numerical example.

Consider a problem with 
                           
                              T
                              =
                              3
                              ,
                           
                         possible order sizes 0,1
                           
                              ,
                              …
                              ,
                           
                        4 and advertising investments going from $0, $1,
                           
                              ,
                              …
                              ,
                           
                        $4. Let the overhead cost be 
                           
                              H
                              =
                              $
                              5
                           
                         and the selling price be 
                           
                              s
                              =
                              $
                              3
                           
                         and the unit cost of an item be 
                           
                              u
                              =
                              $
                              1
                           
                         and the unit cost of increasing the goodwill be $1. Therefore in each state the action set A has 25 possible order-size and advertising investment combinations. Let the salvage value of unsold inventory at the end of the time-horizon be zero. Let θ in this problem be 0.5. Initial cash-on-hand, inventory and goodwill levels are $20, 4 and 3 respectively. Let the maximum goodwill level at any state be five 
                           
                              (
                              
                                 ω
                                 ^
                              
                              =
                              5
                              )
                              .
                           
                         The data used for the numerical example are summarized in Table 2
                        . We start with 
                           
                              j
                              =
                              1
                           
                         and solve the start-up model using the Variance-Retentive SP methodology, which in turn, utilizes backward induction. Suppose in the backward induction algorithm at the boundary, i.e., at 
                           
                              t
                              =
                              3
                              ,
                           
                         a state (30, 3, 2) is reached. We set 
                           
                              
                                 V
                                 3
                                 3
                              
                              
                                 [
                                 30
                                 ,
                                 3
                                 ,
                                 2
                                 ]
                              
                              =
                              0
                           
                         and 
                           
                              
                                 F
                                 3
                                 3
                              
                              
                                 [
                                 30
                                 ,
                                 3
                                 ,
                                 2
                                 ]
                              
                              =
                           
                        
                        
                           
                              
                                 f
                                 3
                                 3
                              
                              
                                 (
                                 30
                                 ,
                                 3
                                 ,
                                 2
                                 )
                              
                           
                        
                        
                           
                              =
                              30
                              .
                           
                         Similarly, for all the terminal states 
                           
                              
                                 V
                                 3
                                 3
                              
                              
                                 [
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 ]
                              
                              =
                              0
                           
                         and 
                           
                              
                                 F
                                 3
                                 3
                              
                              
                                 [
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 ]
                              
                           
                        
                        
                           
                              =
                              
                                 f
                                 3
                                 3
                              
                              
                                 (
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 )
                              
                              =
                              c
                              .
                           
                        
                     

Next suppose at 
                           
                              t
                              =
                              2
                              ,
                           
                         the backward induction algorithm reaches a state (25, 3, 3). Let the demand distribution corresponding to a goodwill level of 3 be given by 
                           
                              p
                              (
                              d
                              =
                              0
                              |
                              ω
                              =
                              3
                              )
                              =
                              0.25
                              ,
                           
                        
                        
                           
                              p
                              (
                              d
                              =
                              1
                              |
                              ω
                              =
                              3
                              )
                              =
                              0.5
                           
                         and 
                           
                              p
                              (
                              d
                              =
                              2
                              |
                              ω
                              =
                              3
                              )
                              =
                              0.25
                              .
                           
                         We need to figure out the expected reward and variance for all the possible actions in state (25, 3, 3). For illustrative purposes we show the functional values for two of the possible 25 order-size and advertising investment options, namely, order-size = 0, advertising investment = $0 and order-size = 1 and advertising investment = $1. The values for the other action sets are calculated in similar fashion. Therefore, 
                           
                              
                                 r
                                 
                                    0
                                    ,
                                    0
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              23
                           
                         & 
                           
                              
                                 r
                                 
                                    1
                                    ,
                                    1
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              22
                              .
                           
                         Next, we show the calculation for γ
                        0, 0[25, 3, 3], γ
                        1, 1[25, 33] and 
                           
                              
                                 K
                                 
                                    0
                                    ,
                                    0
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 33
                                 ]
                              
                              ,
                              
                                 K
                                 
                                    1
                                    ,
                                    1
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              .
                           
                        
                        
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                γ
                                                
                                                   0
                                                   ,
                                                   0
                                                
                                             
                                             
                                                [
                                                25
                                                ,
                                                3
                                                ,
                                                3
                                                ]
                                             
                                             =
                                             4.5
                                             ⇒
                                             
                                                K
                                                
                                                   0
                                                   ,
                                                   0
                                                
                                             
                                             
                                                [
                                                25
                                                ,
                                                3
                                                ,
                                                3
                                                ]
                                             
                                             =
                                             5.11
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                γ
                                                
                                                   1
                                                   ,
                                                   1
                                                
                                             
                                             
                                                [
                                                25
                                                ,
                                                3
                                                ,
                                                3
                                                ]
                                             
                                             =
                                             4.5
                                             ⇒
                                             
                                                K
                                                
                                                   1
                                                   ,
                                                   1
                                                
                                             
                                             
                                                [
                                                25
                                                ,
                                                3
                                                ,
                                                3
                                                ]
                                             
                                             =
                                             4.89
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                f
                                                2
                                                3
                                             
                                             
                                                (
                                                25
                                                ,
                                                3
                                                ,
                                                3
                                                )
                                             
                                             =
                                             
                                                {
                                                
                                                   
                                                      
                                                         …
                                                      
                                                      
                                                         …
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               q
                                                               2
                                                            
                                                            =
                                                            0
                                                            ,
                                                            
                                                               i
                                                               2
                                                            
                                                            =
                                                            0
                                                            :
                                                         
                                                      
                                                      
                                                         
                                                            0.25
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               20
                                                               ,
                                                               3
                                                               ,
                                                               1.5
                                                               )
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                      
                                                         
                                                            
                                                            +
                                                            0.5
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               23
                                                               ,
                                                               2
                                                               ,
                                                               1.5
                                                               )
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                      
                                                         
                                                            
                                                            +
                                                            0.25
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               26
                                                               ,
                                                               1
                                                               ,
                                                               1.5
                                                               )
                                                            
                                                            =
                                                            23
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               q
                                                               2
                                                            
                                                            =
                                                            1
                                                            ,
                                                            
                                                               i
                                                               2
                                                            
                                                            =
                                                            1
                                                            :
                                                         
                                                      
                                                      
                                                         
                                                            0.25
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               19
                                                               ,
                                                               4
                                                               ,
                                                               2.5
                                                               )
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                      
                                                         
                                                            
                                                            +
                                                            0.5
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               22
                                                               ,
                                                               3
                                                               ,
                                                               2.5
                                                               )
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                      
                                                         
                                                            
                                                            +
                                                            0.25
                                                            
                                                               f
                                                               3
                                                               3
                                                            
                                                            
                                                               (
                                                               25
                                                               ,
                                                               2
                                                               ,
                                                               2.5
                                                               )
                                                            
                                                            =
                                                            22
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         …
                                                      
                                                      
                                                         …
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Similarly, we need to figure out the criteria values for the other 23 possible actions and rank them in descending order. Here 
                           
                              j
                              =
                              1
                              ,
                           
                         i.e., we are only considering the action that gives the maximum criteria value and so in this case, the optimal action will be the one that gives the maximum criteria value. When j > 1, we will consider the top j actions with criteria values and then pick the one among them that leads to maximum average reward. Let 
                           
                              
                                 K
                                 
                                    0
                                    ,
                                    0
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              5.11
                           
                         be the maximum of the criteria values. Then the optimal action at 
                           
                              t
                              =
                              2
                           
                         is order-size and advertising investment equal to 0 and $0 respectively. Therefore, 
                           
                              
                                 r
                                 
                                    0
                                    ,
                                    0
                                 
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              
                                 r
                                 *
                              
                           
                         and 
                           
                              
                                 f
                                 2
                                 3
                              
                              
                                 (
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 )
                              
                              =
                              
                                 F
                                 2
                                 3
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              23
                           
                         and 
                           
                              
                                 V
                                 2
                                 3
                              
                              
                                 [
                                 25
                                 ,
                                 3
                                 ,
                                 3
                                 ]
                              
                              =
                              4.5
                              .
                           
                        
                     

We continue the backward induction in our Variance-Retentive SP approach until 
                           
                              t
                              =
                              0
                              ,
                           
                         where we repeat the above process of evaluating the criteria values for each of the possible order-sizes and advertising decisions based on the average reward and variance of the subsequent states. Then we pick the optimal action by ordering the criteria values in descending order and picking the one that has the maximum criteria value. Suppose the optimal order-size and advertising investment at 
                           
                              t
                              =
                              0
                           
                         is 1 and $1 respectively and the corresponding average reward and variance are 30 and 10 respectively. Therefore, 
                           
                              
                                 f
                                 0
                                 3
                              
                              
                                 (
                                 20
                                 ,
                                 4
                                 ,
                                 3
                                 )
                              
                              =
                              
                                 F
                                 0
                                 3
                              
                              
                                 [
                                 20
                                 ,
                                 4
                                 ,
                                 3
                                 ]
                              
                              =
                              30
                           
                         and 
                           
                              
                                 V
                                 0
                                 3
                              
                              
                                 [
                                 20
                                 ,
                                 4
                                 ,
                                 3
                                 ]
                              
                              =
                              10
                              .
                           
                         We store the average reward and variance value at 
                           
                              t
                              =
                              0
                           
                         in 
                           
                              E
                              [
                              j
                              =
                              1
                              ]
                              =
                              30
                           
                         and 
                           
                              Var
                              [
                              j
                              =
                              1
                              ]
                              =
                              10
                              .
                           
                        
                     

Next, we increment 
                           
                              j
                              =
                              2
                           
                         and solve the start-up model again starting with the initial state (20, 4, 3) and using backward induction algorithm. As before at the terminal states 
                           
                              
                                 V
                                 3
                                 3
                              
                              
                                 [
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 ]
                              
                              =
                              0
                           
                         and 
                           
                              
                                 F
                                 3
                                 3
                              
                              
                                 [
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 ]
                              
                              =
                              
                                 f
                                 3
                                 3
                              
                              
                                 (
                                 c
                                 ,
                                 z
                                 ,
                                 ω
                                 )
                              
                              =
                              c
                              .
                           
                         Now suppose at a subsequent time-period 
                           
                              t
                              =
                              1
                              ,
                           
                         the problem reaches the state (20, 2, 2). We now figure out the criteria values for each of the possible actions. We sort the actions in descending order based on the criteria values. Then we consider the actions with respect to the top two criteria values. Let the top two actions with the corresponding functional values be:

                           
                              
                                 
                                    
                                       f
                                       1
                                       3
                                    
                                    
                                       (
                                       20
                                       ,
                                       2
                                       ,
                                       2
                                       )
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   
                                                      q
                                                      1
                                                   
                                                   =
                                                   1
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      i
                                                      1
                                                   
                                                   =
                                                   3
                                                
                                             
                                             
                                                :
                                             
                                             
                                                22
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      q
                                                      1
                                                   
                                                   =
                                                   2
                                                   ,
                                                
                                             
                                             
                                                
                                                   
                                                      i
                                                      1
                                                   
                                                   =
                                                   2
                                                
                                             
                                             
                                                :
                                             
                                             
                                                24
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Here the maximum average reward corresponds with the order size and advertising investment equal to 2 and $2 respectively. Therefore, 
                           
                              
                                 r
                                 *
                              
                              =
                              24
                           
                         and the optimal actions in the state (20, 2, 2) are order-size and advertising investment equal to 2 and $2 respectively. We store the variance and average reward values corresponding to order-size = 2 and advertising investment = $2 in 
                           
                              
                                 V
                                 1
                                 3
                              
                              
                                 [
                                 20
                                 ,
                                 2
                                 ,
                                 2
                                 ]
                              
                           
                         and 
                           
                              
                                 F
                                 1
                                 3
                              
                              
                                 [
                                 20
                                 ,
                                 2
                                 ,
                                 2
                                 ]
                              
                           
                        .

We continue the backward induction until 
                           
                              t
                              =
                              0
                              .
                           
                         Using the actions corresponding to the top two criteria values we pick the optimal action based on the maximum average reward. We store the average reward and the variance corresponding to the optimal actions at 
                           
                              t
                              =
                              0
                           
                         in 
                           
                              E
                              [
                              j
                              =
                              2
                              ]
                           
                         and 
                           
                              Var
                              [
                              j
                              =
                              2
                              ]
                           
                         respectively. Next, we again increment 
                           
                              j
                              =
                              3
                           
                         and continue the above process. We do this until 
                           
                              j
                              =
                              25
                           
                        . We then use the E[j] and 
                           
                              Var
                              [
                              j
                              ]
                              ∀
                              j
                              =
                              1
                              ,
                              2
                              ,
                              …
                              ,
                              25
                           
                         to construct the risk-reward curve.

Now, we need to check the performance of our heuristic in constructing efficient risk-reward curves. We do so by comparing the risk-reward frontier obtained by our heuristic against the risk-reward associated with all enumerated outcomes of the start-up model.

The mean-variance solutions and the efficient frontiers so obtained using RiskTrackr is an approximation to the actual mean-variance frontiers. In this section we check the performance of RiskTrackr heuristic in constructing efficient risk-reward curves by comparing it against the risk and reward associated with the enumerated solutions of the start-up model. We also compare the performance of RiskTrackr against six other heuristics viz. “500-Random”, “1000-Random”, “Greedy-Max Exp Reward”, “Greedy-Min Var”, “Min VaR” and “Min CVaR”. In the “500-Random” and “1000-Random” heuristics we randomly pick 500 and 1000 solutions respectively from the enumerated solutions of the start-up model and use the corresponding expected rewards and variances to construct the risk-reward curves. In the “Greedy-Max Exp Reward” heuristic we iteratively solve the stochastic programming model (1)–(4). In the first iteration we greedily pick the action that provides the highest expected reward, followed by the second iteration where we pick the second highest expected reward and so on. We also track the corresponding variance of these solutions and then use the variance of the solutions at different levels of the expected rewards to construct the risk-reward curves. In the “Greedy-Min Var” heuristic we iteratively solve the stochastic programming model (1)–(4). Here in the first iteration we greedily pick the action that provides the lowest variance, followed by the second iteration where we pick the second lowest variance and so on. We also track the corresponding expected reward of these solutions at and then use the expected rewards of the solutions at different levels of variances to construct the risk-reward curves. In the “Min VaR” heuristic we iteratively solve the stochastic programming model (1)–(4) and at each state we only consider the actions based on the Value-at-Risk (VaR) cut-offs. In the first iteration we only consider the actions corresponding to VaR at 50 percent confidence level and then pick the action that gives the maximum expected reward. We also keep track of the variance of the rewards for that particular action. In the second iteration we only consider the actions corresponding to VaR at 55 percent confidence level and then pick the action that gives the maximum expected reward and also keep track of the variance of the rewards for that particular action. We continue this process until the VaR cut-off is at 95 percent confidence level. Finally, we use the expected reward and the variance of the solutions at different VaR cut-offs to construct the risk-reward curves. The “Min CVaR” heuristic is similar to the “Min VaR” heuristic except that in “Min CVaR” the actions are based on Conditional Value-at-Risk (CVaR) cut-offs at 50 percent, 55 percent, 60 percent
                           
                              ,
                              …
                              ,
                           
                        95 percent confidence levels.

Next we explain our methodology to enumerate all the risk-reward solutions in a finite horizon stochastic program where innumerable states could be traversed by the problem based on the actions sets and the probability branches. Enumerating all the possible outcomes based on all the actions at each of the states can be a complicated and cumbersome task. Here we come up with a simple yet useful method of enumerating the outcomes of a finite-horizon stochastic program and calculating the variance and expected reward of each of those outcomes. Next, we present the steps of our method for enumerating the possible outcomes.

We start from the initial time period, 
                           
                              t
                              =
                              0
                              ,
                           
                         and randomly pick an order quantity and advertising investment from the action set A. Once the actions at a particular state are chosen we know what are the possible states that the problem branches out to. Then at each of the subsequent states we randomly chose the order quantity and advertising investment. We keep track of the decisions at each state and store the information in a policy table. The process of randomly picking the actions is continued until the horizon 
                           
                              (
                              t
                              =
                              T
                              )
                           
                         is reached. Then we run Monte-Carlo simulations at each of the probability nodes to determine the demand and figure out the path traversed starting from the initial time-period to the boundary for the actions in the policy table that we obtained. We run the Monte Carlo simulations for N number of times. N should be a large integer so that most of the demand probabilities are simulated which ensures that all the possible paths for a particular set of actions in the policy table are traversed. For the N simulations, we calculate the average reward and the variance of the possible outcomes. Finally, we repeat the process M number of times. M should also be large positive integer so that all the possible actions are picked at each of the states.

We now compare the performance of our heuristic against the efficient frontier of the enumerated solutions and the six heuristics mentioned above for different values of the parameters of the start-up model. We present the results for different levels of initial cash-on-hand, inventory and goodwill and different kinds of demand distributions viz., right-skewed, bell-shaped and left-skewed. The demand distributions used are presented in Appendix A [2]. For the performance evaluation, we picked a three-period problem with maximum goodwill level equal to five in each state. The maximum order size and advertising investment at any state are 5 and $5 respectively. The possible order sizes are 0,1
                           
                              ,
                              …
                              ,
                           
                        4, 5 and advertising investments going from $0, $1
                           
                              ,
                              …
                              ,
                           
                        $4, $5. So there are 36 different possible actions 
                           
                              (
                              X
                              =
                              36
                              )
                           
                        . Let the overhead cost 
                           
                              H
                              =
                              $
                              5
                           
                         and the selling price be 
                           
                              s
                              =
                              $
                              3
                           
                         and the unit cost of an item be 
                           
                              u
                              =
                              $
                              1
                           
                         and the unit cost of increasing the goodwill be $1. Let θ in this problem be 0.5. We have assumed that there are five goodwill levels 1, 2
                           
                              ,
                              …
                              ,
                           
                        5 and four demand possibilities 0, 2, 4 and 6 at each goodwill level.

We used a small-dimension problem here so that our enumeration algorithm can evaluate nearly all the possible risk-reward outcomes. The problem considered above has around 1000 possible paths and equivalent number of possible solutions. We then compare the performance of the risk-reward curve obtained from RiskTrackr against the enumerated efficient frontier. For the risk-reward outcomes in the enumerated solutions we used 
                           
                              N
                              =
                              10
                              ,
                              000
                           
                         and 
                           
                              M
                              =
                              10
                              ,
                              000
                              .
                           
                         These high values of N and M ensure that nearly all the possible outcomes are enumerated for the relatively small-dimension problem used. Since we used an increment factor of one in the RiskTrackr heuristic we needed to run it 36 times 
                           
                              (
                              X
                              =
                              36
                              )
                           
                         to get the risk-reward frontier. Therefore, out of thousand possible solutions our heuristics picks 36 that are on the efficient frontier. For the problems studied here the RiskTrackr heuristic took around 20 minutes to run on a 2 gigahertz PC whereas for the same problems to enumerate all the solutions it took around 4 hours.

In Tables 3 and 4
                         we present the performance evaluation results of the efficient frontier constructed by RiskTrackr compared to the enumerated efficient frontier and the risk-reward frontiers obtained by the six other heuristics viz. “500-Random”, “1000-Random”, “Greedy-Max Exp Reward”, “Greedy-Min Var”, “Min VaR” and “Min CVaR” for different demand distributions at different values of initial cash-on-hand, inventory and goodwill levels. In Table 3, we look at the mean percentage deviation of the efficient frontiers obtained by RiskTrackr and the other four heuristics from the enumerated efficient frontier. We calculate the percentage deviations of the mean-variance solutions obtained by the different heuristics with the enumerated mean-variance solutions and then calculate the average of the percentage deviations, which we call mean percentage deviation. We find that on average the mean percentage deviation of RiskTrackr from the enumerated efficient frontier is 0.14 percent whereas for “500-Random” it is 69.9 percent, for “1000-Random” it is 53.44 percent, for “Greedy-Max Exp Reward” it is 43.01 percent, for “Greedy-Min Var” it is 31.94 percent, for “Min VaR” it is 21.73 percent and for “Min CVaR” it is 20.52 percent. Hence, the above results confirm that the performance of RiskTrackr is significantly better than the other six heuristics and the accuracy of the risk-reward frontier obtained by RiskTrack is creditable.

In Table 4, we compare the heuristics based on another performance measure viz. Hit-Rate. We define Hit-Rate of a heuristic as the percentage of risk-reward solutions with deviations from the enumerated efficient frontier. We calculated the reward at various levels of risk along the risk-reward frontiers and computed the Hit-Rate of the heuristics at 0 percent, < 1 percent, < 2 percent, < 3 percent and < 5 percent deviations from the enumerated efficient frontier. For example, Hit-Rate at < 5 percent deviations calculates the percentage of the mean-variance solutions obtained by the various heuristics that are deviating less than 5 percent from the enumerated mean-variance solutions. For presentation brevity, in Table 4, we only present the results of the Hit-Rate at 0 percent and < 5 percent deviations. We find that the Hit-Rate of the RiskTrackr heuristic is 100 percent at the < 5 percent level whereas for “500-Random” it is 17 percent, for “1000-Random” it is 26 percent, for “Greedy-Max Exp Reward” it is 41 percent, for “Greedy-Min Var” it is 56 percent, for “Min VaR” it is 65 percent and for “Min CVaR” it is 68 percent. The above accuracy results justify the superior performance of RiskTrackr in constructing efficient frontiers. In Fig. 5 we graphically present the Hit-Rate of the RiskTrackr efficient frontier at different levels of deviations for the different demand distributions.

Next, we focus on the critical managerial insights for a start-up firm based on its risk-sensitivity.

First, we analyze the inventory and advertising decisions of the start-up at different levels of risk tolerance. Here we study the decisions that lead to the most efficient outcomes, i.e., the ones that earned the highest reward at a particular level of risk. At each level of risk tolerance, we find the percentage of total investments that goes into building inventory and that goes into advertising. We ran the model for different demand distributions and various values of the exogenous parameters such as cash-on-hand, goodwill and inventory levels. For simulating different demand distributions we used the beta distribution and discretized it to obtain different demand distributions by varying the values of the two parameters of the beta distribution, α and β. Beta distribution has been extensively used in a wide variety of applications because of its flexibility in generating different kinds of probability distributions (see, for example, Basu & Nair, 2012; Choobinah & Branting, 1986; Fry, Magazine, & Rao, 2006; Lieckens, Colen, & Lambrecht, 2013; Tripathi, Nair, & Karuga, 2009). We consider 10 different levels of goodwill going from 1 to 10. We assume that the maximum goodwill that can be earned is 10 
                        
                           (
                           =
                           
                              ω
                              ˜
                           
                           )
                           .
                        
                      At each goodwill level demand possibilities are 0, 5, 10 and 15 with the probability weights determined by the discretized beta distribution.

Here we present the results for initial cash-on-hand, inventory and goodwill levels of $80, 7 and 5 respectively. We kept 
                        
                           u
                           =
                           $
                           1
                        
                      and assume that $1 needs to be invested in advertising to increase the goodwill by a unit amount. The unit selling price is $5 and the overhead at each time-period is $10. The maximum order size and advertising investment at any state are 16 and $25 respectively. θ in this problem is kept at 0.5. The time horizon for this problem is set at 
                        
                           T
                           =
                           7
                           .
                        
                      We ran the model for various other datasets and obtained similar results however for presentation brevity and illustrative purposes, we use the results for the above dataset. On a 2 gigahertz PC it took around 5 hours for RiskTrackr to provide the risk-reward solutions for these larger sized problem sets. We present the results in Fig. 6.
                     
                     
                  

We find that at low levels of risk tolerance the firm puts most of its investment in advertising (Fig. 6a). Advertising investments increases the level of goodwill. At a higher level of goodwill, the firm stands a higher chance of selling the stock-on-hand. At low risk tolerance the total investments are also low (Fig. 6b). At this low level of total investment the firm puts most of its money in advertising. This decreases the variability in the possible outcomes. Therefore, a start-up firm that wants to operate at very low risk tolerance should invest conservatively and the percentage investment should be higher for advertising than inventory.

With increasing risk tolerance the total investments of the firm increases (Fig. 6b). We also find that as risk tolerance increases, the firm invests more in inventory and the percentage of investments that goes into advertising decreases (Fig. 6a). With increasing investments in inventory, the firm takes more risks because the additional inventory runs the risk of less than expected sales. Lastly at very high risk exposures the firm invests most aggressively and has the highest percentage investment in inventory and the lowest percentage investment in advertising. High investments in inventory increase the risk exposure of the firm. Hence, managers who are exceedingly risk-taking should put more of their funds in inventory than in advertising in comparison to a manager who is risk-sensitive. Risk-sensitive managers need to invest more in advertising to hedge against the risk of lower sales.

Next, we study the percentage of investible funds that are really invested at different risk levels of risk tolerance. The results are presented in Fig. 6(b). In order to take efficient decisions the firm needs to increase the percentage of investible funds that it really invests as its risk-exposure increases. At low levels of risk the firm invests only a small percentage of the investible funds. This, however, increases at higher risk exposures where the firm invests almost 100 percent of the investible funds.

Next, we analyze the total investments and percentage of total investments in inventory and advertising under changing demand variability. Here we ran the model for different demand distributions that have same mean but different variance. The parameters of the beta distribution used to generate the demand distributions are given in Appendix A [3]. As before, for all the different demand distributions the possible demand realizations are 0, 5, 10 and 15. Our results are presented in Fig. 7
                     . We find that at low risk tolerance percentage invested in inventory is highest when demand variance is the least (Fig. 7a). When demand is steady, i.e., when the demand variability is marginal the firm puts most of its investments into inventory. The reason behind this is when demand is steady even at low levels of risk tolerance the firm is exposed to very little risks in terms of lower than expected sales. Therefore, the firm invests more in inventory. However if the demand variability is high the risks due to insufficient demand realization increases and so the firm decreases its percentage investments in inventory at low levels of risk tolerance. Overall, as risk tolerance increases percentage invested in inventory increases. On the other hand, percentage of total investments that goes into advertising is highest when demand variability is maximum (Fig. 7b) and overall percentage invested in advertising decreases with risk tolerance. At low risk tolerance the firm puts most of its investments in advertising to hedge against lower than expected sales. If the goodwill levels are high the firm stands a higher chance of making sales. At high demand variability there is higher risks of lower than expected sales and to counter the additional risks the firm invests more in advertising. With increase in risk tolerance, the percentage invested in advertising decreases. Then the focus shifts to building inventory and taking more risks in order to earn more rewards.

Next,we analyze the total investments made by the firm at different levels of risk exposure with changing demand variability (Fig. 7c). We find that at very low levels of risk tolerance total investments are maximum when demand variance is the least. That is the firm invests more when the demand is steady. This makes sense because when the demand variability is low the risks due to insufficient demand realization are also low. Therefore, at low risk tolerance the firm invests the most when demand variability is the least. However, at moderate levels of risk tolerance, total investments are higher when demand variance is high. Here the firm is more risk tolerant and hence is willing to take more risks in order to earn additional rewards and so invests more at higher demand variability. At very high levels of risk tolerance the firm invests comparably at all levels of demand variability. Here demand variability plays no major role in the investments made by the firm as the firm is open to taking high risks.

Start-up operations are markedly different from operations in an established firm. Often start-ups are capital constrained. The set of policies that can be employed by an established firm cannot be implemented in a start-up. There is considerable debate about how the strategies of a start-up differ from those of a well-established firm. In this paper we focus on two important operational decisions of a start-up viz. its inventory and advertising policies. The start-up needs to balance their advertising and inventory policies. On one hand, carrying too much inventory exposes the firm to the risks of less than expected sales and on the other hand advertising heavily without much regard to stocking policies can be fatal. Risk exposure is another critical element of start-up operations. It is imperative for a start-up firm to weigh the risks associated with any set of optimal policies. Focusing just on the expected reward can be detrimental for the start-up. However, at the same time too conservative decisions can be damaging as risks lead to growth and without growth there is high chance of stagnation and eventual termination.

In this paper, we develop a dynamic stochastic programming model to capture the temporal aspects of the sequential decision problems faced by the start-ups. In most of the literature on stochastic programming models, the focus is on maximizing the sum of expected rewards. To capture the risks associated with a set of policies we develop an easy to implement approach, Variance-Retentive SP, that tracks the variance of the possible outcomes in addition to the expected rewards and use the mean-variance solutions in a heuristic. This heuristic, which we call RiskTrackr, can be used to construct near-optimal risk-reward curves. Based on the risk-reward curves, managers can employ strategies that would be in-line with their risk sensitivity. We find that at low levels of risk tolerance it is optimal to put most of the investment in advertising whereas at higher levels of risk tolerance majority of the investment needs to go into inventory. The heuristic developed in this paper is quite general in nature and can be applied to a broad variety of stochastic dynamic problems.

There is limited research on balancing risk and reward in operations management literature. While financial planning models often incorporate risk measures along with expected reward criteria as in the mean-variance analysis of portfolio selection, much of the operations literature ignores the risks associated with operational decisions. Majority of operational decisions such as capacity planning, facility location, materials planning or inventory control are based on maximizing the expected rewards or minimizing the expected costs with minimal attention to the associated risks. Risk exposure is more so important for start-ups. Examining the operational policies of a start-up such as its trade credit decisions, capacity planning decisions, supply chain issues under risk-reward trade-offs can be interesting future research topics. Here we have looked at variance of the possible outcomes as a risk measure. How to include other well-established risk criteria in finance such as average downside risk (ADR) or value at risk (VaR) in a sequential decision problem can be another interesting research study. In the model developed in the paper we assume that running short on inventory and losing demand has no impact on the reputation of the start-up. In reality, unsatisfied demand could have a significant effect on the company's reputation. Therefore, running out of inventory could pose a risk on the survival of the firm. Modeling this effect on reputation and possibly bankruptcy could be an interesting future research endeavor.


                     [1] Derivation of 
                     
                        Eq. (5)
                     
                     :
                  

If a random variable Z takes values Xi
                      with probability pi
                     , 
                        
                           i
                           =
                           1
                           ,
                           2
                           ,
                           …
                           ,
                           n
                           ,
                        
                      then

                        
                           
                              
                                 
                                    
                                       
                                          E
                                          (
                                          Z
                                          )
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          E
                                          
                                             [
                                             E
                                             
                                                (
                                                Z
                                                |
                                                
                                                   X
                                                   1
                                                
                                                ,
                                                
                                                   X
                                                   2
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   X
                                                   n
                                                
                                                )
                                             
                                             ]
                                          
                                          =
                                          E
                                          
                                             [
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                p
                                                i
                                             
                                             
                                                X
                                                i
                                             
                                             ]
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                p
                                                i
                                             
                                             
                                                E
                                                (
                                             
                                             
                                                X
                                                i
                                             
                                          
                                          
                                             )
                                             =
                                          
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                p
                                                i
                                             
                                             
                                                μ
                                                i
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           
                              μ
                              i
                           
                           =
                           E
                           
                              (
                              
                                 X
                                 i
                              
                              )
                           
                        
                     .

The future states in the dynamic programming problem are random variables because the future states depend on chance or the probability nodes. Therefore, for our problem Z is the present state at t and Xi
                     ’s are the states that can be traversed in t + 1.

                        
                           
                              
                                 
                                    Now
                                    ,
                                 
                                 
                                 E
                                 
                                    (
                                    
                                       Z
                                       2
                                    
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    p
                                    i
                                 
                                 E
                                 
                                    (
                                    
                                       X
                                       i
                                       2
                                    
                                    )
                                 
                              
                           
                        
                     
                  

The variance of Xi
                      is given by: 
                        
                           
                              σ
                              i
                              2
                           
                           =
                           E
                           
                              (
                              
                                 X
                                 i
                                 2
                              
                              )
                           
                           −
                           
                              μ
                              i
                              2
                           
                        
                     . Then,

                        
                           
                              
                                 E
                                 
                                    (
                                    
                                       Z
                                       2
                                    
                                    )
                                 
                                 =
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    p
                                    i
                                 
                                 
                                    (
                                    
                                       σ
                                       i
                                       2
                                    
                                    +
                                    
                                       μ
                                       i
                                       2
                                    
                                    )
                                 
                              
                           
                        
                     
                  

Now the variance of Z, denoted by Var(Z) is given by:

                        
                           (7)
                           
                              
                                 
                                    
                                       
                                          Var
                                          (
                                          Z
                                          )
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          E
                                          
                                             (
                                             
                                                Z
                                                2
                                             
                                             )
                                          
                                          −
                                          
                                             
                                                [
                                                E
                                                (
                                                Z
                                                )
                                                ]
                                             
                                             2
                                          
                                          =
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                p
                                                i
                                             
                                             
                                                (
                                             
                                             
                                                σ
                                                i
                                                2
                                             
                                          
                                          +
                                          
                                             μ
                                             i
                                             2
                                          
                                          
                                             )
                                             −
                                          
                                          
                                             
                                                
                                                   (
                                                   
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         n
                                                      
                                                      
                                                         p
                                                         i
                                                      
                                                      
                                                         μ
                                                         i
                                                      
                                                   
                                                   )
                                                
                                             
                                             2
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                p
                                                i
                                             
                                             
                                                σ
                                                i
                                                2
                                             
                                          
                                          +
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                p
                                                i
                                             
                                             
                                                μ
                                                i
                                                2
                                             
                                          
                                          −
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             n
                                          
                                          
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                p
                                                i
                                             
                                          
                                          
                                             p
                                             j
                                          
                                          
                                             μ
                                             i
                                          
                                          
                                             μ
                                             j
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

In our start-up model, Eqs. (2)–(4), from any state (c, z, ω) at time t, the problem goes to the possible states in 
                        
                           t
                           +
                           1
                        
                      with probability p(d|ω) based on actions q and i. Then using Eq. (7), the variance for any action set q and i, at any state (c, z, ω) is then given by:

                        
                           
                              
                                 
                                    
                                       
                                          
                                             γ
                                             
                                                q
                                                ,
                                                i
                                             
                                          
                                          
                                             [
                                             c
                                             ,
                                             z
                                             ,
                                             ω
                                             ]
                                          
                                       
                                    
                                    
                                       =
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                V
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                          +
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                F
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             
                                                [
                                                
                                                   c
                                                   ˜
                                                
                                                ,
                                                
                                                   z
                                                   ˜
                                                
                                                ,
                                                
                                                   ω
                                                   ˜
                                                
                                                ]
                                             
                                             2
                                          
                                       
                                    
                                 
                                 
                                    
                                    
                                    
                                       
                                          −
                                          
                                          
                                             ∑
                                             
                                                d
                                                |
                                                ω
                                             
                                          
                                          
                                             p
                                             
                                                (
                                                d
                                                |
                                                ω
                                                )
                                             
                                             
                                                F
                                                
                                                   t
                                                   +
                                                   1
                                                
                                                T
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                          
                                             μ
                                             
                                                t
                                                +
                                                1
                                             
                                          
                                          
                                             [
                                             
                                                c
                                                ˜
                                             
                                             ,
                                             
                                                z
                                                ˜
                                             
                                             ,
                                             
                                                ω
                                                ˜
                                             
                                             ]
                                          
                                       
                                    
                                 
                              
                           
                        
                     where,

                        
                           
                              
                                 
                                    μ
                                    
                                       t
                                       +
                                       1
                                    
                                 
                                 
                                    [
                                    
                                       c
                                       ˜
                                    
                                    ,
                                    
                                       z
                                       ˜
                                    
                                    ,
                                    
                                       ω
                                       ˜
                                    
                                    ]
                                 
                                 =
                                 
                                    ∑
                                    
                                       d
                                       |
                                       ω
                                    
                                 
                                 
                                    p
                                    
                                       (
                                       d
                                       |
                                       ω
                                       )
                                    
                                    
                                       F
                                       
                                          t
                                          +
                                          1
                                       
                                       T
                                    
                                 
                                 
                                    [
                                    
                                       c
                                       ˜
                                    
                                    ,
                                    
                                       z
                                       ˜
                                    
                                    ,
                                    
                                       ω
                                       ˜
                                    
                                    ]
                                 
                              
                           
                        
                     and 
                        
                           
                              c
                              ˜
                           
                           =
                           c
                           −
                           H
                           −
                           u
                           q
                           −
                           i
                           +
                           s
                           
                              d
                              ˜
                           
                           ,
                           
                              z
                              ˜
                           
                           =
                           z
                           −
                           
                              d
                              ˜
                           
                           +
                           q
                           ,
                           
                              ω
                              ˜
                           
                           =
                           θ
                           ω
                           +
                           i
                        
                      are the cash-on-hand, inventory and goodwill at 
                        
                           t
                           +
                           1
                        
                      respectively. The variance at any state (c, z, ω) is denoted by 
                        
                           
                              V
                              t
                              T
                           
                           
                              [
                              c
                              ,
                              z
                              ,
                              ω
                              ]
                           
                        
                      and it is the variance corresponding to the optimal action set q*, i*. The expected reward corresponding to the optimal actions is denoted by 
                        
                           
                              F
                              t
                              T
                           
                           
                              [
                              
                                 c
                                 ˜
                              
                              ,
                              
                                 z
                                 ˜
                              
                              ,
                              
                                 ω
                                 ˜
                              
                              ]
                           
                           .
                        
                     
                  


                     [2] Demand distribution with different shapes used in Section 4.3:
                     
                        
                           
                              
                              
                              
                              
                              
                              
                              
                                 
                                    
                                    
                                    Demand structure

                                 
                                 
                                    
                                    
                                    Demand possibilities

                                 
                                 
                                    
                                    
                                    0
                                    2
                                    4
                                    6
                                 
                                 
                                    
                                    Goodwill
                                    Probability distribution of demand
                                 
                              
                              
                                 
                                    
                                       Right skewed
                                    
                                    1
                                    0.31
                                    0.65
                                    0.02
                                    0.02
                                 
                                 
                                    
                                    2
                                    0.27
                                    0.69
                                    0.02
                                    0.02
                                 
                                 
                                    
                                    3
                                    0.2
                                    0.76
                                    0.02
                                    0.02
                                 
                                 
                                    
                                    4
                                    0.15
                                    0.81
                                    0.02
                                    0.02
                                 
                                 
                                    
                                    5
                                    0.1
                                    0.86
                                    0.02
                                    0.02
                                    
                                 
                                 
                                    
                                       Bell-shaped
                                    
                                    1
                                    0.2
                                    0.3
                                    0.3
                                    0.2
                                 
                                 
                                    
                                    2
                                    0.15
                                    0.35
                                    0.35
                                    0.15
                                 
                                 
                                    
                                    3
                                    0.1
                                    0.4
                                    0.4
                                    0.1
                                 
                                 
                                    
                                    4
                                    0.08
                                    0.42
                                    0.42
                                    0.08
                                 
                                 
                                    
                                    5
                                    0.05
                                    0.45
                                    0.45
                                    0.05
                                    
                                 
                                 
                                    
                                       Left skewed
                                    
                                    1
                                    0.02
                                    0.02
                                    0.65
                                    0.31
                                 
                                 
                                    
                                    2
                                    0.02
                                    0.02
                                    0.69
                                    0.27
                                 
                                 
                                    
                                    3
                                    0.02
                                    0.02
                                    0.76
                                    0.2
                                 
                                 
                                    
                                    4
                                    0.02
                                    0.02
                                    0.81
                                    0.15
                                 
                                 
                                    
                                    5
                                    0.02
                                    0.02
                                    0.86
                                    0.1
                                 
                              
                           
                        
                     
                  


                     [3] Beta parameters for demand distributions with changing variance used in 
                     
                        Section 5
                     
                     :
                     
                        
                           
                              
                              
                              
                              
                              
                              
                              
                              
                              
                              
                                 
                                    
                                    Very low
                                    Low variance

                                    High variance

                                    Very high
                                 
                                 
                                    
                                    variance

                                    
                                    
                                    variance

                                 
                                 
                                    Goodwill
                                    α
                                    β
                                    α
                                    β
                                    α
                                    β
                                    α
                                    β
                                 
                              
                              
                                 
                                    1
                                    0.75
                                    3.15
                                    0.5
                                    2.1
                                    0.25
                                    1.05
                                    0.13
                                    0.53
                                 
                                 
                                    2
                                    0.75
                                    2.85
                                    0.5
                                    1.9
                                    0.25
                                    0.95
                                    0.13
                                    0.48
                                 
                                 
                                    3
                                    0.75
                                    2.55
                                    0.5
                                    1.7
                                    0.25
                                    0.85
                                    0.13
                                    0.43
                                 
                                 
                                    4
                                    0.75
                                    2.4
                                    0.5
                                    1.6
                                    0.25
                                    0.80
                                    0.13
                                    0.40
                                 
                                 
                                    5
                                    0.75
                                    2.25
                                    0.5
                                    1.5
                                    0.25
                                    0.75
                                    0.13
                                    0.38
                                 
                                 
                                    6
                                    0.75
                                    2.1
                                    0.5
                                    1.4
                                    0.25
                                    0.70
                                    0.13
                                    0.35
                                 
                                 
                                    7
                                    0.75
                                    1.95
                                    0.5
                                    1.3
                                    0.25
                                    0.65
                                    0.13
                                    0.33
                                 
                                 
                                    8
                                    0.75
                                    1.8
                                    0.5
                                    1.2
                                    0.25
                                    0.60
                                    0.13
                                    0.30
                                 
                                 
                                    9
                                    0.75
                                    1.65
                                    0.5
                                    1.1
                                    0.25
                                    0.55
                                    0.13
                                    0.28
                                 
                                 
                                    10
                                    0.75
                                    1.5
                                    0.5
                                    1
                                    0.25
                                    0.50
                                    0.13
                                    0.25
                                 
                              
                           
                        
                     
                  

@&#REFERENCES@&#


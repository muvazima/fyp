@&#MAIN-TITLE@&#Steerable pyramid transform and local binary pattern based robust face recognition for e-health secured login

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Face recognition system using steerable pyramid transform and local binary pattern is proposed.


                        
                        
                           
                           Zero-norm minimization and local learning based algorithms are used for feature selection.


                        
                        
                           
                           99.28% accuracy was obtained in FERET database with fb set.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Steerable pyramid transform

Local binary pattern

e-Health

Face recognition

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

In an e-Health framework, patients may not be able to speak or write username and password to authenticate him; however, his face is still available and can easily be deployed as a login modality. This aspect of face recognition is less researched in the literature, though a general face recognition research is somewhat matured. Face recognition is considered as one of the noninvasive biometrics, which is widely used in many security systems.

Over the last 10 years, research about recognizing a face takes a popular area over other biometric systems. That because it's a balance between security, as it can be done efficiently without user cooperation or knowledge and social acceptances as it does not require electro-magnetic illumination generating and does not restrict user movement, so it is nowadays relatively inexpensive. Due to these reasons, face recognition is one of the popular choices in many security and law enforcement applications [1].

Hundreds of research works in this area are still published to achieve a higher recognition rate for that incompletely solved problem because of the dynamic structure of faces and different conditions that human faces’ images can be varied on such as illumination, facial expression, makeup, eyeglasses, poses, etc. The current research involves developing a robust face recognition system against age, ethnicity, and occlusion.

Recognizing any pattern must consist of two primary steps. First is the feature extraction and the second is the pattern classification. In case of the feature extraction, there are many methods starting from the simplest one that uses pixel intensities as features. The second method is transforming subspaces of pixel intensities into a low dimensional space in the form of either principal component analysis (PCA), linear discrimination analysis (LDA) or independent component analysis (ICA). The third method uses texture information in the form of a local binary pattern (LBP), histogram of gradients (HoG), or Weber local descriptor (WLD). Nevertheless, another method utilizes multi-resolution transform techniques, such as wavelets, which extract features efficiently by analyzing images into distinct scales of resolution, which gives different sub bands from the same face. After decomposition, the components, which are less sensitive to distortion due to illumination and expressions, are taken [2].

There are two types of face features: holistic and local. The holistic features (also named as appearance or global features) are the overall face features that are extracted from each face as a single vector. In addition, it cannot deal with the variation of pose effectively such as local features because of its high sensitivity to rotation and translation. The famous holistic approaches are LDA and PCA. The local feature in contrast can be extracted out of many parts (such as noise, mouth, eyes and so on) from the face with its local statistics (such as appearances and geometric) and location as multiple vectors for each face. In another word, it measures the geometric relationship and properties such as distances, angles, areas between the important facial points. There are features that are a combination of holistic and local features. In such case, the face image is divided into blocks, and some feature extraction techniques are applied to these blocks [3].

Automatic face recognition is not a new area of research; however, the challenge is still there. The recognition performance significantly decreases with certain factors, such as, rotation, illumination, resolution, noise, etc. Especially, in an e-Health framework, patients face may not align directly to the camera; illumination may vary in different rooms; and noise can be added through transmission. To date, a good performance is achieved by using local features such as LBP or WLD, because these features are robust against some types of geometric modifications. Multi-resolution techniques such as wavelets and their variants are sometimes used to divide the face image into subbands of various scales and orientations for an improved performance. In particular, Gabor filters are fused with the LBP to produce a better descriptor than the LBP alone in the literature. Of them, Local Gabor Binary Pattern (LGBP) histogram, Histogram of Gabor Phase Patterns (HGPP), and Learned Local Gabor Patterns (LLGP) produced good results in several databases [4–6]. The main problem of using Gabor filters is its high computational cost, because each kernel needs to be convolved by the face image [7]. Similarly, the features based on wavelet decomposition are not good if the faces are captured in an uncontrolled environment.

Other variants of wavelets, such as contourlet and curvelet were also investigated in literature. Contourlet with PCA was used to extract face features in [8], and curvelet coefficients from different resolution face images were used in a classifier fusion approach of face recognition in [9]. These methods are also computationally expensive because, some of these transforms require quantized image in addition to the original image. Some recent face recognition systems can be found in [10,11], while some applications of multimedia on this topic can be found in [12,13].

In this paper, steerable pyramid transform (SPT) and LBP based face recognition system is proposed. SPT can decompose a face image into several orientations and in different resolutions. The first scale representations have the same resolution of the original image. SPT was used in several applications of image processing, for example, image denoising [14], forgery detection [15], and texture classification [7]. It has also been investigated in the face recognition system [16]; however, it was not fully explored there. The contributions of this work are (i) the development of an SPT-LBP based face recognition system, (ii) a thorough investigation of different subbands of the SPT towards the recognition of face, and (iii) a selection of subbands that achieve optimum results.

The organization of rest of the paper is as follows. Section 2 explains the proposed SPT-LBP based face recognition system for an e-Health care framework, Section 3 describes the experiments and results, and Section 4 gives the conclusion of the paper.

A framework of an e-Healthcare system, where face is used as a secured login for the patients is shown in Fig. 1
                     . A mobile device in the form of a smart phone takes the face picture of the patient, and along with medical data, the face data is transferred to the cloud using the Internet. A cloud manager initiates the process of authentication by asking a resource allocation manager to distribute several tasks, including feature extraction and classification/recognition of the face. If the face is already enrolled in the system, the manager allows the medical data to be further processed, otherwise, it may ask the user for enrollment. A collaborative service manager manages the tasks of different virtual machines (VMs). The VMs are linked to a number of servers, which are responsible for distinctive executions such as feature extraction, classification, etc. The processed medical data will be made available to registered medical doctors.


                     Fig. 2
                      illustrates the process-flow of the proposed face recognition system. The input image is divided into several subbands using the SPT. The subbands are block-divided and LBP histograms are calculated from each block of the subbands. The histograms from the blocks and from the subbands are fused to construct a final feature set.

Linear transforms represent the base for many techniques in the area of image processing, image analysis and image coding. An important subclass of linear transforms is subband transforms such as SPT. SPT is a powerful image decomposition technique, which divides an image in many scales and orientations. It is a particular variant of the well-known recursive and multi-scale wavelet transform. The basis functions of SPT are derivative operators in many directions, which involves variable sizes [17].

SPT decomposes an image recursively into subbands of different scales and orientations. The orientation bandwidth of these subbands equal to 2π/o, where o represents the number of orientations. Recursive convolutions followed by decimation operations are used to perform SPT. The resultant subbands of SPT are translation and rotation invariant [18,19]. Fig. 3
                         illustrates a block diagram for a first derivative in two scales SPT (both analysis and synthesis). Initially, the image is decomposed into low and high frequency components by applying filters L0 and H0, respectively. The low frequency component is again decomposed into low frequency component and two oriented band-pass components by applying low-pass filter L1, and oriented bandpass filters B0 and B1, respectively. The low frequency part is also down-sampled by a factor of two. In Fig. 3, the shaded part can be inserted into the unfilled small circle to produce a recursive steerable pyramid. The frequency domain output of this system is given by (1).

                           
                              (1)
                              
                                 
                                    
                                       I
                                       ^
                                    
                                    
                                       (
                                       
                                          ω
                                          →
                                       
                                       )
                                    
                                    =
                                    
                                       {
                                       
                                          
                                             
                                                
                                                   |
                                                   
                                                      
                                                         H
                                                         0
                                                      
                                                      
                                                         (
                                                         
                                                            ω
                                                            →
                                                         
                                                         )
                                                      
                                                   
                                                   |
                                                
                                             
                                             2
                                          
                                          +
                                          
                                             
                                                
                                                   |
                                                   
                                                      
                                                         L
                                                         0
                                                      
                                                      
                                                         (
                                                         
                                                            ω
                                                            →
                                                         
                                                         )
                                                      
                                                   
                                                   |
                                                
                                             
                                             2
                                          
                                          
                                             (
                                             
                                                
                                                   
                                                      
                                                         |
                                                         
                                                            
                                                               L
                                                               1
                                                            
                                                            
                                                               (
                                                               
                                                                  ω
                                                                  →
                                                               
                                                               )
                                                            
                                                         
                                                         |
                                                      
                                                   
                                                   2
                                                
                                                +
                                                
                                                   ∑
                                                   
                                                      K
                                                      =
                                                      0
                                                   
                                                   N
                                                
                                                
                                                   
                                                      
                                                         |
                                                         
                                                            
                                                               B
                                                               K
                                                            
                                                            
                                                               (
                                                               
                                                                  ω
                                                                  →
                                                               
                                                               )
                                                            
                                                         
                                                         |
                                                      
                                                   
                                                   2
                                                
                                             
                                             )
                                          
                                       
                                       }
                                    
                                    I
                                    
                                       (
                                       
                                          ω
                                          →
                                       
                                       )
                                    
                                    +
                                    a
                                    .
                                    t
                                    .
                                 
                              
                           
                        where a.t. indicates ‘aliasing terms’. To avoid ‘aliasing terms’, filter L1 should have zero magnitude response for frequencies greater than one-fourth of the sampling frequency.

The orientation of the filters used in SPT construction is fulfilled by satisfying the following two conditions of steerability:

                           
                              1.
                              A filter is rotated and copied to produce another filter. Therefore, all the filters are copy-rotated of their counterparts.

A linear combination of the basis filters can produce a filter of any orientation [18,19].

Increasing the derivative degree (more number of orientations) and the number of pyramid levels, yields finer scale and orientation tuning, which means more robust representation of an image. On the other hand that increases the computation time. In this study, a trade-off is supposed by using the third derivative (4 different orientations) in three levels pyramid. Fig. 4
                         illustrates the details of steerable pyramid filter bank structure used in this study. Fig. 5
                         illustrates an example of the output decomposed image of such a system.

In Fig. 5, there are 12 different subbands located in three scales and four orientations in addition to the lowest frequency and highest frequency residual subbands (the highest frequency residual subband is not shown). All the basis functions that used to produce these subbands (except for the initial high pass subband and the final low pass subband) are related to each other by some sort of translation, dilation or rotation [18].

In this stage, each suuband is convolved with the well-known texture descriptor LBP, yielding different LBP normalized histograms. Each histogram belongs to a specific subband. Different combinations of histograms are fused to produce feature vectors with different lengths. First, the subband images are decomposed into several blocks from where LBP histograms are calculated. Then the histograms from the subbands are fused to produce the features to be fed into a classifier. The procedure is illustrated in Fig. 6.
                        
                        
                     

LBP is one of the simplest yet effective local texture descriptor. In a basic LBP calculation, the neighboring pixels’ gray-scale intensities are threshold by the gray-scale intensity of the center pixel in a 3×3 neighborhood (Fig. 7). If the intensity of a neighboring pixel is higher than or equal to the intensity of the center pixel, a ‘1’ is assigned; otherwise, a ‘0’ is assigned for that neighboring pixel. These binary numbers of the neighborhoods are concatenated to produce an 8-bit binary number, which is then converted into a decimal number. This decimal value is assigned to the center pixel [22].

There are several limitations of the basic LBP; one of them is the failure to capture information in a broad context, because of 3×3 neighborhood. To overcome this limitation, circular neighborhood in different scales was proposed [22]. If the neighborhood points on the circle do not exactly match with the pixel intensities, a bilinear interpolation was used, allowing the provision of having any number of neighborhood points at any radius. If the radius of the circle is R, and there are P number of neighbors in that circle, the LBP of a center pixel (x
                        c, y
                        c) is calculated by using Eq. (2).

                           
                              (2)
                              
                                 
                                    L
                                    B
                                    
                                       P
                                       
                                          P
                                          ,
                                          R
                                       
                                    
                                    
                                       (
                                       
                                          
                                             x
                                             c
                                          
                                          ,
                                          
                                             y
                                             c
                                          
                                       
                                       )
                                    
                                    =
                                    
                                    
                                       ∑
                                       
                                          p
                                          =
                                          0
                                       
                                       
                                          P
                                          −
                                          1
                                       
                                    
                                    f
                                    
                                       (
                                       
                                          
                                             i
                                             p
                                          
                                          −
                                          
                                             i
                                             c
                                          
                                       
                                       )
                                    
                                    
                                       2
                                       P
                                    
                                 
                              
                           
                        where ic
                         and ip
                         are gray-level values of the center pixel and P neighborhood pixels, and function f(x) is defined by Eq. (3).

                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             f
                                             
                                                (
                                                x
                                                )
                                             
                                             =
                                             
                                             
                                                {
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            ,
                                                         
                                                      
                                                      
                                                         
                                                            i
                                                            f
                                                            
                                                            x
                                                            ≥
                                                            0
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         
                                                            0
                                                            ,
                                                         
                                                      
                                                      
                                                         
                                                            i
                                                            f
                                                            
                                                            x
                                                            
                                                            <
                                                            
                                                            0
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

A histogram of the LBP is used as features [22].

Next step of the proposed system is the feature selection. The number of features using LBP in all subbands is quite large, more than 3500. In one hand, this high number of features makes the system slow; on the other hand, not all the features are equally important. Therefore, we applied some feature selection techniques to reduce the number of features without compromising with the accuracy. In the proposed system, two stages of features’ selection are applied. In the first stage, a zero-norm minimization technique reduces the number of features according to statistical significance, and in the second stage, the number is further reduced by using a local learning based algorithm (LLB) that removes redundancy [15]. The weight threshold of the LLB is fixed to 10−10. The number of selected features is this threshold dependent. For example, for the threshold 10−10, the number of selected features is 50.

In the experiments, a classifier based on minimum chi-square (CS) distance was used. In the literature, CS distance measure is proved to be efficient in features like LBP histograms [22]. CS distance is calculated by using Eq. 4.

                           
                              (4)
                              
                                 
                                    C
                                    S
                                    
                                       (
                                       x
                                       ,
                                       y
                                       )
                                    
                                    =
                                    
                                       
                                          
                                             ∑
                                             j
                                          
                                          
                                             
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            x
                                                            j
                                                         
                                                         −
                                                         
                                                            y
                                                            j
                                                         
                                                      
                                                      )
                                                   
                                                
                                                2
                                             
                                             
                                                
                                                   x
                                                   j
                                                
                                                +
                                                
                                                   y
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where, xj
                         and yj
                         are the jth bin of input face histogram x and the template face histogram y.

@&#EXPERIMENTS@&#

In this section, we describe the database used for the experiments, the experimental setup, obtained results, and provide discussion.

The facial recognition technology (FERET) database [23] is a widely used face image database used for face recognition applications. This is a challenging database in the sense that the number of face images per subject is less, and the images were taken in varying conditions. The training set, which is known as set fa, contains 1204 frontal face images of 403 male and 403 female participants. There are several testing sets, which are known as set fb, set fc, set dup I, and dup II. The face images in fb were taken seconds after taking images in set fa for the corresponding participants. There are 1196 face images in fb set. The face images in dup I and dup II were taken months after taking images for fa set. We did not use set fc.

Matlab 7.12.0 (R2011a) in a 64-bit system was used in this study to develop the proposed face recognition system. The proposed system was evaluated as a whole system as well as subband by subband. LBP with 8 points on a circle of radius one was used. Comprehensive experiments were carried out using fb probe set. Once all the parameters were fixed, two other probe sets were used.

@&#RESULTS@&#


                        Fig. 8
                         shows face recognition accuracies (%) using different scales of SPT for a fixed orientation (orientation 1). From the figure, we see that the scale 1 (S1) achieved the highest accuracy, followed by S2 and S3.


                        Fig. 9
                         shows accuracies (%) obtained by different oriented subbands for fixed scale 1. The accuracies did not change much, where orientation 1 had the highest accuracy. Fig. 10
                         displays the accuracies of different scale subbands by combining all the orientation subbands for a particular scale.

By combining all the subbands, an accuracy of 98.14% was obtained by the proposed system.

We now report the performance of the proposed system using feature selection. In the feature selection process, we applied a zero-norm minimization to rank the features according to descending order of statistical significance. Top 50% of the features were selected. These selected features were filtered using the LLB. The features that had weights higher than a specific threshold were finally selected for the classifier.

The proposed system is computationally not expensive. To verify the identity of the face, the system took less than 0.3s on the average. In the cloud environment, the transmission time can be added to this time.

The face recognition accuracy of the proposed system was compared with that of other similar systems, and the performance comparison is shown in
                        Table 2
                        . The accuracies of the compared systems were obtained from the reported accuracies in the corresponding papers including [24]. From the table, we see that the proposed system outperformed all other compared system in all the three sets.

@&#CONCLUSION@&#

SPT-LBP based face recognition system was proposed. The proposed system was evaluated in FERET database. 99.28% accuracy was obtained with fb probe set, while 80.17% and 79.54% accuracies were obtained with dup I and dup II dataset, respectively. This accuracy is higher than that using similar systems with Gabor filters. In the experiments, scale 1, which has the same resolution of the input image, got the higher accuracy than that using other scales; however, the combination of the subbands was the best. From the obtained results, we can find the followings:

                        
                           •
                           Local texture descriptor applied to different subbands of a multiresolution decomposition of a face image increases the accuracy of a face recognition system.

Though various subbands have different face recognition accuracies, the best accuracy is achieved by concatenating features from all the subbands.

The proposed system will be evaluated on other face databases in a future study.

@&#ACKNOWLEDGMENT@&#

The authors extend their appreciation to the Deanship of Scientific Research at King Saud University, Riyadh, Saudi Arabia for funding this work through the research group Project no. RGP-1436-023
               

@&#REFERENCES@&#


@&#MAIN-TITLE@&#A literature review on the levels of automation during the years. What are the different taxonomies that have been proposed?

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We present a literature review of the evolution of the levels of autonomy.


                        
                        
                           
                           We gather and compare the literature on taxonomies on levels of automation.


                        
                        
                           
                           We present the differences between the proposed taxonomies.


                        
                        
                           
                           We survey the term adaptive automation, a new trend in the literature on autonomy.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Levels of autonomy

Autonomy/automation

Taxonomies

Adaptive automation

@&#ABSTRACT@&#


               
               
                  In this paper we present a literature review of the evolution of the levels of autonomy from the end of the 1950s up until now. The motivation of this study was primarily to gather and to compare the literature that exists, on taxonomies on levels of automation. Technical developments within both computer hardware and software have made it possible to introduce autonomy into virtually all aspects of human-machine systems. The current study, is focusing on how different authors treat the problem of different levels of automation. The outcome of this study is to present the differences between the proposed levels of automation and the various taxonomies, giving the potential users a number of choices in order to decide which taxonomy satisfies their needs better. In addition, this paper surveys deals with the term adaptive automation, which seems to be a new trend in the literature on autonomy.
               
            

@&#INTRODUCTION@&#

Looking through history, people have confronted the introduction of automation with scepticism especially in the beginning. The first major demonstration of concern for the potentially negative social impacts of labour-saving machinery was the Luddite movement in the early 1800s (Brain, 1998). During that time English workmen attempted to prevent the use of knitting machinery in their industry by destroying it. Later on, in the 1950s Diebold coined the term “automation” (Diebold, 1952). To his disappointment he discovered soon after that the term had already been used by an executive of the Ford Motor Company. Diebold, however, still stated that “automation is a new word denoting both automatic operation and the process of making things automatic” (Diebold, 1952).

Since then, automation has made a lasting entry into the world of manual labour, and as a result many functions and operations previously performed by humans have been taken over by machines. This change has come with the benefit of replacing lots of manual labour, and has resulted in an increase of productivity in terms of energy and materials saving, improvement of quality, accuracy and precision. What has been really achieved with automation, however, is the shift of the role of the operator from manual to supervisory control (Sheridan and Verplank, 1978). As a result, instead of performing tasks like activating manual switches and following operation procedures, they perform the intellectual or cognitive tasks of diagnosis, planning and problem solving (Liu and Hwang, 2000). Automation systems can be designed and employed in a way to secure a best-fit for the capabilities, advantages and disadvantages of both human and machine.

All this human-machine interaction and cooperation can be expressed by various Levels of Automation (LOA). Each of these levels specify a different degree to which a task is automated. This implies that automation is not all or none, but can vary across a continuum of intermediate levels, between fully manual performance and fully autonomous conditions at the two extremes. Several different LOA have been proposed by different researchers, resulting in numerous taxonomies describing the interaction between humans and machines.

The scope of this paper is to gather the proposed approaches on taxonomies of LOA in an attempt to bring this vast literature together. In addition, the authors try to summarize, categorize and compare the different approaches.

When we started to dig into the literature concerning the LOA, the authors came across with the two words “autonomy” and “automation”. In Section 2, we tried to find (if any) similarities/differences between them and clarify the way they should be used. Furthermore, subsection 3.1 deals with the different LOA proposed by different researchers and subsection 3.2 presents a comparison and summary of them. In Section 4, we present the terms of adaptive, adjustable and adaptable automation. Finally, in Section 5 the conclusions are drawn. The tables describing analytically the taxonomies proposed by different authors are presented in the Appendix of the document, in an attempt to keep the core of the paper shorter and simpler for the reader to follow. We make some short descriptions of the proposed taxonomies in Section 3.1 and in addition the full taxonomy is presented in the Appendix.

In this section, the interpretation of the words autonomy and automation is discussed. Our scope is to investigate if there exists any difference between them. In fact knowing how these two terms are used is a necessary precondition for analysing the literature on this subject.

Historically the word autonomy appears first while the word autonomy is launched later on (http://www.oxforddictiona). Many authors do understand the difference between these two words and several amongst them tend to use them interchangeably. On the other hand, there are some studies in which the two words are used as distinct terms ((Clough, 2002a), (Clough, 2002b)). We have made an extensive search into what exists in the literature and how different authors treat both words. Let us introduce first the etymologies of the two words as they exist in the dictionaries and in addition an extended study on how authors tend to use them is going to be presented.

The word “autonomy” has been launched in the early 17th century, originating from the greek word “autonomia/autonomous” which means “auto = self” and “nomos = law”, independent and self-governing ((http://dictionary.cambrid), (http://dictionary.referen)). The word by itself is a concept found in different kinds of sciences, like engineering, philosophy, biology and medicine. As far as the engineering etymology is concerned, the word autonomy is used in order to describe the ability of an engineering system to make its own decisions about its actions while performing different tasks, without the need for the involvement of an exogenous system or operator (Albus et al., 1998). Since each engineering system has a certain degree of autonomy associated with it, autonomy means independence from an outside supervisor, which may be another engineering system or a human. As a result, autonomous systems can make a choice free from outside influence since they have some perceivable notion of “free will”, and autonomy is the ability of the system to change its initially programmed way of action, to the degree that it has been decided a priori by the designer of the system.

The word “automation” was introduced in the mid of the 19th century and is inspired by the earlier word automatic ((http://dictionary.cambrid), (http://dictionary.referen)). Automation includes the execution by a machine agent of a function that was previously carried out by a human ((Parasuraman, 2000), (Parasuraman and Riley, 1997)). This can concern different control systems for operating equipment in numerous applications such as chemical and power plants, aircraft and air traffic control, automobiles, ships, unmanned vehicles and robots, heating and air conditioning in buildings, business systems, medical devices, home appliances, military systems and stand-alone computers are used in order to name only a few examples. However, the concept of automation has changed through time. It can e.g. mean a simple reallocation of a function from human to machine which is complete and permanent. In that case, the function will tend to be seen simply as machine operation not as automation (Parasuraman and Riley, 1997). To summarize, the word automation refers to a system that will do exactly what it is programmed by the programmer to do without having any choice or possibility to act in any different way dependent on the situation at hand. Its actions are predefined from the beginning and it has no ability to change them into the future.

It seems that at least as far as the etymologies are concerned the two words have two different meanings ((http://dictionary.cambrid), (http://dictionary.referen)). The question that arises is: “Do these terminologies follow the scientific literature as well?” The answer to that question is not easy. It seems that in engineering terms the authors tend to use them interchangeably.

In Table 1
                      we have summarized scientific papers dealing with autonomy and/or automation. This summary indicates that most of the authors tend to use the word automation over the word autonomy even when referring to a system that is “free to make choices”. One conjecture is that many authors are more familiar with the word automation and hence tend to use that in favor of the word autonomy. This is done even when referring to what other authors call the Levels of Autonomy ((Johnson et al., 2009), (Parasuraman, 2005)), thereby denoting what seems to be the more or less identical term Levels of Automation ((Parasuraman, 2000), (Endsley and Kaber, 1999), (Fereidunian et al., 2007a), (Hancock, 2013), (Hancock et al., 2013), (Miller and Parasuraman, 2007), (Onnasch et al., 2014), (Parasuraman et al., 2000)). We have no indication that there is a difference one word has been used over the other.

All the previous observations lead to the conclusion that there is no constant way of using both words and that there is quite a lot of flexibility on how they can be used. As far as this paper is concerned we decided to treat the two words as distinct, being constant to the meanings described in dictionaries - thereby using the term “autonomous system” when we refer to a system that “has the freedom to make choices”. Although we try to be consistent with the usage of the words autonomy and automation, quite often we need to reproduce them both, in the way the authors use them since we think it is inappropriate to change their terminology. So, when presenting a taxonomy, or reproducing some points from another study we do that without criticising or distinguishing the terms, we just present them the way the authors do staying consistent to their nomenclature.

This section is the core of the study. Its scope is to present the different approaches on LOA as proposed in the literature so far. In the beginning of the section we present analytically the approaches that are included in the paper, and in the sequel we try to summarize them in a common table (see Fig. 1
                     ) trying to make some sort of categorization. The scope of this table is to give the readers the opportunity, to find any possible differences and similarities between them. The sumarization done is trying to give an answer to the following key questions:
                        
                           1.
                           Why do different authors use a differing number of LOA?

What are the differences and similarities between the different LOA of different authors?

Can different taxonomies be combined in a proper way so that new taxonomies can evolve?

Do there exist more or less used LOA? What does this mean in practice? Which are these levels?

Which is (if it exists) the “best taxonomy” of LOA proposed? How can a reader decide which is the best taxonomy for his/her needs?

This subsection includes most of the previous presented approaches on LOA that we had access to in the well known article databases. No novel approach has been excluded from the study at least deliberately, but we decided not to include similar approaches by the same authors unless there was some kind of differentiation of his/her previously proposed work.

This study begins with an approach that seems to be one of the most widely cited and used taxonomies amongst the ones that have been presented so far. This is the approach proposed by Sheridan and Verplank (1978) and Sheridan (1992). Their analytic approach is one of the oldest taxonomies that can be found in the literature and has been the basis for many others presented later on. Sheridan and Verplank identified six functions that either a human operator or a computer could maintain during teleoperation control. They included commands like gets, selects, starts, requests, approves and tells. They offer a detailed explanation on how the human operator and the computer are supposed to cooperate with each other and how they can change roles under different LOA. In that sense, they actually introduce 10 LOA, proposing a variety of choices regarding the cooperation of operator and machine varying from fully manual to fully computer automated, giving an analytical description of who can be in control in every stage. The levels they propose are presented and analysed in Table 5 in the Appendix.

A decade later, in 1987, Endsley (1987) presented a more compact taxonomy consisting of a model of 4 LOA for an advanced cockpit developed in the context of the use of expert systems to supplement human decision making for automated systems control (the human operator is the pilot in this approach). She identified 4 functions during which the human operator or the machine had the possibility to be in charge. These functions included suggest, concur, veto and act. She offered her 4 different LOA, which are described in detail in Table 6 in the Appendix. It seems that her taxonomy has different boundaries than the one by Sheridan and Verplank (1978) and Sheridan (1992). The main differences between the approaches are 1) the fact that she skips the fully manual level and 2) she gives less in-between options as far as the intermediate levels of automation are concerned. In that sense her approach eliminates or amplifies the power of the system over the human. There exists a variation that extends from the possibility of the human acting upon system recommendation to being completely excluded from the loop by having the system deciding and acting on an autonomous way. Central to this study is the fact that any possible considerations of pilot workloads, situation awareness, performance, and acceptance are key to the successful design and implementation of expert systems which will truly enhance the pilot in the performance of his tasks.

Endsley's approach is followed by Ntuen and Park (1988) and Ntuen and Park (1996), who progressed her approach by just adding a first level of fully manual teleoperation. Their final approach consistes of 5 levels, 4 of which are identical with Endsley's.

In the following year 1989, Riley (1989) published a novel proposal different in layout from the approaches that have been presented up to that time. This means that the authors approached the taxonomy problem in a completely different way. They did not only care about the level of autonomy that they were going to use, but they also introduced the idea of the system's intelligence. In that sense the taxonomy is presented as a 2-D matrix the rows of which corresponded to the LOA while the columns to the Levels of Intelligence. Each combination of a level of intelligence and a level of autonomy is referred to as an “automation state”, and each state corresponds to a unique, predefined form. The taxonomy is presented in Tables 7 and 8, and Fig. 2 in the Appendix. In this approach each succeeding level of intelligence subsumes all the previous ones. The number of levels he uses (12 levels) is the largest amongst all presented authors. However he remained loyal to the boundaries of fully autonomous and fully manual levels. Between these levels, the first six ones were created based on the sophistication of the machine's information processing functions and authority to manipulate the human operator's displays. In addition, the next six ones, starting from the level named servant, give the machine the ability and opportunity to take actions. In this case, the distinction between the different levels is made based on the permission and override protocol between the operator and machine. In this approach the user has more things to take into consideration, when deciding which is the proper combination for each different operation that he is going to carry.

Yet a different taxonomy for sorting human mediated control of remote manipulator systems is proposed several years later by Miligram et al. (1995) in the content of tele-robot control. Their research is based on a 3-D approach which includes the degree of machine autonomy, the level of structure of remote environment, and the extent of knowledge or modellability of the remote world. As far as the LOA are concerned, they propose a taxonomy of five levels considering the different roles a human operator could play in telerobot control, including decision maker and direct controller (trading off decision making and other elements of the control system is a key aspect that must be considered as far as the human operator role is concerned (Burtnyk and Greenspan, 1991)). The taxonomy proposed is presented in the Appendix in Table 9.

Later on, Endsley and Kiris (1995) focused on the out of the loop performance problem, which excludes the human from the ability to take over manual control in the event of a of failure. Their objective was to identify LOA that sufficiently maintained human operators in the control loop during normal system functioning to permit manual task performance during automation failures. They suggested that implementing automation while maintaining a high level of control for the human operator provides definite benefits in minimizing the out of the loop performance problem, as compared with full automation. This usage of a lower LOA, which maintained the human operator in the loop is beneficial to situation awareness and participants are better able to perform tasks manually when needed. The levels of automation as presented by the authors are equal to the ones described in (Endsley, 1987) with the addition of the fully manual level.

The same year as Endsley and Kiris (1995) and Draper (1995) presented a taxonomy by introducing a different layout from the ones already presented. This approach combines human operators with machine control in a teleoperator capable of carrying out functions that can be either semi-autonomous or fully autonomous. In his research, he identified nine degrees of automation functions. Amongst these functions five are carried out by the human operators and the other four are allocated to the machine. He categorizes his functions to levels of control, machine roles, human tasks and critical information. The levels of control continuum as presented by him are described analytically in Table 10 in the Appendix.

Building on Draper's research (Draper, 1995) and by evolving their own previous approach (Endsley, 1987), Endsley and Kaber (1999) presented a new taxonomy of 10 levels to be used in the context of teleoperation. Their work provided wider applicability to a range of cognitive and psychomotoric tasks requiring real time control in different domains like air traffic control, aircraft piloting, advanced manufacturing and teleoperation. All these domains share common characteristics. This taxonomy provided advantages over the previous proposed ones in the sense that it identified numerous LOA combinations which were not included in other taxonomies proposed by different researchers. Their approach described with detail “who” (human or system) is supposed to do “what” (task) at each level as compared to the previous hierarchies of degrees of autonomy. In all levels there is a distinction on who has the greater authority, the human or the machine, and this was described and analysed thoroughly. The levels of autonomy proposed are presented in Table 11 in the Appendix.

Later on, Parasuraman et al. (2000), building on their previous approaches ((Sheridan and Verplank, 1978), (Sheridan, 1992)), started to emphasize the different aspects of human machine interaction that could be noticed. In that sense, they proposed that automation could be applied across four different classes of input functions named as they are presented in Table 2
                        . The above described model did not explicitly provide LOAs, like the ones presented until that time, but rather stipulated that each of the four factors can be automated at a different level. Within each of these types, automation can be applied across a continuum of levels from low to high, i.e., from fully manual to fully automatic. They also proposed that any particular level of automation should be evaluated by examining its associated human performance consequences. These constitute primary evaluative criteria for levels of automation. However, human performance is not the only important factor. Secondary evaluative criteria include automation reliability and the costs of decision/action consequences. These should also be applied to evaluate the feasibility and appropriateness of particular levels of automation.

In 2001, the year after the approach of Parasuraman et al., Lorenz et al. (2001) presents a more compact taxonomy than the previous ones, consisting of only three LOA. This one is a quite simple approach taking into account only three principles that they considered important. Thus, the levels introduced are: 1) The Base Line, 2)The Automation Support and 3)The Automation Support Failure Level. These levels do not follow directly the fully manual fully autonomous principles during the Automation Support Level. The operator can choose between the alternatives when presented with suggested actions by the automation system: 1) to agree before the veto time has elapsed, 2) to disagree by pressing a button and 3) to give no response which would be considered as a silent agreement. In case of an acceptance the suggested actions were implemented automatically and the operator was notified about all actions and their outcome until full recovery was achieved but could not intervene. A rejection from the side of the operator would be equivalent to a switch to manual fault management. This is what differentiates this approach to the previous ones: it takes into account the fault management level. The levels of this taxonomy analytically are presented in Table 12 in the Appendix.


                        Clough, (2002a) presented a taxonomy with a specific application on Unmanned Aerial Vehicles. In his approach autonomy was split into four different levels which depend on the amount of human interaction and the point at which it occurs. These different levels of automation are presented in Table 13.

Clough's approach has been followed by Proud et al. (2003) who presented a taxonomy of automation with eight different levels. This approach was also different than the one dimensional approaches that have been presented until now. It corresponded to complete human and computer responsibility respectively, (similar to Sheridan's scale and degrees of automation). They tailored each level of autonomy scale to fit the tasks encompassed by a function type or column: observe, orient, decide, or act. In order to explain the taxonomy, one needs to remember that each of the columns has a different meaning. Observe column refers to gathering, monitoring, and filtering data. Column orient refers to deriving a list of options through analysis, trend prediction, interpretation and integration. In addition, the levels in the decide column refer to decision-making based on ranking available options, and the levels in the act column refer to execution or authority to act on the chosen option. What these columns manage to ensure, is that individual levels in each scale are relatively consistent in magnitude of change between levels across the function types. Generally, the levels of autonomy can be broken down into three different sections: (a) the ones where the human is primary and the computer is secondary (Level 1–2), (b) the ones where the computer operates with the human interaction (Levels 3–5) and (c) the ones where the human has decreasing access to information and decreasing override capability (Levels 6–8). It is very important to understand the differences between the levels in order to interpreter them correctly. The Table 14 in the Appendix presents the taxonomy analytically.

The last and most recent approach presented in this paper is the one by Fereidunian et al. (2007b), Fereidunian et al. (2007a), who presented a methodology which is an extension of the well established LOA proposed by Sheridan (1992), switch due to the implementation requirements. In the current approach, the automation scheme proposed deals with 11 LOA instead of the original 10-levels one. The level 1 of the original Sheridan's taxonomy is shifted down to form a new level 0, and a new level named 1∗ is introduced (The computer acquires the date from the process and registers them without analysis). The taxonomy as proposed by Feredunian et al., is presented with details in Appendix in Table 15.

The different taxonomies presented in the previous subsection share many similarities and differences as well, when viewed in detail. The goal of this subsection is to summarize them and try to reach some conclusions regarding the previous approaches. The most important thing, and the first one to be considered, is the number of LOA that each approach includes in its taxonomy. However, there are more things that need to be taken into consideration when comparing different LOA approaches. Practically, the comparison that is carried, is based on giving satisfactory answers to the following questions:
                           
                              1.
                              How many different LOA exist in each taxonomy?

Which levels of one taxonomy are similar to the levels of another?

Are there some levels amongst the different taxonomies that can be combined?

Do there exist more popular and less popular levels?

The answers to these questions will be given by a special table created by the authors presented in Fig. 1. The left column of the table includes all the possible LOA that have been proposed by all studies included in this paper. At each level (table row) a code name has been given, the one that makes it easier for the reader to understand which level it is. Each table row shares the same properties when it comes to levels of autonomy, i.e. every row corresponds to a specific level of automation that has been presented. Each one of the columns corresponds to a given author/group from the ones presented in the previous section. The intersection of rows and columns gives the current level of autonomy that has been attributed by each author and if the name attributed by the author is different by the code name we used in the left column, the exact name as proposed by the authors is given under the level number (in bracket). From this table, it seems that in most of the taxonomies presented there is a pattern when it comes to the boundary levels of fully manual and fully autonomous states. In most studies this is the case with the exceptions of (Clough, 2002a), (Billings, 1991), (Draper, 1995), (Endsley, 1987) and (Lorenz et al., 2001) which do not follow the fully manual vs. fully autonomous principle.

Between the various intermediate levels that exist, it seems that some are more popular than others when it comes to their frequency of use. For example levels like Fully manual (a), Computer offers decisions (f), Human veto restrict time (m) and Fully autonomous (s) are considered as the most popular ones. Other levels are sporadically used by the different authors. The level execute and inform the human (n), and supervisory control (r) are a little bit more popular, amongst the ones not already mentioned. The remaining ones are used rarely in different mixtures and frequencies by authors.

But what does it really mean that one level is more used than another? It seems that the correct answer to this question does not exist. The fact that there are some levels that are used by most authors shows that these levels can be used on a wide range of applications. Does this make one level more popular/essential than another? That is a good question to answer. This is in a way expected, since between fully manual and fully autonomous levels there exists a finite number of levels that can be invented and therefore it is common that authors “invent” identical levels. What users need to remember, is that what can really vary is the application on which the different taxonomies are going to be applied on. Every application is special, and it has its own needs, so therefore no statistics are important, the user only needs to decide what fits his/her needs better. However, an interesting categorization could be based on what applications every taxonomy has been used so far. Table 3
                         presents the categorization of different taxonomies according to applications that they have been applied to. This can be a helpful tool, for readers that want to apply a taxonomy on a specific operation. However, it is important that the readers should not consider that this categorization should restrict any other possible usage of any taxonomy on another technological field. On the contrary - this is should be welcome.

What is important to remember is that amongst the different levels presented by the authors there exist no “correct” or “wrong” levels, “better or worse” ones, they are just different. It would be wrong to claim that some levels are better than others, or that one taxonomy is the best one. To be accurate, there is no available tool in measuring how “good” or “bad” a taxonomy is, which gives the opportunity to every potential user to use the one that fits his needs better. Even taxonomies that are supposed to be used for the same types of applications can vary a lot. For example taxonomies by Sheridan and Verplank (1978), Sheridan (1992), Parasuraman et al. (2000) and Endsley (1987) are supposed to be used for the same application: avionics. However, there exists quite a significant difference between the number of the levels that their taxonomies include. In that sense every potential user should decide which approach fits his needs better, with the freedom to design his own taxonomy by mixing the levels that have already been proposed or even add some new ones. In that sense the authors believe that there does not exists such a thing as “best taxonomy” presented at least as far as all possible applications are concerned. The number and the variety of levels is in most cases different. However, it needs to be admitted that taxonomies that are more analytical than others (have more levels) have probably more chances to be used in different types of applications.

In this subsection we present our approach on a taxonomy of Levels of Automation. Our approach is used to show how a new taxonomy can be created, and what the authors would take into account if they would design a taxonomy fitting their needs better. This taxonomy, is not meant to be one more taxonomy added to the ones already proposed. It is just a simple way of showing the reader what we would prioritize and take into account when designing a taxonomy by ourselves. By no means do we claim that this taxonomy is superior than the others. It consists of the levels that we think are crucial in most applications, and also levels which according to us seem to have a wide range of usability.

In addition, we tried to combine levels that seem to have no significant differences between them, at least from our point of view. What was interesting when trying to produce our approach were the things that we needed to focus on. What we decided to do is to create a taxonomy that could be widely used, meaning that we did not want to restrict ourselves with a limited number of LOA. We followed the principle of fully manual and fully autonomous boundaries. The challenge was what levels to include in between them. In that sense we tried to keep it short but we also tried to find similarities amongst previously presented taxonomies that would help us mix and combine some of them. Therefore, we concluded in an 8-level approach included some “popular” and some “unpopular” levels. For example we include the level Decision proposal stage (Level 2) which is a combination of levels already proposed by other users. Also, we introduced the failure mode at the fully autonomous level, which means that the computer can be fully in charge unless an unexpected condition arises. In that case, if the error is not included in the specifications the computer should seek human support. The levels and explanations of our proposed taxonomy are presented analytically in Table 4
                        . This is an example that shows how a taxonomy of levels on automation can be created. This example, shows that it is up to any user to decide how they can create their own taxonomy of levels of automation and prioritize their needs and requirements.

So far the effects on system performance of various forms of automation have been discussed. The forms were defined by different levels of autonomy or by different stages of information processing to which machine aid can be applied (Parasuraman, 2005). The taxonomies presented in the previous section assume that once a LOA is identified by the designer, it remains fixed or consistent until the end of the operation. This approach can be referred to as static automation (Parasuraman et al., 1992).

On the other hand, there is the possibility that the level and/or type of automation might not be fixed but has the ability to change in real time during system operation. This possibility i.e. that the levels of autonomy change during a system's operations, is referred to as adaptive automation ((Moray et al., 2000), (Parasuraman et al., 1993), (Scerbo, 1996)). Adaptive automation is akin to dynamic function allocation, in which the division of labour between human and machine agents is not fixed but dynamic, flexible, and context dependent ((Inagaki, 1993), (Parasuraman et al., 1992), (Scerbo, 1996), (Hancock et al., 1985), (Kaber and Endsley, 2004), (Rouse, 1988), (Scerbo, 2001)). Adaptive automation can be important, since the peripheral situation can affect the performance of the systems especially since they are not based on the philosophy “autonomate as much as possible” (Fereidunian et al., 2007b). Consequently, the automation solution should be smart enough to adapt the LOA to changes in peripheral situations. Many researchers have investigated human performance in relation to adaptive automation using simulations of flight, air traffic control, driving tasks, and process control ((Inagaki, 1993), (Moray et al., 2000), (Parasuraman et al., 1993), (Scerbo, 1996)). Lets say for example that, if the performance in a higher level of automation is getting worse, for any kind of reasons this means that actions need to be taken. In that case it is good if there exists a possibility of re-evaluating the LOA that the system is operating at, and ideally changing it. In that case, the automation may change level to a lower one and/or turn over more or even all control to the human until the problem is solved. On the other hand, the opposite example can exist. If high human workload is detected and/or the human operator is not responding appropriately, automation may go to a higher level so as to become less dependent on the human. Adaptive automation may reduce the human performance costs (unbalanced mental workload, reduced situation awareness, complacency, skill degradation, etc.) that can sometimes be associated with high-level decision automation. The thorny human factors issue of allocation of function has typically been based on stereotypical characteristics of human and computer capabilities, an approach that has been met with marginal success.

Although the adaptive automation concept is not new ((Hancock et al., 1985), (Rouse, 1988), (Parasuraman, 1987), (Rouse and SheridanJohannsen, 1976)) many researchers have carried out empirical studies regarding it ((Moray et al., 2000), (Hancock and Scallen, 1996), (Hilburn et al., 1997), (Kaber et al., 2001), (Parasuraman and Hancock, 1999), (Parasuraman and Mouloua, 1996), (Scallen et al., 1995)). A variety of frameworks for adaptive human-automation systems have been suggested along these lines. In the previous section we presented analytically the use and the necessity of the intermediate LOA as a way of improving human automation performance ((Endsley and Kiris, 1995), (Wickens et al., 1998)). In contrast, several authors ((Miller and Parasuraman, 2007), (Opperman, 1994)) propose that the LOA should be adjustable during system operation, which is also consistent with the adaptive automation concept ((Inagaki, 1993), (Parasuraman et al., 1992), (Scerbo, 1996), (Rouse, 1988)).

Different research has demonstrated that adaptive automation has its merits, but in most of these works the automation solution decides on its own how to adapt its own behavior ((Hancock et al., 1985), (Rouse, 1988), (Scerbo, 2001), (Banks and Lizza, 1991), (Dornheim, 1999), (Hancock and Scallen, 2001), (Kaber and Riley, 1999), (Miller and Hannen, 1999), (Opperman, 1999), (Parasuraman et al., 1999)). A different proposal can be implemented, by proposing that the human should remain in charge, deciding how much automation to use. This approach has been characterized as adaptable automation ((Scerbo, 2001), (Opperman, 1994)). Adaptable automation can lead to benefits similar to those of adaptive automation while avoiding many of its pitfalls.

@&#CONCLUSION@&#

The literature review deals with autonomy, levels of automation, different taxonomies presented in the recent years and adaptive and adaptable automation. A summary of taxonomies proposed by various authors is presented analytically in order for the reader to understand better the differences between them. “How many levels of autonomy are proposed?” “What kind of levels are they?” “What are the similarities and the differences amongst them?”, are a few of the questions we try to answer. In addition, a table gathering all the presented taxonomies and a categorization of them is presented. Finally, terms that have been recently used, like adaptive and adaptable automation are presented and analysed in order to give the reader the possibility to launch new trends and approaches in their work.

@&#ACKNOWLEDGEMENTS@&#

This work is part of the project Next Generation Robotics for Norwegian Industry. The project is funded by the Norwegian Research Council and the Norwegian industry: Statoil, Hydro, Tronrud Engineering, Scandinavian Business Seating, Glen Dimplex Nordic and RobotNorge.


                     
                        
                           Table 5
                           
                              Taxonomy proposed by Sheridan and Verplank.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Fully manual control
                                    The computer offers no assistance.
                                 
                                 
                                    Level 2
                                    The computer offers a complete set of decision/action alternatives
                                    Several options are provided to the human who decides.
                                 
                                 
                                    Level 3
                                    The computer narrows the selection down to a few
                                    Human still has to decide.
                                 
                                 
                                    Level 4
                                    The computer suggests one alternative
                                    Human decides amongst suggestions.
                                 
                                 
                                    Level 5
                                    The computer executes that suggestion if the human approves
                                    Human approval needed for execution.
                                 
                                 
                                    Level 6
                                    The computer allows the human a restricted time to veto before automatic execution
                                    Limited time for veto given to the human.
                                 
                                 
                                    Level 7
                                    The computer executes automatically, then necessarily informs the human
                                    No human interference, just information at the end.
                                 
                                 
                                    Level 8
                                    The computer informs the human only if asked
                                    Human gets information only if asks.
                                 
                                 
                                    Level 9
                                    The computer informs the human only if it decides to
                                    Computer decides whether to give information.
                                 
                                 
                                    Level 10
                                    Fully autonomous Control
                                    The computer decides everything and acts autonomously, ignoring the human.
                                 
                              
                           
                        
                     
                     
                        
                           Table 6
                           
                              Taxonomy proposed by Endsley.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Decision support
                                    Human acts upon system recommendations.
                                 
                                 
                                    Level 2
                                    Conseptual Artificial Intelligence (AI)
                                    The system acts autonomously however, the consent of the operator is required to carry out actions.
                                 
                                 
                                    Level 3
                                    Monitored AI
                                    The system acts autonomously unless vetoed by the human.
                                 
                                 
                                    Level 4
                                    Fully automation with no operation interaction
                                    The system excludes the human from the loop-Fully autonomous case.
                                 
                              
                           
                        
                     
                     
                        
                           Fig. 2
                           
                              Taxonomy presented by Riley.
                           
                           
                        
                     
                     
                        
                           Table 7
                           
                              Levels of Intelligence proposed by Riley.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of intelligence
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Raw data
                                    No real data processing.
                                 
                                 
                                    Level 2
                                    Procedural
                                    The processes information or acts according to predefined procedures.
                                 
                                 
                                    Level 3
                                    Context response
                                    The system can change its behaviour in response to its environment.
                                 
                                 
                                    Level 4
                                    Personalized
                                    Can contain a static model of a particular operator's preferences.
                                 
                                 
                                    Level 5
                                    Inferred intent responsive
                                    Can dynamically infer operator intent based on the context and the operator's behavior.
                                 
                                 
                                    Level 6
                                    Operator state response
                                    Can also use information about the operator's physical state.
                                 
                                 
                                    Level 7
                                    Operator predictive
                                    Can anticipate operator actions, such as errors.
                                 
                              
                           
                        
                     
                     
                        
                           Table 8
                           
                              Levels of Autonomy proposed by Riley.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    None
                                    Manual operation.
                                 
                                 
                                    Level 2
                                    Information fuser
                                    Process available information.
                                 
                                 
                                    Level 3
                                    Simple aid
                                    The system cannot perform any action by itself, other than advising the operator, but can process available information and provide recommendation to the human.
                                 
                                 
                                    Level 4
                                    Advisor
                                    The machine has no authority to act, and is limited to communication with the operator.
                                 
                                 
                                    Level 5
                                    Interactive advisor
                                    The machine has no authority to act, and is limited to communication with the operator.
                                 
                                 
                                    Level 6
                                    Adaptive advisor
                                    The machine has no authority to act, and is limited to communication with the operator.
                                 
                                 
                                    Level 7
                                    Servant
                                    The machine is given the ability to take actions.
                                 
                                 
                                    Level 8
                                    Assistant
                                    The machine can take actions but needs the operator's approval.
                                 
                                 
                                    Level 9
                                    Associate
                                    The machine is capable of autonomous action without explicit operator permission, but the operator may always override. inhibit it.
                                 
                                 
                                    Level 10
                                    Partner
                                    The machine has equal override authority with the operator.
                                 
                                 
                                    Level 11
                                    Supervisor
                                    The machine can override the operator has no equal authority.
                                 
                                 
                                    Level 12
                                    Autonomous
                                    Fully autonomous operation.
                                 
                              
                           
                        
                     
                     
                        
                           Table 9
                           
                              Taxonomy proposed by Miligram et al.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Manual Teleoperation
                                    The human is constrained to remain continuously in the control loop.
                                 
                                 
                                    Level 2
                                    Telepresence
                                    Telepresence, or tele-existence, is to provide the means for the human to influence remotely operations, as if he was actually present at that worksite.
                                 
                                 
                                    Level 3
                                    Director/agent control
                                    Is considered to be a basic form of Supervisory Control (Zhai and Miligram, 1991), (Zhai and Miligram, 1992) involving the human operator acting as a director of the task performance and the telerobot serving as the agent.
                                 
                                 
                                    Level 4
                                    Supervisory control
                                    The human remains in the loop but has no authority to act.
                                 
                                 
                                    Level 5
                                    Autonomous robotics
                                    The human gets out of the loop.
                                 
                              
                           
                        
                     
                     
                        
                           Table 10
                           
                              Taxonomy proposed by Draper.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    
                                       
                                          
                                             Manual control
                                          
                                          
                                             1
                                             Manual control
                                          
                                          
                                             2
                                             Manual control with computer model display
                                          
                                          
                                             3
                                             Manual control with model based feedback
                                          
                                       
                                    
                                    Humans must control the entire range of system functioning. In that case the machine displays information from the worksite and action user inputs.
                                 
                                 
                                    Level 2
                                    Manual control with Intelligent Assistance
                                    The machine has the ability to become intelligent, giving the user the possibility to teach the machine rudimentary information about the work site, such as defining regions that should not be entered. The machine is able to modify user inputs to provide guidance, perhaps in the form of movement restrictions.
                                 
                                 
                                    Level 3
                                    
                                       
                                          
                                             Shared Control
                                          
                                          
                                             1
                                             Manual control with automated movement restrictions
                                          
                                          
                                             2
                                             Manual control with automated trajectory guidance
                                          
                                          
                                             3
                                             Manual control with reflective machine actions
                                          
                                       
                                    
                                    The user and the machine share the tasks that need to be controlled.
                                 
                                 
                                    Level 4
                                    Traded control
                                    Level in which both of the machine and the human are continuously responsible for subtasks. In that case either the machine or the human can be in complete control of the task.
                                 
                                 
                                    Level 5
                                    
                                       
                                          
                                             Supervisory control
                                          
                                          
                                             1
                                             Tactional inputs to symbolic interface
                                          
                                          
                                             2
                                             Automated task competition with human innervation
                                          
                                          
                                             3
                                             Automated completion
                                          
                                       
                                    
                                    Level in which the computer apparently has more authority than the human. The human operator intermittently programs and continuously receives information from the PC that controls the teleoperator. The human stays out of the loop if nothing unexpected arrives.
                                 
                              
                           
                        
                     
                     
                        
                           Table 11
                           
                              Taxonomy proposed by Endsley and Kaber.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Manually
                                    The human performs all tasks including monitoring the state of the system and holds the main role.
                                 
                                 
                                    Level 2
                                    Action support
                                    The human still holds a main role and the system assists with performance of the selected action. Some human action might be required.
                                 
                                 
                                    Level 3
                                    Batch processing
                                    Human generates and selects the options to be performed, which are later on turned over to the system to be carried out automatically.
                                 
                                 
                                    Level 4
                                    Shared control
                                    Both the human and the computer generate possible decision options. The human retains full control over the selection of which option to implement, however, carrying out the actions is shared between the human and the system.
                                 
                                 
                                    Level 5
                                    Decision support
                                    The computer generates a list of decision options, which the human can select from. The operator may generate his or her own options. Once the human has selected an option, it is turned over to the computer to implement.
                                 
                                 
                                    Level 6
                                    Blended decision making
                                    The computer generates a list of decision, which selects from and carries out if the human consents. The human may approve of the option or select another one from the computer or operator.
                                 
                                 
                                    Level 7
                                    Rigid system
                                    The system presents only a limited set of actions to the operator and the option is restricted to them. The operator has little discretion on the option.
                                 
                                 
                                    Level 8
                                    Automated decision making
                                    The system selects the best option to implement and carries out that action, based upon a list of alternatives it generates.
                                 
                                 
                                    Level 9
                                    Supervisory control
                                    The system generates options, selects the option to implement and carries out that action. The human mainly monitors the system and intervenes if necessary.
                                 
                                 
                                    Level 10
                                    Full automation
                                    The system carries out all actions. The human is completely out of the control loop and cannot intervene.
                                 
                              
                           
                        
                     
                     
                        
                           Table 12
                           
                              Taxonomy proposed by Lorenz et al.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Base line (Low)
                                    The operator takes the form of a computerized fault finding guide. It is essentially a computerization of a paper version used by (Sauer et al., 2000).
                                 
                                 
                                    Level 2
                                    Automation support (Medium)
                                    The system automatically generates a fault diagnosis and suggests a sequence of actions to be done by the operator who, however retains the authority to follow advisory or to choose other actions.
                                 
                                 
                                    Level 3
                                    Automation support failure (High)
                                    The system generates diagnosis and then the operator is granted with 45 s time to accept the advisory of a sequence of repair actions.
                                 
                              
                           
                        
                     
                     
                        
                           Table 13
                           
                              Taxonomy proposed by Clough.
                           
                           
                              
                              
                              
                              
                                 
                                    Level of autonomy
                                    Description
                                    Explanation
                                 
                              
                              
                                 
                                    Level 1
                                    Remotely piloted
                                    The UAV is simply a remotely piloted aircraft with the human operator making all decisions.
                                 
                                 
                                    Level 2
                                    Remotely operated
                                    The human allows the UAV to do the piloting, but outer loop decisions are made by the human, the UAV asks for human permission to do a task.
                                 
                                 
                                    Level 3
                                    Remotely supervised
                                    The human allows the UAV to execute its own tasks, only by taking command if the UAV fails to properly execute them
                                 
                                 
                                    Level 4
                                    Fully autonomous
                                    The UAV receives goals from the humans and translates that into tasks which does it without human intervention. The UAV has authority to make all decisions.
                                 
                              
                           
                        
                     
                     
                        
                           Table 14
                           
                              Taxonomy proposed by Proud et al.
                           
                           
                              
                              
                              
                              
                              
                              
                                 
                                    Autonomy level
                                    Observe
                                    Orient
                                    Decide
                                    Act
                                 
                              
                              
                                 
                                    1
                                    The human is the only source for gathering and monitoring (defined as filtering, prioritizing and understanding) all data
                                    The human is responsible for analysing all data, making predictions, and interpretation of the data
                                    The computer does not assist in or perform ranking tasks. Human must do it all
                                    Human alone can execute decision
                                 
                                 
                                    2
                                    The human is the prime source for gathering and monitoring all data, with computer shadow for emergencies
                                    The human is the prime source of analysis and predictions, with computer shadow for contingencies. The human is responsible for interpretation of the data
                                    The human performs all ranking tasks, but the computer can be used as a tool for assistance
                                    The human is the prime source of execution, with computer shadow for contingencies
                                 
                                 
                                    3
                                    The computer is responsible for gathering and displaying unfiltered, unprioritized information for the human. The human still is the prime monitor for all information
                                    The computer is the prime source of analysis and predictions, with human shadow for contingencies. The human is responsible for interpretation of the data
                                    Both human and computer perform ranking tasks, the results from the human are considered prime
                                    The computer executes decision after human approval. Human shadows for contingencies
                                 
                                 
                                    4
                                    The computer is responsible for gathering the information for the human and for displaying all information, but it highlights the non-prioritized, relevant information for the user
                                    The computer analyzes the data and makes predictions, though the human is responsible for interpretation of the data
                                    Both human and computer perform ranking tasks, the results from the computer are considered prime
                                    The computer allows the human a pre-programmed restricted time to veto before execution. Human shadows for contingencies
                                 
                                 
                                    5
                                    The computer is responsible for gathering the information for the human, but it only displays nonprioritized, filtered information
                                    The computer overlays predictions with analysis and interprets the data. The human shadows the interpretation for contingencies
                                    The computer performs ranking tasks. All results, including ”why” decisions were made, are displayed to the human
                                    The computer allows the human a context-dependant restricted time to veto before execution. Human shadows for contingencies
                                 
                                 
                                    6
                                    The computer gathers, filters, and prioritizes information displayed to the human
                                    The computer overlays predictions with analysis and interprets the data. The human is shown all results
                                    The computer performs ranking tasks and displays a reduced set of ranked options while displaying ”why” decisions were made to the human
                                    The computer executes automatically, informs the human, and allows for override ability after execution. Human is shadow for contingencies
                                 
                                 
                                    7
                                    The computer gathers, filters, and prioritizes data without displaying any information to the human. Though, a “program functioning” flag is displayed
                                    The computer anlayzes, predicts, interprets, and integrates data into a result which is only displayed to the human if result fits programmed context (context dependant summaries)
                                    The computer performs ranking tasks. The computer performs final ranking and displays a reduced set of ranked options without displaying “why” decisions were made to the human
                                    The computer executes automatically and only informs the human if required by context. It allows for override ability after execution. Human is shadow for contingencies
                                 
                                 
                                    8
                                    The computer gathers, filters, and prioritizes data without displaying any information to the human
                                    The computer predicts, interprets, and integrates data into a result which is not displayed to the human
                                    The computer performs ranking tasks. The computer performs final ranking, but does not display results to the human
                                    The computer executes automatically and does not allow any human interaction.
                                 
                              
                           
                        
                     
                     
                        
                           Table 15
                           
                              Taxonomy proposed by Fereidunian.
                           
                           
                              
                              
                              
                                 
                                    Level of autonomy
                                    Explanation
                                 
                              
                              
                                 
                                    Level 0
                                    The computer offers no assistance: human must take all decisions and action
                                 
                                 
                                    Level 1
                                    The computer acquires the data from the process, and registers them without analysis (1∗ new level)
                                 
                                 
                                    Level 2
                                    The computer offers a complete set of decision/action alternatives, or
                                 
                                 
                                    Level 3
                                    The computer narrows the selection down to a few
                                 
                                 
                                    Level 4
                                    The computer suggests one alternative
                                 
                                 
                                    Level 5
                                    The computer executes that suggestion if the human approves, or
                                 
                                 
                                    Level 6
                                    The computer allows the human a restricted time to veto before automatic execution, or
                                 
                                 
                                    Level 7
                                    The computer executes automatically, then necessarily informs the human, and
                                 
                                 
                                    Level 8
                                    The computer informs the human only if asked, or
                                 
                                 
                                    Level 9
                                    The computer informs the human only if it, the computer, decides to
                                 
                                 
                                    Level 10
                                    The computer decides everything, acts autonomously, ignoring the human
                                 
                              
                           
                        
                     
                  

@&#REFERENCES@&#


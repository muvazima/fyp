@&#MAIN-TITLE@&#Viewpoint-independent gait recognition through morphological descriptions of 3D human reconstructions

@&#HIGHLIGHTS@&#


               
                  
                     
                        
                           
                           We propose a new model-free approach for gait recognition.


                        
                        
                           
                           The recognition is achieved independently of the trajectory.


                        
                        
                           
                           Our method is based on 3D morphological analysis of gait sequences.


                        
                        
                           
                           Our approach is able to identify people walking on curved paths.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gait recognition

Morphology

View-independent

Appearance-based

3D reconstruction

Histogram

@&#ABSTRACT@&#


               
               
                  Many studies have confirmed gait as a robust biometric feature for identification of individuals. However, direction changes cause difficulties for most of the gait recognition systems, due to appearance changes. This study presents an efficient multi-view gait recognition method that allows curved trajectories on unconstrained paths in indoor environments. The recognition is based on volumetric analysis of the human gait, to exploit most of the 3D information enclosed in it. Appearance-based gait descriptors are extracted from 3D gait volumes and temporal patterns of them are classified using a Support Vector Machine with a sliding temporal window for majority voting. The proposed approach is experimentally validated on the “AVA Multi-View Dataset (AVAMVG)” and on the “Kyushu University 4D Gait Database (KY4D)”. The results show that this new approach is able to identify people walking on curved paths.
               
            

@&#INTRODUCTION@&#

Research on human gait as a biometric feature for identification has received a lot of attention due to the apparent advantage that it can be applied discreetly on the observed individual without needing the active participation of the individual.

Previous studies on gait recognition have been classified into two categories: model-based and model-free approaches. The model-based methods extract gait features by fitting a model to input images, whereas model-free approaches characterize the human gait pattern by a compact representation, without having to develop any articulated model for feature extraction and having practical application even with low quality images where the color and texture information is lost.

In addition, regarding viewing angle, the previous work can be categorized into two approaches: view-dependent and view-independent approaches. The view-dependent approaches assume that the appearance will not change during walking. In such methods, a change in the appearance, caused by a view change, will adversely affect performance [1]. Fig. 1
                      shows the influence of a curved path on the silhouette appearance. As one of the advantages of gait as biometric is that it does not need the cooperation of the individual, the trajectory of motion cannot be restricted to just straight paths.

On the other hand, the use of volumetric information allows more information to be analyzed in contrast to methods which only compute gait descriptors from silhouettes or 2D images. This paper presents an efficient view-independent method to recognize people walking along unconstrained (curved and straight) trajectories. This approach focuses on capturing 3D morphological and structural information from volumetric reconstructions of walking humans, which are previously aligned along the way. The main contribution is that our method allows direction changes, achieving a good recognition rate on unconstrained paths.

Some potential applications of this work are access control in special or restricted areas (e.g. military bases, governmental facilities and laboratories) or smart video surveillance (e.g. bank offices) [2].

This article is organized as follows. Section 2 describes works related to the topic of gait recognition. Section 3 explains the details of the proposed algorithm and describes three new descriptors which obtain information from 3D occupancy volumes. An analysis of the proposed method and the performance is given in Section 4. Finally, we conclude this paper in Section 5.

@&#RELATED WORK@&#

The previous work can be categorized into two approaches: view-dependent and view-independent approaches. In the following we describe works related to both categories.

One of the earliest model-free and view-dependent approaches can be seen in [3], where the width of the outer contour of the binarized silhouette from a side view is used to build a descriptor which contains both structural features and dynamic aspects of gait. Feature vectors derived from binary silhouettes have been also used to train Hidden Markov Models [4]. The contours of silhouettes have been used directly [5,6], and through their Fourier descriptors [7,8].

In addition, the authors of Ref. [9] present a gait recognition method which analyzes the shape of the silhouette using Procrustes Shape Analysis and Elliptic Fourier Descriptors. The Gait Energy Image (GEI) descriptor is introduced in [10], which is the average of all silhouette images for a single gait cycle. Silhouette images are also used by Lam et al. [11] to generate the gait flow image (GFI).

Based on the idea of GEI, Depth Energy Image (DEI) was defined in [12], which is simply the average of the depth silhouettes taken along a gait cycle, over the front view. GEI is also extended in [13] to consider depth information from the side view, by means of a new feature called Depth Gradient Histogram Energy Image (DGHEI). Depth information is also used by Chattopadhyay et al. [14] to address the problem of occlusion in frontal gait recognition.

The Gait Energy Volume (GEV), a binary voxel-discretized volume which is spatially aligned and averaged over a gait cycle, is presented in [15]. The authors apply GEV on partial reconstructions obtained with depth sensors from the front view of the individual. An extended work from GEV [15] that combines the frontal-view depth gait image and side-view 2D gait silhouette by means of a back-filling technique is presented in [16]. A spatio-temporal representation based on point clouds in a spherical coordinate space was proposed in [17], where frontal 3D point clouds of humans obtained with stereo cameras are used.

A work closely related to our proposed approach in terms of analysis by morphological size distributions was proposed in [18]. In this work, video cameras are placed in hallways to capture longer sequences from the front view of walkers rather than the side view, which results in more gait cycles per gait sequence. Despite the high recognition rate, the main drawback of this model-free approach is the dependence with respect to the viewpoint. To obtain a gait representation directly from silhouettes, the authors proposed the use of a morphological descriptor, called Cover by Rectangles, which is defined as the union of all the largest rectangles that can fit inside a silhouette.

In [19], a 3D approximation of a Visual Hull (VH) [20] is used to design a multi-modal recognition approach. Although a VH model is computed, a gait recognition scheme based on silhouette analysis is applied, which restricts a large amount of discriminant information because the recognition is based on single view silhouette analysis, instead of analyze 3D information. Seely et al. [21] use 3D volumetric data to synthesize silhouettes from a fixed viewpoint relative to the subject. The resulting silhouettes are then passed to a standard 2D gait analysis technique, such as the average silhouette. The sequences are collected from a multi-biometric tunnel, where the subjects just walk straight.

Ariyanto and Nixon [22] propose a model-fitting algorithm, correlation filters and dynamic programming to extract gait kinematics features. They use a structural model including articulated cylinders with 3D Degrees of Freedom (DoF) which are fitted to a visual hull shape to model the human lower legs. In [23], 3D data collected from a projector–camera system is used to fit 3D body models and reconstruct synthetic poses in a gait cycle.

Appearance changes due to viewing angle changes cause difficulties for most of the model-free gait recognition methods. This situation cannot be easily avoided in practical applications. There are three major approach categories to sort out this problem, namely: (1) approaches that construct 3D gait information through multiple calibrated cameras; (2) approaches that extract gait features which are invariant to viewing angle changes; (3) approaches whose performance relies on learning mapping/projection relationship of gaits under various viewing angles [24].

Approaches of the first category are represented in [25,26]. Bodor et al. [25] apply image-based rendering on a 3D VH model to reconstruct gait features under a required viewing angle. This approach tries to classify the motion of a human in a view-independent way, but it has two drawbacks. On the one hand it considers only straight paths to estimate the position and orientation of a virtual camera. Tests were performed only on straight path motions. On the other hand, not all the 3D information available in the VH is used, because feature images are extracted from 2D images rendered only from a single view.

In [26], an observation angle at each frame of a gait sequence is estimated from the walking direction, by fitting a 2D polynomial curve to the foot points. Virtual images are synthesized from 3D reconstructions, so that the observation angle of a synthesized image is the same that the observation angle for the real image of the subject, which is identified by using affine moment invariants extracted from images as gait features. The advantage of this method is that the setup assumes multiple cameras for training, but only one camera for testing. However, as in the above two works, despite 3D volumes are used, descriptors are extracted from 2D images, so that, the amount of used information is restricted. On the other hand, shadows on the floor complicate the estimation of the foot points in silhouette images.

Approaches of the second category extract gait features which are invariant to viewing angle change. A method to generate a canonical view of gait from any arbitrary view is described in [27]. The main disadvantage of this method is that the synthesis of a canonical view is only feasible from a limited number of initial views. The performance is significantly dropped down when the angle between image plane and sagittal plane is large.

In [28], a method based on homography to compute view-normalized trajectories of body parts obtained from monocular video sequences was proposed. But this method only works properly for a limited range of views. Planar homography has also been used to reduce the dependency between the motion direction and the camera optical axis [29], however this method seems not to be applicable when the person is walking nearly parallel to the optical axis. In [30] view-invariant features are extracted from GEI. Only parts of gait sequences that overlap between views are selected for gait matching, but this approach cannot cope with large view angle changes under which gait sequences of different views can have little overlap.

A self-calibrating view-independent gait recognition based on model-based gait features is proposed in [31]. The poses of the lower limbs are estimated based on markerless motion estimation. Then, they are reconstructed in the sagittal plane using viewpoint rectification. This method has two main drawbacks that are worth mentioning: 1) the estimation of the poses of the limbs is not robust from markerless motion; 2) it is not applicable for frontal view because the poses of the limbs become untraceable; and 3) this method assume that subjects walk along a straight line segment.

Zhao et al. [32] present a multi-camera approach for gait tracking and recognition. The video sequences are used as input, and then a human 3D model is set up. The lengths of key segments are extracted as static parameters, and the motion trajectories of lower limbs are used as dynamic features. A skeletal 3D model is also used in the work of Kastaniotis et al. [33], which presents a framework for pose-based gait recognition and identification, as well as gender recognition.

The approaches of the third category rely on learning mapping/projection relationship of gaits under various viewing angles. The trained relationship may normalize gait features from different viewing angles into shared feature spaces. An example from this category can be read in [34], where LDA-subspaces are learned to extract discriminative information from gait features under each viewing angle.

A View Transformation Model (VTM) was introduced in  [35] to transform gait features from different views into the same view. The method of Makihara t al. [35] creates a VTM based on frequency-domain gait features, obtained through Fourier Transformation. To improve the performance of this method, Kusakunniran t al. [36] created a VTM based on GEI optimized by linear discriminant analysis. A sparse-regression-based VTM for gait recognition under various views is also proposed in [24]. However, this method cannot deal with changes in the direction of motion.

Although methods of the third category have better ability to cope with large view angle changes compared to other works, some common challenges are the following [24]: (1) performance of gait recognition decreases as the viewing angle increases; (2) since the methods rely on supervised learning, it will be difficult for recognizing gait under untrained/unknown viewing angles, (3) these methods implicitly assume that people walk along straight paths and that their walking direction does not change during a single gait cycle (i.e., that people do not walk along curved trajectories). However, people often walk on curved trajectories in order to turn a corner or to avoid an obstacle.

@&#PROPOSED METHOD@&#

We propose a model-free approach to recognize walking humans independently of the viewpoint and regardless direction changes. Our approach focuses on capturing 3D morphological and structural information from the gait through volumetric reconstructions of the walking humans.

The use of volumetric information allows more information to be analyzed in contrast to other related works, which only compute gait descriptors from silhouettes, discarding an important part of the dynamical and structural information of the gait. So that, our method extends the input domain for the morphological gait descriptors used in [18], from 2D silhouettes to 3D reconstructions of the individuals, aligned along the way.

Our approach relies on morphological analysis of series of 3D occupation volumes which are generated from the multi-view video sequences. For each time of the gait sequence, a 3D occupation volume is obtained by combining information from multiple silhouette images, from several points of view. Then, this gait volume is aligned and centered with respect to a global reference system. Next, our gait descriptor is computed from each 3D gait volume in order to provide information about their 3D appearance.

A gait signature is built by aggregating descriptors. The gait signature is a temporal pattern of gait, a sample that feeds a classifier producing a class label corresponding to the identity of a particular person. The proposed recognition algorithm is shown in Fig. 2
                     , where the identity of a walking human is predicted at each time t. The algorithm consists of five steps which are exposed in detail in this section:


                     
                        
                           1.
                           Silhouette extraction of each camera's view by a background subtraction technique [37].

3D reconstruction from silhouettes captured from several viewpoints, by a Shape from Silhouette algorithm (SfS) [38].

Person detection and gait alignment.

Gait descriptor generation, which is used to update the gait signature.

Classification of gait signature by a machine learning algorithm.

The first three steps of the algorithm generate a 3D volume with occupancy information of the person at time t, whereas the last three steps perform the feature extraction, signature generation and gait classification.

We start by computing a 3D reconstruction of the individual from silhouettes extracted from several viewpoints. This procedure requires calibration parameters, such as the camera matrix, distortion coefficients (intrinsic parameters), pose and orientation (extrinsic parameters) of each camera.

After the 3D reconstruction, the individual is detected and the 3D volumes corresponding to a gait sequence are aligned and centered with respect to a global reference system, so that the generation of the descriptors can be made as if the person had walked on a treadmill in a certain direction.

Since our method generates gait descriptors from 3D occupation volumes or VH, a 3D reconstruction procedure, such a Shape from Silhouette algorithm [38] is required. Fig. 3
                            shows a 3D reconstructed gait sequence.

Given a reconstructed volume V
                           
                              t
                            of a person at each instant t along the way, it required a mechanism of detection and alignment to achieve the independence which refers to the viewpoint. This process will allow the individual to walk freely in the scene, without adversely affecting the subsequent generation of gait descriptors.

We assume that although there is only one individual in the scene, reconstructed shadows as well as noise can coexist, due to poor segmentation. By obtaining the ground marginal distribution of occupied voxels (ground projection of the volume), we detect the volume belonging to a person as that which has a greater volume than a certain threshold ϕ, and its volume has fully entered into the workspace. The value of ϕ is tuned up accordingly to the average corporal volume for humans and the resolution of the 3D reconstructions. This is described in Section 4.2.

When the volume belonging to a person has been detected, the centroid p of the ground projection is calculated. Then, the volume is moved into a bounding-box of average adult human's size, so that the workspace where the descriptor will be computed is bounded. This process is illustrated in Fig. 4
                           . The estimation of the direction of path is determined by the displacement vector, defined as: 
                              
                                 (1)
                                 
                                    
                                       
                                          
                                             
                                                v
                                             
                                             →
                                          
                                       
                                       
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          p
                                       
                                       
                                          t
                                       
                                    
                                    −
                                    
                                       
                                          p
                                       
                                       
                                          t
                                          −
                                          1
                                       
                                    
                                    ,
                                 
                              
                           where t is the current time, p
                           
                              t
                            is the centroid's current position, and p
                           
                              t
                              −1 is the last known position of the centroid.

The angle of the displacement vector is calculated using the expression: 
                              
                                 (2)
                                 
                                    
                                       
                                          α
                                       
                                       
                                          t
                                       
                                    
                                    =
                                    arctan
                                    ⁡
                                    
                                       
                                          
                                             
                                                v
                                             
                                             
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      y
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                v
                                             
                                             
                                                
                                                   
                                                      t
                                                   
                                                   
                                                      x
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

An example of extraction of the displacement vector angle can be seen in Fig. 5
                           , where top projections of the individual can be seen in several moments of the gait, and the principal axis (perpendicular to displacement vector) is represented. The reconstructed volume is rotated about the body vertical axis.

Although we assume a constant walking speed, an individual could vary moderately the walking speed in a certain moment of the gait. It could happen, for example, when the individual is describing a curved closed path.

If the walking speed is very low at time t, 
                              
                                 
                                    
                                       
                                          
                                             v
                                          
                                          →
                                       
                                    
                                    
                                       t
                                    
                                 
                              
                            will be too small, which could result in a noisy estimation of the angle α
                           
                              t
                           . To attenuate this noise in the α
                           
                              t
                            estimation and smooth the path, we propose a weighted average of the displacement vector angle as follows: 
                              
                                 (3)
                                 
                                    
                                       
                                          
                                             
                                                α
                                             
                                             ¯
                                          
                                       
                                       
                                          t
                                       
                                    
                                    =
                                    
                                       
                                          α
                                       
                                       
                                          t
                                       
                                    
                                    ⋅
                                    β
                                    +
                                    
                                       
                                          
                                             
                                                α
                                             
                                             ¯
                                          
                                       
                                       
                                          t
                                          −
                                          1
                                       
                                    
                                    ⋅
                                    (
                                    1
                                    −
                                    β
                                    )
                                    ,
                                 
                              
                           where
                              
                                 (4)
                                 
                                    β
                                    =
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  v
                                                               
                                                               →
                                                            
                                                         
                                                         
                                                            t
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                max
                                             
                                             
                                                i
                                                =
                                                0
                                                …
                                                t
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     
                                                                        v
                                                                     
                                                                     →
                                                                  
                                                               
                                                               
                                                                  i
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

The aim of β is to reduce this noise in the estimation of the alignment angle, giving more or less weight to the current estimation depending on the walking speed. For example, if the walking speed is decreasing and it becomes too small, the magnitude of the displacement vector may not be large enough, causing oscillations in the estimation of the angle. In this case, it would be right to give less importance to the current angle estimation. However, if the walking speed is increasing, it would be more appropriate to give more weight to the current angle estimation. A method to decrease over time the denominator in Eq. (4) should be applied if the gait sequence were too large. Thus, the whole gait sequence can be centered and aligned along the path as it is illustrated in Fig. 6
                           .

The algorithm steps that handle up the gait identification are described below.

The first step is the generation of the gait descriptor on the V
                           
                              t
                            volume. We propose the three following candidate descriptors. 
                              
                                 •
                                 Cover by Rectangles from frontal volume projection:

The Cover by Rectangles descriptor, denoted here as CR(S), was proposed by Barnich and Van Droogenbroeck [18]. It is defined as the union of all the largest rectangles that can fit inside of a silhouette S. In Barnich's method, video cameras are placed in hallways to capture longer sequences from the front view of walkers rather than the side view, which results in more gait cycles per gait sequence. The main drawback of this method is the dependence on the viewpoint.

Each silhouette is then converted to an intra-frame histogram, which compacts the width and height distributions of the set of all the rectangles that can be wedged inside the silhouette. In order to build the histogram, the widths and heights of the rectangles are discretized into M and N bins respectively.

As the occupation volumes have been aligned to achieve the view independence, a virtual camera can be placed in front of the volumes to obtain projections on which the CR(S) can be computed, as can be seen in Fig. 7
                                     (b).

Cover by Cubes:

We propose a new gait descriptor defined as the union of all the cubes with the largest size that can fit into a volume belonging to the person. It is called Cover by Cubes.

Considering V as the 3D volume of a person in a moment of the gait, CC(V ) is the union of all cubes of maximum size that can fit in it. The new descriptor deals with three-dimensional domain spatial information, and like Cover by Rectangles, it has the following useful properties: 
                                       
                                          –
                                          The elements of the set overlap each other, introducing redundancy (i.e. robustness).

Each element (cube) of CC(V ) covers at least one voxel that belongs to no other cube.

The union of all cubes reconstructs the volume V so that no information is ever lost.

Let α
                                    =
                                    #CC(V ) be the cardinality of the set CC(V ). The cubes of CC(V ) are indexed with a parameter e, so that 
                                       
                                          
                                             C
                                          
                                          
                                             e
                                          
                                       
                                       (
                                       e
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       α
                                       )
                                     are the cubes of CC(V ). The width, height and depth of 
                                       
                                          
                                             C
                                          
                                          
                                             e
                                          
                                       
                                     are, respectively, denoted by w
                                    
                                       e
                                    , h
                                    
                                       e
                                     and d
                                    
                                       e
                                    ; and they are upper-bounded by w
                                    
                                       max
                                    , h
                                    
                                       max
                                     and d
                                    
                                       max
                                    , so ∀e, w
                                    
                                       e
                                     ≤ w
                                    
                                       max
                                    , h
                                    
                                       e
                                     ≤ h
                                    
                                       max
                                     and d
                                    
                                       e
                                     ≤ d
                                    
                                       max
                                    .

In order to build histograms, the widths, heights and depths of the cubes R
                                    
                                       e
                                     are discretized into M bins B
                                    
                                       W
                                    (i), N bins B
                                    
                                       H
                                    (j) and D bins B
                                    
                                       D
                                    (k)
                                       
                                          (5)
                                          
                                             
                                                
                                                   B
                                                
                                                
                                                   W
                                                
                                             
                                             (
                                             i
                                             )
                                             =
                                             
                                                
                                                   i
                                                   
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         M
                                                      
                                                   
                                                   ,
                                                   (
                                                   i
                                                   +
                                                   1
                                                   )
                                                   
                                                      
                                                         
                                                            
                                                               w
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         M
                                                      
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          (6)
                                          
                                             
                                                
                                                   B
                                                
                                                
                                                   H
                                                
                                             
                                             (
                                             j
                                             )
                                             =
                                             
                                                
                                                   j
                                                   
                                                      
                                                         
                                                            
                                                               h
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         N
                                                      
                                                   
                                                   ,
                                                   (
                                                   j
                                                   +
                                                   1
                                                   )
                                                   
                                                      
                                                         
                                                            
                                                               h
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         N
                                                      
                                                   
                                                
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          (7)
                                          
                                             
                                                
                                                   B
                                                
                                                
                                                   D
                                                
                                             
                                             (
                                             k
                                             )
                                             =
                                             
                                                
                                                   k
                                                   
                                                      
                                                         
                                                            
                                                               d
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         D
                                                      
                                                   
                                                   ,
                                                   (
                                                   k
                                                   +
                                                   1
                                                   )
                                                   
                                                      
                                                         
                                                            
                                                               d
                                                            
                                                            
                                                               m
                                                               a
                                                               x
                                                            
                                                         
                                                      
                                                      
                                                         D
                                                      
                                                   
                                                
                                             
                                             
                                          
                                       
                                    where i
                                    =0,…,M
                                    −1; j
                                    =0,…,N
                                    −1 and k
                                    =0,…,D
                                    −1.

Three histograms are defined, H
                                       W
                                    (i), H
                                       H
                                    ( j) and H
                                       D
                                    (k): 
                                       
                                          (8)
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                
                                                
                                                   W
                                                
                                             
                                             (
                                             i
                                             )
                                             =
                                             
                                                
                                                   1
                                                
                                                
                                                   α
                                                
                                             
                                             #
                                             
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      e
                                                   
                                                
                                                |
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      W
                                                   
                                                
                                                (
                                                i
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          (9)
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                
                                                
                                                   H
                                                
                                             
                                             (
                                             j
                                             )
                                             =
                                             
                                                
                                                   1
                                                
                                                
                                                   α
                                                
                                             
                                             #
                                             
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      e
                                                   
                                                
                                                |
                                                
                                                   
                                                      h
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      H
                                                   
                                                
                                                (
                                                j
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                          (10)
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                
                                                
                                                   D
                                                
                                             
                                             (
                                             k
                                             )
                                             =
                                             
                                                
                                                   1
                                                
                                                
                                                   α
                                                
                                             
                                             #
                                             
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      e
                                                   
                                                
                                                |
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      D
                                                   
                                                
                                                (
                                                k
                                                )
                                             
                                             ,
                                          
                                       
                                    and the three-dimensional histogram H
                                       W
                                       ×H
                                       ×D
                                     as: 
                                       
                                          (11)
                                          
                                             
                                                
                                                   
                                                      H
                                                   
                                                
                                                
                                                   W
                                                   ×
                                                   H
                                                   ×
                                                   D
                                                
                                             
                                             (
                                             i
                                             ,
                                             j
                                             ,
                                             k
                                             )
                                             =
                                             
                                                
                                                   1
                                                
                                                
                                                   α
                                                
                                             
                                             #
                                             
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      e
                                                   
                                                
                                                |
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      W
                                                   
                                                
                                                (
                                                i
                                                )
                                                ,
                                                
                                                   
                                                      h
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      H
                                                   
                                                
                                                (
                                                j
                                                )
                                                ,
                                                
                                                   
                                                      d
                                                   
                                                   
                                                      e
                                                   
                                                
                                                ∈
                                                
                                                   
                                                      B
                                                   
                                                   
                                                      D
                                                   
                                                
                                                (
                                                k
                                                )
                                             
                                             .
                                          
                                       
                                    
                                 

All these histograms are normalized taking into account the number of cubes of maximum size of the volume.

From the four histograms, H
                                       W
                                    (i), H
                                       H
                                    (j), H
                                       D
                                    (k) and H
                                       W
                                       ×H
                                       ×D
                                    (i,j,k), the latter is the one that better describes V. However, its dimensionality is proportional to the product of the numbers of bins (M
                                    ×
                                    N
                                    ×
                                    D), which might be too high, e.g., for embedded systems. To deal with such situation, a composite histogram is proposed, H
                                       W
                                       +H
                                       +D
                                    (l), with l
                                    =0,…,M
                                    +
                                    N
                                    +
                                    D
                                    −1 defined as the concatenation of H
                                       W
                                    (i), H
                                       H
                                    (j) and H
                                       D
                                    (k) (marginal distributions).

An example of Cover by Cubes histograms is shown in Fig. 8
                                    . In this figure, the joint distribution and the marginal distributions of the histograms can be seen, corresponding to Eqs. (11), (8), (9), and (10).

Cover by Rectangles from top, side, and frontal volume projections:

The availability of 3D gait volumes leads us to that think we can use several projections of the gait volumes, instead of just using the frontal projection of them, in order to exploit the 3D information of gait.

So following the idea about the use of virtual cameras, we also propose a new descriptor based on computing the CR descriptor on the front, side, and top projections of the volume V, as it is shown in Fig. 7. Its concatenation can be denoted as CRP(V ).
                                       
                                          (12)
                                          
                                             CRP
                                             
                                             (
                                             V
                                             )
                                             =
                                             
                                                C
                                                R
                                             
                                             (
                                             
                                                side
                                             
                                             )
                                             ,
                                             
                                                C
                                                R
                                             
                                             (
                                             
                                                front
                                             
                                             )
                                             ,
                                             
                                                C
                                                R
                                             
                                             (
                                             
                                                top
                                             
                                             )
                                             ,
                                          
                                       
                                    where side, front and top are lateral, frontal and top rendered projections of V, respectively.

The action immediately prior to the classification by a machine learning algorithm is the generation of the sample or vector of features. A sample is generated at every moment of the walking, which enables synchronous classification. This is known as 
                              G
                            or gait signature, and represents a temporal pattern of movement of the person.

For the CR descriptor, obtained on the front projection of the volume, the signature 
                              G
                            can be obtained by combining a number L of successive histograms into a single spatio-temporal (inter-frame) gait signature, as it was described in [18]. The signature can be made by the combination of the marginal or joint distribution of the histograms and it needs to be updated in every time t.

However, with the new proposed gait descriptors (CC and CRP) which get information from 3D occupancy volumes instead of getting it from silhouettes, it is necessary to reformulate the procedure to construct the signature 
                              G
                           . The way in which this signature is built depends on the descriptor.

With regard to CC descriptor, the gait signature
                           
                              G
                            relies on temporal series of descriptors obtained from the 3D volumes of a person's gait sequence. So if t refers to the current time, and H(i,j,k,t) is the Cover by Cubes descriptor obtained from the volume V
                           
                              t
                           , we have two possible signatures as follows: 
                              
                                 (13)
                                 
                                    
                                       
                                          G
                                       
                                       
                                          W
                                          ×
                                          H
                                          ×
                                          D
                                       
                                    
                                    (
                                    i
                                    ,
                                    j
                                    ,
                                    k
                                    ,
                                    t
                                    )
                                    =
                                    
                                       
                                          
                                             H
                                          
                                       
                                       
                                          W
                                          ×
                                          H
                                          ×
                                          D
                                       
                                    
                                    (
                                    i
                                    ,
                                    j
                                    ,
                                    k
                                    ,
                                    t
                                    −
                                    (
                                    L
                                    −
                                    1
                                    )
                                    )
                                    ,
                                    …
                                    ,
                                    
                                       
                                          
                                             H
                                          
                                       
                                       
                                          W
                                          ×
                                          H
                                          ×
                                          D
                                       
                                    
                                    (
                                    i
                                    ,
                                    j
                                    ,
                                    k
                                    ,
                                    t
                                    )
                                 
                              
                           which consist of n-uples of L consecutive histograms, and a shortened version as: 
                              
                                 (14)
                                 
                                    
                                       
                                          G
                                       
                                       
                                          W
                                          +
                                          H
                                          +
                                          D
                                       
                                    
                                    (
                                    o
                                    ,
                                    t
                                    )
                                    =
                                    
                                       
                                          
                                             H
                                          
                                       
                                       
                                          W
                                          +
                                          H
                                          +
                                          D
                                       
                                    
                                    (
                                    o
                                    ,
                                    t
                                    −
                                    (
                                    L
                                    −
                                    1
                                    )
                                    )
                                    ,
                                    …
                                    ,
                                    
                                       
                                          
                                             H
                                          
                                       
                                       
                                          W
                                          +
                                          H
                                          +
                                          D
                                       
                                    
                                    (
                                    o
                                    ,
                                    t
                                    )
                                 
                              
                           where o
                           =0,…,M
                           +
                           N
                           +
                           D
                           −1.

Similarly, for CRP descriptors, the gait signature 
                              G
                            can be also composed by aggregating, on a sliding window, L CRP descriptors (joint or marginal distribution of the histograms computed on rendered side, top and front projections of V).

The gait signature obtained at time t is the feature vector used for recognition. Each of these feature vectors is assigned to a class label that corresponds to one of the individuals in the database. This idea is well known as multi-class classification system. We adopt a Support Vector Machine (SVM) [39] for training and classification.

Our recognition algorithm provides the identity of the person as soon as possible, without having to split the gait sequence into gait cycles. This makes our method less restrictive compared to other techniques from the literature. A possibly different class label can be produced for each new gait signature, on the basis of L previous volumes.

To smooth and reinforce the results over time, a majority vote policy over a sliding temporal window of size W is used. As the gait signature information is computed on L previous volumes, the use of this window causes a delay of L
                           +
                           W frames in obtaining the identity. Fig. 9
                            shows an example of majority voting system over a sliding temporal window, with L
                           =5 and W
                           =3.

In this section we start by describing the used datasets, and then we present the experimental results.

To perform a 3D reconstruction by the SfS algorithm, the dataset must be multiview and calibration information have to be provided. Two datasets have been used to carry out the experiments, the “AVA Multi-View Dataset for Gait Recognition (AVAMVG)”
                           2
                        
                        
                           2
                           Publicly available at: http://www.uco.es/investiga/grupos/ava/node/41.
                         [40] and the “Kyushu University 4D Gait Database (KY4D)”
                           3
                        
                        
                           3
                           Publicly available at: http://robotics.ait.kyushu-u.ac.jp/research-e.php?content=db.
                         [26].

In AVAMVG, 20 subjects perform 9 walking trajectories in an indoor environment. Each trajectory is recorded by 6 color cameras placed around a room that is crossed by the subjects during the performance, according to the distribution shown in the diagram of Fig. 10
                        .

The video sequences of AVAMVG have a resolution of 640×480 pixels, and were recorded at a rate of 25 frames per second. For each actor, 9 gait sequences are captured in several trajectories as described in the figure by {t1,…,t9}. Of these trajectories, 3 are straight ({t1,…,t3}) and 6 are curved ({t4,…,t9}). An example of this dataset is shown in Fig. 11
                        , in which several subjects are walking along different paths, from multiple viewpoints. Calibration parameters for the cameras of AVAMVG have been obtained with Aruco library [41].

With respect to KY4D Gait Database, it is composed of sequential 3D reconstructions and image sequences of 42 subjects walking along four straight and two curved trajectories. The sequences were recorded by 16 cameras, at a resolution of 1032×776 pixels. Although the KY4D Gait Database also provide sequential 3D reconstructions of subjects, we have reconstructed them with the same SfS method and resolution parameters used for reconstructing the 3D AVAMVG models.

As far as we know, there are other well-known multi-camera databases, as CMU Motion of Body (MoBo) Database [42] and CASIA Dataset B [43]. However, since these databases do not include information on camera parameters, 3D reconstructions of walking people cannot be obtained. Therefore, we did not use these databases in the experiments of the present study.

@&#EXPERIMENTAL RESULTS@&#

In this section, we present the results of multiple experiments run on both gait datasets. First of all, we need to determine the value of several parameters of our method. Thus, considering the 3D reconstruction stage, the first relevant parameter is the voxel size. We consider that a voxel size of 0.27×10
                           −4m3 is enough to get detailed 3D human reconstructions.

The average corporal volume for humans is 66.4L
                        =0.6640×10
                           −1m3 measured by the water displacement method in 521 people aged 17−51 years [44]. Using a voxel size of 0.27×10
                           −4m3, the number of voxels belonging to a person in the 3D volume should be about 2459. With a value of 1×103 < ϕ < 2459 (see Section 3.1.2) the system should be able to detect an adult human.

Regarding the volume alignment, Table 1
                         shows the mean error in the estimation angle for each trajectory of the KY4D dataset. We also report the 95% confidence interval on the mean, assuming that the data are normally distributed.

As it was proved in [18], the number of silhouettes (volumes in our case) aggregated in a single gait signature can be set in L
                        =20, because we have a rate of 25 volumes per second, and L
                        =20 responds to a signature of about 1s which matches the length of a gait cycle.

The decision to build the gait signatures with joint or marginal distributions of histograms depends on the amount of training data and memory available for the classification process. If all the other parameters are kept unchanged, the use of joint distributions should lead to get better results. However, the dimensionality of the corresponding feature space using joint distributions is M
                        ×
                        N
                        ×
                        L for CR [18], M
                        ×
                        N
                        ×3×
                        L for CRP, or M
                        ×
                        N
                        ×
                        D
                        ×
                        L for CC, which is too expensive to compute. Alternatively, the dimensionality of the feature space using marginal distributions of histograms is (M
                        +
                        N)×
                        L for CR, (M
                        +
                        N)×3×
                        L for CRP and (M
                        +
                        N
                        +
                        D)×
                        L for CC. For example, for a value of M
                        =
                        N
                        =
                        D
                        =25 and L
                        =20, the feature space of the CC descriptor has a dimensionality of 312500 using joint distributions, compared to 1500 features using marginal distributions.

In several previous experiments, we noted that if we use joint distributions and SVM, the accuracy is lower than if we use marginal distributions. Maybe it can occur because the statistical significance of the joint distribution of histograms is much lower than the statistical significance of the marginal distributions of them. Moreover, may be impracticable to compute the joint distribution of histograms such as CC or CRP because of the high dimensionality. Therefore, we focus our experimentation on the use of marginal distributions of the histograms.

In order to determine M, N and D (the number of bins), we tested values ranging from 5 to 25, with step 5 on both AVAMVG and KY4D gait databases. It was observed that large values of M, N or D generally lead to better performance. However, the performance saturates with 20 bins and above, depending on the descriptor.

Depending on the size of the training dataset and the resolution of the 3D reconstructed volumes, the statistical significance of all the bins of the histograms needs to be taken into account. The first series of experiments consisted in determining the appropriate number of bins for each descriptor. For the sake of simplicity, we restricted to the case where M=N or M=N=D, and disabled the majority vote on the previous W frames (or equivalently set W to 1).

We use a leave-one-out cross-validation strategy. Regarding experiments on the AVAMVG dataset, each fold is composed by a tuple formed by a set of 20 sequences (one sequence per actor) for testing, and by the remaining eight sequences of each actor for training, i.e. 8×20 sequences for training and 20 sequences for test. For the KY4D gait dataset, each fold is composed by 42 sequences for testing (one sequence per actor) and by the remaining five sequences of each actor (i.e. 42×5 sequences) for training.

We use a C-SVC SVM, which allows imperfect separation of classes with penalty multiplier C for outliers. Several SVM kernels were tested, and finally we selected Radial Basis Function since we obtained better results than with linear, polynomial, or sigmoid kernels. We set the same weight to all classes. To make the choice of SVM parameters independent of the sequence test data, we cross-validate the SVM parameters on the training set. We report the improvement with respect to different kernels in Table 4.


                        Fig. 12
                        , shows the performance of each descriptor with L
                        =20 and different histogram sizes on the AVAMVG dataset. We use marginal distributions of histogram and we get the best results with M
                        =
                        N
                        =25 for the CR descriptor, M
                        =
                        N
                        =20 for the CRP descriptor, and M
                        =
                        N
                        =
                        D
                        =15 for the CC descriptor.

On the other hand, Fig. 13
                         shows the performance of each descriptor with different histogram sizes, applied on the KY4D gait dataset. We use marginal distributions, and in this case, we get the best results with M
                        =
                        N
                        =20 for the CR descriptor, M
                        =
                        N
                        =25 for the CRP descriptor, and M
                        =
                        N
                        =
                        D
                        =10 for the CC descriptor. In this experiment, for the sake of simplicity, we disabled the sliding temporal window for majority vote.

The second series of experiments that were carried out consisted in determining the optimum size of the sliding temporal window for majority voting. In Figs. 14 and 15
                        
                         we show how the accuracy increases with respect to the size of the sliding temporal window for majority voting on both datasets, using the histogram sizes selected in the previous experiment.

The sliding temporal window of majority voting stage improves the performance of the method with any of the three proposed descriptors for both datasets. Nevertheless, the size of the sliding temporal window for voting is limited by the number of available gait signatures for each sequence.

For the AVAMVG, with CR descriptors applied on frontal volume projections, we obtain a maximum accuracy of 90.8%. Nevertheless, using the CC descriptor computed on the entire volume, the accuracy is about 94.5% and finally, with the CRP descriptor, the system was able to correctly identify up to 96.1% of subjects. On the other hand, on the KY4D dataset we obtain a maximum accuracy of 80.4% for CR, 93.4% for CC and 93.8% for CRP descriptors.


                        Tables 2 and 3
                        
                         show detailed results for the leave-one-out experiment on AVAMVG and KY4D datasets respectively. We compare the accuracy of our approach for CRP and CC signatures with the accuracy of state-of-art methods such as [21,22] on AVAMVG and KY4D datasets. For the comparison with Ariyanto and Nixon we used the best kinematics features proved in [22], whereas for the case of Seely et al. [21] we have used the side-on, front-on, top-down average silhouettes. Since these methods are not designed to cope with curved trajectories, we have aligned the gait volumes along the path (see Section 3.1.2). The resolution of the reconstructed volumes was the same for all cases.

The third series of experiments that we performed consisted in testing our method, which allows completely free trajectories, with the method presented in [26], for identification of people walking along curved trajectories. Comparative of recognition results on both datasets are shown in Tables 5 and 6. In this experiment, we used the straight trajectories for training, and the curved trajectories for testing.

As we can observe in Tables 4 and 5
                        
                        
                        , the performance of compared methods is dropped down when the training set does not contain curved trajectories. Moreover, we have noticed a decrease of performance of the method presented in [26] when it is trained with the straight paths and tested with the curves of AVAMVG. We think it may be due to the low number of cameras of AVAMVG and therefore to the quality of the 3D reconstructions. Besides that, in the AVAMVG dataset, depending on the viewpoint and performed trajectory, people appear at diverse scales, even showing partially occluded body parts.

We think that when the subject walks on a curved path, the gait pattern is consequently modified, as we can see in Fig. 16
                        . For this reason, we consider that it is not entirely correct to train the classifier of our model-free approach with straight paths only.

@&#CONCLUSIONS@&#

This paper has proposed a method to recognize walking humans independently of the viewpoint and regardless direction changes. The method focuses on capturing 3D morphological and structural information from volumetric reconstructions of the gait. The main contribution is that the method achieves a good recognition rate on completely unconstrained paths, allowing direction changes, in contrast to others view-independent approaches where the view change is restricted to a few angles. In our method, the individual can walk freely in the scene without adversely affect to the recognition.

For this purpose, it was designed a mechanism of person detection and gait alignment based on 3D reconstructions. In order to extract information from the 3D volumes, three gait morphological descriptors are proposed. The first one is the Cover by Rectangles (CR) [18] applied on rendered front projections of the gait volume. The second is composed by an aggregation of three Cover by Rectangles descriptors computed on the top, side, and frontal projections of the gait volume (CRP). Lastly, the third new proposed descriptor is called Cover by Cubes (CC) and it is defined as the union of all the cubes with the largest size that can fit into a gait volume of a person.

The experimental results show that the CRP descriptor is the most reliable for using with our gait recognition method, providing good results in both AVAMVG and KY4D gait databases. The experimental results also show what is the optimal size for the histograms of each descriptor on each dataset. Finally, by using a majority vote policy on a sliding temporal window, the system is able to correctly identify up to 96% of the subjects of the AVAMVG gait database and nearly 94% of subjects of the KY4D dataset.

@&#ACKNOWLEDGMENTS@&#

This work has been developed with the support of the Research Projects called TIN2012-32952 and BROCA both financed by Science and Technology Ministry of Spain and FEDER.

@&#REFERENCES@&#


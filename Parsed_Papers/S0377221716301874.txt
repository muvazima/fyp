@&#MAIN-TITLE@&#The predictive power of the business and bank sentiment of firms: A high-dimensional Granger Causality approach

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We study the predictive power of industry-specific sentiment indicators for future macro-economic growth.


                        
                        
                           
                           To this end, we use a high-dimensional Granger Causality test.


                        
                        
                           
                           Forecast accuracy is improved by using only the most predictive industries rather than all.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Bootstrap

Granger Causality

Lasso

Sentiment surveys

Time series forecasting

@&#ABSTRACT@&#


               
               
                  We study the predictive power of industry-specific economic sentiment indicators for future macro-economic developments. In addition to the sentiment of firms towards their own business situation, we study their sentiment with respect to the banking sector – their main credit providers. The use of industry-specific sentiment indicators results in a high-dimensional forecasting problem. To identify the most predictive industries, we present a bootstrap Granger Causality test based on the Adaptive Lasso. This test is more powerful than the standard Wald test in such high-dimensional settings. Forecast accuracy is improved by using only the most predictive industries rather than all industries.
               
            

@&#INTRODUCTION@&#

Sentiment indicators are often considered to be among the most important leading indicators of the real economy (Dreger & Kholodilin, 2013) and are therefore closely followed by business cycle analysts, central banks and business owners (Claveria, Pons, & Ramos, 2007; Martinsen, Ravazzolo, & Wulfsberg, 2014; Vuchelen, 2004). However, studies on the predictive power of sentiment indicators find mixed results. While many studies find that sentiment indicators have predictive power for future economic developments (Abberger, 2007; Christiansen, Eriksen, & Moller, 2014; Hansson, Jansson, & Lof, 2005; Klein & Oezmucur, 2010; Kumar, Leone, & Gaskins, 1995; Lemmens, Croux, & Dekimpe, 2005), others conclude that sentiment indicators provide only limited information for predicting economic variables (Claveria et al., 2007; Cotsomitis and Kwan, 2006; Dreger and Kholodilin, 2013 and Bruno, 2014).

An important communality between these studies is the use of aggregate sentiment indicators. This paper, instead, examines the predictive power of disaggregate sentiment indicators. Especially in the context of business sentiment – as is the topic of this paper – some segments have more predictive power than others. Here, we segment firms according to their industry. Our methodology takes into account that different industry segments might contain predictive power for different macro-economic indicators.

To study the predictive power, we use a Granger Causality approach. A set of time series Granger Causes another time series if the former has incremental predictive power for the latter. Granger Causality tests in low-dimensional time series settings have a long history. They are used, among others, in macro-economics to study the predictive power of monetary aggregates for output and price variables (Sahoo & Acharya, 2010), in operational research to study the predictive power of academic literature for practitioner literature (Ghosh, Troutt, Thornton, & Offodile, 2010), or in finance to study the predictive power of volume for stock prices (Blasco, Corredor, Del Rio, & Santamaria, 2005). Because predictive analysis based on disaggregate sentiment indicators requires handling a large number of such indicators, we introduce a Granger Causality test for high-dimensional time series data.

Recently, testing procedures for high-dimensional cross-section data has gained attention, for instance Meinshausen, Meier, and Bühlmann (2009); Wasserman and Roeder (2009) and Chatterjee and Lahiri (2011). We extend the residual bootstrap procedure of Chatterjee and Lahiri (2011) to high-dimensional time series data. The bootstrap test statistic, based on the Adaptive Lasso (Zou, 2006), identifies those industry segments whose predictive power is statistically significant. Our simulation study shows that this test statistic is more powerful than the standard Wald test statistic in a high-dimensional setting. Furthermore, important gains in forecast accuracy are obtained by not using all industry segments but by first selecting the most predictive ones using the bootstrap test.

We use a unique data set that not only measures the sentiment of firms towards their own situation (“business sentiment”) – as is classical for sentiment indicators – but also measures the sentiment of firms towards the banking industry (“bank sentiment”). For the economy to be able to grow, it is essential that firms have access to credit, typically provided by banks. Especially in the aftermath of the recent economic downturn and banking crises, distressed banks can constrain the economy (Dell’Ariccia, Detragiache, & Rajan, 2008; Fernandez, Gonzalez, & Suarez, 2013; Kroszner, Laeven, & Klingebiel, 2007).

The remainder of this article is structured as follows. In Section 2, we discuss the contribution of our paper to the Business Sentiment literature. Section 3 describes the data on business and bank sentiment, as well as the macro-economic indicators. Section 4 introduces Granger Causality Testing in high-dimensional time series models. In Section 5, a simulation study shows the good performance of our methodology in terms of size and power of the test statistic and forecast accuracy. In Section 6, we apply the proposed methodology to identify the most predictive industry segments for several future macro-economic indicators. In Section 7, we show that forecast accuracy can be improved by using only the most predictive industry segments instead of all industry segments. The robustness of our findings is investigated in Section 8. Finally, Section 9 concludes.

Our objective is to study the predictive power of Business Sentiment Surveys for future macro-economic growth. Business Sentiment Surveys are carried out on a monthly basis by various public and private institutions. These surveys are the most popular channel to get insight into the beliefs of economic agents at the supply side of the economy. If business owners feel confident about their current and future economic situation, they might invest more and increase their activity. Hence, Business Sentiment Surveys are often seen as early indicators for future economic developments.

The Joint Harmonized EU Programme of Business and Consumer Sentiment Surveys systematically collects sentiment data using surveys. The Business Sentiment Survey includes questions on several aspects of the firm’s economic situation, such as their expected production, selling prices and exports. In contrast to Consumer Sentiment Surveys that include questions on the consumer’s assessment of the overall economy, Business Sentiment Surveys typically only consist of an evaluation of each firm’s own economic situation, i.e. the well-known “business sentiment” (e.g. Abberger, 2007; Christiansen et al., 2014; Claveria et al., 2007; Gelper and Croux, 2010; Hansson et al., 2005; Klein and Oezmucur, 2010; Lemmens et al., 2005.).

In addition to business sentiment, we also study “bank sentiment”, i.e. the sentiment of firms towards the banking industry. Studying bank sentiment is relevant since access to financial resources is crucial for firms being able to grow. Typically, these financial resources are provided by banks. This is especially true for small- to medium-sized firms (e.g. Angilella & Mazzu, 2015; Beck & Demirguc-Kunt, 2006). Germany, the country we study in this paper, is dominated by this type of companies: in our sample, around 93% of the respondents are small- to medium-sized firms. To the best of our knowledge, we are the first to study the importance of sentiment towards the banking industry.

Studying the predictive power of these business and bank sentiment indicators is challenging given the large amount of sentiment indicators that is available. In our sentiment application, 150 sentiment indicators are measured over 40 months. We combine all 150 sentiment indicators in one large model. To handle this high-dimensionality, we use Penalized Maximum Likelihood estimation. Our approach also involves a selection procedure: out of the 150 sentiment indicators, we select the most predictive ones using a Granger Causality test. These selected sentiment indicators are then used to forecast macro-economoic growth.

To handle the high-dimensionality of sentiment data, previous studies either (i) summarize the information from all individual sentiment indicators into a aggregated sentiment indicator and study the latter’s predictive power (Abberger, 2007; Christiansen et al., 2014; Claveria et al., 2007; Gelper & Croux, 2010; Hansson et al., 2005; Klein & Oezmucur, 2010), or (ii) estimate separate models for the individual sentiment indicators and combine the forecast from these models (Martinsen et al., 2014). However, these approaches involve several issues. By aggregating, one risks losing valuable information. Though aggregate indicators are often followed by business analysts and used in economic research, the individual sentiment indicators might contain even more relevant and interesting information (Roos, 2008). Indeed, Martinsen et al. (2014) find that forecast models with individual sentiment indicators considerably improve models with aggregated sentiment indicators. An advantage of our approach compared to the forecast combination approach of Martinsen et al. (2014) is that we investigate whether forecast performance can be improved by using only the most predictive indicators instead of using all. Our empirical results, to be discussed in Section 7, show that further improvements in forecast performance are indeed obtained by using only the most predictive indicators.

We use a unique data set provided to us by EUWIFO, the European Economic Research Institute. EUWIFO is an owner-managed business that conducts business climate interviews. By conducting interviews with firms spread over Germany, EUWIFO gathers information on the confidence these firms have in their own economic situation and in the banking sector. Firms are divided into segments according to the industry in which they are active. To this end, we use NACE codes since this is the standard business classification framework in the European Union (e.g. Weinstein, 2013). We consider 10 industry segments, as listed in Table 1
                     .

The interviews consist of two parts. In the first part, the Business Survey, firms are asked to assess their own situation. In the second part, the Bank Survey, firms are asked to assess the German bank sector.

Each firm receives 9 questions to assess their own economic situation. They are asked to assess changes (this year compared to last year) in (1) turnover, (2) earnings, (3) number of employees, (4) investments, (5) incoming domestic orders, (6) incoming foreign orders, (7) utility and maintenance costs, (8) tax burden, and (9) cost through government red tape. For each question, answers are favorable, neutral or unfavorable. For all the firms within an industry segment, we calculate a balance of opinion for each question, defined as the percentage of favorable answers minus the percentage of unfavorable answers. We construct 9 such sentiment indicators for each of the 10 industries, which amounts to 90 business sentiment indicators.

Each firm is asked to assess the German bank sector. In total, 243 German banks are included in the Bank Survey. Each firm first has to indicate which of these 243 German banks they know. For the banks they know, they are asked to assess their consideration towards that specific bank and the reputation of that specific bank. Answers are either favorable or unfavorable and a balance of opinion indicator is calculated for each question. We include three indicators: the average consideration indicator, averaged over all German banks, the consideration indicator towards the Sparkassen, and the consideration indicator towards the Volksbanken. The latter two are the most well-known banks in Germany. We also construct three reputation indicators per industry segment following an analogous approach. As we construct three bank considerations and three bank reputation indicators for each of the 10 industries, this amounts to 60 bank sentiment indicators.

Joining the 90 business sentiment indicators and the 60 bank sentiment indicators results in a total of 150 time series. We combine all 150 sentiment indicators in one high-dimensional data set. All time series are observed over 
                                 
                                    T
                                    =
                                    40
                                 
                               months (January 2012–April 2015). We study the predictive power of these sentiment indicators for 8 German macro-economic indicators (Table 2
                              ).

The 150 time series are grouped into blocks by industry segment (cfr. Table 1). For each of the 10 industry segments, we have one block of 9 indicators from the Business Survey and one block of 6 indicators from the Bank Survey. Our methodology is such that we select either all 9 business sentiment indicators for an industry, or none. Similarly, we will select either all 6 bank sentiment indicators for an industry or none. This way, we can investigate the difference in predictive power between the business and bank sentiment indicators. To identify the most predictive blocks, we perform joint hypothesis tests. We test if the set of indicators in a particular block Granger Causes a particular macro-economic indicator. This predictive analysis involves a large number of disaggregate sentiment indicators. In the next section, we introduce a Granger Causality testing procedure that can handle such a high-dimensional situation.

Performing Granger Causality tests on a data set with many time series relative to the length of the series is challenging. In these high-dimensional settings, estimation by standard procedures becomes inaccurate. In our sentiment application, the number of time series (i.e. 
                        
                           k
                           =
                           150
                        
                     ) even exceeds the length of the time series (i.e. 40), making it impossible to use standard estimation procedures. Penalized estimation brings an outcome.

Let yt
                         be a one-dimensional stationary time series. We assume that yt
                         follows a ARX(p) model, i.e. an autoregressive model of order p with k predictor time series collected in the (k × 1) vector x
                        
                           t
                        :

                           
                              (1)
                              
                                 
                                    
                                       
                                          
                                             y
                                             t
                                          
                                       
                                       
                                          =
                                       
                                       
                                          
                                             
                                                b
                                                1
                                             
                                             
                                                y
                                                
                                                   t
                                                   −
                                                   1
                                                
                                             
                                             +
                                             
                                                b
                                                2
                                             
                                             
                                                y
                                                
                                                   t
                                                   −
                                                   2
                                                
                                             
                                             +
                                             ⋯
                                             +
                                             
                                                b
                                                p
                                             
                                             
                                                y
                                                
                                                   t
                                                   −
                                                   p
                                                
                                             
                                             +
                                             
                                                a
                                                1
                                             
                                             
                                                x
                                                
                                                   t
                                                   −
                                                   1
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                       
                                       
                                          
                                             +
                                             
                                             
                                                a
                                                2
                                             
                                             
                                                x
                                                
                                                   t
                                                   −
                                                   2
                                                
                                             
                                             +
                                             ⋯
                                             +
                                             
                                                a
                                                p
                                             
                                             
                                                x
                                                
                                                   t
                                                   −
                                                   p
                                                
                                             
                                             +
                                             
                                                e
                                                t
                                             
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where b
                        1 to bp
                         are the autoregressive parameters, the parameters a
                        1 to a
                        
                           p
                         are (1 × k) vectors and the error term et
                         is assumed to follow a N(0, σ) distribution. We assume, without loss of generality, that all time series are mean centered such that no intercept is included.

If the number of components in x
                        
                           t
                         is large, the number of unknown parameters in Eq. (1) explodes. To ensure accurate estimation, we use Penalized Maximum Likelihood estimation (e.g. Zou, 2006 in a regression context, or Gelper, Wilms, and Croux, 2015 in a time series context). Write model (1) in matrix notation as

                           
                              (2)
                              
                                 
                                    y
                                    =
                                    X
                                    
                                       β
                                    
                                    +
                                    e
                                    
                                    ,
                                 
                              
                           
                        where y is the column vector 
                           
                              (
                              
                                 y
                                 1
                              
                              ,
                              …
                              ,
                              
                                 y
                                 T
                              
                              )
                              ,
                           
                         and the matrix 
                           
                              X
                              =
                              (
                              
                                 
                                    Y
                                    ̲
                                 
                                 1
                              
                              ,
                              …
                              ,
                              
                                 
                                    Y
                                    ̲
                                 
                                 p
                              
                              ,
                              
                                 
                                    X
                                    ̲
                                 
                                 1
                              
                              ,
                              …
                              ,
                              
                                 
                                    X
                                    ̲
                                 
                                 p
                              
                              )
                           
                        . Here 
                           Y
                         
                        
                           j
                         is (T × 1), containing the values of the time series at lag j in its column; and 
                           X
                         
                        
                           j
                         is an (T × k) matrix, containing the values of the k predictor time series at lag j in its columns, for 1 ≤ j ≤ p. The vector 
                           β
                         contains the parameters values 
                           
                              
                                 b
                                 1
                              
                              ,
                              …
                              ,
                              
                                 b
                                 p
                              
                              ,
                              
                                 a
                                 1
                              
                              ,
                              …
                              ,
                              
                                 a
                                 p
                              
                              ,
                           
                         and has length 
                           
                              p
                              (
                              1
                              +
                              k
                              )
                           
                        . In case 
                           
                              p
                              (
                              1
                              +
                              k
                              )
                              >
                              T
                              ,
                           
                         the Maximum Likelihood estimator does not exist. The Penalized Maximum Likelihood estimator is, however, still computable.

The penalized estimator of the regression parameter 
                           β
                         is obtained by minimizing the negative log likelihood with a penalization on the elements of 
                           β
                        :

                           
                              (3)
                              
                                 
                                    
                                       
                                          
                                             β
                                          
                                          ^
                                       
                                       λ
                                    
                                    =
                                    
                                       argmin
                                       
                                          β
                                       
                                    
                                    
                                    
                                       1
                                       T
                                    
                                    
                                       
                                          (
                                          y
                                          −
                                          X
                                          
                                             β
                                          
                                          )
                                       
                                       ′
                                    
                                    
                                       (
                                       y
                                       −
                                       X
                                       
                                          β
                                       
                                       )
                                    
                                    +
                                    λ
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          p
                                          (
                                          1
                                          +
                                          k
                                          )
                                       
                                    
                                    
                                       
                                          w
                                          ^
                                       
                                       i
                                    
                                    
                                       |
                                       
                                          β
                                          i
                                       
                                       |
                                    
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              
                                 w
                                 ^
                              
                              i
                           
                         are weights and λ > 0 is a sparsity parameter. This estimator is the Adaptive Lasso (Zou, 2006). It generalizes the popular Lasso (e.g. Hastie, R., and Friedman, 2009, Chapter 3) which shows good performance in operational research (e.g. Ballings & Van den Poel, 2015; Huang, Fildes, & Soopramanien, 2014). Use of the Adaptive Lasso ensures that the bootstrap (Section 4.3) is consistent (Chatterjee & Lahiri, 2011). We take the weights of the Adaptive Lasso as 
                           
                              
                                 
                                    w
                                    ^
                                 
                                 i
                              
                              =
                              1
                              /
                              
                                 |
                                 
                                    
                                       β
                                       ^
                                    
                                    i
                                    ridge
                                 
                                 |
                              
                              ,
                           
                         where the Ridge estimator (Hastie et al., 2009, Chapter 3) is

                           
                              
                                 
                                    
                                       
                                          
                                             β
                                          
                                          ^
                                       
                                       λ
                                       ridge
                                    
                                    =
                                    
                                       argmin
                                       
                                          β
                                       
                                    
                                    
                                       1
                                       T
                                    
                                    
                                       
                                          (
                                          y
                                          −
                                          X
                                          
                                             β
                                          
                                          )
                                       
                                       ′
                                    
                                    
                                       (
                                       y
                                       −
                                       X
                                       
                                          β
                                       
                                       )
                                    
                                    +
                                    
                                       λ
                                       ridge
                                    
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          p
                                          (
                                          1
                                          +
                                          k
                                          )
                                       
                                    
                                    
                                       β
                                       i
                                       2
                                    
                                    .
                                 
                              
                           
                        
                     

The sparsity parameter λ and the order of the ARX, p, are selected using the Bayesian Information Criterion (BIC) (e.g. Abegaz and Wit, 2013 and references therein):

                           
                              
                                 
                                    
                                       BIC
                                       λ
                                    
                                    =
                                    T
                                    ·
                                    log
                                    
                                       (
                                       
                                          1
                                          T
                                       
                                       
                                          
                                             (
                                             y
                                             −
                                             X
                                             
                                                
                                                   
                                                      β
                                                   
                                                   ^
                                                
                                                λ
                                             
                                             )
                                          
                                          ′
                                       
                                       
                                          (
                                          y
                                          −
                                          X
                                          
                                             
                                                
                                                   β
                                                
                                                ^
                                             
                                             λ
                                          
                                          )
                                       
                                       )
                                    
                                    +
                                    d
                                    
                                       f
                                       λ
                                    
                                    ·
                                    log
                                    
                                       (
                                       T
                                       )
                                    
                                    ,
                                 
                              
                           
                        where dfλ
                         equals the number of non-zero estimated regression coefficients. We solve (3) over a range of values for λ and select the one with lowest value of the BIC. To select the order of the ARX model, we estimate the ARX model for different values of p, each time using the optimal value of λ for that value of p. We then select the order p of the ARX model again by minimizing the BIC.

We partition the vector x
                        
                           t
                         in different blocks, and denote the jth block of x
                        
                           t
                         by x
                        
                           t, j
                        , consisting of kj
                         time series. In the ARX model (1), denote the jth block of coefficients at lag i corresponding to x
                        
                           t, j
                         by a
                        
                           i, j
                        . The multivariate time series x
                        
                           t, j
                         is said to Granger Cause yt
                         if the former has incremental predictive power for the latter. We say that x
                        
                           t, j
                         does not Granger Cause yt
                         if the coefficients on all lags of x
                        
                           t, j
                         are equal to zero, i.e. 
                           
                              
                                 a
                                 
                                    1
                                    ,
                                    j
                                 
                              
                              =
                              …
                              =
                              
                                 a
                                 
                                    p
                                    ,
                                    j
                                 
                              
                              =
                              0
                           
                        .

The Adaptive Lasso estimator in (3) is sparse, meaning that some of its elements are exactly zero. The larger the value of λ, the sparser the estimator. The “Granger Lasso Selection” method (e.g. Bahadori & Liu, 2013; Fujita et al., 2007) says that a time series x
                        
                           t, j
                         Granger Causes yt
                         if at least one of the corresponding parameters 
                           
                              
                                 a
                                 
                                    1
                                    ,
                                    j
                                 
                              
                              ,
                              …
                              ,
                              
                                 a
                                 
                                    p
                                    ,
                                    j
                                 
                              
                           
                         is estimated as non-zero. Our approach is different, we infer Granger Causality relations from a bootstrap testing procedure.

The null hypothesis that a block of time series x
                        
                           t, j
                         is not Granger Causing yt
                         can be stated as

                           
                              (4)
                              
                                 
                                    
                                       H
                                       0
                                    
                                    :
                                    
                                    
                                       R
                                       j
                                    
                                    
                                       β
                                    
                                    =
                                    0
                                    ,
                                 
                              
                           
                        where R
                        
                           j
                         is a suitable 
                           
                              p
                              
                                 k
                                 j
                              
                              ×
                              p
                              
                                 (
                                 1
                                 +
                                 k
                                 )
                              
                           
                         matrix. The elements of R
                        
                           j
                         are either zero or one. We assign the value one to the elements of R
                        
                           j
                         corresponding to the autoregressive parameters 
                           
                              
                                 a
                                 
                                    1
                                    ,
                                    j
                                 
                              
                              ,
                              …
                              ,
                              
                                 a
                                 
                                    p
                                    ,
                                    j
                                 
                              
                           
                        . The corresponding Wald test statistic is given by

                           
                              (5)
                              
                                 
                                    Q
                                    =
                                    
                                       
                                          (
                                          
                                             R
                                             j
                                          
                                          
                                             
                                                β
                                             
                                             ^
                                          
                                          )
                                       
                                       ′
                                    
                                    
                                       
                                          (
                                          
                                             R
                                             j
                                          
                                          Cov
                                          
                                             (
                                             
                                                
                                                   β
                                                
                                                ^
                                             
                                             )
                                          
                                          
                                             R
                                             j
                                             ′
                                          
                                          )
                                       
                                       
                                          −
                                          1
                                       
                                    
                                    
                                       (
                                       
                                          R
                                          j
                                       
                                       
                                          
                                             β
                                          
                                          ^
                                       
                                       )
                                    
                                    .
                                 
                              
                           
                        
                     

To bootstrap this test statistic, we use the following residual bootstrap procedure (Kreiss & Lahiri, 2012):

                           
                              1.
                              Estimate the model under the null hypothesis, i.e. model (1) with the block x
                                 
                                    t, j
                                  removed at the right-hand-side. Compute the centered residuals 
                                    
                                       
                                          
                                             
                                                ɛ
                                             
                                             ^
                                          
                                          t
                                       
                                       ,
                                       for
                                       
                                       t
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       T
                                    
                                 .

Let 
                                    
                                       B
                                       =
                                       500
                                    
                                  be the number of bootstraps. For 
                                    
                                       b
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       B
                                    
                                 :
                                    
                                       (a)
                                       Construct the bootstrap time series 
                                             
                                                y
                                                t
                                                *
                                             
                                           from model (1) with the parameter estimates from step 1 and with bootstrap errors 
                                             
                                                
                                                   
                                                      ɛ
                                                   
                                                   
                                                      t
                                                   
                                                   *
                                                
                                                =
                                                
                                                   
                                                      
                                                         ɛ
                                                      
                                                      ^
                                                   
                                                   
                                                      U
                                                      t
                                                   
                                                
                                             
                                           with 
                                             
                                                
                                                   U
                                                   t
                                                
                                                ,
                                                t
                                                =
                                                1
                                                ,
                                                …
                                                ,
                                                T
                                             
                                           an i.i.d. sequence of discrete random variables uniformly distributed on 
                                             
                                                {
                                                1
                                                ,
                                                …
                                                ,
                                                T
                                                }
                                             
                                          . The predictor time series are kept fixed.

Apply the Penalized Maximum Likelihood estimator of Eq. (3) to the bootstrap sample. Denote the bootstrap estimate by 
                                             
                                                
                                                   
                                                      β
                                                   
                                                   ^
                                                
                                                b
                                                *
                                             
                                          .

Compute the bootstrap statistic 
                                             
                                                
                                                   Q
                                                   b
                                                   *
                                                
                                                =
                                                
                                                   
                                                      (
                                                      
                                                         R
                                                         j
                                                      
                                                      
                                                         
                                                            
                                                               β
                                                            
                                                            ^
                                                         
                                                         b
                                                         *
                                                      
                                                      )
                                                   
                                                   ′
                                                
                                                
                                                   
                                                      (
                                                      
                                                         R
                                                         j
                                                      
                                                      Cov
                                                      
                                                         (
                                                         
                                                            
                                                               β
                                                            
                                                            ^
                                                         
                                                         )
                                                      
                                                      
                                                         R
                                                         j
                                                         ′
                                                      
                                                      )
                                                   
                                                   
                                                      −
                                                      1
                                                   
                                                
                                                
                                                   (
                                                   
                                                      R
                                                      j
                                                   
                                                   
                                                      
                                                         
                                                            β
                                                         
                                                         ^
                                                      
                                                      b
                                                      *
                                                   
                                                   )
                                                
                                             
                                          .

Compute

                                    
                                       
                                          
                                             mid
                                             
                                             p
                                             -Value
                                             
                                             =
                                             
                                                1
                                                B
                                             
                                             
                                                ∑
                                                
                                                   b
                                                   =
                                                   1
                                                
                                                B
                                             
                                             
                                                (
                                                I
                                                
                                                   (
                                                   
                                                      Q
                                                      b
                                                      *
                                                   
                                                   >
                                                   Q
                                                   )
                                                
                                                +
                                                
                                                   1
                                                   2
                                                
                                                I
                                                
                                                   (
                                                   
                                                      Q
                                                      b
                                                      *
                                                   
                                                   =
                                                   Q
                                                   )
                                                
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                 with 
                                    
                                       
                                          Q
                                          b
                                          *
                                       
                                       
                                       
                                          (
                                          for
                                          
                                          
                                          b
                                          =
                                          1
                                          ,
                                          …
                                          ,
                                          B
                                          )
                                       
                                    
                                  
                                 B independent bootstrap statistics. I( · ) is an indicator function that takes on the value one if its argument is true and equals zero otherwise. We use the mid p-Value (Lancaster, 1949) since it may occur that the value of the test statistic and the bootstrap test statistic are both equal to zero.

By means of a simulation experiment, we (i) evaluate the size and power of the Granger Lasso test and (ii) conduct a forecast exercise. We generate yt
                      according to the following ARX(1) model

                        
                           (6)
                           
                              
                                 
                                    y
                                    t
                                 
                                 =
                                 0.5
                                 
                                    y
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 +
                                 
                                    a
                                    1
                                 
                                 
                                    x
                                    
                                       t
                                       −
                                       1
                                    
                                 
                                 +
                                 
                                    e
                                    t
                                 
                                 ,
                              
                           
                        
                     where et
                      ∼ N(0, 0.1). The predictors are generated as autoregressive processes 
                        
                           
                              x
                              t
                           
                           =
                           C
                           
                              x
                              
                                 t
                                 −
                                 1
                              
                           
                           +
                           
                              u
                              t
                           
                           ,
                        
                      with u
                     
                        t
                      ∼ Nk
                     (0, 0.1I), 
                        
                           C
                           =
                           0.5
                           I
                        
                      and I the k-dimensional identity matrix. The model parameters are chosen according to the four designs detailed in Table 3. The first three designs are the same except for the number of time series k. In design two and three, we add more non-informative time series to the model, i.e. time series with a coefficient equal to zero. The standard Maximum Likelihood estimator is computable in these three designs. The last design corresponds to the design of our sentiment application, with 
                        
                           k
                           =
                           150
                        
                      predictor time series and 
                        
                           T
                           =
                           40
                        
                     . Here, only the Penalized Maximum Likelihood estimator is computable.

For each design, we consider a data generating process under the null hypothesis H
                     0 and under the alternative hypothesis HA
                     . We divide the time series x
                     
                        t
                      and the corresponding coefficient vector a
                     1 into several blocks, as can be seen from Table 3. The first block of time series Granger Cause the response both under H
                     0 and under HA
                     . The second block of time series Granger Cause the response only under HA
                     . The remaining blocks of time series never Granger Cause the response. In the first three designs, block one to three each contain five time series, the fourth block contains the remaining ones. In the last design, there are 20 blocks, similar to our sentiment application.

We test the null hypothesis that the second block of time series does not Granger Cause the response. We compare the performance of Granger Lasso test to the standard Wald test computed from the standard Maximum Likelihood (ML) estimator.

To study the size of the test statistic, we simulate 
                           
                              N
                              =
                              1000
                           
                         time series under the null hypothesis and compute the simulated size, i.e. the proportion of simulation runs were the null hypothesis is rejected:

                           
                              (7)
                              
                                 
                                    Simulated
                                    
                                    size
                                    =
                                    
                                       1
                                       N
                                    
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       N
                                    
                                    I
                                    
                                       (
                                       
                                          p
                                          j
                                          
                                             H
                                             0
                                          
                                       
                                       <
                                       α
                                       )
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              p
                              j
                              
                                 H
                                 0
                              
                           
                         is the mid p-Value obtained in simulation run 
                           
                              j
                              =
                              1
                              ,
                              …
                              ,
                              N
                              ,
                           
                         and α is the pre-specified significance level. We consider 
                           
                              α
                              =
                              0.01
                           
                         and 
                           
                              α
                              =
                              0.05
                           
                        .


                        Results. 
                        Table 4
                         shows the simulated sizes for the standard Wald test and the Granger Lasso test. The simulated sizes of the Granger Lasso test and the standard Wald test are both close to the nominal size α in the design with 
                           
                              T
                              =
                              100
                              ,
                              k
                              =
                              25
                           
                        . When the number of time series increases relative to the length of the time series (i.e. second and third design), the Granger Lasso test remains accurately sized whereas the standard Wald test statistic gets distorted: its simulated size deviates strongly from the nominal size. In the last design, only the Granger Lasso test is available. For both 
                           
                              α
                              =
                              0.01
                           
                         and 
                           
                              α
                              =
                              0.05
                              ,
                           
                         the Granger Lasso test is reasonably accurately sized.

To study the power of the test statistic, we use size-power curves (see Davidson & MacKinnon, 1998). Size-power curves are constructed using two empirical distribution functions. We carry out the following steps:

                           
                              1.
                              Simulate 
                                    
                                       N
                                       =
                                       1000
                                    
                                  time series under the null hypothesis. Compute for each simulation run 
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                  the mid p-Value 
                                    
                                       p
                                       j
                                       
                                          H
                                          0
                                       
                                    
                                 . Calculate the empirical distribution function of the p-Values:

                                    
                                       
                                          
                                             
                                                
                                                   F
                                                   ^
                                                
                                                
                                                   H
                                                   0
                                                
                                             
                                             
                                                (
                                                
                                                   x
                                                   i
                                                
                                                )
                                             
                                             =
                                             
                                                1
                                                N
                                             
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                N
                                             
                                             I
                                             
                                                (
                                                
                                                   p
                                                   j
                                                   
                                                      H
                                                      0
                                                   
                                                
                                                ≤
                                                
                                                   x
                                                   i
                                                
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                 for a grid of values 
                                    
                                       
                                          x
                                          i
                                       
                                       ,
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       m
                                    
                                  between zero and one.

Simulate 
                                    
                                       N
                                       =
                                       1000
                                    
                                  time series under the alternative hypothesis. Compute for each simulation run 
                                    
                                       j
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                  the mid p-Value 
                                    
                                       p
                                       j
                                       
                                          H
                                          A
                                       
                                    
                                 . Calculate

                                    
                                       
                                          
                                             
                                                
                                                   F
                                                   ^
                                                
                                                
                                                   H
                                                   A
                                                
                                             
                                             
                                                (
                                                
                                                   x
                                                   i
                                                
                                                )
                                             
                                             =
                                             
                                                1
                                                N
                                             
                                             
                                                ∑
                                                
                                                   j
                                                   =
                                                   1
                                                
                                                N
                                             
                                             I
                                             
                                                (
                                                
                                                   p
                                                   j
                                                   
                                                      H
                                                      A
                                                   
                                                
                                                ≤
                                                
                                                   x
                                                   i
                                                
                                                )
                                             
                                             .
                                          
                                       
                                    
                                 
                              

Plot 
                                    
                                       
                                          
                                             F
                                             ^
                                          
                                          
                                             H
                                             0
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             i
                                          
                                          )
                                       
                                    
                                  against 
                                    
                                       
                                          
                                             F
                                             ^
                                          
                                          
                                             H
                                             A
                                          
                                       
                                       
                                          (
                                          
                                             x
                                             i
                                          
                                          )
                                       
                                       ,
                                    
                                  for 
                                    
                                       
                                          x
                                          i
                                       
                                       ,
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       m
                                    
                                 .


                        Results. Size-power curves of the Granger Lasso test and standard Wald test are shown in Fig. 1 (first three designs). The larger the difference between the size-power curve and the 45° line, the more power the test has. For 
                           
                              k
                              =
                              25
                           
                         (i.e. left panel) both curves are rapidly increasing and very similar. When the number of time series increases (i.e. middle and right panel), the size-power curve of the Granger Lasso test is hardly affected, and achieves a much larger power than the standard Wald test.

For forecasting the time series yt
                        , we use a two-step procedure. First, we select predictor time series. Second, we estimate the model with only the selected predictor time series. We consider four selection and six estimation techniques, yielding 24 selection–estimation combinations. We investigate the performance of each combination in forecasting the response.

As selection techniques we consider: (1) use all time series, (2) use the standard Wald test to discard blocks of time series that are not Granger Causing the response, (3) use Granger Lasso Selection (cfr. Section 4.1) to discard blocks of time series that are not Granger Causing the response, (4) use the Granger Lasso test to discard blocks of time series that are not Granger Causing the response. Selection technique (4) is our proposed selection technique. The tests are carried out at a 1% significance level.

After selecting the predictor time series, we forecast the response using either (1) Maximum Likelihood, (2) the Adaptive Lasso estimator, (3) Bayesian shrinkage with the Minnesota prior (Litterman, 1986), (4) the Factor Model of Stock and Watson (2002), (5) Bagging (Hastie et al., 2009, Chapter 8), (6) Random Forest (Hastie et al., 2009, Chapter 15). These are all leading methods for macro-economic forecasting (Inoue & Kilian, 2008). Methods (2) and (3) perform shrinkage. While the Adaptive Lasso puts some of the estimated coefficients exactly to zero, the Bayesian estimator only shrinks the estimated coefficients towards zero. Factor Models reduce the dimension of the predictor time series by extracting a small number of common factors using principal component analysis.
                           1
                        
                        
                           1
                           The number of factors r is determined by calculating the maximum eigenvalue ratio criterion 
                                 
                                    
                                       
                                          r
                                          ^
                                       
                                       j
                                    
                                    =
                                    
                                       
                                          λ
                                          ^
                                       
                                       j
                                    
                                    /
                                    
                                       
                                          λ
                                          ^
                                       
                                       
                                          j
                                          +
                                          1
                                       
                                    
                                 
                               for 
                                 
                                    j
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    k
                                    −
                                    1
                                 
                               from the eigenvalues 
                                 
                                    
                                       
                                          λ
                                          ^
                                       
                                       j
                                    
                                    ,
                                    …
                                    ,
                                    
                                       
                                          λ
                                          ^
                                       
                                       k
                                    
                                 
                               and selecting 
                                 
                                    r
                                    =
                                    
                                       argmax
                                       j
                                    
                                    
                                       
                                          r
                                          ^
                                       
                                       j
                                    
                                 
                              .
                         Bagging draws bootstrap samples from the original model, makes a prediction - for which we use the Adaptive Lasso – based on each bootstrap sample and averages these predictions over the bootstrap samples. We use a stationary bootstrap (Politis & Romano, 1994) to account for the time series structure of the data in the construction of the bootstrap samples.
                           2
                        
                        
                           2
                           The block resampling uses a random bootstrap block size generated from a genometric distribution with mean six. We take 
                                 
                                    B
                                    =
                                    100
                                 
                               bootstrap samples.
                         Random Forest differs from Bagging in that it selects random subsets of predictors. We take this subset size to be equal to the square root of the number of predictors.

To evaluate forecast accuracy, we conduct a rolling window forecast exercise. We use a window of size 
                           
                              S
                              =
                              ⌊
                              0.90
                              ·
                              T
                              ⌋
                           
                        . At each point 
                           
                              t
                              =
                              S
                              ,
                              …
                              ,
                              T
                              −
                              1
                              ,
                           
                         the models are re-estimated and one-step-ahead forecasts are calculated. We evaluate the forecast accuracy of each selection–estimation technique combination by calculating the Mean Absolute Forecast Error
                           3
                        
                        
                           3
                           Similar conclusions can be drawn by looking at the Mean Squared Forecast Error.
                        
                        
                           
                              (8)
                              
                                 
                                    MAFE
                                    =
                                    
                                       
                                          1
                                          
                                             T
                                             −
                                             S
                                          
                                       
                                    
                                    
                                       ∑
                                       
                                          t
                                          =
                                          S
                                       
                                       
                                          T
                                          −
                                          1
                                       
                                    
                                    
                                       |
                                       
                                          
                                             y
                                             ^
                                          
                                          
                                             t
                                             +
                                             1
                                          
                                       
                                       −
                                       
                                          y
                                          
                                             t
                                             +
                                             1
                                          
                                       
                                       |
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              
                                 y
                                 ^
                              
                              
                                 t
                                 +
                                 1
                              
                           
                         is the predicted response for time 
                           
                              t
                              +
                              1
                           
                        . The MAFE is computed for each simulated time series, and their average over 
                           
                              N
                              =
                              100
                           
                         simulation runs is reported in Table 5.


                        Results. 
                        Table 5 shows that selecting predictor time series is better than taking all series, for all estimation techniques (except the Bayesian shrinkage estimator). Among the selection techniques, improvements are, overall, larger with the proposed Granger Lasso test compared to the Granger Lasso Selection approach. Granger Lasso Selection discards less blocks of time series compared to the Granger Lasso test, yielding less parsimonious models and reduced forecast performance. When the number of time series increases relative to the length of the time series, the Granger Lasso test also performs substantially better than the standard Wald test. Paired t-tests confirm that (in the large majority of cases), the improvements of the Granger Lasso test compared to the other selection techniques are significant. More precisely, the Granger lasso test performs significantly best – among the four selection techniques - in 15 out of 18 cases (design 
                           
                              T
                              =
                              100
                              ,
                              k
                              =
                              50
                           
                        ), 16 out of 18 cases (design 
                           
                              T
                              =
                              100
                              ,
                              k
                              =
                              75
                           
                        ), and 8 out of 10 cases (design 
                           
                              T
                              =
                              40
                              ,
                              k
                              =
                              150
                           
                        ). The good performance of the Granger Lasso test is most pronounced in the high-dimensional designs.

For all simulation designs, the best forecast always includes the Granger Lasso test. Among the estimation techniques, the Adaptive Lasso performs best. After the first selection of predictive blocks of time series, the Adaptive Lasso can further reduce the number of predictor time series in the second step. This is most suited for settings with few relevant predictor time series and many irrelevant, noise predictor time series. Similar conclusions are obtained by Bühlmann and Hothorn (2010) who discuss a “Twin Boosting” procedure for improved feature selection and prediction.

We identify the most predictive industry segments for future macro-economic developments using the Granger Lasso test from Section 4.

We estimate 8 ARX models, one for each macro-economic indicator to predict. Following standard practice, we study the predictive power of sentiment change indicators for macro-economic growth. Hence, the time series yt
                         entering model (1) is one of the 8 macro-economic indicators of Table 2 taken in log-differences. The vector x
                        
                           t
                         contains the 
                           
                              k
                              =
                              150
                           
                         business and bank sentiment indicators in first differences at time t. To ensure a uniform treatment of all time series, we check for stationarity using the pooled unit root test from Levin, Lin, and Chu (2002). We find the 8 macro-economic growth time series to be jointly stationary (p-Value < 0.01), as well as the 150 sentiment change time series (p-Value < 0.01). The Augmented Dickey-Fuller tests also indicate each individual time series to be stationary.

We estimate each ARX model using the Penalized Maximum Likelihood estimator from Section 4. Then, we perform Granger Causality tests, one for each of the 20 blocks of sentiment indicators (cfr. Section 3). As such, we test if the change in opinion of a particular industry segment – as measured through the Business Survey – has incremental predictive power for the German macro-economic growth indicators. We repeat this exercise for each industry segment using the Bank Survey.

For each industry, Table 6
                         reports the p-Value of the test that the change in opinion of that particular industry does not Granger Cause a particular macro-economic growth indicator. Significant results at the 1% level are in bold. We discuss the results by building on the sectoral classification framework which distinguishes the primary, secondary, tertiary and quaternary sector.


                        Business Survey. The primary sector, unlike the other sectors, has almost no incremental predictive power. The primary sector’s contribution to Germany’s GDP is also the smallest. The secondary industry has most incremental predictive power for the macro-economic growth indicators to which these sectors contribute most (IP-A1, IP-A2, IP-M and IP-E). Firms active in the tertiary and especially the quaternary sector have incremental predictive power for several macro-economic growth indicators. This sector consists of the knowledge-based part of the economy, and accounts for roughly 65% of Germany’s GDP. Firms active in these sectors are at the heart of the whole economy.


                        Bank Survey. The Bank Survey contains less incremental predictive power than the Business Survey. Except for the Public services industry that has incremental predictive power for the majority of macro-economic growth indicators, the predictive power of bank sentiment for predicting future macro-economic developments is limited. This is in line with Dell’Ariccia et al. (2008) who find that the real effects of a banking crisis are limited in developed countries, in countries that have more access to foreign financing, and countries where banking crises are less severe, which all apply to Germany.

We perform a rolling-window forecast exercise using a window of length 
                        
                           S
                           =
                           30
                        
                     . For each time window, we estimate the 8 ARX models. We use the same selection and estimation techniques as in Section 5.2, except for the standard Wald test and the ML estimator which are not available since the number of time series exceeds the time series length. Next, one-step-ahead forecasts are computed for 
                        
                           t
                           =
                           S
                           +
                           1
                           ,
                           …
                           ,
                           T
                        
                     . We report the Mean Absolute Forecast Error, see Eq. (8), for each macro-economic indicator and each selection–estimation technique combination in Table 7
                     .

Among the three selection techniques, the proposed Granger Lasso test performs best. It attains the lowest value of the MAFE in 31 out of 40 cases (78% of the cases). A paired t-test on the 40 MAFEs indicates that the Granger Lasso test significantly outperforms the other selection techniques (both p-Values < 0.01). Using all industries or using Granger Lasso Selection yields MAFEs close to each other. It turns out that the latter hardly discards industry blocks. In contrast, a much more parsimonious model is obtained using the Granger Lasso test. These parsimonious models lead to an improved forecast accuracy, in the majority of cases.

For the Adaptive Lasso estimation technique, selection based on the Granger Lasso test consistently leads to the lowest MAFE. The MAFEs with the Granger Lasso test are, on average, 21% lower compared to the other selection techniques. After the first selection step where either an entire block of business or bank sentiment indicators is selected or not, the Adaptive Lasso allows some of the time series belonging to one of the selected blocks to be discarded in this second stage. Further reducing the number of relevant predictor time series within the selected blocks improves forecast accuracy.

In line with the results of our simulation study, pre-selecting based on the Granger Lasso test is less favorable for the Bayesian shrinkage estimator compared to the other estimation techniques. Nevertheless, the Granger Lasso test in combination with the Bayesian shrinkage estimator still leads to the lowest MAFE for 5 out of 8 macro-economic indicators, with an average reduction in MAFE of 5%.

For the Factor Model, the Granger Lasso test leads to the lowest MAFE for 6 out of 8 macro-economic indicators. The MAFEs with the Granger Lasso test are, on average, 20% lower compared to the other selection techniques. Discarding the least predictive industry blocks in this high-dimensional data set and estimating the factors based on the most predictive industry blocks thus leads to important gains in forecast accuracy. This result is in line with Bai and Ng (2008) who find important gains in forecast accuracy from diffusion index models by not using all predictors but by using fewer, informative predictors.

Also for Bagging and Random Forest, the Granger Lasso test selection technique leads towards the lowest MAFE for the majority (6 out of 8) of macro-economic indicators, with an average reduction of 8%. A similar conclusion is drawn by Inoue and Kilian (2008) who find Bagging in combination with pre-selecting predictors to improve macro-economic forecast performance.

We consider three alternative approaches to select the most predictive sentiment indicators and investigate whether they change our findings from Section 6 and Section 7.
                        4
                     
                     
                        4
                        Detailed results are available from the authors upon request.
                     
                  

The proposed Granger Lasso test investigates the predictive power of blocks of sentiment indicators. Either all 9 business sentiment indicators are selected for an industry, are none. Similarly, either all 6 bank sentiment indicators are selected for an industry, are none. An advantage of this block approach is that it is decisive: an industry segment is either found to be predictive or not, which eases interpretation. Alternatively, we take blocks of size one and perform 
                           
                              k
                              =
                              150
                           
                         Granger Causality tests, each time testing whether an individual sentiment change indicator (one out of 150) Granger Causes the macro-economic growth indicator.

We find no significance difference in forecast performance between the Granger Lasso test applied on the blocks, as discussed in Section 7, or on the blocks of size one (p-Value 
                           
                              =
                              0.22
                           
                         of paired t-test). It turns out that cost-related assessment questions (i.e. assessment of changes in investments, cost through government red tape, utility and maintenance costs, employees) contain most incremental predictive power. Income-related assessment questions (i.e. assessment of changes in turnover) contain, overall, less incremental predictive power.

Instead of working with 20 blocks of individual sentiment indicators, we replace them by their average value. This results in a total of 20 aggregated sentiment indicators. We test whether an aggregated sentiment change indicator (one out of 20) Granger Causes the macro-economic growth indicator.

We find no significant difference in forecast performance between the Granger Lasso test applied on the blocks, as discussed in Section 7, or on the aggregated sentiment indicators (p-Value = 0.90 of paired t-test). In line with our previous results, we find that (i) the Business Survey contains more incremental predictive power than the Bank Survey, (ii) industries contain most predictive power for those macro-econonmic indicators most closely tied to their day-to-day business.

Our main research question is whether the sentiment of different industry segments has predictive power for macro-economic indicators. Our methodology is also applicable to other ways of segmenting firms, as region in which they are located or according to their company size. For our data, there are 10 regions and three company sizes. We re-estimate the 8 ARX models and perform the Granger Causality tests for the 20 regional blocks (i.e. 10 blocks for the Business Survey, 10 blocks for the Bank Survey). Likewise, we re-estimate the 8 ARX models and perform the Granger Causality tests for the 6 company size blocks (i.e. 3 blocks for the Business Survey, 3 blocks for the Bank Survey).

The forecast performance of the Granger Lasso test obtained with either industry, region or company size segments is very similar. We compare Mean Absolute Forecast Errors as in Table 7. For the regional segments, the Granger Lasso test is the best performing selection technique and attains the lowest value of the MAFE in 60% of the cases (24 out of 40). Similarly for the company size segments where the Granger Lasso test leads towards the lowest MAFE in 68% of the cases (27 out of 40).

We again find business sentiment to have more incremental predictive power than bank sentiment. Furthermore, Germany’s largest geo-economical regions (i.e. Ruhr area and the Southern states) have most incremental predictive power for the macro-economic indicators to which their day-to-day business contributes most, i.e. IP-A1, IP-A2, IP-M, IP-E and IP-CaGo, IP-CoGo respectively. Finally, small- and medium-sized companies have more incremental predictive power than large companies. Germany is dominated by small- to medium-sized companies who are global market leaders in their segments, and, hence, those might be best at evaluating Germany’s economy.

@&#DISCUSSION@&#

This paper presents a high-dimensional Granger Causality test. It detects the most predictive industry segments for future macro-economic developments. For this purpose, we use both business and bank sentiment surveys answered by firms across Germany. Not all industry-specific sentiment indicators are equally predictive for all macro-economic indicators. Industries contain most predictive power for the macro-economic indicators most closely tied to their day-to-day business activities.

Our forecast exercise shows that important gains in forecast accuracy can be obtained by not using all industry segments, but by first selecting the most predictive ones using the Granger Lasso test selection technique. In high-dimensional settings, a lot of noise might be present. By selecting predictor variables, a more parsimonious model with less noise is obtained. Note that losing information is a potential risk of selecting predictor variables, hence, the need for research on appropriate selection methods. The selection of the most pertinent industry segments also provides important information for institutes conducting these sentiment surveys. For instance, instead of equally spreading respondents among all segments, the number of respondents in predictive segments could be increased, whereas the number of respondents in non-predictive segments could be decreased. Alternatively, non-predictive segments could even be completely discarded, which provides an opportunity to obtain cost savings.

The identification of pertinent respondents also applies to consumer sentiment surveys. In the large literature on consumer sentiment, this topic has received little attention. We perform a similar exercise as described in this paper using a consumer sentiment survey data set from the National Bank of Belgium. Sentiment indicators are available for different classes of consumers’ net disposable income, profession, employment status, education, age and gender. We study their predictive power for several retail trade indicators. The profession, education, and age sentiment indicators contain most predictive power. Again, important gains in forecast accuracy can be obtained by first selecting the most predictive sentiment indicators (for a specific target variable of interest) instead of using all indicators.

We use a high-dimensional Granger Causality approach to study the predictive power of sentiment data collected via surveys. One could consider social media as an alternative channel to collect sentiment data. While their role in collecting consumer sentiment has received considerable attention (e.g. Asur & Huberman, 2010; Pang & Lee, 2008; Stieglitz & Dang-Xuan, 2013), their role in collecting business sentiment has received limited to no attention. It should be noted that collecting data via social media poses sampling issues since only a subpopulation (i.e. the participants of these social media) of all respondents is reached. In contrast, data collected via surveys are sent out to a random sample of all respondents.

While we study the predictive power of sentiment indicators for future macro-economic growth, another interesting research question is whether sentiment indicators and macro-economic indicators move together in the long-run. This could be addressed using Cointegration analysis, which aims at detecting long-run relationships between several time series (see Lütkepohl, 1993 for an introduction, Östermark, 2001 or Musti and D’Ecclesia, 2008 for an application. Testing for cointegration in high-dimensions is, however, an open research area (e.g. Breitung & Cubadda, 2011) and ideas similar to the once introduced in this paper could serve as a starting point.

Finally, we need to further deepen our understanding on the usefulness of bank sentiment. It would be interesting to investigate if this sentiment differs between, for instance, countries that are more or less severely hit by banking crises, and developed or developing countries. The study of sentiment with respect to the banking sector opens a new area of research on sentiment surveys.

@&#ACKNOWLEDGMENTS@&#

The authors gratefully acknowledge financial support from the FWO (Research Foundation Flanders, Contract number 11N9913N). We would also like to thank EUWIFO for providing the data.

@&#REFERENCES@&#


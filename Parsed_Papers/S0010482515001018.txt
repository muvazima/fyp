@&#MAIN-TITLE@&#Improving brain–computer interface classification using adaptive common spatial patterns

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           An adaptive common spatial patterns method is proposed for EEG spatial filtering.


                        
                        
                           
                           The method is evaluated for intra- and inter-subject classifications.


                        
                        
                           
                           The method is compared to existing techniques and shows superior performance.


                        
                        
                           
                           The effects of adding misclassified trials to training data are investigated.


                        
                        
                           
                           The method is potentially applicable to various real-time BCI tasks.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Brain–computer interface

Common spatial patterns

Electroencephalography

Adaptive

Nonstationarity

@&#ABSTRACT@&#


               
               
                  Common Spatial Patterns (CSP) is a widely used spatial filtering technique for electroencephalography (EEG)-based brain–computer interface (BCI). It is a two-class supervised technique that needs subject-specific training data. Due to EEG nonstationarity, EEG signal may exhibit significant intra- and inter-subject variation. As a result, spatial filters learned from a subject may not perform well for data acquired from the same subject at a different time or from other subjects performing the same task. Studies have been performed to improve CSP׳s performance by adding regularization terms into the training. Most of them require target subjects׳ training data with known class labels. In this work, an adaptive CSP (ACSP) method is proposed to analyze single trial EEG data from single and multiple subjects. The method does not estimate target data׳s class labels during the adaptive learning and updates spatial filters for both classes simultaneously. The proposed method was evaluated based on a comparison study with the classic CSP and several CSP-based adaptive methods using motor imagery EEG data from BCI competitions. Experimental results indicate that the proposed method can improve the classification performance as compared to the other methods. For circumstances where true class labels of target data are not instantly available, it was examined if adding classified target data to training data would improve the ACSP learning. Experimental results show that it would be better to exclude them from the training data. The proposed ACSP method can be performed in real-time and is potentially applicable to various EEG-based BCI applications.
               
            

@&#INTRODUCTION@&#

Brain–computer interface (BCI) is a communication technique that aims to identify a subject׳s brain intents and translate them into machine commands to control the operations of electromechanical devices. Electroencephalography (EEG) might be the most widely used noninvasive imaging technique in BCI. Due to the non-stationary nature of EEG, which is usually caused by changes of electrodes impedance or positions, subjects׳ attention, fatigue, eye movements, or muscular activity, EEG signals exhibit large intra- and inter-subject variation [1]. As a result, an observed EEG pattern from a subject might not be repeatable from the same subject at a different time or from different subjects performing the same task. Various methods have been proposed to address the nonstationarity in EEG-based BCI [1,2]. These methods were focused on either feature extraction process [1,3–16], or feature modelling and classification [16–29]. Some methods adapt to the intra- and/or inter-subject variation through supervised adaptive learning [20,24,30], semi-supervised or unsupervised learning [3,4,7,11,17–19,23,31–34], while others try to identify stationary patterns that are common within a single subject or across multiple subjects [1,5,6,8–10,12,14,13,15,21,22,25–27,35,36]. Among these studies, methods developed based on common spatial patterns (CSP) have been paid special attention. CSP is a two-class spatial filtering technique that maximizes the variance of band-passed EEG signals from one class while minimizing the signal variance from the other [37]. It is efficient in extracting representative features for BCI classification, and can be extended for multi-class BCI applications. The original CSP method is a supervised and subject specific technique that requires training data from a target subject with known class labels. It is typically used on a subject-by-subject basis, and might not perform well for multi-subject BCI.

In order to improve the multi-subject performance of CSP, prior information from different subjects can be added to the CSP learning via regularization. The regularization is typically implemented in two ways [14]. One is to calculate a weighted average of covariance matrices of EEG data from different subjects [3,38,4,6,7,12,39]. Fixed experiential weights are often used [3,4,12,39], but adaptive weights are also proposed to better quantify the similarity between training and testing data [40,41,38,6,7]. The other is to regularize the CSP objective function by adding a penalization term to impose prior information from multiple subjects [5,15,14,10,9]. By incorporating multi-subject information, the regularized CSP methods can outperform the conventional CSP in multi-subject BCI classification tasks. Most of the regularized CSP methods require labelled training data from target subjects. If training data are unlabelled, an estimation of their class labels is performed so that the data can be assigned to a specific class to update the covariance matrix of this class [3,9,7,4]. Erroneous estimations would affect the CSP learning and deteriorate the BCI classification performance.

In this work, a different method to perform adaptive CSP (ACSP) learning is investigated. The method uses unlabelled EEG data from target subjects to learn spatial filters without an estimation of class labels for the target data, and updates spatial filters for both classes simultaneously using adaptive weights. There is no classification needed during the adaptive learning, and spatial filters can be updated in real-time to adapt to intra- and inter-subject variation in EEG. It can be used to classify single trial EEG data from single or multiple subjects. The proposed method was evaluated using multi-subject motor imagery EEG data from BCI competitions III and IV.

The remaining part of the paper is organized as follows. The classic CSP method is introduced in Section 2.1. The proposed ACSP method is described in Sections 2.2, 2.3, and 2.4. Section 2.5 explains the experimental EEG data used in this study, and how the method was evaluated. Experimental results are described and discussed in Section 3. Finally, Section 4 summarizes the paper.

The proposed adaptive CSP method is developed based on the classic CSP approach [42,43]. CSP is a supervised two-class spatial filtering technique that aims to maximize feature variation for one class and simultaneously minimize feature variation for the other. Given an 
                           M
                           ×
                           N
                         matrix 
                           
                              
                                 E
                              
                              
                                 i
                              
                           
                           (
                           y
                           )
                         that represents the ith trial of EEG data collected under a brain task with class label y, 
                           y
                           ∈
                           {
                           1
                           ,
                           2
                           }
                        , the normalized class-specific spatial covariance matrix 
                           
                              
                                 C
                              
                              
                                 y
                              
                           
                         is computed as:
                           
                              (1)
                              
                                 
                                    
                                       C
                                    
                                    
                                       y
                                    
                                 
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             y
                                          
                                       
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             y
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                       
                                       (
                                       y
                                       )
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                          
                                             T
                                          
                                       
                                       (
                                       y
                                       )
                                    
                                    
                                       tr
                                       (
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                       
                                       (
                                       y
                                       )
                                       
                                          
                                             E
                                          
                                          
                                             i
                                          
                                          
                                             T
                                          
                                       
                                       (
                                       y
                                       )
                                       )
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 E
                              
                              
                                 i
                              
                           
                           (
                           y
                           )
                         is mean-centered, M is the number of channels, N is the number of time points, n
                        
                           y
                         is the number of EEG trials in class y, and T is the matrix transpose operator. Based on the covariance matrix, the CSP training is to maximize the following Rayleigh coefficient:
                           
                              (2)
                              
                                 
                                    
                                       
                                          
                                             WC
                                          
                                          
                                             y
                                          
                                       
                                       
                                          
                                             W
                                          
                                          
                                             T
                                          
                                       
                                    
                                    
                                       W
                                       
                                          
                                             ∑
                                          
                                          
                                             y
                                          
                                       
                                       
                                          
                                             C
                                          
                                          
                                             y
                                          
                                       
                                       
                                          
                                             W
                                          
                                          
                                             T
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        which is equivalent to solve the generalized eigenvalue problem [40,14,37]:
                           
                              (3)
                              
                                 
                                    
                                       C
                                    
                                    
                                       1
                                    
                                 
                                 
                                    
                                       W
                                    
                                    
                                       T
                                    
                                 
                                 =
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                                 
                                    
                                       W
                                    
                                    
                                       T
                                    
                                 
                                 Λ
                                 ,
                              
                           
                        where the matrix W consists of spatial filters in rows, and 
                           Λ
                         is a diagonal matrix assorted in descending order of eigenvalues of 
                           
                              
                                 C
                              
                              
                                 2
                              
                              
                                 −
                                 1
                              
                           
                           
                              
                                 C
                              
                              
                                 1
                              
                           
                         that measure the variance ratio between the two classes. With the projection matrix W, the spatial filtering of a trial 
                           
                              
                                 E
                              
                              
                                 i
                              
                           
                           (
                           y
                           )
                         is computed as:
                           
                              (4)
                              
                                 
                                    
                                       Z
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       WE
                                    
                                    
                                       i
                                    
                                 
                                 (
                                 y
                                 )
                                 .
                              
                           
                        
                     

The columns of 
                           
                              
                                 W
                              
                              
                                 −
                                 1
                              
                           
                         are the common spatial patterns that are considered as time-invariant EEG source distribution vectors. The discrimination is based on the feature projections on W with maximal variations, which are the first and last m rows of 
                           
                              
                                 Z
                              
                              
                                 i
                              
                           
                        . Based on 
                           
                              
                                 Z
                              
                              
                                 i
                              
                           
                        , a feature vector is constructed for the ith trial with the rth spatial filter:
                           
                              (5)
                              
                                 
                                    
                                       x
                                    
                                    
                                       r
                                    
                                 
                                 =
                                 log
                                 [
                                 
                                    
                                       
                                          Var
                                          (
                                          
                                             
                                                z
                                             
                                             
                                                r
                                             
                                          
                                          )
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                2
                                                m
                                             
                                          
                                          Var
                                          (
                                          
                                             
                                                z
                                             
                                             
                                                j
                                             
                                          
                                          )
                                       
                                    
                                 
                                 ]
                                 ,
                              
                           
                        where 
                           Var
                           (
                           )
                         is the variance calculator, and z
                        
                           r
                         is the rth row of 
                           
                              
                                 Z
                              
                              
                                 i
                              
                           
                        . The logarithmic transformation is applied to make the distribution of x
                        
                           r
                         more close to Gaussian.

In CSP and some of its extensions for multi-subject analysis, the spatial filter W is calculated and then fixed for the processing of new data [6,12,15]. When there is no or unlabelled training data from target subjects, fixed spatial filters are usually not sufficient to characterize spatial covariance structures of new data. CSP extensions have been proposed to adapt to unlabelled data [3,38,9,7,4]. For example, in an adaptive method proposed in [3], the class label of each testing trial is first estimated. Then the trial is assigned to the estimated class to update its covariance matrix with a fixed weight, and CSP features are updated and reclassified. In a parametric model-based adaptive method [4], CSP features extracted from a testing trial are modelled by a two-component Gaussian mixture model (GMM). The expectation maximization (EM) algorithm is used to estimate class labels for testing trials. The classified trials showing high posterior class probabilities are added to the estimated class to update its covariance matrix and CSP features. This process is repeated multiple times until the overall change of class labels between two contiguous iterations is below a predefined threshold. In another adaptive method [7], an initial classification is first performed on a testing trial, and then the covariance matrix of the estimated class is updated based upon a weight calculated using the Kullback–Leibler divergence (KLD) between the training and testing trials. After updating the covariance matrix, CSP features are updated and reclassified. This process can be repeated multiple times. An initial classification is required in these methods to assign a testing trial to a class to update the class spatial covariance matrix. Ideally, if the new trial is from class y, then it should be similar to training trials from y in terms of feature variation, data distribution, or normalized spatial covariance matrix, and be correctly classified by a classifier. Due to EEG nonstationarity, however, the expected similarity may not be apparent, and it is possible that the new data is more similar to training data of the opposite class. If the new trial is mis-classified, the spatial filters updated based on the erroneous classification could affect the BCI classification. In this work, a different way to perform the ACSP learning is proposed. Instead of estimating class labels for new EEG trials, a similarity measure between new and training data in each class is calculated, and spatial filters of both classes are simultaneously updated based on the similarity measure. Three different similarity measures are used based upon which the ACSP method is developed. The details of the proposed method are described as follows.

Given a new EEG trial from a target subject with an unknown class label and a normalized spatial covariance matrix 
                           
                              
                                 C
                              
                              
                                 new
                              
                           
                        , the following method is proposed to calculate the new class covariance matrices:
                           
                              (6)
                              
                                 
                                    
                                       
                                          
                                             C
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    
                                       1
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             1
                                          
                                       
                                       +
                                       sgn
                                       (
                                       
                                          
                                             ϕ
                                          
                                          
                                             1
                                          
                                       
                                       )
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       new
                                    
                                 
                                 +
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             1
                                          
                                       
                                       +
                                       sgn
                                       (
                                       
                                          
                                             ϕ
                                          
                                          
                                             1
                                          
                                       
                                       )
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          
                                             C
                                          
                                          
                                             ¯
                                          
                                       
                                    
                                    
                                       2
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ϕ
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             2
                                          
                                       
                                       +
                                       sgn
                                       (
                                       
                                          
                                             ϕ
                                          
                                          
                                             2
                                          
                                       
                                       )
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       new
                                    
                                 
                                 +
                                 
                                    
                                       
                                          
                                             n
                                          
                                          
                                             2
                                          
                                       
                                    
                                    
                                       
                                          
                                             n
                                          
                                          
                                             2
                                          
                                       
                                       +
                                       sgn
                                       (
                                       
                                          
                                             ϕ
                                          
                                          
                                             2
                                          
                                       
                                       )
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                                 ,
                              
                           
                        where n
                        1 and n
                        2 are numbers of training trials from classes 1 and 2, respectively. 
                           
                              
                                 ϕ
                              
                              
                                 1
                              
                           
                           ≥
                           0
                         and 
                           
                              
                                 ϕ
                              
                              
                                 2
                              
                           
                           ≥
                           0
                         are two measures that quantify the similarity between the target and training data in the two classes, and need to be estimated. sgn(x) is the sign function that equals to 1 if 
                           x
                           >
                           0
                        , and equals to 0 if x=0. Three different similarity measures are used to estimate ϕ
                        
                           y
                        , 
                           y
                           ∈
                           {
                           1
                           ,
                           2
                           }
                        .

When a new EEG trial is projected onto existing spatial filters of the two classes using Eq. (4), the feature variance x
                           
                              r
                            is computed using (5). ϕ
                           
                              y
                            is calculated as the ratio of the sum of feature variance in class y to the overall feature variance of the two classes:
                              
                                 (7)
                                 
                                    
                                       
                                          ϕ
                                       
                                       
                                          y
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                r
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                r
                                             
                                             
                                                y
                                             
                                          
                                          )
                                       
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                r
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                r
                                             
                                             
                                                1
                                             
                                          
                                          )
                                          +
                                          
                                             
                                                ∑
                                             
                                             
                                                r
                                             
                                          
                                          (
                                          
                                             
                                                x
                                             
                                             
                                                r
                                             
                                             
                                                2
                                             
                                          
                                          )
                                       
                                    
                                    ,
                                 
                              
                           where x
                           
                              r
                           
                           1 is computed from the first rth row of the feature projection on W, x
                           
                              r
                           
                           2 is from the last rth row of the feature projection, and x
                           
                              r
                           
                           
                              y
                            is the rth feature in class y. The feature variance defined in (5) was originally proposed as a primary CSP-based feature for BCI classification, where a class with a greater projected feature variance has a higher possibility to be the true motor imagery class. Therefore, it may be used as a similarity indicator between training and target data, based upon which a weight parameter can be derived to update the class covariance matrices.

KLD is a distance measure between two probability distributions, and used to quantify the similarity between distributions of target and training data. If EEG data in each trial are normalized to zero mean and standard deviation, then we may assume that EEG data follow a zero mean M-dimensional multivariate Gaussian distribution, where M is the number of EEG channels. The probability distributions of a new target EEG trial and training data are represented as 
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              =
                              N
                              (
                              0
                              ,
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                              )
                            and 
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              =
                              N
                              (
                              0
                              ,
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                              )
                           , respectively. The KLD between f
                           
                              new
                            and f
                           
                              y
                            is calculated as:
                              
                                 (8)
                                 
                                    KL
                                    (
                                    
                                       
                                          f
                                       
                                       
                                          new
                                       
                                    
                                    ,
                                    
                                       
                                          f
                                       
                                       
                                          y
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          1
                                       
                                       
                                          2
                                       
                                    
                                    {
                                    
                                       tr
                                       (
                                       
                                          
                                             C
                                          
                                          
                                             y
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          
                                             C
                                          
                                          
                                             new
                                          
                                       
                                       )
                                       −
                                       log
                                       [
                                       
                                          
                                             
                                                det
                                                (
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      new
                                                   
                                                
                                                )
                                             
                                             
                                                det
                                                (
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      y
                                                   
                                                
                                                )
                                             
                                          
                                       
                                       ]
                                       −
                                       M
                                    
                                    }
                                    ,
                                 
                              
                           where 
                              det
                              (
                              )
                            is the determinant operator, and 
                              y
                              ∈
                              {
                              1
                              ,
                              2
                              }
                           . Since KLD is not a symmetric distance measure, 
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              )
                              ≠
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              )
                           . KLD can be symmetrized by adding 
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              )
                            and 
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              )
                            together:
                              
                                 (9)
                                 
                                    KLD
                                    (
                                    
                                       
                                          f
                                       
                                       
                                          new
                                       
                                    
                                    ,
                                    
                                       
                                          f
                                       
                                       
                                          y
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          
                                             1
                                          
                                          
                                             2
                                          
                                       
                                    
                                    [
                                    KL
                                    (
                                    
                                       
                                          f
                                       
                                       
                                          new
                                       
                                    
                                    ,
                                    
                                       
                                          f
                                       
                                       
                                          y
                                       
                                    
                                    )
                                    +
                                    KL
                                    (
                                    
                                       
                                          f
                                       
                                       
                                          y
                                       
                                    
                                    ,
                                    
                                       
                                          f
                                       
                                       
                                          new
                                       
                                    
                                    )
                                    ]
                                 
                              
                           The parameter ϕ
                           
                              y
                            is computed as:
                              
                                 (10)
                                 
                                    
                                       
                                          ϕ
                                       
                                       
                                          y
                                       
                                    
                                    =
                                    1
                                    −
                                    
                                       
                                          KLD
                                          (
                                          
                                             
                                                f
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                f
                                             
                                             
                                                y
                                             
                                          
                                          )
                                       
                                       
                                          KLD
                                          (
                                          
                                             
                                                f
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                f
                                             
                                             
                                                1
                                             
                                          
                                          )
                                          +
                                          KLD
                                          (
                                          
                                             
                                                f
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                f
                                             
                                             
                                                2
                                             
                                          
                                          )
                                       
                                    
                                    .
                                 
                              
                           If 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            is not from class y, theoretically the value of 
                              KLD
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              )
                              /
                              (
                              KLD
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    1
                                 
                              
                              )
                              +
                              KLD
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    2
                                 
                              
                              )
                              )
                            is relatively large, resulting in a small ϕ
                           
                              y
                           . On the contrary, a large ϕ
                           
                              y
                            will be obtained to assign a greater weight to 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                           .

Frobenius norm (FN) is a matrix norm defined as the square root of the sum of the absolute squares of its elements. It can be used to measure the distance between two matrices. In this work, FN is used to estimate the similarity between 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            and 
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                           :
                              
                                 (11)
                                 
                                    FN
                                    (
                                    
                                       
                                          C
                                       
                                       
                                          new
                                       
                                    
                                    ,
                                    
                                       
                                          C
                                       
                                       
                                          y
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                i
                                                ,
                                                j
                                             
                                          
                                          
                                             
                                                [
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      new
                                                   
                                                
                                                (
                                                i
                                                ,
                                                j
                                                )
                                                −
                                                
                                                   
                                                      C
                                                   
                                                   
                                                      y
                                                   
                                                
                                                (
                                                i
                                                ,
                                                j
                                                )
                                                ]
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           The parameter ϕ
                           
                              y
                            is estimated using
                              
                                 (12)
                                 
                                    
                                       
                                          ϕ
                                       
                                       
                                          y
                                       
                                    
                                    =
                                    1
                                    −
                                    
                                       
                                          FN
                                          (
                                          
                                             
                                                C
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                C
                                             
                                             
                                                y
                                             
                                          
                                          )
                                       
                                       
                                          FN
                                          (
                                          
                                             
                                                C
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                C
                                             
                                             
                                                1
                                             
                                          
                                          )
                                          +
                                          FN
                                          (
                                          
                                             
                                                C
                                             
                                             
                                                new
                                             
                                          
                                          ,
                                          
                                             
                                                C
                                             
                                             
                                                2
                                             
                                          
                                          )
                                       
                                    
                                    .
                                 
                              
                           If 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            is not from class y, theoretically the difference between 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            and 
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                            is greater than the case that 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            is from class y, resulting in a small ϕ
                           
                              y
                           . Contrarily, a large ϕ
                           
                              y
                            will be assigned to 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                           .


                           ϕ
                           1 and ϕ
                           2 can be estimated by using one of the three similarity measures. After calculating 
                              
                                 
                                    
                                       
                                          C
                                       
                                       
                                          ¯
                                       
                                    
                                 
                                 
                                    y
                                 
                              
                            using (6), the remaining steps are the same as the CSP method to obtain updated spatial filters for feature extraction.

It can be observed from (6) that the weights for 
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                            and 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            are also related to the number of training trials. More training trials lead to less weights for the target data. A greater number of training trials means a higher opportunity to provide more prior information about target subjects, and consequently a lower chance that the new trial may exhibit considerably different patterns. When the number of training trials is large, the weights assigned to 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            are relatively small, and have a slight effect on the overall covariance matrices. However, such small variation may result in a significant change of feature distribution and final classification results. It was confirmed by the experimental results of this study.

The proposed ACSP method is equivalent to a simplified EM algorithm [44,45], where the EEG data is characterized by a zero-mean two-component multivariate GMM. The two components correspond to the two classes in CSP. The probability of each component is approximated using the weights of 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            and 
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                            shown in (6) (the E-step), and the covariance matrix of each component is estimated using the weighted average of 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            and 
                              
                                 
                                    C
                                 
                                 
                                    y
                                 
                              
                            (the M-step). To facilitate the real-time processing, no iteration between the E-step and the M-step is performed. The proposed method is quite different from another EM-based approach described previously [4], where the GMM is used to model CSP features instead of EEG data, and a decision of class label is made in each EM iteration. By assigning partial membership to each target EEG trial, it is expected that the proposed ACSP method can adapt to intra- and inter-subject variation and provide a better learning performance than the classic CSP method.

In the following sections, the ACSP implementation using the feature variance-based distance is called ACSP-Ia, the one using the symmetrized KLD is named ACSP-Ib, and the other using FN is denoted as ACSP-Ic. Although different similarity measures could be used, the proposed ACSP can be implemented following a general procedure:
                           
                              •
                              
                                 Step 1: A spatial filter W is computed using the classic CSP with EEG training data.


                                 Step 2: Input a new EEG trial from a target subject.


                                 Step 3: ACSP-Ia: Compute feature projection of the new data on W using (4) and (5). ACSP-Ib and -Ic: Compute the covariance matrix 
                                    
                                       
                                          C
                                       
                                       
                                          new
                                       
                                    
                                  of the new data, and the KLD or FN between 
                                    
                                       
                                          C
                                       
                                       
                                          new
                                       
                                    
                                  and 
                                    
                                       
                                          C
                                       
                                       
                                          y
                                       
                                    
                                 , 
                                    y
                                    ∈
                                    {
                                    1
                                    ,
                                    2
                                    }
                                  using (9) or (11).


                                 Step 4: Estimate ϕ
                                 1 and ϕ
                                 2 using (7) (ACSP-Ia), or (10) (ACSP-Ib), or (12) (ACSP-Ic).


                                 Step 5: Compute 
                                    
                                       
                                          
                                             
                                                C
                                             
                                             
                                                ¯
                                             
                                          
                                       
                                       
                                          1
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             
                                                C
                                             
                                             
                                                ¯
                                             
                                          
                                       
                                       
                                          2
                                       
                                    
                                  using (6), and update the spatial filter W. Project the target and training data onto the updated W and extract features using (4) and (5).


                                 Step 6: Features extracted from the training data are used to train/retrain a data classifier to classify features extracted from the target data.


                                 Step 7: Go to Step 2 for the next target trial.

In existing ACSP studies [3,7,4], classified target trials are added to training data to improve the CSP learning performance. This procedure is denoted as accumulative ACSP in this work. On the contrary, non-accumulative ACSP does not include classified trials to update the training data. The proposed ACSP method can be implemented in the accumulative or non-accumulative way, and we examined both cases in the experiments. For the accumulative ACSP, we examined two different implementations. The first is to add classified target trials to training data of the estimated class, and the update of spatial covariance matrix is class-specific. The second implementation is to update 
                           
                              
                                 C
                              
                              
                                 1
                              
                           
                         and 
                           
                              
                                 C
                              
                              
                                 2
                              
                           
                         to 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 1
                              
                           
                         and 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 2
                              
                           
                         using (6) after the classification. This is equivalent to add target trials to training data of both classes with the weights shown in (6). The first class-specific accumulative implementation is denoted as “ACCU-1” in the experimental study, and the second implementation that updates spatial filters for both classes is called “ACCU-2”. In the non-accumulative ACSP, classified trials are not added to training data, and as a result, 
                           
                              
                                 C
                              
                              
                                 1
                              
                           
                         and 
                           
                              
                                 C
                              
                              
                                 2
                              
                           
                         are not updated to 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 1
                              
                           
                         and 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 2
                              
                           
                         after the classification of each target trial although 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 1
                              
                           
                         and 
                           
                              
                                 
                                    
                                       C
                                    
                                    
                                       ¯
                                    
                                 
                              
                              
                                 2
                              
                           
                         are computed during the ACSP learning.

Intuitively, the accumulative ACSP would outperform the non-accumulative one because previous studies have shown improvements induced by including target subjects׳ data into the CSP training. This is usually true if there is a feedback loop or “ground truth” to know true class labels of target trials. However, if the true class label is not instantly available in real-time BCI applications, mis-classified target trials will be added to training data of a wrong class and affect the CSP learning and final classification. The non-accumulative ACSP does not add classified trials to the training data, and would be an alternative option to the accumulative one if it outperforms the accumulative ACSP in this situation. A comparison study was performed between the non-accumulative and accumulative ACSP and the results are reported in Section 3.

@&#EVALUATION@&#

The proposed method was evaluated using four datasets from BCI Competitions III (datasets IIIa and IVa) and IV (datasets IIa and IIb) [46,47]. Dataset IIIa was recorded from three subjects using a 64-channel EEG system at a sampling rate of 250Hz and band-pass filtered between 1 and 50Hz with a 50Hz notch filter on. One of the four motor imagery tasks, including left hand, right hand, foot, and tongue, was performed during the data acquisition. For each subject, there are 60 training and 60 testing trials from each class. The left hand and foot data were used in this work. A time segment from 3.5s to 5s was extracted from each trial. Dataset IVa was acquired from five subjects using 118 EEG channels at a sampling rate of 1000Hz while the subjects were performing one of the left hand, right hand, and right foot motor imagery tasks. The data were bandpass filtered between 0.05 and 200Hz, and down-sampled to 100Hz. In each task, the numbers of training and testing trials vary over different subjects, and are listed in Table 1
                           . The five subjects׳ IDs are “aa”, “al”, “av”, “aw”, and “ay”. The data associated with the left and right hand tasks were used in this study. Dataset IIa was collected from 9 subjects with 22 EEG channels while the subjects were performing one of the four motor imagery tasks: left hand, right hand, foot, and tongue. Two sessions of data were acquired from each subject on different days. Each session consists of 288 trials, with 72 trials for each task. In this work, only the left and right hand data were used. The data from the first session were used for training, and those from the second session were used for the evaluation. Dataset IIb was acquired from the same set of subjects as that in IIa using 3 EEG channels while the subjects were performing either left or right hand task. Five sessions were recorded for each subject on different days. Three sessions were used for training, and the other two were used for the testing. In each session there are about 60–80 trials from each task condition. All trials in IIa and IIb were sampled at 250Hz and band-pass filtered between 0.5 and 100Hz during the acquisition. A 50Hz notch filter was applied to attenuate line noise. A time segment from 2s to 4s was extracted from each trial. Eye movement artifacts in IIa and IIb were attenuated using regression based on the simultaneously acquired electrooculogram data [48]. All EEG trials were band-pass filtered in the 8–32Hz frequency band, which is considered to contain the most relevant information of motor imagery [49]. The filtered EEG data have a zero mean and were normalized to standard deviation.

The evaluation was based upon the intra-subject and inter-subject classification performance. In the intra-subject evaluation, the training and testing trials were from the same subject. In the inter-subject study, two types of evaluations were performed. One was to use training trials from all subjects in a dataset to learn spatial filters, and apply them to the testing data from all subjects in the same dataset. The other is more challenging: the training trials from only one subject in a dataset were used to learn spatial filters, and the testing trials from all other subjects in the same dataset were used for the evaluation. A cross validation was performed so that each subject׳s training trials were used once to train spatial filters, while all other subjects׳ evaluation trials were used for the testing. A linear support vector machine (SVM) was used as the data classifier. In the accumulative or non-accumulative ACSP, the linear SVM is retrained using the updated features each time after a new target trial is provided and the ACSP learning is performed. Accuracy and Cohen׳s kappa (κ) coefficient were computed to evaluate the classification performance [50]. κ ranges from 0 to 1 where 0 corresponds to a chance level classification with a 50% accuracy, and 1 means a perfect classification. Compared to accuracy, Cohen׳s kappa (κ) coefficient provides a more reliable evaluation of classification performance for unbalanced two- or multi-class classifications problems. The effects of training data size on the ACSP learning were also investigated for both intra- and inter-subject studies. The training data from each subject were split into two groups by indices odd and even. Each group was used once to train spatial filters, and the ACSP learning and classification were performed on all testing data. The final accuracy and κ were computed using the classification results from the two groups.

The evaluation of the non-accumulative ACSP was based on a comparison study with the classic CSP and the semi-supervised importance weighted extreme energy ratio (SIWEER) method [34]. The SIWEER method was developed based on the extreme energy ratio (EER) criterion [51], which is theoretically equivalent to CSP but computationally more efficient. The SIWEER method uses the Kullback–Leibler importance estimation procedure (KLIEP) to update the weights of class covariance matrices for the CSP learning [52]. KLIEP is a covariate shift adaptation technique where a Gaussian kernel is used to measure the distance between training and testing data, and the kernel width σ needs to be estimated using cross validation. An optimal setting of σ=8 was also suggested based on the previous experimental study of the SIWEER method [34]. In the experimental study, both cross validation and σ=8 were investigated and their results are quite similar. Finally the results obtained using σ=8 were selected for the comparison. The study of the accumulative ACSP was based upon a comparison with two existing accumulative ACSP methods [3,7]. The first method, which is briefly described in Section 2.2, uses a fixed experiential weight for the covariance matrix 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            of the testing trial [3], and is called ACSP-II in this work. The class label of a testing trial is first estimated in ACSP-II using the CSP features and a nonlinear SVM with the radial basis function (RBF) kernel. Then 
                              
                                 
                                    C
                                 
                                 
                                    new
                                 
                              
                            is assigned to the estimated class to update its covariance matrix with a weight of 0.05, and the weight assigned to the current covariance is 0.95. Finally the CSP learning is performed to update spatial filters and features for the SVM classification. The second method is also described in Section 2.2 and named ACSP-III in the comparison study [7]. It performs an initial classification on the testing trial using the Filter Bank Common Spatial Pattern (FBCSP) method [53,54]. Then the covariance matrix of the estimated class is updated by assigning a weight of 
                              n
                              /
                              (
                              N
                              +
                              n
                              )
                            to the current covariance, where N is the total number of training trials in the class, and n is the number of testing trials analyzed by ACSP-III so far. A weight of 
                              n
                              /
                              (
                              N
                              +
                              n
                              )
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              )
                            is assigned to the covariance of the testing trial, where y is the estimated class, and 
                              KL
                              (
                              
                                 
                                    f
                                 
                                 
                                    new
                                 
                              
                              ,
                              
                                 
                                    f
                                 
                                 
                                    y
                                 
                              
                              )
                            is the KLD between the testing and training trials as defined in (8). After updating the covariance matrix, CSP learning is performed and features are extracted based on the new spatial filters and classified using a SVM classifier. The updating of covariance matrix, CSP learning, feature re-extraction and classification can be repeated multiple times. In this study, three times of iteration was used as suggested in the original work [7].

Since the focus of this work is the adaptive CSP learning, and in order to make the comparison study under the same data/feature condition and not obscured by contributions from advanced preprocessing, feature extraction/selection, and data classifiers, the input to all ACSP methods is minimally preprocessed to remove major artifacts as described in Section 2.5.1, and the same linear SVM is used as the data classifier for all methods. Some processing steps in ACSP-II and -III were not performed, including the subject specific bandpass filtering and nonlinear SVM in ACSP-II, and multi-band filtering and feature extraction in ACSP-III. Therefore, the numerical results reported in the next section are not directly comparable to the results published in the original works using the two methods [3,7], as well as other works competing for the best results on the datasets from BCI competitions.

@&#RESULTS@&#

In order to determine an optimal m value in (5) for feature extraction after the CSP/ACSP training, candidate m values ranging from 1 to 5 were examined for datasets IIa, IIIa, and IVa using the classic CSP in the intra- and inter-subject studies. It was found that in most cases m=2 generates the highest classification accuracy. Thus m=2 was used for the three datasets in the CSP- and ACSP-based feature extraction in the experimental study. Since there are only three EEG channels in dataset IIb, m=1 was used for this dataset.


                        Fig. 1
                         shows a comparison of the intra-subject classification accuracy between the CSP, SIWEER, and non-accumulative implementation of the proposed ACSP method. Each circle in the figure represents the classification accuracy of an individual subject from one of the four datasets. It was observed that the ACSP method outperforms the conventional CSP on most subjects, and ACSP-Ia, -Ib, and -Ic exhibit a similar performance in terms of the number of subjects showing increased accuracy. The SIWEER method can improve the accuracy for part of the subjects. The overall classification accuracy P
                        
                           a
                         and κ values for the four datasets are given in Table 2
                        . It can be seen that the adaptive method can improve the spatial filtering and lead to increased P
                        
                           a
                         and κ values compared to CSP. For dataset IIa, a P
                        
                           a
                         of 71.84% was achieved from ACSP-Ib associated with a κ value of 0.44. This P
                        
                           a
                         value is 14.43% higher than that from the CSP. A two-tailed t-test was performed on the classification accuracies of all individual subjects, and the improvement obtained from ACSP-Ib is significant at the 0.003 level. The improvements from ACSP-Ia and -Ic are close to that of ACSP-Ib. For dataset IIb, the performances of ACSP-Ia, -Ib, and -Ic are also close to each other, and the increases in P
                        
                           a
                         are greater than 13.0% as compared to CSP. After examining the accuracies of individual subjects, it was found that ACSP-Ia, -Ib, and -Ic can improve the classification accuracy for all subjects in this dataset, and the increases range from 0.62% to 31.88%. The t-test indicates that the increases in P
                        
                           a
                         obtained from ACSP-Ia, -Ib, and -Ic are significant at the 0.007 level. The highest P
                        
                           a
                         for dataset IIIa was from ACSP-Ia with an increase of 21.35% compared to that of CSP. The corresponding κ is 0.51. The significance level of this increase is 0.18. The accuracies computed for individual subjects in this dataset range from 50.0% to 93.1% with a standard deviation of 22.60%. This large standard deviation is the primary reason for the high significance level. For dataset IVa, ACSP-Ib resulted in the highest accuracy with a P
                        
                           a
                         of 76.55% and κ=0.53. The increase in P
                        
                           a
                         is 9.65% compared to CSP, and the significance level of this increase is 0.09. The improvements from ACSP-Ia and -Ic are close to that of ACSP-Ib. It was also found that the improvement generated from SIWEER is not so significant as compared to the proposed method.


                        Table 3
                         lists P
                        
                           a
                         and κ values when a half of the training data were used in each method. It was found that the final classification performance was not significantly affected for datasets IIa and IIb when ACSP-Ia, -Ib, -Ic, and SIWEER were used. For dataset IIIa, further increases of 10.39% (SIWEER) and 2.81% (ACSP-Ib) in P
                        
                           a
                         were achieved, while decreases of 16.79% (SIWEER) and 15.12% (ACSP-Ia, ACSP-Ib) were observed from dataset IVa. After checking the accuracies of individual subjects obtained by both of the methods, it was found that the largest decrease was from subject “ay” with the least number of training trials but the largest number of testing trials. The second largest decrease was from subject “aw”, and the third was from subject “av”. An increase in accuracy was observed from subjects “aa” and “al”. After reducing the training trials to a half, the numbers of training trials are 84 for “aa”, 112 for “al”, 42 for “av”, 28 for “aw”, and 14 for “ay”. This implies that an increased number of training trials does not necessarily improve the CSP learning because sometimes more training data could bring more artifacts. On the other hand, if the number of training trials is too small to obtain representative spatial patterns for each subject, the CSP learning is also affected.

For the inter-subject study of ACSP with multi-subject training data, the training trials of all subjects in each dataset were used with an equal weight. Fig. 2
                            illustrates a comparison of the classification accuracies of all individual subjects in the four datasets between the CSP, SIWEER, and the non-accumulative ACSP. Table 4
                            gives the overall classification performance. For dataset IIa, ACSP-Ia, -Ib and -Ic achieved an increase of 22.91% in P
                           
                              a
                            as compared to CSP at a significance level of 0.0004. An increase of 7.89% in P
                           
                              a
                            was obtained for dataset IIb using ACSP-Ib. This increase is significant at the 0.005 level. The highest improvement for dataset IIIa was obtained using ACSP-Ia, with an increase of 22.48% in P
                           
                              a
                            as compared to CSP at a significance level of 0.13. Similar to the intra-subject study, the high significance level is due to a large standard deviation of accuracies, which range from 56.67% to 90.0% with a standard deviation of 16.67%. For dataset IVa, the highest increase of 6.9% in P
                           
                              a
                            is from ACSP-Ib, and the significance level is 0.25. The range of individual subjects׳ accuracies is from 50% to 74.14% with a standard deviation of 10.73%. The relatively low increase and large standard deviation resulted in the high significance level. ACSP-Ia, -Ib, and -Ic exhibit a similar performance for these datasets. Slight increases in P
                           
                              a
                            were obtained by the SIWEER method for datasets IIa, IIIa, and IVa, but a decrease was observed from dataset IIb.

The reduction of training trials to a half did not bring too much variation in the classification performance for all four datasets when the non-accumulative ACSP was used, as shown in Table 5
                           . Compared to the P
                           
                              a
                            values in Table 4, the highest P
                           
                              a
                            is reduced a little for datasets IIa, IIb, and IVa, but slightly increased for dataset IIIa. When the SIWEER method was used with the reduced training sets, a 14.63% decrease in accuracy was observed from dataset IIb, but an increase of 8.71% was obtained for dataset IIIa. If we compare the results in Tables 2 and 4, it can be seen that P
                           
                              a
                            and κ values obtained from CSP in the inter-subject study using multi-subject training are lower than those from the intra-subject study for three of the four datasets. The proposed ACSP method can raise the inter-subject classification performance to a similar level of the intra-subject classification for datasets IIa, IIb, and IIIa. For dataset IVa, the small numbers of training trials in part of the subjects and the unbalanced training and testing data would be two primary reasons that the ACSP method cannot make the inter-subject classification performance close to the intra-subject case.

The inter-subject study using single-subject training data is an extreme case to examine the adaptability of the proposed method. Fig. 3
                            shows a comparison of the classification accuracies of all individual subjects in the four datasets between the classic CSP, SIWEER, and the non-accumulative ACSP. Table 6
                            shows the overall classification performance. For dataset IIa, the highest increase in P
                           
                              a
                            when compared to CSP was from ACSP-Ic, and the significance level of this 5.97% increase is 0.03. For dataset IIb, ACSP-Ib provided an increase of 13.75% in P
                           
                              a
                            at a significance level of 0.005. For dataset IIIa, the highest P
                           
                              a
                            was obtained using ACSP-Ia, and it is 3.93% higher than that of CSP. The highest improvement for dataset IVa was from ACSP-Ib with a 2.83% increase in P
                           
                              a
                            at a significance level of 0.08. When SIWEER was used, slight increases in accuracy were obtained for all four datasets. Under such a challenging experimental condition, the proposed ACSP method and SIWEER can still improve the learning of spatial filters and result in increased P
                           
                              a
                            and κ. Additionally, ACSP-Ia, -Ib, and -Ic show a similar performance, and outperform the SIWEER method.


                           Table 7
                            shows the classification performances of the CSP, SIWEER, and non-accumulative ACSP methods obtained using a half of the training trials. Compared to the results in Table 6, the accuracies obtained by ACSP were slightly decreased for datasets IIa, IIb, and IIIa, but increased for dataset IVa. The accuracies obtained using the SIWEER method were increased for datasets IIb and IIIa, but decreased for datasets IIa and IVa. The P
                           
                              a
                            values obtained from ACSP are higher than those from CSP for datasets IIa, IIb and IVa, but slightly lower for dataset IIIa. When SIWEER was used, the accuracies of datasets IIb, IIIa, and IVa are close to those obtained from CSP. If we compare the results in Tables 4 and 6, it can be seen that the classification performance of ACSP using a single subject׳s training data are lower than that using multi-subject training data. Similar observations were made from the SIWEER method except for dataset IIa. This verified that the use of multiple subjects׳ training data may improve the learning of spatial filters and discrimination performance.

In this work we also examined the effects of including classified trials into the training data if there is no feedback loop or “ground truth” to know true class labels of testing trials. Table 8
                         shows the accuracies of the four datasets when the proposed accumulative ACSP implementations described in Section 2.4 were performed for the intra-subject study and the inter-subject study using single- and multi-subject training data. For comparison, the results obtained from the two existing accumulative ACSP methods (ACSP-II and -III) described in Section 2.5.2 are also provided. It was observed that ACCU-2 outperforms ACCU-1, ACSP-II and -III in most cases. The performances of ACCU-1, ACSP-II and -III are close to each other. ACCU-1, ACSP-II and -III perform the class specific updating of the spatial covariance matrix, while ACCU-2 implements a weighted update of spatial covariance matrices for both classes. If we compare the results in Table 8 to those shown in Tables 2, 4 and 6, it can be found that the proposed non-accumulative ACSP usually outperforms ACSP-II, -III, and the proposed accumulative ACSP.

To investigate how the proposed accumulative ACSP affects the classification performance, the EEG data from each evaluation session in datasets IIa and IIb were divided into four blocks, each of which has the same number of trials. Then the accuracy of each block was computed from the results of inter-subject study using single-subject training data over all evaluation sessions and all subjects in each dataset. Fig. 4
                         shows the overall accuracies of individual blocks from the two datasets using the proposed non-accumulative (NACCU) ACSP, ACCU-1, and ACCU-2, where (a)–(c) are the block accuracies obtained from ACSP-Ia, -Ib, and -Ic using dataset IIa, and (d)–(e) are those obtained using dataset IIb. It was observed that the block accuracies from ACCU-1 and ACCU-2 are lower than those from the non-accumulative ACSP. This verifies that mis-classified trials can deteriorate the learning of spatial filters. On the contrary, the non-accumulative ACSP does not accumulate spatial covariance information from the opposite class, and provides better discrimination performance. It was also found that the block accuracies obtained from ACCU-1 are lower than those from ACCU-2. This is consistent to the results shown in Table 8. In ACCU-2, the spatial covariance matrices are updated for both classes instead of one class. Although the accumulation of partial spatial covariance from the opposite class affects the discrimination performance of spatial filters in ACCU-2, compared to the accumulation of an entire spatial covariance from the opposite class, mis-classified trials have less effects on the learning of spatial filters in ACCU-2. The observations from this comparison study imply that if true class labels cannot be provided for target trials, the non-accumulative ACSP would be a better choice for motor imagery BCI tasks.

A major limitation of the proposed ACSP method is that its performance is affected by EEG artifacts, such as eye blinks and swallowing. 
                           
                              
                                 C
                              
                              
                                 y
                              
                           
                         is the average covariance matrices of all trials in training data, and 
                           
                              
                                 C
                              
                              
                                 new
                              
                           
                         is the covariance matrix of a testing trial. The artifacts in training trials can be attenuated after the averaging, while possible artifacts in the testing trial may lead to an ill-conditioned 
                           
                              
                                 C
                              
                              
                                 new
                              
                           
                         that could generate unreliable estimations of the similarity measures defined in (7), (10) and (12). For instance, a poorly estimated 
                           
                              
                                 C
                              
                              
                                 new
                              
                           
                         dominates the symmetric KLD defined in (9) 
                        [1], and as a result, the similarity measure computed using the symmetric KLD is not reliable. Similar issues will also appear for the other two similarity measures. Therefore, some preprocessing is necessary to remove the EEG artifacts before the ACSP learning.

@&#CONCLUSION@&#

The CSP method has been shown an efficient but subject-specific tool to identify discriminative spatial patterns for EEG-based BCI systems. In order to improve the single- and multi-subject performances of CSP, an adaptive CSP method is proposed to integrate spatial covariance of target data into the learning of spatial filters. The proposed ACSP method was evaluated based on a comparison study with the classic CSP method and SIWEER, a CSP extension that implements an importance weighted covariate shift adaptation to update spatial filters for the CSP learning. The motor imagery data provided from BCI competitions III and IV were used in the comparison study. Three circumstances of BCI classification were examined, including intra-subject classification and inter-subject classification using multi-subject and single-subject training data. Experimental results show that the proposed ACSP outperforms the classic CSP and SIWEER methods in all three circumstances. To investigate if classified EEG trials could be added to training data to improve the ACSP learning when true class labels of target data are not instantly available, two accumulative implementations of the proposed ACSP were investigated and compared to two existing accumulative ACSP methods. The results show that one of the proposed accumulative ACSP implementations outperforms the others. In addition, the non-accumulative ACSP outperforms the accumulative ones. There are two major innovations in the proposed method. First, it does not estimate class labels for target data during the adaptive learning. Second, it updates spatial filters for both classes simultaneously. Since the purpose of this study is to examine the performance of the proposed adaptive learning method, the algorithm does not include advanced preprocessing and classification to compete with the best of BCI competitions. In the future work, the proposed method will be integrated with advanced noise/artifacts removal, feature extraction/selection, and nonlinear data classification methods, such as those showing impressive performances in the past BCI competitions, and be evaluated on more EEG data.

None declared.

@&#REFERENCES@&#


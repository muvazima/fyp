@&#MAIN-TITLE@&#Segmentation of heterogeneous or small FDG PET positive tissue based on a 3D-locally adaptive random walk algorithm

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose to use the distance between adjacent nodes in place of a constant β parameter to take into account the different distances between adjacent nodes in 26 connectivity.


                        
                        
                           
                           To reduce the partial volume effect in PET imaging, we propose to strengthen the grouping of voxels having similar intensity by adding the likelihood of probability to each class (tumor and non-tumor).


                        
                        
                           
                           The accuracy in the small and heteregenous tumor segmentation is improved using our improvements.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Random walk

PET imaging

Tumor segmentation

Heterogeneous tumors

@&#ABSTRACT@&#


               
               
                  A segmentation algorithm based on the random walk (RW) method, called 3D-LARW, has been developed to delineate small tumors or tumors with a heterogeneous distribution of FDG on PET images. Based on the original algorithm of RW [1], we propose an improved approach using new parameters depending on the Euclidean distance between two adjacent voxels instead of a fixed one and integrating probability densities of labels into the system of linear equations used in the RW. These improvements were evaluated and compared with the original RW method, a thresholding with a fixed value (40% of the maximum in the lesion), an adaptive thresholding algorithm on uniform spheres filled with FDG and FLAB method, on simulated heterogeneous spheres and on clinical data (14 patients). On these three different data, 3D-LARW has shown better segmentation results than the original RW algorithm and the three other methods. As expected, these improvements are more pronounced for the segmentation of small or tumors having heterogeneous FDG uptake.
               
            

@&#INTRODUCTION@&#

Traditionally in oncology, treatments planning in radiation therapy (RT) and evaluation of response after a treatment are mainly based on anatomical images such as computed tomography (CT) and magnetic resonance imaging (MRI). For RT, one needs to delineate the target volume, also called gross tumor volume (GTV). One of the criteria of response from solid tumor is the unidimentional measurement of the lesion size on CT images [2]. Positron emission tomography (PET) with 18F-2-fluoro-2-deoxyglucose (FDG) is now also widely used for RT [3] and patient follow-up [4]. FDG positive tissue corresponds to tumor cells having a high glucose metabolism. In the context of patient follow-up, early metabolic changes detected on FDG PET images can occur before anatomic changes. By assessing differences in several PET scans acquired before and at different times during treatment, various quantitative parameters have been proposed to characterize the therapeutic response [5], such as the tumor volume. In radiation therapy, the use of FDG PET in addition to CT can modify GTV volume and shape compared to those obtained on CT images alone [6]. Furthermore, Hall [7] has proposed the concept of dose painting consisting of the application of a non-uniform dose prescription based on biological characteristics of the tumor. To this end, PET images are used for segmentation of subvolumes, also called biological target volumes (BTV) [8].

For this purpose, several algorithms have been proposed in the literature for segmentation of FDG PET positive tissue [9]. One can quote thresholding methods [10,11]. The advantages of these methods are their ease of used, but they need a calibration step. Region growing methods have also been developed [12], but most of these algorithms propose a stopping rule based on a threshold value similar to thresholding methods. Watershed algorithms have been proposed [13], with the advantage of not requiring a calibration step. As the method is based on gradient measurement, it is sensitive to noise. Finally, methods based on voxel classification using probability [14], fuzzy measures (i.e. fuzzy-C-means algorithm (FCM), fuzzy local adapting Bayesian (FLAB) [15]) and belief functions [16] have also been proposed.

Graph based techniques have been recently developed for medical image segmentation because only a slight user interaction is needed for the initialization step. The most studied one is the graph cuts method [17] which has been used for segmentation, for example, of liver on CT images [18], multiple sclerosis lesions in brain structure in MRI [19]. Although performing well in many situations, this approach is less well suited for the segmentation of non-homogeneous region of interest. The random walk (RW) algorithm firstly proposed by Grady [1,20], has been applied on different medical image modalities with success. This algorithm has been evaluated for segmentation of FDG PET images on oncology [21,22] showing better performances than the FCM [23] and FLAB algorithms [15].

If most of these methods are efficient in case of large lesions with a good contrast and a homogeneous distribution of radioactivity, they are less effective in case of small tumors or a heterogeneous distribution of radioactivity. So, even if several methods have been proposed for PET segmentation, there is no consensus on this issue [9]. It is also not clear that only one algorithm can cover all the complexity of the segmentation of PET positive tissue [24], allowing the development of algorithms dedicated to the resolution of a specific problem, such as segmentation of heterogeneous lesions or small lesions.

The difficulty in PET image segmentation is compounded by the low spatial resolution and high noise characteristics of PET images. Among the many physical factors degrading image quality and quantitative accuracy, the partial volume effect (PVE) is recognized as one of the most important factors [9]. Owing to the limited spatial resolution of clinical PET systems, the resulting images are blurred by the system response and as a consequence smaller lesions appear larger. Although the total number of counts is preserved, they are distributed over a larger volume. Partial volume problem becomes more serious in the context of “small” objects, i.e. with dimensions smaller than around 2–3 times the full width at half-maximum (FWHM) of the point spread function (PSF) of the PET. A physiological characteristic also impacts the performances of PET image segmentation, because it makes the FDG uptake inhomogeneous in a lesion. This phenomenon is mainly observed on large lesion. Furthermore, necrotic tissue is most likely found on large lesions than on small ones.

Our goal is to improve the initial random walk algorithm [1,20,21,25] by integrating local information for segmentation of (i) lesions with heterogeneous distribution of FDG and (ii) small lesions blurred by PVE. The proposed method is called 3D-locally adaptive random walk (3D-LARW). This paper is organized as follows: Section 2 describes the principle of the random walk algorithm and the proposed improvements. Section 3 presents the material and methods used to evaluate the 3D-LARW algorithm, and Section 4 provides results on phantom and FDG PET images of patients. A conclusion is finally given with a summary of the proposed segmentation and perspectives in the future work.

At first, the method needs a small number of voxels corresponding to seeds with a pre-defined label according to each of the structure to be segmented. The algorithm calculates the probability that a constrained random walker starting from each unlabeled voxel will first reach the seeds [1]. A final segmentation is obtained by selecting, for each point, the most probable seed destination of the random walker. The constraint of the RW depends on the gradient between the intensity of the voxels.

In this approach, the image is considered as a purely discrete object. So a graph, with a fixed number of nodes and edges corresponding to the image size, is created. This graph consists of a pair G
                        =(V, E) with nodes v
                        ∈
                        V and edges e
                        ∈
                        E. An edge, e, spanning two v
                        
                           i
                         and v
                        
                           j
                        , is denoted by e
                        
                           ij
                        . The weight necessary for the walker's moving on this graph according to connectivity, follows the empirical function ω
                        
                           ij
                        , such as:
                           
                              (1)
                              
                                 
                                    
                                       ω
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    exp
                                    [
                                    −
                                    β
                                    
                                       
                                          (
                                          
                                             g
                                             i
                                          
                                          −
                                          
                                             g
                                             j
                                          
                                          )
                                       
                                       2
                                    
                                    ]
                                 
                              
                           
                        where both g
                        
                           i
                         and g
                        
                           j
                         are the image intensity values at points i and j. β represents a free parameter depending on the application.

The desired random walker probability is considered as the combinatorial Dirichlet problem [1]. A Dirichlet integral is defined as:
                           
                              (2)
                              
                                 
                                    D
                                    [
                                    U
                                    ]
                                    =
                                    
                                       1
                                       2
                                    
                                    
                                       ∫
                                       Ω
                                    
                                    
                                       |
                                       
                                          Δ
                                       
                                       U
                                       
                                          |
                                          2
                                       
                                       d
                                       Ω
                                    
                                 
                              
                           
                        for a field 
                           U
                         and a region Ω.

The solution of Eq. (2) is given by a harmonic function that satisfies the Laplace equation:
                           
                              (3)
                              
                                 
                                    
                                       ∇
                                       2
                                    
                                    U
                                    =
                                    0
                                 
                              
                           
                        
                     

The harmonic function that satisfies the boundary conditions minimizes the Dirichlet integral of Eq. (2).

The combinatorial Laplacian matrix proposed in [1] is defined as:
                           
                              (4)
                              
                                 
                                    
                                       L
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         d
                                                         i
                                                      
                                                   
                                                
                                                
                                                   
                                                      if
                                                       
                                                      i
                                                      =
                                                      j
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      −
                                                      
                                                         ω
                                                         
                                                            i
                                                            j
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      if
                                                       
                                                      
                                                         v
                                                         i
                                                      
                                                       
                                                      and
                                                       
                                                      
                                                         v
                                                         j
                                                      
                                                       
                                                      are adjacent nodes
                                                   
                                                
                                             
                                             
                                                
                                                   0
                                                
                                                
                                                   
                                                      otherwise
                                                   
                                                
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        with 
                           
                              
                                 d
                                 i
                              
                              =
                              ∑
                              
                                 
                                    ω
                                    
                                       i
                                       j
                                    
                                 
                              
                           
                         for each node.

The Laplacian matrix is a sparse matrix. It can be built according to 4 or 8 connectivity for 2D images, and 6 or 26 connectivity for 3D images. It is partitioned into four submatrices:
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         L
                                                         M
                                                      
                                                   
                                                
                                                
                                                   B
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         B
                                                         T
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         L
                                                         U
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        in which, the subscripts M and U stand for labeled and unlabeled voxels.

The way to solve the harmonic function for finding probabilities on unlabeled nodes is shown in [1]. As result, the harmonic function can be found by solving a system of linear equations as follows:
                           
                              (6)
                              
                                 
                                    
                                       L
                                       U
                                    
                                    χ
                                    =
                                    −
                                    
                                       B
                                       T
                                    
                                    M
                                 
                              
                           
                        
                     


                        L
                        
                           U
                        : submatrix of edge weights for the unlabeled voxels (n
                        
                           U
                        
                        *
                        n
                        
                           U
                        , n
                        
                           U
                         number of unlabeled voxels);


                        M: binary matrix of values 0 or 1 (n
                        
                           M
                        
                        *
                        l, l number of labels and n
                        
                           M
                         number of seeds), corresponding to the boundary conditions of seeds;


                        B
                        
                           T
                        : submatrix of edge weights corresponding to the labeled voxels (n
                        
                           U
                        
                        *
                        l);


                        χ: the probability for each voxel being a member of the labels (n
                        
                           U
                        
                        *
                        l).

Using the probability obtained by solving the system of linear Eq. (6), the assigned label of each voxel corresponds to the highest probability.

In the original method, parameter β is a constant [20]. A value of 1 was proposed by Bagci et al. in case of segmentation of 2D FDG PET images [21]. We propose to use the distance between adjacent nodes in place of a constant β parameter to take into account the different distances between adjacent nodes. Thus, the weight function in Eq. (1) becomes:
                           
                              (7)
                              
                                 
                                    
                                       ω
                                       
                                          i
                                          j
                                       
                                    
                                    =
                                    exp
                                    
                                       
                                          
                                             
                                                −
                                                β
                                                
                                                   
                                                      (
                                                      
                                                         g
                                                         i
                                                      
                                                      −
                                                      
                                                         g
                                                         j
                                                      
                                                      )
                                                   
                                                   2
                                                
                                             
                                             
                                                
                                                   h
                                                   
                                                      i
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where the added term h
                        
                           ij
                         represents the Euclidean distance between adjacent voxels i and j. In the initial method, the probability depends only on the gradient between voxels, but not directly on their intensity. Due to the PVE, the classification of voxels at interface between non-tumor and tumor regions is very difficult. This effect causes errors regardless of the segmentation method. To reduce this effect, we propose to strengthen the grouping of voxels having similar intensity by adding the likelihood of probability to each class (tumor and non tumor) to Eq. (6). Supposing each class k having a Gaussian distribution, their observation likelihood function can be written as:
                           
                              (8)
                              
                                 
                                    
                                       p
                                       k
                                    
                                    (
                                    I
                                    ,
                                    
                                       μ
                                       k
                                    
                                    ,
                                    
                                       σ
                                       k
                                    
                                    )
                                    =
                                    
                                       1
                                       
                                          
                                             
                                                2
                                                π
                                             
                                          
                                          
                                             σ
                                             k
                                          
                                       
                                    
                                    exp
                                    
                                       
                                          
                                             
                                                −
                                                
                                                   
                                                      (
                                                      I
                                                      −
                                                      
                                                         μ
                                                         k
                                                      
                                                      )
                                                   
                                                   2
                                                
                                             
                                             
                                                2
                                                
                                                   σ
                                                   k
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where μ
                        
                           k
                         and σ
                        
                           k
                         represent, respectively, the mean and the standard deviation of class k. The submatrix B
                        
                           T
                         in (6) is then modified according to:
                           
                              (9)
                              
                                 
                                    
                                       B
                                       ′
                                    
                                    =
                                    
                                       p
                                       k
                                    
                                    ⋅
                                    
                                       B
                                       T
                                    
                                 
                              
                           
                        
                     

The system of linear equations becomes:
                           
                              (10)
                              
                                 
                                    
                                       L
                                       U
                                    
                                    χ
                                    =
                                    −
                                    
                                       B
                                       ′
                                    
                                    M
                                 
                              
                           
                        
                     

Due to these improvements proposed according to local information, the method is called 3D-locally adaptive random walk (3D-LARW).

The tumor segmentation algorithm, 3D-LARW, is composed as follows. The first step corresponds to the definition of a region of interest (ROI) surrounding the tumor and corresponding to a 3D cubic box. A median filter is applied on the image to attenuate noise. Afterward, seeds are defined automatically. Finally, the 3D segmentation is obtained using the improved RW algorithm (Section 2.2). Voxels corresponding to the boundary of the ROI are assigned as non-tumor seeds. For tumor seeds and in order to face the problem of heterogeneous FDG uptake in the lesions, we propose a FCM algorithm [23] to classify voxels of ROI into three classes: the first class corresponds to the centroid having the lowest intensity value (R1), the second one corresponds to voxels with a moderate uptake (R2), and the third one, the highest uptake (R3). The seeds having the tumor label are those whose intensity value is higher than the middle of the centroid of R2 and R3. To build the Laplacian matrix in 3D, 26 connectivity for the adjacency graph is used. Eq. (8) related to the two labels (tumor and healthy tissue) are estimated from the two sets of seeds. Two probability maps corresponding to the two labels are finally obtained by resolving Eq. (10). Then, each voxel is assigned to the label whose probability is the highest.

@&#MATERIAL AND METHODS@&#

At first, the method was evaluated on homogeneous lesions using a physical phantom. The phantom corresponds to a cylindrical object (Data Spectrum Corporation, Hillsborough, NC, USA) containing eight spheres of volume ranging from 0.99 to 97.3mL. The FDG was included in the spheres and in the background of the cylinder according to radioactive concentration used in clinical routine. Data were acquired under five different contrasts between the spheres and background, ranging from 2 to 7.7 (2, 3.4, 4.9, 6.3 and 7.7). PET acquisitions and image reconstruction were obtained on a Biograph Sensation 16 Hi-Rez PET scanner (Siemens Medical Solution, Knoxville, TN, USA) following the protocol used in clinical routine. PET emission data were acquired in 3D mode with a 162mm axial field of view (FOV). After the acquisition, the data were corrected for dead-time, random, scatter and attenuation, and reconstructed with an attenuation weighted ordered subset expectation maximization method (AWOSEM: four iterations and eight subsets) in a 168×168 matrix (voxel size of 4.1mm×4.1mm×2.0mm). A Gaussian post-filtering was applied with a full width at half maximum of 5mm. The spatial resolution was 6.8mm in transverse plane at the center of FOV.

The performances of the segmentation method were also evaluated on simulated heterogeneous lesions. The lesions correspond to four spheres of diameter around 12, 29, 57 and 90mm. At first, different levels of heterogeneity were defined from a patient's data with a significant heterogeneity. Four regions were manually delineated corresponding to background, moderate uptake, high uptake and partial necrosis, leading to the following normalized mean value of 0.11 (μ
                           background), 0.50 (μ
                           moderate uptake), 1 (μ
                           high uptake) and 0.20 (μ
                           necrosis) respectively. The signal-to-noise ratio, SNR, was defined according to:
                              
                                 (11)
                                 
                                    
                                       SNR
                                       =
                                       
                                          
                                             
                                                μ
                                                
                                                   moderate uptake
                                                
                                             
                                             −
                                             
                                                μ
                                                
                                                   background
                                                
                                             
                                          
                                          σ
                                       
                                    
                                 
                              
                           
                        

For the two smallest spheres, three regions were defined corresponding to background, moderate FDG and high uptake in the lesions, whereas for the two largest ones, four regions (background and three regions in the lesion) were defined.

In this last case, three levels of uptake were considered inside the sphere corresponding to moderate FDG uptake, high uptake and partial necrosis. Then, each region was filled by the corresponding intensity (see Fig. 1
                           ).

The procedure to generate the images of the simulated lesions is shown in Fig. 2
                           . A 3D point spread function (PSF) was applied on ground truth images corresponding to those of biograph PET scanner. Finally, a Gaussian noise (0, σ) was applied according to four σ-values. In real PET images, SNR is achieved in the range of 1.5–5.5 according to our experimentations on 14 patients. Then, SNR simulated corresponded to 1.5, 2.5, 3.5 and 4.5. The last two steps were repeated 20 times for each of the four spheres and SNR to generate each time 20 noise replicates.

The performances of 3D-LARW and the original random walk algorithm RW (β
                           =1) were also evaluated on PET images of 14 patients (12 men and two women) who were injected by an average activity of FDG of 261±48MBq. The patients had non-small cell lung cancer (NSCLC). Two medical experts manually delineated the lesions and classified them as homogeneous (six lesions, range of volume between 1.9 and 37.7mL) or heterogeneous (eight lesions, range of volume between 20.8 and 135.8mL).

At first, a study of the contribution of the adaptive parameter was carried out on phantom data (simulated and physical phantoms) by comparing the original method RW(β) with five values of β close to 1 (i.e. 0.5, 0.7, 1, 2 and 3) and the new approach of the random walk. In order to study only the contribution of the adaptive parameter without the integration of PVE, Eq. (8) was not integrated in the algorithm. This method is noted as 3D-LARWSD.

Then, the contribution of the integration of probability density on the segmentation was conducted on the same phantom data by comparing 3D-LARW with 3D-LARWSD.

Finally, a comparison of the performances between 3D-LARW and the original RW (β
                        =1) was done on the patient data.

On physical phantom, the evaluation of the segmentation of the spheres was performed using descriptive analysis by calculating the mean and standard deviation of the absolute relative error by differentiating small and large spheres. The absolute relative error on volume measurement (in %) verifies the relationship:
                           
                              (12)
                              
                                 
                                    Error
                                     
                                    (
                                    %
                                    )
                                    =
                                    
                                       
                                          |
                                          
                                             V
                                             m
                                          
                                          −
                                          
                                             V
                                             r
                                          
                                          |
                                       
                                       
                                          
                                             V
                                             r
                                          
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        where V
                        
                           m
                         and V
                        
                           r
                         are respectively the measured volume after segmentation and the true volume of the sphere. Furthermore, a Bland–Altman statistical analysis was also realized.

On simulated data, as the ground truth is available, the evaluation of the segmentation error (SE) in the case of two classes (tumor and background) was done as follows:
                           
                              (13)
                              
                                 
                                    SE
                                    =
                                    
                                       
                                          Card
                                          (
                                          
                                             TF
                                             +
                                          
                                          )
                                          +
                                          Card
                                          (
                                          
                                             TF
                                             −
                                          
                                          )
                                       
                                       
                                          Card
                                          (
                                          T
                                          )
                                       
                                    
                                    ×
                                    100
                                 
                              
                           
                        where Card(TF+), Card(TF−) and Card(T) are respectively the number of the false positive voxels, false negative voxels and voxels of the tumor.

On patient data, the evaluation of the performances of the segmentation methods was done by comparing them with the delineation of the lesion by the medical expert. This evaluation was achieved using the Jaccard Index, JI (Eq. (14)). For two given segmentations (S) and (V), the Jaccard index measures the similarity between S and V and is defined as the size of the intersection divided by the size of union of S and V.
                           
                              (14)
                              
                                 
                                    JI
                                    =
                                    
                                       
                                          |
                                          S
                                          ∩
                                          V
                                          |
                                       
                                       
                                          |
                                          S
                                          ∪
                                          V
                                          |
                                       
                                    
                                 
                              
                           
                        
                     

@&#RESULTS@&#


                           Fig. 3
                            shows the mean and the standard deviation of the absolute relative error for small spheres (V
                           
                              r
                           
                           ≤3.78mL) and large spheres (V
                           
                              r
                           
                           ≥11.6mL) of the physical phantom for 3D-LARWSD and RW(β) algorithms for the five values of β tested. This figure shows that the performances of the initial RW algorithm depend on the chosen β-value. This is particularly pronounced for large spheres. In that case, the best results were found for RW(0.7) (Err=9.2±3.8%) and RW(1) (Err=10.1±4.9%) with a significant difference (p
                           <0.05) between β-values. Whereas for the small spheres, the best result was obtained with RW(2) (Err=48.4±22.2%), but with no significant difference (p
                           >0.1) with the other β-values. These results support the use of an adaptive β-parameter. Incorporating this parameter in the RW(3D-LARWSD) improves the segmentation of small uniform spheres (see Fig. 3a), with a significant difference (p
                           <0.05) between 3D-LARWSD and RW(β) for each value of β tested. On the other hand, there is no significant difference (p
                           =0.07) between these two methods for the large spheres (see Fig. 3b). Fig. 4
                            corresponds to the representation of Bland–Altman for 3D-LARWSD and RW(β) methods for the two β-values that previously gave the best results (RW(0.7) and RW(1)). The corresponding statistical analysis with confidence intervals (IC), given Table 1
                           , shows that RW(1) provides measurements not statistically different with the true volume of the studied spheres, while RW(0.7) overestimates the true volume with a bias of 2.9mL and 3D-LARWSD underestimates the true volume with a bias of −1.6mL. On the other hand, the confidence interval at 95% is narrower for 3D-LARWSD than for RW(1).


                           Fig. 5
                            presents the mean segmentation error and the standard deviation by differentiating small (D
                           
                              m
                           
                           ≤12mm, V
                           
                              r
                           
                           ≤2.15mL) and large (D
                           
                              m
                           
                           ≥29mm, V
                           
                              r
                           
                           ≥15.98mL) simulated lesions using RW(0.7), RW(1) and 3D-LARWSD. This figure shows that 3D-LARWSD leads to better segmentation results compared to the two other methods, significantly with RW(0.7) (p
                           =0.04) and not significantly with RW(1) (p
                           =0.22). These results confirm the contribution of the adaptive parameter on the segmentation. In addition, RW(1) gives better results compared to RW(0.7) (p
                           <0.05). Therefore, only results using RW(1) will be presented thereafter.


                           Fig. 3 shows the improvement of the segmentation results on homogeneous spheres when the contribution of the probability density is integrated in the RW algorithm (3D-LARW vs. 3D-LARWSD). This improvement is more pronounced for small spheres than for large spheres for which the mean errors of volume measurement are very close (p
                           =0.74) between the two methods. For the small spheres, 3D-LARW gives better mean error (30.8±7.6) than 3D-LARWSD (34.4±5.3) with a significant difference (p
                           =0.01) between the two methods.


                           Fig. 6
                            corresponds to the representation of Bland–Altman for 3D-LARWSD and 3D-LARW methods. The most important errors were found for low contrasts (see green arrows). Statistical analysis and the error of volume measurement are given Table 2
                           . This analysis shows that the two methods provide segmentation results that are very closed on the uniform phantom.


                           Fig. 5 shows also the improvement of the segmentation results when the contribution of the probability density is integrated in the RW algorithm on heterogeneous lesions. This improvement is also more pronounced for the smallest simulated heterogeneous sphere than for the largest ones. For the small spheres, 3D-LARW gives better mean error (17.2±4.5) than 3D-LARWSD (24.6±10.8) with a significant difference (p
                           <0.05).


                           Fig. 7
                            presents the segmentation error on the two smallest simulated lesions (12mm and 29mm) regarding the signal-to-noise ratio for 3D-LARW and 3D-LARWSD. For a given sphere, this figure shows an increase of segmentation error when the SNR decreases regardless of the method. It may be noted that the contribution of the probability density (3D-LARW vs. 3D-LARWSD) is more pronounced and significant for the smallest sphere (diameter 12mm (see Fig. 7a), p
                           =0.04), than for the sphere of diameter 29mm (see Fig. 7b, p
                           =0.3). It was also the case for the two largest spheres (diameter of 57mm and 90mm, i.e. improvements less pronounced and not significant). Therefore, the results are not presented here. Nevertheless, for each sphere and SNR, 3D-LARW gives better results compared to 3D-LARWSD.

3D-LARW performances were carried out by comparing the segmentation results of 3D-LARW with RW(1), and two thresholding methods commonly proposed in the literature for segmentation of FDG PET positive tissues [3,9]: a fixed threshold value corresponding to 40% (T40%) of the maximum value in the lesion [10], an adaptive thresholding method [11] (TAD) and FLAB method [15]. This study was evaluated on physical phantom, simulated data and patient data.


                           Fig. 8
                            corresponds to the representation of Bland–Altman for the five evaluated methods: 3D-LARW, RW(1), T40%, TAD and FLAB. Statistical analysis and the error of volume measurement are given in Table 3
                           . This analysis shows that RW(1) gives measurements not statistically different from the true volume of the studied spheres. On the other hand, 3D-LARW, TAD and FLAB tend to underestimate the sphere volumes with respective biases of −1.5mL, −2.84mL and −4.9mL. Otherwise, T40% tends to overestimate the sphere volumes with bias of 12.89mL. However, 3D-LARW gives the results the more compact (IC at 95% more narrow), unlike RW(1), TAD, T40% and FLAB are responsible for a greater dispersion of results. Average errors (see Table 3) show that 3D-LARW gives the best results regardless the sphere size (small or large) compared to the other methods. All methods are significantly different (p
                           <0.05), two by two, except 3D-LARW and TAD (p
                           =0.14).


                           Fig. 9
                            presents segmentation errors on simulated heterogeneous data for five evaluated methods. It should be noted that 3D-LARW leads to best results compared to the others, especially for small lesions simulated. For small and large lesions, there is a significant difference between the four methods, considered in pairs (p
                           <0.05).

In Table 4
                           , are presented the mean value and the standard deviation of JI for the tumor volume of the six homogeneous and eight heterogeneous lesions of the five studied methods. 3D-LARW gives better segmentation results than the other methods when compared with the segmentation of the medical expert, which is not statistically different (p
                           =0.1) on homogeneous lesions, but statistically different (p
                           <0.05) on heterogeneous lesions. For a given segmentation method, the mean JI are very closed from one expert to another. Furthermore, the mean JI between the two experts are 0.65 and 0.61 for heterogeneous and homogeneous lesions respectively, while the mean JI between an expert and 3D-LARW are always higher than 0.67. An example of segmentation results is given in Fig. 10
                            on heterogeneous lesions for two patients (patients 11 and 12). These images show that 3D-LARW gives segmentation results closer to the one done by the experts than others. RW(1) overestimates the first lesion (patient 11) and underestimates the second voluminous lesion (patient 12), whereas T40%, TAD and FLAB underestimate the two lesions. One may also note that thresholding methods and FLAB are not suitable for segmentation of large heterogeneous lesions.

@&#DISCUSSION AND CONCLUSION@&#

Definition of positive tissue in FDG positron emission tomography is a crucial medical task. Most of the methods proposed in the literature are efficient for the tumor segmentation with a homogeneous distribution of radioactivity, dimensions larger than 2–3 times the FWHM of the PSF of the PET scanner and a high SNR. Among them, the random walk algorithm [1,20] with a constant β parameter equal to 1 has shown interesting performances, better than the FCM [23] and FLAB algorithms [15] on homogeneous spheres [21].

Our aim was to improve this initial random walk method, RW, for small or lesions with a heterogeneous distribution of radioactivity without degrading the initial performances for large and homogeneous lesions [21,22]. An adaptive β parameter depending on the reverse of the distance between adjacent voxels (Eq. (7)) was integrated in the algorithm, as well as, a Gaussian density of probability (Eq. (8)) to deal with partial volume effect. Whatever the data evaluated, the new RW algorithm, 3D-LARW, integrating our improvements has shown better performances than the initial RW algorithm. These improvements are significant, particularly in the case of small lesions and heterogeneous lesions (Figs. 3 and 5).

The performances of 3D-LARW have been evaluated on three different PET data (physical phantom, simulated and patient data). The physical phantom corresponds to a homogeneous distribution of radioactivity in different spheres and for different sphere-to-background ratios, while simulated data corresponds to a heterogeneous distribution of radioactivity for several SNR. The advantages of phantom data (physical and simulated) are that the ground truth is well known: sphere volume for the physical phantom and the membership of the voxels to the lesion or the surrounding background for the simulated data. It is the reason why the performances of the segmentation algorithm were evaluated using the error of volume measurement on physical phantom and the segmentation error on the simulated data. With patient data the ground truth is not known, and a third index was used to compare the methods (Jaccard Index). To illustrate the impact of our improvement of the segmentation of small lesions, the results were separated on small and large spheres with respect to the FWHM of the PSF of the PET scanner, since the PVE occurs mainly for the lesions whose dimensions are smaller than two times the FWHM. The simulated data that we have performed are rather coarse compared to Monte Carlo simulations, but they have allowed to show that the integration of a Gaussian density of probability in the algorithm (Eq. (8)) is particularly efficient on small heterogeneous spheres (Fig. 7).

At first, the impact of the adaptive parameter in the initial RW algorithm has been evaluated. In a previous work, Grady et al. have proposed a value of β
                     =500 [20], β
                     =1500 for 2D images, 4000 for 3D images [25] and β
                     =900 [1], while Bagci et al. [21] have proposed a value of β
                     =1 for the segmentation of 2D PET images. Theses authors did not justify the choice of these values. In a not published preliminary study (results not given here), we have found that β-values close to 1 give better results for the segmentation of 3D PET lesions than high β-values. On the uniform physical phantom (Fig. 3) and heterogeneous simulated data (Fig. 5), the segmentation results with the original RW(β) algorithm, for five β-values around 1 show that the performances of the algorithm depends on β-value. Among the β-values tested, those below 1 overestimate and those above 1 underestimate the sphere volume of the physical phantom. This influence of β-value on the segmentation is more pronounced for large spheres (Figs. 3b and 5b) than for small ones (Figs. 3a and 5a). In this case, RW(0.7) gives better results (9.2±3.8%) with a significant difference (p
                     <0.05) between β-value, taken two by two. Whereas for small spheres, the best results were obtained by RW(2), but with no significant difference (p
                     >0.1) with the other β-values evaluated. These results show that it is advisable to be vigilant with the use of a constant β-value, and justify the use of an adaptive parameter. Thus, due to the presence of anisotropic voxels, we have chosen a weight associated to the walker's moving depending on the distance between two adjacent voxels (Eq. (7)). In our approach, the mathematical expression of the weight is a function not only of the intensity gradient, but also of five normalized Euclidean distances, between 0.33 and 1, associated to 26 adjacent nodes. This first study shows that 3D-LARWSD gives better overall results than the original method while avoiding the choice of β-value.

Due to the difficulty of voxel classification at the interface between pathological and healthy tissues caused by partial volume effect, the integration of the probability density in the system of linear equations has been proposed, allowing strengthening the grouping of similar intensities of voxels in the contours. This improvement strengthens the connection between unlabeled voxels and seeds, reducing the blur on the boundary of the lesion.

Segmentation of positive tissue on FDG PET images requires the use of robust segmentation algorithms. Most of the methods in the literature are efficient for the segmentation of large and homogeneous lesions. Our 3D-LARW has given better performances than the original RW algorithm, the two thresholding methods mainly used in clinical practice [3] and FLAB method. As expected, the improvements are more pronounced for small spheres than for large ones and on heterogeneous lesions than on homogeneous lesions showing our contribution to solve these two main problems of segmentation in PET imaging.

@&#REFERENCES@&#


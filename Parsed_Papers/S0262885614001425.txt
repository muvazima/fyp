@&#MAIN-TITLE@&#Scale-invariant contour segment context in object detection

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We design a scale-invariant shape descriptor for shape matching and object detection.


                        
                        
                           
                           A graph-based segment matching algorithm is introduced.


                        
                        
                           
                           Accurate boundary of object can be detected in natural image.


                        
                        
                           
                           Compute the similarity between descriptors properly in clutter background


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Object detection

Shape descriptor

Scale-invariant

Contour segment context

@&#ABSTRACT@&#


               
               
                  The evaluation of the scale of an object in a cluttered background is a serious problem in computer vision. The most existing contour-based approaches relevant to object detection address this problem by normalizing descriptor or multi-scale searching, such as sliding-window searching, spatial pyramid model etc. Besides, Hough-voting framework can predict the scale of an object according to some meaning fragments. However, utilizing scale-variant descriptor or complicated structure in these measures reduces the efficiency of detection. In the present paper, we propose a novel shape feature called scale-invariant contour segment context (CSC). This feature is based on the angle between contour line segments. It remains unchanged as scale varies. Most importantly, it evaluates the scale of objects located in cluttered images and facilitates localization of the boundary of the object in unseen images simultaneously. In this way, we need to focus on just the shape matching algorithm without considering the variant scale of the object in an image. This is a procedure which absolutely differs from voting and sliding window searching. We do experiments on ETHZ shape dataset, Weizmann horses dataset, and the bottle subset from PASCAL datasets. The results confirm that the present model of object detection, based on CSC, outperforms state-of-the-art of shape-based detection methods.
               
            

@&#INTRODUCTION@&#

Shape plays an important role in object detection in computer vision. This is because some invariant shape information remains in various transformations and blurs. Shape-based approaches for object detection have drawn considerable attention from many researchers and many studies of object detection and shape matching have focused on this area [1–17].

Generally, there are three main problems in object detection in a cluttered background: 1) Variant scale of object, which prevents the vision system from knowing the scale of object in unseen image. 2) Deformations of intra-class objects, which affects the accuracy of detection. 3) Cluttered edges between background and object, which contain missing or clustered object edges.

Other detection models meant to address these problems have been proposed recently. Hough-voting is used to assess variations in scale [2,11,7,15]. Shotton et al. [18] combined contour and texture information. Shotton et al. [16] introduced a multi-scale model using contour fragments. The sliding window scheme was designed for searching multiple scales and identifying the optimal scale [1,19]. Part-based matching approaches are suitable for dealing with the deformation of objects. These approaches incorporate skeleton models and local fragment features [20,1,4,6,7,21,9]. Global shape matching using combinations of partial matching, such as fragment matching, has an advantage when dealing with non-rigid deformations within classes. Most existing models are based on fragment matching, so optimization algorithms are used to integrate the results of early matching into a final evaluation of detection. Ma and Latecki [6] proposed a novel advanced method of object detection involving the use of maximum clique in similarity graphs. The model poses shape matching as graph matching. Wang et al. [22] proposed to use graph matching for detecting object. Yang et al. [23] regarded object detection as a problem of finding dominant sets in weighted graph. Lu et al. [5] grouped fragments for detection using particle filters. Srinivasan et al. [9] built many-to-one maps using image-to-model matching to deal with unequal numbers of fragments.

Some parts of intra-class objects remain unchanged and others may vary. As shown in Fig. 1(a), the body of a swan remains invariant over time but the neck deforms. The unchanged parts contribute more to detection than the changed parts do. Approaches based on voting use the unchanged areas to locate objects and evaluate scale. However, the local shape features used in these methods are not very discriminative. Most of the aforementioned algorithms use local feature descriptors limited to a small local area [1,6]. To achieve global detection, most of these methods can be combined with spatial construction [21]. There are also global feature descriptors suitable for evaluation of detection but sensitive to transformation. Given the variety of inner class objects, multiple prototypes with deformation can be combined and used to detect objects accurately in cluttered backgrounds. These models ignore transform-invariant shape features and the fact that unchanged parts can be the discriminative. Unchanged areas are not just local or global features. They can be defined by the proportions of unchanged parts. This feature is here considered, and a novel descriptor that uses unchanged parts is presented.

In the present paper, shape representation is based on contour line segments. These are similar to the contour fragments that appear in many models [1,4,6,15,16]. However, the present fragment here is a line segment. As shown in Fig. 1(b), the line segments are marked by different colors. For simplicity, all segments mentioned in the remainder of the paper refer to line segments. Observing two segments of partially occluded object that tend to be unchanged shows the absolute dissimilarity of the angle between them to be invariant under scaling, translation, and rotation conditions. The segments are called orientation-based features because only the angles between them are considered. Orientation-based models are inspired by biological systems, specifically the human visual system. Hubel and Wiesel [24] provided a fundamental analysis of orientation features. Currently, there are some effective biologically inspired computational models which use orientation feature. These include the famous HMAX model [25]. HMAX has shown outstanding performance in object recognition. Another research team has shown a novel approach to the detection of orientation in natural images [26].

A scale-invariant shape feature, contour segment context (CSC), is here proposed. It functions by adding context information to orientation features. Another characteristic of the present model is its ability to capture the maximum similarity of CSC between images when comparing their correspondence. This is a novel means of addressing noisy backgrounds in that the deficiency boundary of the object and cluttered segments does not increase the difference of the actual object from the background.

A detection schema integrating feature correspondence and matching is here presented and used for object detection. Experiments indicate that the present model is rational. A result of detection is shown in Fig. 1. The present model solves the three problems described above: Variation of scale, Deformation within classes, and Confounded boundaries. CSC makes a fundamental contribution to accurate evaluation of scale and simultaneous detection of objects boundaries.

The rest of this paper is organized as follows: Section 2 introduces some related works. Section 3 gives an overview of the method. Section 4 introduces a shape model based on line segments and an algorithm for basic matching between two images represented by segments. Section 5 shows the procedure for object detection. Experimental results are shown in Section 6. Conclusion and future work are outlined in Section 7.

@&#RELATED WORK@&#

Belongie et al. [27] proposed a novel shape descriptor, called shape context, for shape matching and object recognition. However, the accuracy of shape matching is very poor because there is no way to evaluate the scale of objects in unseen images that have backgrounds. In addition, the standard shape context can be extended by considering the tangle vector of sample points [28,29]. This method, however, is still sensitive to the cluttering that can be caused by noisy or irrelevant points, so it does not include a means of evaluating variations in scale.

Many models use contour fragments to represent shape [1,4,6,7,21,9]. Ferrari et al. [1] used line segments (k-AS) as local features and detected object using the sliding-window method. Local adjacent line segment features are robust to scale variants, rotation, and transformation. However, local fragments that lack context information are less discriminative.

Lu et al. [5] introduced a triangle-based shape descriptor differing from shape context. Lin et al. [4] combined it and shape context to produce an effective contour descriptor. In triangle-based descriptor, the distances need to be normalized to make it scale invariant. However, in our model, we ignore this distance information due to it is sensitive to scale. Besides, the angle of triangle-based descriptor is produced by line segments which link sample points while ours is the angle of line segments which represent the contour of object, as shown in Fig. 1(b). Cao et al. [30] presented a descriptor named SYM-FISH to improve shape context by integrating symmetric information. Hu et al. [31] proposed a sparse image representation using line and arc segments of active curve to fit image. Lin et al. [32] designed a layered graph matching algorithm and apply it to shape matching and object detection.

Wang et al. [10] introduced a ray based descriptor which contains distance and two kinds of angles, but a referred point need to be determined. Lu et al. [33] improved chamfer matching algorithm by incorporating edge orientation information which is similar to line segment. Yarlagadda and Ommer [34] introduced an approach to detect object and depict shape simultaneously by utilizing valuable contour.

Many studies have evaluated shape distance and shape transformation and the ways in which these factors can be used to measure deformation. One research team proposed a TPS-RPM algorithm for non-rigid shape matching [35]. Another proposed a new concept of shape distance, called inner distance, for processing deformation of inner class object [36]. However, these methods do not work on cluttered images. Another study extended TPS-RPM, taking the deformation model into consideration, and used it to detect objects [2].

The main procedure of our model for object detection is shown in Fig. 2
                     . Firstly, an edge map of the image is made using Pb-detector [37], producing a line segment map [38], as the first column images in Fig. 2(b). Next every segment orientation as represented by CSC is calculated to extract shape information, as the second column images in Fig. 2(b). Then the correspondence of segment matching is aligned by computing the similarity among the CSCs, as Fig. 2(c). At this stage, the model and query image were matched in an iterative fashion to facilitate the precise detection of objects and to reduce disruption of the cluttered background, as Fig. 2(e). Note that the present model can evaluate the scale and location of objects during the first iteration in most images. In our experiments, 2 iterations were used. Finally, segments belonging to the boundary of the object were distinguished from the cluttered background so that the target object could be detected, as Fig. 2(f).

The shape of an object is determined by the contours of the boundaries. A contour map can be represented approximately using straight line segments, as in Fig. 1(b). The key idea is that the distribution of segments of an object that belongs to the same class remains unchanged even in cluttered backgrounds. This property contributes to object detection. The goal of the present work is to develop discriminative and transform-invariant shape representation processes.

The contour line segments of two shapes I
                        ={I
                        1,
                        I
                        2,
                        I
                        3,…,
                        I
                        
                           k
                        } are here called basic segments. For every basic-segment, we link the mid-point of it to other segments¡¯, called a link-segment, as shown in the dashed line in Fig. 3(a). In this way, for every segment I
                        
                           j
                        , there are k related link-segments, L
                        ={L
                        1,
                        L
                        2,
                        L
                        3,…,
                        L
                        
                           k
                        }, and its shape information is determined by its link-segments and other basic segments. The context information of other segments was used to represent the shape of the green segment in Fig. 3(a). This information included both basic-segments and link-segments but not partial segments within a fixed area. The context information is here called contour segment context (CSC) and it was measured using two types of angles, first is the intersection angle θ between basic segment and link-segment, the other is the angle φ between basic-segments. These compose the shape vector (θ,
                        φ) of CSC. The shape vector is scale-invariant because the angle between segments remains stable as the scale changes. In this way, the shape feature vector of the green segment can be represented as P
                        
                           j
                        
                        ={p
                        
                           j1,
                        p
                        
                           j2,…,
                        p
                        
                           jk
                        }, where p
                        
                           ji
                        
                        =(θ
                        
                           ji
                        ,
                        varphi
                        
                           ji
                        ). The shape vectors of all basic segments can be grouped to represent the shape of an object, so the CSC of object is P
                        ={P
                        1,
                        P
                        2,…,
                        P
                        
                           k
                        }.

Discriminative representation: The CSC of total segments of an object has a discriminative power and it is objective between the shape of an object and shape descriptor. The CSCs describing a single segment alone, however, might be identical. As shown in Fig. 3(b), with respect to red segment 1, the CSC formed from {p
                        12,
                        p
                        13} was the same as the vector produced from {p
                        12,
                        p
                        14}.

However, the shape {1,2,3} differs from {1,2,4}. For this reason, the CSC values of all segments must be combined to describe the contour shape of an object, which differs from shape context in that it involves only partial sample pints in fixed scope. After combining the CSC of each segment to represent CSC of an object, the contour shape corresponds one-to-one to CSC, and vice versa.

As shown in Fig. 4
                        , the similarity of CSC values to each other is high within classes, which includes apples, but it is low between classes. The property is maintained in cluttered backgrounds, which means that cluttered segments would not affect the common unchanged parts that mostly belong to the object. The CSC values of two images of apple are similar. The same is true of images of the swan. However, the CSC values of the apple and swan are different. The common areas were marked in different colors, and these areas were used to detect target object.

A histogram was used to represent CSC.
                           
                              
                                 
                                    h
                                    j
                                    k
                                 
                                 =
                                 #
                                 
                                    
                                       
                                          p
                                          
                                             j
                                             i
                                          
                                       
                                       :
                                       
                                          p
                                          
                                             j
                                             i
                                          
                                       
                                       ∈
                                       bin
                                       
                                          k
                                       
                                    
                                 
                              
                           
                        
                     

Here bin(k) represents a fixed range of angles, such as 0−45°,45−90°, and p
                        
                           ji
                         is the angle between basic segment i and basic segment j or between basic segment i and link-segment j.

To evaluate the similarity of two segments in different images, the similarity of the items within each bin rather than the distance, such as χ
                        2 distance, is assessed. The key idea is that the act of calculating differences among cluttered segments will increase them. However, when similarity is assessed, the presence of cluttered segments does not reduce similarity. As shown Fig. 4, if χ
                        2 distance is used, the shape distance will be large because of the presence of cluttered segments. However, similarity became more pronounced because it increased in marked areas but not in others. For this reason, the similarity of two segments P
                        
                           i
                         and Q
                        
                           j
                         was computed as follows:
                           
                              (1)
                              
                                 s
                                 
                                    
                                       P
                                       i
                                    
                                    
                                       Q
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       nbins
                                    
                                    
                                 
                                 
                                    
                                       min
                                       
                                          
                                             h
                                             i
                                             t
                                          
                                          
                                             h
                                             j
                                             t
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Here min(h
                        
                           i
                        
                        
                           t
                        ,
                        h
                        
                           j
                        
                        
                           t
                        ) indicates the minimum number of segments in bin(t).

When two segments are actually pair segments, the histograms are also similar and the accumulation in similarity should be high. This method may offer an advantage over other methods with respect to object detection in cluttered images.

The similarity of segments located in the same bin was evaluated to increase robustness to deformation. When one real pair of segments is located in the same bin of a different histogram, their CSC values are very large. For this reason, the similarity is adjusted as follows:
                           
                              (2)
                              
                                 S
                                 
                                    
                                       P
                                       i
                                    
                                    
                                       Q
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                       
                                          t
                                          =
                                          1
                                       
                                       nbins
                                    
                                    
                                 
                                 
                                 
                                    
                                       max
                                       
                                          
                                             s
                                             
                                                
                                                   p
                                                   
                                                      i
                                                      ′
                                                   
                                                
                                                
                                                   q
                                                   
                                                      j
                                                      ′
                                                   
                                                
                                             
                                             :
                                             
                                                p
                                                
                                                   i
                                                   ′
                                                
                                             
                                             ,
                                             
                                                q
                                                
                                                   j
                                                   ′
                                                
                                             
                                             ∈
                                             bin
                                             
                                                t
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

To simulate the attribution of real shape segments, such as shape continuity, the adjacent segments were successively organized into a queue. Shape spatial structure was depicted by considering adjacent segments. The process is summarized as Algorithm 1.
                           Algorithm 1: organizing segments
                           
                              
                                 
                                    
                                 
                              
                           

CSC allows the user to solve the problems mentioned at the beginning of this paper. There are three main advantages inherent in this shape model:
                           
                              Scale-invariant
                              When the scale of an object varies across different occasions, then even in a strongly cluttered background, the shape vector p
                                 =(θ,
                                 φ) remains stable. In this way, the CSC naturally becomes scale-invariant. This is the largest advantage to the present shape model. It promotes object detection in cluttered backgrounds by evaluating scale and locating the boundary simultaneously (more details in Section 5). This method is completely different from Hough-voting and sliding window.

Scale-invariant CSC values are more tolerant to deformation than other shape descriptors within the inner class. Because deformation of the same class of object is more pronounced in unchanged parts than in changed areas and because CSC mainly captures the shape information of unchanged parts of an object. Most parts of the categories upon which the partial matching process is based can be utilized efficiently, and CSC promotes integration of partial matching to facilitate global detection.

Even parts of an image far from the site of deformation can be affected by it. Because accumulation of similarity was incorporated into the process, areas near the site of deformation show less of an affect. This facilitates partial matching. By combining the similarity of parts of the image to that of other parts of the image, the total similarity can be determined. This process can deal with the deformation of matching even when only one exemplar image is used. In this way, CSC can be used to evaluate deformation in inner classes more easily than other methods can.

After evaluating the scale and deformation of an object, the boundaries of that object are detected. The detection scheme used to find the boundaries of an object, incorporated a many-to-one mapping process from exemplar to quest image. In an image where most of the cluttered segments belong to the background, according to Eq. (2), these cluttered segments are always dissimilar. Cluttered segments only affect the similarity of real pairs of segments slightly. This is because of the incorporation of accumulation of similarity into the strategy.

Transposition-invariant is a natural characteristic of CSC. Besides, we take the direction of the current segment during the computation of CSC which can serve as a reference and so be used to render the process rotation-invariant.

Given the CSC of model images P
                        ={p
                        1,
                        p
                        2,…,
                        p
                        
                           k
                        } and the query images Q
                        ={q
                        1,
                        q
                        2,…,
                        q
                        
                           n
                        }, the goal of segment matching is to find the following mapping from model to the following query image:
                           
                              
                                 ϕ
                                 
                                    
                                       p
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       
                                          arg
                                          
                                          max
                                       
                                       
                                          
                                             q
                                             i
                                          
                                          ∈
                                          Q
                                       
                                    
                                 
                                 
                                 S
                                 
                                    
                                       p
                                       j
                                    
                                    
                                       q
                                       i
                                    
                                 
                                 .
                              
                           
                        
                     

Due to the missing partial boundary of the object, it is impossible to perform one-to-one mapping between two segment maps. A many-to-one method, in which one model segment can have the multiple corresponding segment in the query map, was here used to perform the matching process. Eq. (2) shows the similarity of two segments.


                        x here serves as the indicated vector of segments in the query map. The global maximum similarity must be found by choosing specific segments. This problem is transformed to a standard quadratic programming.
                           
                              
                                 
                                    
                                       
                                          
                                          
                                          
                                             ⁢
                                             max
                                             ⁡
                                          
                                          
                                          H
                                          
                                             x
                                          
                                          =
                                          
                                             x
                                             ⊤
                                          
                                          S
                                          x
                                       
                                    
                                    
                                       
                                          
                                          s
                                          .
                                          t
                                          .
                                          
                                          
                                          x
                                          ∈
                                          Δ
                                       
                                    
                                    
                                       
                                          
                                          where
                                          
                                          
                                          Δ
                                          =
                                          
                                             
                                                x
                                                ∈
                                                
                                                   
                                                      0
                                                      1
                                                   
                                                   
                                                      K
                                                      ×
                                                      N
                                                   
                                                
                                             
                                          
                                          ,
                                          K
                                          =
                                          
                                             P
                                          
                                          ,
                                          N
                                          =
                                          
                                             Q
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Solving this optimization directly becomes more complex as the number of segments increases, so another greedy algorithm was used to replace it. First, we organize all segments by Algorithm 1 in model not query image since the object is not known. Then we compute the similarity of segments. Notice that we utilize the advantage of CSC, scale-invariant, to compute similarity without considering search space and can combine the segments according model automatically. As in a previous study, they utilize relation adjacent segments to enhance measure of similarity [1]. However, unlike in that study, the similarity of segments with context information was computed throughout the image total image. In this way, there was enough shape information in every segment.

For two pairs of segments M′={M
                        1′,
                        M
                        2′},
                        I′={I
                        1′,
                        I
                        2′}, where M
                        1′,
                        M
                        2′ is neighboring to each other. The similarity of these segments is computed as follows:
                           
                              (3)
                              
                                 simi
                                 
                                    
                                       I
                                       ′
                                    
                                    
                                       M
                                       ′
                                    
                                 
                                 =
                                 αmin
                                 
                                    
                                       
                                          D
                                          
                                             
                                                I
                                                1
                                                ′
                                             
                                             
                                                I
                                                2
                                                ′
                                             
                                          
                                       
                                       
                                          D
                                          
                                             
                                                M
                                                1
                                                ′
                                             
                                             
                                                M
                                                2
                                                ′
                                             
                                          
                                       
                                    
                                    
                                       
                                          D
                                          
                                             
                                                M
                                                1
                                                ′
                                             
                                             
                                                M
                                                2
                                                ′
                                             
                                          
                                       
                                       
                                          D
                                          
                                             
                                                I
                                                1
                                                ′
                                             
                                             
                                                I
                                                2
                                                ′
                                             
                                          
                                       
                                    
                                 
                                 +
                                 β
                                 
                                    
                                       T
                                       
                                          
                                             I
                                             1
                                          
                                          
                                             I
                                             2
                                          
                                       
                                       −
                                       T
                                       
                                          
                                             M
                                             1
                                          
                                          
                                             M
                                             2
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

Here, D is the distance between midpoints of segments, and T is normalized, indicating the angle of two segments. In the present model, α
                        =0.8 and β
                        =0.4.

Shape matching can be considered a core principle of object detection. The main difficulty in this is that query images contain many noisy and uncorrelated segments. After the early rounds of matching, a many-to-one mapping construct was built from model segments M to query image I, ϕ
                        :
                        M
                        →
                        I. The goal of the present work was to identify segments in the boundaries of objects accurately and to direct matching process.

All detection hypotheses in all images examined were evaluated using freshly collected model segments and matched segments, ignoring unmatched segments. Eq. (2) was used to compute similarity for scoring. The more matched the correct segments, the more accurate the hypothesis was believed to be. Given model M and the last matched segments Φ(M), the score for every match hypothesis was taken to consist of two parts, both of average similarity in model segments and in test segments.

The similarity of two shapes can be computed as follows:
                           
                              
                                 simi
                                 
                                    
                                       M
                                       ,
                                       Φ
                                       
                                          M
                                       
                                    
                                 
                                 =
                                 
                                    1
                                    
                                       M
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          M
                                       
                                    
                                    
                                 
                                 
                                 
                                    max
                                    
                                       
                                          I
                                          j
                                       
                                       ∈
                                       Φ
                                       
                                          M
                                       
                                    
                                 
                                 simi
                                 
                                    
                                       M
                                       i
                                    
                                    
                                       I
                                       j
                                    
                                 
                                 .
                              
                           
                        
                     

To detect multiple objects in an image, a score threshold η was set, and one image segment was re-detected without any matched segments. Any score under η caused the detection process to cease. In this paper, the least score of the first detection served as a threshold for that image.

The process of detecting objects involved several rounds of matching. The results of the previous iteration serve as input for later detections. The whole matching process is summarized in Algorithm 2.
                           Algorithm 2: object detection using CSC
                           
                              
                                 
                                    
                                 
                              
                           

To validate the scale-invariant property of CSC, we do some test in images with different scale objects to same template, as Fig. 5
                        . We find that most of them can detect the accurate location and scale of an object, and then we integrate them into object detection.

The present shape model can promote shape matching directly from natural segment maps containing both objects and a cluttered background. With scale-invariant CSC, it can be used to align two object segments. Fig. 6
                         shows matching between boundaries of objects of the same class from two different images with very cluttered backgrounds.

@&#EXPERIMENTAL RESULTS@&#

We test our model on three popular datasets containing ETHZ shape dataset [39], Weizmann horses dataset [40] and the bottle subset from PASCAL datasets [41]. The detection algorithm was run for 2 iterations. The threshold for detecting multiple objects was served as the minimum score that indicated that an object had been detected during the first iteration. The formula was as follows:
                        
                           
                              η
                              =
                              min
                              
                                 
                                    score
                                    
                                       M
                                       
                                          I
                                          i
                                       
                                    
                                    :
                                    i
                                    =
                                    1
                                    ,
                                    2
                                    ,
                                    …
                                    ,
                                    255
                                 
                              
                              .
                           
                        
                     
                  

Here, I
                     
                        i
                      and M are the query image and the model shape of class.

PASCA criteria were used. As for detection bound-box B
                     
                        db
                      and ground truth bound-box B
                     
                        gt
                     , if B
                     
                        db
                      and B
                     
                        gt
                      intersected over 50% of the time, then they were considered a true match.

The total algorithm is implemented by MATLAB. The experimental platform is a PC with Core quad-core 3.4 GHZ CPU and 4GB memory. The computational time of detecting an object on an image depends on the amount of line segments. In our model, the amount of line segment in one image, on average, is about 500–800, and the time to detect object is about 1–4 minutes.

The popular shape-based object detection ETHZ dataset contains 255 images arranged in 5 categories. Every category contains 32–87 images. Hand-drawn models of every category in the set are available. All 255 images served as test images.

These results were mainly compared to approaches based on hand-drawn models. This was because a hand-drawn model was used here to test the 255 images. These results were compared to those of previous studies [39,2,29,5]. However, the present work used a stable model rather than several deformable templates and showed some false positive results per image (FPPI) vs. detection rate (DR), as shown in Fig. 7
                        . The curve shows that the present approach can peak sharply in 5 categories. This approach can yield a 100% detection rate, but the FPPI will be somewhat large. That indicates that the present model can recall all the objects within an image. Generally, the detection rate in 0.3/0.4 FPPI was evaluated, as shown in Table 1
                        . The images of the apple and giraffe showed higher than average detection rates.

The results returned by the present model included the segments of object boundaries, not only the bound-box. As shown in Fig. 8
                        , objects can be detected even in very cluttered backgrounds. Three results containing false positives are also shown. They are in the bottom row.

Weizmann horses is a challenging multi-scale dataset. It contains 228 positive images and 228 background images. We take all the images as our test images. That denotes that we test more images than other approaches based on classifier. We compare our results with the state-of-the-art methods [15,18,16]. We show our quantitative results in Figs. 9
                         and. 10
                        .

As Fig. 9 shows, our model achieves better performance with all positive images compared to [15,18]. The ROC curve in Fig. 10 indicates that our method exceeds the performance of SVM benchmark depicted in [16]. Note that our model can locate the accurate boundary of an object, while the three methods aforementioned only detect object with bounding box.

Besides, we show some examples of detection, as shown in Fig. 11
                        . We only use one exemplar with fixed scale, and our model detect boundary of object under various scale conditions.

PASCAL data set [41] is another popular image dataset in computer vision, but there are little shape-based models of object detection focusing on this set. To demonstrate the robustness of our model, we use the exemplar of bottle from ETHZ shape data set to detect the bottle from PASCAL data set. We chose 100 images of bottle as positive images and 100 negative images from PASCAL data set. As Fig. 12
                         shows, our model outperforms shape context [27] and kAS [1]. We show some results of detection in Fig. 13
                        . That indicates that our model can adapt to a new image dataset under a variety of scales within intra-class.

This paper proposes a scale-invariant shape featuring CSC and a detecting scheme involving the accumulation of similarity. This is a novel approach to the simultaneous evaluation of scale and boundaries, and facilitates validation of the detection, especially detections performed in a strongly cluttered background. The model, however, was given manually, so the next issue is to focus on learning shape models directly from natural images with cluttered background.

@&#ACKNOWLEDGMENTS@&#

This work was supported by the 973 Program (Project No. 2010CB327900), the NSFC project (Project No. 61375122, No. 81373556) and the National Twelfth 5-Year Plan for Science & Technology (Project No. 2012BAI37B06).

@&#REFERENCES@&#


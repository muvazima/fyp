@&#MAIN-TITLE@&#Tensor low-rank and sparse light field photography

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We present a computational camera system for efficient light field image and video acquisition.


                        
                        
                           
                           Our mathematical framework models the intrinsic low dimensionality of light fields using tensor low-rank and sparse priors.


                        
                        
                           
                           We design and implement a prototype compressive light field camera that avoids capturing redundancy of high-dimensional plenoptic function.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Computational photography

Low-rank tensor factorization

Low-rank and sparse decomposition

Compressive sensing

@&#ABSTRACT@&#


               
               
                  High-quality light field photography has been one of the most difficult challenges in computational photography. Conventional methods either sacrifice resolution, use multiple devices, or require multiple images to be captured. Combining coded image acquisition and compressive reconstruction is one of the most promising directions to overcome limitations of conventional light field cameras. We present a new approach to compressive light field photography that exploits a joint tensor low-rank and sparse prior (LRSP) on natural light fields. As opposed to recently proposed light field dictionaries, our method does not require a computationally expensive learning stage but rather models the redundancies of high dimensional visual signals using a tensor low-rank prior. This is not only computationally more efficient but also more flexible in that the proposed techniques are easily applicable to a wide range of different imaging systems, camera parameters, and also scene types.
               
            

@&#INTRODUCTION@&#

One of the main goals of computational photography is to design camera systems which record visual information that can be processed so as to facilitate new imaging modalities. Examples of such modalities include motion deblurring, extended depth of field as well as multi-spectral and light field imaging. It could be argued that an “ultimate” computational camera would capture all visual information so as to allow for the most general processing algorithms to be applied after the fact.

The plenoptic function [1] was introduced as a ray-based model for light that encompasses all visual information: spatial, angular, and temporal light variation as well as the color spectrum. So what makes it hard to design a camera that captures the plenoptic function in a single image? The shear amount of required plenoptic samples make this a “big data” problem with extreme challenges for camera optics, sensor electronics, and computation. Consider the example of a light field video recorded at 30 Hz, with 11.1 Megapixel resolution, 10 × 10 angular samples, and three color channels—about 100 billion light rays (∼100 GB of raw data) have to be recorded, processed, and stored per second. Clearly, camera technology today is not suited for this task.

However, high-dimensional visual signals are highly redundant. Compression algorithms, for instance, exploit this fact to minimize the memory footprint of images and videos. Moreover, recent proposals have shown that images [2], videos [3], and light fields [4] can be recovered from only a few measurements using sparsity-constrained optimization. In this paper, we present a new mathematical framework for efficient high-dimensional visual signal processing, acquisition, and storage. We demonstrate that there is a large amount of correlation between the dimensions of time-varying light fields, which can be exploited by a low-rank prior applied to the five-dimensional tensor space containing spatial, temporal, and angular light variation. This prior is a good model for exploiting view-independent and slow-moving scene parts whereas an additional sparse term captures view-dependent effects and fast motions.

We also propose a light field camera design that is well-suited for capturing coded projections of the plenoptic function that can be reconstructed by the proposed algorithms. In contrast to existing, dictionary-based light field capture systems [4], our tensor low-rank and sparse light field recovery does not require a learning phase, which is computationally expensive (tens to hundreds of hours). Further, the LRSP prior is flexible enough to be applied to a wide range of scenes and optical systems. In particular, we make the following contributions:

                        
                           •
                           We present a computational camera system for light field image and video capture that facilitates efficient acquisition without a dictionary learning phase.

We introduce a mathematical framework that models intrinsic low-dimensionality of light fields using tensor low-rank and sparse priors. We show that this model captures redundancy in the high-dimensional plenoptic function well and allows for new optical setups to be derived.

We design and implement a prototype compressive light field camera that is evaluated both by simulation and experiments.

@&#RELATED WORK@&#

Since their introduction to computer graphics [5,6], light fields have found widespread application in image-based rendering and computational photography. Light field cameras predate the use in computational photography; prototypes using arrays of microlens [7] or pinholes [8] were proposed more than a century ago. Recent improvements to those basic designs [9–14] have made light field photography practical for snapshot imaging via multiplexing [15]. Whereas light fields can also be captured with camera arrays [16,17] or sequential image acquisition [5,6,18–21], these approaches are either expensive or incapable of capturing dynamic scenes.

Compressive sensing has been employed in image and video acquisition [22–27], but these approaches are often depth-dependent. The compressive rendering scheme [28,29] exploits sparsity of the entire light field in frequency domain to address an inpainting problem. Compressive sensing for camera arrays has been addressed, but either requires the knowledge of disparity [30] or the method relies on image alignment [31]. Measurements taken with most light field cameras contain aliasing; a variety of approaches has recently been proposed to exploit this optical effect using advanced reconstruction algorithms to improve image resolution [17,32–39]. All of these approaches use some type of super-resolution algorithm that uses linear optimization to reconstruct a higher-resolution light field and cannot be used for compressive light field acquisition. Nonlinear, sparsity-constrained approaches have also been proposed [40–42]. Most recently, these have been shown to recover high-resolution light fields from a single coded image [4]. This method however is based on a computationally expensive 4D light field dictionary learning stage which is extremely slow and memory intensive; extending this dictionary learning to 5D space-time-angle light field patches is currently intractable.

We introduce tensor low-rank and sparse light fields as a computational photography architecture that generalizes compressive light field photography. The proposed techniques are more flexible than previously-proposed dictionaries [4], we show that temporal variation and other plenoptic dimensions [1] can easily be integrated into the proposed framework, and we demonstrate our techniques with a prototype compressive light field video camera.

The global structure of multilinear datasets is exploited either by modeling it in matrix format, for instance in image alignment [43], video denoising and background subtraction [44,45] or using tensor algebra in multilinear image-based rendering [46], BRDF [47] representation, BTF [48,49], multispectral reflectance field acquisition with a light stage [50], fluorescence measurements [51,52] and subsurface scattering [53] acquisition as well as 3D display [54]. The method most closely related to ours is [50], where low-rank and sparse priors are employed for efficient capture and recovery of lighting- and wavelength-dependent material reflectance properties with a multi-spectral light stage. While similar in spirit, we address a completely different application—light field video capture—which uses a vastly different optical setup and we also employ a different formulation for low-rank and sparse tensor factorization. The proposed methods facilitate novel applications in computational optics and photography.

@&#MOTIVATION@&#

Our choice of a low-rank prior for light field, or the plenoptic function in general, is motivated by a simple insight. In the absence of occlusion, light fields have smooth variation between views and frames. Thus static light fields are highly redundant in angular dimension in addition to the spatial redundancy of individual views. To further clarify the smooth behavior of light field in angular direction, we plot a 2D light field in Fig. 2
                      which shows the direct link between parallax and rank. We observe that when the objects are in the focal plane (disparity equal to zero), there is no parallax so the structures in the light field are constant along the angular dimension, i.e. the rank of the 2D light field matrix is equal to 1. For objects out of focal plane, the amount of disparity is increased, however the variation between views is still smooth. Thus light fields are highly redundant along the angular direction. This means light field angular rank is small in comparison with the maximum possible rank: the number of views.

When objects move in time, the captured light field frames change smoothly. Thus similar to the angular direction, the light fields represent highly correlated structures in time. Intuitively, the intrinsic dimensionality of light fields is significantly lower that the size of light fields and the actual information is contained within some lower-dimensional manifold. We exploit the redundancy in spatial, angular and motion of 5D light fields using a low-rank prior. The low-rank structure of static light fields is also discussed in [39,55–57].

Similar to [55], one way to exploit the light field low-rank structure is to reshape views into column vectors and concatenate them in the columns of a matrix. However, this model is sub-optimal, since the low-rank structure on matrix assembled from the light field views promotes a global pattern and cannot consider different degree of freedom of individual dimensions of the light field. We preserve the original structure of light fields by representing 5D light fields with 5D tensors which independently models the correlated structure of each dimension.

In practice, we reduce the computational cost of our light field structure modeling scheme by working in parallel on independent 5D light field patches. The size of light field patch depends on the amount of parallax and motion in the scene. For a fixed patch size, increase in the amount of parallax and motion decrease the similarity between views. Thus, one needs to adapt the spatial size and the number of frames grouped in light field patches with respect to the amount of parallax and motion so that the correlations in light field patches are preserved. Therefore, the patch size can have an influence on the maximum tolerated parallax and motion modeled by our proposed scheme.

Unfortunately, the notion of a high-dimensional singular value decomposition (SVD) is not clearly defined. A variety of high-dimensional extensions of the SVD exist, for instance the Tucker decomposition and PARAFAC/CANDECOMP (CP) [58], a higher-order SVD (HOSVD) [59], or what is known as the square norm [60]. All of these are compared w.r.t. speed and quality in Table 1
                     . We choose to work with CP as a general low-rank tensor model that is computed via alternating least squares [58]. This not only provides the best quality but is also more flexible than HOSVD, because CP is oblivious to the actual dimension where the signal is low rank. HOSVD on the other hand requires a specific rank to be assigned to each dimension a prior. The interested reader is referred to the supplement for more details.

Light fields cannot always be perfectly represented as low-rank tensors. For example, a large amount of parallax or motion, specularity, reflections, and the noise of acquisition devices can distort the similarity between views. However, the distortion has sparse structure. This argument is supported by Figs. 3
                      and 4
                     , where the remainders between target light fields and rank-6 CP decompositions are shown. Inspired by robust Principle Component Analysis (RPCA) [45], we decompose the light fields into the low-rank and sparse components to improve the reconstruction performance. RPCA with exactly the same principal is employed in various computer vision problems (e.g., [43,44]).

We compare a variety of possible choices for low rank and sparse priors in Fig. 5
                      and conclude that CP as a tensor low-rank model combined with a discrete cosine transform-based sparsity prior is the best choice among the ones tested. So why not simply use the dictionaries of light field atoms for 5D light field videos? Dictionaries for high-dimensional visual data have a lot of advantages, but also two major disadvantages: (a) they require a dictionary learning phase and (b) the dictionary only models structures well that were also part of the training data. For (a), compute times can be extremely long (tens of hours or days for a 4D light field) or even prohibitive (we were not able to learn dictionaries on 5D light field videos). Whereas a large set of training light fields should be sufficient to learn a good dictionary, oftentimes not all possible configurations of f-number settings, scene types, depth ranges, or other scene properties are available to learn from. Hence, the proposed model is more tractable and also more flexible.

A video y(x, t) for a conventional camera sensor is formed by integrating the incident, time-varying light field l(x, ν, t) over its angular domain Ων
                         as

                           
                              (1)
                              
                                 
                                    y
                                    
                                       (
                                       x
                                       ,
                                       t
                                       )
                                    
                                    =
                                    
                                       ∫
                                       
                                          Ω
                                          ν
                                       
                                    
                                    
                                       l
                                       
                                          (
                                          x
                                          ,
                                          ν
                                          ,
                                          t
                                          )
                                       
                                       
                                       d
                                       ν
                                    
                                    .
                                 
                              
                           
                        In this formulation, vignetting and other angle-dependent effects are absorbed by the light field. Whereas the recorded video y varies over the sensor surface
                           1
                        
                        
                           1
                           We consider a single dimension x and ν in both space and time, respectively. Extensions to the full 4D case are straightforward.
                         
                        x and over time t, all angular variation of the light field is irreversibly lost.

Light field photography is concerned with the design of camera systems that preserve the desired angular information optically, such that it can be recovered using computation. In the most general sense, the optical image formation can be expressed as a convolution along the plenoptic dimensions

                           
                              (2)
                              
                                 
                                    y
                                    
                                       (
                                       
                                          x
                                          ′
                                       
                                       ,
                                       
                                          t
                                          ′
                                       
                                       )
                                    
                                    =
                                    
                                       ∫
                                       
                                          Ω
                                          x
                                       
                                    
                                    
                                       ∫
                                       
                                          Ω
                                          ν
                                       
                                    
                                    
                                       ∫
                                       
                                          Ω
                                          t
                                       
                                    
                                    
                                       l
                                       
                                          (
                                          x
                                          ,
                                          ν
                                          ,
                                          t
                                          )
                                       
                                       m
                                       
                                          (
                                          x
                                          −
                                          
                                             x
                                             ′
                                          
                                          ,
                                          ν
                                          ,
                                          t
                                          −
                                          
                                             t
                                             ′
                                          
                                          )
                                       
                                       d
                                       x
                                       
                                       d
                                       ν
                                       
                                       d
                                       t
                                    
                                    .
                                 
                              
                           
                        As discussed in Section 2, a variety of different light field acquisition schemes have been proposed, each one resulting in different tradeoffs. For the purpose of this paper, we only consider a subset of all possible convolution kernels m: the ones allowing for coded optical attenuation, but no ray mixing or refraction. This simplifies the image formation to

                           
                              (3)
                              
                                 
                                    y
                                    
                                       (
                                       x
                                       ,
                                       t
                                       )
                                    
                                    =
                                    
                                       ∫
                                       
                                          Ω
                                          ν
                                       
                                    
                                    
                                       l
                                       
                                          (
                                          x
                                          ,
                                          ν
                                          ,
                                          t
                                          )
                                       
                                       m
                                       
                                          (
                                          x
                                          ,
                                          ν
                                          ,
                                          t
                                          )
                                       
                                       d
                                       ν
                                    
                                    .
                                 
                              
                           
                        In discretized form, this is a coded projection of an order-3 light field tensor 
                           
                              L
                              ∈
                              
                                 R
                                 
                                    n
                                    ×
                                    m
                                    ×
                                    p
                                 
                              
                           
                         to an order-2 video tensor 
                           
                              Y
                              ∈
                              
                                 R
                                 
                                    n
                                    ×
                                    p
                                 
                              
                           
                        :

                           
                              (4)
                              
                                 
                                    Y
                                    =
                                    P
                                    
                                       (
                                       L
                                       )
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              P
                              :
                              
                                 R
                                 
                                    n
                                    ×
                                    m
                                    ×
                                    p
                                 
                              
                              →
                              
                                 R
                                 
                                    n
                                    ×
                                    p
                                 
                              
                           
                         is the linear projection operator incorporating the effect of the modulation kernel m. The number of spatial, angular, and temporal samples is n, m, and p, respectively. Although 
                           Y
                         is technically a matrix in this intuitive “flatland” model, in practice we work with order-5 light field tensors that are coded in order-3 video tensors. Hence, we use tensor notation for both quantities.

The specific choice of the kernel in Eq. (3) is unique in that it allows the measured video tensor 
                           Y
                         to be subdivided into small spatio-temporal windows—neighboring windows in the light field tensor space are not linked by their angles, which could be the case for general convolution kernels (Eq. (2)).

As discussed, light fields can be well approximated by a low-rank and sparse priors. We follow RPCA and represent the light field tensor as the sum of a low-rank and a sparse tensor 
                           
                              L
                              =
                              R
                              +
                              S
                           
                        . Eq. (4) then becomes

                           
                              (5)
                              
                                 
                                    Y
                                    =
                                    P
                                    
                                       (
                                       R
                                       +
                                       S
                                       )
                                    
                                    ,
                                 
                              
                           
                        where 
                           
                              R
                              ,
                              S
                              ∈
                              
                                 R
                                 
                                    n
                                    ×
                                    m
                                    ×
                                    p
                                 
                              
                           
                         are low-rank and sparse, respectively. We allow 
                           S
                         to be sparse in some transform domain 
                           
                              Ψ
                              (
                              S
                              )
                              ,
                           
                         which is expressed by the operator 
                           
                              Ψ
                              :
                              
                                 R
                                 
                                    n
                                    ×
                                    m
                                    ×
                                    p
                                 
                              
                              →
                              
                                 R
                                 
                                    n
                                    ×
                                    m
                                    ×
                                    p
                                 
                              
                           
                        . Motivated by the experiment shown in Fig. 5, we use a high-dimensional discrete cosine transform (DCT) for Ψ and the CANDECOMP (CP) decomposition for 
                           R
                         throughout this paper. The CP decomposition [58,61] of an order-3 tensor 
                           R
                         is the sum of vectors aligned with the dimensions of the tensor:

                           
                              (6)
                              
                                 
                                    R
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       r
                                    
                                    
                                       u
                                       i
                                       
                                          (
                                          x
                                          )
                                       
                                    
                                    ∘
                                    
                                       u
                                       
                                          i
                                       
                                       
                                          (
                                          ν
                                          )
                                       
                                    
                                    ∘
                                    
                                       u
                                       
                                          i
                                       
                                       
                                          (
                                          t
                                          )
                                       
                                    
                                    ,
                                 
                              
                           
                        where r is the rank of 
                           R
                         and 
                           
                              
                                 u
                                 i
                                 
                                    (
                                    x
                                    )
                                 
                              
                              ∈
                              
                                 R
                                 n
                              
                              ,
                              
                              
                                 u
                                 
                                    i
                                 
                                 
                                    (
                                    ν
                                    )
                                 
                              
                              ∈
                              
                                 R
                                 m
                              
                              ,
                           
                        
                        
                           
                              
                                 u
                                 
                                    i
                                 
                                 
                                    (
                                    t
                                    )
                                 
                              
                              ∈
                              
                                 R
                                 p
                              
                           
                         for 
                           
                              i
                              =
                              1
                              ,
                              …
                              ,
                              r
                           
                        . Fig. 6
                         schematically demonstrate our optical setup and light field tensor decomposition.

We follow general convex formulations for RPCA and define the light field low-rank and sparse tensor decomposition by solving the following objective function

                           
                              (7)
                              
                                 
                                    
                                       
                                          
                                             arg
                                             
                                                min
                                                
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   {
                                                   R
                                                   ,
                                                   S
                                                   }
                                                
                                             
                                          
                                       
                                       
                                       
                                          
                                             
                                                ∥
                                                Ψ
                                                
                                                   (
                                                   S
                                                   )
                                                
                                                ∥
                                             
                                             1
                                          
                                       
                                    
                                    
                                       
                                          
                                             subject
                                             
                                             to
                                          
                                       
                                       
                                       
                                          
                                             
                                                
                                                   ∥
                                                   Y
                                                   −
                                                   P
                                                   
                                                      (
                                                      R
                                                      +
                                                      S
                                                      )
                                                   
                                                   ∥
                                                
                                                2
                                                2
                                             
                                             ≤
                                             ϵ
                                             ,
                                          
                                       
                                    
                                 
                              
                           
                        where ϵ is the sensor noise level and ℓ1 norm of a tensor is defined as absolute sum of its elements.

To solve Eq. (7) we resort to the parallel proximal algorithm (PPXA) described by Combettes et al. [62]. For this purpose, the Lagrangian form of the objective is solved as

                           
                              (8)
                              
                                 
                                    arg
                                    
                                       min
                                       
                                          
                                          
                                          
                                          
                                          
                                          
                                          {
                                          R
                                          ,
                                          S
                                          }
                                       
                                    
                                    λ
                                    
                                       
                                          ∥
                                          Ψ
                                          
                                             (
                                             S
                                             )
                                          
                                          ∥
                                       
                                       1
                                    
                                    +
                                    
                                       
                                          ∥
                                          Y
                                          −
                                          P
                                          
                                             (
                                             R
                                             +
                                             S
                                             )
                                          
                                          ∥
                                       
                                       2
                                       2
                                    
                                    ,
                                 
                              
                           
                        where the inequality constraints are incorporated into the objective function. Although there exists a weight λ that corresponds to the sensor noise level ϵ, in practice neither is known exactly and needs to be approximated by a user-defined value. We list all algorithmic parameters in Section 6.
                     

The PPXA algorithm solves Eq. (8) by iteratively computing the proximity operators for each objective term and averaging them. Pseudo-code for this algorithm is outlined in Algorithm 1. All intermediate variables 
                           
                              
                                 X
                                 i
                              
                              ,
                              
                                 Z
                                 
                                    i
                                    j
                                 
                              
                           
                         are tensors of the same size as the light field and 
                           
                              X
                              ,
                              
                                 Z
                                 
                                    (
                                    1
                                    ,
                                    2
                                    )
                                 
                              
                              ,
                              A
                              ,
                              
                                 A
                                 
                                    (
                                    1
                                    ,
                                    2
                                    )
                                 
                              
                           
                         represent concatenations of two such tensors. The proximity operators of our problem are

                           
                              (9)
                              
                                 
                                    
                                       
                                       
                                          
                                             
                                                
                                                   prox
                                                
                                                
                                                   CP
                                                
                                             
                                             
                                                (
                                                X
                                                )
                                             
                                             =
                                             arg
                                             
                                                min
                                                
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   {
                                                   
                                                      u
                                                      
                                                         i
                                                      
                                                      
                                                         (
                                                         x
                                                         ,
                                                         ν
                                                         ,
                                                         t
                                                         )
                                                      
                                                   
                                                   }
                                                
                                             
                                             
                                                
                                                   ∥
                                                   X
                                                   −
                                                   
                                                      ∑
                                                      
                                                         i
                                                         =
                                                         1
                                                      
                                                      r
                                                   
                                                   
                                                      u
                                                      i
                                                      
                                                         (
                                                         x
                                                         )
                                                      
                                                   
                                                   ∘
                                                   
                                                      u
                                                      
                                                         i
                                                      
                                                      
                                                         (
                                                         ν
                                                         )
                                                      
                                                   
                                                   ∘
                                                   
                                                      u
                                                      
                                                         i
                                                      
                                                      
                                                         (
                                                         t
                                                         )
                                                      
                                                   
                                                   ∥
                                                
                                                2
                                                2
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   prox
                                                
                                                
                                                   η
                                                   
                                                      
                                                         ∥
                                                         
                                                            (
                                                            ·
                                                            )
                                                         
                                                         ∥
                                                      
                                                      1
                                                   
                                                
                                             
                                             
                                                (
                                                X
                                                )
                                             
                                             =
                                             
                                                Ψ
                                                *
                                             
                                             
                                                (
                                                
                                                   S
                                                   η
                                                
                                                
                                                   (
                                                   Ψ
                                                   
                                                      (
                                                      X
                                                      )
                                                   
                                                   )
                                                
                                                )
                                             
                                             ,
                                          
                                       
                                    
                                    
                                       
                                       
                                          
                                             
                                                
                                                   prox
                                                
                                                
                                                   η
                                                   
                                                      
                                                         ∥
                                                         
                                                            (
                                                            ·
                                                            )
                                                         
                                                         ∥
                                                      
                                                      2
                                                      2
                                                   
                                                
                                             
                                             
                                                (
                                                X
                                                )
                                             
                                             =
                                             arg
                                             
                                                min
                                                
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   
                                                   {
                                                   Z
                                                   }
                                                
                                             
                                             
                                                
                                                   ∥
                                                   Y
                                                   −
                                                   P
                                                   
                                                      (
                                                      Z
                                                      )
                                                   
                                                   ∥
                                                
                                                2
                                                2
                                             
                                             +
                                             
                                                1
                                                
                                                   2
                                                   η
                                                
                                             
                                             
                                                
                                                   ∥
                                                   Z
                                                   −
                                                   X
                                                   ∥
                                                
                                                2
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where η ∈ (0, ∞) is a scalar, 
                           Z
                         is an intermediate slack variable, 
                           
                              
                                 S
                                 η
                              
                              
                                 (
                                 X
                                 )
                              
                              =
                              
                                 sign
                              
                              
                                 (
                                 X
                                 )
                              
                              
                                 
                                    (
                                    
                                       |
                                       X
                                       |
                                    
                                    −
                                    η
                                    )
                                 
                                 +
                              
                           
                         is a soft-thresholding operator that is applied element-wise to 
                           
                              X
                              ,
                           
                         and 
                           
                              
                                 
                                    prox
                                 
                                 
                                    CP
                                 
                              
                              
                                 (
                                 X
                                 )
                              
                           
                         computes the CP decomposition of 
                           X
                         using alternating least squares ( see Appendix A). As discussed in more detail by Combettes et al. [62], proximal splitting methods basically split up an objective function, such as Eq. (8), into a set of sub-problems, each of which can be solved conveniently by applying a simple proximity operator. Convergence of this iterative scheme is only guaranteed for a sum of convex sub-problems. Although the CP decomposition is not convex, in practice we observe quick convergence.

@&#ANALYSIS@&#

We show two views of a short light field video sequence and corresponding views of the low-rank and sparse components using canonical basis and 5D discrete cosine transform in Fig. 7
                        . Looking at Fig. 7 top, we observe that most parts of this scene are well-approximated by a tensor low-rank representation. Yet, the canonical domain helps to recover high-frequency edges and specularities. However, using DCT5 transform as shown in Fig. 5 improves the performance and allows to recover areas with larger amounts of parallax. However, unlike the canonical domain, discrete cosine transform in addition to high-frequency edges and specularities can also sparsely represent low-frequency and smooth regions. Therefor, when DCT5 is used the low-rank component and sparse component are not well separated.

In all experiments in this paper, we use masks that contain random Gaussian patterns as modulation codes. Throughout the capture process, the codes are changed for successive frames of the video. To satisfy the restricted isometry property, employed codes should be mutually incoherent in angle and time. This property is derived for sparse priors [63] but also exists for low-rank priors [64,65]. Basically, the optical codes should be as random as possible w.r.t. each other such that the diversity of the sampling process is maximized. In Section 6, we present a new compressive light field camera prototype that allows us to code all light fields views independently and which could scale to large baselines.

It is important to understand the conditions under which low-rank and sparse components can actually be recovered. Usually this is given as the order of the number of required measurements given some properties of the projection operator 
                           P
                         (“the measurement matrix”). Oftentimes, the degree of freedom of a tensor is used to derive an expression for the required number of measurements in the literature. The degree of freedom of a generic order-k tensor with rank r is 
                           
                              
                                 r
                                 k
                              
                              +
                              k
                              n
                              r
                              ,
                           
                         where 
                           
                              n
                              =
                              max
                              {
                              
                                 n
                                 i
                              
                              ;
                              i
                              ∈
                              
                                 [
                                 k
                                 ]
                              
                              }
                           
                         is the largest dimension of the tensor. The degree of freedom for a combined low-rank and sparse tensor is 
                           
                              
                                 d
                                 t
                              
                              =
                              
                                 r
                                 k
                              
                              +
                              k
                              n
                              r
                              +
                              
                                 
                                    ∥
                                    Ψ
                                    
                                       (
                                       S
                                       )
                                    
                                    ∥
                                 
                                 0
                              
                           
                        . Recall that ‖ · ‖0 denotes the number of non-zeros elements entries in a tensor. Wright et al. [66], for instance, showed when the measurements are taken from a Gaussian random distribution, the minimum number of required measurements to decompose a matrix into low-rank and sparse components is 
                           
                              
                                 O
                                 (
                              
                              
                                 log
                                 2
                              
                              
                                 
                                    (
                                    n
                                    )
                                 
                                 (
                              
                              
                                 (
                                 2
                                 n
                                 r
                                 −
                                 
                                    r
                                    2
                                 
                                 )
                              
                              +
                              
                                 
                                    ∥
                                    S
                                    ∥
                                 
                                 0
                              
                              
                                 )
                                 )
                              
                              ,
                           
                         i.e. O(log2(n)dm
                        ), where dm
                         is the degree of freedom of a low-rank matrix. Holger et al. [64] give an expression for the minimum number of required measurements to recover a low-rank tensor from linear measurements as O(log (k)dt
                        ). Disregarding what the actual number is, it is proportional to the degree of freedom of the tensor and therefore to its rank. We experimentally verify this in the following section by varying parallax and motion of the tensor, hence its rank.

We evaluate reconstruction quality w.r.t. varying amounts of parallax and scene motion in Fig. 8
                        . All target light fields contain a resolution chart with some amount of parallax over 5 × 5 simulated views and motion over 5 frames. The plot shows that it is easier to recover motion than parallax (top right), which is intuitive because parallax is integrated by the sensor. Overall, relatively ≈ 5 pixels of both parallax and motion can be recovered well with the simulated setup. Increase in the amount of parallax for a fixed patch size blurs the high frequency details in the patch. As discussed in Section 5.3, we can increase the amount of recovered parallax by the algorithm with more measurements. Nevertheless, the quality of the proposed method is better than that achieved with light field dictionaries (lower right). High-frequency details are successfully recovered with the proposed algorithm. For this experiment, we used the dictionary provided by Marwah et al. [4] on their project website.

@&#IMPLEMENTATION@&#

We built a proof-of-concept prototype light field camera that is optimized for the proposed algorithms (Fig. 9
                              ). The special property of this device is that intermediate images, showing the individual views of the light field, are generated in mid air (yellow boxes). These can be independently modulated before they are optically combined on the sensor. Though the system is designed to capture light fields with 2 × 2 views through a lens array with a single sensor, it can be extended to more views by some modification to the design, such as use of prism sets or Fresnel plates. The array has a baseline of 6.5 cm and the optical setup consists of an entrance lens (L1, f = 25 cm, D = 15 cm) that feeds converging light into a set of four smaller lenslets (LL1, f = 10 cm, D = 2.54 cm). The image of each lenslet is projected on the mask plane (see Fig. 9). As discussed in Section 5.2, the mask pattern is a random distribution and printed on a transparency with 50800 DPI by http://www.fineline-imaging.com/. In light field video acquisition, in order to increase the incoherency between consequent acquisition, we slightly displace the mask. However, one could program a motor for the displacement. In general, LCDs could replace the printed mask but the resolution of LCDs are limited and the resolution of the mask imposes a limitation on the resolution of reconstructed light field. Thus, we preferred a printed mask to the available LCDs.

Each image under the lenslets is optically multiplied by a different random pattern. The masked images are then re-imaged by a set of secondary lenslets (LL2, f = 10 cm, D = 1.27 cm) and overlaid via L2 (f = 20 cm, D = 7.5 cm) on the camera sensor to form the light field projection operator outlined by Eq. (4). More compact setups could be realized using aberration-corrected optical elements. The monolithic entrance lens is not necessary and could be replaced by smaller elements resembling the curvature of corresponding pieces of a large lens (similar to fresnel lenses but with high imaging quality). This would remove the need for a large front lens and make the system more scalable for wider baselines. The baseline currently achieved is limited by the size of that entrance lens. However unlike the simple lenslet array our design does not suffer from dividing the sensor area and unlike previous single-sensor coded aperture it doesn’t have major aperture overlap between adjacent views. We emphasize that the proposed mathematical technique is more resilient w.r.t larger baselines than previous methods, as evaluated in Fig. 5.

The optical system resembles a macro light field photography system or a single lens imaging system (with L1-L2 compound lens) combined with a 4f system between the (LL1 and LL2) lenslets (Fig. 9). Depending on the required field of view, resolution of the mask, and the distance of the object to the lens (d
                              0) the rest of the geometry (d
                              1, d
                              2, d
                              3, d
                              4) can be aligned or predicted based on ray transfer matrix analysis. We experimentally aligned the system so that the plane of focus is also the parallax-free plane. Larger d
                              0 would form smaller images and force denser masks which would be ultimately limited by the diffraction limit and sensitivity of the camera. LL1 lenslets are flush to the L1 lens to allow the largest possible baseline. Stretching the LL1 array all the way to the peripheral of L1 can induce undesired relative aberration in the images on the side and thus some compensation elements would be required for aberration correction. The current prototype has f/7.5 and each view has approximately f/18. Unlike the case of coded aperture where adjacent views share the same aperture here the different lenslets have non-overlapping views but at the same time each view is imaged by the entire sensor. The total image intensity signal to noise is ultimately limited by aperture size for each lenslet, smaller lenslets would reduce the aperture size for each view and thus its signal intensity. This means scaling up the views would reduce the signal intensity per view for a constant entrance aperture. The signal level per pixel is, however, limited by the mask resolution, by increasing the mask resolution for a constant aperture size the light intensity is reduced as the illuminated area for each pixel is reduced. Finally, the larger entrance aperture also plays a role in amount of light and aberration that is induced into the system. Based on 50,800 dpi mask resolution, the mask has 500 nm features that is close to the diffraction limit. However, this is not a limitation for our system as we use 10 × 10 matrix for dithering. This indicates that each pixel has a 5 μm × 5 μm footprint that is far from diffraction limit. when the pixels are pushed below the diffraction limit color in consistency can appear for individual pixels due to diffraction. It must be mentioned while this can be a limiting barrier it might be manageable with further processing or time averaging. The system is extendable to larger baselines if the large entrance lens is replaced with prism pieces, however the main drawback is that a higher optical complexity is required compared to a conventional camera lens. More details on calibration and alignment of the system are provided in the supplement.

For the physical experiments, light fields with 2 × 2 views are reconstructed from a single sensor image with a resolution of 400 × 400 pixels. The resolution of the prototype is currently limited by the printed mask resolution re-imaged on the sensor, and the accuracy of the calibration. Reconstruction is performed independently for each light field patch and color channel using a sliding window reconstruction. The patch size is chosen to contain the maximum amount of observed parallax in the scene. We used window sizes of 20 × 20 pixels with a varying number of time frames, as indicated for a specific dataset. A single 4D or 5D light field patch is recovered for each window location. Overlapping patch reconstructions are averaged for the final result. Processing time is about 8 h for the sliding patch reconstructions on a computer with 4 nodes each with 4 cores at 2.2 GHz and 8 GB RAM. The rank threshold is set to 
                                 
                                    r
                                    =
                                    6
                                 
                               and the sparsity penalizing parameter is 
                                 
                                    λ
                                    =
                                    0.05
                                 
                              . The solver usually converges in average within 300 iterations.

@&#RESULTS@&#


                     Fig. 1
                      shows a light field comprising 81 views recovered with the proposed algorithmic framework. We simulate a coded sensor image by multiplying each view by a Gaussian random code and summing over the modulated images. A reconstruction can faithfully estimate the target light field from two captured images.

As explained in Section 5.3, the minimum number of measurements to perfectly recover light fields depends on the degree of freedom of the light field tensor which is a function of the number of views and the amount of parallax (rank). Therefore, for light fields with high number of views such as Fig. 1 (81 views), one cannot recover the static light fields with a single shot. However, when light fields video is captured the degree of freedom of light fields would be smaller than the static light fields since the correlation along the motion can also be exploited. Therefore, light fields video can be recovered from single measurement at each frame, given that the measurement mask is changing at each frame (see Fig. 7). Fig. 10
                      shows a static 2 × 2 light field similar to the prototype recovered from a single measurement using the proposed tensor low-rank and sparse model.

High-quality light field recovery from a single measurement is possible with the prototype configuration when the modulation codes introduce a high degree of randomness in the measurements. Fig. 11
                      demonstrates a set of scenes captured with the prototype compressive light field camera and reconstructed with the proposed low-rank and sparse light field recovery. Finally, we also show reconstructions of a light field video in Fig. 12
                     . For this experiment, we manually move the object for 7 frames of a 9-frame sequence. A five-dimensional tensor low-rank and sparse reconstruction benefits from the coherence in time and angle of the light fields to recover the views from coded measurements in time. The former benefit is available when the optical codes change for each captured frame. Observed reconstruction quality is best when the motion between frames is small, though for scenes with a large amount of motion one could employ motion estimation and compensation techniques, such as [31].

@&#DISCUSSION@&#

In this paper, we present a new approach to compressive light field photography. By combining tensor low-rank and sparse priors on the high-dimensional signal, we are able to efficiently model light field images and videos. We propose an efficient solver for the recovery problem and also a prototype device that allows for high-resolution light fields to be captured that have a wider baseline than previously-described single-device solutions.

The proposed compressive camera offers a higher resolution than conventional, microlens-based light field cameras. Yet, these come at the cost of increased significantly reconstruction times. Compared with learned light field dictionaries, the proposed framework does not require a learning phase and is therefore not bound to the capture parameters of the training scenes. This saves a significant amount of compute time and also makes the proposed framework more flexible and widely applicable. We believe that distributed compute infrastructures, such as cloud computing, have the potential to significantly reduce the reconstruction times.

Although the proposed framework is developed for light field videos with an arbitrary number of views and frames, the prototype we built is currently limited to four views and a few frames. The number of views is restricted by the size and cost of employed optical elements and the number of frames is limited by the fact that we record all animations in a stop-motion fashion by manually moving scene and mask while capturing coded light field projections. The prototype was designed only to experimentally verify the proposed framework. Optical aberrations and a low resolution of the printed masks place a limit on the resolution we currently achieve.

@&#FUTURE WORK@&#

We would like to speed up processing times using cloud computing and improve the quality of the prototype design. Chromatic aberrations can be reduced using compound lens systems. Higher-resolution and dynamic spatial light modulators, instead of printed masks, will significantly improve image resolution and automate the capture process. Instead of using a single large imaging lens in the prototype, we would like to experiment with custom elements that do not require a monolithic lens but instead are a collection of independent compound lenses. Finally, we would like to further increase the baseline of the prototype and add more cameras to the array. The proposed mathematical framework also has applications in reducing the number of devices in camera arrays. We evaluate this application extensively in the supplement using simulations. Finally, we would like to incorporate the color spectrum, polarization, and other properties of light into our framework. Although a few approaches have been proposed to use related techniques for multi-spectral and lighting-dependent reflectance acquisition [50], a comprehensive and unified framework for compressive plenoptic or reflectance acquisition would be very interesting.

@&#CONCLUSION@&#

Analyzing and exploiting redundancies of high-dimensional visual signals is the key to future camera designs. The proposed algorithmic framework is a step towards a new generation of computational imaging systems that follow this paradigm. System designs at the intersection of optics and compressive computation, such as the proposed, facilitates higher resolutions, lower cost, new form factors, wider baselines, and many other benefits for computational photography.

Recall that the CP decomposition of an order-3 tensor 
                        R
                      is

                        
                           (A.1)
                           
                              
                                 
                                    
                                       
                                          R
                                          =
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             r
                                          
                                          
                                             u
                                             i
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          ∘
                                          
                                             u
                                             
                                                i
                                             
                                             
                                                (
                                                ν
                                                )
                                             
                                          
                                          ∘
                                          
                                             u
                                             
                                                i
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where r is the rank of 
                        R
                      and vectors 
                        
                           
                              u
                              i
                              
                                 (
                                 x
                                 )
                              
                           
                           ∈
                           
                              R
                              n
                           
                           ,
                           
                           
                              u
                              
                                 i
                              
                              
                                 (
                                 ν
                                 )
                              
                           
                           ∈
                           
                              R
                              m
                           
                           ,
                        
                     
                     
                        
                           
                              u
                              
                                 i
                              
                              
                                 (
                                 t
                                 )
                              
                           
                           ∈
                           
                              R
                              p
                           
                        
                      for 
                        
                           k
                           =
                           1
                           ,
                           …
                           ,
                           r
                        
                     . The factor matrices are defined as the concatenation of rank-1 vectors: 
                        
                           
                              U
                              
                                 (
                                 x
                                 ,
                                 ν
                                 ,
                                 t
                                 )
                              
                           
                           =
                           
                              [
                              
                                 u
                                 1
                                 
                                    (
                                    x
                                    ,
                                    ν
                                    ,
                                    t
                                    )
                                 
                              
                              ,
                              
                                 u
                                 2
                                 
                                    (
                                    x
                                    ,
                                    ν
                                    ,
                                    t
                                    )
                                 
                              
                              ,
                              …
                              ,
                              
                                 u
                                 r
                                 
                                    (
                                    x
                                    ,
                                    ν
                                    ,
                                    t
                                    )
                                 
                              
                              ]
                           
                        
                     . Unfolding 
                        R
                      can be defined using the factor matrices, for instance along the spatial mode x as

                        
                           (A.2)
                           
                              
                                 
                                    
                                       
                                          
                                             R
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          =
                                          
                                             U
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          
                                             
                                                (
                                                
                                                   U
                                                   
                                                      (
                                                      t
                                                      )
                                                   
                                                
                                                ⊙
                                                
                                                   U
                                                   
                                                      (
                                                      ν
                                                      )
                                                   
                                                
                                                )
                                             
                                             ⊺
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where ⊙ denotes the Khatri–Rao product [61]. The ALS algorithm decomposes 
                        R
                      into r components as

                        
                           (A.3)
                           
                              
                                 
                                    
                                       
                                          arg
                                          
                                             min
                                             
                                                
                                                
                                                
                                                
                                                
                                                
                                                
                                                   R
                                                   ^
                                                
                                             
                                          
                                          
                                             
                                                ∥
                                                R
                                                −
                                                
                                                   R
                                                   ^
                                                
                                                ∥
                                             
                                             2
                                          
                                          
                                          with
                                          
                                          
                                             R
                                             ^
                                          
                                          =
                                          
                                             ∑
                                             
                                                i
                                                =
                                                1
                                             
                                             r
                                          
                                          
                                             u
                                             i
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          ∘
                                          
                                             u
                                             
                                                i
                                             
                                             
                                                (
                                                ν
                                                )
                                             
                                          
                                          ∘
                                          
                                             u
                                             
                                                i
                                             
                                             
                                                (
                                                t
                                                )
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where the tensor ℓ2-norm is the sum of squared elements, for instance 
                        
                           
                              
                                 ∥
                                 X
                                 ∥
                              
                              2
                              2
                           
                           =
                           
                              ∑
                              
                                 i
                                 j
                                 k
                              
                           
                           
                              x
                              
                                 i
                                 j
                                 k
                              
                              2
                           
                        
                      for an order-3 tensor. ALS alternates between updating one factor matrix while fixing the others, for all matrices U
                     (x, ν, t). This is repeated until convergence. Tensor unfolding is employed to calculate the CP decomposition (Eq. (A.2)). For instance, U
                     (x) is computed as

                        
                           (A.4)
                           
                              
                                 arg
                                 
                                    min
                                    
                                       
                                       
                                       
                                       
                                       
                                       
                                          U
                                          
                                             (
                                             x
                                             )
                                          
                                       
                                    
                                 
                                 
                                    
                                       ∥
                                       
                                          R
                                          
                                             (
                                             x
                                             )
                                          
                                       
                                       −
                                       
                                          U
                                          
                                             (
                                             x
                                             )
                                          
                                       
                                       
                                          
                                             (
                                             
                                                U
                                                
                                                   (
                                                   t
                                                   )
                                                
                                             
                                             ⊙
                                             
                                                U
                                                
                                                   (
                                                   ν
                                                   )
                                                
                                             
                                             )
                                          
                                          ⊺
                                       
                                       ∥
                                    
                                    2
                                 
                                 ,
                              
                           
                        
                     which simplifies to

                        
                           (A.5)
                           
                              
                                 
                                    
                                       
                                          
                                             U
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          =
                                          
                                             R
                                             
                                                (
                                                x
                                                )
                                             
                                          
                                          
                                             (
                                             
                                                U
                                                
                                                   (
                                                   t
                                                   )
                                                
                                             
                                             ⊙
                                             
                                                U
                                                
                                                   (
                                                   ν
                                                   )
                                                
                                             
                                             )
                                          
                                          
                                             (
                                             
                                                U
                                                
                                                   
                                                      (
                                                      t
                                                      )
                                                   
                                                   ⊺
                                                
                                             
                                             
                                                U
                                                
                                                   (
                                                   t
                                                   )
                                                
                                             
                                             *
                                             
                                                U
                                                
                                                   
                                                      (
                                                      ν
                                                      )
                                                   
                                                   ⊺
                                                
                                             
                                             
                                                U
                                                
                                                   (
                                                   ν
                                                   )
                                                
                                             
                                             )
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        
                     where * is the element-wise product.

Supplementary material associated with this article can be found, in the online version, at 10.1016/j.cviu.2015.11.004 .


                     
                        
                           Supplementary Data S1
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  


                     
                        
                           Supplementary Data S2
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  


                     
                        
                           Supplementary Data S3
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  


                     
                        
                           Supplementary Data S4
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  


                     
                        
                           Supplementary Data S5
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  


                     
                        
                           Supplementary Data S6
                           
                              Supplementary Raw Research Data. This is open data under the CC BY license http://creativecommons.org/licenses/by/4.0/
                              
                           
                           
                        
                     
                  

@&#REFERENCES@&#


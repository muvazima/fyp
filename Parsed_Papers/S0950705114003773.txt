@&#MAIN-TITLE@&#The effect of feature selection on financial distress prediction

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Filter and wrapper based feature selection are employed for financial distress prediction.


                        
                        
                           
                           In addition, two bankruptcy prediction datasets and two credit scoring datasets are used.


                        
                        
                           
                           On average, GA and LR perform better over the credit and bankruptcy datasets respectively.


                        
                        
                           
                           However, there is no exact winner over the four datasets.


                        
                        
                           
                           In addition, performing feature selection does not always improve the models’ performance.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Financial distress prediction

Bankruptcy prediction

Credit scoring

Feature selection

Data mining

@&#ABSTRACT@&#


               
               
                  Financial distress prediction is always important for financial institutions in order for them to assess the financial health of enterprises and individuals. Bankruptcy prediction and credit scoring are two important issues in financial distress prediction where various statistical and machine learning techniques have been employed to develop financial prediction models. Since there are no generally agreed upon financial ratios as input features for model development, many studies consider feature selection as a pre-processing step in data mining before constructing the models. However, most works only focused on applying specific feature selection methods over either bankruptcy prediction or credit scoring problem domains. In this work, a comprehensive study is conducted to examine the effect of performing filter and wrapper based feature selection methods on financial distress prediction. In addition, the effect of feature selection on the prediction models obtained using various classification techniques is also investigated. In the experiments, two bankruptcy and two credit datasets are used. In addition, three filter and two wrapper based feature selection methods combined with six different prediction models are studied. Our experimental results show that there is no the best combination of the feature selection method and the classification technique over the four datasets. Moreover, depending on the chosen techniques, performing feature selection does not always improve the prediction performance. However, on average performing the genetic algorithm and logistic regression for feature selection can provide prediction improvements over the credit and bankruptcy datasets respectively.
               
            

@&#INTRODUCTION@&#

Financial distress prediction is very critical in enterprise risk management, especially for financial institutions. In particular, financial institutions have to develop various risk management models, such as bankruptcy prediction and credit scoring models [37,43]. For bankruptcy prediction, financial institutions need effective prediction models in order to make appropriate lending decisions. On the other hand, credit scoring models are used for the management of large loan portfolios and/or credit admission evaluation.

Specifically, bankruptcy prediction and credit scoring are two binary classification problems in financial distress prediction, which aim at assigning new observations to two pre-defined decision classes (e.g., ‘good’ and ‘bad’ risk classes) [40]. For example, bankruptcy prediction models are used to predict the likelihood that the loan customers will go bankrupt whereas credit scoring models are used to determine whether the loan applicants should be classified into a high risk or low risk group. In the literature, many supervised machine learning (or classification) techniques have been used for financial distress prediction [2,10,24,29].

Though many novel sophisticated techniques have been proposed for effective prediction, very few have examined the effect of feature selection on financial distress prediction. Feature selection is an important data pre-processing step of knowledge discovery in databases (KDD). The aim is to filter out unrepresentative features from a given dataset [11,17]. As there are no generally agreed financial ratios for bankruptcy prediction and credit scoring, collected variables must be examined for their representativeness, i.e., importance and explanatory power, in the chosen dataset [29]. Therefore, the performance of classifiers after performing feature selection could be enhanced over that of classifiers without feature selection.

Generally speaking, feature selection can be broadly divided into the filter, wrapper, and hybrid approaches [3,31]. The filter based method (usually based on some statistical techniques) evaluates and selects feature subsets by the general characteristics of the given dataset. The wrapper based method is based on a pre-determined mining algorithm and its performance is used as the evaluation criterion to select feature subsets. Specifically, it aims at searching for features that are better suited to the mining algorithm to improve the mining performance. The hybrid method is based on combining these two methods by exploiting different evaluation criteria in different search stages.

In recent studies, the filter and wrapper based feature selection methods have been widely used for bankruptcy prediction [41,13,14,27,25,26,8,4] and credit scoring [18,7,30,16,42,5]. Most studies apply either filter or wrapper based methods for single domain problems, i.e., bankruptcy prediction and credit scoring. One reason for the lack of using hybrid based feature selection methods is because currently there is no standard and representative method. In addition, there are no guidelines for which filter and wrapper based methods should be combined to select the best features for the later prediction performance.

One major limitation of current studies is that each work only considers one specific feature selection method for either bankruptcy prediction or credit scoring problems. In other words, there is no study focusing on comparing both types of feature selection methods for both bankruptcy prediction and credit scoring problems (c.f. Section 2.2). Therefore, the aim of this paper is to examine the effect of the filter and wrapper based feature selection methods on both bankruptcy prediction and credit scoring problems. Moreover, the effect of performing feature selection on different classification techniques will also be investigated.

The contributions of this paper are twofold. First, we provide a comprehensive study of comparing different filter and wrapper based feature selection methods in terms of two financial distress problems, which are bankruptcy prediction and credit scoring. In particular, the most suitable methods for these two specific problems are identified. As a result, the identified methods can also be regarded as the baseline feature selection methods for future related researches. Second, the research findings also allow us to understand which classification technique(s) are more sensitive to feature selection. Therefore, this can provide a guideline for future studies to choose suitable techniques for their prediction models.

The rest of this paper is organized as follows. Section 2 overviews related literature about filter and wrapper based feature selection methods. Moreover, related works are compared in terms of the feature selection methods employed, prediction methods constructed, etc. Sections 3 and 4 present the experimental setup and results, respectively. Finally, Section 5 concludes the paper.

@&#LITERATURE REVIEW@&#

As there are no generally agreed factors (i.e., variables) for bankruptcy prediction and credit scoring, some of the collected variables as features may contain noise that could affect the prediction result. On the other hand, if too many features were used for data analysis, it can cause high dimensionality problems [36]. In data mining, feature selection or dimensionality reduction can be approached to reduce irrelevant or redundant features. This is an important data pre-processing technique in data mining, which aims at selecting more representative features having more discriminatory power over a given dataset [11,17].

Feature selection can be defined as the process of choosing a minimum subset of m features from the original dataset of n features (m
                        <
                        n), so that the feature space (i.e. the dimensionality) is optimally reduced according to four steps, which are subset generation, subset evaluation, stopping criteria, and result validation [11,31].

In general, subset generation is a search procedure which generates subsets of features for evaluation. Each subset generated is evaluated by a specific evaluation criterion and compared with the previous best one with respect to this criterion. If a new subset is found to be better, then the previous best subset is replaced by the new subset.

The filter based feature selection methods usually contain the following procedures. Given a dataset, the method based on a particular search strategy initially searches from a given subset, which may be an empty set, a full set, or any randomly selected subset. Then, each generated subset is evaluated by a specific measure and compared with the previous best one. This search process iterates until the pre-defined stopping criterion is met. Consequently, the final output of this method is the last current best subset.

More specifically, the search strategy and evaluation measure can be different depending on the algorithms used. In addition, filter based methods do not involve any mining algorithm during the search and evaluation steps, they are computationally efficient. Some examples of filter based methods that are used in financial distress prediction are based on statistical techniques, such as t-testing, principal component analysis, discriminant analysis, and regression [4,8,37,26,41,45].

Linear Discriminant analysis (LDA) is used to find a linear combination of features which characterizes or separates two or more classes of objects. The resulting combination can be used for dimensionality reduction. LDA can also be used to express one dependent variable as a linear combination of other features. In other words, LDA looks for the linear combination of features which best explains the given data [34].

LDA involves the determination of a linear equation like regression that will predict which group the case belongs to. The form of the equation or function is
                              
                                 (1)
                                 
                                    D
                                    =
                                    
                                       
                                          v
                                       
                                       
                                          1
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          1
                                       
                                    
                                    +
                                    
                                       
                                          v
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    
                                       
                                          v
                                       
                                       
                                          3
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          3
                                       
                                    
                                    +
                                    ⋯
                                    
                                       
                                          v
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          X
                                       
                                       
                                          i
                                       
                                    
                                    +
                                    a
                                 
                              
                           where D is the discriminant function, v is the discriminant coefficient or weight for that feature, X is the respondent’s score for that feature, a is a constant, and i is the number of predictor features.

The t-test method is used to determine whether there is a significant difference between two group’s means. It helps to answer the underlying question: Do the two groups come from the same population, and only appear differently because of chance errors, or is there some significant difference between these two groups? Three basic factors help determine whether an apparent difference between two groups is a true difference or just an error due to chance [35]:
                              
                                 1.
                                 The larger the sample, the less likely that the difference is due to sampling errors or chance.

The larger the difference between the two means, the less likely that the difference is due to sampling errors.

The smaller the variance among the participants, the less likely that the difference is created by sampling errors.

Logistic regression (LR) is a type of probabilistic statistical classification model. LR measures the relationship between a categorical dependent variable and one or more independent variables, which are usually continuous, by using probability scores as the predicted values of the dependent variables. LR allows us to look at the fit of the model as well as at the significance of the relationships between dependent and independent variables that are modeled [19].

The LR function can be written as
                              
                                 (2)
                                 
                                    P
                                    =
                                    
                                       
                                          
                                             
                                                e
                                             
                                             
                                                α
                                                +
                                                β
                                                x
                                             
                                          
                                       
                                       
                                          1
                                          +
                                          
                                             
                                                e
                                             
                                             
                                                α
                                                +
                                                β
                                                x
                                             
                                          
                                       
                                    
                                 
                              
                           where P is the probability of a 1, e is the base of the natural logarithm and α and β are the parameters of the model.

The wrapper based feature selection methods are similar to the filter based ones except that a pre-defined mining algorithm is utilized for the search strategy and evaluation measure. That is, for each generated subset, the mining algorithm is used to evaluate the goodness of the selected subset in terms of the quality of mined results. Therefore, using different mining algorithms will produce different feature selection results over the same dataset.

Since the mining algorithms are used to select and evaluate the feature subsets, the wrapper based methods are likely to perform better than the filter based methods [20]. However, it is usually more computationally expensive than the filter based methods. Some examples of wrapper based methods used in financial distress prediction are the Bayesian classifier, particle swarm optimization, rough set, and genetic algorithm methods [14,33,30,42].

Genetic algorithms (GA) have become an effective feature selection approach to improve the performance of data mining algorithms. In GA, a population of strings (called chromosomes), which encode candidate solutions (called individuals) to an optimization problem, evolves for better solutions. In general, the genetic information (i.e., chromosome) is represented by a bit string (such as binary strings of 0s and 1s) and sets of bits encode the solution. Then, genetic operators are applied to the individuals of the population for the next generation (i.e., a new population of individuals). There are two main genetic operators, which are crossover and mutation. Crossover creates two offspring strings from two parent strings copying selected bits from each parent. On the other hand, mutation randomly changes the value of a single bit (with small probability) to the bit strings. Furthermore, a fitness function is used to measure the quality of an individual in order to increase the probability that the single bit can survive throughout the evolutionary process [15].

Particle swarm optimization (PSO) is also a type of evolutionary algorithm. It optimizes a problem by looking at a population of particles (i.e., candidate solutions). The particles are moved around in the search space according to a mathematical formula considering the particle’s position and velocity. As a result, it is expected that the swarm will move toward the best solutions [22].

Specifically, both GA and PSO share the following common elements:
                              
                                 •
                                 Both initialize a population in a similar manner.

Both use an evaluation function to determine how fit (good) a potential solution is.

Both are generational, that is both repeat the same set of processes for a predetermined amount of time.

PSO has two primary operators, which are velocity update and position update. During each generation each particle is accelerated toward its previous best position and the global best position. In each iteration, a new velocity value for each particle is calculated based on its current velocity, the distance from its previous best position, and the distance from the global best position. The new velocity value is then used to calculate the next position of the particle in the search space. This process continues until a minimum error is achieved.


                        Table 1
                         compares related works from the past five years (2009–2013) in terms of the feature selection methods employed, prediction methods constructed, and domain datasets used. Note that the number for the filter and wrapper based methods means the number of methods used in their corresponding works. According to Table 1, we can observe that most studies performing feature selection only consider one specific type of method. In addition, many works only focus on one specific domain problem, i.e., either bankruptcy prediction or credit scoring.

To be specific, wrapper based methods are applied for bankruptcy prediction in three studies and filter based methods in seven studies. On the other hand, wrapper based methods are used for credit scoring in four studies and filter based methods are applied in three studies.

Consequently, this literature review raises two research questions. The first one is: which type of feature selection method is suitable for which problem domain? Second, is there any best combination for combining specific types of feature selection methods and specific classification techniques for bankruptcy prediction and credit scoring? The following experiments are conducted to answer these two questions.

@&#EXPERIMENTAL DESIGN@&#


                        Table 2
                         shows the information for the four chosen datasets utilized in this study. The Australian and German datasets are public sets widely used in the literature. The Taiwanese and Chinese datasets were collected from the Taiwan Economic Journal
                           1
                           
                              http://www.tej.com.tw/twsite/.
                        
                        
                           1
                         and the definitions of bankrupt companies are based on the business regulations from the Taiwan Stock Exchange and Shanghai and Shenzhen Stock Exchange, respectively.

Since the Chinese and Taiwanese bankruptcies are real-world datasets, in practice they contain very few bankrupt cases whereas the numbers of non-bankrupt cases are very large. This makes the class imbalance problem of the collected datasets, which is likely to degrade the final prediction performance. Therefore, the method of stratified sampling [1] is used to collect the same numbers of good and bad cases. Moreover, each of the attributes is normalized into the range from 0 to 1. For training and testing each classifier, the 10-fold cross-validation strategy is used to divide each dataset into 10 distinct training and testing subsets.

From the relevant studies reviewed in Section 2, three widely used filter based feature selection methods are chosen for comparison, namely, linear discriminant analysis (LDA), t-test, logistic regression (LR).


                           Fig. 1
                            outlines the process of performing filter based feature selection for financial distress prediction. The first step is to divide each dataset into the training and testing sets by 10-fold cross validation. Then, each feature selection method is executed over the training set. Next, the selected features are used as the new training set (not the original training set) to train a prediction model. Finally, the testing set containing the same selected features as the new training set is used to test the performance of the prediction model.

Note that the threshold to determine representative features by the filter based feature selection methods is based on the feature, which is significant at the 0.05 level. For example, using the t-test method the features having the p values less than 0.05 are kept; otherwise they are filtered out.

Two representative methods are used for wrapper based feature selection in this paper, which are genetic algorithm (GA) and particle swarm optimization (PSO).


                           Fig. 2
                            shows the process of performing wrapper based feature selection for financial distress prediction. First, each dataset is divided into the training and testing sets by 10-fold cross validation. Each training set is further sampled for the training and validation subsets to train the wrapper based feature selection methods. Then, the population pool is initialized where each group of the chromosome or particle represents the selected feature set. Next, each chromosome or particle in the population pool (as the training subset) is used to construct multiple models. After the models are constructed, the validation subset is used to test their accuracy. For GA, the performance of the models constructed by each chromosome is examined, and then the selection, crossover, mutation operations are performed to replace the current population pool. On the other hand, each particle of PSO is examined for its performance and its position and velocity in the feature space are adjusted by the sigmoid function to replace the current population pool. Consequently, the evolutionary process will be terminated until the stopping criterion is met. Then, the chromosome or particle having the highest accuracy over the validation subset is used as the training set to train the prediction model. Finally, the testing set containing the same selected features as the chromosome or particle is used to test the performance of the prediction model.


                           Table 3
                            lists related parameters of GA and PSO, which are based on some related works, such as Srinivas and Patnaik [38], Ko and Lin [23], Lin et al. [28], and Liu et al. [32]. Note that different values of the population size and swarm size (20–500), crossover rate (0.4–1.0), mutation rate (0.001–0.1), and generations (100–5000) were compared in order to find out the best parameter values.

For classifier design, six classification techniques are used, namely, linear SVM, RBF SVM, k-NN, Naïve Bayes, CART, and MLP. These were identified as the most popular and widely used classification techniques by Wu et al. [44]. Table 4
                         lists the parameters for constructing these classifiers for comparison.

To assess the performance of the above mentioned classifiers (i.e., prediction models), two evaluation metrics are used, which are prediction accuracy and the Type I error. They can be measured by a confusion matrix, as shown in Table 5
                        .

Therefore, the average prediction accuracy is obtained by
                           
                              (3)
                              
                                 Prediction accuracy
                                 =
                                 
                                    
                                       a
                                       +
                                       d
                                    
                                    
                                       a
                                       +
                                       b
                                       +
                                       c
                                       +
                                       d
                                    
                                 
                              
                           
                        and the Type I error is based on
                           
                              (4)
                              
                                 Type I error
                                 =
                                 
                                    
                                       b
                                    
                                    
                                       b
                                       +
                                       d
                                    
                                 
                              
                           
                        
                     

In addition to the average accuracy, Type I error is taken into account. This occurs when the classifier incorrectly classifies a bankrupt firm (or member of the high risk group) into the non-bankrupt class (or the low risk group). This is also critical because a higher Type I error rate requires financial institutions to expend larger costs, which can enhance the enterprise risk.

@&#RESULTS@&#


                        Tables 6 and 7
                        
                         show the performances of different classifiers over the Australian and German credit datasets, respectively. Note that the baseline means the classifier without feature selection. In addition, the bold numbers indicate performances that significantly outperform the other classifiers (indicated by non-bold numbers). The level of performance significance is measured by the Wilcoxon test [12]. Furthermore, the highest rate of classification accuracy and the lowest rate of the Type I error are underlined.

The results show that filter based feature selection methods generally perform better than wrapper based ones. In particular, the LDA and t-test perform the best over the Australian and German datasets, respectively.

On the other hand, on average, for the Australian dataset, performing feature selection makes the classifiers outperform the ones without feature selection in terms of the prediction accuracy and the Type I error. This is different from the German dataset, in that only performing a t-test can allow the classifiers to provide better performance than the baselines. These results are consistent with Tsai [41], who compared five filter based feature selection methods and found the t-test to be the optimal feature selection method.


                        Tables 8 and 9
                        
                         show the performances of different classifiers over the China and Taiwan bankruptcy datasets, respectively. The results are interesting in that, on average, performing feature selection makes the classifiers outperform the baselines in terms of prediction accuracy. However, the classifiers followed by feature selection do not necessarily mean that they can provide lower Type I errors than the baselines.

On the other hand, the GA based feature selection method can make CART and linear SVM provide the highest rate of prediction accuracy over the China and Taiwan datasets respectively. For the Type I error, LDA and GA perform the best over the China and Taiwan datasets, respectively. These results are somewhat similar to Hua et al.’s [20] conclusion that wrapper based methods could be superior to filter based methods over high dimensional datasets.

@&#DISCUSSION@&#

Based on the above results, the effect of performing feature selection on classification techniques is discussed below.
                              
                                 •
                                 Linear SVM: Linear SVM combined with feature selection does not perform significantly better than baseline linear SVM over the four datasets. This may be because some weights are assigned to the input features when constructing the linear SVM classifier. In other words, important features can be identified and have higher weights assigned. Therefore, executing feature selection may not be necessary.

RBF SVM: In most cases, there is no significant difference between combining feature selection with RBF SVM and the baseline method. However, for the Australian dataset RBF SVM combined with filter based feature selection methods perform significantly better than the baseline method. This implies that the chosen dataset may have a positive impact on the performance of RBF SVM after performing feature selection.

CART: For the four datasets, CART combined with feature selection does not provide significantly better accuracy or Type I error than the baseline method. This may be because the feature selection step is already employed during the construction of the CART classifier. Therefore, similar to linear SVM, feature selection may not help CART for the performance improvement.


                                    k-NN: The k-NN classifier combined with feature selection performs significantly better than the baseline k-NN for prediction accuracy and the Type I error over the four datasets. Particularly, using k-NN with the filter based feature selection methods can provide better performance than with the wrapper based feature selection methods. Since k-NN does not include pre-processing of the input features (like linear SVM and CART) and the final output of using k-NN is based on the distances in the feature space between the training data samples and the testing ones, performing feature selection first can have a positive impact on the k-NN performance.

Naïve Bayes: The naïve Bayes classifier combined with feature selection can significantly outperform the baseline method in most cases. The only exception is using the filter based feature selection methods over the Australian dataset. Specifically, using the wrapper based methods allows the naïve Bayes classifier to provide better performance than using the filter based methods. Similar to k-NN, performing feature selection can positively impact the naïve Bayes performance. This finding is consistent with related works, such as Chen et al. [6], that the naïve Bayes classifier is highly sensitive to feature selection.

MLP: Combining feature selection with MLP can provide significantly better performance than the baseline MLP over three datasets, with the exception of the German dataset. In particular, using filter based methods make MLP perform better than wrapper based methods. Therefore, performing feature selection improves the performance of MLP. Despite different weights being assigned to the input features during the construction of MLP, overfitting can occur during the classifier training stage. As a result, performing feature selection can reduce the risk of overfitting and thus improve the final accuracy [39].

The best combinations for combining the feature selection methods and classification techniques over the four datasets are discussed below.
                              
                                 •
                                 Australian dataset: Looking at both prediction accuracy and Type I error, there are several better combinations that do not have a significant level of difference in performance, which are t-test+
                                    k-NN, GA+naïve Bayes, PSO+naïve Bayes, t-test+RBF SVM, GA+MLP, and LDA+
                                    k-NN. Among them, GA+naïve Bayes and PSO+naïve Bayes provide the highest rate of prediction accuracy and the lowest Type I error rate respectively. In particular, GA+naïve Bayes performs the third best for the Type I error. Therefore, the optimal combination could be GA+naïve Bayes.

German dataset: In this dataset, the baseline linear SVM and RBF SVM classifiers without feature selection perform the best in terms of prediction accuracy and the Type I error respectively. In addition, the baseline RBF SVM performs the second best in terms of prediction accuracy. Therefore, these indicate that performing feature selection is likely to degrade the models’ performances over this dataset, especially for SVM. However, to compare all of the combinations t-test+linear SVM and t-test+RBF SVM outperform the others for prediction accuracy and the Type I error respectively.

China dataset: In this dataset, the baseline CART and t-test+CART provide the same prediction accuracy and Type I error, which outperform the other models. On the other hand, LDA+linear SVM provide the lowest Type I error rate, whereas the baseline CART and t-test+CART perform the second best. These indicate that performing feature selection is not necessary in this dataset. Particularly, the baseline CART is a more suitable model for this dataset.

Taiwan dataset: LR+
                                    k-NN and the baseline RBF SVM perform the best in terms of prediction accuracy where they perform the same. On the other hand, the baseline RBF SVM provides the lowest Type I error rate. Specifically, LR+
                                    k-NN and GA+RBF SVM outperform the other combinations in terms of prediction accuracy and Type I errors respectively.

In summary, there is no exact answer for the best combination of the feature selection method and the classification technique over the four datasets. However, if we compare the average prediction results (including average prediction accuracy and the Type I error) by each feature selection method and the baseline models, we can see that the models’ performances can be improved if the feature selection method was carefully chosen. Particularly, the better feature selection methods for credit scoring and bankruptcy prediction are GA and LR respectively (c.f. Tables 6–9).

Although it is difficult to conclude the best feature selection for the financial distress prediction problems, several feature selection methods that can provide relatively better performances can be recommended for future researches. That is, better filter and wrapper feature selection methods are t-test, LR, and GA.

Finally, the prediction improvements by performing filter based feature selection over the credit scoring datasets containing small numbers of attributes (i.e. 14 and 24) are small. That is, on average the prediction improvements by using filter based feature selection is only about 0.17–0.67% and 0.08–0.66% over the Australian and German datasets respectively. These may be within the standard deviation of the prediction accuracy obtained from 10-fold cross validation. On the other hand, performing GA can provide about 3.09% and 0.66% prediction improvements over the Australian and German datasets respectively. These results demonstrate the importance of choosing a suitable feature selection for credit scoring and bankruptcy prediction.

@&#CONCLUSION@&#

In this paper, we examine the effect of feature selection in financial distress prediction. Specifically, filter and wrapper based feature selection methods are compared in terms of prediction accuracy and the Type I errors made by six different classifiers.

We found that there is no the best combination of the feature selection method and the classification technique over the four datasets. However, on average GA performs better than the others over the credit scoring datasets whereas LR outperforms the other methods over the bankruptcy prediction datasets. Despite these findings, several feature selection methods have shown some promising results for bankruptcy prediction and credit scoring. In particular, t-test and LR as the filter methods and GA as the wrapper method can be used in the future.

It should be noted that performing feature selection does not always improve the models’ performances, especially for CART and SVM. This may be because when constructing these models, CART can determine important features like many feature selection methods do during the tree construction process whereas SVM generally assigns some weights to the input features (i.e. attributes). Moreover, since related studies, e.g. Clarke et al. [9], have shown the advantage of SVM for high dimensional data, the dimensionalities of financial distress datasets are relatively small compared with other domains, such as genomic and proteomic problems. Therefore, the need of performing the feature selection step for credit scoring and bankruptcy prediction depends on the chosen classifiers.

For future works, several issues could also be considered. First of all, since the chosen filter and wrapper based feature selection methods are based on the mostly used methods in bankruptcy prediction and credit scoring, other filter (e.g. information gain) and wrapper (e.g. naïve Bayes) methods can also be employed for the feature selection task. Secondly, in addition to using single classification techniques to develop the prediction models, combining multiple classifiers or classifier ensembles by the bagging and boosting combination methods can be developed for further comparison.

@&#REFERENCES@&#


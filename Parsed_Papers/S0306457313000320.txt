@&#MAIN-TITLE@&#A scalable privacy-preserving recommendation scheme via bisecting k-means clustering

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel bisecting k-means clustering-based privacy-preserving CF scheme is proposed.


                        
                        
                           
                           A two-level preprocessing scheme is suggested to enhance scalability and accuracy.


                        
                        
                           
                           Effects of scalability and sparseness challenges are alleviated considerably.


                        
                        
                           
                           Accuracy of the solution is significantly better than knn-based CF and PPCF methods.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Accuracy

Binary decision diagrams

Clustering methods

Data preprocessing

Data privacy

Recommender systems

@&#ABSTRACT@&#


               
               
                  Privacy-preserving collaborative filtering is an emerging web-adaptation tool to cope with information overload problem without jeopardizing individuals’ privacy. However, collaborative filtering with privacy schemes commonly suffer from scalability and sparseness as the content in the domain proliferates. Moreover, applying privacy measures causes a distortion in collected data, which in turn defects accuracy of such systems. In this work, we propose a novel privacy-preserving collaborative filtering scheme based on bisecting k-means clustering in which we apply two preprocessing methods. The first preprocessing scheme deals with scalability problem by constructing a binary decision tree through a bisecting k-means clustering approach while the second produces clones of users by inserting pseudo-self-predictions into original user profiles to boost accuracy of scalability-enhanced structure. Sparse nature of collections are handled by transforming ratings into item features-based profiles. After analyzing our scheme with respect to privacy and supplementary costs, we perform experiments on benchmark data sets to evaluate it in terms of accuracy and online performance. Our empirical outcomes verify that combined effects of the proposed preprocessing schemes relieve scalability and augment accuracy significantly.
               
            

@&#INTRODUCTION@&#

From the beginning of the Industrial Age, lives of people have been constantly changing into fast-paced living styles by mechanical, electronic, and eventually software-based innovations. While modernization relaxes people as access to information gets easier, much more information appears to be needed to handle, called information overload problem, which in turn confuses people’s mind creating anxiety. Collaborative filtering (CF) algorithms emerge at such complicated circumstances by simplifying access to useful information (Shardanand & Maes, 1995).

CF filters out irrelevant content and/or ranks items to be evaluated on other like-minded users’ preferences. Relying on the assumption that users having similar experiences on past items are tend to agree on new items, CF systems primarily attempt to predict a newbie’s ratings for available products operating on the collection of previous users’ rating information. Studies of researchers on CF show its success (Chen, Wang, & Zhang, 2009; Symeonidis, Nanopoulos, Papadopoulos, & Manolopoulos, 2008). There are also real-life deployments adopting this technique such as Amazon.com and Last.fm (Linden, Smith, & York, 2003; Symeonidis et al., 2008) and recently Cechinel, Sicilia, Snchez-Alonso, and Garca-Barriocanal (2013) proposed applying memory-based approaches for discovering specific context in learning object repositories.

It has been a risky time to continue blithely using the Internet services with little regard for how personal data are treated. As e-commerce facilities advance, commercial competition among online companies causes privacy violations. Recently, Federal Trade Commission draws attention to privacy violations and thrilling increases in usage of mobile applications in a report titled “Mobile Apps for Kids: Current Privacy Disclosures are Disappointing”. Similar confidentiality issues can arise during online shopping such as price discrimination, profiling, or being subject to surveillance (Ackerman, Cranor, & Reagle, 1999; Cranor, 2003; Jensen, Potts, & Jensen, 2005). In terms of CF, implicit preferences and list of rated products are considered private. Due to such risks, customers either refrain from using those systems or worse, submit non-authentic data. However, accurate recommendations cannot be estimated on poor quality data, which gives escalation to research on privacy-preserving collaborative filtering (PPCF) to produce accurate predictions without violating individuals’ confidentiality (Ameur, Brassard, Fernandez, & Mani Onana, 2008; Canny, 2002a; Polat & Du, 2005).

Providing privacy measures within CF applications help them being more preferable; however, inevitable costs and difficulties emerge concerning the deployment of PPCF systems (Acilar & Arslan, 2009; Bilge & Polat, 2012b). Due to continually enlarging structure of the Internet, number of users and/or items tend to be quite large in online shopping databases (often in terms of millions) (Chen et al., 2009). Consequently, calculating similarities among users requires unreasonably large amount of computations causing scalability problems (Zhang & Chang, 2006). Another problem arises with the increase in number of ratable products. Similarity between any two users can only be calculated over co-rated items. Since users are generally able to rate a very small fraction of all products, user-item matrices are typically highly sparse (Bilge & Polat, 2012b). Hence, it gets more unlikely to find co-rated items between users affecting accuracy and coverage adversely.

Mainly, research on CF and PPCF can be classified into three categories according to the method they are based on, i.e., (i) memory-based, (ii) model-based, and (iii) hybrid approaches (Al-Shamri & Bharadwaj, 2008; Breese, Heckerman, & Kadie, 1998; Herlocker, Konstan, Terveen, & Riedl, 2004). Moreover, such approaches might take content into account. Memory-based algorithms typically operate on the entire data to produce recommendations. Model-based schemes, on the other hand, operate on a prototype derived from the original user-item matrix. However, although models are helpful in practice, it is relatively hard to fine-tune parameters and they often come with the cost of accuracy (Xue et al., 2005). Hybrid approaches utilize both schemes for improved performance.

In this study, we propose a novel PPCF framework aiming at alleviating the problems of state-of-the-art k-nearest neighbor-based methods by applying a two-level preprocessing scheme. Initially, effects of sparseness on neighborhood formation is aimed to be relieved by a transformation of rating data into item features-based profiles (FBPs). Since number of item features is constant and extremely less than number of items, such FBPs function as a dimension reduction module. First preprocessing method focuses mainly on scalability issue and it is at the heart of the proposed framework. In this approach, a binary decision tree (BDT) is constructed by recursively clustering FBPs via bisecting k-means algorithm to locate the nearest neighbors in a significantly rapid and robust manner. Second preprocessing method is motivated to boost accuracy of scalability-enhanced scheme by enhancing discrimination skills of bisecting k-means clustering approach. For this purpose, clones of original users are reproduced by inserting pseudo-self-predictions (PSPs) into user profiles. Proposed preprocessing framework is evaluated in both CF and PPCF frameworks.

Major contributions of the work are, as follows:
                        
                           1.
                           A novel PPCF framework based on bisecting k-means clustering is proposed.

A two-level preprocessing scheme is suggested to deal with scalability and accuracy problems.

Effects of scalability and sparseness challenges are alleviated considerably.

Prediction accuracy of the proposed solution is significantly higher compared to the k-nearest neighbor-based CF and PPCF methods.

The rest of the paper is organized, as follows. We briefly describe previous related research in Section 2. We give a general background on CF in the next section. We deeply describe our novel scheme and the proposed preprocessing methods in Section 4. After analyzing our scheme by means of overhead costs and privacy in Section 5, we present experiments and their results in Section 6. Finally, we conclude the paper and give future research directions in Section 7.

@&#RELATED WORK@&#

CF methods operate on collected preference data and estimate predictions by calculating a weighted average over similar entities’ ratings (Acilar & Arslan, 2009; Herlocker et al., 2004). Content-based systems utilize descriptive information of items to filter products to be recommended. These two methods are combined together in some research to improve recommendation qualities, as well (Adomavicius & Tuzhilin, 2005; Li, Lu, & Xuefeng, 2005). Most practical deployments of CF are memory-based implementations in which similarities are calculated among all pairwise entities using a variety of methods, such as Pearson’s correlation coefficient, cosine similarity, or concordance (Lathia, Hailes, & Capra, 2007; Sarwar, Karypis, Konstan, & Riedl, 2000). Online vendors marketing over a diverse variety of products mostly prefer item-based methods (Linden et al., 2003); conversely, others prefer user-based systems (Herlocker et al., 2004). The advantage of those systems is in their simplicity as they do not have complicated parameters to tune; however, they are more vulnerable to scalability and sparseness issues because they operate on raw rating data. Chen and Yu (2010) propose a hybrid user- and item-based approach to overcome sparseness issue of traditional methods; nevertheless, their method still suffers from scalability problem because it has to search whole data set to locate the nearest neighbors to a given user. Recently, Altingovde, Subakan, and Ulusoy (2012) adapted an individualistic strategy by tailoring a cluster-based information retrieval method to overcome scalability.

Model-based approaches mostly utilize various data mining techniques such as clustering (Chen et al., 2009; Zhang & Chang, 2006), dimensionality reduction (Russell & Yoon, 2008), decision trees (Breese et al., 1998), Bayesian classifiers (Miyahara & Pazzani, 2000), and association rule mining (Shyu, Haruechaiyasak, Chen, & Zhao, 2005) to simplify and compact original matrix. Such produced prototypes need to be updated periodically (Herlocker et al., 2004). Dimensionality reduction techniques project data into a narrower dimension handling sparseness and scalability problems; however, they generally suffer from loss of potential useful information (Russell & Yoon, 2008; Xue et al., 2005). Conventional clustering approaches, on the other hand, are preferable in relieving scalability to some extent (Zhang & Chang, 2006); yet, there is a limit to scale systems using traditional one-level clustering without sacrificing accuracy much. In addition, model-based techniques usually require considerably large computation power to tune complex parameters related to the model.

Researchers propose to construct hybrid methods in order to combine advantages of memory- and model-based techniques. Chen et al. (2009) propose applying a clustering-based approach through nonnegative tri-factorization method along with user- and item-based methods. Russell and Yoon (2008) propose a wavelet data reduction-based model construction to reduce number of items, where Bilge and Polat (2012b) propose an item ordering method to improve its accuracy.

Closely related to this work, bisecting k-means clustering is attracting attention mostly in the fields of where lots of data present to be distinguished and analyzed, such as object tracking (Dubuisson & Fabrizio, 2009), image processing (Thilagamani & Shanthi, 2011), and document clustering (Steinbach, Karypis, & Kumar, 2000). In those fields, traditional clustering approaches fall short to process lots of data fast; thus, researchers propose clustering objects recursively to process images for tracking movement or graphical representations. In this paper, we employ an off-line bisecting k-means clustering to form a BDT model rather than instantly utilizing clustering results like performed in (Dubuisson & Fabrizio, 2009; Thilagamani & Shanthi, 2011).

Due to privacy risks of online shopping, PPCF is becoming more popular (Polat & Du, 2005). First approaches to build privacy measures on CF applications are distributed solutions by Canny (2002a, 2002b), relying on formation of an aggregate data using cryptographic techniques to hide confidential data in distributed environments. Central server-based applications are more popular, where individuals submit their preferences after perturbing up to a level for concealing their actual ratings and rated products. Data obfuscation methods, such as randomized perturbation techniques (RPTs) (Bilge & Polat, 2012b; Polat & Du, 2005), randomized response techniques (RRTs) (Polat & Du, 2006), and data substitution (Berkovsky, Kuflik & Ricci, 2012), are employed to perform filtering processes without violating privacy. RPT and RRT are successfully utilized in most central server-based research (Bilge & Polat, 2010, 2012b; Polat & Du, 2006). Although data obfuscation methods prevent data holders from disclosing confidential data, they inevitably come with reasonable loss of accuracy (Polat & Du, 2005). Since they are more practical to assure individual user privacy against central servers, these methods have been employed extensively instead of other privacy-preserving techniques such as anonymization and semi-trusted third parties. However, recovering accuracy losses due to privacy preservation process is not extensively studied. In this study, we focus on overcoming scalability challenge to maintain a deployable PPCF framework as well as producing qualified predictions with comparable accuracy to non-private schemes.

CF systems collect ratings and form a user-item matrix, U
                        
                           n×m
                        , containing preference information from n users on m items. During an online interaction with a CF system, an active user (a) requests a prediction for a target item (q) by sending her available ratings. CF prediction estimation can be thought as a two-step process: (i) locating neighbors by computing similarities between a and all other users in the system and (ii) estimating a weighted prediction based on preferences of neighbors on q. Such similarities between a and any user u are calculated using various methods. Most typically employed measure, Pearson’s correlation coefficient (PCC) is given in (Herlocker et al., 2004):
                           
                              (1)
                              
                                 
                                    
                                       sim
                                    
                                    
                                       au
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             
                                                
                                                   m
                                                
                                                
                                                   ′
                                                
                                             
                                          
                                       
                                       (
                                       
                                          
                                             r
                                          
                                          
                                             ai
                                          
                                       
                                       -
                                       
                                          
                                             
                                                
                                                   r
                                                
                                                
                                                   a
                                                
                                             
                                          
                                          
                                             ¯
                                          
                                       
                                       )
                                       (
                                       
                                          
                                             r
                                          
                                          
                                             ui
                                          
                                       
                                       -
                                       
                                          
                                             
                                                
                                                   r
                                                
                                                
                                                   u
                                                
                                             
                                          
                                          
                                             ¯
                                          
                                       
                                       )
                                    
                                    
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                
                                                   
                                                      
                                                         m
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                             
                                             (
                                             
                                                
                                                   r
                                                
                                                
                                                   ai
                                                
                                             
                                             -
                                             
                                                
                                                   
                                                      
                                                         r
                                                      
                                                      
                                                         a
                                                      
                                                   
                                                
                                                
                                                   ¯
                                                
                                             
                                             
                                                
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                
                                                   
                                                      
                                                         m
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                             
                                             (
                                             
                                                
                                                   r
                                                
                                                
                                                   ui
                                                
                                             
                                             -
                                             
                                                
                                                   
                                                      
                                                         r
                                                      
                                                      
                                                         u
                                                      
                                                   
                                                
                                                
                                                   ¯
                                                
                                             
                                             
                                                
                                                   )
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where r
                        
                           ui
                         is the rating for item i by user u, 
                           
                              
                                 
                                    
                                       
                                          r
                                       
                                       
                                          u
                                       
                                    
                                 
                                 
                                    ¯
                                 
                              
                           
                         is the average rating of user u, and m′ is the number of items co-rated by users. After calculating similarities, nearest neighbors can be determined by choosing the N closest ones (Herlocker et al., 2004). Formerly, a prediction for a on q, p
                        
                           aq
                        , is produced as a weighted average of neighbors’ ratings on q using the formula given in the following equation:
                           
                              (2)
                              
                                 
                                    
                                       p
                                    
                                    
                                       aq
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             r
                                          
                                          
                                             a
                                          
                                       
                                    
                                    
                                       ¯
                                    
                                 
                                 +
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             u
                                             =
                                             1
                                          
                                          
                                             N
                                          
                                       
                                       (
                                       
                                          
                                             r
                                          
                                          
                                             uq
                                          
                                       
                                       -
                                       
                                          
                                             
                                                
                                                   r
                                                
                                                
                                                   u
                                                
                                             
                                          
                                          
                                             ¯
                                          
                                       
                                       )
                                       ×
                                       
                                          
                                             sim
                                          
                                          
                                             au
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             u
                                             =
                                             1
                                          
                                          
                                             N
                                          
                                       
                                       
                                          
                                             sim
                                          
                                          
                                             au
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

High quality predictions can only be produced upon authentic data. However, customers often hesitate to submit their true preferences due to privacy concerns. Hence, the goal is to provide accurate predictions by guaranteeing customer confidentiality. Privacy-preserving schemes generally require a level of distortion in user profiles. Accordingly, accuracy losses are inevitable. Therefore, privacy parameters must be well-tuned as not allowing the server to extract any valuable information from user profiles and yet still be able to produce precise predictions.

PPCF has two key aspects (Polat & Du, 2005): (i) hiding individual preferences and (ii) concealing list of rated items. Disclosure of the actual preferences might cause privacy violations such as profiling and price discrimination; and revelation of the rated items list can be abused to achieve unsolicitepd marketing. One approach for preserving individual privacy is to mask personal data by randomly perturbing each vote in the profile and randomly filling some fraction of the empty cells (Polat & Du, 2005). RPTs are useful for applying a preferred level of distortion on data to provide proper privacy intervals by obstructing disclosure of individual data items.

In terms of PPCF, RPTs offer to disguise a vote entry v by replacing it with v
                        +
                        r, where r is a random number drawn from either a uniform or Gaussian distribution with mean (μ) being zero and a standard deviation (σ). The range of produced random numbers is adjusted to distort data items sufficiently. Such range is controlled by the value of σ. In Gaussian distribution, random numbers are generated with zero mean and σ while in uniform distribution, random numbers are generated over the range [−α, +α], where α is a constant and 
                           
                              
                                 
                                    3
                                 
                              
                              σ
                           
                        . Also, users insert additional random numbers to selectively or uniformly randomly chosen some of the empty cells as fake ratings. The number of empty cells to be filled can be determined based on the value of β
                        
                           max
                         associated with the density of user-item matrix. After the data holder sets σ
                        
                           max
                         and β
                        
                           max
                        , users can mask their vectors, as described in Algorithm 1 (Polat & Du, 2005). After data disguising, users send their disguised vectors to the data holder, which creates a disguised user-item matrix, 
                           
                              
                                 
                                    U
                                 
                                 
                                    n
                                    ×
                                    m
                                 
                                 
                                    ′
                                 
                              
                           
                        , and estimates predictions based on it. Hereafter, each active user a disguises her vector similarly and sends masked data along with a query to the server in order to get a prediction.
                           Algorithm 1
                           Data Disguising Procedure
                                 
                                    
                                       
                                       
                                       
                                          
                                             
                                                Require: User vector (u
                                                1×m
                                                ), σ
                                                
                                                   max
                                                , β
                                                
                                                   max
                                                
                                             
                                             
                                          
                                          
                                             
                                                
                                                
                                                Estimate z-scores (→Z):
                                             
                                          
                                          
                                             1: 
                                                   
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      ←
                                                      mean
                                                      (
                                                      u
                                                      )
                                                      ;
                                                      
                                                         
                                                            σ
                                                         
                                                         
                                                            u
                                                         
                                                      
                                                      ←
                                                      std
                                                      (
                                                      u
                                                      )
                                                   
                                                
                                             
                                             
                                          
                                          
                                             2: for all items in u (j
                                                ←1 to m) do
                                             
                                             
                                          
                                          
                                             3: 
                                                
                                                   
                                                      
                                                         
                                                            z
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      =
                                                      (
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      -
                                                      
                                                         
                                                            u
                                                         
                                                         
                                                            ¯
                                                         
                                                      
                                                      )
                                                      /
                                                      
                                                         
                                                            σ
                                                         
                                                         
                                                            u
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                          
                                          
                                             4: end for
                                             
                                             
                                          
                                          
                                             
                                                
                                                
                                                Determine privacy parameters:
                                             
                                             
                                          
                                          
                                             5: 
                                                   
                                                      β
                                                      ←
                                                      rnd
                                                      (
                                                      0
                                                      ,
                                                      
                                                         
                                                            β
                                                         
                                                         
                                                            max
                                                         
                                                      
                                                      )
                                                      ;
                                                      σ
                                                      ←
                                                      rnd
                                                      (
                                                      0
                                                      ,
                                                      
                                                         
                                                            σ
                                                         
                                                         
                                                            max
                                                         
                                                      
                                                      )
                                                      ;
                                                      α
                                                      ←
                                                      
                                                         
                                                            3
                                                         
                                                      
                                                      σ
                                                   
                                                
                                             
                                             
                                          
                                          
                                             6: e
                                                ←# of empty cells; g
                                                ←# of genuine ratings
                                             
                                          
                                          
                                             7: F
                                                ←
                                                e
                                                ×
                                                β%
                                             ▷ # of empty cells to be filled
                                          
                                          
                                             
                                                
                                                
                                                Select distribution & generate random numbers:
                                             
                                             
                                          
                                          
                                             8: dist
                                                ←
                                                random(uniform, Gaussian)
                                             
                                          
                                          
                                             9: R
                                                ←
                                                dist(g
                                                +
                                                F; μ
                                                =0, σ∣α)
                                             
                                          
                                          
                                             
                                                
                                                
                                                Disguise z-scores (→Z′):
                                             
                                          
                                          
                                             10: for all items in u (j
                                                ←1 to m) do
                                             
                                             
                                          
                                          
                                             11: 
                                                
                                                   
                                                      
                                                         
                                                            z
                                                         
                                                         
                                                            j
                                                         
                                                         
                                                            ′
                                                         
                                                      
                                                      =
                                                      (
                                                      
                                                         
                                                            z
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      +
                                                      
                                                         
                                                            R
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                             
                                          
                                          
                                             12: end for
                                             
                                             
                                          
                                          
                                             
                                                
                                                return 
                                                Z′
                                             
                                          
                                       
                                    
                                 
                              
                           

Clustering algorithms take n objects and assemble them into c clusters so that the members of a cluster are close to each other in terms of discrimination measure and the members of different clusters are diverse. To overcome scalability challenges, clustering has been employed as an off-line preprocessing tool to narrow search space in CF applications. Although traditional one-level clustering helps finding neighbors fast; however, it creates a trade-off for accuracy as number of clusters increases due to loss wisdom of the crowd (Bilge & Polat, 2012a). On the other hand, small number of clusters does not facilitate well for scalability. Even if number of entities raises drastically, there is a reasonable limit to increase number of clusters to provide predictions with reasonable accuracy. k-means clustering (Gan, Ma, & Wu, 2007) is a well-known center-based clustering algorithm in which each cluster has a center called the mean. Number of clusters (k) is preset and an error function is defined as the change in cluster centers or membership of data items between two consecutive epochs. Initially, k random objects are chosen as centers, one for each cluster. It proceeds by calculating similarities between all entities and each seed; assigns them to the nearest cluster, and recalculates cluster centers. This process is repeated until the error function does not change significantly or the membership of the clusters no longer changes.

Bisecting k-means algorithm is a divisive hierarchical clustering (Steinbach et al., 2000), which starts with a single cluster and splits it into two sub-clusters using k-means algorithm (bisecting step). It repeats this process recursively for either a desired number of times or a certain criterion is met. Note that it has a time complexity of linear with the number of entities. If the number of clusters is large, then bisecting k-means is even more efficient than the regular k-means algorithm (Steinbach et al., 2000).

Calculating similarity between any two users relies on their commonly rated items, as seen from Eq. (1). However, due to constantly growing nature of products, it becomes more unlikely to find such co-rated items. Also, the quantity of them will be very few not allowing to calculate accurate and dependable similarities. Instead of using rating/preference profiles for clustering purposes, in our previous work (Bilge & Polat, 2011), we propose to employ merging those ratings into FBPs to reduce typically large and sparse user vectors into compact models. Although individual ratings are independent, items correlate among themselves as they have common features, where number of such features are naturally very much less than number of items. Therefore, if such features are determined, then histograms of absolute frequencies can be produced by giving a weight to corresponding features of a rated item. Those weights can be simply equal to each other or can also reflect rankings between preferences (Bilge & Polat, 2011). We employ an equal weight-based profiling scheme to prevent fluctuations in histograms due to data disguising scheme. To understand FBP producing procedure, let us examine a small user-item matrix, given in Table 1
                        , including ratings for movies in a 5-star scale, where ⊥ indicates an unrated item. Also, suppose that genre features of movies are also provided as having at least one from the set {Comedy, Drama, Romance, Action, Fantasy} in Table 2
                        . FBPs of users are given in Fig. 1
                        .

As seen from Fig. 1, Alice’s FBP is [2,2,2,0,1] because there are two items, i
                        1 and i
                        3, whose genre includes Comedy and she rated both items; hence, corresponding FBP value is 2; similarly, there are two items, i
                        4 and i
                        5, whose genre includes Fantasy and she rated one of them only; hence, corresponding FBP value is 1, and so on. Similarly, Bob’s FBP can be obtained as [0,1,0,1,1]. Moreover, obtained FBPs should be normalized because in real-world data sets, every user rates different number of items. Similarly, number of features might be different for various items, as i
                        1 has three features while i
                        3 having only one in our example. Due to these reasons, produced FBPs might fluctuate. In order to smooth such effects, FBPs are normalized by dividing each profile value by the sum of profile. Therefore, FBPs are updated as 
                           
                              
                                 
                                    
                                       
                                          
                                             2
                                          
                                          
                                             7
                                          
                                       
                                       ,
                                       
                                          
                                             2
                                          
                                          
                                             7
                                          
                                       
                                       ,
                                       
                                          
                                             2
                                          
                                          
                                             7
                                          
                                       
                                       ,
                                       0
                                       ,
                                       
                                          
                                             1
                                          
                                          
                                             7
                                          
                                       
                                    
                                 
                              
                           
                         and 
                           
                              
                                 
                                    
                                       0
                                       ,
                                       
                                          
                                             1
                                          
                                          
                                             3
                                          
                                       
                                       ,
                                       0
                                       ,
                                       
                                          
                                             1
                                          
                                          
                                             3
                                          
                                       
                                       ,
                                       
                                          
                                             1
                                          
                                          
                                             3
                                          
                                       
                                    
                                 
                              
                           
                         for Alice and Bob, respectively. Note that similarity between these two users cannot be calculated over rating profiles as they do not have any co-rated items; however, it can be calculated over their FBPs and such circumstances are not rare on real-world data sets.

In this section, we define our novel scheme based on the proposed two preprocessing methods, where users are supposed to interact with the CF system by explicitly submitting preferences on their ratings because implicit mechanisms are often less accurate and tractable (Adomavicius & Tuzhilin, 2005). We explain how to form a BDT by applying a bisecting k-means clustering. We study how to produce clone profiles to recover accuracy losses due to the first scheme. We also show that applied clustering method can be run on masked data.

As a model-based CF technique, clustering-based CF is a valuable approach. Yet, it needs to be utilized in a more profound manner rather than one level application to alleviate its shortcomings. While clustering algorithms are very useful in discriminating entities relying onto a criterion, they best perform while dividing a set into two halves because it is more unlikely to happen very close membership values in case of two clusters, which intensify the algorithm’s sensitivity. However, forming only two clusters would not relieve scalability issues much. Thus, we propose to apply multi-level clustering by recursively bisecting input data into clusters and forming a BDT according to clustering results. Hence, we aim to produce tiny clusters containing very similar users at the leaf nodes of BDT and find the nearest neighbors of a newcomer by simply traversing down the tree.

Suppose that an optimal value of N in a PPCF system is known. A BDT with at most N users in the leaf nodes can be constructed to efficiently form neighborhoods, as described through a pseudo-code layout in Algorithm 2. Given U
                        
                           n×m
                        , the server first estimates FBPs of users, F
                        
                           n×f
                        , where f is the number of features. Then, bisecting k-means clustering is employed and FBPs are divided into two distinct clusters at each level. Cluster centers are indexed to be used as a forwarding tool for each corresponding level, as well. If the number of profiles in any cluster exceeds N, then recursive bisecting continues to divide those clusters using the same approach and indexes cluster centers of each clustering process. This procedure continues repeatedly until leaves having at most N profiles are reached; thus, N can be thought as a stopping criterion. Finally, a BDT having indexed cluster centers as branch nodes and grouped similar profiles at leaf nodes is obtained. Corresponding rating profiles-based tree structure can be formed easily.
                           Algorithm 2
                           BDT formation via bisecting k-means clustering
                                 
                                    
                                       
                                       
                                       
                                          
                                             1: function BKM(F, N)
                                             ▷ bisecting k-means cluster
                                          
                                          
                                             
                                                
                                                
                                                Initialize:
                                             
                                             
                                          
                                          
                                             2: 
                                                IDX(n)←0
                                             
                                          
                                          
                                             3: 
                                                BDT.centers
                                                2×f
                                                
                                                ←
                                                null
                                             
                                             
                                          
                                          
                                             4: 
                                                BDT.left
                                                ←
                                                null
                                             
                                             
                                          
                                          
                                             5: 
                                                BDT.right
                                                ←
                                                null
                                             
                                             
                                          
                                          
                                             6: 
                                                BDT.LST: a new BDT
                                             ▷ Left sub-tree
                                          
                                          
                                             7: 
                                                BDT.RST: a new BDT
                                             ▷ Right sub-tree
                                          
                                          
                                             
                                                
                                                
                                                Cluster:
                                             
                                             
                                          
                                          
                                             8: [IDX, BDT.centers]=
                                                k-means(F, 2)
                                             
                                          
                                          
                                             9: 
                                                for all 
                                                u
                                                
                                                   i
                                                 in F (i
                                                ←1 to n) do
                                             
                                             
                                          
                                          
                                             10: 
                                                if 
                                                IDX(u
                                                
                                                   i
                                                )= “left” then
                                             
                                             
                                          
                                          
                                             11: 
                                                append u
                                                
                                                   i
                                                 into BDT.left
                                             
                                             
                                          
                                          
                                             12: 
                                                else
                                             
                                             
                                          
                                          
                                             13: 
                                                append u
                                                
                                                   i
                                                 into BDT.right
                                             
                                             
                                          
                                          
                                             14: 
                                                end if
                                             
                                             
                                          
                                          
                                             15: 
                                                end for
                                             
                                             
                                          
                                          
                                             16: 
                                                if size (BDT.left)>
                                                N 
                                                then
                                             
                                             
                                          
                                          
                                             17: 
                                                
                                                
                                                   
                                                      BDT
                                                      .
                                                      LST
                                                      =
                                                      BKM
                                                      (
                                                      BDT
                                                      .
                                                      left
                                                      ,
                                                      N
                                                      )
                                                   
                                                
                                             
                                             
                                          
                                          
                                             18: 
                                                end if
                                             
                                             
                                          
                                          
                                             19: 
                                                if size (BDT.right)>
                                                N 
                                                then
                                             
                                             
                                          
                                          
                                             20: 
                                                
                                                
                                                   
                                                      BDT
                                                      .
                                                      RST
                                                      =
                                                      BKM
                                                      (
                                                      BDT
                                                      .
                                                      right
                                                      ,
                                                      N
                                                      )
                                                   
                                                
                                             
                                             
                                          
                                          
                                             21: 
                                                end if
                                             
                                             
                                          
                                          
                                             22: 
                                                return 
                                                BDT
                                             
                                             
                                          
                                          
                                             23: end function
                                             
                                             
                                          
                                       
                                    
                                 
                              
                           

During an online transaction with a, the PPCF server first generates FBP of a, F
                        
                           a
                        , and determines the leaf, which F
                        
                           a
                         belongs to by traversing down the tree. While traversing, two similarity calculations are performed at each level to find relationships to both cluster centers and higher resemblance decides the next hope, which is stored in IDX variable in Algorithm 2. This way, locating exact leaf of F
                        
                           a
                         requires at most 2×(h
                        −1) similarity computations, where h is the height of the BDT. The leaf, F
                        
                           a
                         goes into, can reference to at most N users; however, this amount might be fewer. Therefore, the server treats all references in that particular leaf and its sibling as potential neighbors, calculates exact similarities with all such users, and eventually, marks the nearest N of them as neighbors, which requires at most 2N additional similarity computations. Although h is dependent to the value of n in the system, intuitively, both h and N are much less than n in systems suffering from scalability. Hence, once the tree is formed, at most 2×(h
                        −1+
                        N) similarity computations are performed instead of n to form the neighborhood. In other words, number of computations performed to find similarities significantly becomes smaller.

An example BDT produced via bisecting k-means clustering can be seen in Fig. 2
                        . Suppose that there are initially 200 users and N is chosen as 30 in this example. Users are divided into two clusters with 120 and 80 users at the first level. Corresponding cluster centers are indexed at the root of the tree as 
                           
                              
                                 
                                    C
                                 
                                 
                                    1
                                 
                                 
                                    L
                                 
                              
                           
                         and 
                           
                              
                                 
                                    C
                                 
                                 
                                    1
                                 
                                 
                                    R
                                 
                              
                           
                        , where superscripts indicate for which sub-tree the cluster center forwards (either left or right) and subscripts indicating the height of BDT so far, which is one for the case of root. Similarly, in the left sub-tree of root, 120 users are clustered into two groups of 75 and 45 users with branch node containing cluster centers 
                           
                              
                                 
                                    C
                                 
                                 
                                    2
                                 
                                 
                                    L
                                 
                              
                           
                         and 
                           
                              
                                 
                                    C
                                 
                                 
                                    2
                                 
                                 
                                    R
                                 
                              
                           
                        . Note that subscripts are incremented by 1 and superscripts show again the forwarding paths as left or right. Going on so forth, each branch node is divided into two sub-clusters unless they contain N or fewer users. Finally, the BDT is completed with two cluster centers at each branch node to facilitate forwarding and tiny but very similar user groups at leaf nodes to enable forming accurate neighborhoods. For this specific example, locating neighbors of a new user requires at most 2(5−1+30)=68 similarity computations instead of 200, reducing the number of computations approximately three times. Since the time consuming part in CF algorithms is neighborhood formation, the effect of this preprocessing scheme on scalability can be seen more clearly as the number of users in the system increases.

Considering the discrimination mechanism of k-means clustering over levels, correlations between users are utilized as distance criterion and they must be calculated precisely to construct accurate clusters. Such correlations are calculated over FBPs of users, which project rating preferences onto a feature-based dimension. Therefore, two users having similar tastes cannot be caught by the system unless they rate on items having the same features. Finding similar users relying on past preferences may not always result accurate findings due to sparseness. Consequently, discriminations over levels of BDT can be performed with limited accuracy. Although the first preprocessing scheme deals with scalability issues well, accuracy of recommendations cannot be jeopardized greatly. Hence, we propose a second scheme to alleviate effects of sparseness and boost accuracy in CF systems.

Regarding similarity between users in terms of PCC, two users are similar if their preferences to co-rated items show concordance no matter what their uncommon ratings are. Even FBPs are utilized in similarity calculation, two users are required to rate on the same kind of items. The idea of this preprocessing scheme is to produce identical clones of an original user’s rating profile in terms of PCC (having exact same ratings with the original user) and also having some additional ratings to unrated cells. Then, such clones’ FBPs will also be included in the BDT formation process. This way, if the system falls short to determine a high correlation between a’s and an existing user’s FBP, it can figure it out through one of its replicas profile. Since clones will have more ratings, consequently, they will have more meaningful FBPs. Moreover, since each clone is identical to its parent in terms of PCC, we can assume that if a is similar to any clone profile, she also most likely be similar to the parent of which that clone is created. This process naturally increases the number of users in the system; anyway, the first scheme reduces the search space logarithmically. Therefore, while one scheme enhances discrimination capabilities of clustering approach, the other can still cover overheads caused by it.

The outline of the proposed cloning scheme is given as a pseudo-code layout in Algorithm 3. According to the algorithm, each produced clone includes all true ratings of the original user and additional PSPs to randomly chosen unrated cells. Such PSPs are estimated from the input-matrix itself using the traditional PPCF prediction method, i.e., the nearest neighbors of an existing user in U are determined through calculating PCC and predictions to unrated cells are estimated via Eq. (2). Also, each clone has PSPs to distinct random empty cells. Therefore, the correlation among a user and all of its replicas shows the highest resemblance because their co-rated items are all the same. However, additional PSPs will change corresponding FBPs, which will help revealing uncovered relations between original users. To provide a base for tuning, we offer to produce clones by inserting PSPs into the original profiles proportional to the number of existing ratings of each user. We name this parameter as the density. Suppose that an original user has 100 ratings in her profile and we would like to create five clones by increasing the density by 50%, which means that 50 extra ratings per clone are added. Since five clones will be created, a total of 250 PSPs are estimated and then each replica will have initial 100 ratings along with additional 50 PSPs to distinct empty cells. After creating clones, FBPs of such clones are also generated and BDT is formed. Supposedly an original user and her clones will fall into the same leaf. However, while the BDT is created, clones will affect cluster centers, which will facilitate forwarding a new user to her neighbors. Note that the number of clones to produce and how much to increase density in clones are to be determined experimentally.
                           Algorithm 3
                           Generating clones of a user by PSPs
                                 
                                    
                                       
                                       
                                       
                                          
                                             
                                                Require User-item matrix (U
                                                
                                                   n×m
                                                ), User-id (id),
                                             
                                          
                                          
                                             
                                                
                                                Clone Count (ω), Density (ρ)
                                             
                                          
                                          
                                             1: Initialize: 
                                                Clones
                                                
                                                   ω×m
                                                
                                                ←0
                                             ▷ clones matrix
                                          
                                          
                                             2: for 
                                                i
                                                ←1 to ω 
                                                do
                                             
                                             
                                          
                                          
                                             3: 
                                                Clones(i)=
                                                U(id)
                                             ▷ create identical clones
                                          
                                          
                                             4: end for
                                             
                                             
                                          
                                          
                                             5: n
                                                
                                                   r
                                                
                                                ←# of ratings in U(id)
                                             
                                          
                                          
                                             6: i
                                                
                                                   ec
                                                
                                                ←index of empty cells in U(id)
                                             
                                          
                                          
                                             7: 
                                                   
                                                      
                                                         
                                                            r
                                                         
                                                         
                                                            ec
                                                         
                                                      
                                                      ←
                                                      RandomPermutation
                                                      (
                                                      
                                                         
                                                            i
                                                         
                                                         
                                                            ec
                                                         
                                                      
                                                      )
                                                   
                                                
                                             
                                             ▷ random index of empty cells
                                          
                                          
                                             8: n
                                                
                                                   ec
                                                
                                                ←
                                                n
                                                
                                                   r
                                                
                                                ×
                                                ρ
                                             
                                             ▷ # of empty cells to be filled
                                          
                                          
                                             
                                                
                                                
                                                Calculate and sort similarities:
                                             
                                             
                                          
                                          
                                             9: for all 
                                                u
                                                
                                                   i
                                                 in U (i
                                                ←1 to n) do
                                             
                                             
                                          
                                          
                                             10: 
                                                
                                                   
                                                      similarities
                                                      (
                                                      i
                                                      )
                                                      =
                                                      pcc
                                                      (
                                                      U
                                                      (
                                                      i
                                                      )
                                                      ,
                                                      U
                                                      (
                                                      id
                                                      )
                                                      )
                                                   
                                                
                                             
                                             
                                          
                                          
                                             11: end for
                                             
                                             
                                          
                                          
                                             12: 
                                                   
                                                      sorted
                                                      _
                                                      sim
                                                      =
                                                      sort
                                                      (
                                                      similarities
                                                      ,
                                                      descending
                                                      )
                                                   
                                                
                                             
                                             ▷ to be used by PSP production
                                          
                                          
                                             
                                                
                                                Produce PSPs for each clone:
                                             
                                             
                                          
                                          
                                             13: for 
                                                i← 1 to ω 
                                                do
                                             
                                             
                                          
                                          
                                             14: 
                                                for 
                                                j← 1 to n
                                                
                                                   ec
                                                 
                                                do
                                             
                                             
                                          
                                          
                                             15: 
                                                idx
                                                =(i
                                                −1)×
                                                n
                                                
                                                   ec
                                                
                                                +
                                                j
                                             
                                             
                                          
                                          
                                             16: 
                                                target_item
                                                =
                                                i
                                                
                                                   ec
                                                (r
                                                
                                                   ec
                                                (idx))
                                             
                                          
                                          
                                             17: 
                                                
                                                   
                                                      Clones
                                                      (
                                                      i
                                                      ,
                                                      target
                                                      _
                                                      item
                                                      )
                                                      ←
                                                      PSP
                                                      (
                                                      sorted
                                                      _
                                                      sim
                                                      ,
                                                      target
                                                      _
                                                      item
                                                      )
                                                   
                                                
                                             
                                             ▷ estimated using Eq. (2)
                                             
                                          
                                          
                                             18: 
                                                end for
                                             
                                             
                                          
                                          
                                             19: end for
                                             
                                             
                                          
                                       
                                    
                                 
                              
                           

After estimating FBPs of the collected disguised user vectors, the server forms a BDT by running Algorithm 2, where bisecting k-means is performed through FBPs to cluster users. However, in a privacy-preserving environment, such profiles can only be estimated through disguised user vectors. Given a user-item matrix, U, it is an easy task to cluster users; however, the server holds the disguised user-item matrix, U′, for privacy reasons. Bisecting k-means algorithm performs two different calculations using FBPs, i.e., estimating cluster centers by taking average of members of clusters and calculating similarities between user profiles and cluster centers. Thus, we analyze how precise the server can cluster U′.

Considering the FBP generation process explained in Section 3.4, the server simply increments each vote’s corresponding feature value by 1 and normalizes the vector at the end. Estimation of FBPs on masked data must be analyzed under two circumstances. As explained in Algorithm 1, to protect their privacy, users (i) disguise their individual ratings and (ii) insert fake ones into their profiles. Indeed, disguising actual ratings does not affect the estimation of an FBP, because the server increments corresponding feature values by 1 no matters the related rating values are disguised. Hence, an original ratings vector and its disguised version shall produce the same FBP.

Remember that users forge additional ratings to hide their truly rated items. Nevertheless, due to normalization procedure of profiles, effects of those artificial ratings are diminished. Given m
                        
                           d
                         disguised actual ratings for user u (u
                        
                           i
                         for i
                        =1,2,…,
                        m
                        
                           d
                        ), each element of F
                        
                           u
                         is estimated by incrementing the related feature values of u
                        
                           i
                        ’s, normalized by the 
                           
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          m
                                       
                                       
                                          d
                                       
                                    
                                 
                              
                              
                                 
                                    f
                                 
                                 
                                    j
                                 
                              
                           
                        , where f
                        
                           j
                         is the number of features for item j. Then, random artificial ratings are inserted into profile by β
                        
                           u
                        % of m
                        
                           d
                         and as m
                        
                           d
                         grows, expected value of increase in each element of F
                        
                           u
                         is also β
                        
                           u
                        %. Also, as m
                        
                           d
                         increases, we can assume that 
                           
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                    =
                                    1
                                 
                                 
                                    
                                       
                                          m
                                       
                                       
                                          d
                                       
                                    
                                 
                              
                              
                                 
                                    f
                                 
                                 
                                    j
                                 
                              
                              ≈
                              
                                 
                                    m
                                 
                                 
                                    d
                                 
                              
                              ×
                              δ
                           
                        , where δ is the average number of features per item. Due to the proportional increase in elements of FBP and normalization coefficient, negligible differences occur in estimated FBPs. While calculating cluster centers, average of those FBPs will be taken, which will further diminish such difference. In addition, when clones of users are included in the process, number of users will increase drastically and effects of random filling procedure will become further insignificant.

It is imperative to analyze the proposed schemes in terms of both off-line and online costs like storage, communication, and computation costs. Although off-line costs do not have acute effects on performance compared to online ones, they are still needed to be analyzed to provide a report on off-line size of work overload. Furthermore, a detailed analysis evaluating the employed individual privacy protection mechanism is provided to see what extent it is effective.

Compared to the traditional k-nearest neighbor-based CF approaches, neither of our preprocessing schemes introduces any extra communication costs, i.e., both the number of communications and amount of data to be transmitted in online and off-line phases remain the same.

Traditional CF schemes require a storage cost in the order of O(nm) to collect n users’ data for m items. Additionally, we utilize FBPs of users, which requires an extra storage cost in the order of O(nf), where note that f is the constant number of features and f
                        ≪
                        m. Due to the BDT generation process, there will be two 1-by-f vectors being the cluster centers to be recorded after each recursive call. Therefore, at each level, there will be at most 2
                           k
                         such vectors, where k
                        =1,2,…,
                        h
                        −1 and h is the height of BDT. Also notice that h
                        ≪
                        n in systems suffering from scalability. Moreover, the second preprocessing scheme increases number of users by producing clones; however, the upsurge is linear; and thus, the storage cost is linear, as well. Consequently, total storage cost of both schemes is in the order of O(nm).

Additional computation costs can be analyzed, as follows. Off-line phase includes three stages: (i) estimating FBPs, (ii) generating clones, and (iii) building a model through bisecting k-means. FBPs are estimated in O(nm) time because every item of every user is checked through. Then, the server creates clones of all n original users by predicting PSPs in an identical manner it produces actual recommendations, which has an online running time in the order of O(n
                        2
                        m). Thus, total cost of producing clones is in the order of O(n
                        3
                        m). Finally, it constructs a BDT by applying bisecting k-means clustering, which runs in the order of O(n
                        3log
                        n) for each iteration. At each level for BDT, at most 2
                           k
                         clustering operations (k
                        =0,1,…,
                        h
                        −1) will be performed yielding a total computation cost in the order of O(2
                           h
                        
                        n
                        3log
                        n) to form a BDT.

Actual performance of a recommender system is determined by its response time to queries. After forming neighborhood, data disguising schemes allow PPCF systems to produce predictions identical to traditional CF schemes. Unlike the PPCF approach, the proposed scheme constructs neighborhood by traversing the BDT. For this purpose, during an online transaction, FBP
                        
                           a
                         of a new user is estimated initially, which requires O(m) time. While traversing the tree, PCC is calculated between cluster centers and F
                        
                           a
                        , where each calculation requires O(f) time. After locating user’s neighbors, exact similarities between rating profiles is determined. Therefore, online predictions can be estimated in the order of O(Nm) because h and f are small constants, where typically N
                        ≪
                        n in systems suffering from scalability.

Employed perturbation protocol aims to avoid the data holder to infer about both if a rating is genuine or forged and actual values of the genuine ratings. Accordingly, there are two considerations to analyze the privacy level provided by the system.

Each user profile contains genuine ratings along with the forged ones to β% of the empty cells, where β is uniformly randomly chosen from the interval (0, β
                           
                              max
                           ], as explained in Section 3.2. Therefore, the server first needs to guess β and then it can predict the set of genuine items with some probability.

We measure privacy provided by random selection of β as Shannon entropy (Shannon, 1948) of user’s apparent rating distribution. Recall that the entropy of a random variable X with possible values {x
                           1,
                           x
                           2,…,
                           x
                           
                              n
                           } and distributed by a probability mass function p is defined as 
                              
                                 H
                                 (
                                 X
                                 )
                                 =
                                 -
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       n
                                    
                                 
                                 p
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 
                                    
                                       log
                                    
                                    
                                       2
                                    
                                 
                                 
                                 p
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                           , which can be interpreted as measure of uncertainty of the outcome. Intuitively, such uncertainty can be maximized through uniform selection of β% over (0, β
                           
                              max
                           ]. Inline with the perturbation scheme described in Section 3.2, we can model items of a CF system as random variables taking on values from normal distribution 
                              
                                 N
                                 (
                                 x
                                 ;
                                 0
                                 ,
                                 
                                    
                                       σ
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                            or uniform distribution 
                              
                                 U
                                 (
                                 x
                                 ;
                                 2
                                 σ
                                 
                                    
                                       3
                                    
                                 
                                 )
                              
                           . Let g and e be the numbers of genuine ratings and empty cells of a particular user, respectively. Accordingly, let P
                           ={p
                           1,
                           p
                           2,…,
                           p
                           
                              g
                           } define the probability distribution of genuine ratings and R
                           ={r
                           1,
                           r
                           2,…,
                           r
                           
                              e×β
                           } define the distribution of forged items. Now, we can model user’s distribution as 
                              
                                 S
                                 =
                                 
                                    
                                       #
                                       P
                                       +
                                       #
                                       R
                                    
                                    
                                       g
                                       +
                                       (
                                       e
                                       ×
                                       
                                          
                                             β
                                          
                                          
                                             max
                                          
                                       
                                       )
                                    
                                 
                              
                           , where #P and #R indicate the number of elements in the sets P and R, respectively. Thus, we can quantify privacy obtained by Pr(β) as the entropy of 
                              
                                 S
                              
                           . We depict an example of provided privacy levels in Fig. 3
                            for three different scenarios by varying β
                           
                              max
                            from 5 to 100, where the user is assumed to have 50 genuine ratings on 500, 1000, and 2000 ratable items.

After guessing β with probability 1 out of β
                           
                              max
                           , the server can try to extract the list of truly rated items. However, due to perturbation protocol the server has g′ and e′ instead of g and e as numbers of actual ratings and empty cells, respectively. Hereafter, g can be calculated as g
                           =
                           m
                           −
                           e, where e
                           =
                           e′/β%. Then, the list of genuine ratings can be predicted as one of the combinations of selecting g ratings out of g′ disguised values. Combining these probabilities, we can conclude that the probability of determining genuine ratings from a given disguised user vector is 1 out of 
                              
                                 
                                    
                                       β
                                    
                                    
                                       max
                                    
                                 
                                 ×
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         g
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   g
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           , where 
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         g
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   g
                                                
                                             
                                          
                                       
                                    
                                 
                              
                            stands for the number of combinations of g′ objects chosen g at a time.

After distinguishing between genuine and forged ratings, the server tries to find real values of ratings from their masked z-score values. Therefore, privacy levels achieved by adding random noise on ratings must also be quantified. Such quantification can be performed using the measure proposed by Agrawal and Aggarwal (2001); and also utilized in PPCF context in (Polat & Du, 2005). This metric utilizes differential entropy of a random variable to quantify disclosure of an additive noise-based perturbed variable. Let P is perturbed by R yielding D as D
                           =
                           P
                           +
                           R, then average conditional confidentiality of P is defined as Π(P∣D)=2
                              H(P∣D), where 2
                              H(P∣D) stands for conditional differential entropy of P given D. Bearing in mind that P and R are independent random variables, confidentiality level of P after disclosing of D is given by Π(P∣D)=
                           Π(P)×(1−
                           Pr(P∣D)), where Pr(P∣D)=1−2
                              H(D∣P)−H(D). Under the assumption of original data (P) distributes normally, privacy levels, Π(P∣D), for various perturbation levels are computed, as performed in (Polat & Du, 2005) and presented in Fig. 4
                           . Recall that the distribution of perturbing values is chosen by coin tosses. As seen from Fig. 4, provided privacy levels enhance with increasing level of perturbation and Gaussian distribution provides slightly better privacy. Note also that the server needs to de-normalize extracted z-score values, which requires deducing mean and standard deviation of each user’s original rating profiles.

@&#EXPERIMENTS@&#

We conducted experiments on benchmark data sets collected for CF purposes to investigate how proposed schemes perform with respect to accuracy and efficiency on both CF and PPCF schemes. First, BDT produced by bisecting k-means approach is evaluated solely against state-of-the-art k-nearest neighbor-based CF method to see its effects on scalability clearly. Then, the second preprocessing scheme is built on scalability enhanced structure to determine its impact on accuracy. Finally, combined effects of the proposed schemes are evaluated on PPCF architecture and obtained enhancements are analyzed in terms of their significance.

Trials were performed on two variations of well-known publicly available data set collected by GroupLens at the University of Minnesota (http://www.grouplens.org). MovieLens Public (MLP) and MovieLens Million (MLM) contain preferences for movies in a 5-star rating scale. In addition, each movie in the sets contain at least one or more genre features from predefined 18 categories. Data sets are suitable to show effects of preprocessing schemes as they both are extremely sparse and especially MLM is very large. Detailed information about the data sets is given in Table 3
                        .

CF systems can be evaluated through several metrics in terms of statistical accuracy. We utilized mean absolute error (MAE), which measures how close the predictions are to the actual ratings as an average of absolute errors, i.e., e
                        
                           i
                        
                        =∣p
                        
                           i
                        
                        −
                        v
                        
                           i
                        ∣, where p
                        
                           i
                         is the estimated prediction and v
                        
                           i
                         is the actual rating value. Thus, the smaller the MAE, the better the results are. Since the proposed approaches aim at improving scalability, total elapsed time (T) in seconds spent on producing online referrals is also recorded.

Experiments were realized using a 10-fold cross-validation experimentation methodology. The original data set (U or U′) was uniformly randomly divided into ten subgroups and at each iteration i (i
                        =1,2,…,10), corresponding subset (U
                        
                           i
                         or 
                           
                              
                                 
                                    U
                                 
                                 
                                    i
                                 
                                 
                                    ′
                                 
                              
                           
                        ) was considered as the test users and the remaining ones were as the training users. After training and test sets were constructed, five rated items’ actual votes were withheld for each test (active) user. Such entries were replaced with null, their values were tried to be predicted, and estimations were compared with actual values. Trials were done in MATLAB 7.9.0 environment using a computer with an Intel Xeon 2.8GHz processor and 6GB RAM. For k-means clustering operations, MATLAB’s built-in function was used with parameters to take head k user vectors in the input matrix as initial centers and utilizes correlation as the distance measure based on PCC.

@&#RESULTS AND DISCUSSION@&#

Several trials were performed to assess the effects of preprocessing schemes with different parameters. Proposed schemes were evaluated in non-private and private environments separately. Mainly, distinct performances of schemes were assessed in non-private architecture and optimized configuration of both preprocessing methods was evaluated through varying privacy parameters in privacy-preserving architecture. Details of experimental procedures and results of conducted tests were explained in the following.

To examine improvements with respect to scalability, we first produced predictions relying on the BDT constructed by bisecting k-means clustering approach and compared empirical outcomes against the traditional CF scheme, where these schemes will hereafter be referred to as BKM and CF methods, respectively. Then, we employ the second preprocessing method onto the first one, denoted as BKM+, by accompanying clones into user-item matrix, showed its effects on accuracy and online performance.

We experimented on the BKM model to examine its effects on accuracy and online performance. For all folds, we produced FBPs initially, recursively clustered training sets, as described in Section 4.1, and constructed corresponding BDTs. Then, we located belonged leaf of each test user by forwarding them in relation to cluster centers and located the nearest neighbors by calculating similarities to the users in that particular leaf node and its sibling. We then produced predictions to withheld items, estimated MAEs, measured T for whole online process. Trials were repeated by varying N from 20 to 100 because employing more than 100 neighbors might have adverse effects on scalability, as stated in (Herlocker et al., 2004). Outcomes are displayed in Table 4
                               for both data sets.

According to Table 4, CF scheme obtains its best accuracy values for MLP and MLM as 0.772 and 0.747 with N values of 60 and 80, respectively. BKM scheme achieves 0.758 and 0.742 MAE values with N values of 80 and 100, respectively. We can conclude that there is not a significant improvement in accuracy for MLM and a slight progress for MLP. However, there is a significant improvement in T. Through overall trials, we produced five predictions for each test user, which yields a total of 4715 and 30,200 predictions for MLP and MLM, respectively. Compared to CF scheme, BKM model produces such predictions in 18s instead of 150 for MLP and 311s instead of 1526 for MLM, which means an enhancement of approximately 88% and 80% on the online performance, respectively. Moreover, since BKM model operates by simply traversing over the BDT, which is constructed off-line, as the number of users in the system increases linearly, such online performance enhancements will be much greater due to logarithmic grow of height of the tree. This phenomenon can be observed better in the next set of experiments, where the number of users in the system increases dramatically due to additional clone profiles injected into the system.

BKM model proves that it can handle scalability issues well; however, it is not very successful at boosting accuracy. BKM+ model is proposed as reinforcement onto BKM model to improve precision of predictions, which are restricted due to information losses caused by narrowing down search space through a BDT. However, BKM+ model must be studied in terms of its controlling parameters to get the most possible gain of accuracy. Such parameters are experimentally analyzed in the following.


                              Number of clones (ω): We hypothesize that cloning original user profiles shall improve determination skills of BDT; and hence, accuracy of the system. However, ω must be fine-tuned because it can influence scalability of the system. While producing clones, we located 100 nearest neighbors to each train user in the system and produced PSPs to uniformly randomly chosen empty cells using such neighbors’ data. While we were varying ω from 1 to 5, we held N
                              =80 and ρ
                              =1, i.e., each clone has twice as much ratings as the original user. After estimating FBPs of original and clone users, we recursively clustered clones-added profiles and produced corresponding BDTs. In order to avoid U to converge to itself and lose personalization, we produced predictions through only original user profiles. Due to the randomness while inserting PSPs, those experiments were repeated 100 times and average results were computed to obtain more dependable outcomes. Estimated MAEs and measured T values for both data sets are given in Table 5
                              .

As can be followed from Table 5, adding more clones has positive effects on accuracy; however, enhancements are getting smaller as ω grows. The highest accuracy values are obtained at ω
                              =5 for both data sets, being around 0.72. Also note that even if there are five times more users in the system, online performance is negligibly affected, i.e., T increases by approximately 11% (from 18s to 20s) and 7% (from 233s to 249s) in this sample case for MLP and MLM, respectively. These outcomes present the robustness of the proposed BKM model in terms of scalability.


                              Density coefficient (ρ): Cloning process aims to boost accuracy of the system. Thus, it is imperative to define effects of PSP amount to be inserted into replicated profiles. We produced PSPs like before and we held N
                              =80, ω
                              =1 while varied ρ from 0.5 to 4, which created one clone per user with ρ times much ratings. After cloning users, FBPs were produced and preprocessing steps were applied. Experiments were repeated 100 times due to randomness, as before. Estimated MAE values are given in Table 6
                              .

Inserting as much PSPs as existing ratings into clone profiles helps boosting accuracy; however, further insertions cause losing personalization and decrease accuracy. Online performance evaluation is not given in Table 6. Since ω
                              =1, for all values of ρ, the models require approximately 18 and 240s for MLP and MLM, respectively. As displayed in Table 6, ρ
                              =1 maximizes accuracy. Note that the reached maximum accuracy values of about 0.73 are higher than both CF and BKM models’ accuracy, which concludes that by combining two preprocessing methods, we can both produce more precise predictions and achieve a significant enhancement in online performance.


                              Overall comparison: After experimenting how accuracy and efficiency changes by utilizing the proposed schemes, we conducted another experiment to present a clear picture of comparison among CF, BKM, and BKM+ in terms of accuracy. We also showed the joint effects of controlling parameters. We ran all three models while varying N from 20 to 100. For BKM+ model, we set ω
                              =5 and ρ
                              =1 for both data sets because those values were verified to maximize accuracy. We presented MAE values in Fig. 5
                              .

As can be seen from Fig. 5, for both data sets and at all N values, BKM+ clearly outperforms CF scheme in terms of accuracy. We also performed statistical significance t-tests to compare the results of CF and BKM+ schemes. Overall MAE results were handled by taking average of 10-fold experimental accuracy values. A series of paired t-tests were performed for varying N values and statistics are displayed in Table 7
                              . The results of one-tailed hypotheses show that all of the differences appear to be statistically significant at 99% confidence level except for N
                              =40 in MLP, which is also significant at 95% confidence level.

After examining effects of the preprocessing schemes on non-private CF schemes and determining optimum values of parameters (ω
                           =5 and ρ
                           =1), we experimented on privacy-preserving environment. Since prediction production process in a privacy-preserving architecture is the same with non-private schemes, BDT generation step achieves the same improvements in online performance. Therefore, we do not present T values for experiments, as they are similar with non-private experimental outcomes. Also, we proceeded experiments only with BKM+ scheme in privacy-preserving parts because distinct effects of preprocessing were investigated in previous section. Privacy-preserving form of the proposed scheme (P2BKM+) was examined against the PPCF method (P2CF) in terms of accuracy. For disguising schemes, we kept standard deviation of produced random values constant because it is obvious that if such interval grows, disguising level increases and accuracy deteriorates, as shown in Fig. 4. Effects of different σ values on accuracy can be found in (Bilge & Polat, 2012b; Polat & Du, 2005). However, due to the results of (Huang, Du, Chen, 2005; Kargupta, Datta, Wang, & Sivakumar, 2003), utilizing σ
                           ⩽1 may permit recovery of original data from perturbed values. Thus, we kept σ
                           =2 in the experiments as it is appropriate to see effects of data perturbation and still provides pretty sufficient level of privacy. Nevertheless, effects of varying forgery rates (β
                           
                              max
                           ) were studied.

Data disguising protocol proposes users to choose β value uniformly randomly over (0, β
                              
                                 max
                              ] to mask genuine ratings. Effects of different β
                              
                                 max
                               levels on privacy were studied in Section 5.2.1. Now, we examine effects of this parameter on accuracy. In the experiments, N was set at 80 for both data sets while β
                              
                                 max
                               was varied from 5 to 100. Due to randomized selection of β and cells to insert PSPs by each user, the experiments were repeated 100 times and average of outcomes are demonstrated in Table 8
                              .

It is expected that β
                              
                                 max
                               is inversely correlated with accuracy. Although forged ratings deteriorates accuracy with P2CF model especially for MLP, losses are not that much for the proposed P2BKM+ scheme. Even for β
                              
                                 max
                               value of 100, accuracy losses are approximately 0.06 for MLP and 0.12 for MLM. Thus, we can infer that P2BKM+ scheme is more resistant to changes in β
                              
                                 max
                               compared to the P2CF method. Considering provided privacy levels due to maximum forgery rate discussed before, choosing a β
                              
                                 max
                               value of 20 for both data sets seems optimal because it balances the trade-off between conflicting goals accuracy and privacy for this case.

We conducted the last experiment to demonstrate a clear comparison among CF, P2CF, and P2BKM+ schemes in terms of accuracy, like we did in non-private scheme. For this purpose, we set β
                              
                                 max
                               at 20, then ran P2CF and P2BKM+ models while varying N from 20 to 100, and combined outcomes with the results of previous experiments. Estimated MAE values are presented in Fig. 6
                              .

As seen from Fig. 6, the proposed P2BKM+ scheme performs significantly better than P2CF for both data sets. We again performed paired t-tests to compare the accuracy of P2CF and P2BKM+ schemes and presented statistics for varying N values in Table 9
                              . The results of one-tailed hypotheses claim that all enhancements appear to be statistically significant at 99% confidence level.

In fact, P2BKM+ performs even better than non-private CF scheme for MLP as seen from Fig. 6a; however, these differences are not significant. Also, it can be seen from Fig. 6b that P2BKM+ performs slightly worse than CF scheme while providing privacy measures to individuals. Thus, it can be concluded that the combined effects of the proposed preprocessing schemes allow providing high quality private referrals in considerably less amount of time.

@&#CONCLUSIONS AND FUTURE WORK@&#

We proposed a novel CF scheme based on two preprocessing methods, which can be performed off-line in order to improve online performance and accuracy. In the first approach, we offered to apply a bisecting k-means clustering algorithm on item-category based histograms of users to construct a BDT and utilized it to determine neighbors of new users, which improves scalability of CF systems significantly. The second preprocessing scheme focuses on enhancing accuracy of predictions produced by the first scheme by alleviating the effects of sparseness. We proposed to replicate original user profiles and increased their density by inserting PSPs into some randomly chosen empty cells. We also proposed a scheme to solve the privacy problem of the offered schemes by utilizing RPTs. Our privacy-preserving scheme hides users’ preferences and the items they rated. We performed experimental studies to evaluate the proposed schemes using benchmark data sets. Empirical outcomes showed that employing our proposed preprocessing schemes significantly outperforms the state-of-the-art k-nearest neighbor-based PPCF scheme in terms of online performance and accuracy, as demonstrated by significance tests. Although RPTs distort original data in order to achieve privacy, they might make accuracy worse because privacy and accuracy are conflicting goals. However, relative errors due to randomization are not significant and the proposed privacy-preserving scheme is able to produce predictions with comparable accuracy to original non-private scheme. Moreover, the proposed bisecting k-means clustering approach promises much better relative improvements on online performance as input matrix gets larger, which is vital to scale CF systems.

In this study, we essentially tried to provide a different perspective on data configuration and recommendation production process. More important than observed empirical achievements, we claim that the proposed preprocessing ideas are modular and easy to manipulate, yet effective. They can be easily integrated into real life deployments by adjusting them to particular needs. In addition to user-based approach, an item-based BDT construction is also possible for online vendors marketing over diverse products.

Other than numerical ratings, CF schemes also deal with binary rating-based data obtained by market-basket analysis and web logs. We are planning to explore effects of applying the proposed approaches on implicit preference based systems, employing other clustering algorithms, and fuzzy techniques on recursive approach. Also, rather than a single tree, we are planning to employ a random forest of BDTs to further improve performance. In addition, we are considering to study on what empty cells to be filled with PSPs and to combine our proposed schemes with previously proposed CF enhancing approaches such as data reduction techniques as future research goals.

@&#ACKNOWLEDGEMENT@&#

This work is supported by TUBITAK under Grant 108E221.

@&#REFERENCES@&#


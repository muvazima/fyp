@&#MAIN-TITLE@&#Prior schemata transfer as an account for assessing the intuitive use of new technology

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An experiment is conducted for assessing the intuitive use of an interface.


                        
                        
                           
                           Intuitive use relies on the transfer of prior knowledge schemata.


                        
                        
                           
                           Familiar and new features yield distinct patterns of prior schemata transfer and of new schemata induction, respectively.


                        
                        
                           
                           Transfer and induction patterns were moderated by participants' cognitive style.


                        
                        
                           
                           Assessment of these patterns is reported for the evaluation and redesign of interfaces.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Intuitive use

Schemata theory

Transfer

@&#ABSTRACT@&#


               
               
                  New devices are considered intuitive when they allow users to transfer prior knowledge. Drawing upon fundamental psychology experiments that distinguish prior knowledge transfer from new schema induction, a procedure was specified for assessing intuitive use. This procedure was tested with 31 participants who, prior to using an on-board computer prototype, studied its screenshots in reading vs. schema induction conditions. Distinct patterns of transfer or induction resulted for features of the prototype whose functions were familiar or unfamiliar, respectively. Though moderated by participants' cognitive style, these findings demonstrated a means for quantitatively assessing transfer of prior knowledge as the operation that underlies intuitive use. Implications for interface evaluation and design, as well as potential improvements to the procedure, are discussed.
               
            

@&#INTRODUCTION@&#

Intuition is a mode of effortless thinking in which pre-existing knowledge pre-empts the analysis of new situations (Hodgkinson et al., 2008; Kahneman, 2003; Klein, 1998). In this vein, devices that fit users' prior knowledge and require little effort to use are considered ‘intuitive’ (Blackler, 2008; Hurtienne, 2009; O'Brien et al., 2012). Currently, the means for assessing device use and intuitive use as a function of prior knowledge (a.k.a. prior experience or familiarity) consist of observational analyses of participants using a test device (e.g., a digital camera) and questionnaires to assess their familiarity with technology (for an overview, see Blackler et al., 2011). Observational analysis requires usage sessions to be recorded by video so that an experimenter may manually isolate each feature use (e.g., menu, option) and assign the corresponding performances, behaviors, and verbal protocols
                        1
                     
                     
                        1
                        Verbal protocols were obtained concurrently (Blackler, 2008; Blackler et al., 2004), retrospectively (Langdon et al., 2007, 2010), or both (Lawry et al., 2010). For concurrent protocols, participants were instructed to use the device while they ‘talk aloud about what they are doing’ (Blackler, 2008, p. 298). For retrospective protocols, participants were asked to ‘describe and explain their interpretation’ of their performance while a video of their usage is played back to them (Langdon et al., 2007, p.186).
                      to a set of heuristics. A feature use is considered intuitive when it displays at least two of the following heuristics: expectedness, subjective certainty of correctness, latency, (verbalized) relevant past experience, and absence of evidenced (verbalized) reasoning (Blackler, 2008; see also Blackler et al., 2010; Gudur et al., 2013; Lawry et al., 2010). Technology familiarity questionnaires assess participants' exposure to and competence with device types both similar and different to the one being tested (Blackler et al., 2010; Hurtienne et al., 2013; Langdon et al., 2007). Such assessment revealed that features whose function or appearance is familiar from other devices tended to be used correctly, rapidly, and intuitively. Notably, Blackler et al. (2010) showed that a digital camera yielded more intuitive uses from participants who had a broad familiarity with technology, yet little experience with digital cameras, than from participants who had limited familiarity with technology, yet were familiar with digital cameras. In this sense, intuitive use seems to reflect a transfer of knowledge from familiar devices and domains onto new devices (Blackler et al., 2010; Blackler and Hurtienne, 2007; Langdon et al., 2007).

The notion of transfer deserves further consideration. First, it is evident from studies of functional fixedness (Duncker, 1945), analogical reasoning (Gentner et al., 2003; Keane, 1987) and multimedia learning (Mayer, 2001) that the availability of knowledge does not imply its transfer (for a review, see Barnett and Ceci, 2002; Bracke, 1998). Thus, the way in which prior knowledge is transferred onto new devices needs to be clarified. Second, assuming that knowledge transfer is the underlying mechanism of intuitive use, it would be pertinent to assess intuitive use in terms of the transfer itself, rather than sets of other descriptors
                        2
                     
                     
                        2
                        Examples of these sets: Evalint questionnaire (perceived effortlessness, perceived error rate, perceived achievement of goals, and perceived effort of learning; Mohs et al., 2006); QUESI questionnaire (low subjective mental workload, high perceived achievement of goals, low perceived effort of learning, high familiarity, and low perceived rate of errors; Hurtienne and Naumann, 2010); INTUI questionnaire (magical experience, effortlessness, gut feeling, and verbalizity; Ullrich and Diefenbach, 2010); and coding heuristics (expectedness, subjective certainty of correctness, latency, relevant past experience, and absence of evidenced reasoning; Blackler, 2008).
                     . To date, intuitive use is assessed through observational analyses of participants, a method that is reportedly quite time-consuming (Blackler and Hurtienne, 2007), or through surveys of participants' impressions of a device (Ullrich and Diefenbach, 2010; Mohs et al., 2006; Hurtienne and Naumann, 2010). The major disadvantage of these approaches is their subjectivity, which justifies a search for alternatives. The present study is an effort in this direction: psychology studies are reviewed as a basis for assessing knowledge transfer quantitatively. In Section 2, we argue that transfer requires abstract representations of knowledge called schemata. In Section 3, we specify an experimental procedure, along with the factors and hypotheses for assessing schemata in terms of their operations in human computer interactions (HCI). In Section 4, we detail the experiment for verifying our hypotheses, including materials and experimental conditions. In Section 5, the results of this experiment are presented and discussed. Finally, in Sections 6 and 7, we review implications and future directions of this research.

Knowledge transfer is a composite phenomenon. Of the various existing transfer mechanisms, two are directly relevant to the understanding of intuitive use: near transfer and far transfer. These mechanisms have been conceptualized in the field of analogical reasoning by means of a two-stage procedure in which participants study a source problem and its solution, and then solve a target problem. Source and target problems are formulated so as to be similar in terms of surface (near transfer) and/or means-goal structure (far transfer). Transfer is demonstrated if participants, without being told this similarity, spontaneously reuse the source to solve the target. Near transfer has been demonstrated to occur robustly. For example, participants presented with a source problem about a doctor who treats a cerebral tumor by converging low-intensity X-rays were able to transfer this convergence solution to the X-ray treatment of a stomach tumor (Gick and Holyoak, 1980). Transfer even occurred between outwardly similar yet structurally incompatible problems: participants drew superficial analogies that did not result in a conceptually relevant solution, and they repeatedly attempted to reuse the source rather than analyze the target (Holyoak and Koh, 1987; Novick, 1988). Conversely, far transfer could not be obtained between analogous problems in which structure is similar, yet surface attributes differ. For example, consider the above tumor problem presented after a source problem in which a military general converges his troops to attack a fortress (Gick and Holyoak, 1980). In such cases, even when made to summarize, memorize, or recall the source while solving the target, participants did not reuse the convergence solution, instead analyzing alternative solutions to the target (Gick and Holyoak, 1983; Spencer and Weisberg, 1986).

The fact that outward similarity promotes transfer and prevents analysis upholds design strategies that consist of replicating the appearance attributes of familiar devices and domains (see Blackler and Hurtienne, 2007). Yet as surface dissimilarity disrupts transfer, it is unclear how devices that depart from replication and skeuomorphism (for reasons of style revitalization, trademarked property, etc.) can still be intuitive. This issue of far transfer was resolved by Gick and Holyoak (1983) with a study in which participants compared, in writing, two problem instantiations of the convergence solution (e.g., the fortress problem and an analogous parade problem) before solving the tumor problem. The tumor problem was solved through transfer by nearly 90% of participants who emphasized the convergence solution in their comparisons, but by none of the participants who focused on details of the source stories in their comparisons. This finding was attributed to the induction of a schema. Schema induction requires that structure common to several instances be encoded as constant and differing attributes be encoded as variables (Gentner et al., 2003). The resulting representation (schema) can be assigned optional values and transferred to instances that are new as well as superficially different (Reeves and Weiberg, 1994).

Comparison of just two instances suffices for a new schema to be induced. Even if instances are not fully understood, knowledge gained from one aids in understanding the other (Gentner et al., 2003). Without comparison, exposure to several instances results in the formation of representations that are specific, in that they support near transfer but not far transfer (Catrambone and Holyoak, 1989; Cummins, 1992; Hintzman, 1986; Spencer and Weisberg, 1986). It takes many instances for a schema to be ‘abstracted’ without comparison. Since Reber (1969), it is known that participants who study many character strings from an artificial grammar become able to classify new target strings based on this grammar. The knowledge hence acquired is implicit, as participants fail to explain their judgments or recognize previously studied source strings. Debate occurred as to whether such transfer was due to a schema being abstracted (Reber, 1989; Reber and Allen, 1978) or fragments of the source strings being memorized. Compelling evidence in favor of schema abstraction includes demonstrations of far transfer whereby participants classified strings composed of new letters, and even new stimuli such as aural tones, based on the grammar (Altmann et al., 1995; Gomez, 1997; Kürten et al., 2012; Reber, 1969). Studies from analogical reasoning and implicit learning established the key role of schemata in the transfer of knowledge from known contexts and domains to new ones. Likewise, we posit that schemata mediate the transfer of knowledge onto devices that are new-to-innovative.

Many aspects of intuitive use resemble the schema construct. Intuitive use has been described as an application of well-learned knowledge or existing skills that result in chunking, grouping of actions, or automated procedures (Langdon et al., 2007; Lawry et al., 2010; Raskin, 1994). Psychological accounts of expert thinking have established that schemata result in a chunking of information that working memory processes automatically and effortlessly (Chase and Simon, 1973; Chi et al., 1981, 1982; Ericsson and Kintsch, 1995; Gobet et al., 2001; Larkin et al., 1980; Saling and Phillips, 2007; Shiffrin and Schneider, 1977). Intuitive use has also been described as the unconscious application or transfer of knowledge across devices and domains (Blackler et al., 2010; Langdon et al., 2007; Raskin, 1994). In psychological accounts of reasoning, schemata designate abstract knowledge structures that mediate far transfer and allow the unconscious anticipation of an indefinitely large number of situations (Gentner et al., 2003; Gick and Holyoak, 1983; Neisser, 1976).

Some accounts of intuitive use have attempted to connect the application of knowledge across devices to either transfer or schemata. According to Blackler and Hurtienne (2007), intuitive interaction ‘at its most complex’ requires that ‘completely new concepts or functions’ be explained through metaphors (p. 39). They posited, in reference to Holyoak (1991), that metaphors allow an analogical mapping of known sources and new target situations. However, it should be noted that analogical mapping (a.k.a. ‘metaphor-based reasoning’ or ‘far transfer’) could not be explained before being connected to the schema construct by Gick and Holyoak (1983). Hurtienne (2009) conceptualized intuitive use in terms of sensorimotor knowledge abstractions called image schemas. Yet Hurtienne et al. (2013) hypothesized that device first-usage should reflect a knowledge that is specific (from similar devices) rather than abstract (from other devices). In the first case, users would possess the skills required to operate the device, and in the latter the amount of transferrable interaction knowledge would be less. This hypothesis was tested by decomposing prior knowledge in terms of competency and prior exposure, at levels of high vs. medium vs. low specificity (i.e., for products similar to the one tested vs. computer-related activities vs. other interactive devices). The largest impact was found to be from medium specificity, meaning that knowledge transfer accompanying first usage was not specific, but rather necessitated a degree of abstractedness. It is also important to note that competency scores were more explanatory than prior exposure scores. This finding suggests that prior exposure questionnaires may not be that relevant for addressing the abstractedness of prior knowledge, which we discuss below.

On another occasion, Blackler et al. (2010) chose not to switch from the phrase ‘intuitive interaction’ to ‘transfer’, arguing that the former ‘adds a further dimension than simple knowledge transfer or prior experience – that of non-conscious or implicit knowledge’ (p. 75). However, transfer falls under so-called implicit memory effects (Hintzman, 1990; Richardson-Klavehn and Bjork, 1988; Roediger et al., 1993). In psychology there is a major distinction between direct (a.k.a. ‘explicit’ or ‘episodic’) and indirect (a.k.a. ‘implicit’ or ‘incidental’) memory tests. Direct memory tests (e.g., recall, recognition) ask participants about their past and measure their ability to discriminate between old and new facts. Indirect memory tests (e.g., priming, implicit grammar learning, transfer-based problem solving) engage participants in a cognitive task with no given reference to their past, and measure changes in task performance as a function of prior study. Direct and indirect memory tests display dissociations between their respectively measured episodic and transfer performances. Analogical reasoning and multimedia learning studies showed that participants who read source contents demonstrated good detail recall, yet failed far-transfer tests. Conversely, participants who compared source contents and induced a common schema recalled fewer source details, yet solved far tasks by transfer (Gick and Holyoak, 1983; Gentner et al., 1993; Mayer, 1980). In implicit learning, as participants abstracted underlying grammar schema, their ability to categorize new strings increased while their recognition of studied strings decreased (Reber, 1969, 1989). Such dissociations discredit the adequacy of basic recognition- and recall-based questionnaires for measuring abstract knowledge. Likewise, this may explain why Langdon et al. (2010) did not find the relationship expected between the usage of a microwave oven and a familiarity questionnaire involving recognition of feature labels and positions. Altogether, previous accounts of intuitive use have overlooked the evidence suggesting that far transfer is a memory effect that is implicit when based on schemata.

The transfer of schemata across domains suggests that intuitive use can involve schemata from domains other than technology. From this perspective, technological-familiarity questionnaires (Blackler et al., 2010; Hurtienne et al., 2013) cannot fully capture the knowledge responsible for intuitive use because their scope would need to be extended to cover all possible knowledge domains. Schemata exist at all levels of abstraction (Rumelhart and Ortony, 1977), and various sub-theories of the schema construct have been substantiated in psychology (e.g., theories of scripts; Shanks and Abelson, 1977). One such theory, called ‘image schemas’, has recently been applied to design (Loeffler et al., 2013). Previously, Hurtienne (2009) posited that, because they are sensorimotor, universal, and hold higher-order metaphorical extensions, image schemas endorse intuitive use on a broader scale than specialized higher-order schemata (e.g., scripts). An inventory called ISCAT
                           3
                        
                        
                           3
                           Available on January 2014 at http://iscat.stefciu.de/.
                         (Image Schema CATalog; Hurtienne, 2009) was developed that links 45 image schemas (e.g., up/down) to 255 metaphorical extensions (e.g., ‘up’ is ‘more’), 197 user interfaces, and 622 instances of image schemas. An ‘image schema expert’ would code users' verbal protocols in terms of image schemas, which are then fed into design improvements (see the IBIS method, named after the German phrase for design of intuitive use with image schemas; Loeffler et al., 2013). However, Hurtienne (2009) observed confusion in the coding of co-occurring image schemas. This presents a difficulty, since schemata fundamentally embed one within another (Rumelhart and Ortony, 1977). While image schemas can improve the intuitive use of sensorimotor design elements (e.g., vertical sliders), there remains the more pressing issue of creating higher design levels (e.g., technical, technological). Yet in a review of 77 papers regarding design abstractions, Hurtienne and Blessing (2007) found that one quarter related to the sensorimotor while the rest related to higher-order abstractions such as culture and expertise. We believe that human activity is specified at such higher levels, and that higher-order schemata (e.g., scripts, skills) override the processing of lower-order schemata (e.g., image schemas) through embedding and chunking (Rumelhart and Norman, 1981; Rumelhart and Ortony, 1977). While schemata are too numerous to be inventoried, their impact on user behavior can nevertheless be assessed through transfer-type tests. The following sections formulate operations of schemata in HCI as a basis for measuring their transfer.

Most modern technologies are interfaced through digital screens or displays. Technological features are typically implemented as icons and labels that are grouped into states. A state corresponds to the distinct collection of features displayed on a screen at any given time (see Figs. 1 and 2
                        
                         for examples). As long as a desired feature (goal) is not displayed in the current state, users must move from state to state until the desired feature is found. The distance between the current and goal states is reduced through iterative means-end analyses (Newell, 1980), whereby users judge which of the current state's features (e.g., menu entry) best matches the goal. Typically, users perceive and interpret a current state, determine the feature closest to the goal, and then command its execution (Norman and Draper, 1986).

Means-end analysis entails multiple comparisons whose cost and outcomes reflect the compatibility of a state's attributes with prior schemata (see schema theory and its repercussions on cognitive load theory; Chi et al., 1982). Attributes compatible with prior schemata are processed effortlessly through transfer (Chalmers, 2003; Kalyuga et al., 2001). Processing is moderately consuming when prior schemata must be amended, and highly consuming when new schemata must be induced (Chalmers, 2003; Rumelhart and Norman, 1978). This latter operation is difficult to achieve with the few resources left over from means-end analysis (Sweller, 1988, 1994; Sweller and Levine, 1982; Van Gerven et al., 2002), meaning that states for which users should induce new schemata remain resource-demanding at later encounters (Tuovinen and Sweller, 1997). Schemata operations can therefore serve as a criterion for differentiating states deemed intuitive, in that prior schemata transfer suffices, from those detrimental to intuitive use, in that new schemata must be induced (Fischer et al., 2009; Fischer, 2010).

Here the question arises: how can transfer and induction be assessed? In HCI, it is customary to translate cognitive constructs into heuristics. Heuristics are inherently qualitative, however, which represents a methodological drawback that the field of psychology attempts to overcome experimentally. Some have expressed doubt that operationalization of isolated processes from psychology may capture said processes' integration in HCI (Newell, 1990). Consider, though, how other fields proceed: the human body is an integrated system, yet physicians ultimately apply component techniques from physiology, pharmacology, and so on. In this vein, it is logical that operationalization of transfer and induction from psychology be considered for characterizing such operations in HCI. Another classic criticism from HCI is that laboratory tasks and materials in psychology do not translate to HCI (Newell and Card, 1985). Such a presumption should be examined through applied research that probes the validity of psychology experiments beyond their initial scope and outlines their translation to HCI.

We now examine transfer experiments as a means of assessing intuitive use. Because such experiments typically begin with a study phase, Blackler (2008) has cautioned that the assessed transfer originates from this study phase and not from prior knowledge. Prior knowledge, though, has been controlled in various transfer studies from multimedia learning. Namely, source material is studied by participants with high vs. low knowledge, in learning vs. control conditions, before they solve target tasks. These experimental settings reveal a factor interaction between learning and prior knowledge that is robust: while participants with low knowledge display better target performances in learning than in control conditions, those with high knowledge display equally good performances in both conditions. For example, Peper and Mayer (1986) showed that participants required to take notes while learning an unfamiliar topic were more successful at far transfer problems than participants required only to listen. However, participants familiar with the topic performed equally well in both cases. Similarly, while inexperienced trainees benefited from learning instructions, this advantage disappeared as they gained experience in the domain (Kalyuga et al., 1998, 2000, 2001; Mayer, 2001; Tuovinen and Sweller, 1999). Therefore, one can distinguish between transfer and induction by manipulating schema induction (e.g., induction vs. control study conditions) in a transfer experiment. A pattern of equally good target performances in induction and control conditions indicates that participants' prior schemata sufficed and were transferred. A pattern of improved target performances in induction conditions indicates that participants had to induce new schemata. These patterns, which we call transfer and induction, respectively, should also occur when schema induction is manipulated for an interface consisting of familiar and unfamiliar features.

Schema induction is typically not manipulated for materials such as interfaces. However, Mayer (1980) conducted the following series of transfer experiments to outline the induction of schemata relative to the programming of a system. Novices studied nine source commands for database management (e.g., LIST, FOR, AND) from a manual, then used these commands to write target programs. Target programs involved either near or far transfer, depending on whether or not their instructions hinted at the source commands (e.g., ‘LIST the owners FOR all cars weighing more than … ’ vs. ‘find the percentage of cars weighing more than … ’). A control group was required to read the manual. A comparison group was required to write down comparisons of the manual's commands (e.g., ‘how is FOR similar to LIST?’). This group outperformed the control group in writing near-transfer programs. A comparison-plus-elaboration group was required to write down comparisons between each command and a concrete situation supporting elaboration (e.g., ‘how does the COUNT command relate to a basket filled with records?’). This group outperformed the former two in the writing of near and far transfer programs, meaning that comparison and elaboration of new commands resulted in the induction of more versatile schemata. With a few adjustments, we generalized this principle to the induction of interface schemata.


                        Mayer (1980) required that participants study commands from the pages of a manual prior to using these commands to write programs. Similarly, one can capture screenshots of the states of an interface and require participants to study them and the features they display prior to using the interface. Following Mayer's findings, the induction group should study the source screenshots through written comparison and elaboration. Although writing is appropriate in multimedia learning studies that tend to emulate educational settings, it is not appropriate in HCI settings that strive to emulate usage behaviors. Users perform comparisons incidentally when they judge the features of a current state against a goal (i.e. means-end analysis). Thus, we emulated comparison through matching judgments, where participants are presented with a clue, then the screenshot of a state, and must judge whether they match (see Fig. 4
                        
                        ).

Participants tend to encode source attributes indicated by a clue (Gentner et al., 2003). Thus, the clue allows creation of versions of clue-screenshot matching that tap a desired level of attribute encoding. Blackler et al. (2010) showed that intuitive use is upheld by feature appearance (e.g., symbols, labels) and function (e.g., role on the interface). Accordingly, one can specify two types of clue: word clues, which consist of single words, and function clues, which are sentences that describe, in terms of a concrete task, a function common to two of the screenshot's features. Consider the smart phone screenshot in Fig. 1 (given for illustrative purposes; see Fig. 2 for a screenshot of our test interface).

A word clue such as ‘Mail’ would be a match (appears in the screenshot), whereas a word clue such as ‘Notification’ would be a mismatch. A function clue such as ‘Change of notification mode for your incoming messages’ would be a match (corresponds to the functions in the screenshot), whereas a function clue such as ‘Check your inbox for new messages’ would be a mismatch. Function clues differ from the words appearing in the screenshot (e.g., ‘message’ instead of ‘mail’), and the task they describe relates two features (i.e. ‘Mail’ and ‘Settings’).

Now consider two groups of participants, each of whom study all possible state screenshots of the smart phone depicted in Fig. 1. A reading group performs ’word matching‘ judgments by matching screenshots with word clues. Word matching requires that screenshots be encoded rather lexically, meaning that function need not be understood. Thus, members of the reading group are not likely to update their prior schemata for functions of the phone that are new
                           4
                        
                        
                           4
                           Given that new schemata are not induced when sources are read for comprehension (Gick and Holyoak, 1983; Mayer, 1980), they would not be induced when features are encoded at a rather lexical level.
                        . Similarly, an induction group performs ’function matching’ judgments by matching screenshots with function clues. Function matching causes function attributes from the screenshots being interpreted with respect to the clues (comparison), until the relationship and concrete task depicted by the clue (comparison plus elaboration) are identified. The induction group should thereby induce schemata for functions of the phone that are new to them. At this point, the groups differ strictly in terms of the schemata at their disposal for interpreting the smart phone: prior schemata for the reading group, and newly induced schemata for the induction group. Both groups then complete a target task scenario involving some selection of the smart phone's features
                           5
                        
                        
                           5
                           Such usage scenarios are plotted at the experimenter’s discretion. In Mayer (1980), comparison and elaboration indeed enabled participants to write near and far programs, respectively. Similarly, function matching – because it combines elaboration and comparison- should enable participants to translate the smart phone’s features into near and far usage tasks alike. Thus, in principle, the experimenter is free to specify the usage scenario deemed relevant for evaluating the test interface.
                        . In terms of performance, states with previously unfamiliar functions would yield an induction pattern, with more means-end analysis errors committed by the reading group, while states with familiar functions would yield a transfer pattern, with equally few means-end analysis errors committed by both groups.

Intuitive use has been shown to depend on prior usage of other devices (Blackler, 2008; Hurtienne et al., 2013). Thus, if transfer underlies intuitive use, prior usage should yield a transfer pattern. Furthermore, intuitive use can be considered to reflect knowledge from other domains (see Section 2.2), which would also result in a transfer pattern. A familiarity questionnaire can address this by asking whether each feature of a test interface has been used in another device (used), has never been used yet its function is known from other domains (cognized), or is not known at all (new). Cognized features are those features whose function is familiar from any activity domain that comes to mind. For example, while a feature labeled ‘sort by key’ may never have been used, its function may still be ‘cognized’ through prior knowledge of ‘sorting’ and music. Used—and likely cognized—features should yield a transfer pattern, whereas new features should yield an induction pattern.

Since use of an interface involves comparison of each state encountered with a goal (viz. means-end analysis), users may benefit from familiarity of not only the current state but also the goal. As the goal of a target task is to find and use a certain feature, and the familiarity of each feature is determined by the aforementioned questionnaire, we correspondingly assigned familiarity of the goal as used, cognized, or new. This goal familiarity factor was examined at an exploratory level.

Previous work on intuitive use has assumed that, like intuition, intuitive use is available to all and does not depend on personality type (Bastick, 2003; Blackler, 2008; Blackler et al., 2010). Antle et al. (2009) observed the contrary, albeit fortuitously. Their study compared two versions of a responsive audio system. One version, which implemented image schemas (e.g., ‘more’ is ‘louder’), should have met the requirements for intuitive interaction. The other version conflicted with such schemas and required participants to analyze the system's functioning. The results, however, were less clear-cut: many participants did not follow their intuitions, regardless of the system version, and instead strove to interact with both systems ‘analytically’. Antle et al. (2009) thus raised concern over the fact that users may differ in their willingness to approach new systems through either intuition or analysis.

It is well substantiated that, independent of task familiarity or demand, people differ in their haste to follow intuition or engage in effortful analysis (Epstein and Pacini, 1999; Kahneman, 2003). This difference can be considered a cognitive style, since performances for explicit tasks, such as judgment and problem-solving - both prominent in the use of a new device - are affected (Langan-Fox and Shirley, 2003; Reber and Walkenfeld, 1991). Performance of implicit tasks designed to objectify intuition (e.g., artificial grammar learning, accumulation clue task) can also be affected to some extent (Kaufman et al., 2010; Pretz et al., 2010). These studies employed the Rational-Experiential Inventory (REI; Pacini and Epstein, 1999; for validation aspects, see also Pretz and Totz, 2007). This self-assessment tool comprises 20 experiential statements that address ability and preference for intuition, and 20 rational statements that address ability and preference for analysis. In contrast to experiential scores, rational scores are associated with the personality trait of conscientiousness, which encompasses deliberation, carefulness, and attentiveness to norms and rules (Pacini and Epstein, 1999). Compared to individuals with high experiential scores (called Experientials), individuals with high rational scores (called Rationals) tend to perform more slowly, exhibit better decision-making skills in problems of logic and mathematics, and are less sensitive to stereotypes, beliefs, and heuristic biases (Shiloh et al., 2002; Witteman et al., 2009).


                           Reber et al. (2007) examined the role of cognitive style in solving state-transformation problems. Their study employed Accumulated Clue Tasks (ACT), in which participants read 15 sequential clue words (e.g., science, gas, …, war, bang) that increasingly relate to a solution word (e.g., explosion). After each clue, participants proposed a hypothesis word and guessed its proximity to the solution on a scale of 1–10. When a hypothesis word rated as ‘10’ matched the solution, the ACT was deemed successful. Analytical thinking was measured by the number of clues a participant studied before rating a hypothesis word as ‘10’. Implicit knowledge was measured as the number of hypothesis words closer to the solution than the participant's rating (for details, see Reber et al., 2007). This study showed positive correlations among ACT performances, analytical thinking, and conscientiousness as measured by the NEO Five Factors Inventory (McCrae and Costa, 1987). These three variables showed negative correlation with experiential scores measured by the REI, and no correlation with implicit knowledge. Reber et al. concluded that state-transformation problems formulated to entail implicit knowledge nevertheless expressed individual differences: people who relied on intuition made quicker decisions, considered fewer clues, and performed poorly compared to those who analyzed. This may be an issue for reducing intuitive use to prior familiarity and for operationalizing schema induction through function matching. In the latter case, if Experientials do not sufficiently compare a function clue to the screenshot, they will induce fewer schemata and display less-pronounced induction patterns than Rationals. This motivated us to control participants' cognitive style with the REI, and examine this factor at an exploratory level.

We conducted an experiment to investigate the effects and interactions of schema induction, feature familiarity, goal familiarity, and cognitive style on usage performances. As users advance through an interface, states for which means-end analysis is correct tend to be explored once. States for which means-end analysis is incorrect tend to be re-explored, as users return to try other features. This dependent variable, which we call state exploration, represents the number of times a participant explored an interface state while searching for a goal (i.e., per target usage task).

Schema induction and feature familiarity were examined in a hypothetico-deductive manner. By transposing previous interactions of learning and prior knowledge (see Section 3.1) to the role of feature familiarity in intuitive use (see Section 3.3.1), we expected that:
                              
                                 •
                                 new features would yield more state explorations for the reading group compared to the induction group (induction pattern), and

features that are used or cognized would result in equally few state explorations for both groups (transfer pattern).

Goal familiarity and cognitive style were controlled for exploratory purposes.

Thirty-one Japanese students, aged 18–25 years (mean = 21.9 years), were selected at the University of Tsukuba in Japan based on the following survey criteria: they possessed a driver's license, did not major in computer science or engineering, had no prior experience with on-board computers or GPS navigation systems, and were familiar with computers and phones. Each participant received 820 yen (approximately $9.00) as compensation for attending a 45-min experiment. Although presented here in English, all materials were written and administered in Japanese. The experiment used a mixed factorial design (Table 1
                        ).

The between-subjects factors were cognitive style (2) and schema induction (2). The within-subjects factors were feature familiarity (3) and goal familiarity (3). The dependent variable, state exploration, was averaged per participant and target task.

The tested interface was a prototype of an on-board computer called DoIT#, which we developed in C#. This prototype is a continuation of an earlier version based on automotive reviews (Floudas et al., 2004) and technology blogs (for details see Fischer, 2010). DoIT# contains approximately 160 features (e.g., menu entries, options) gathered into 75 states and grouped into five technology domains: Audio, Air conditioning, Navigation, On-board computer, and Telephone. Feature functions ranged from common (e.g., dial a number, defrost the windshield) to speculative (e.g., wireless retrieval of billboard advertisements). DoIT# was interfaced with a state window and command panel (see Fig. 2).

Participants navigated through DoIT#’s states by clicking on the command panel with a mouse. The buttons labeled ‘Audio’, ‘Phone’, ‘GPS’, ‘AirCon’, and ‘Computer’ allow direct access to the corresponding technology domain. Participants could scroll through the list of features by using the ‘UP’ and ‘DOWN’ buttons. The ‘ENTER’ and ‘ESC’ buttons could be used to display the state of a feature and return to the previous state, respectively.

Command clicks (e.g., ENTER, ESC) were recorded in a log file as raw data and later formatted to calculate state exploration by means of a tool kit called AMME (Automatic Mental Model Evaluation; Rauterberg, 1993). Using an interface description
                           6
                        
                        
                           6
                           Description of the interface is contained in a text file listing its states, commands, and state-command-state triplets. Details available on January 2014 at http://www.idemployee.id.tue.nl/g.w.m.rauterberg/amme.html.
                        , AMME automatically formats observable actions collected by the log file into a network description, a set of complexity metrics, and a state matrix. Though Rauterberg provided these three outputs as indicators of mental model, navigation strategy, and solving performance, respectively, only the state matrix output was employed in our study. This output was formatted with complementary VBA (Visual Basic for Applications) macros that counted the number of times each state had been explored per participant and usage task.

Participants' cognitive style was characterized according to a Japanese translation of the REI (Naitou et al., 2004). The inventory comprised twenty experiential-oriented and twenty rational-oriented statements. Examples of experiential-oriented statements are ‘I believe in trusting my hunches’, ‘Using my gut feelings works well for me in figuring out problems in my life’. Examples of rational-oriented statements are ‘I enjoy thinking in abstract terms’, ‘I think that it is foolish to make important decisions based on feelings’.

Although the REI is typically administered via paper and pencil, we administered it electronically so that participants' scores could be calculated in real-time. Additionally, electronic administration can limit desirability bias such as reluctance to report socially demeaning traits (e.g., being ‘absolutely not good at figuring out complicated problems’). Fox and Schwartz (2002) showed that such bias is attenuated when questionnaires are administered electronically, the order of statements is randomized, or respondents are prevented from adjusting their ratings based on previous responses. Accordingly, the REI was implemented in an Excel template that presented statements in random order and faded out each one immediately after it was rated (Fig. 3).

Participants rated each statement of the REI from 1 (completely false) to 5 (completely true). This scale was reversed for experiential ratings, and individual scores were calculated by summing the forty ratings. Participants scoring above 120 were assigned alternately to word or function matching, meaning either the reading or induction group, and likewise for those scoring under 120. Actual cognitive styles were assigned during data analysis (see Section 5) after the median score for all participants had been calculated.

Screenshots of DoIT#’s 75 states were arbitrarily placed into two (equivalent) subsets and studied in either matching or mismatching trials. For matching trials, one feature was randomly selected from each screenshot (e.g., ‘driving indices’ in Fig. 4). Word clues corresponded to a single word chosen from the label of each selected feature. Function clues consisted of a sentence that described, in plain terms and as a concrete task, a function common to the selected feature and another feature in the screenshot. For mismatching trials, the word clues corresponded to any word that did not appear in the screenshot, while the function clues corresponded to a function that slightly mismatched those of screenshot's features. Function clues were formulated using a thesaurus and an automotive dictionary, and were then revised by two proofreaders who rephrased any term they found too technical.

A Labview module was employed that display a clue for 15 s, or until the participants clicked ‘GO’. The screenshot to be matched was then similarly displayed for 15 s, or until the participants clicked either ‘YES’ or ‘NO’. Fig. 4 illustrates a word-matching trial. To begin the trial, participants read the clue (i.e. ‘Indices’) then clicked ‘GO’ in order to display the screenshot to be matched. Participants responded with either ‘YES’ or ‘NO’, depending on whether or not they found the word clue in the screenshot.

A function-matching trial resembles the word-matching trial depicted in Fig. 4, except in place of the word clue (‘Indices’) would be a function clue (e.g., ‘Display the average speed’). Participants would respond with either ‘YES’ or ‘NO’, depending on whether they find the function relationship that matches the clue in the screenshot. In order to avoid bias from their ordering, the 75 clue-screenshot trials were placed into two random orders that were counterbalanced from one participant to the next.

The usage phase entailed ten tasks, which we attempted to word differently from DoIT#’s labels whenever possible: (1) display the number of kilometers traveled, (2) request the route to the house of a friend whose contact information is in the address book, (3) request a route that avoids tolls, (4) display the navigation directions in the rear-view mirror, (5) set the temperature to 18 °C, (6) activate sleeping alert, (7) activate assistance for passing cars, (8) activate the internal air filter, (9) set the ventilation to silent mode, and (10) calculate rest time during the trip. Tasks were printed on separate pages of a handout.

The labels of DoIT#'s features were copied into the same Excel template used for the REI (Fig. 5
                           ). Participants selected either ‘used’ for features they had used in another device, or ‘cognized’ for features they knew from any other context. Features that were new were left unselected. The responses provided a basis for coding the main feature of each state explored during the usage phase, along with the goal of each target task, as used, cognized, or new to the participants.

@&#PROCEDURE@&#

The REI, familiarity questionnaire, DoIT#, and animated instructions for the experiment were embedded in a PowerPoint slideshow that participants browsed at their own pace. This self-directed administration permitted the experimenter to test several participants simultaneously. The test room contained three desks equipped with a PC, pencils, and paper. The desks were placed about 4 m from each other. Opaque panels were installed between each desk, and participants were given noise-canceling headphones to prevent them from hearing each other's progress. The study was presented to the participants as an evaluation campaign for the prototype of an on-board computer. Participants were encouraged to proceed at any pace they found comfortable. No achievement feedback was given and no performance requirements (e.g., being fast, avoiding errors) were enforced.

Following a welcome message and instructions, participants completed the REI. The slideshow resumed with an animation that illustrated either the word- or function-matching study conditions. Once their study phase was completed, participants were instructed to write down the names of at least three videogames, TV programs, cartoon characters, and foods that came to mind. This categorical fluency task aimed to prevent recency effects. The slideshow then resumed with a description of DoIT#’s command panel. The experimenter interacted individually with each participant and demonstrated two basic usage tasks (call a recently dialed number and check inbox messages). The experimenter also provided the handout that listed the target tasks. Participants were instructed to start with the first target task and click on the command panel button labeled ‘Task Completed’ once they reached the corresponding goal feature in DoIT# (Fig. 2). This action triggered a pop-up message instructing participants to proceed to the next task. Participants could call the experimenter whenever they felt stuck at a task. To avoid bias, the experimenter noted the task and directed the participant to the next task. Tasks aborted, as well as those not correctly solved, were excluded from analysis. After the tenth task, the slideshow resumed with the familiarity questionnaire, which participants completed in the same way as the REI.

@&#RESULTS@&#

Participants' REI scores ranged from 34 to 156, with an average of 113.1 and median of 121.5. The 13 participants who scored under the median were coded as Experientials (reading group = 7, induction group = 6), while the 18 participants who scored above the median were coded as Rationals (reading group = 10, induction group = 8). According to the familiarity questionnaire, 61.27% of DoIT#’s features were new to participants, 18.53% were cognized, and 20.20% were used. Regarding target tasks, 69.11% were new to participants, 16.36% were cognized, and 14.52% were used. The percentages of used, cognized, and new features did not differ significantly by schema induction, χ
                     2(2, N = 863) = 5.577, ns, or cognitive style, χ
                     2(2, N = 863) = 3.641, ns. The percentages of used, cognized, and new goals did not differ significantly by schema induction, χ
                     2(2, N = 310) = .793, ns, or cognitive style, χ
                     2(2, N = 310) = 2.128, ns.

State exploration was subjected to a 2 × 2 × 3 × 3 ANOVA. As Levene's tests (all F(3, 27) ≤ 2.586, p ≥ .74) and Mauchly's tests (all p ≥ .064) were non-significant, variance homogeneity and sphericity were assumed, respectively. Therefore, an alpha level of .05 was used for the ANOVA, which revealed a significant effect of goal familiarity, F(2, 54) = 6.595, p = .003 (ηp² = .196). A Bonferroni post-hoc test showed that participants made more state explorations for target tasks whose goal was new, compared to cognized (p = .012) and used (p = .009). The pairwise comparison between cognized and used goals was non-significant. Feature familiarity, F(2, 54) = 2.903, p = .063 (ηp² = .097, power = .544), schema induction, F(1, 27) = 2.341, p = .138 (ηp² = .080, power = .314), and cognitive style, F(1, 27) = .390, p = .537 (ηp² = .014, power = .093), did not reach significance. The significant interactions between these factors are reported below.

The interaction of schema induction and feature familiarity (Fig. 6
                        ) was significant, F(2, 54) = 3.364, p = .042 (ηp² = .109).

Since the central question of the experiment concerns the effect of schema induction, we examined the simple effects of schema induction at each level of feature familiarity. Schema induction was significant for new features, F(1, 27) = 13.484, p = .001 (ηp² = .333), with fewer state explorations for the induction group than for the reading group. This finding is characteristic of the induction pattern. Schema induction did not reach significance for cognized features, F(1, 27) = .012, p = .914 (ηp² = .000, power = .051) or for used features, F(1, 27) = .029, p = .867 (ηp² = .001, power = .054). The absence of a significant difference between the reading and induction groups supports the transfer pattern discussed Section 3.1.

The interaction between feature familiarity, schema induction, and cognitive style (see Fig. 7
                        ) yielded an F-ratio of F(2, 54) = 3.237, p = .047 (ηp² = .107). Simple effects of schema induction were analyzed for each combination of feature familiarity and cognitive style in order to screen the induction and transfer patterns pertaining to this interaction. For Rationals, schema induction was significant for new features, F(1, 27) = 4.654, p = .040 (η
                        p² = .147), with an induction pattern of fewer state explorations from the induction group than from the reading group. Transfer patterns occurred as expected, since Rationals displayed no significant effect of schema induction for cognized, F(1, 27) = .308, p = .583 (η
                        p² = .011; power = .087) or used features, F(1, 27) = .152, p = .700 (η
                        p² = .006, power = .066). Experientials did not exhibit any effect of schema induction, regardless of whether features were new, F(1, 27) = .628, p = .435 (η
                        p² = .023, power = .103), cognized, F(1, 27) = .156, p = .696 (η
                        p² = .006, power = .069), or used, F(1, 27) = .685, p = .415 (η
                        p² = .025, power = .126). The two latter outcomes resulted in a small effect size, yet insufficient power to exclude the possibility of a Type II error. Altogether, the three-way interaction was such that only Rationals exhibited the expected transfer and induction patterns.

The interaction between feature familiarity and goal familiarity (see Fig. 8
                        ) yielded an F-ratio of F(4, 108) = 4.427, p = .002 (η
                        p² = .141). Separate ANOVAs for each level of goal familiarity revealed no significance of feature familiarity when the goal was new, F(2, 26) = 1.384, p = .269 (η
                        p² = .096, power = .270). The effect size associated with this finding was moderate, though, and power was insufficient to reject a possibility of Type-II error. Feature familiarity had a significant effect when the goal was cognized, F(2, 26) = 5.973, p = .007 (η
                        p² = .315). A Bonferroni post-hoc test indicated significantly fewer state explorations for used features than for new (p = .005) or cognized ones (p = .017). The pairwise comparison of new features with cognized ones was non-significant. Feature familiarity had a significant effect when the goal was used, F(2, 26) = 6.801, p = .004 (η
                        p² = .343). A Bonferroni post-hoc test showed that there were significantly fewer state explorations for cognized features than for new (p = .003) or used ones (p = .002). The pairwise comparison of new features with used ones was non-significant. Altogether, while familiar features were processed by transfer of prior schemata, their means-end analysis ultimately depended on goal familiarity. When a goal was new, feature familiarity improved usage performance tendentially, yet not significantly. When the goal was familiar, the effect of feature familiarity on state exploration proved to be more elaborate. Participants seemed inclined toward cognized features when the goal was cognized, and toward used features when the goal was used. This was confirmed by conducting follow-up ANOVAs for only the cognized and used levels of feature by goal familiarity. When their goal was cognized, participants made more explorations toward cognized features than used ones, F(1,30) = 8.061, p = .008 (η
                        p² = .212), and vice versa when the goal was used, F(1,30) = 13.192, p = .001 (η
                        p² = .305). In other words, participants responded to familiarity by tailoring their means-end analyses toward the features with familiarity levels similar to the pursued goal.

@&#DISCUSSION@&#

We conducted this study to verify the interaction of schema induction with a primary factor of intuitive use, namely feature familiarity. As expected, schema induction improved state explorations for new features (induction pattern) and not for familiar ones (transfer pattern). This finding confirms that function matching supports the induction of new schemata. Previous studies from analogical reasoning (Gick and Holyoak, 1983) and multimedia learning (Mayer, 1980) found that instance comparison supports new schema induction. Our study examined one application of this finding by generalizing it in three respects. First, while the aforementioned studies involved written comparisons, we obtained schema induction with comparisons elicited through incidental yes/no judgments. Second, while sources typically included solutions and explanations, schema induction was obtained with features whose labels were concise and offered little explanation. Third, compared to just a few sources, the inductive potential of comparison proved sufficiently robust for the approximately 160 features grouped into 75 states. Regarding intuitive use, we found that features used in other devices and features whose functions were cognized from other domains yielded transfer patterns. In other words, transfer seemed to be addressed in its broadest scope, meaning not only across devices but also across domains. This finding substantiates the argument, developed in Sections 2.1–2.2, that transfer requires knowledge that is abstract rather than domain-specific, and thus intuitive use is not reducible to technological familiarity or device exposure.

Cognitive style and goal familiarity were involved in interactions whose simple effects could not be fully interpreted due to insufficient statistical power. We controlled these factors for exploratory purposes, meaning that in the future they should be re-examined with specific hypotheses and sensitive experimental designs. Concerning cognitive style, the interaction of schema induction and feature familiarity was qualified by a three-way interaction in which only Rationals exhibited induction and transfer patterns. Statistical power was insufficient to interpret the results for Experientials. Studies involving judgment and problem solving have already established that, compared to Rationals, Experientials tend to take less information into account (Epstein, 2008; Epstein and Pacini, 1999; Reber et al., 2007; Stanovich and West, 2000). The fact that we enforced no performance requirements may have reinforced this tendency. Typically, the amount and type of encoding achieved by participants can be verified with an explicit memory test (e.g., recognition, Fischer, 2010). In any case, instructing participants to answer rationally may suffice in yielding more rational behavior. Ferreira et al. (2006) selectively increased rational responses (i.e., the rate of heuristic responses was unchanged) by telling participants they would participate in a study on rationality and should base their answers on reflective thinking, as opposed to telling the participants they would participate in a study on intuition and should follow their sensibilities. Similarly, Nisbett et al. (1983) found that providing participants with the analytical requirements of a judgment task selectively increased rational answers. Altogether, our results for Experientials could be further addressed with an explicit memory test and, if necessary, corrected by emphasizing the analytical aspects of function matching.

We found a main effect of goal familiarity that was qualified by a two-way interaction with feature familiarity. This examination of feature familiarity against goal familiarity is unprecedented. Blackler (2008, p. 125; see also Blackler et al., 2010) coded as ‘intuitive’ feature uses that were correct (‘participants knew what they wanted to do and used the right feature to do it’) regardless of their appropriateness for the goal (using this feature could be ‘the wrong thing to do at that moment’ or not ‘required’ for the pending task). This coding does not reveal whether familiar features, beyond their local intuitive use, effectively guide users from start to goal completion (O’Brien et al., 2010). Here, we confirmed that schemata operations underlying state exploration are determined by feature familiarity. Yet by controlling for goal familiarity, we found that state exploration was degraded by novelty of the goal. In this case, and in particular for hidden information architectures such as that of DoIT#, feature familiarity may fail to restore effective state explorations. Conversely, familiarity of the goal (viz. cognized or used) appeared to improve state exploration and also spur some form of strategy, or perhaps bias, from participants who may have treated feature familiarity as a criterion for means-end analysis. This outcome, which reflects the solving nature of HCI whereby users encode and assess states against a goal, warrants further investigation of the interplay between the intuitive and the effective.

The present study examined the construct validity of schema induction as a means to assess transfer and induction for the states of an interface. This verification is a prerequisite for diagnosing the intuitive use of an interface, namely screening which of its states allow prior schemata to be transferred and which require new schemata to be induced. For each state, the number of explorations for the reading and induction groups can be averaged and an effect size calculated. These effect sizes provide a quantitative measure for screening states in terms of schemata operations and identifying those that require redesign (Fischer et al., 2014). Such an approach requires no subjective rating (on behalf of participants) or coding (on behalf of an experimenter), and is quantitative from data collection to analysis. This is a marked improvement over the observational analysis that Blackler et al. (2011) endorsed for being a ‘mainly quantitative approach even though much of the data collected has been qualitative’ (p. 9).

Schema induction experiments endeavor to assess underlying mechanisms of intuitive use rather than symptoms (listed in footnote 2). Following the dissociation between indirect and direct memory effects discussed Section 2.2, the patterns that result from such experiments seem more appropriate than questioning participants about devices or features they remember using. Furthermore, schema induction experiments are readily automatable. In the preparatory phase of our study, the experimenter captured screenshots of a test interface, labeled them, generated word and function clues, and formed clue-screenshot matching trials (see Section 4.3.2). Albeit routine, this phase can be tedious when an interface consists of many states and features (such as DoIT#). We employed dedicated Delphi GUI modules (not reported in the Methods section) to assist an experimenter in this preparation. The experiment itself was administered by computer (see Section 4.4). Participants’ actions were recorded and formatted with AMME and VBA macros, meaning that data could be analyzed in an automated way. A simple matter of programming would allow the preparatory, experimental, and analysis phases to be integrated into a single application. Practitioners could then upload their own interface screenshots, prepare their clues, conduct their experiments, and screen the interface states in terms of transfer and induction patterns. Our experiment required no particular supervision, and thus we envisage that participants can be tested remotely with little cost to the design cycle.

The aforementioned screening could be valuable during the design cycle. Blackler et al. (2007, 2010) formalized a design framework for practitioners to inspect technological familiarities of device features and, whenever suitable, add stereotypes, affordances, and metaphors. This framework, however, does not address when such additions are suitable. We showed that familiar features yielded a transfer pattern regardless of whether they were used elsewhere or cognized from other domains. Such features may not benefit from familiarity-oriented design. It has been shown in multimedia learning and HCI that design enhancements such as metaphors, explanations, or consistency barely improve the realization of familiar and simple tasks (Borgman, 1999; Hsu, 2005, 2006; Mayer, 1999, 2001; Ozgungor and Guthrie, 2004; Pollock et al., 2002; see also Mugge and Schoorman, 2012). Such findings may explain why Hurtienne et al. (2013) did not obtain any benefit from redesigning a ticket-vending machine with meaningful labels, familiar tabs, and visual metaphors. In that case, participants' schemata related to purchasing were perhaps sufficiently generic to have been transferable to both versions of the machine. This highlights the pitfalls of unreservedly adding stereotypes, affordances, or metaphors. The practicality of redesigning all features of a prototype versus redesigning only those that yield an induction pattern, based on the screening of its states in terms of schemata operations, warrants further examination.

We consider two directions for extending the present study. The first is a formalization of state screening in terms of induction and transfer. While new states yielded an induction pattern on average, variations exist in the degree to which schemata were induced and fit the information architecture of the interface. It is possible that some states exhibit many explorations by each group, while others exhibit more explorations by the induction group (Fischer et al., 2014). These patterns, which we call inoperative and negative induction, respectively, hold both cognitive significance and diagnostic value. Inoperative induction indicates that the induction group failed to induce new schemata, and has been observed when participants are too naïve to elaborate upon a topic (Bransford et al., 1982; Garner and Gillingham, 1991; Hyde and Jenkins, 1969; Slamecka and Graf, 1978; Woloshyn et al., 1992). Negative induction indicates that the induction group is more likely than the reading group to detect and (re-)explore states that are functionally consistent with a goal, yet do not neighbor the goal state within the interface's architecture. Altogether, the patterns of a schema induction experiment are valuable for screening states that are intuitive (transfer pattern), and diagnosing the reasons why other states are not (positive, negative, or inoperative induction). The authors are presently considering a means to visualize these patterns across the network of an interface's states and features. This analysis extends the assessment and screening of schemata operations to the modeling of users' representation of an interface.

As a second future direction, schema induction experiments are a promising avenue for studying the factors of (and design strategies for) intuitive use. Blackler and Hurtienne (2007) reviewed existing HCI concepts that, in theory, are relevant for intuitive use (e.g., metaphors, suitability for task, feedback, self-descriptiveness, redundancy). Yet some of these concepts may not elicit intuitive use per se. For example, Blacker and Hurtienne endorsed stimulus-response compatibility because it supports ‘faster learning’. Any such design strategy can be manipulated along with schema induction in order to identify the schemata operations it supports. In principle, only factors that yield a transfer pattern should be considered factors of intuitive use, while those that modulate induction patterns would be factors of learning. Should our results be sufficiently robust, feature familiarity, which yielded a transfer pattern, would qualify as a factor of intuitive use. Cognitive style, whose impact was restricted to the induction pattern, would qualify as a factor of learning. Goal familiarity, which did not interact with schema induction, would instead relate to usage performance. Ultimately, tests of other factors can help refine the content validity of schema induction as a means for assessing intuitive use.

@&#CONCLUSION@&#

Psychology offers a host of operationalizations that have yet to be applied. To rephrase Byrne (2009), design improvements require quantitative guidance in the form of evaluation tools and precise guidelines of interpretation. Schema induction, along with its distinct interaction patterns with prior knowledge, supports this guidance, and endorses the idea that transient phenomena such as intuitive use can be assessed in ways other than heuristic. The present study advances the agendas of both HCI and psychology. Paradigms in psychology are imported into HCI as a means of objectifying user cognition, which in turn generalizes and refines their construct. Notably, the interaction between schema induction and prior knowledge, thus far employed for the conceptualization of mechanisms in multimedia learning and analogical reasoning, was shown to be relevant for assessing intuitive use in HCI. Though this approach draws upon distinct fields of psychology, it nevertheless outlines an automatable method for assessing intuitive use within the design cycle.

@&#ACKNOWLEDGEMENT@&#

The present research was supported by the G-COE Cybernics Program in the University of Tsukuba. We gratefully acknowledge Alejandra Maria Ramirez Quiros for her support in conducting the experimental tests.

@&#REFERENCES@&#


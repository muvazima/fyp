@&#MAIN-TITLE@&#Big data and ergonomics methods: A new paradigm for tackling strategic transport safety risks

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Data from on-train data recorders is underused.


                        
                        
                           
                           Can be used as an input to existing ergonomics methods.


                        
                        
                           
                           300 methods were reviewed and nine leading indicators of human factors risks extracted.


                        
                        
                           
                           The proofs-of-concept can all be automated in a full application.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Big data

Leading indicators

Human performance

Methods

@&#ABSTRACT@&#


               
               
                  Big data collected from On-Train Data Recorders (OTDR) has the potential to address the most important strategic risks currently faced by rail operators and authorities worldwide. These risk issues are increasingly orientated around human performance and have proven resistant to existing approaches. This paper presents a number of proof of concept demonstrations to show that long standing ergonomics methods can be driven from big data, and succeed in providing insight into human performance in a novel way. Over 300 ergonomics methods were reviewed and a smaller sub-set selected for proof-of-concept development using real on-train recorder data. From this are derived nine candidate Human Factors Leading Indicators which map on to all of the psychological precursors of the identified risks. This approach has the potential to make use of a significantly underused source of data, and enable rail industry stakeholders to intervene sooner to address human performance issues that, via the methods presented in this paper, are clearly manifest in on-train data recordings. The intersection of psychological knowledge, ergonomics methods and big data creates an important new framework for driving new insights.
               
            

@&#INTRODUCTION@&#

Data recording is the act of automatically logging information on system parameters over time. Data recording has become increasingly ubiquitous in rail transport operations and easily qualifies as a big data problem (e.g. Wu and Liu, 2014; Geisler et al., 2012). Big data is a rather broad term first used by NASA scientists to describe particularly thorny computer graphics problems which taxed the ability of computer hardware like memory and storage: “We call this the problem of big data. When data sets do not fit in main memory (in core), or when they do not fit even on local disk, the most common solution is to acquire more resources.” (Cox, 1997, p. 235). In the absence of universal agreement on a definition (e.g. Press, 2014) it is possible to turn to Google™, where it is described more broadly as: “extremely large data sets that may be analysed computationally to reveal patterns, trends, and associations, especially relating to human behaviour and interactions.” For this reason, big data looms large over the Ergonomics discipline and represents a potentially paradigm shifting trend going forward (see Drury, 2015). An example of the issues at stake can be found in the rail industry. Entire national train fleets are now required to carry On Train Data Recorders (OTDRs), or so called ‘Black Boxes’, for the purposes of post-accident investigation. Although the data is only accessed periodically (often rarely) the devices themselves are continuously recording how individual trains are being driven, at increasing rates, and across an increasing range of parameters. The outflow of data is therefore extensive and growing in terms of volume (the amount of data), velocity (the speed at which it is growing) and variety (the number of things being measured; Laney, 2001; Drury, 2015). Perhaps because of this, and the practical challenges involved in storing and mining such large quantities of data, it currently represents a significantly underused resource (Hart, 2003). The question, then, is what could it be used for? In this paper we aim to demonstrate that it has the potential to be coupled to existing ergonomics methods, and used to tackle the most important strategic risk issues currently faced by rail operators and authorities worldwide.

The intersection of big data and the rail transport context embodies three paradoxes:

Improving safety trends are a very welcome outcome of improved safety practices, but because so few major rail accidents occur there are now relatively few opportunities to use OTDRs for their original purpose. With so few accidents there is also no longer enough data to construct reliable forward looking estimates in a way that might have been possible for certain historic engineering (e.g. metal fatigue) or human performance issues (e.g. fatigue risk; Evans, 2011).

Safety data is levelling off, with a persistent class of human/system accident now elevated to the status of a key risk (RSSB, 2009; Stanton and Walker, 2011). When safety performance data reaches the level of that achieved in the rail sector it instead starts to become characterised by periodicities, cycles or discrete events. This is becoming evident in EU rail safety data, with a large scale rail accident occurring on average every six years (EU, 2003). This class of accident includes Signals Passed At Danger (SPADs) or overspeed events such as the Santiago de Compostela rail accident in Spain. Here it is possible to demonstrate numerous engineering and procedural safeguards, full compliance with necessary regulatory requirements, well trained individuals and a modern train fleet, yet a largely unforeseen accident still occurred.

The third and final paradox is that the opportunities to use On-Train Data Recorders (OTDRs) for their original purpose (i.e. post-accident analysis) are diminishing at the same time as the technical capabilities of data recorders are increasing (Geisler et al., 2012; Morcom, 1970). What this means is that Exabyte's of non-accident data are being collected day in and day out, but not currently used. This is a significant irony given the “widespread concern within the industry that the background indicators – rather than the headline grabbing ones – have remained worryingly stable” (Wolmar, 2012).

The opportunity embedded in these paradoxes is to use big data from transport recordings to detect accident precursors, specifically those accidents which have proven resistant to current approaches and which are responsible for the current plateauing of accident trends.

Leading indicators are measurable precursors to major events such as an accident. The indication of a precursor leads, or comes before, the actual event itself. Lagging indicators are the opposite. These are so called loss metrics that can only become apparent after an event (Rogers et al., 2009). Leading indicators are said to be proactive because they enable steps to be taken to avoid seriously adverse consequences. Lagging indicators are said to be reactive in that a seriously adverse event needs to occur before it can be learnt from. For this reason, leading indicators are also sometimes referred to as positive performance indicators and lagging indicators as negative performance indicators. The concept of leading and lagging indicators originally derives from the field of economics and the need to understand when one phase of a cyclical economic process this will change to another (Mitchell and Burns, 1938). The terms have been appropriated more recently by the safety and risk field, particularly in view of developments in Safety Management Systems (SMS) since the 1990s. The notion of leading indicators is also beginning to emerge from the ergonomics literature in the form of research on behavioural markers (e.g. Nixon et al., 2015), the use of novel human performance proxy measures (e.g. McIntire et al., 2014), and a more long standing interest in the modelling and prediction of human performance (Hamilton and Clarke, 2005). Leading indicators, in a safety management and ergonomics context, can be defined as “something that provides information that helps the [the organisation] respond to changing circumstances and take actions to achieve desired outcomes or avoid unwanted outcomes” (Step Change, 2003, p. 3). That ‘something’ can be defined according to the risk factors underlying the troublesome class of operational accident (or near accident) that is the focus of this paper.

The reason for the emphasis on human performance can be seen in the ‘broad causes’ attributed to recent rail accidents. Out of seven broad causes attributable to European rail accident data (Evans, 2011), four out of seven, including the top three, involve a prominent human performance dimension. Expressed in descriptive terms, these broad causes involve a task in which a combination of the following happens: ‘getting out of sequence’, ‘losing situational awareness’, ‘allocating attention incorrectly and/or ‘allowing prior experience to override the correct action’, or combinations of all four. Table 1
                         summarises a comprehensive review of the literature (reported elsewhere, Walker and Strathie, 2012) linking these descriptive terms to a set of specific risk factors. If we are able to detect when these risk factors are present, using big data as the input, then we should also be able to make progress on these key strategic risks.

The basic research problem can be stated thus: despite considerable improvements in safety performance in the rail sector, a persistent class of accident/near accident continues to occur. These incidents reside at the interface of people and systems. What is required is a means to detect the presence or emergence of such problems before they manifest themselves as a serious operational incident. This paper describes how big data from OTDRs can be used to ‘drive’ established ergonomics methods to provide leading indicators of specific risk factors. Four proof-of-concept demonstrators are presented to show how these approaches work, selected on the basis of their potential scalability when used with big data.

@&#METHODOLOGY@&#

On-Train Data Recording (OTDR) devices are the equivalent of aircraft ‘black boxes’ and continuously record a range of parameters referring to the individual train unit and how it is being driven. The study uses a real-world OTDR sourced from a UK train operating company. The UK rail industry has an excellent safety record, but like rail operators the world over, the accidents which do occur tend to foreground the role of human factors. Likewise, the range of parameters measured is similar to those measured in all other regions. The OTDR data file itself is a continuous download from a single traction unit. The recording started at 05:34:57 on the 6th July 2012 and ceased at 21:36.32 on the 11th July 2012. This is a period of 136 h, 1 min and 35 s during which the train made 107 journeys and travelled 1638 miles. The raw data takes the form of a Comma Separated (CSV) file containing a data matrix 191,021 time samples (rows) deep by 72 parameters (columns) wide: a total of 13.8 million data points. The logger itself scans the parameters for changes at a rate of 20 mS but, in the present system, to economise on memory requirements data are only logged when one of the 72 parameters changes (up to the maximum scanning/sampling rate). In the present case the mean sampling rate was 2.56 s. The OTDR device itself was a UK Railway Group Standards compliant Arrowvale unit which recorded 72 parameters, 25 of which are in addition to those mandated. In terms of data classification four of the parameters; time, distance and two speed signals derived from a driven and non-driven axle, are continuous ratio data. The remaining 68 are nominal/binomial (i.e. on or off). Explanations for the channels relevant to the present analyses are contained in the proof of concept descriptions.

The sample of OTDR data was obtained from a Class 153 ‘super sprinter’. This is a single-unit diesel powered railcar built between 1987 and 1988. Class 153s are 23.2 m in length and have an un-laden weight of 41.2 tons. They seat 72 passengers, comprise a riveted aluminium body shell affixed to a steel under-frame, and are equipped with four electrically powered single-leaf Bode doors. The prime-mover is an under-slung turbocharged 6 cylinder Cummins NT855 diesel engine producing 285bhp. A Cummins-Voith T211r hydraulic transmission drives both axles of the leading BT38 bogie via a Gmeinder final drive. The Units' maximum operating speed is 75mph. It is fitted with electro-pneumatic clasp brakes, with cast iron brake pads acting directly on the tread of the wheel(s) via compressed air actuation. Air suspension is provided for additional passenger comfort and refinement. Tight-lock compact BSI auto-couplers enable Class 153s to work flexibly in unison with several other multiple unit classes, but the present unit worked solo for the duration of the data collection period.

Data collection took place on the Great Eastern (Route 7) and West Anglia (Route 5) regions of Network Rail. The strategic ‘backbone’ of the Great Eastern region is the Great Eastern Main Line (GMEL) originating from London Liverpool Street and travelling North East to Norwich. There are numerous branch lines attached to the GMEL providing services to commuter areas such as Upminster, Southend and Colchester, to important freight hubs such as Harwich and Felixstowe, and to more remote communities in East Anglia such as Sudbury, Cromer and Sheringham. Route 7 (Great Eastern) joins Route 5 (West Anglia) at Haughley Junction, approximately 14 miles from Ipswich, where a secondary route runs West towards Cambridge, Ely and Peterborough. The journey diagram for unit 153 306 between 6th and 11th July 2012 is shown in Fig. 1
                         along with the technical characteristics of those routes in Table 2
                        .

Ergonomics methods, of course, provide an explicit way of linking theories on human performance and capabilities to practical situations such as rail operations. Methods are an integral part of the discipline (Stanton et al., 2013, Karwowski, 2001). The normal inputs to ergonomics methods vary, but common to them all is scale. It is common for methods to be applied to individual scenarios, to accidents/incidents that have already happened, and in rarer cases, to the analysis of entities the size of an organisation. Despite this there is no inherent limitation on the scalability of some of the methods, both in terms of the ability to apply methods over long periods of time and/or to organisational units of considerable size. As such, there is no conceptual reason why some methods cannot accept big data as an input. A systematic methods review was performed to identify candidate methods.

The result of an initial methods review was a database of over 300 ergonomics methods and techniques, grouped into nine categories as shown in Table 3
                           .

Before the database of methods were subject to further analysis, a screening process was employed to remove any that were not suitable for further consideration due to the following:
                              
                                 •
                                 Unavailable – some methods are proprietary. In order to be included, the method should be freely available in the public domain.

Inapplicable –those methods that did not refer directly or indirectly to the design and analysis of systems (not all methods refer to design and analysis), or that were too specialised to be applicable to transport systems (some methods are designed for specific domains), were rejected.

Duplication – HF methods are sometimes re-iterated and presented in a new format. Any methods that were very similar to other methods already chosen for review were rejected (the version in most common usage and/or most appropriate to transportation environments being selected instead).

Limited use –quite often a method is developed and not used by anyone other than the developer. Any methods that had not been applied in a practical analysis of some sort were rejected.

As a result of the method screening procedure, 213 of the 300 methods could be discounted as not meeting the criteria. This left a list of 87 methods available for further screening in Stage 3.

The 87 methods derived from Stage 2 were then analysed with respect to the simple questions: “could the method accept recorder data as an input” and “what output would it provide”. Table 4
                            presents the list of candidate methods and their possible contribution to the analysis of big data. The methods met a further three criteria:
                              
                                 1.
                                 “can the method be ‘demonstrated’ within reasonable timescales and cost”

“constrained by (1) does the method add sufficient value in terms of Human Factors Leading Indicators”

“could the method (at this early stage of analysis) be feasibly automated such that it would require low overhead in terms of external validation, and be compatible with software-based approaches to the management of big data”

@&#RESULTS AND DISCUSSION@&#

Having linked HF methods to strategic risks on the railway, and revealed the possibility to drive these methods from big data, this section proceeds to apply them to the OTDR dataset. A brief description of the underlying variables being measured is provided, and the method of application described. Even though the data set comprises in the region of 13 million data points and is, in big data terms, relatively small, it is clear that useful and interesting ergonomic insights were emerging with comparative ease.

Individuals possess a malleable but ultimately finite attentional resource (e.g. Young and Stanton, 2002). Mental Workload represents the proportion of that resource demanded by a task at any given moment. Excessive demand (over-load) or lack of demand (under-load) can lead to performance problems, in particular, with attention being allocated incorrectly (Theeuwes, 1991). A simple but effective indication of workload can be provided directly from transport data recordings. Certain data recording channels can be associated with mental demand, others with physical demand. As a journey progress a form of workload profile can be derived in order to identify the demands being placed on attentional resources.

@&#METHOD@&#

The proof of concept was tested using a single railway journey from Marks Tey to Sudbury, a distance of 18.5 Km. The 72 parameters extracted from the data recorder were classified into physical and mental demand according to the following simple taxonomy:
                              
                                 1.
                                 Those that impose a mental demand (e.g. such as an alarm or warning sounding in the cab)

A physical demand (e.g. moving the power or brake controllers)

Both physical and mental demand

Neither

Reference was made to previous cab rides and a task analysis of train driving (McLeod et al., 2005). This gave 24 parameters that relate to mental demand, 45 that relate to physical demand, and 6 that related to both as shown in Table 5 
                           
                           . Each time one of the parameters changed it was recorded in the appropriate category. For the journey selected this gave an overall load of 371 channel activations, 145 (39%) for mental workload and 226 (61%) for physical workload (Table 6).

To create a workload profile, the journey was divided into periods of 10 s, and the number of parameters that altered in each was recorded. Fig. 2
                            reveals how mental and physical demands are distributed across a journey, and when workload might be particularly high or low. Overlain on this graph is a further explanatory curve. The first part of the curve shows that as the journey progresses between sampling intervals 17 to 25 workload declines to a low level. The literature informs us that after approximately 30 min of low demand, such as this, we could expect to observe a vigilance decrement (Mackworth, 1948). Depending on the task and context, this can yield a 10/15% reduction in human performance (e.g. Eysenck, 1982; Mackworth, 1948). Time elapsed since workload exceeded a previous value is, therefore, one indication of potential attention-based risks. The other curve illustrates the effect of a sudden change following a long period of low demand, as occurs at sampling interval 117. Again, the psychological literature informs us that attentional resources cannot expand to new demands instantaneously and that performance problems can arise while they do (e.g. Stanton et al., 1997).

Leading Indicator 1: Conventional event detection based on comparing individual samples of workload with mean values across journeys/journey segments/driver population(s) etc. In a wider application, averaging across multiple journeys on the same route, it may be possible to build up a profile of how workload is distributed under typical driving conditions. If changes in the profile appear, this may offer an indication that something has altered in driving conditions that was impacting on drivers.

Leading Indicator 2: Time elapsed since a significant change in workload based on theories of vigilance. While drivers may be more vulnerable to errors during periods of high load, extended periods of low workload can also be problematic. Theoretical knowledge on human performance under the specific conditions pertaining in rail settings could be used to define when occurrences like these constitute early warning of unacceptable risk.

Leading Indicator 3: A significant workload event occurs after a pre-set length of time at low workload has been exceeded. While the example journey analysed here identified periods of high load on arrival and departure from stations (which may not be unexpected), longer journeys on more complex infrastructure may create additional periods of high workload. The ability to respond appropriately to these changes depends on the magnitude and rate of workload change, and the period of time prior to the change during which low levels of workload were experienced.

Type of Risk Detected: Getting out of sequence because of task interruptions, and/or an unusual responses being required. Faulty allocation of attention due to unexpected events, distractors or when attention is spread across a range of demanding tasks. Prior experience overriding correct action due to long periods when minimal inputs/responses are required.

Process charting techniques are used to represent complex real-world activity in an easy to read graphical format using standardised symbols and layout (Stanton et al., 2013). The process chart methodology has an extremely long legacy and history of use. Early examples date from the 1920s (Gilbreth and Gilbreth, 1921) and it has been used extensively in military and high hazard domains as a way of understanding the interaction between people and systems, particularly in terms of identifying human error potential. In this application, process charts offer a novel way of converting the raw trace plots derived from data recorders into an alternative representation, one that makes it easier to discern how larger journey phases break down into smaller component activities, the order and timing that component activities occur, who is performing what activity, and the presence of distinct activity clusters.

@&#METHOD@&#

The proof of concept was tested using several journey segments spanning a range of different activities and contexts. The 72 parameters extracted from the data recorder were classified into:
                              
                                 
                              
                           
                        

Again, this relied on previous in-cab observations and a task analysis train driving (McLeod et al., 2005). Once all of the recorder channels have been classified into the appropriate symbol categories, the process chart itself can be constructed. This involves creating a timeline and columns for each ‘agent’ in the system. In the case of the railway example six such agents/columns have been used:
                              
                                 1.
                                 Driver

Guard

Passengers

Train

Signalling/Track

External Environment

As different recorder channels become active, the corresponding process chart symbol is inserted into the relevant column at the correct point on the timeline. The sequence of activities and their dependence on each other defines when these symbols are linked. Thus an activity/symbol which occurs after another activity/symbol becomes linked ‘vertically’. Activities that are performed concurrently are linked ‘horizontally’.


                           Fig. 3
                            shows how the channel activations associated with a station departure can be converted into a process chart. The boxes have been added to provide a narrative of the activities being performed, and an explanation for the categorisation of those activities into process chart symbology.

The simplest output to be derived from a process chart, one that links to the workload profile above, is an Operations Loading table. This shows how busy each agent in the system is. Whilst the Workload Profile technique provides a high level overview of workload according to Mental and Physical Demand, the Process Chart Method provides a more detailed assessment broken down by different actors in the scenario and specific task/operation types. It is also important to note that the agents/actors represented in the Process Chart are human (i.e. drivers, passengers, guards etc.) and non-human (the train itself, the track and signalling infrastructure and so on). The points at which these different actors/agents have to interact are clearly shown, along with any potential problems with that interaction in terms of missing information, out-of-sequence and/or overly demanding activities.

The simplifying effect of converting raw trace plots into process charts enables meaningful patterns to be better detected and thus made more amenable to automatic detection. Process charts also help in the identification of interruptions to the normal sequence of activities and in providing leading indicators around the issue of prospective memory. Having the ability to detect behavioural clusters also grants the opportunity to assess whether such structures are typical or atypical. Indeed, whether they are one of a number of different behavioural responses within a wider repertoire, and whether one cluster of behaviour is implicated in risk outcomes more than another, and under what circumstances. Despite only having access to a comparatively small sample of data distinct patterns of behaviour were still evident. Below are three different clusters of behaviour for performing the same task (cancelling an AWS warning by pressing a button when an in-cab alert is heard). The first cluster is the normative ‘perceive-decide-act’ sequence. Here the infrastructure on the track triggers an in-cab warning horn. The driver perceives (hears) this, has enough time to classify it (0.89 s) and respond by pressing the cancellation button. The second cluster is the ‘predictive cancel’ sequence. In this case the infrastructure on the track triggers the in-cab warning horn but the driver responds so quickly that it is not possible to have perceived, classified and responded to the warning. Instead, the driver has seen the track infrastructure and has anticipated the in-cab warning and timed their response to coincide with it starting. The third cluster is the ‘multiple predictive cancel’ sequence. As in cluster two, the driver can see the track infrastructure ahead and is pressing the cancellation button numerous times before hearing the in-cab warning horn, and several times after the warning has sounded and been cancelled. Driver behaviour with AWS has been implicated in several high profile rail accidents (e.g. Cullen, 2001; Uff, 2000).

Leading Indicator 4: Operations loading as a means of detecting normal/abnormal workload across different agents/actors in the system. It also reveals the different modalities by which different parts of the system communicate with each other revealing, in turn, sensory channels that might be over or under-relied upon.

Leading Indicator 5: The extraction and definition of behavioural clusters which, in turn, can be explored for their possible impacts on overall risk. Clusters are defined by structure and sequence of operations. Operations that occur too much or too little, too late or too early, out of sequence or unexpectedly, can be detected.

Type of Risk Detected: Getting out of sequence because of task interruptions, unusual future responses being required, removal of normal environmental cues that trigger habitual behaviour, and deviations from well-practised routines. Loss of situational awareness due to missing information that would normally come from other elements of the system. Faulty allocation of attention due to unexpected events. Prior experience that overrides correct action because of high routine and minimal (new) inputs, changes in system mode meaning that a routine behaviour now causes a different outcome, and conflicting information resulting in situations being misclassified.

Link analysis is used to identify and represent links between interface components and human operations, and to determine the nature, frequency and importance of those links. Links are defined by a driver's interaction with their cab interface. For example, if the driver is required to press button A and then button B in sequence a link between buttons A and B is recorded. The data matrix created by populating the frequency of these links can be subject to analysis via Graph Theory in order to extract useful numerical metrics referring to the type of interaction recorded. In this application, link diagrams can be driven directly from recorder data, analysed using graph theory metrics, then used to provide a novel way of detecting events based on drivers' physical interactions with technology.

@&#METHOD@&#

Defining the links between components of a user interface is normally achieved by a walkthrough or observational study of the task(s) under analysis (Stanton and Young, 1999). Recorder data avoids the need for this. Human interactions with cab or cockpit interfaces can be monitored directly based on the changing activation of recorder channels related to cab/cockpit interfaces as shown in Fig. 5
                           
                           . For this proof of concept demonstration link analyses was performed on six drivers undertaking 17 journeys from Bures to Sudbury.

The pattern of control activities across all 17 journeys is summarised in the network diagram in Fig. 6
                           . This gives a visual representation of the pattern of driver/cab interaction produced across all the sampled journeys. The link diagram shows that some components of the cab interface are more heavily interconnected than others (as represented by thicker connecting lines), that there is an ‘overall’ level of connectivity, and that the number of links one needs to traverse to reach different pairs of nodes (controls) also differs.

To investigate whether individual drivers differ in their interactions with the cab interface and controls Graph Theory metrics can be calculated from the link matrices. An example is the network metric centrality, given by the formula:
                              
                                 
                                    
                                       Centrality
                                       =
                                       
                                          
                                             ∑
                                             
                                                j
                                                =
                                                1
                                             
                                             Y
                                          
                                          
                                             
                                                C
                                                D
                                             
                                              
                                             
                                                (
                                                
                                                   y
                                                   *
                                                
                                                )
                                             
                                          
                                       
                                       −
                                       
                                          C
                                          D
                                       
                                        
                                       
                                          (
                                          
                                             
                                                y
                                                j
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           where the node with the greatest number of links converging upon it (CD(y*), that which has the highest ‘degree’, is used to derive centrality values for every other node in the network. Simply stated, centrality is a way to identify which part of the interface is more heavily connected, and therefore more prominent in the network, compared to others. In practice, heavily connected nodes are more visible to other nodes, serve as a conduit for control sequences more than other nodes, and will be subject to network influences more quickly and more often than other nodes.

The results of an analysis of centrality performed on the six drivers responsible for 17 journeys between Bures and Sudbury shows there is a distinct pattern. For many drivers, the lower positions of the brake and power controllers are dominant. Indeed, there is close concordance between all drivers in terms of the power controller, with progressively less emphasis given to higher power settings. There is much greater variation in terms of brake controller usage and three distinct signatures seem to emerge. The first is the ‘mean signature’ where equal and low importance is ascribed to all of the running brake control positions (steps 1 to 3 on the controller). Then there is another group of drivers who ascribe descending importance to brake steps 1 to 3. The pattern for a third driver also stands out from the group in that their responses cluster greatly around brake step 2. Distinct patterns such as these grant access to leading indicators around driver strategy and technique.

Leading Indicator 6: Link analysis enables network diagrams to be created directly from recorder data. These represent human interactions with control interfaces in a graphical format, showing link frequency, direction and strength. Patterns of behaviour can be readily detected from these representations and potentially serve as leading indicators of driving technique.

Leading Indicator 7: The results of Link Analyses can be expressed as single numbers through the use of Graph Theory metrics. These summarise different facets of human interaction with in cab controls, such as response diversity, sequencing and clustering, and provide key performance indicators of when these interactions change.

Type of Risk Detected: Getting out of sequence because of task interruptions, unusual future responses being required, removal of normal environmental cues that trigger habitual behaviour, and deviations from well-practised routines: all of which are detectable via link diagrams and associated metrics. Loss of situational awareness due to missing information/links between elements of the system. Faulty allocation of attention due to experience/training related factors as revealed by driving strategies and signatures. Prior experience which overrides the correct action because of high routine and minimal (new) inputs. Changes in system mode, meaning that a routine cluster of links now causes a different outcome, and conflicting information/links resulting in situations being misclassified.

Drivers have to respond to a wide range of stimuli in their environment, all of which is subject to some level of uncertainty. Tasks like these are not merely perceptual ones of seeing or hearing something, they are also cognitive: drivers not only have to discriminate a stimulus from within a noisy environment, but correctly classify it and respond. Signal detection Theory (SDT) formalises these concepts by separating out an individual's sensitivity to a stimuli (how easy it is to detect something) from their response bias (their preference for responding one way or another to the stimuli; Green and Swets, 1966). SDT helps us to understand why a particular stimulus, which might be very loud, visible or unambiguous, is not always responded to in the ways we expect (or vice versa). SDT classifies human responses to stimuli in the environment in four ways, either as a hit, miss, false alarm or correct rejection. The ability to accurately detect stimuli in the environment and correctly classify them is the desired outcome. Taking the example of AWS and the need to press a cancellation button in response to an in-cab warning, if the button was pressed in response to ANY warning indication this will ensure a 100% Hit rate but will also increase the rate of False Alarms. Accuracy in this case is low. If, on the other hand, the driver is trying to do the opposite, to avoid False Alarms and instead maximise Correct Rejections, they would not respond to ambiguous signals. This would increase the number of Correct Rejections but it would also increase the number of Misses. Accuracy in this case is also low. SDT enables us to separate sensitivity (d′) from decision bias (C) and characterise human performance in a robust way.

@&#METHOD@&#

The proof of concept was tested using three railway journeys from Ipswich to Felixstowe. SDT was applied to the activation of the in-cab AWS where the driver responses could be categorised as follows:

Sensitivity to a stimulus is given by the metric d-prime, which was calculated as follows:

d′ = z(FA) − z(H).where z(H) is the number of Hits expressed as a z-value subtracted from the same Z-transformed False Alarm rate. The results obtained are shown in Table 7
                           :

The d-prime figure measures the strength of the stimulus, which in this case is the in-cab warning provided by the AWS system. A value of 3.03 indicates drivers are highly sensitive to it: in this situation it is unambiguous and easy to discriminate from the wider background of noise, distractions, other contextual factors and so on. Expressed more formally, the responses drivers are providing when an AWS warning is overlain on top of the contextual noise is 3.03 standard deviations different from the responses they give when the signal is absent (and only the contextual noise is present). Sensitivity provides an important leading indicator concerning the discriminability of information needed for drivers to develop accurate situational awareness. This is because the same stimuli may yield different levels of sensitivity depending on external/contextual factors. A warning that was not expected, ambiguous, not fully understood or masked, for example, may lower sensitivity despite the fact that it is the same objective warning in terms of prominence, sound intensity level etc.

Decision bias/criterion is given by the metric c, which was calculated as follows:
                              
                                 
                                    
                                       c
                                       =
                                       −
                                       
                                          
                                             Z
                                             
                                                (
                                                H
                                                )
                                             
                                             +
                                             Z
                                             
                                                (
                                                
                                                   F
                                                   A
                                                
                                                )
                                             
                                          
                                          2
                                       
                                    
                                 
                              
                           
                        

The results obtained are shown in Table 8
                           . Decision Bias is independent of sensitivity and relates not to the discriminability of the signal but to the payoffs involved in making one response in favour of another. Thus, regardless of how easy it is to discriminate a stimulus a counter intuitive response may still be favoured. This is because the consequences of False Alarms, Misses and Correct Rejections vary with the context. Research shows that decision bias is more unstable and situationally dependent than sensitivity and therefore a potentially valuable Leading Indicator (Green and Swets, 1966).

The mean decision bias value across the three sampled drivers was c = −1.24 which indicates a liberal bias. The drivers make more responses which indicate the AWS signal is present than it is absent. In other words, they are prioritising False Alarms over Correct Rejections which, in turn, provides a clue as to the sorts of error that may be more likely to occur in future (i.e. warnings that are cancelled incorrectly). Assuming drivers'‘internal responses to the AWS warning are normally distributed (as per Signal Detection Theory) it is possible to plot individual driver decision bias into Fig. 7
                            which, in turn, provides an important diagnostic tool in defining risky psychological/decision making states.

According to Fig. 7, Driver 1 shows no systematic bias in their responses to the AWS warning. They respond correctly to the AWS warning on every occasion and his/her False Alarm rate is zero. Drivers 2 and 3 are different. They are exhibiting a strong liberal response bias meaning they are much more inclined to exhibit false alarm responses (and behavioural clusters 2 and 3 shown in Fig. 4). With the ability to detect these changes in decision bias comes the possibility to analyse a) the extent to which different biases interact with accident/incident rates (i.e. is a liberal bias of this magnitude associated with particular types of risk) and b) how the context influences human decision making (and therefore how that context can be modified to ‘un-bias’ it).

Leading Indicator 8: Sensitivity provides a measure of how much useful information there is in the environment and the extent to which drivers can discriminate it from the background of contextual noise. Warnings, stimuli and so forth may, in an engineering sense, appear to be unambiguous yet they may be considerably less so cognitively. Sensitivity provides a measure of this which can, in turn, be associated with changing risk.

Leading Indicator 9: Decision bias reveals the likelihood that one type of driver response will be favoured and, in a wider application, how this interacts with risk. In a wider application it would be possible to examine decision bias in a systematic way looking at differences between drivers and between particular routes. This could provide insight into driving styles and indicate whether particular aspects of a route result in a shift in decision bias. For example, a specific AWS signal on a particular route may result in a high level of predictive cancellations/button pressing (high false alarms) relative to most others, identifying this as a more risky section of journey. Relationships such as these would need to be established based on a future research but the feature itself is now detectable.

Type of Risk Detected: Getting out of sequence because of changing levels of sensitivity to environmental cues that trigger habitual behaviour. Loss of situational awareness because of the detectability (or absence of detectability) of information in the environment. Risk of a failure to understand what environmental cues might mean due to high levels of decision bias. Faulty allocation of attention due to misdirected attention lowering sensitivity to other environmental stimuli. Prior experience overriding correct action as revealed by shifts in decision bias as a result of highly routine journeys, experience and habit; biases that favour one response type in a multi-modal system; the role of conflicting information in reducing sensitivity and increasing misclassifications.

@&#CONCLUSIONS@&#

Exabytes of data are routinely and continuously collected from normal journeys by On-Train Data Recorders (OTDR), but are currently not used in a systematic fashion. At the same time, not only are the opportunities to use OTDR data after accidents diminishing because of improving safety trends but we are increasingly left with a class of ergonomics problem that is difficult to predict based on previous occurrences. Human performance issues are a strategic risk and innovative new ways to work at this interface are required. The research reported in this paper advances this agenda. Table 9
                      
                      summarises the nine leading indicator candidates that arise from coupling big data to ergonomics methods and how they map to key risk types (Table 10).

The advantage of this approach is that ergonomics methods are able to bring with them a substantial and robust form of construct validity. They have already been shown to provide access to the behavioural issues that are of interest in detecting key risks, and as such provide a novel framework for interrogating big data from OTDR devices. Importantly, the process of review and proof of concept testing establishes the scalability of the methods. They ‘can’ be driven from this new type of data, and furthermore, are amenable to software-based implementation in future. This finding hints at considerable reductions in the analytical overhead required to perform these analyses, indeed, with more automation Human Factors Leading Indicators of the sort tested in this paper could become continuous key performance indicators, relying more on real-time data streams rather than post-hoc analysis. The possibilities are tantalising, but having proved the concept a number of important future research tasks are required. Ergonomics methods are able to demonstrate good construct validity and reliability (based on their substantial legacy of prior use and development) but another source of big data on actual accident and risk outcomes needs to be combined with these candidate leading indicators. This is currently underway. This critical step is required in order to answer questions about whether identified risks around vigilance decrements, clusters of behaviour or decision bias find themselves implicated in actual incidents such as SPADs, overspeeding, wrong-side door releases and station over-runs. The main task is to establish the sensitivity of the leading indicators, along with their predictive validity in terms of actual risk outcomes. If this loop can be closed then we have a powerful and potentially paradigm changing approach that is not restricted to the rail sector. The same insights apply equally to existing Flight Data Monitoring/Flight Operations Quality Assurance practices, wherein problematic Human Factors issues have also become key strategic risks. The authors have also begun to apply this approach in the truck/logistics sector where big data from vehicle telematics is widespread, as is the business need to make better use of an underused resource to solve issues around safety, fatigue risk management, fuel use and eco-driving. Indeed, there are numerous commercial and industrial sectors who collect various forms of system telemetry, and for which Human Factors Leading Indicators would represent a valuable source of insight. The wider implications for the HF/E discipline are perhaps more profound. Instead of applying our methods to samples of a population we can instead work with the entire population. Instead of taking a time isolated slice through a system we can start to look at it continuously. Instead of narrow insights derived from laboratory studies of subjects removed from their context, we can adopt a naturalistic ‘whole-systems’ approach. This paper has tried to show the power of big data in revealing new and previously hidden insights using ergonomics methods. The big data haystack may not be any smaller than it was previously, but the proof of concept demonstrators show that the number of useful needles to be found has been increased and made easier to find.

@&#ACKNOWLEDGEMENTS@&#

This work was funded by the UK Economic and Physical Sciences Research Council (EPSRC) under Grant Reference: EPSRC EP/I036222/1. The involvement and support of the UK Rail Safety and Standards Board (RSSB), the Association of Train Operating Companies (ATOC) and Greater Anglia Trains is gratefully acknowledged.

@&#REFERENCES@&#


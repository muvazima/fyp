@&#MAIN-TITLE@&#Recent evidence on the effectiveness of group model building

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Group model building is a participatory approach to system dynamics.


                        
                        
                           
                           This paper reviews 45 published studies of group model building effectiveness.


                        
                        
                           
                           Different research designs report a wide range of beneficial outcomes.


                        
                        
                           
                           More emphasis is needed on comparative rather than exploratory research.


                        
                        
                           
                           Settings should shift from controlled experiments to applied problems.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Behavioural OR

Group model building

System dynamics

Evidence

Literature review

@&#ABSTRACT@&#


               
               
                  Group model building (GMB) is a participatory approach to using system dynamics in group decision-making and problem structuring. This paper considers the published quantitative evidence base for GMB since the earlier literature review by Rouwette et al. (2002), to consider the level of understanding on three basic questions: what does it achieve, when should it be applied, and how should it be applied or improved? There have now been at least 45 such studies since 1987, utilising controlled experiments, field experiments, pretest/posttest, and observational research designs. There is evidence of GMB achieving a range of outcomes, particularly with regard to the behaviour of participants and their learning through the process. There is some evidence that GMB is more effective at supporting communication and consensus than traditional facilitation, however GMB has not been compared to other problem structuring methods. GMB has been successfully applied in a range of contexts, but there is little evidence on which to select between different GMB tools, or to understand when certain tools may be more appropriate. There is improving evidence on how GMB works, but this has not yet been translated into changing practice. Overall the evidence base for GMB has continued to improve, supporting its use for improving communication and agreement between participants in group decision processes. This paper argues that future research in group model building would benefit from three main shifts: from single cases to multiple cases; from controlled settings to applied settings; and by augmenting survey results with more objective measures.
               
            

@&#INTRODUCTION@&#

Participative and behavioural aspects of OR are important and underexplored (Hamalainen, Luoma, & Saarinen, 2013). One area with an emerging evidence-base is group model building (“GMB”, Vennix, 1996), a participatory approach to the development of system dynamics models. Recent GMB literature has given more prominence to participant behaviour and interpersonal dynamics, to explore how GMB supports persuasion (Rouwette, Korzilius, Vennix, & Jacobs, 2011a), trust (Black & Andersen, 2012), and agreement (Rouwette, 2011).

The importance of involving the client in the modelling process has been acknowledged since the conception of system dynamics (Forrester, 1961). Practitioners observed that recommendations developed through system dynamics were not automatically adopted by the client (Greenberger, Crenson, & Crissey, 1976), and experimented with involving the client in the modelling process. This became known as “group model building” (Vennix, 1996). The term has been criticised as cosy, narrow and parochial (Andersen, Vennix, Richardson, & Rouwette, 2007), in that it fails to mention that the models in question are always system dynamics models. Authors have proposed that GMB should be considered as a sub-set of problem structuring methods (Andersen et al., 2007; Rouwette, Vennix, & Felling, 2009) or group decision support systems (Vennix, Andersen, Richardson, & Rohrbaugh, 1992). Nonetheless, the term and its limitation to system dynamics methods has been used in many publications (e.g. Akkermans & Vennix, 1997; Andersen & Richardson, 1997; Andersen, Richardson, & Vennix, 1997, 2007; Luna-Reyes et al., 2006; Richardson, 2013; Richardson & Andersen, 1995; Richardson, Andersen, Rohrbaugh, & Steinhurst, 1992; Rouwette & Vennix, 2006, 2011; Rouwette et al., 2009; Rouwette, Vennix, & Thijssen, 2000, 2002, 2011a, 2011b; Vennix, 1996, 1999; Vennix & Rouwette, 2000; Vennix, Scheper, & Willems, 1993, 1996; Zagonel, 2002, 2004). Maintaining this narrow definition allows this paper to build directly on an earlier literature review (Rouwette, Vennix, & Mullekom, 2002).

Despite over 100 publications on GMB methods (see
Section 3), relatively few have described attempts at quantitative analysis. This paper collates the available evidence on group model building, including studies of how it is used, what it achieves, and why. This information is used to reflect on the quantitative evidence base for GMB, to synthesise the conclusions, to consider how this addresses fundamental research questions, and to identify key opportunities for the future. The analysis is arranged around three themes: what group model building achieves; when it should be applied; and how it should be applied or improved. This is likely to be of interest to GMB practitioners in understanding the state of empirical evidence for their craft, and for GMB researchers in identifying further research opportunities. The study is also likely to be of interest to the broader OR community, as many of the research challenges (particularly balancing experimental control with external validity) are likely to be applicable to other participative and behavioural approaches.

This paper is arranged in four sections after this introduction. Section 2 summarises early research on GMB, as articulated by Rouwette et al. (2002). The methodology for augmenting and updating the literature review by Rouwette et al. (2002) is then explained in Section 3. Literature is presented and analysed in Section 4 to describe the quantitative evidence base for GMB. And finally in Section 5, there is a discussion of the implications of the research findings, and an exploration of research gaps and future research opportunities.

The first empirical study was conducted in 1988, and in the following 13 years, there were 19 studies on GMB that collected quantitative evidence regarding its use. In 2002, Rouwette et al. reviewed 107 GMB studies, including the 19 that attempted some sort of quantitative assessment. The studies that included quantitative evidence were published between 1987 and 2000. The review considered five aspects of the studies: the source of the data; what data were collected; how they were collected; when they were collected; and what was found. The different studies related to a range of intervention contexts and tools, described in different and incomplete ways. The evaluations consisted of post-workshop surveys or pretest/posttest questionnaires, and mostly relied on participants’ own views of what the workshops had achieved. Of those using a pretest/posttest design, three used a single case study and two a field experiment. The authors expressed caution about biases introduced by measurement methods, and recommended direct comparison of different measurement methods to determine if they were associated with different results (Rouwette et al., 2002).

The conclusions of this review were relatively modest: GMB literature included a number of small-scale evaluations that demonstrated that participants believe GMB contributes to improved communication quality, insight, consensus and commitment to conclusions. The reasons for this success were unclear, as was the relative effectiveness of GMB versus other techniques (Rouwette et al., 2002).

Three papers at around this time contained recommendations on a research programme for the future of GMB. Andersen et al. (1997) proposed that more rigorous and consistent recording of the intervention context and tools was required, as well as evaluation of several explanatory hypotheses: systems thinking, group structure, chunking, gifted practitioner, group communication, or Hawthorn effect. While noting the barriers to effective research design, they recommended experiments to complement survey results, and the use of common survey methods to allow results from many studies to be aggregated. They also proposed: the inclusion of measurement methods that do not rely on participants reporting their own cognitive processes; that studies measure either mental models or their changes but not both in the same subjects; that some study of the enduring effects (if any) of GMB is conducted; and that mixed methods are used to improve the robustness of results. Coyle (2000) proposed an exploration into the wise balance between qualitative and quantitative GMB, through the development of a metric for measuring the presumed added understanding and confidence from quantitative modelling. Finally, Rouwette et al. (2002) echoed the earlier call from Andersen et al. (1997) to thoroughly record case research in a standardised format, while also calling for more reporting of unsuccessful case studies.

@&#METHODOLOGY@&#

These calls for more research into how GMB is conducted, what it achieves, and why, set the scene for several important quantitative studies over the coming decade, as well as a number of smaller pilot studies. This paper reviews this research, in order to reflect on the current quantitative evidence base regarding GMB.

A literature search was conducted to identify relevant evidence for GMB. This included past issues of five journals from 2001 to 2014 (European Journal of Operational Research, Journal of the Operational Research Society, Group Decision and Negotiation, System Dynamics Review, System Research and Behavioral Sciences), and past proceedings of two international conferences (Meeting of the International Society of Systems Sciences, and International Conference of the System Dynamics Society). Papers were selected that included quantitative evidence relating to GMB. The references cited in these papers were subsequently analysed to reveal additional research.

This method introduces several possible biases. First, it is possible that empirical GMB studies have been published elsewhere than the publications examined, and not subsequently referenced by empirical GMB studies within those publications examined. Secondly, it is possible that some papers were missed due to human error, where it was not immediately apparent that the paper related to GMB. Third, not all research is published, for a number of reasons including: ambivalence, commercial sensitivity, or a reluctance to publish findings from unsuccessful cases. It is not possible to measure these possible biases, and therefore caution must be taken in assuming that this paper describes all empirical research on GMB.

Papers were selected on the basis of three criteria: quantitative evidence, system dynamics tools, and a focus on client participation or group interaction (see Table 1
                        ).

Several studies were excluded that evaluated participant learning through use of system dynamics methods but that did not feature significant group interaction (e.g. Capelo & Dias, 2009; Cavaleri, Raphael, & Filletti, 2002; Gary & Wood, 2007, 2011; Hopper & Stave, 2008; Jensen, 2005; Kopainsky, Alessi, Pedercini, & Davidsen, 2009, 2010a, 2010b, 2011a, 2011b, 2012; Kopainsky & Saldarriaga, 2012; Kopainsky & Sawicka, 2011; Langley & Morecroft, 2004; Maani & Maharaj, 2003; Moxnes, 2004; Mulder, Lazonder, & de Jong, 2011; Plate, 2010; Stouten, Heeme, Gellynck, & Polet, 2012; Yasarcan, 2009). Conversely, several papers were included that described individual work on system dynamics tools alternated with group feedback activities that did not use system dynamics tools (Borštnar, Kljajić, Škraba, Kofjač, & Rajkovič, 2011; Škraba, Kljajić, & Leskovar, 2003, 2007).

Papers were also excluded that described problem structuring methods or soft OR methods that were not necessarily system dynamics tools (Allsop & Taket, 2003; Berry, Bowman, Hernandez, & Pratt, 2006; Bryant & Darwin, 2004; Charnley & Engelbert, 2005; Cole, 2006; Fan, Shen, & Lin, 2007; Fjermestad, 2004; Franco, 2007; Halvorsen, 2001; Joldersma & Roelofs, 2004; McGurk et al., 2006; Phahlamohlaka & Friend, 2004; Rowe & Frewer, 2004; Rowe, Marsh, & Frewer, 2004; Rowe, Horlick-Jones, Walls, & Pidgeon, 2005; Shaw 2003; Sørensen, Vidal, & Engström, 2004). The distinction between GMB and other problem structuring methods may not always be helpful (Andersen et al., 2007). However, maintaining a narrow focus on participative interventions using system dynamics methods allows direct comparison with the earlier review by Rouwette et al. (2002), to reflect on how the evidence base has changed in the intervening years. While this paper does not comment on the evidence to support other problem structuring methods, lessons from related fields are included where this is useful as a basis for recommending where further GMB research should be directed.

Some authors have begun to divide GMB practice into two related sub-fields based on how the model is perceived (Andersen et al., 2007; Zagonel, 2002). One perspective considers the model as an allegedly realistic representation of the external policy environment (“micro world” – Zagonel, 2002; “virtual world” – Sterman, 2000). The second perspective considers the model as a socially constructed artefact for building trust and agreement (“boundary object” – Black, 2013; Black & Andersen, 2012; Franco, 2013; Scott, Cavana, & Cameron, 2014b; Zagonel, 2002; “transitional object” – Eden & Ackermann, 2006). In many of the cases reviewed, it was not possible to clearly distinguish between each perspective, and indeed each may be the prevailing view at different points of the same GMB intervention (Zagonel, 2002). This paper includes both perspectives under the general category of GMB.

Finally, four papers were included that met the criteria for inclusion in this review, but did not describe case research. One paper measured the time commitment by participants and different members of the modelling team (Luna-Reyes et al., 2006). A second paper surveyed leading system dynamics practitioners on best-practice methods – while not explicitly inquiring about GMB, many of the responses related to client involvement and participation (Martinez-Moyano & Richardson, 2013). A third paper concerned the use of model validation in GMB, and conducted a meta-analysis of published GMB studies (Happach, Veldhuis, Vennix, & Rouwette, 2012). The fourth paper asked potential GMB clients to rate each of the reported outcomes of GMB based on importance to them in conducting group decision processes (Scott, Cavana, & Cameron, 2015).

@&#ANALYSIS@&#

Each paper identified and selected as described above was read and summarised into a short synopsis arranged in five fields: the research design, the research context, the GMB tools used, the evaluation tools employed, and the results reported. These synopses formed the data set for subsequent analysis.

No framework was found for assessing the sufficiency of evidence for a group facilitation tool. Therefore, a framework was created as a composite of four partial frameworks from the literature. These four partial frameworks are each explored below: themes for evaluating interventions (Riecken & Boruch, 1974); evidence for effectiveness of group processes (Burlingame, MacKenzie, & Strauss, 2004); levels of outcomes (Rouwette et al., 2002); and extent of use (Mingers & Taylor, 1992).


                        Riecken and Boruch (1974) suggest that there are three logical themes for research into the application of a social intervention: what the intervention achieves; when it should be applied; and how it should be applied or improved.

In considering evidence for small group methods in psychology, Burlingame et al. (2004) propose that the effects of the intervention should be considered in terms of general efficacy (what does it achieve), differential efficacy with respect to context (what does it achieve in what situations), and differential efficacy with respect to method (what does it achieve compared to other alternative methods). As GMB consists of a range of tools (Rouwette et al., 2002), this might be further separated into differential efficacy compared to other group methods and differential efficacy between different GMB tools. Burlingame et al. (2004) also suggest that insights into the mechanism of change are important for informing future efforts to improve practice.

Efficacy in GMB literature is considered at four levels: individual, group, organisational and method/efficiency (Rouwette et al., 2002). Individual effects include cognitive changes such as insight as well as affective changes such as commitment to a decision. Group effects include group behaviours such as communication quality as well as group alignment through shared language and consensus. Efficiency refers to the time and resources taken to achieve these individual and group effects. It is likely to be impossible to attribute organisational level changes like system improvement to the GMB intervention (Shadish, Cook, & Campbell, 2001), so this has been omitted from the composite framework used in this paper.

In relation to SSM, Mingers and Taylor (1992) suggest a baseline for understanding a group method is first to know how prevalent the method is, and how and where it is currently used.

These four partial frameworks were summarised into a composite framework, and used to identify the research questions for this paper (Table 2
                        ). Each of the included studies was assessed for its contribution to answering the research questions, and the collated results are reported in Section 4 of this paper.

The literature review resulted in the selection of 26 new studies since 2001 that include quantitative evidence on GMB. This section describes: where these studies were published; the research designs; and their findings (what GMB achieves, when is should be used, and how it should be applied or improved).

The 19 studies identified by Rouwette et al. (2002) and additional 26 papers in more recent literature were published in a variety of forms, including journal articles, conference papers, and student dissertations (see Table 3). While the System Dynamics Review and the proceedings International Conference of the System Dynamics Society remain the two most popular vehicles for publishing GMB evidence, the more recent studies differed in two ways from the earlier review by Rouwette et al. (2002): the increased representation in mainstream OR journals, and the decrease in research published only in student dissertations. These two differences are explained below.

Publication in OR journals such as Group Decision and Negotiation (Scott et al., 2015; Škraba et al., 2003), and the Journal of the Operational Research Society (Rouwette, 2011; Scott, Cavana, & Cameron, 2014a) may represent a greater interest by GMB authors and OR journals in how GMB practices relate to similar OR practices (Ackermann, Andersen, Eden, & Richardson, 2010; Andersen et al., 2007; Lane & Oliva, 1998; Rouwette et al., 2009, 2011b).

In both periods (1987–2000 and 2001–2014), the same research findings were often published in a combination of dissertations, conference papers and journal articles; where this occurred, only the “higher” publication was included in the analysis (journal articles were included in preference to conference papers, which were in turn included in preference to dissertations). The trend toward more journal articles and fewer unpublished dissertations can be explained in two ways. First, as a manifestation of more general trends in doctoral publication, toward the conversion of doctoral research into articles suitable for journal publication (Kamler, 2008). Alternatively, it may be that this paper does not capture all unpublished dissertational research – all but one dissertation cited by Rouwette et al. (2002) were from the same institution and known to the authors of that paper.

The quantitative evidence for GMB consists of diverse forms that differ by study type, problem type, and sample size (both the number of cases and the number of individual research subjects). These are summarised in Table 4
                        , and each explained in detail below.

The number of research subjects in the 26 studies above varied widely from single case studies involving a group of 9 participants (Cockerill et al., 2006; Mooy et al., 2001) to 12 groups featuring 174 subjects (Škraba et al., 2007; see Table 4). The number of research subjects divided the studies into two main groups: small case-research involving a small number of research subjects (14 studies featuring between 9 and 42 subjects) and controlled experiments with large research groups (7 studies featuring 56–174 subjects).

Consideration must be given to whether this pattern of small case research and large experiments remains appropriate. Small case studies are useful for exploratory research, because it requires less investment of time and resources. Many of the promising findings from these exploratory studies are yet to be investigated by larger studies with greater statistical power (Cohen, 1988), and this represents the next logical step in GMB research. The large experimental studies may also be decreasing in their relevance to understanding GMB, for reasons discussed under “study type” below.

Beyond the number of research subjects, the number of cases is also important in small group research (Levine & Moreland, 1990). The dynamics of a group may introduce a systemic effect on the responses of all research subjects in that group in ways that cannot be attributed to the workshop method. This is particularly relevant in field experiments, when trying to make comparisons between a treatment group and control group, or between two different treatment groups. Recent GMB field experiments have compared a single treatment group with a single control group (Dwyer & Stave, 2008; Eskinasi et al., 2009; van Nistelrooij et al., 2012), which is a very small sample on which to make generalised conclusions (Levine & Moreland, 1990).

One study (Rouwette et al., 2011a) is notable as a meta-analysis of previously published case studies (including Mooy et al., 2001, and Eskinasi et al., 2009). Meta-analysis has the potential to increase the statistical power of the results and possible reasons for their variation (Shadish et al., 2001).

Recent studies represent more diverse study types than those explored by Rouwette et al. (2002), as shown in Table 5. Recent research includes five different study types (Cavana, Delahaye, & Sekaran, 2001; Cook & Campbell, 1979): experiments (with a randomized control group), field experiments (with a non-randomised control group), pretest–posttest comparisons (with no control group), posttest surveys (with no control group), and population surveys (with no treatment group).

Early research on GMB included mostly posttest surveys, with three single group pretest/posttest surveys and two field experiments. Before 2001 there had not been an experiment in controlled conditions using randomised groups; and their new presence represents a shifting balance in GMB research, between external validity against experimental control (Blaikie, 1993). These experiments involve problems where participants do not expect their recommendations to be implemented (Borštnar et al., 2011; Fokkinga et al., 2009; McCardle-Keurentjes et al., 2008, 2009; Shields, 2001, 2002; Škraba et al., 2003, 2007). These are in contrast to applied problems, where participants have an expectation that their recommendations will be implemented, and where participants may therefore feel affected by or responsible for the outcomes of the GMB process. In working on applied problems, the recommendations of the group have greater consequence, which may affect the attitudes and behaviours of participants (Aronson, Wilson, & Brewer, 1998; Zagonel, 2002).

The combination of high validity applied settings and high control experimental settings should theoretically increase the reliability of the findings through triangulation (Jick, 1979). Other authors (Andersen et al., 1997; Rouwette et al., 2002; Scott et al., 2013) have supported the idea that these various research designs are each valuable and make important contributions. Unfortunately, each method explores slightly different topics, reducing the advantage of mixed methods research. Additionally, as experimental research has increased in prevalence it may simultaneously be declining in relevance, as GMB literature places increasing emphasis on social and behavioural dynamics. Early GMB research focussed primarily on the individual learning effects of participants (Andersen, Maxwell, Richardson, & Stewart, 1994; Richardson, Andersen, Maxwell, & Stewart, 1994). It is thought that these learning effects can be studied in controlled experiments, as the cognitive processes are thought to be influenced by the workshop method more than the decision context (Capelo & Dias, 2009; Cavaleri et al., 2002; Gary & Wood, 2007, 2011; Hopper & Stave, 2008; Jensen, 2005; Kopainsky et al., 2009, 2010a, 2010b, 2011a, 2011b, 2012; Kopainsky & Saldarriaga, 2012; Kopainsky & Sawicka, 2011; Langley & Morecroft, 2004; Maani & Maharaj, 2003; Moxnes, 2004; Mulder et al., 2011; Plate, 2010; Stouten et al., 2012; Yasarcan, 2010). More recently, there has been a split between research on learning effects of individuals through using system dynamics methods and the interpersonal effects of groups working together to create system dynamics models (GMB). Recent theory in group model building focuses on interpersonal persuasion (e.g. Rouwette et al., 2011a) and conditions that build group trust, agreement, and fuel further working together (e.g. Black & Andersen, 2012). Experimental research is likely to be less applicable for studying these effects, as the social dynamics likely differ between group decisions in applied and not applied contexts.

The studies reported in Rouwette et al. (2002) include only surveys and pretest/posttest comparisons. In recent literature, a number of new tools were used, including interaction analysis (van Nistelrooij et al., 2012) and content analysis of the workshop conversations themselves (McCardle-Keurentjes et al., 2008), as well as a pretest/posttest/delayed comparison (Scott et al., 2013). Several studies compared multiple evaluation methods, either comparing survey results with interview results (Rouwette, 2011; Scott et al., 2015), or comparing survey results with pretest/posttest comparison (Scott et al., 2013). Each method revealed compatible results, which increases our confidence in the validity of the instruments used.

Surveys are convenient but limited (Baddeley, 1979). Individuals do not provide reliable descriptions of their own cognitive change (Doyle, 1997), due to: introspection illusion (where individuals describe what they think must have happened, rather than actual recollections, Nisbett & Wilson, 1977); hindsight bias (where individuals assume their current view is the one they have always held,
Tversky & Kahneman, 1973); or subject bias (where individuals report what they think researchers want to hear,
Orne, 1962). Recent literature includes a range of methods that do not rely on participant introspection (Fokkinga et al., 2009; McCardle-Keurentjes et al., 2008; Scott et al., 2013; van Nistelrooij et al., 2012). These more objective tools are preferable to increase our insight into actual (rather than perceived) effects of GMB.

There have now been at least 45 publications from 1987 to 2014 that provide quantitative evidence relating to the effectiveness of GMB. Almost all studies provide evidence that supports the efficacy of GMB (see Table 6
                        ). We can say with some confidence that GMB produces a range of cognitive and interpersonal outcomes that are considered beneficial to group decision processes.


                           Rouwette et al. (2002) described the outcomes of GMB as occurring at four levels: individual; group; organisation and method (see Table 6). Many of the outcomes explored in early research continue to be evaluated in recent studies, alongside several new outcomes. The new outcomes are persuasion, decision quality, power levelling, and group cohesion. Each is considered further below.

GMB studies on persuasion include both studies on the outcome (Eskinasi et al., 2009; Rouwette et al., 2011; Scott et al., 2013) and the mechanism (Eskinasi et al., 2009; Rouwette et al., 2011; Scott et al., 2014b).

Decision quality has been rated by participants (van den Belt et al., 2004; Rouwette et al., 2014), and also assessed using the number of variables considered (Dwyer & Stave, 2008; Fokkinga et al., 2009) and the extent to which discussion of the problem preceded discussion of solution (Dwyer & Stave, 2008).

The study on power levelling used interaction analysis to demonstrate that, in GMB, less-powerful members are less disadvantaged in their contribution to discussion (van Nistelrooij et al., 2012).

In two studies, participants rated the dynamics of the group at the conclusion of the GMB intervention as more cohesive and collaborative than at the beginning (van den Belt, 2004; Videira et al., 2012).

Although many of the same outcomes were reported, the quality of evidence has improved. In particular, there has been a shift from survey results reporting on participants’ perceptions of what the intervention achieved, to more objective methods. Before 2001, efficiency and communication quality had only been reported on the basis of participants’ perceptions. Now, these have been reported using more objective measures (Borštnar et al., 2011; McCardle-Keurentjes et al., 2009). Additionally, there has been a greater focus on objective measures in the reporting of insight (Eskinasi et al., 2009; Rouwette et al., 2011; Scott et al., 2013) and consensus (Scott et al., 2013; Škraba et al., 2003, 2007).

The outcomes reported in GMB literature have been observed at different stages: during modelling workshops (e.g. McCardle-Keurentjes et al., 2008; van Nistelrooij et al., 2012), at the conclusion of the workshops (e.g. Rouwette, 2011; Scott et al., 2014a), or a long time after the intervention (e.g. Huz, 1999; Scott et al., 2013).

Several studies directly compared GMB to other methods, but the relative effectiveness and appropriate context for GMB versus other methods remains unclear. Four field experiments have been used to compare GMB to traditional meeting facilitation. Two studies compared treatment and control groups in different organisations, and found greater consensus and commitment with GMB (Dwyer & Stave, 2008; Huz, 1999), but it is not clear that the groups in either field experiment were comparable. van Nistelrooij et al. (2012) tested a control and treatment group in the same organization, and found that GMB is associated with greater power-levelling than a normal meeting. One further field experiments compared the conditions for persuasion and found GMB more effective than a “study day” (Eskinasi et al., 2009).

Three experiments compared GMB to other methods using randomised control trials, studying university students working on abstract problems. Two compared GMB to traditional facilitation, and found that GMB is associated with more sharing of hidden knowledge (McCardle-Keurentjes et al., 2008), but not more shared understanding, communication or commitment (McCardle-Keurentjes et al., 2009). Fokkinga et al. (2009) compared participation in the creation of causal loop diagrams to studying diagrams completed by others, and noted improved outcomes associated with GMB at a group and individual level. As discussed earlier, the artificial context for these experiments may affect the behaviour of participants, and therefore these studies may lack external validity (Shadish et al., 2001).

Several studies ask participants to compare the outcomes of the meeting to a hypothetical “normal” meeting (Mooy et al., 2001; Rouwette, 2011; Scott et al., 2014a; Vennix & Rouwette, 2000; Vennix et al., 1993). Participants in all studies believed that GMB results in faster and better outcomes than a normal meeting.

There is an apparent contradiction between the experimental results on shared understanding, communication quality, and commitment, that did not support GMB (McCardle-Keurentjes et al., 2009), and both field experiments (Dwyer & Stave, 2008; Eskinasi et al., 2009; Huz, 1999) and posttest surveys without a control group (Rouwette, 2011; Scott et al., 2014a; Vennix & Rouwette, 2000; Vennix et al., 1993), that did support GMB as more effective than normal meetings. This apparent contradiction highlights the challenges with applied business research (Shadish et al., 2001): the abstract experimental research has unknown external validity; the small number of cases in the field experiments mean the treatment and control groups may not be comparable; and the method used in the applied research (where participants compare their experience to another hypothetical situation) is of unknown reliability (Scott et al., 2014a). On balance, the bulk of the evidence supports GMB as likely to be more effective than normal meetings at achieving individual and group outcomes in the group decision contexts in which it has been tested.

There have also been several calls to understand how GMB is both similar to and different from other related methods (Ackermann et al., 2010; Andersen et al., 2007; Lane & Oliva, 1998; Rouwette et al., 2009, 2011b). GMB has been compared only to “traditional facilitation” and “normal” meetings, and not to other problem structuring methods. The current state of our understanding with respect to what GMB achieves is summarised in Table 7
                            below. The research questions have been split for clarity and improved granularity where the results differ (for example, “Can GMB produce individual and group level effects” is reported in Table 7 as “Can GMB produce individual level effects?” and “Can GMB produce group level effects?”).

Group model building has now been evaluated and shown to be effective in a range of contexts, including policy making (Beall & Ford, 2010; Cockerill et al., 2006; Dwyer & Stave, 2008; van Nistelrooij et al., 2012), strategy development (Rouwette, 2011), strategy implementation (Scott et al., 2014a), and both intra- (Scott et al., 2013) and inter-organisational (Rouwette, 2011) agreement. All of these studies report positive outcomes; this provides some evidence to indicate use of GMB in these contexts, but nothing to guide when not to use group model building.

These case studies provide examples of where GMB has been applied, but are likely to be a tiny sample of GMB practice, and provide no evidence about its prevalence or distribution. There remain unanswered questions about when and why GMB is chosen by practitioners, and when and why GMB practitioners are chosen by clients (see “negotiating entry” – Mingers & Rosenhead, 2004). In a related field, members of the OR profession were surveyed about their use and decision to use soft systems methodology (Mingers & Taylor, 1992). A similar survey approach could be used in the system dynamics profession to explore when, how often, and why GMB is used.

Despite its apparent virtues, GMB is unlikely to be the best approach to every problem. Two factors appear important for choosing when to apply GMB: the outcomes desired in a given situation; and the likely effectiveness of GMB in achieving those outcomes compared to alternate methods. One study related the reported outcomes of GMB to potential-client objectives in a range of decision contexts (Scott et al., 2015). This study explored only a small range of contexts (group decisions commissioned by public servants in New Zealand), but begins the quantitative evidence base for understanding clients’ objectives.

There remains no direct comparison of GMB effectiveness in different settings, to suggest when GMB might be most effective. Several studies have used identical or similar survey instruments (Dwyer & Stave, 2008; Eskinasi et al., 2009; Mooy et al., 2001; Rouwette, 2011; Scott et al., 2014a; Vennix & Rouwette, 2000; Vennix et al., 1993). Meta-analysis of these results could add greater statistical power to the analysis, as well as the opportunity to directly compare results from different contexts. Such a comparison has not yet been published. One unpublished dissertation described the conditions under which GMB supports learning, based on qualitative study of ten cases (Thompson, 2009).

It is only part of the story to consider that GMB is effective in certain situations, or that it is more effective in some situations than others. When faced with a problem setting, there are a large number of possible methods to choose from. As described in Section 4.1 above, GMB evidence should ideally identify when GMB is likely to be the best available approach to meeting the clients’ objectives. Four field experiments compare GMB effectiveness to “normal” meetings, with findings that are likely to be most applicable in comparable settings. Two studies concern intra-organisational policy decisions (Huz, 1999; van Nistelrooij et al., 2012) and two concern inter-organisational policy decisions (Dwyer & Stave, 2008; Eskinasi et al., 2009). Two studies were conducted with a government client (Huz, 1999; van Nistelrooij et al., 2012) and two with stakeholders from the community sector (Dwyer & Stave, 2008; Eskinasi et al., 2009). All four studies reported GMB as more effective than “normal” meetings. No comparisons were found for other contexts.


                           Jackson and Keys (1984) provide one theoretical framework for understanding when to use different methods. Though this framework does not mention GMB by name, the focus in GMB literature on group participation and complex problems (Vennix, 1999) suggests GMB would be most effective in “complex pluralist” settings. This framework has not been tested empirically.

The empirical basis for selecting GMB is further complicated by multi methodology approaches (Mingers & Brocklesby, 1997; Munro & Mingers, 2002). While some authors suggest choosing a single method for each system (Flood & Jackson, 1991), other suggest using mixed and multi methodology, and adapting the selection of methods as the intervention progresses and the problem is better understood (Mingers & Brocklesby, 1997). Creating evidence-based guidelines for method selection in a multi method environment may be an unreasonable expectation, due to the many variables and combinations that could be explored. The current state of our understanding with respect to when GMB should be used is summarised in Table 8
                            below.

Group model building has evolved organically as an offshoot of system dynamics modelling. System dynamics was created within a positivist paradigm as a discipline for to understanding the nonlinear behaviour of complex systems over time using stocks and flows, internal feedback loops and time delays (Forrester, 1961). The reported positive effects on group trust and agreement (Black & Andersen, 2012) were an unintended consequence that is now exploited by GMB practitioners. These effects were discovered and cultivated by talented practitioners, but further development will depend on adding more “science” to the “craft” (Andersen et al., 1997). There is evidence of varying quality for how it is used now, how it works, and how to select the right tools for the job, as explored below.

There is limited evidence for how GMB is currently applied. One literature review describes the processes used in 86 published case studies (Happach et al., 2012). One survey explores practitioners’ views on best practice in system dynamics (Martinez-Moyano & Richardson, 2013), which includes reference to group and participatory methods such as GMB. Another survey documents the time commitment to various activities (Luna-Reyes et al., 2006). There is no direct evidence for which tools are used in practice, or how often. In a related field, a survey was used to understand when different tools are used and how they are combined (Munro & Mingers, 2002), and a similar study could usefully be undertaken with respect to GMB.

The workshop tools used in GMB literature vary widely. Many studies do not describe the process in a way that would allow them to be repeated (Andersen et al., 1997). GMB “scripts” (Andersen & Richardson, 1997; Hovmand et al., 2012) provide a new approach to documenting interventions, and describe the tools used with greater consistency and precision. The processes used in GMB literature range from: purely qualitative causal loop diagrams (Fokkinga et al., 2009) through to quantitative simulation (Eskinasi et al., 2009); participant-led modelling (Scott et al., 2013) and expert-led modelling (van den Belt, 2004); and single short workshops (Scott et al., 2014a) to in-depth GMB interventions lasting up to a year (Rouwette, 2011). It is therefore difficult to make general statements about the efficacy of GMB when the term describes such a wide range of processes.

There have recently been efforts to understand how and why GMB affects participants at an individual and group level (Eskinasi et al., 2009; Fokkinga et al., 2009; McCardle-Keurentjes et al., 2008; Rouwette et al., 2011a; Scott et al., 2013, 2014a; van Nistelrooij et al., 2012). These studies provide quantitative evidence to support a number of causative mechanisms that may contribute to its effectiveness. The concepts of cognitive bias (Scott et al., 2014a), persuasion (Eskinasi et al., 2009; Rouwette et al., 2011a; Scott et al., 2014b), and models as boundary objects (Black, 2013; Black & Andersen, 2012; Scott et al., 2014b; Zagonel, 2002), provide a theoretical basis for understanding why GMB is effective, and for identifying new tools to explore. Quantitative evidence has been published to support the modelling as persuasion (Eskinasi et al., 2009; Rouwette et al., 2011a; Scott et al., 2013, 2014b) and boundary object (Scott et al., 2014b) mechanisms. One study compares these proposed mechanisms, and finds comparatively greater support for the boundary object mechanism as an explanation for participants’ experience of a GMB intervention (Scott et al., 2014b).

GMB describes a range of system dynamics tools that have been applied in many different ways (Andersen et al., 1997). There is limited evidence for the effectiveness of different tools. Seven of the reviewed papers used only qualitative GMB tools, and 16 included quantitative GMB methods, but none directly compare the two. Rouwette et al. (2002) compared data from different case studies to provide indirect evidence that commitment, consensus and system change were more likely in quantitative models (than in qualitative-only models), but this could have been due to the longer time-commitment involved in the case studies that used quantitative GMB. Despite the development of a possible framework (Coyle, 2000), there has been no further study on this topic, which limits the ability of practitioners to select the most appropriate method for the job.

Several studies compare the presence or absence of GMB components, and how these contribute to learning outcomes. Experiments have evaluated the importance of the presence of a facilitator (Borštnar et al., 2011; Shields, 2001), the creation of causal loop diagrams (Fokkinga et al., 2009), and the opportunity for group feedback and discussion (Borštnar et al., 2011; Škraba et al., 2003, 2007). One study explored the relationship between the type of modelling used and the importance of facilitation (Shields, 2001), and suggested that facilitation is more important in simulation modelling than conceptual analysis.

Other studies, without control groups, ask participants to rate the contribution of different components to the success of the intervention (Eskinasi et al., 2009; Scott et al., 2014a; Vennix & Rouwette, 2000; Vennix et al., 1993). There are limitations to the ability of individuals to describe their own learning (Doyle, 1997; Nisbett & Wilson, 1977), and the reliability of these findings is not clear.

Several authors have called for greater exploration into why some GMB interventions fail (Andersen et al., 1997; Rouwette & Vennix, 2006). To date this has been explored only qualitatively (Eskinasi & Fokkema, 2006; Größler, 2007), and it is not clear whether this is due to the context (see Section 4.4) or the methods used. Greater clarity in this area could be used to improve intervention design. The limited state of our understanding with respect to how the application of GMB should be applied or improved is summarised in Table 9
                            below.

@&#CONCLUSIONS@&#

Twelve years after Rouwette et al. (2002) considered the state of GMB research, much has changed, but many challenges remain. There has been greater use of more-objective measures that do not rely on participant recollection, new measurements methods have explored different outcomes, and several studies lift the lid on what happens during GMB sessions (rather than only evaluating change at the end). There are several interesting results from small studies that may warrant further attention: what clients want, the duration of participant change, persuasion, the model as boundary object, power-levelling, and the discovery of hidden knowledge. In almost all cases, GMB is reported to be effective in supporting individual and collective changes considered desirable in group-decision contexts.

Although the overall picture is now much richer and more complex, it is far from comprehensive. Evidence is still based on small sample sizes or single case studies, although the use of common methods may allow a meta-analysis in the future. Research is usually lacking in either experimental control or external validity, and each design has been used to measure different things. Finally, there is considerable scope for comparison between GMB and other methods, or between different GMB tools. In many of the research questions, the current literature lacks objective measure, external validity and direct comparison.

Continuing with the status quo seems unlikely to yield different results. More pilot studies will bring more loose ends (Andersen et al., 1997). Further controlled experiments in unrealistic conditions will be discounted by those who see group model building as a social process (Scott et al., 2014b). Additional survey-based studies will be challenged by research that suggests individuals are unreliably witnesses to their own learning processes (Nisbett & Wilson, 1977). Future research in group model building would therefore benefit from three main shifts: from single cases to multiple cases; from controlled settings to applied settings; and by augmenting survey results with more objective measures. Each of these shifts is explored below.

GMB literature contains a large number of pilot studies with interesting and novel findings. These were useful for determining lines of enquiry that warrant further investigation, but despite an increasing number of promising leads, GMB literature is not making the logical step to increased research scale. The findings from these pilot studies should be explored with comparative research across multiple cases (Ragin, 1987, 2000).

There are different views within the OR community on how to gather evidence regarding group processes. Some advocate for controlled experiments to understand analytical processes (Finlay, 1998), whereas others advocate the use of social science methods to understand group/social processes in applied contexts (Checkland, 1999). There has been a gradual change in emphasis in GMB literature from individual-level learning outcomes (e.g. Andersen et al., 1994; Richardson et al., 1994) to the study of group and social processes that build trust and agreement (e.g. Black & Andersen 2012; Rouwette et al., 2011a; Scott et al., 2014b), which suggests that empirical studies should shift their emphasis from unrealistic controlled experiments to field experiments on applied problems. There are limits to what we can learn about these social processes through research where participants are not invested in the outcomes, and where social dynamics do not mirror practical applications.

It is on the basis of these two points that we conclude that the biggest opportunities to advance group model building literature lie in field experiments exploring multiple comparable case studies that differ by a small number of key variables. This can be achieved in two ways. Where resources allow, large research projects can compare multiple interventions (e.g. Huz, 1999). Alternately, multiple projects can be conducted in similar ways to allow for meaningful meta-analysis between different studies (e.g. Rouwette et al., 2011).

This latter approach will require the use of consistent research methods, including providing detailed context (Andersen et al., 1997; Scott et al., 2015), consistent description of the intervention (e.g. “scripts” – Hovmand et al., 2012) and common measurement tools. The only tool that has been reported in multiple studies is the CICC survey tool (Vennix et al., 1993), and continued use of this tool will increase the sample size for meta-analysis. However, this tool relies on self-reporting and is therefore unreliable (Nisbett & Wilson, 1977; Orne, 1962; Tversky & Kahneman, 1973), and should be augmented or supplemented with repeated use of more objective measures.

A number of more objective measurement tools have been described in the literature, including two promising categories: tools that track participants’ decision preferences over time (pretest–posttest – Rouwette et al., 2011a; pretest–posttest–delayed – Scott et al., 2013); or those that use session transcripts as a basis to analyse communication between participants (content analysis – McCardle-Keurentjes et al., 2008; sequential analysis – Franco & Rouwette, 2011; interaction analysis – van Nistelrooij et al., 2012). The analysis of decision preferences is useful for measuring effectiveness and requires only a small investment of time and effort. Analysis of session transcripts is more time consuming, but helps to lift the veil on what actually occurs during a group model building session. The use of these existing tools should be preferred where possible to the creation of new tools, as this will increase the available sample size for meta-analysis.

Robust, comparative field experiments, using consistent research methods, provide an opportunity for GMB research to move beyond anecdote, experience, case studies and unrealistic controlled experiments. Such a research approach could be used to help inform practitioners on both when and how to use group model building approaches.

@&#REFERENCES@&#


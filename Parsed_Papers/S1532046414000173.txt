@&#MAIN-TITLE@&#Evolutionary strategy to develop learning-based decision systems. Application to breast cancer and liver fibrosis stadialization

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An evolutionary-based strategy for building decision models is proposed.


                        
                        
                           
                           Five medical datasets (breast cancer and liver fibrosis) were used for assessment.


                        
                        
                           
                           The synergetic decision-making involved is easy to understand and apply.


                        
                        
                           
                           Statistical benchmark showed the effectiveness of the model.


                        
                        
                           
                           The model is expected to easily adapt to different medical decision-making issues.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Decision support systems

Evolutionary computing

Machine learning algorithms

Weighted voting system

Breast cancer

Liver fibrosis stadialization

@&#ABSTRACT@&#


               
               
                  The purpose of this paper is twofold: first, to propose an evolutionary-based method for building a decision model and, second, to assess and validate the model’s performance using five different real-world medical datasets (breast cancer and liver fibrosis) by comparing it with state-of-the-art machine learning techniques. The evolutionary-inspired approach has been used to develop the learning-based decision model in the following manner: the hybridization of algorithms has been considered as “crossover”, while the development of new variants which can be thought of as “mutation”. An appropriate hierarchy of the component algorithms was established based on a statistically built fitness measure. A synergetic decision-making process, based on a weighted voting system, involved the collaboration between the selected algorithms in making the final decision. Well-established statistical performance measures and comparison tests have been extensively used to design and implement the model. Finally, the proposed method has been tested on five medical datasets, out of which four publicly available, and contrasted with state-of-the-art techniques, showing its efficiency in supporting the medical decision-making process.
               
            

@&#INTRODUCTION@&#

A decision support system(DSS) is defined as a computer-basedinformation system assisting thedecision-makingprocess involved in solving a large variety of real-life problems [1]. Basically, DSSs are developed to support the solution of unstructured management issues in order to improve the decision-making process.

Recent advances in information technology, artificial intelligence (AI) and statistical learning (SL) enhanced these systems, giving rise to intelligent DSS (IDSS). By incorporating different AI/SL techniques, DSS is likely to become “artificially” intelligent, ideally behaving like a human expert [2]. IDSSs are based either on standalone machine learning (ML) techniques, such as neural networks, genetic algorithms, support vector machines, cluster analysis, k-nearest neighbors, swarm intelligence, and random forests [3–5], or structured frameworks involving more than one algorithm. Usually, in the latter case, the contribution of the ML paradigms is either weighted or parallelized using more or less sophisticated techniques [6–10]. The IDSSs development was encouraged by their effectiveness proven in many different real-world decision problems, such as: medical decision-making, business and management and education.

The use of IDSS in medical decision-making is nowadays a current practice. On the one hand, the use of single ML approaches is widespread due to their modeling relative simplicity. Thus, in [11] neural networks are applied to predict the severity of acute pancreatitis at admission to hospital. A support vector machines approach has been used for the seizure prediction with spectral power of EEG in epilepsy [12]. Both support vector machines with linear kernel and classification trees have been used for improving the accuracy of early diagnosis of Alzheimer-type dementia [13]. In [14] a competitive/collaborative neural computing system has been considered for early detection of pancreatic cancer. A hybrid neural network-genetic algorithm has been applied in [15] for breast cancer. On the other hand, even if the modeling process is more complex, there are many examples in the literature using combinations of ML techniques in medical studies. Thus, in [16] an ensemble of optimal numbers of pruned classification trees is proposed to both distinguish disease subtypes for optimal treatment in lymphoma and lung cancer patients, and to identify breast cancer patients. Two classifiers ensembles (rotation forest and random oracles) are experimented with in [17] for several medical datasets from the UCI Machine Learning Repository showing the improvement obtained using combination of several classifiers in computer-based medical systems. Rotation forest ensembles of classifiers of 30 machine learning algorithms have been constructed to evaluate their classification performances using Parkinson’s, diabetes and heart diseases datasets from literature [18]. In [19] a combination of multiple feature representations and AdaBoost ensemble learning have been used for tackling the high number of false-positive detections of masses on mammograms when using the computer-aided medical diagnosis. An ensemble of ML classifiers generated by a rotation forest technique is used in [20] to substantiate/justify the performance of such a method in the medical field, using Thyroid, Liver, Haberman, Wisconsin and Hepatitis datasets from UCI Machine Learning Repository.

It is worth mentioning the existence of powerful research groups within well-established universities, who are working in developing IDSSs for medical decision-making, e.g., the project “Heart Disease Program” – a computer system assisting the physician in the task of differential diagnosis and anticipating the effects of therapy in the domain of cardiovascular disorders, developed by the Clinical Decision Making Group within the Computer Science and Artificial Intelligence Laboratory-CSAIL, Massachusetts Institute of Technology-MIT (http://groups.csail.mit.edu/medg/projects/hdp/).

The current work proposes a flexible strategy to design and implement an IDSS, inspired by both swarm intelligence and the evolutionary metaphor. Thus, like in the swarm intelligence approach, typically considering a population of simple agents, interacting locally with one another and with the environment, and also based on the evolutionary paradigm, this strategy envisages integration in an evolutionary manner different well-performing ML algorithms, competing and collaborating with each other in a direct relation to the environment, hence making an “intelligent” global decision. The main contributions of the paper are twofold: first, the description of the evolutionary-inspired strategy followed by the design of IDSS, and, secondly, its validation in different real-life applications regarding medical diagnosis.

The evolutionary-based concept underlying the design and functionality of IDSS is inspired by the meta-classification paradigm successfully used in different domains [21,22]. Thus, by combining several ML techniques into a single system, a committee of algorithms is firstly formed, and, secondly, the overall decision of the committee is achieved in a synergetic evolutionary way using a fitness-based weighted voting system (WVS).

Firstly, the idea borrowed from the evolutionary paradigm is choosing efficient types of natural computing algorithms to form the initial population of solutions for a decision problem. Then, they will “evolve”: (a) new variants (obtained by ‘mutation’), and (b) hybrids (obtained by ‘crossover’) will be developed, forming the next population. Next, they will be tested based on their fitness given by the individual decision performance and the best of them will be retained, in order to replenish the new generation. After a certain number of generations, the most performing algorithms will be kept to form the decision system. Briefly, the population of potential solutions (i.e., algorithms) is subject to a problem-dependent selection process, followed by the creation of a fitness proportional hierarchy.

Secondly, the synergism of this structure involves the collaboration between the selected algorithms in making the final decision, based on proportionally WVS and inspired again from the evolutionary metaphor. In this respect, the ‘crossover’ operator refers to the ‘recombination’ of the individual ‘decision genes’ using the fitness-based weights, and the ‘offspring’ represents the ‘joint’ final decision.

Because the algorithms representing the ‘intelligent’ components of the decision ‘engine’ are mostly of stochastic nature, they have to be independently run a certain number of times to obtain a reliable result regarding their robustness and effectiveness. From a statistical point of view, the classification accuracy obtained during the multiple independent computer runs of each algorithm constitutes a sample of decision performance. To ensure the statistical tests will have adequate power, one must perform a power analysis prior to running the experiment. In this respect, a sample size estimation procedure (two-tailed type of null hypothesis, with default statistical power goal P
                        ⩾95%, and type I error α
                        =0.05) has been proposed. The model validation has been achieved by using the standard 10-fold cross-validation. The average accuracy computed as the percentage of correctly classified cases represents the decision performance of each competitor.

The corresponding fitness measure of selecting the best performing algorithms has been defined by the decision accuracy of each algorithm in the testing phase (Test), along with the corresponding standard deviation (SD).

The fitness-based contrast between the algorithms performance was statistically analyzed using the well-known one-way ANOVA technique applied to the independent samples of computer runs, allowing thus the testing of nested performances [23]. The ANOVA output consisted of: sums of squares (SS), degrees of freedom (df), mean squares (MS), F-value, and p-level. Note that the underlying assumptions are fulfilled since the samples are independent, with equal size (balanced experiment), and fairly large. A follow-up test consisting of the two-sided z-test for comparing proportions of correctly classified cases was done, thus assessing the difference between algorithms performances.

The algorithms were then grouped according to their appropriateness to the problem solving using the k-means clustering. Technically, the algorithm has been run for k ranging from 2 to N
                        −1, where N is the number of competitors, using the decision performance of each competitor on each dataset. The initial centroids have been chosen to maximize the distances between-cluster. An analysis of variances comparing the within-cluster variability and between-cluster variability to estimate the near optimal number of clusters has been subsequently conducted. Finally, the clusters are sorted in descending order of mean performances, representing the first level of algorithms’ hierarchization.

Based on the fitness measure used in conjunction with the benchmark methodology, the initial algorithms were statistically compared and the fittest were chosen to seed the next generation by applying the ‘variation’ approach. Inspired by the idea underlying the classical variation operators from the evolutionary computing field, we have naturally considered the hybridization of two algorithms as ‘recombination’, and the development of new variants as ‘mutation’.

The survivor selection mechanism used in this approach is based on a steady-state model, in which the entire population is not replaced at once, but just a number of individuals are replaced using a rank-based selection.

The end of the evolutionary process is determined by choosing different STOP conditions, such as: flat improvement curve, and limited population diversity.

In the decision-making process, the IDSS components are involved in a weighted collaborative operating mode, seen as a variation of meta-classification techniques.

Technically, once the benchmark process accomplished for the last generation, one chooses a number of clusters containing the best performing algorithms. The choice of the optimal number of clusters is problematic. If we carry out a decision-making process in a sensitive medical area like cancer detection, for instance, we have to take into account a larger number of algorithms although computational costs are higher. Conversely, if the decision process must be fast even if accuracy will be lower, the choice will target algorithms in the very first top clusters. Thus, the choice of a cut-off value for the number of algorithms (clusters) depends on the problem at hand.

The overall decision-making process consists of a two-level hierarchization of algorithms according to their testing accuracy:
                           
                              (a)
                              Hierarchization of clusters.

Hierarchization of algorithms in each cluster.

The best performing algorithm in each kept cluster will be weighted proportionally to both the normalized performance of the cluster and its own normalized performance. Mathematically speaking, the normalized performances of the chosen clusters form a convex combination of the corresponding mean performances, while the normalized performances of algorithms in a cluster also form a convex combination of their mean performances. Technically, if P(Ci
                        ) represents the mean performance of the cluster Ci
                        , then αi
                         represents its normalized performance, and:
                           
                              (1)
                              
                                 
                                    
                                       α
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 P
                                 (
                                 
                                    
                                       C
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 /
                                 Σ
                                 P
                                 (
                                 
                                    
                                       C
                                    
                                    
                                       i
                                    
                                 
                                 )
                                 ,
                                 Σ
                                 
                                    
                                       α
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 1
                                 .
                              
                           
                        
                     

Next, if P(Aik
                        ) represents the mean testing performance of the algorithm Aik
                         belonging to the cluster Ci
                        , then βik
                         represents its normalized performance, and:
                           
                              (2)
                              
                                 
                                    
                                       β
                                    
                                    
                                       ik
                                    
                                 
                                 =
                                 P
                                 (
                                 
                                    
                                       A
                                    
                                    
                                       ik
                                    
                                 
                                 )
                                 /
                                 Σ
                                 P
                                 (
                                 
                                    
                                       A
                                    
                                    
                                       ik
                                    
                                 
                                 )
                                 ,
                                 
                                 Σ
                                 
                                    
                                       β
                                    
                                    
                                       ik
                                    
                                 
                                 =
                                 1
                                 .
                              
                           
                        
                     

Finally, the weight 
                           
                              
                                 
                                    α
                                 
                                 
                                    i
                                 
                              
                              *
                              
                                 
                                    β
                                 
                                 
                                    ik
                                 
                              
                           
                         will be assigned to algorithm Aik
                        .

The best algorithms thus selected to form IDSS will be applied to new data and an overall decision will be made based on WVS. Mathematically, WVS was represented as {w
                        1
                        ,w
                        2,…,
                        wk
                        }, where to algorithm Ak
                         is assigned the corresponding weight wk
                        .

In essence, the synergetic decision-making process has two steps:
                           
                              (1)
                              The weights’ estimation for the selected algorithms. By default, a weight is directly proportional to the individual decision performance.

Computation of the voting process output to establish the IDSS decision, and estimation of the corresponding confidence level representing the weighted mean of the best algorithms’ decisions; moreover, an upper bound of the IDSS decision can also be determined.

The assessment of both the confidence level and the upper bound of the IDSS decision is based on a probabilistic approach described in [14], using the total probability formula and theinclusion–exclusion principle in probability.

The proposed IDSS has been applied on five real-world medical datasets presented below:
                           
                              1.
                              
                                 Breast Cancer Wisconsin (Original) – BCWO (UCI Machine Learning repository). BCWO consists of 683 cases with two decision classes: benign 444 (65%) instances and malign 239 (35%) instances. The database contains nine ordinal (categorical) attributes: clump thickness, uniformity of cell size, uniformity of cell shape, marginal adhesion, single epithelial cell size, bare nuclei, bland chromatin, normal nucleoli, mitoses (detailed description of the BCWO database at: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Original%29).


                                 Breast Cancer Wisconsin (Diagnostic) – BCWD (UCI Machine Learning repository). BCWD consist of 569 cases, with two decision classes: benign 357 (62.74%) instances and malign 212 (37.25%) instances. From the total of thirty-two attributes, ten numerical attributes have been considered as the most relevant from medical point of view: radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension (detailed description of the BCWD database at: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer Wisconsin+%28Diagnostic%29).


                                 Breast Cancer – BC (UCI Machine Learning repository). BC consists of 286 cases with two decision classes: non-recurrent-events 201 (70.27%) instances and recurrent-events 85 (29.72%) instances. The database contains nine mixed attributes, with three numerical attributes and six categorical attributes: age, tumor-size, inv-nodes, menopause, node-caps, deg-malig, breast, breast-quad,irradiat (detailed description of the BC database at: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer).


                                 Breast Cancer Wisconsin (Prognostic) – BCWP (UCI Machine Learning repository). BCWP, consists of 198 cases with two decision classes: non-recurrent-events 151 (76.26%) instances and recurrent-events 47 (23.73%) instances. From the total number of thirty-four attributes contained by the database, ten numerical attributes have been considered to be the most relevant from medical point of view: radius, texture, perimeter, area, smoothness, compactness, concavity, concave points, symmetry, fractal dimension (detailed description of the WRBC database at: http://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Prognostic%29).


                                 Liver fibrosis – LF Liver fibrosis database (LF) consists of 722 patients with chronic HCV infection. They have been tested for the assessment of liver stiffness with the Fibroscan® (Echosens, Paris, France – http://www.echosens.com/). The dataset contains twenty-five attributes related to the five fibrosis stages (F0–F4), considered as decision classes. The database originates from the 3rd Medical Clinic, University of Medicine and Pharmacy Cluj-Napoca, Romania. Recall that, from medical point of view, liver fibrosis is evaluated semi-quantitatively according to the METAVIR F scoring system as follows: F0 – no fibrosis, F1 – portal fibrosis without septa, F2 – portal fibrosis and few septa, F3 – numerous septa without cirrhosis and F4 – cirrhosis, representing liver fibrosis stadialization.

Altogether, the following ML algorithms have been considered in this study: neural networks (NNs), genetic algorithms (GAs), support vector machines (SVMs), k-nearest neighbor (kNN), and naïve Bayes (nB). In this context, four well-known NNs have been selected: four-layer perceptron (MLP), radial basis function (RBF), probabilistic neural network (PNN), and self-organizing map (SOM) [24,25].

We considered in this study only the hybridization of MLP with GA in order to illustrate the methodology, although a lot of other combinations are possible.

Although the combination of GAs with NNs is not new [26,27], we considered a recent developed variant of evolutionary-driven MLP, which has been thoroughly investigated and validated on several real-world medical datasets [15]. The proposed methodology unfolds in the following manner. The hybrid algorithm consists of:
                              
                                 (a)
                                 
                                    The NN component – the classifier, designed as MLP.


                                    The GA component – the MLP’s weights optimizer, designed as GA.

Concretely, MLP consisted of a number of inputs equaling the number of predictive attributes, one hidden layer with a number of processing units equaling the number of decision classes, and one output unit representing the resulting class attribute.

For GA, the binary tournament selection has been used, while the blend crossover (BLX-α) and non-uniform mutation have been considered as variation operators.

The ‘mutation’ considered in this paper consisted of an artificial replica of the way the human brain works, commonly known as partially connected neural network (PCNN). Thus, following the methodology presented in [28], we developed PCNN built in the following manner: after a certain number of training samples have been presented to the network, the weights that did not suffer major modifications (i.e., did not surpass a certain threshold 
                              
                                 τ
                              
                            throughout the BP learning algorithm) are erased from the network’s architecture, being inhibited (i.e., set to 0). After heuristically investigating different MLP architectures, we have considered a model with two hidden layers. For the first hidden layer we experimentally chose 7 neurons, providing optimal performance. The second hidden layer contains a number of processing units equaling the number of decision classes, and there is one output unit representing the resulting class attribute. Different parameters have been investigated aiming to produce higher performance with less computational costs.


                              
                                 
                                    1.
                                    For a standardization of the decision performance of MLP, RBF, PNN, SVM, kNN, and nB, and for statistical tests, we used the implementation within the Statistica 7 package – StatSoft. Inc., Tulsa, OK 74104, USA.

MLP/GA, PCNN, and SOM have been implemented in Java by the authors.

For the sake of simplicity, we considered in this study the evolutionary process based only on a crossover and a mutation. Without any further difficulty, the process can be extended over several generations. The significant optimization of the decision model, obtained ending the evolution after one generation, showed the efficacy of such an approach.

A main open question that cannot be simply answered without a complex combinatorial optimization approach concerns the choice of the values to be set for the algorithms parameters, taking into account the diversity of datasets. For the sake of simplicity, in this study we heuristically chose them for each dataset separately.

@&#RESULTS@&#

Experiments on the five benchmark real medical datasets, involving the nine ML algorithms – the initial seven and the two offspring – are twofold. It is envisaged to validate the new decision-making approach against real-world decision tasks, as well as to confirm the assumption that an ensemble-classifier reaches a more precise decision than a single one. Comparisons to results obtained by other state-of-the-art techniques on the same datasets have also been made.

In this subsection, the experimental results of the nine algorithms, competing to form IDSS, are presented, described and discussed. Since 100 independent computer runs provide an adequate statistical power, each algorithm has been independently executed 100 times (i.e., each model has been run 100 times in a complete 10-fold cross-validation cycle). The experimental results regarding the performance of the proposed ML algorithms are displayed in Table 1
                        .

Depending on the algorithm and the dataset, the best accuracy result, obtained as the average over 100 independent complete cross-validation cycles, is of 96.92% correctly classified patients provided by SVM on BCWO, while the worst accuracy is of 18.53% provided by SOM on LF.

The visual comparison of the decision performance is illustrated in Fig. 1
                        . The figure clearly indicates that the classification performance depends, as expected, on both the dataset and the algorithm. The largest variations regarding the decision accuracy were observed for SOM and PNN (71.61% and 57.85%, respectively), while MLP/GA, SVM, PCNN and MLP proved a much better stability (32.42%, 36.05%, 36.29% and 36.69%, respectively). In addition, the smallest standard deviations of the latter techniques demonstrated their larger robustness against the datasets diversity.

The one-way ANOVA technique used to test for differences among the average decision accuracies revealed highly significant contrasts (p-level <0.0001) in testing accuracy between the nine competitors regardless of the dataset. The ANOVA output is presented in Table 2
                        .

The follow-up two-sided z-test conducted to assess the difference in proportions of correctly classified cases has revealed the following statistically significant differences in classification performance (p-level <0.05):
                           
                              •
                              BCWO dataset: PNN vs. {MLP, RBF, SVM, kNN, nB, PCNN};


                                 BCWD dataset:
                                    
                                       –
                                       MLP vs. {SVM, kNN, nB, MLP/GA},

RBF vs. {PNN, SVM};


                                 BC dataset:
                                    
                                       –
                                       PNN vs. {MLP, RBF, SVM, kNN, nB, MLP/GA, PCNN},

SOM vs. {MLP, RBF, SVM, kNN, nB, MLP/GA, PCNN};


                                 BCWP dataset:
                                    
                                       –
                                       MLP vs. {PNN, SOM, SVM, MLP/GA},

RBF vs. {PNN, SVM, MLP/GA, PCNN},

SOM vs. {SVM, kNN, MLP/GA, PCNN};


                                 LF dataset:
                                    
                                       –
                                       MLP vs. kNN,

SOM vs. {MLP, RBF, PNN, SVM, kNN, nB, MLP/GA, PCNN}.

Next, the algorithms have been clusterized and hierarchized according to their decision accuracy using the k-means technique. The results of the corresponding analysis of variances (within-cluster variability vs. between-cluster variability) are illustrated in Fig. 2
                        .


                        Fig. 2 displays the significance p-level against the number of clusters for each dataset. The number of clusters corresponding to the minimum of the p-value ranges between 3 and 5, depending on dataset. The optimum number of clusters (minimum p-level) provided by the analysis of variances technique, and the mean performance P(C) of each cluster are presented in Table 3
                        .

The competitive phase generated a fitness-based hierarchy in terms of classification performance, given in Table 3. Taking into account the difference in performance between algorithms, measured by the corresponding mean performance P(C) of each cluster, and for the sake of simplicity in this concrete application concerning breast cancer and liver fibrosis stadialization, the following clusters of algorithms have been chosen to form IDSS in each case – Table 4
                        .

The corresponding WVSs, computed according to formulas (1), (2) and the probabilistic approach, are shown in Table 5. To avoid the difficulty inherent in the application of the Poincaré formula, and for the sake of simplicity, the upper bound in each case has been computed for the algorithms belonging to the best performing cluster.

Several other ML techniques, such as: cooperative co-evolution, CART decision tree, LFC, ASI, ASR decision trees, naïve Bayes, linear discriminant analysis, SVM, evolutionary SVM (EASVM), hybrid GA/ESVM had been tested against the UCI breast cancer and the liver fibrosis datasets [29–38]. However, their performance displayed in Table 6 cannot be directly compared with the ones obtained by IDSS since the 10-fold cross-validation has not always been used, and ones of them have removed samples with missing data.

Nevertheless, accuracies from Tables 5 and 6
                        
                         indicate that IDSS offers results comparable to other well-established techniques in the literature.

Concrete examples using one real testing case in each dataset are presented in Table 7
                        . The model decision was given by the weighted sum of the corresponding classifiers’ decisions, rounded to the nearest integer, determining thus the medical IDSS diagnosis. Despite the diversity of the standalone decisions, the WVS mechanism provided the correct one. This proves that, due to the two-step hierarchy of the algorithms, the system optimally manages the various decisions of its components. To conclude, this example illustrates the effectiveness of the competitive/collaborative diagnosis system in comparison to separate standalone competitors.

@&#DISCUSSION@&#

Summarizing, the above study focused on two goals: first, to explore the possibility of applying the evolutionary paradigm to optimize the use of ML algorithms in medical decision-making through IDSS, and, second, to validate it in real-world applications regarding breast cancer and liver fibrosis stadialization. Starting from an initial population of eight efficient ML algorithms, and using the evolutionary metaphor of evolving them, an IDSS has been built and applied to real medical data. The synergetic decision-making of the intelligent system proved its effectiveness, regardless the type of data and the dataset size. Moreover, IDSS is readily applicable to other datasets with different number/types of features and decision classes via simply changing its parameters.

Although the evolutionary process was reduced to minimum, involving just one offspring and one mutant, IDSS proved its efficiency. As is borne out by the concrete results, the performance was at least equal to the literature results, therefore it was not necessary to deepen the experiments (more generations, larger initial population of algorithms), even if the system performance would have increased if the evolutionary process had continued, since the main goal was to prove the IDSS effectiveness. It is worth pointing out that in case of different testing samples drawn from each database, IDSS succeeded to smartly use the ability of its component, and hence to provide the true diagnosis, despite the inter-rater disagreement.

Even though the approach is not totally novel, the solution to build IDSS based on an evolutionary strategy is straightforward, advantageous and handy in several aspects:
                        
                           •
                           The evolutionary tools to generate IDSS are transparently presented.

The benchmark process allows a good discrimination between competitors.

The synergetic decision-making, seen as variation of meta-classification techniques, is easy to understand and apply.

Moreover, IDSS is also adaptable to a wide variety of medical decision problems, due to the well-known flexibility and adaptability of its “intelligent” components.

@&#CONCLUSIONS@&#

An evolutionary-based strategy to build an intelligent medical decision model for breast cancer detection and recurrence, as well as for prediction of stages for liver fibrosis in chronic hepatitis C is proposed in this paper.

Applied to five real-world medical databases, its design and functionality proved to be straightforward and efficient. Comparisons to results obtained by other techniques on the same datasets have also been made in order to objectively validate the results of this approach. The proposed IDSS outputs accuracy comparable to that of state-of-the-art ML classifiers applied on the same datasets.

The design and functionality of the application of IDSS for breast cancer detection and recurrence, on the one hand, and for discrimination among stages of liver fibrosis, on the other hand, attained its planned goals. Its performance equaled or exceeded the results reported in literature.

Future research may lie in:
                        
                           •
                           The design and deploy of a management module, seen as the “engine control unit”, automatically running the decision system.

More tuning of the system’s parameters attempting to enhance accuracy, as a combinatorial optimization approach.

The enrichment of the initial population of candidate algorithms by considering other powerful ML algorithms.

The enrichment of the next generations of algorithms by considering more ‘offspring’.

@&#ACKNOWLEDGMENTS@&#

This work was partially supported by the grant number 42C/2014, awarded in the internal grant competition of the University of Craiova. The BC database was obtained from the Institute of Oncology, University Medical Centre, Ljubljana, Slovenia. Thanks go to M. Zwitter and M. Soklic for providing the data. The BCWO, BCWD and BCWP databases were obtained from the University of Wisconsin Hospitals, Madison. Thanks go to Dr. William H. Wolberg, W. Nick Street and Olvi L. Mangasarian for providing the data. The LF database was obtained from the 3rd Medical Clinic, University of Medicine and Pharmacy Cluj-Napoca, Romania. Thanks go to Prof. Radu Badea, Monica Lupsor, and Horia Stefanescu. This work was partially supported by the grant number 42C/2014, awarded in the internal grant competition of the University of Craiova.

@&#REFERENCES@&#


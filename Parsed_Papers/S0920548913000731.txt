@&#MAIN-TITLE@&#The LEGO strategy: Guidelines for a profitable deployment

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Discuss the benefits from a well established long-term strategy (not only tactic).


                        
                        
                           
                           Propose the LEGO approach for making organizations more effective and efficient, optimizing resources.


                        
                        
                           
                           Show the needed elements for designing a strategy for a better deployment of a process improvement initiative.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Process improvement

Maturity models

LEGO

CMMI

ISO/IEC 15504

@&#ABSTRACT@&#


               
               
                  Context
                  When dealing with improvements, organizations seek to find a break-even point as early as possible in order to maximize ROI. In some cases such a strategy can lead to long-term failures by not realizing full benefits, when focusing only on the short-term. LEGO (Living Engineering Process) allows building customized process meta-models based on multiple inputs, making an organization more efficient and effective by optimizing resources, time and costs. This paper introduces elements for designing a strategy for more efficient deployments of process improvement initiatives, optimizing the choice of models and elements to be considered as input to the LEGO approach.
               
            

@&#INTRODUCTION@&#

In the IT domain there are some periodical reports that reveal issues regarding organizational and project management styles and the results achieved, such as the Standish Group CHAOS report [2] or the Gartner Magic Quadrants [3]. Consequently, literature exists that analyzes the possible “top 10” or “top 5” main causes for project failure. However, these reports do not focus on the core problem, concentrating instead on short-term objectives, as opposed to the wider mid to long-term objectives [4–8]. When trying to understand why this happens so frequently and (possibly) to propose ideas for reducing such phenomenon, it is important to analyze an organizations structure [1]. This can be achieved by initially focusing upon the strategic levels of an organization: strategic, tactical and operational, and looking at long, mid and short term objectives. Following a Balanced Scorecard (BSC) deployment [9], all the organizational levels (not only the processes within each defined perspectives) must be aligned and properly communicated to each other, providing enough information at each level to enable management to make the organization effective and proficient.

Unfortunately, there is often a misunderstanding concerning coordinating the different purposes, goals and time-targets, provoking an improper distribution of resources across the different organizational areas [10] (aka “organizational conflict”). One of these areas is the monitoring and control of the organization by periodical audits and appraisals. Due to the “inner quality” costs, many managers feel that minimizing the cost of the “monitoring and control” process as well as the associated improvement actions could lead to a reduction in profit in the short-term, but do not consider investing this saving in other “productive” actions. This lack of vision can be easily represented in business terms through the “cost of non-quality” (CONQ), as in most, well-known total quality management (TQM) studies. Thus, one of the leverages for minimizing the CONQ is to increase the COQ (cost of quality), to help prevent post-release defects and problems from occurring. Looking at the list of possible cost attributes that contribute to the COQ, prevention costs are mostly based on appraisals [11] at different levels, with the aim to detect potential problems or inefficiencies before they happen, removing them earlier at a lower cost, than if detected later after the validation and post-production phases. Thus, the main question is: how much should a company invest in performing appraisals in order to optimize the balancing between COQ and CONQ?

The aim of this paper is to provide at least a partial description of the logical boundary for process appraisals in an organization, not necessarily an IT one, when using Maturity and Capability Models (MCMs). The inclusion of certain questions in management and budget discussions may give the quality department an opportunity to obtain real commitment for long-term objectives [12,13]. Such questions could be e.g.: how many processes should be considered to obtain sufficient information for determining an effective process improvement? Which processes should be included in the initial set of processes to be analyzed in order to stimulate an effective and efficient improvement, when investing a certain amount of budget, without having (or willing) to start with a “big bang” approach?

The paper is organized as follows: Section 2 discusses the main reasons why a process improvement program fails and what should be focused upon to increase the probability of success. Section 3 introduces the LEGO approach and processes, and the need for a strategy. Section 4 describes the first LEGO phase, introducing a simple but effective way to derive your own implementation strategy based upon your historical data and objective evidence. Finally, Section 5 provides some conclusions and the next steps for this work.

Traditionally, process improvement has been used to obtain a path towards achieving certification in a certain model/framework, typically to achieve recognition within a particular market and/or from a customer base. For instance, in the mid '90s, the first wave involved obtaining ISO 9001:1994 certification (and ISO 9002:1994 for services), the main standard for quality management, providing market recognition as being the best in class. The second wave in early Y2K involved gaining compliance with CMMI [14], ISO/IEC 15504 [15] (for ICT companies) or other maturity models, with a focus on the staged representation more than the continuous one, because of the possibility to achieve a benchmark to enable them to compete against direct competitors. The third and last wave was in the mid Y2Ks; this involves searching for multi-model approaches, without having a defined way to create a meta-model. SEI's PRIME initiative [16], like other proposals [17–19], sought a proficient way to integrate multiple models into a single model for representing the final “process reference model” (PRM) that may be used to compare against the organizational Business Process Model (BPM). Existing literature [20–22] highlights the common problems that occur in an improvement project, for example, lack of resources, time pressure, staff turnover, lack of support, lack of sponsorship, etc.

Existing generic Software Process Improvement models are available which include the CMMI and ISO 15504, but these models were not developed to provide sufficient coverage of all areas. Consequently, there is a need to tailor models to a specific context based on these generic models for specific domains (e.g. automobile (Automotive SPICE), space (SPICE for SPACE), medical devices (Medi SPICE etc.).

There are some misconceptions and issues that require particular attention:

An ISO management system standard such as ISO 9001 or ISO 27001 is a list of requirements, not a process model. For instance, clause 6.2.2 (competence, training and awareness) asks for a series of “shalls” about such issues (requirements), but not about how an organization should implement them. On the other side a process model (e.g. CMMI) provides tips and best practices (not mandatory) that may be operational suggestions concerning “how” to do it (e.g. mostly from OT – organizational training – process area plus GP 2.5 – the generic practice about training for each of the assessed processes). Thus, also mappings and comparisons between requirements and process models need to be carefully considered, but not treated as complete substitutes as it often happens
                           1
                        
                        
                           1
                           Mappings and comparisons between CMMI constellations and other models/frameworks are freely accessible at http://www.sei.cmu.edu/cmmi/compatibility/.
                         (I would suggest as much as possible to eliminate footnotes and put them into the text).

In MCMs, a staged representation proposes a predefined list of processes for an evolutionary implementation using blocks of processes. But few people carefully consider, if such a predefined progression is valid for them both from a technical and business viewpoint. For instance, even if many studies (and common-sense) propose and demonstrate that an ISO 9001:2000 certified company is approximately equivalent to a company with a maturity level (ML) between CMMI ML2 and ML3 [23–25], a basic and core process such as root–cause analysis (RCA), CAR (causal analysis and resolution) is a CMMI ML5 process. This means that using the staged representation, an organization that is ISO 9001:2000+ certified cannot demonstrate directly an equivalent value from this inner capability (RCA is part of the ISO 9001 requirements, e.g. clause 8.5.2), therefore, creating an impression that is less than its real value. However, adopting the continuous representation would overcome this issue, by instead measuring capability levels (CLs) for the set of processes – whatever the established ML reference – a company intends to evaluate.

Well-established SPI models such as CMMI or SPICE (ISO/IEC 15504) include a set of processes covering a large part of the project lifecycle in a timely manner and can therefore be defined as “horizontal” (following a timeline, from the beginning to the end of a project). Even if an organization adopts a multi-model integration approach, there are some questions that should be answered e.g. which risks could arise if the organization did not perform a preliminary analysis on critical success factors (CFS) for a proper deployment?

Thus, an RCA should be performed at the strategic level to establish what should be the main list of issues whose fixing would represent the starting point for a sustainable, mid-long term improvement program.

Instead of many organizations working in a proactive manner to determine the yearly budget for process appraisals and improvement programs (e.g. ISO 9001, ISO/IEC 20000-1, CMMI-DEV, ISO/IEC 15504, etc.), they instead work in a “reactive” way. Certification and compliance to standards should be achieved through simply following a logical sequence to accomplish business objectives using common-sense rules and principles. Such a common-sense approach should be based on:
                           
                              •
                              People: even if properly designed, processes will only succeed if executed by competent and skilled people. Most of the core processes in any organization (e.g. requirements elicitation, CMMI-DEV RD process area) cannot be automated. Consequently, attention to “soft skills” is required. Furthermore, as in many performance management models and frameworks (e.g. BSC [26,27], MBQA [28], EFQM [29], etc.), people are an “enabler,” coming first in terms of timing in the value chain [9]. Fig. 1
                                  comes from a proposal for splitting the “Learning and Growth” perspective into two: infrastructure and innovation and people. This helps to explain the interactions among the resources used for activating the “internal business process(es).” The greater the training and motivation that people receive, in addition to be supported by the right infrastructure, the more productive and proactive they can be in running the internal business processes.

Data–information–knowledge–wisdom (DIKW) [30]: is an acronym from the ITIL v3 Knowledge Management process, describing what is required for increasing the organizational knowledge, from historical data (less data equates to lower quality estimates and higher discrepancies between estimates and final values) to real wisdom, providing guidance as to “why” specific actions are or are not taken. The business questions to be answered include: are we assessing/appraising the right things? And are we assessing/appraising the things right?

The most important lesson learned relates to the logical flow to follow for learning: you cannot derive information if you do not gather data; you cannot derive knowledge without having enough information; and last but not the least, wisdom cannot be acquired without having an organizational knowledge based on proper, structured historical data (Figs. 2, 3, 5, 6, and 11
                        
                        
                        
                        
                        
                        
                        
                        
                        
                        ).

But – from the aim of this paper – the same happens also when dealing about the three working levels, introduced later (STO: strategic–tactical–operational). A strategy cannot take place if a history of what happened has not been gathered and “absorbed” into the organization itself a long time. The vision and the capacity to properly look at the mid-long term, mixing the right ingredients for a recipe that can be what can make the real difference between good and excellent or fair and good results.

In an attempt to encourage proactive process improvement, we have proposed a common-sense approach, called LEGO (Living Engineering Process) [17] for stimulating organizations to improve their own processes, by taking components (such as the real LEGO bricks) from multiple, potential information sources and integrating them to form a unique, reinforced picture for a particular process or set of processes.
                           2
                        
                        
                           2
                           Other approaches to achieve this goal are ontology-based (e.g. comparing couples of models/frameworks at a time [39]) or SLC-based (e.g. using the five ITIL v3 phases for introducing changes in the light of the Continual Service Improvement approach [40]).
                         The starting point – for this paper – is that any model/framework typically represents only a part of the real story. Thus, through handling similar elements from different sources, we can hopefully find more “fresh blood” for improving the organizational processes. This becomes necessary as a frequent misconception of organizations when dealing with certification programs is to shift the real target (improving the process to better satisfy the business objectives) with the supporting tool (e.g., achieving a certain maturity level). Therefore, in order to achieve the real target, we need to pragmatically improve organizational processes by introducing best practices from a selection of models/frameworks and experiences. Therefore, after establishing the business goals there is a need to search for and identify which “supporting tools” are most applicable for the current situation. Unfortunately, it is often the case that organizations prioritize what is required in order to obtain compliance against a particular model rather than striving for the best solution in terms of their processes. Consequently, they risk achieving the opposite effect to what they intended, i.e. to lose and not gain “value.” Thus, the “fresh blood” we need are ideas and practices to be tailored, integrated and re-adjusted so that they will work in a specific organization, as opposed to a generic one. Thus, the LEGO approach enables little bricks to be used for building a concrete organizational value. LEGO has four main elements:
                           
                              1.
                              a “Maturity and Capability Models” (MCM) repository [31] allowing a systematic search for and identification of relevant processes or MMs from existing models;

knowledge about the process architecture of each model, as a basis for understanding how to transform desired elements from a certain model into the target format, especially when considering that the source models may have different architectures that may need to be harmonized into a single model;

mapping(s) and comparisons between relevant models, in order to understand the real differences or the deeper level of detail from “model A” to import into “model B”;

a process appraisal method (PAM) to be applied on the target BPM (Business Process Model).

LEGO has also a related four-step process for determining which elements to consider when improving your current BPM:
                           
                              1.
                              Identify your informative/business goals: clearly identify your needs, moving from the current BPM version and content.

Query the MCM repository: browse and/or search the MCM repository, setting up the proper filters in order to obtain the desired elements (processes, practices, etc.) to be inserted into the target BPM (see Fig. 4).

The MCM is a web-based repository that enables the storage, discovery and retrieval of information on Maturity and Capability Models, providing the ability to locate models through simple and advanced searches using different attributes.

Include the selected element(s) into the target BPM: include the new element(s) in the proper position in the target BPM (e.g. process group, maturity level, etc.).

Adapt and adopt the selected element(s): according to the process architecture of both process models (the target and the source one), the selected elements may need to be adapted, through tailoring the elements as needed.

The LEGO approach and its basic elements have been presented in more detail in Refs. [17,31]. The next step is to provide tips and basic rules concerning how to proficiently apply it from the beginning, providing details about the first step from a strategic viewpoint, but not necessarily from a tactical one.

The first step of the LEGO process is to clearly identify your needs. It then assumes you can choose the preferred approach for an organization, according to both the quantity and quality of data and information available. The interesting question is: how can we do it? This is the goal of this paper. We also attempt to provide an answer to this question in a straightforward manner using practically applicable solutions. It is important to have a strategy, and not to have only a tactical or operational short-mid term focus.

Looking at the Merriam-Webster's dictionary, one of the possible definitions is “an adaptation or complex of adaptations (as of behavior, metabolism, or structure) that serves or appears to serve an important function in achieving evolutionary success.” Thus, a strategy should consider the long-term (“evolutionary success”) and should not be confused with the tactical and operational levels. A possible formalization of such common-sense concepts is the STO model [32], associating different actors, time-frame and business questions to each level.

From the viewpoint of appraisers and auditors, they check the performance of the strategic decisions that were previously established by their management. But is there any consideration as to whether what we are performing is in fact correct or even if we working in the best way possible to achieve our goals? Table 1
                         below illustrates a simple example of using STO goals, from the strategic to the operational level.

The final choice should be made by considering all elements in such a scenario and calculating (even approximately) the ROI looking at different moments in time, not only for determining the BEP (break-even point). Such a multi-level view can also be proposed using a BSC approach, as proposed by Pollard and Buckle [38] in the following figure.

The same approach has been also presented in ITIL core books, stressing the relevance of coordinating more organizational level into a drill-down approach. There would not be a value chain generating a real “value” if the different rings of the chain would not be properly linked overturning from top to bottom their goals in a measurable way.

One of the problems about establishing a strategy is the timing. Few years ago, the operational level was referred to a short time (e.g. 1year), the tactical one to a mid time (e.g. till 3years) and a strategy for a longer period (long time). Now – in period where anything is “i-something” or “e-something” – those time laps have been dramatically reduced and often the difficulty is properly distinguish more and more strategy from tactic issues. Thus, more initiatives are going to fail making confusion about the expected BEP period because of that time lapses reduction, being not properly aligned expectations and business results [43,44]. As Porter wrote few years ago, “operational effectiveness is not strategy” [45].

As introduced at the end of Section 3.1, there could not be any real improvement if an organization does not properly plan, gather and analyze on a periodical basis its own historical data. Table 1 provided a couple of example scenarios about the STO levels: establishing a strategy means to have a vision, a mission and values to introduce and “live” in order to pursue and achieve such goals. Thus the well-known Shewart–Deming cycle, aka PDCA (plan–do–check–act) represents the way to visually identify “where” the strategy should be placed and executed, as discussed below.

In this section we outline our proposal for the design of a strategy. Using the well-known PDCA (plan–do–check–act) phases, Fig. 7 illustrates the main steps within each of the four phases and the potential added value (also stressed with the “+” or “−” signs) for an organization adopting this approach to perform process management for the mid-long term. The colored text shows the additional steps to be run for implementing a strategy against the typical steps for a usual PDCA-based improvement.
                           
                              •
                              Plan: there are three additional steps:
                                    
                                       (a)
                                       establish the strategy;

balance short-term and mid-term objectives;

determine the best appraisal boundary.

The first two relate to the establishment of strategic and tactical goals. During the first step, similar elements from the organization's past experience should be retrieved and analyzed (see notes on the step #4 — Act). When dealing with experience data, they should be mostly referable to products/services more than to other outcomes and outputs such as the strategy. Thus, from a PDCA viewpoint, at an (n
                        +1) iteration, the Plan step should be able also to retrieve information stored in the “Act” phase from the previous iteration(s).
                           3
                        
                        
                           3
                           In order to solve this apparent contradiction, SEI and ESI proposed few years ago their own views on improvement programs with respectively a five or six steps models, called IDEAL and IMPACT.
                         Finally, the third one concerns the final decision for determining the technical boundary for performing the audit/appraisal. A recent proposal for this last step is described and augmented in Ref. [33].
                           
                              •
                              Do: no additional steps in this phase.

Check: two additional steps, extensively explained in Refs. [1,17]:
                                    
                                       (a)
                                       apply the LEGO approach;

output: improved processes.

Act: just a final, additional step:
                                    
                                       (a)
                                       improve the data gathering into the organizational PALs (Process Asset Libraries), but introducing something more than solely D–I levels (Data–Information) from the DIKW path previously introduced (typical for a PAL, as described in CMMI OPD SP1.5) from the full DIKW (as described in ITIL v3, Service Transition book [30]).

In particular, still looking to ITIL CSI (Continual Service Improvement) book [42] and in order to stress how much this is true and commonly shared and diffused by some of the most known frameworks in the IT domain, a PDCA refinement has been introduced, the “7-step improvement” process. Each phase has been split – except for the “A — Act” one – into two steps and the first one (Plan) includes as the first step “Identify the strategy for improvement,” where the main issues are to identify the vision, business needs, strategy, tactical and operational goals.

Focusing our attention on the “Plan” phase, and on the first step (establish the strategy), we can refer to the well-known techniques of total quality management (TQM). TQM tools contain many possible answers for applying old and new quality tools with a simple common-sense mood: e.g. RCA (root–cause analysis), affinity diagrams, pareto diagrams, control charts, etc. [34]. Simulations based on historical data could help in designing a program looking at a larger timeframe than is currently used in organizations. Fig. 8 presents an example of taking a RCA analysis for determining why a project has many more defects than expected [35], and then redrawing it using mind maps, as suggested in Ref. [36]. Fig. 8a shows the same elements from the original paper, while Fig. 8b proposes a refined analysis using the “5 why's game,”
                           4
                        
                        
                           4
                           
                              http://en.wikipedia.org/wiki/5_Whys.
                         showing 3–4 levels of depth.

When determining the final leaf for each branch, it is possible to create a match with the process element from the improvement model(s)/framework(s) from which useful support can come for re-designing processes. We now take a deeper look at some leafs, from the top of Fig. 8b. Time pressure could be due to underestimations which may have arisen for several reasons such as: little historical data were available to assist the estimating process, or estimates were provided by inexperienced people. In the first case, the root–cause is due to the unavailability of a “measurement repository” (using CMMI-DEV, would be stated in OPD SP1.4) or to missing definitions for some values in the project data (related in such case to MA SG1). In the second case (low experience), the related CMMI-DEV element is Project Planning (PP) GP 2.5; this relates to the need for people to be trained. Of course, here a single well-known model has been considered, but suppose we wish to include all the potential elements that could be useful when following the LEGO approach. In other words, mapping one/more model elements is a way to name the areas where the gaps need to be filled and reworked.

Another fundamental concept in TQM is the classification – based on the frequency a certain fact occurs – or problems with special causes (such as low frequencies with no seasonality) or common causes (dependant upon seasonality, repeating patterns of activities may occur). A strategic goal should therefore focus upon repeated patterns (in this case with a negative meaning) for determining stable, mid-long term actions reducing (or at least minimizing) potential negative impacts and stressing as much as possible the positive effects for an organization, whatever the perspective. Thus, consider running several RCAs within an organization in a certain timeframe, and think about the frequency of the “models” elements in order to provide an interesting analysis. We refer to the analysis of the “Project” main leaf from Fig. 8b. Table 2
                         summarizes how many times that specific element was mentioned and establishes an implementation priority (with “A” being the highest priority etc.) based on the causal relationships among processes. Such information is contained into the “Related Process Areas” section at the beginning of each process area description in CMMI. Thus, since missing requirements could be the root–cause for having less formalized requirements and therefore fewer test cases than expected (with a higher potential number of final defects at the release phase), achieving better and deeper requirement elicitations (RD — requirement development) should be implemented first.

In order to determine which areas should be given more priority for reinforcing organizational processes, a Pareto analysis can be performed. Such an analysis lists process areas in descending order of the potential gaps from several RCA run across the organization in a certain time frame (see Fig. 9).

Of course, an improvement plan must consider actions grouped by a certain criterion to be run at the same time, because of the causal link between them. In our research, this criterion is included in the “implementation priority” field.


                        Fig. 10 groups process areas by implementation priority level (from A to E). Thus, if the main problem for an organization related to having too many defects at the release stage, from such an analysis (assuming it has been validated), the improvement plan should start by refining how requirements are captured, making all requirements visible and no longer implicit (priority A), and storing historical data for improving future estimates (priority B), etc. If work is started on the priority A chunk, LEGO will aim to reinforce the organizational BPM through analyzing all possible maturity models/frameworks in relation to it e.g. to Requirement Engineering, or Project Management. The substantial difference from this structured analysis as opposed to simply adopting the thoughts from the management of an organization is that such decision will be augmented by the historical data of the organization, therefore adding more strength to such a decision. Finally, Fig. 10 summarizes the operational flux for satisfying the “establish the strategy” step within the Plan phase.

Thus, the business value from such a preliminary activity would provide a more objective way for deciding which improvement areas should be included when planning an improvement project through using your own historical data as a starting point. Such data can be retrieved from any type of objective evidence (e.g. audits, appraisals) and it is useful as it provides a better understand issues etc. within previous projects. Therefore, such approach would minimize from the outset the risk of adopting a costly and unfruitful process improvement program.

@&#DISCUSSION@&#

Whatever the organization size, a strategy is always required: applying a “flavor of the month” approach cannot allow an organization to achieve mid-long term results, with seeds for a continual improvement over time. Thus, a strategy should be provided that is appropriate to the size and main attributes of an organisation, as also stated both in ISO management system standards (e.g. ISO 9001:2008) and main maturity models (e.g. CMMI-DEV with the quest of introducing a tailoring guideline; see OPD SP 1.2). On the contrary, there is a lack of clear organizational strategy that can be easily observed by the absence (or not clear presence) of MVV (mission–vision–values) elements. Such an absence can easily reveal a weak or absent strategy, that would lead an organization to focus mostly on tactical goals, increasing the risk of not achieving its long-term business goals. A BPR (Business Process Re-engineering) initiative applying a multi-model approach such as LEGO should fit with a certain organizational size and characteristics, as often an ideal model is applied without due consideration as to what really happens.

@&#CONCLUSIONS@&#

This paper introduced and discussed how a strategy can be established for applying LEGO, through building upon an organization's historical data and objective evidences, using well-known TQM tools. Such a preliminary filter allows an organization to focus resources on its technical priorities but keeps in mind that the reference model is the management system of an organization and that any external model must be a potential input for strengthening it and not the ideal target for modifying the processes. Furthermore, even if many valid models/frameworks could be used for carrying out the LEGO approach, from observing ICT organizations they appear to continue to look for and apply only a few common models, while enlarging the analysis to a wider scope could provide richer sources. For example, performance management models such as the Malcolm Baldrige Quality Award (MBQA) and the European Foundation for Quality Management (EFQM) could provide greater assistance in relation to leadership (their first “enabling” criteria) supporting and sustaining improvement initiatives and programs, as well as when using LEGO, which is not particularly developed in ISO 9001 [37] requirements and in CMMI or ISO/IEC 15504 models, as well as other process models in other domains (e.g. Ref. [41]). The more the potential sources to be used, the higher the probability to redesign a set of valuable, improved processes for your own organization. Few more recent experiences have been done in the Requirement Management [46] and Reuse [47] domains.

The next steps of this research will be to formally apply the LEGO strategy on real case studies, in order to validate it by quantitative figures comparing the initial different working hypothesis for an improvement program with and without such an approach.

@&#ACKNOWLEDGEMENTS@&#

This work has been supported by the CNPq (Conselho Nacional de Desenvolvimento Científico e Tecnológico — www.cnpq.br), an entity of the Brazilian government focused on scientific and technological development.

This research is also supported in part by the Science Foundation Ireland (SFI) Stokes Lectureship Programme, grant number 07/SK/I1299, the SFI Principal Investigator Programme, grant number 08/IN.1/I2030 (the funding of this project was awarded by Science Foundation Ireland under a co-funding initiative by the Irish Government and European Regional Development Fund), and supported in part by Lero (http://www.lero.ie) grant 10/CE/I1855.


                     
                        
                           
                              
                              
                              
                                 
                                    BEP
                                    Break-even point
                                 
                                 
                                    BPM
                                    Business Process Model
                                 
                                 
                                    BSC
                                    Balanced scorecard
                                 
                                 
                                    CAR
                                    Causal analysis and resolution (CMMI ML5 PA)
                                 
                                 
                                    CFS
                                    Critical success factor
                                 
                                 
                                    CL
                                    Capability level
                                 
                                 
                                    CMMI
                                    Capability Maturity Model Integration (www.sei.cmu.edu/cmmi)
                                 
                                 
                                    CMMI-DEV
                                    CMMI for development
                                 
                                 
                                    CNPq
                                    Conselho Nacional de Desenvolvimento Científico e Tecnológico (www.cnpq.br)
                                 
                                 
                                    CONQ
                                    Cost of non-quality
                                 
                                 
                                    COQ
                                    Cost of quality
                                 
                                 
                                    DIKW
                                    Data–information–knowledge–wisdom
                                 
                                 
                                    EFQM
                                    European Foundation for Quality Management (www.efqm.org)
                                 
                                 
                                    GP
                                    Generic practice
                                 
                                 
                                    ICT
                                    Information and communication technology
                                 
                                 
                                    IEC
                                    International Electrotechnical Commission (www.iec.ch)
                                 
                                 
                                    ISO
                                    International Organization for Standardization (www.iso.org)
                                 
                                 
                                    IT
                                    Information technology
                                 
                                 
                                    ITIL
                                    IT infrastructure library
                                 
                                 
                                    LEGO
                                    Living Engineering Process
                                 
                                 
                                    LERO
                                    The Irish Software Engineering Research Centre (www.lero.ie)
                                 
                                 
                                    MA
                                    Measurement and Analysis (CMMI ML2 PA)
                                 
                                 
                                    MBQA
                                    Malcolm Baldridge Quality Award (www.nist.gov/quality)
                                 
                                 
                                    MCM
                                    Maturity and Capability Model
                                 
                                 
                                    ML
                                    Maturity level
                                 
                                 
                                    MVV
                                    Mission–vision–values
                                 
                                 
                                    OPD
                                    Organizational Process Deployment (CMMI ML3 PA)
                                 
                                 
                                    PAM
                                    Process Assessment Model
                                 
                                 
                                    PDCA
                                    Plan–do–check–act cycle (Deming)
                                 
                                 
                                    PI
                                    Product Integration (CMMI ML3 PA)
                                 
                                 
                                    PP
                                    Project Planning (CMMI ML2 PA)
                                 
                                 
                                    PRIME
                                    Process Improvement in Multimodel Environments (http://goo.gl/p2GX3)
                                 
                                 
                                    PRM
                                    Process reference model
                                 
                                 
                                    QMS
                                    Quality management system
                                 
                                 
                                    RCA
                                    Root–cause analysis
                                 
                                 
                                    RD
                                    Requirement Development (CMMI ML3 PA)
                                 
                                 
                                    REQM
                                    Requirement Management (CMMI ML2 PA)
                                 
                                 
                                    SFI
                                    Science Foundation Ireland (www.sfi.ie)
                                 
                                 
                                    SG
                                    Specific goal
                                 
                                 
                                    SP
                                    Specific practice
                                 
                                 
                                    SPI
                                    Software Process Improvement
                                 
                                 
                                    SPICE
                                    Software Process Improvement and Capability Determination (ISO/IEC 15504)
                                 
                                 
                                    STO
                                    Strategic–tactical–operational
                                 
                                 
                                    TQM
                                    Total quality management
                                 
                                 
                                    VER
                                    Verification (CMMI ML3 PA)
                                 
                              
                           
                        
                     
                  

@&#REFERENCES@&#


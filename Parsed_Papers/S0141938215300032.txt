@&#MAIN-TITLE@&#Introduction to editable visual object and its description schema for mobile applications

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We analyze the drawbacks of current emoticon system.


                        
                        
                           
                           We introduce an editable visual object which can substitute the emoticon.


                        
                        
                           
                           We propose a schema based EVO description method.


                        
                        
                           
                           We propose a differential coding to transmit the EVO.


                        
                        
                           
                           We implement the prototype mobile application to verify the performance the proposed EVO.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Editable visual object

Description schema

EVO

Prototype

Mobile applications

@&#ABSTRACT@&#


               
               
                  With the spread of portable smart devices, social networking services are gaining popularity. At the same time, emoticons which can be used a primary tool to deliver the enriched personal feelings are also gaining popularity in the social networking services. Now, emoticon markets are much bigger than before since the territory of emoticons broadens the culture and social issues. However, provided emoticons from the service providers are difficult to express the exact personalized feeling. Thus, users cannot edit what they want to express. In this study, we propose a new concept of emoticons, an editable visual object, to resolve above problems. User can edit the components inside the proposed editable visual object and send it to express exact intention. Further, we propose an efficient editable visual object description schema to represent and transmit the editable visual object. To prove the performance and efficiency of proposed technique, we implement and test the prototype system for the mobile device. As shown in the test results, the proposed description method is at most 100 times superior to the compared screen capturing method in the view of transmission bandwidth. The proposed editable visual object can be exploited not only mobile applications, but also various fields such as education and medical field.
               
            

@&#INTRODUCTION@&#

Through the dialogue, people want to not only exchange information, but also sympathize with their thoughts and feelings. Since we could chat with someone via the computer, people was attempting to deliver their exact intention or enriched feeling by using simple drawing which is composed of alphabets or symbols such as :) and ;P. These are called texticons, and these are widely used in computer chatting and short message service (SMS) in the mobile phone. The position of texticons is changed to emoticons after smartphone generalization around 2010 [1–3]. Emoticons are now an essential component of mobile applications such as social networking service (SNS) and mobile messengers. Now, many people choose the mobile applications based on the diversity and design of included emoticons.

As you can see from the survey results about mobile messenger application usage in Fig. 1
                     , the proportion using emoticons in the mobile messenger chatting is gradually increasing. In the case of Kakaotalk which is the most commonly used mobile messenger in South Korea, the proportion of emotion usage is over 95%. The survey results also tell us the prospect that emoticon usage is not easily drop down. The size of emoticon market is also very huge. As shown in Fig. 2
                     , the sales of global mobile messenger market in 2014 will be around 193 billion dollars, and the sales will be reached at 229 billion dollars in 2015. More than 1 billion persons are using mobile messenger, thus a great many emoticons are used in a day.

The amount of emoticon usage is tremendously increased nowadays. The reasons can be found in the abstraction of feelings and intimacy which is the innate characteristics of emoticons. Users can express their complex feelings in easy way by using emoticons. Further, the receiver may feel intimacy when the sender uses emoticons in the case of simple reply.

Emoticons have a lot of strong points mentioned above, however, they also have a few inevitable drawbacks:
                        
                           •
                           It is difficult to find the well-suited one among lots of emoticons in the given situation.

Sometimes, there is no suitable emoticon in the given situation.

Most of emoticons are difficult to deliver the accurate information.

Emoticons are difficult to express the specific actions that user want.

Provided emoticons could not reflect the every user’s personalized preference.

In this study, we propose a new concept of emoticons, the editable visual object. (From now, we refer an editable visual object as EVO.) Also, we propose an efficient way to describe EVO. EVO description method can be used for transmitting and storing EVO.

The remainder of this paper is organized as follow. In Section 2, we propose EVO definition, description method, and transmission. More specifically, the definition and structure of EVO is presented in subSection 2.1. In subSection 2.2, the way how to describe EVO is proposed. In subSection 2.3, the efficient EVO transmission method is presented. In Section 3, we check the operation of EVO and its desciption schema by using the implemented mobile application prototype. Finally, Section 4 provides conclusion and future works.

In this section, we first define the concept and structure of EVO and propose the efficient EVO description method. Also, we think about the efficient way of EVO transmission.

One emoticon uses just one image to express one object, whereas EVO composes a set of component images to express one perfect object as shown in Fig. 3
                        . Further, every component image in the EVO can be rotated, translated, and scaled (i.e. can be affine transformed). For example, in the case of “face” emoticon, every single emoticon is needed to express every facial expression such as smile, irritancy, sad, etc. In the case of “face” EVO, however, we need just one “face” EVO to express the whole facial expressions, since we can edit the angle, size, and position of face components such as eye, nose, and mouth. Also, we can express something by adding or removing the component images. For example, we can express sad by adding tear. Or we can express bold hair by removing hair component images.

To make the EVO structurally, we define EVO is a set of EVOs or one image. It means EVO is recursively defined as shown in Fig. 4
                        . The leaf of tree be a component image. Here, the component images positioned in the leaf is now called NEVO (Non-editable visual object) and NEVO has its own image and it can be rotated, translated, and scaled. According to the definition of EVO, EVO is now a group of EVO/NEVOs. For example, every component image in Fig. 3 are NEVOs such as ears, eyes, nose, mouth and face shape. EVO points a group of face component images here. If EVO is transformed in the affine space, every sibling EVO/NEVO is also transformed in the same way with their parent EVO.

There are many advantages by defining the EVO recursively. First, the number of EVO does not need to be large because one EVO can alternate numerous emoticons in the same category by editing the EVO. Second, users can tailor the personalized EVO which reflects the user preference. Third, EVO can be used to deliver the information that user want to send.

To store and transmit the EVO efficiently, well-structured EVO description method is needed. To design the EVO description schema, we refer to the schema design guideline of service descriptions in the MPEG User Description (MPEG-UD) standard which is one of the MPEG standard groups [7].

Since both EVO and NEVO can be edited in a similar way because EVO is a group of EVO/NEVOs, EVO and NEVO can be described as the same schema format. By doing so, the implementation complexity becomes lower and the reusability becomes higher than maintaining two different schema formats for EVO and NEVO each. From now on, we call the schema which can contain EVO or NEVO data as an EVO schema or EVO description schema.

The proposed EVO description schema is shown in Fig. 5
                        . In the schema, there are three classes; Attribute, AffineTransformation, and ChildInfo. Attribute class describes the basic and unique identifications of given EVO/NEVO object, and it contains ID, Version, and ImageLink fields of a given object. Here, ImageLink field contains the location data of a designated image file of a given object. It means only NEVO has the ImageLink value. The second class is AffineTransformation class. This class has the editing information of a given object. The component fields of AffineTransformation class are StartX, StartY, EndX, EndY, Angle, IsFlip, Label and ActionCode. By using these component fields, the mobile application can draw the EVO/NEVO on the display. Here, we assume that ActionCode field is filled with the predefined code which matches with preset action of a given object. ChildInfo class has the sibling information of a given object. If a given object has siblings, their ID is recorded in ContainedEVO field inside the class. Among these component fields, ImageLink and ContainedEVO are mutually exclusive. If a given object is NEVO, it has a designated image and does not have siblings. On the contrary, if a given object is EVO, it does not have an image, but it has siblings. Thus, only one of ImageLink or ContainedEVO has the value.

For better understanding, we want to explain the proposed EVO description schema by showing an example. If the user wants to express a watch, the system calls the EVO metadata which represents the watch. Here, E001 is the watch metadata. After retrieving E001, the system checks ContainedEVO field and retrieves every EVO metadata inside that field. In the example, N001∼N003 is retrieved. Thus, four objects (one EVO and three NEVOs) are initialized as shown in Fig. 6
                        (a) when we call a watch from the mobile application. As you can see in the figure, each component field inside AffineTransformation class of all objects are different because they need to be laid on the different positions.

Now, Let us think about the NEVO editing. If one user rotate the hour hand from 12 to 3, Angle field inside the 
                           
                              N
                              003
                           
                         object is changed from 0 to 90 degree because the orientation of an hour hand is changed to 90° as shown in Fig. 7
                        . Likewise, other fields inside AffineTransformation class are changed according to the user’s editing.

In the case of EVO editing, every NEVO image inside the parent EVO is influenced by the change of EVO object. However, the values inside NEVO object are not changed, because AffineTransformation data inside the EVO object are changed and these changes influence whole objects inside the parent EVO. For example, if one user vertically downsizes the watch to 50%, startY of 
                           
                              E
                              001
                           
                         is altered from 0 to 0.5 as shown in Fig. 8
                        . Naturally, whole objects inside the 
                           
                              E
                              001
                           
                         are vertically downsized because of this alteration. However, every field of N001∼N003 is not changed because the value of their parent EVO is already changed and these changes are affected to every image that the parent EVO has.

As shown in Fig. 9
                        , most of current emoticon transmission systems are ID based transmission [8]. Each mobile device has its own emoticon database. The emoticon database organizes the pairs of emoticon image and its ID. To send a specific emoticon, the application just transmits the ID of the emoticon that wants to send. When the application receives the ID of a specific emoticon, it searches the emoticon image in the database by using received emoticon ID and retrievethe emoticon image.

The emoticon transmission system is very efficient in case of transmitting pre-defined images because every user has the exactly same emoticon database. However, this system is difficult to be directly applied in the case of EVO transmission. one EVO is composed of a group of EVO/NEVOs, and each component object can be freely manipulated what user prefers. Therefore, the EVO could not have the fixed image. It means the numbers of possibly generated images from one EVO are numerous, and giving the unique ID for each edited EVO image is inefficient way because it needs huge EVO database size.

To solve this problem, we can think about two different solutions. The first solution is a screen capturing. To send edited EVO, the mobile application captures the edited EVO as one image and transmits that image. This solution is the easiest way to represent and transmit the edited EVO. However, this way is not efficient on the view of data size and transmission bandwidth because a whole image needs to be transmitted via data transmission network. Also, the receiver could not re-edit the received EVO because it is now just one image like an emoticon. Further, this method could not support the action of EVO.

The second solution is a differential coding. In the case of differential coding, the application first finds the differential data between initial EVO and edited EVO. Then, it generates the differential codes from the differential data, and transmit that code. By doing so, the transmission overhead could be minimized. When the receiver application receives the code, it first calls the original EVO object from its database. Then, it restores the edited EVO which the sender intended by replacing the data inside the original EVO using the received differential code. The restored EVO also can be reused by the receiver because it is also represented as a schema. Fig. 10
                         shows the conceptual way how to transmit the edited EVO from one to another.

For better understanding, we want to give one example as shown in fig.. In the example, user A calls “face” EVO and edit its eyes. To transmit edited “face” EVO, the system send EVO ID and the changed data in the description metadata. These changed data is called the differential codes. When the system of user B receives this ID and differential codes, the system first call original “face” EVO by using the received EVO ID. Then, the system overwrites the metadata by using the received differential codes. According to the above sequence, the exactly same EVO is displayed to users (see Fig. 11
                        ).

@&#IMPLEMENTATION@&#

To verify the performance and efficiency of EVO, we implemented the mobile application prototype. Then, we tested EVO editing, transmission, and restoration. The prototype is designed for android based smart pad having 8 inches display and implemented under android version 4.3.3 environments. Some screenshots of prototype applications are shown in Fig. 12
                      Also, four EVOs and 26 NEVOs were described by using the proposed EVO description schema for the tests. Designed EVOs and their attributes are explained in Table 1
                     . Also, we compared the proposed EVO system with the current emoticon system in detail to prove the excellence of the proposed EVO.

In order to ensure that the proposed EVO description schema works well, we first checked that there was any EVO/NEVO editing malfunction caused by the description schema. The test results are depicted in Fig. 13
                        . There was no problem in the case of NEVO editing because NEVO is composed of only one object. In the case of EVO editing, we need to check the functionality of the schema thoroughly because the EVO points a group of component NEVOs. As we mentioned in Section 2.2, every NEVO image inside that EVO is also transformed accordingly when one EVO is undergone the affine transform. However, the values inside each NEVO metadata must not be altered. Since the fields, which are related with the affine transformation of given object (StartX, StartY, EndX, EndY, and Angle), of component NEVO is described in the relative coordinates proportionate to the size of parent EVO, above problem is resolved. The test results of EVO editing was fine as presented in Fig. 13(d).

After finishing EVO editing, editing results were recorded in the description schema. Then, the differential codes were generated by comparing the edited EVO with the original EVO. This differential codes were transmitted to the other side finally.

To measure the efficiency of the proposed differential coding, we compared the transmission data of the differential coding with the screen capturing, which is the easiest way to send the edited EVO. We did not compare with emoticon transmission system due to that system cannot transmit EVO. For the screen capturing, png format, which is most widely used format for the mobile application, and jpg format with 75% of compression rate were used. In the real field, 75% of jpg compression is not commonly used because this compression rate severely degrades the image quality. The resolution of transmitted EVO is set to 640 
                           
                              ×
                           
                         640, which is one of the most widely used resolution in the mobile application. Table 2
                         shows the transmission data size comparison of two solutions. As you can see in the table, the transmission data is from 5 to 100 times smaller than the screen capturing when we use the proposed differential coding method.

After the receiver receives the differential codes from the sender, the application first calls the original EVO and related NEVO objects from its own EVO database. Then, it alters the value of original EVO/NEVO objects by using the received differential codes. Then, the application can draw the received EVO on the canvas. The restored EVO can be reedited and retransmitted to other by the receiver. Fig. 14
                         shows the prototype application can restore and re-edit the received EVO.

To demonstrate the superiority of the proposed EVO, we compared the EVO system with the emoticon system in the case of transmitting hand gestures. As you can see in the Table 3
                        , the biggest difference between EVO and emoticon system is scalability. EVO system needs just 11 component images to express whole hand gestures, whereas the emoticon system needs a lot of emoticons because one emoticon represents only one hand gesture. Thus, the size of emoticon database gradually increases to express more hand gestures. However, the size of EVO database is fixed because user just edit the hand components to express any hand gesture. This difference influences searching convenience. In the case of emoticon system, it is difficult to find the exact emoticon that user want among the big emoticon database. However, it is easy to find the exact EVO that user want among the EVO database because the database is relatively very small in the case of EVO system.

Another difference is transmitted data. The emoticon system transmits just ID of emoticon that want to send. The EVO system, however, transmits ID and the editing history of sender to receiver to regenerate the edited EVO. Thus, the amount of transmitted data of EVO system is slightly higher than that of emoticon system. In both cases, we suppose that the sender and receiver have the same EVO/emoticon database.

@&#CONCLUSION@&#

Emoticons are now an essential component of mobile applications. At the same time, people start to feel inconvenience of current emoticons, and people want advanced emoticon system to resolve the drawbacks of current emoticons.

In this study, we introduced the new concept called EVO which could cover the drawbacks of current emoticons. Also, we proposed the efficient way to represent and transmit EVO. The proposed techniques were implemented as a mobile application prototype to verify its possibility and efficiency.

EVO can be exploited in many areas such as education, medical fields which are difficult to exploit in case of emoticons because the EVO not only can solve the drawbacks of emoticons, but also can be used as “information interaction tool”. Some examples of EVO applicable fields are shown in Table 4
                     .

However, there are some problems to resolve. Since every people has different thinking about the intuitive editing, it is difficult to provide the well-defined intuitive editing method. This problem may need a lot of time to adjust. For better reality, three-dimensional affine transformation is also supported.

@&#ACKNOWLEDGMENT@&#

This work was supported by the Industrial Strategic Technology Development Program, (10044312, Developments of Visual Communication Platform and Authoring Tool for Emotional Expression) funded by the Ministry of Science, ICT and Future Planning (MSIP, Korea).

@&#REFERENCES@&#


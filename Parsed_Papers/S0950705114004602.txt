@&#MAIN-TITLE@&#A Swarm-Optimized Fuzzy Instance-based Learning approach for predicting slope collapses in mountain roads

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel AI model (SOFIL) for predicting slope collapses is proposed.


                        
                        
                           
                           The SOFIL integrates the Fuzzy K-NN and the Firefly Algorithms.


                        
                        
                           
                           Slope observations were collected to construct the prediction model.


                        
                        
                           
                           The new method can outperform other benchmarking algorithms.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Instance-based learning

Swarm intelligence

Fuzzy k-Nearest Neighbor

Slope collapse prediction

Firefly Algorithm

@&#ABSTRACT@&#


               
               
                  Due to the disastrous consequences of slope failures, forecasting their occurrences is a practical need of government agencies to develop strategic disaster prevention programs. This research proposes a Swarm-Optimized Fuzzy Instance-based Learning (SOFIL) model for predicting slope collapses. The proposed model utilizes the Fuzzy k-Nearest Neighbor (FKNN) algorithm as an instance-based learning method to predict slope collapse events. Meanwhile, to determine the model’s hyper-parameters appropriately, the Firefly Algorithm (FA) is employed as an optimization technique. Experimental results have pointed out that the newly established SOFIL can outperform other benchmarking algorithms. Therefore, the proposed model is very promising to help decision-makers in coping with the slope collapse prediction problem.
               
            

@&#BACKGROUND@&#

Road is the major transportation construction that support modern society; many researchers have found significant positive correlations between roads and economic growth at both local and regional levels [1,2]. Accordingly, in various countries around the world, extensive networks of mountain roads has recently been built to catch up with the population expansion and the economic development [3,4].

Furthermore, natural hazards coupled with rugged terrains lead to the fact that slope collapses possibly occur in many sections of the road network. These catastrophic events are often triggered by earthquakes or heavy rainfalls during typhoons or monsoon storms [5,6]. Slope collapses are very undesirable since they inflict damages to man-made structures, disruption of traffic, and indispensible losses of human lives. Hence, slope stability assessment is an inevitable task which should be regularly conducted by roadway maintenance authorities [7,8]. The analysis results can be utilized for identifying collapse-prone areas as well as allocating scarce resources to establish an overall disaster prevention program [9]. In order to analyze slope stability, physical model, expert evaluation, and machine learning are the three common methods [10].

The physical model method is based on the slope displacement model which can analyze the slope stability by identifying of the most dangerous sliding surface and calculating the factor of safety [11]. Although this approach can deliver accurate analytical results, it requires input parameters for every calculation point of the investigated area. Therefore, the physical model method is only appropriate for evaluating stability in small areas, and its capacity for analysis over large areas is inapplicable [12].

The expert evaluation approach utilizes expert judgments and information of slope collapse events occurred in the past [8,13]. Using expert knowledge, the main influencing features and possible triggering factors can be identified [14]. Based on that information, the stability of a slope can be evaluated by expert knowledge. Obviously, requiring many subjective judgments and inconsistency of the prediction results are the main drawbacks of this method.

Recently, machine learning approaches have been utilized to automate the slope assessment process due to their better flexibilities and prediction capabilities compared to the traditional approaches. Generally, machine learning based models are established by combining artificial intelligence (AI) techniques and historical databases [15]. Using these models, the slope evaluation can be considered as a classification task in which prediction outputs are either “stable” or “unstable”.

Lu and Rosenbaum [16], Zhou and Chen [17], Jiang [18], Das et al. [7], Cho [19], Lee et al. [20], and Wang et al. [21] applied the Artificial Neural Network (ANN) to predict the slope condition. Zhao et al. [22] employed the Relevance Vector Machine (RVM) to explore the nonlinear relationship between slope stability and its influence factors. Slope stability forecasting models based on the Support Vector Machine (SVM) were developed by Li and Wang [23], Cheng et al. [24], Zhao [25], Samui [26], and Li and Dong [27]; these studies found that SVM based models are very effective under the condition of limited data.

Although the ANN has been extensively applied for predicting slope collapse, the implementation of this approach has several drawbacks. The major disadvantage of the ANN is that its training process is achieved through a gradient descent algorithm on the error space, which can be very complex and may contain many local minima [28]. Moreover, the SVM training requires solving a quadratic programming problem subjected to inequality constraint; this means that the training process for large data sets requires expensive computational cost [29]. Most importantly, the black box nature of the ANN, SVM, and RVM algorithms makes them difficult for practical engineers or government agencies to comprehend how they predict slope collapses.

Different from the aforementioned AI methods, the Fuzzy k-Nearest Neighbor (FKNN) algorithm [30] belongs to the class of instance-based learning. This algorithm utilizes the whole collected data to establish its memory. A FKNN classifier utilizes the information obtained from the k nearest neighbors of a sample vector and assigns class memberships to it. The vector’s membership values provide a level of assurance to accompany the resultant classification. Moreover, the algorithm also assigns fuzzy memberships as a function of the vector’s distance from its k nearest neighbors and those neighbors’ memberships in the possible classes [31]. Needless to say, this approach is simple to implement and its classification outcomes are also easily interpretable. In addition, the competitive prediction performance of the FKNN has been demonstrated in various studies [30,32–34]. Nevertheless, none of previous works has evaluated the capability of the FKNN method in slope collapse assessment.

Additionally, the implementation of the FKNN requires a proper setting of two tuning parameters: the neighboring size (k) and the fuzzy strength (m). Furthermore, this parameter selection process can be modeled as an optimization problem. Meta-heuristic approaches have been illustrated to be feasible to tackle the optimization problem at hand [35–39]. Recently developed by Yang [40], the Firefly Algorithm (FA) is a fast and effective meta-heuristic for solving global optimization in continuous space. Numerical experiments in previous researches have demonstrated the superior performance of the FA over other meta-heuristic methods [41–43]. Nonetheless, few research works have investigated the capability of this algorithm in optimizing the parameter selection process of the FKNN. Thus, this study proposes to hybridize the FKNN with FA [40] to automatically search for appropriate hyper-parameters of the prediction model.

Thus, this research employs the FKNN classifier as the machine learning technique to construct a prediction model for slope collapse assessment. We propose to hybridize the FKNN algorithm with the FA [40] to automatically search for an appropriate combination of tuning parameters for the prediction model. The newly established approach is named as Swarm-Optimized Fuzzy Instance-based Learning (SOFIL). The remaining part of this paper is organized as follows. The second section of this paper presents the research methodology. The framework of the proposed SOFIL is described in the third section. The fourth section demonstrates the experimental results. Conclusions of the study are stated in the final section.

@&#METHODOLOGY@&#

The FKNN algorithm is an instance-based classifier that incorporates the fuzzy set theory into the classification process [30]. In the FKNN, the fuzzy memberships of samples are assigned to different classes. The class which possesses the maximum membership degree can be chosen as the winner. The first step of the FKNN algorithm is to calculate the fuzzy partition matrix U
                        =[uij
                        ] from the memory which stores a set of n training sample vectors [x
                        1,…,
                        xn
                        ]. Herein, we denote j as the vector index (j
                        =1,2,…,
                        n), where n is the number of training samples. And, the variable i represents the class index (i
                        =1,2,…,
                        C), where C is the number of classes. For each training case x, we identify its k nearest neighbors by calculating Euclidean distances. The membership degree of the sample vector xj
                         in the class i is given as follows:
                           
                              (1)
                              
                                 
                                    
                                       u
                                    
                                    
                                       ij
                                    
                                 
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       u
                                    
                                    
                                       i
                                    
                                 
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   0.51
                                                   +
                                                   (
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   /
                                                   k
                                                   )
                                                   ×
                                                   0.49
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   c
                                                   (
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   )
                                                   =
                                                   i
                                                
                                             
                                             
                                                
                                                   (
                                                   
                                                      
                                                         n
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   /
                                                   k
                                                   )
                                                   ×
                                                   0.49
                                                   ,
                                                
                                                
                                                   if
                                                   
                                                   c
                                                   (
                                                   
                                                      
                                                         x
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   )
                                                   
                                                   ≠
                                                   
                                                   i
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where ni
                         is the number of neighbors found which belong to the class i and c(xj
                        ) represents the class label of the sample vector xj
                        . It is obvious that uij
                         is an element of the C-by-n matrix U. Moreover, it is also worth noticing that the purpose of Eq. (1) is to assign higher fuzzy membership grades to the training samples that stay away from the decision boundary and lower fuzzy memberships grade to the patterns that lie in the vicinity of the decision boundary [30]. It is because the information supplied by the samples in the region close to the decision surface is more uncertain than that provided by other samples.

Since uij
                         is a fuzzy membership grade of the sample xj
                         in the class i, uij
                         must satisfy the following properties:
                           
                              (2)
                              
                                 
                                    
                                       u
                                    
                                    
                                       ij
                                    
                                 
                                 ∈
                                 [
                                 0
                                 ,
                                 1
                                 ]
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          C
                                       
                                    
                                 
                                 
                                    
                                       u
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 1
                              
                           
                        
                        
                           
                              (4)
                              
                                 0
                                 <
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          1
                                       
                                       
                                          n
                                       
                                    
                                 
                                 
                                    
                                       u
                                    
                                    
                                       ij
                                    
                                 
                                 <
                                 n
                              
                           
                        
                     

The second step of the FKNN approach is to assign fuzzy memberships of the unknown sample x to different classes according to the following equation:
                           
                              (5)
                              
                                 
                                    
                                       u
                                    
                                    
                                       i
                                    
                                 
                                 (
                                 x
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             j
                                             =
                                             1
                                          
                                          
                                             k
                                          
                                       
                                       
                                       
                                          
                                             u
                                          
                                          
                                             ij
                                          
                                       
                                       (
                                       1
                                       /
                                       ‖
                                       x
                                       -
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             ‖
                                          
                                          
                                             2
                                             /
                                             (
                                             m
                                             -
                                             1
                                             )
                                          
                                       
                                       )
                                    
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             j
                                             =
                                             1
                                          
                                          
                                             k
                                          
                                       
                                       (
                                       1
                                       /
                                       ‖
                                       x
                                       -
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                       
                                          
                                             ‖
                                          
                                          
                                             2
                                             /
                                             (
                                             m
                                             -
                                             1
                                             )
                                          
                                       
                                       )
                                    
                                 
                              
                           
                        where i
                        =1,2,…,
                        C, and j
                        =1,2,…,
                        k. j represents the jth sample vector among the k nearest neighbors of x. C is the number of classes; k denotes the neighboring size. The fuzzy strength m is used to determine how heavily the distance is weighted when computing each neighbor’s contribution to the membership value. 
                           
                              ‖
                              x
                              -
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              ‖
                           
                         represents the distance between x and its jth nearest neighbor xj
                        . In this study, Euclidean metric is used as the distance measurement. uij
                        , denotes the membership degree of the sample vector xj
                         in the class i and is computed in the first step of the algorithm (refer to Eq. (1)).

In order to commence the training process of the FKNN, two tuning parameters 
                           
                              (
                              k
                              ,
                              m
                              )
                           
                         are required to be determined. A proper setting of these tuning parameters is necessary to achieve a desirable performance of the prediction model [29]. Thus, in this study, we utilize the FA as a means for tuning the FKNN parameters. The description of the FA algorithm is provided in the following section of the article.

The FA is a population-based swarm intelligence which simulates the flashing and communication behavior of fireflies [44]. In the natural world, a firefly is attracted to brighter ones as it randomly explores the habitat. Based on that phenomenon in nature, the FA is formulated as a global optimization method in which the brightness of fireflies characterizes the value of the objective function. Previous studies have demonstrated that this advanced swarm intelligence is fast and effective for locating the global optimum and superior performance of the FA over other meta-heuristic algorithms has been proved in various applications [39,41,42].

The FA utilizes the following rules: (1) all fireflies are unisex, so each firefly is attracted to other fireflies regardless of their sex, (2) the attractiveness of a firefly is proportional to its brightness and decreases as the distance increases. A firefly moves randomly if no other firefly is brighter, and (3) the brightness of a firefly is affected or determined by the landscape of the objective function. The FA pseudo code is illustrated in Fig. 1
                        .

The brightness of an individual firefly can be defined similarly to the fitness value in the genetic algorithm. The light intensity I(r) varies according to the following equation:
                           
                              (6)
                              
                                 I
                                 (
                                 r
                                 )
                                 =
                                 
                                    
                                       I
                                    
                                    
                                       o
                                    
                                 
                                 exp
                                 (
                                 -
                                 γ
                                 
                                    
                                       r
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                           
                        where Io
                         denotes the light intensity of the source. γ is the light absorption coefficient. r represents the distance from the source.

As the attractiveness of a firefly is proportional to the light intensity seen by adjacent fireflies, the attractiveness β of a firefly is defined as:
                           
                              (7)
                              
                                 β
                                 =
                                 
                                    
                                       β
                                    
                                    
                                       o
                                    
                                 
                                 exp
                                 (
                                 -
                                 γ
                                 
                                    
                                       r
                                    
                                    
                                       2
                                    
                                 
                                 )
                              
                           
                        
                     

In a D-dimensional space, the distance between any two fireflies i at xi
                         and j at xj
                        , is the calculated as follows:
                           
                              (8)
                              
                                 
                                    
                                       r
                                    
                                    
                                       ij
                                    
                                 
                                 =
                                 ‖
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 ‖
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             k
                                             =
                                             1
                                          
                                          
                                             D
                                          
                                       
                                       
                                          
                                             (
                                             
                                                
                                                   x
                                                
                                                
                                                   i
                                                   ,
                                                   k
                                                
                                             
                                             -
                                             
                                                
                                                   x
                                                
                                                
                                                   j
                                                   ,
                                                   k
                                                
                                             
                                             )
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Since a specific firefly xi
                         is attracted to the brighter one xj
                        , the movement of the ith firefly can be expressed as:
                           
                              (9)
                              
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 +
                                 
                                    
                                       β
                                    
                                    
                                       o
                                    
                                 
                                 exp
                                 (
                                 -
                                 γ
                                 
                                    
                                       r
                                    
                                    
                                       ij
                                    
                                    
                                       2
                                    
                                 
                                 )
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 -
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 +
                                 α
                                 (
                                 ω
                                 -
                                 0.5
                                 )
                              
                           
                        where γ is the light absorption coefficient, γ varies from 0.1 to 10; βo
                         represents the attractiveness at rij
                        
                        =0; 
                           
                              α
                           
                         denotes a trade-off constant to determine the random behavior of movement; 
                           
                              ω
                           
                         represents a random number drawn from the Gaussian distribution.

The historical data utilized in this research contains 211 slope evaluation cases collected in the Taiwan Provincial Highway No. 18 and No. 21 during the typhoons Herb (1996), Nari (2001), and Toraji (2013). In this database, there are 105 failure and 106 non-failure cases. In this research, a slope condition, either failure or non-failure, is determined and recorded during field surveys. Specifically, a non-failure slope is determined when there is no movement of the soil in the slope surface that affects the safety of road traffic. Moreover, a case of slope is characterized by slope attributes and slope observations (failure/non-failure).

For the purpose of slope collapse prediction, this study employs 16 slope attributes divided into 9 groups: landforms, geological structure, stratigraphy, rock properties, vegetation coverage, water condition, road properties, earthquake, and rainfall. These attributes can be considered as influencing factors that determine slope conditions and they are selected based on engineering judgments, available statistical data, and findings from previous researches [4,9,45–47].


                        Table 1
                         provides the information of the influencing factors and their statistical descriptions. Illustration of the database is shown in Table 2
                         where the output of 1 indicates a failed slope and the output of −1 represents a stable slope. In Table 1, the first group covers four factors: slope aspect, slope gradient, slope height, and slope form. The slope aspect refers to the horizontal direction to which a mountain slope faces; and it has an indirect impact on moisture content of the soil, which is related to the reduction of the effective stresses at the potential failure surface. The slope angle measures the steepness inclination of the slope. The slope height, defined as the distance from crest to toe of a slope, is physically related to the magnitude of the stress and the pore-water pressure in the lower slope [48]. The slope form describes the geometry of slope surface which influences soil movement, rill patterns, and run-off production [49].

The second group depicts the geological characteristic of the area along the mountain roads. The stratigraphic feature of the region is described in the third group; it includes two impact factors, namely the angle between slope aspect and trend and the angle between gradient and inclination. In addition, the fourth group of factors provides information of rock properties in which the rock mass size and the rock mass volume are taken into account. Moreover, the characteristic of vegetation on slope surface is also critical when assessing the slope stability; to quantify this characteristic, the vegetation coverage percentage and the vegetation coverage thickness are considered [46,50].

Furthermore, in this research, the water condition of a slope is reflected by the size of catchment area which is computed by a digital terrain model (DTM) [4]. Additionally, since road construction is the artificial factor that can cause slope failure, our study considers two features of mountain roads: excavation height at slope toe and change of slope gradient due to toe cutting. On the other hand, earthquake and typhoon are generally considered as the two natural hazards that trigger slope collapse events in many places (e.g. Taiwan). In our study, the maximum ground acceleration at the slope location during earthquake and the maximum accumulated rainfall during typhoon are taken into account to measure their effects on slope stability.

This section of the article describes the proposed slope collapse prediction method, named as SOFIL, in detail. The model (see Fig. 2
                     ) is established by a fusion of the FKNN algorithm and the FA optimization algorithm.
                        
                           (1)
                           
                              Input data: The input data provides the attributes of a slope. As mentioned earlier, the slope attributes consist of influencing factors that impose significant impacts on the slope collapse events. The data can be real values or integers and they should be normalized into a range of (0,1). This transformation can help avoid numerical difficulties and prevent the situation in which attributes with greater numeric magnitudes dominate those with smaller magnitudes.


                              Tuning parameter initialization: The aforementioned tuning parameters of the model are randomly generated within the range of lower and upper boundaries. In this study, the lower and upper boundaries of the neighboring size (k) are 1 and 30, respectively. Meanwhile, these two values of the fuzzy strength (m) are 1.0001 and 10. Moreover, the equation used for generating the model tuning parameters can be shown as follows:
                                 
                                    (10)
                                    
                                       
                                          
                                             X
                                          
                                          
                                             i
                                             ,
                                             0
                                          
                                       
                                       =
                                       LB
                                       +
                                       rand
                                       [
                                       0
                                       ,
                                       1
                                       ]
                                       ×
                                       (
                                       UB
                                       -
                                       LB
                                       )
                                    
                                 
                              where 
                                 
                                    
                                       
                                          X
                                       
                                       
                                          i
                                          ,
                                          0
                                       
                                    
                                 
                               is the tuning parameter i at the first generation. rand[0,1] denotes a uniformly distributed random number between 0 and 1. LB and UB are two vectors of lower bound and upper bound for any parameter.


                              Class membership assignment: In this step, the FKNN algorithm is deployed to assign fuzzy memberships of an input vector to different classes. This step requires two parameters (the neighboring size and the fuzzy strength) that are acquired from the FA component. It is noted that the slope assessment problem is a two-class classification problem with two labels: “collapse” and “non-collapse”. Thus, for each input pattern x, there are two outputs, u
                              1(x) and u
                              2(x), representing membership degrees of x in the two classes.


                              Firefly Algorithm searching: the FA optimization technique is applied to automatically explore the various combinations of the tuning parameters (k and m). At each generation, the optimizer carries out its searching process to guide the population of fireflies to the optimal solution. By evaluating the fitness of each firefly, the algorithm discards inferior combinations of m and k, and permits robust combinations of these parameters to be passed on the next generations.


                              Output defuzzification: Because the FKNN yields fuzzy memberships of an input pattern in the two classes (u
                              1(x) and u
                              2(x)), a step of defuzzification is employed to convert fuzzy outputs to crisp outputs (Y(x)) as follows: 
                                 
                                    (11)
                                    
                                       Y
                                       (
                                       x
                                       )
                                       =
                                       
                                          
                                             
                                                arg
                                                max
                                                (
                                                
                                                   
                                                      u
                                                   
                                                   
                                                      i
                                                   
                                                
                                                (
                                                x
                                                )
                                                )
                                             
                                             
                                                i
                                                =
                                                1
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           


                              Fitness evaluation: In this step, the training data set is divided into five mutually exclusive subsets. In each run, one subset is used as a validating set; meanwhile, the other subsets are used for constructing the model memory. In order to determine the optimal tuning parameters of the FKNN, the following objective function is used: 
                                 
                                    (12)
                                    
                                       
                                          
                                             F
                                          
                                          
                                             fitness
                                          
                                       
                                       =
                                       
                                          
                                             1
                                          
                                          
                                             
                                                
                                                   ∑
                                                
                                                
                                                   k
                                                   =
                                                   1
                                                
                                                
                                                   5
                                                
                                             
                                             
                                                
                                                   AR
                                                
                                                
                                                   k
                                                
                                             
                                          
                                       
                                    
                                 
                               where AR
                                 k
                               denotes the classification accuracy of the validating set at the kth run. The classification accuracy is calculated as the number of correct classifications divided by the number of all data instances within a data set.


                              Stopping condition: The optimization process of the FA algorithm terminates when the maximum number of generation is achieved. If the stopping condition is not met, the FA will continue its searching progress.


                              Optimal prediction model: When the program terminates, the optimal set of tuning parameters has been successfully identified. The SOFIL is ready to predict new input patterns.

@&#EXPERIMENTAL RESULTS@&#

To demonstrate the capability of the proposed SOFIL, its performance is compared to results acquired from other benchmark approaches including the ANN, FKNN, RVM, and SVM algorithms. As mentioned earlier, in the SOFIL, the neighboring size (k) and the fuzzy strength (m) are automatically chosen by the FA optimization. In FKNN algorithms, the neighboring size k is allowed to vary between 1 and 30; additionally, this parameter is also selected via a fivefold cross validation process based on the training cases. The fuzzy strength parameter (m) in the FKNN algorithm is set to be 2, as recommended by the previous work [30]. Moreover, the parameters of the SVM is determined via the grid search approach [51,52].

When using an ANN, it is needed to specify the number of hidden layers, the number of neurons in the hidden layer, the learning rate, and the number of training epochs [53]. These parameters of an ANN are generally selected via repetitive trial-and-error processes. The network configuration is described as follows: the number of hidden layers is set to be 1; the number of neurons in the hidden layer is 16; and the number of training epochs is selected to be 2000. The back-propagation approach is used as the method for training the ANN model [54].

In the experiment, the whole database is randomly divided into two set: set 1 (including 80% of the cases) used to construct the prediction model, and set 2 (including 20% of the cases) utilized for testing the model. To evaluate model performance, the classification accuracy rate can be employed. The classification accuracy rate (CAR) is the ratio of correctly predicted cases over the total number of cases, can be used to measure the classifier performance [55,56].

Moreover, the predictive capability of the classifiers can also be assessed using the following four metrics [56]: true positive rate (the percentage of positive instances correctly classified), true negative rate (the percentage of negative instances correctly classified), false positive rate (the percentage of negative instances misclassified), and false negative rate (the percentage of positive instances misclassified). These four metrics can be summarized in a confusion matrix [57]. A well-known approach to incorporate these four measures and to produce an evaluation criterion is to employ the Receiver Operating Characteristic (ROC) curve [58]. Furthermore, the area under the ROC curve, denoted as AUC, provides a single measure of a classifier’s performance for evaluating which model is better on average [59,60].

It is noted that a higher AUC value indicates a better predictive performance. Generally, a classifier with perfect predictive ability has an AUC of 1; meanwhile, a poor classifier with random predictions has an AUC of 0.5. Moreover, an AUC of the range (0.7, 0.8) indicates an acceptable classification performance. If 0.8⩽AUC⩽0.9, an excellent classification performance is attained. And, if AUC⩾0.9, the classifier has attained an outstanding performance.

When the FA-based parameter tuning process terminates, the optimized hyper-parameters of the SOFIL has been identified as: k
                     =5, m
                     =1.28. Furthermore, the evolutionary process of the SOFIL can be observed in Fig. 3
                     . It can be seen that the value of the fitness function (shown in Eq. (12)) gradually improved and it reached the best value at iteration 102. During the latter part of the searching process, the fitness value remains the same until the stopping condition (the maximum number of generation=300) is satisfied.

The experimental result has demonstrated that the FA is a very effective meta-heuristic since it can help the proposed model to converge quickly toward the most desirable set of hyper-parameters. Detailed of the SOFIL’s prediction results for the testing data is shown in Table 3
                     . Herein, μ
                     1(X) and μ
                     2(X) represent the membership degrees of the input vector X in the two classes (collapse and non-collapse).

The confusion matrices of the SOFIL and other methods are described in Table 4
                     . In the training process, the numbers of common false positives and false negatives of the five models are 1 and 3, respectively. Meanwhile, in the testing process, the proposed approach and the SVM do not commit any false positive. The RVM, ANN, and FKNN algorithms have 1 overlapped false positive. In addition, the number of overlapped false negatives of the five methods is 2. It can be observed that the proposed SOFIL has achieved the lowest false positives and false negatives in both the training and testing processes.


                     Table 5
                      provides the result obtained from the training and testing processes of the SOFIL and other benchmark methods. The CAR results of the SOFIL, SVM, RVM, ANN, and FKNN methods are 95.24%, 92.85%, 88.01%, 88.10%, and 85.71% in the testing process, respectively. When predicting testing samples, the AUC values of the five methods are 0.95, 0.94, 0.89, 0.88 and 0.86, respectively. Observably, the proposed SOFIL can deliver the best result of slope collapse prediction in both training and testing processes. Notably, the newly established method can properly classify 40 testing cases with only 2 misclassifications. Thus, the SOFIL deems best suited for the slope collapse prediction problem at hand.

@&#CONCLUSION@&#

In this research, a new slope collapse prediction model, named as SOFIL, has been proposed. Experimental results obtained from both training and testing processes have verified that the new model can outperform other benchmark methods in terms of all performance measurements. This demonstrates that the SOFIL is a very promising alternative to support decision makers in slope collapse assessment.

The newly built approach is established by a hybridization of the FKNN – an instance-based learning classifier and the FA – a swarm intelligence optimization technique. The SOFIL utilizes the FKNN algorithm to assign a membership grade in each class to an unknown pattern of slope attributes. Additionally, the FA searching algorithm is deployed to identify the most appropriate set of the FKNN’s tuning parameters. As a result, the proposed method can eliminate the need of human effort or domain knowledge for parameter setting. Since the SOFIL is an effective classifier, it can be applied for solving other problems in the field of civil engineering. Moreover, investigating a mechanism of adaptive weightings for calculating distances can be a promising future enhancement of the current prediction model.

@&#REFERENCES@&#


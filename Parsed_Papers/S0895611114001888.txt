@&#MAIN-TITLE@&#A manifold learning method to detect respiratory signal from liver ultrasound images

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We proposed a manifold learning based method to detect the respiratory signal from 2D ultrasound images.


                        
                        
                           
                           We apply the proposed method to create breathing-corrected 3D ultrasound images.


                        
                        
                           
                           The experiments demonstrate robustness and accuracy of the proposed, and potential application in 3D ultrasound imaging.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Liver ultrasound images

Respiratory gating

Respiratory signal

Manifold learning

Local tangent space alignment

@&#ABSTRACT@&#


               
               
                  Respiratory gating has been widely applied for respiratory correction or compensation in image acquisition and image-guided interventions. A novel image-based method is proposed to extract respiratory signal directly from 2D ultrasound liver images. The proposed method utilizes a typical manifold learning method, based on local tangent space alignment based technique, to detect principal respiratory motion from a sequence of ultrasound images. This technique assumes all the images lying on a low-dimensional manifold embedding into the high-dimensional image space, constructs an approximate tangent space of each point to represent its local geometry on the manifold, and then aligns the local tangent spaces to form the global coordinate system, where the respiratory signal is extracted. The experimental results show that the proposed method can detect relatively accurate respiratory signal with high correlation coefficient (0.9775) with respect to the ground-truth signal by tracking external markers, and achieve satisfactory computing performance (2.3s for an image sequence of 256 frames). The proposed method is also used to create breathing-corrected 3D ultrasound images to demonstrate its potential application values.
               
            

@&#INTRODUCTION@&#

Respiration motion is a quasi-cyclic physiologic process and may lead to motion and deformation of abdominal organs, e.g. liver [1]. This physiologic process seriously affects the efficacy and efficiency of interventional and radio-therapeutic procedures performed for diagnosing and treating these diseased organs. A variety of respiratory motion modeling methods [2] have been proposed to overcome this problem, which inevitably involves detection of the respiratory signal. Here, respiratory signal can be considered as a generalized pattern of the human respiration and feature the principal component of the 3D respiratory motion.

The respiratory signal can find its value in multiple liver-related clinical applications. For instance, it may be individually used for image acquisition to capture the respiration-induced moving liver [3], respiratory gating for liver ablation interventions [4,5] and radiation therapies [6], and accuracy improvement of quantitative evaluation of the hepatic perfusion [7]. In addition, the respiratory signal can also be combined with a 4D respiratory motion model for motion correction or prediction during radiation therapies [8,9] and high intensity focused ultrasound (HIFU) [10,11]. For this case, the signal is firstly used in the pre-operative procedure for establishing a correspondence model with 3D motion of the whole liver motion or specific liver part (e.g. vessels or lesions), and applied as input in the intra-operative stage to parameterize the motion model for motion estimation or prediction.

One traditional and widely used method to obtain the respiratory signal is to place one or multiple external markers on the thoracic or abdominal skin to detect the dominant anterior-posterior translation of the human skin [12–14], which is viewed as measurements of the breathing phases. These markers are usually optical or electromagnetic (EM) sensors, whose position variations could be monitored by optical cameras or EM tracking devices. Recently, marker-less external tracking methods were proposed to track the whole chest or abdomen surface using optical imaging devices to provide high-dimensional respiratory information [15,16]. However, these extra positioning or imaging devices are not routinely available in clinical procedures, also need long device setup time and extra surgical working space and consequently lead to high financial costs.

In order to relieve these problems existing in external marker-based methods, researchers and physicians recently proposed another class of more flexible and lower-cost methods, i.e. purely image-based respiratory signal tracking [6,17–22], which extract the respiratory signal directly from time-varying US liver images during pre-operative image acquisition or intra-operative image-guided procedures. These methods detect the respiration-related information by utilizing some specific image processing techniques to process an image region or the whole image.

For the image-region-based methods [6,17–19], it is necessary to firstly specify a special image patch containing salient anatomical structures, such as the diaphragm, liver vessels or liver boundaries, from a reference image. Xu and Hamilton [6] calculated statistical dependency of successive image patches, which are located on the same position on all the processed images. These calculated statistical values (mutual information or correlation coefficient) are representative of principal respiratory motion. Hwang et al. [17] pointed that this method has severe dependency on the reference image with salient features, and statistical values cannot represent the respiratory signal well, especially in key respiratory phases, end of inhalation (EI) or exhalation (EE). Furthermore, they proposed to directly identify the motion of the salient anatomical features in image patches (called feature windows) and calculate displacements of these features with the first image patch's feature. These displacements reflect the respiratory motion of the anatomical features on images and, hence, can better delineate the respiratory signal. However, the feature identification is based on some thresholding technique, which is susceptible to speckle noise and intensity variations usually appearing in US images. Therefore, Wu et al. [18,19] proposed a template matching (TM) based method to estimate the respiratory motion of the anatomical structures on the image patches (also called template blocks). This method is robust to speckle noise and intensity variations and can recover the respiratory motion well. However, these methods above heavily rely on predefined distinctive anatomical features with strong contrast and large motion. When the features are absent or not distinctive in images, or they have small motion, these methods fail to extract satisfactory respiratory signal.

Sundar et al. [20] proposed a novel phase correlation method to detect respiratory signal by considering the whole images but not image patches. This method uses the cumulated phase shift in the spectral domain of successive image frames as a measure of the respiratory motion. Wachinger et al. [21,22] pointed and experimentally demonstrated that this method cannot well recover the respiratory information from US images and further proposed a manifold learning (ML) based respiratory signal tracking for 4D US imaging. The ML-based tracking method makes use of a classic nonlinear dimensionality reduction technique, Laplacian Eigenmaps (LEM) [23], to infer intrinsic low-dimensional structures (e.g. respiratory motion of at most three dimensions) from very high-dimensional data (e.g. images of hundreds of thousands of dimensions).

In this paper, we present a novel manifold learning based method to extract the respiratory signal from a sequence of 2D US B-mode images. The proposed method is based on a manifold learning technique, local tangent space alignment (LTSA) [24], which is a typical dimensionality reduction technique. This method assumes a low-dimensional manifold embedded in the high-dimensional space (image space) and each frame of the image sequence lies on this manifold. Based on this assumption, images over the breathing cycle will roughly form a continuous back-and-forth trajectory on the manifold in image space, with points at similar positions on the manifold related by the similar or same state of the breathing cycle. LTSA uses a linear approximation within each neighborhood to construct a local coordinate system for the neighborhood, and then aligns these overlapping local coordinate systems to obtain a global coordinate system. By such nonlinear mapping process, LTSA may assign to each image a low-dimensional coordinate (namely the respiratory phase) by exploring the neighborhood relationship and is well suitable for extracting the respiratory information from the image sequence.

In contrast to previous image-region-based methods, our ML-based method directly takes the entire image sequence as input to extract the respiratory information and has no special requirement on salient anatomical features in images. In addition, our method could be more robust to artifacts and noise in US images and produces much smoother respiratory signal than previous image-region-based methods, which is important for respiratory gating during image acquisition. Compared to the LEM-based tracking method, the main advantage of the proposed LTSA-based method is that it can extract the local geometric information by constructing tangent planes of the local neighborhood of each point on the manifold, but LEM directly uses the distance relationship of each point with other points on the manifold. Therefore, LTSA in our paper is able to construct better mapping function to convert the high-dimensional images into corresponding low-dimensional respiratory states. The experiments in this paper will prove that the proposed LTSA-based method is able to extract more accurate and robust respiratory signal than other image-based methods and as a typical application example used to reconstruct respiration-corrected 3D US images from multiple 2D image sequences.

@&#METHODS@&#

Manifold learning belongs to a class of nonlinear dimensionality reduction techniques, which aims to discover some underlying structure of complex high dimensional data and reduce them to a simpler representation of much lower dimensionality, while still retaining the local spatial relationship of the original data. Local tangent space alignment [24] is such a manifold learning algorithm, which can efficiently learn a nonlinear embedding into the low-dimensional space from high-dimensional data, and can also reconstruct high-dimensional coordinates from embedding coordinates. It has a number of attractive features: simple geometric intuitions, straightforward implementation, and global optimization.

For a set of D-dimensional input feature vectors (X
                        ={x
                        1, x
                        2, …, x
                        
                           n
                        }, x
                        
                           i
                        
                        ∈
                        R
                        
                           D
                        , i
                        =1, 2, …, n), drawn from a intrinsically low-dimensional manifold lying on the D-dimensional space, LTSA attempts to find a nonlinear mapping to transform these vectors to a d-dimensional space (d
                        <
                        D) to produce a set of corresponding d-dimensional vectors (Y
                        ={y
                        1, y
                        2, …, y
                        
                           n
                        }, y
                        
                           i
                        
                        ∈
                        R
                        
                           d
                        , i
                        =1, 2, …, n). The mapping process is performed to as much as possible preserve local geometrical information around each vector. For LSTA, the local geometrical information of each input vector is described by the local coordinates of this vector with respect to its tangent space on the manifold.

This algorithm begins by computing the k nearest neighbors (d
                        <
                        k
                        <
                        D) of every vector on the manifold. It then computes the first d principal components on each neighborhood of input vectors to get a d-dimensional subspace which approximates the local tangent space. It finally computes the local tangent coordinates of data samples and finds an embedding to align them into a global coordinate system. The detailed process can be divided into four basic steps as follows:


                        Step 1: Identify nearest neighbors. For each input vector x
                        
                           i
                        
                        ∈
                        X, 1≤
                        i
                        ≤
                        n, find its k nearest neighbors, i.e. a set of feature vectors X
                        
                           i
                         satisfies the following formula:
                           
                              
                                 
                                    
                                       
                                          arg
                                          min
                                       
                                       
                                          
                                             X
                                             i
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                             
                                                
                                                   x
                                                   j
                                                
                                                ∈
                                                
                                                   X
                                                   i
                                                
                                             
                                          
                                          
                                             |
                                             
                                                x
                                                i
                                             
                                             −
                                             
                                                x
                                                j
                                             
                                             |
                                          
                                       
                                       2
                                       2
                                    
                                    ,
                                     
                                    1
                                    ≤
                                    j
                                    ≤
                                    n
                                    ,
                                     
                                    j
                                    ≠
                                    i
                                 
                              
                           
                        where the identified k nearest neighbors are denoted as 
                           
                              
                                 X
                                 i
                              
                              =
                              {
                              
                                 x
                                 
                                    
                                       i
                                       1
                                    
                                 
                              
                              ,
                              
                                 x
                                 
                                    
                                       i
                                       2
                                    
                                 
                              
                              ,
                              …
                              ,
                              
                                 x
                                 
                                    
                                       i
                                       k
                                    
                                 
                              
                              }
                              ,
                           
                         and, naturally, the indices of these neighbors in the input vector set X may be denoted as N
                        
                           i
                        
                        ={i
                        1, i
                        2, …, i
                        
                           k
                        }, 1≤
                        i
                        1, i
                        2, …, i
                        
                           k
                        
                        ≤
                        n..


                        Step 2: Extract local information. Compute the correlation matrix G of these k neighbors, namely each element is represented as
                           
                              
                                 
                                    
                                       G
                                       
                                          p
                                          ,
                                          q
                                       
                                    
                                    =
                                    (
                                    
                                       x
                                       
                                          
                                             i
                                             p
                                          
                                       
                                    
                                    −
                                    
                                       
                                          x
                                          ¯
                                       
                                       i
                                    
                                    ,
                                    
                                       x
                                       
                                          
                                             i
                                             q
                                          
                                       
                                    
                                    −
                                    
                                       
                                          x
                                          ¯
                                       
                                       i
                                    
                                    )
                                    ,
                                     
                                    
                                       
                                          x
                                          ¯
                                       
                                       i
                                    
                                    =
                                    
                                       1
                                       k
                                    
                                    
                                       ∑
                                       
                                          p
                                          =
                                          1
                                       
                                       k
                                    
                                    
                                       
                                          x
                                          
                                             
                                                i
                                                p
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        
                        
                           
                              
                                 
                                    1
                                    ≤
                                    p
                                    ≤
                                    k
                                    ,
                                     
                                    1
                                    ≤
                                    q
                                    ≤
                                    k
                                 
                              
                           
                        where (·, ·) means dot product of both vectors. Use principal component analysis (PCA) to compute the first d largest eigenvectors g
                        1, g
                        2, …, g
                        
                           d
                        , which represent the local coordinates of the input vector x
                        
                           i
                         with respect to its local tangent space and the local geometrical characteristics.


                        Step 3: Construct sparse alignment matrix. Compute the matrix
                           
                              
                                 
                                    Q
                                    =
                                    [
                                    
                                       1
                                       k
                                    
                                    /
                                    
                                       k
                                    
                                    ,
                                    
                                       g
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       g
                                       d
                                    
                                    ]
                                    
                                       
                                          [
                                          
                                             1
                                             k
                                          
                                          /
                                          
                                             k
                                          
                                          ,
                                          
                                             g
                                             1
                                          
                                          ,
                                          …
                                          ,
                                          
                                             g
                                             d
                                          
                                          ]
                                       
                                       T
                                    
                                    ,
                                 
                              
                           
                        where 1
                           k
                        
                        ∈
                        R
                        
                           k
                         is a column vector of all ones and Q is a k
                        ×
                        k matrix. This matrix is appended into the sparse alignment matrix B using the following procedure:
                           
                              
                                 
                                    
                                       B
                                       
                                          
                                             i
                                             p
                                          
                                          ,
                                          
                                             i
                                             q
                                          
                                       
                                    
                                    ←
                                    
                                       B
                                       
                                          
                                             i
                                             p
                                          
                                          ,
                                          
                                             i
                                             q
                                          
                                       
                                    
                                    +
                                    
                                       
                                          (
                                          
                                             E
                                             k
                                          
                                          −
                                          Q
                                          )
                                       
                                       
                                          p
                                          ,
                                          q
                                       
                                    
                                    ,
                                 
                              
                           
                        where E
                        
                           k
                         denotes a k
                        ×
                        k identity matrix, B is firstly initialized by zeros and the indices of the matrix elements have been already explained in step 2.


                        Step 4: Align global coordinates through eigendecomposition. To obtain d features (coordinates) of embedded vectors, solve the standard eigenproblem
                           
                              
                                 
                                    B
                                    v
                                    =
                                    λ
                                    v
                                    ,
                                 
                              
                           
                        
                     

For first d
                        +1 smallest eigenvalues, λ
                        1, λ
                        2, …, λ
                        
                           d
                        , λ
                        
                           d+1, and its corresponding eigenvectors, 
                           
                              
                                 v
                                 1
                              
                              ,
                              
                                 v
                                 2
                              
                              ,
                              …
                              ,
                              
                                 v
                                 d
                              
                              ,
                              
                                 v
                                 
                                    d
                                    +
                                    1
                                 
                              
                              .
                           
                         Drop the smallest eigenvalue λ
                        1
                        ∼0 and the corresponding eigenvector v
                        1, and form the embedding matrix such that i-th coordinate (i
                        =1,2,…,n) of j-th eigenvector (j
                        =1,2,…,d) corresponds to j-th coordinate of the projected i-th vector, namely Y
                        ={y
                        1, y
                        2, …, y
                        
                           n
                        }.

In this paper, the goal of the LTSA-based algorithm is to extract the corresponding respiratory state of each image from an US B-mode image sequence S consisting of n images, S
                        ={I
                        1, I
                        2, …, I
                        
                           n
                        }, and spanning multiple breathing cycles. For each image sequence S, LTSA firstly needs to convert I
                        
                           i
                         into a corresponding high-dimensional vector x
                        
                           i
                         in a row-majored pixel serialization, and forms a set of data vectors X
                        ={x
                        1, x
                        2, …, x
                        
                           n
                        }. According to the manifold learning theory and approximate reproducibility of these US images due to the breathing, the converted data vectors can be reasonably assumed to lie on or near a naturally low-dimensional manifold embedded in a high-dimensional space. Since the core idea of the manifold learning is to maximally preserve local neighboring information when mapping a manifold from the high-dimensional space to the low-dimensional space, similar images during a breathing cycle or spanning different cycles should have the same or adjacent coordinates in the mapped low-dimensional space. Finally, by running the LTSA-based manifold learning, a series of low-dimensional coordinates (namely 1D for respiratory signal in this paper) will be extracted from a sequence of images.

For US liver images, the respiratory motion is dominant in contrast to other motion, deformation or noise. Therefore, the first several eigenvalues (especially the first one) and corresponding eigenvectors are highly relevant to the respiratory motion. In addition, the respiratory signal is considered as one-dimensional basic breathing pattern, which can be featured by the principal component of the 3D respiratory motion. Therefore, the respiratory signal in this paper is defined to be one-dimensional and represented by the first eigenvector extracted from the embedding matrix, namely d
                        =1.

As stated in the introduction, the respiratory signal is valuable in multiple clinical situations, e.g. image acquisition. Acquisition of US images plays a key role in image-guided interventions. When US images can clearly visualize tumors, they can directly guide the needle insertion in image-guided interventions. Even though tumors are not visible under US imaging, US images can also be utilized for multi-modal image fusion [25,26] to register intra-operative images (e.g. US) with pre-operative images, such as computerized tomography (CT) and magnetic resonance (MR). Since 2D US only provides relatively few information, it is extremely challenging to register a 2D US image with other images modalities. The 3D US probe is still very expensive and also has limited field of view. Therefore, freehand [27] and mechanically-swept [28] 3D US are usually more cost-effective options in image-guided interventions, and were also comprehensively studied in the literature [29]. However, their main issue is to create 3D US images from 2D images with different orientations and breathing phases and does not provide any respiratory correction.

The proposed method in this paper can be easily integrated with freehand or mechanically-assisted 3D US to acquire respiration-corrected 3D US images. Herein, we especially discuss how to apply it to acquire respiration-corrected 3D US images using a conventional 2D US probe. The basic idea is to utilize the proposed gating method to detect multiple 2D images with a specific breathing phase from multiple 2D image sequences with different scanning angle, and then combine these detected 2D images into a respiration-corrected 3D image, which captures the moving liver at the specific breathing stage. In order to do that, the first step is to use a motorized mechanical arm to hold and regularly rotate a 2D US probe to acquire multiple image sequences with different scanning angles, as illustrated in Fig. 1
                        . The proposed signal gating method in this paper is then applied to label the breathing phase of each frame of each image sequence. For each sequence, one image with the specific breathing phase is then selected. Finally, all the images with the same breathing phase and different scanning angles (from different image sequences) are collected together to reconstruct a 3D US image.

@&#EXPERIMENTS AND RESULTS@&#

The US imaging system for acquiring image videos is the Terason (Burlington, USA) t3000 with a 5C2 curved transducer. The used frequencies vary from 2.0MHz to 5.0MHz and the focusing depth is in the range of 16–19cm. The US image resolution is 640×480 pixels and the temporal resolution is nearly 10 FPS. The pixel size is about 0.37×0.37mm, and slightly varies under different depth settings.

In order to avoid tremor of the US probe by hands, a robotic arm (Fig. 2
                        ) is designed to hold the probe, which can help to stably scan the moving liver. US images will be acquired from volunteers lying on a bench bed with the supine position. The US probe is firstly held by hands to flexibly scan the liver at inter-rib intervals of the chest to avoid obstruction of ribs. After finding a proper scanning position and orientation, the US probe will be mounted onto the holder of the robotic arm with its position and orientation similar to that just selected manually. The mounted US probe can be tilted to scan the liver because the probe holder is actuated by a geared motor (Faulhaber DC-Micromotor 0615, Schönaich, Germany). The relative scanning angle can be tracked by an encoder embedded in the motor. This motor is connected to a computer using an Ethernet mode (via a network cable). On the computer, a customized imaging tool was developed and deployed to acquire different angles of image sequences. This tool can send commands to drive the motor and tilt the US probe at a regular angular interval to sweep the liver.

In order to validate the breath signal tracked by our method, a NDI (Ontario, Canada) Aurora electromagnetic (EM) tracking system is used to track an EM sensor placed on the umbilicus of the volunteers while acquiring the US images. The dominant motion direction of the tracked sensor for the umbilicus will be applied as the reference respiratory signal. The translational motion of umbilicus is selected for the ground-truth signal because the umbilicus on the abdominal surface is usually a good position to monitor the abdominal respiration and is often adopted in respiratory motion modeling to obtain standard surrogate breathing signals [2].

For reducing the relative latency between US images and EM positions, a customized software tool is developed and deployed onto the laptop computer of the Terason US system to acquire both US images and EM positions. The EM tracking device is connected to the laptop using an Ethernet cable with 1000Mbps. In our customized tool, a corresponding EM position will be instantly recorded on demand before an US image being acquired.

For the following experiments, eight healthy volunteers (male, average age 36, ranged 25–46) were recruited. For the first fourth experiments, eight US image sequences, numbered as {S1, S2, …, S8} for convenience, were collected from these volunteers under normal and free breathing. Each sequence consists of 256 frames. For the fifth experiment, 48 image sequences were acquired from one of these volunteers and each sequence consists of 128 frames. All acquisitions were performed with these volunteers lying in the supine position. All the acquired US images and corresponding EM positioning data will be transferred to our working computer for further off-line analysis. Relevant analysis experiments were run on a Dell workstation with Intel Xeon CPU E5620 2.4GHz and 12G RAM, and the single-thread programming mode was used.

@&#EXPERIMENTS@&#

It is noted that the respiratory signals, we are interested in, are used to qualitatively characterize general pattern (state or phase) of the respiratory motion but not quantitatively measure physical motion amount. Therefore, for more convenient visual inspection, the respiratory signals extracted from the US images or tracked by the EM device are all linearly normalized to the interval (0, 1) using their minimums and maximums. The correlation coefficient (CC) metric will be applied for evaluating quantitative accuracy between the extracted signals, by different tracking methods, and the reference signals, tracked by the EM device.

The experiment herein was performed to analyze how different numbers of nearest neighbors affect the signal accuracy and computing time, and help determine the optimal neighborhood size to achieve the trade-off between the signal accuracy and computing efficiency. In this experiment, the images as the input vectors of this algorithm are kept to the original size to preserve all the image details in order to focus on the effect of the nearest neighbors. The used neighbor numbers in the experiments are 16, 32, 64 and 128, respectively.

The experiment was executed to investigate how different levels of image downsampling influence the accuracy and efficiency of the signal extraction. In the experiment, the number of neighbors is fixed as 64 according to the results in the first experiment, the downsampling levels for reducing the images both horizontally and vertically are 1/2×1/2, 1/4×1/4, 1/8×1/8, 1/16×1/16 and 1/32×1/32, respectively. Since the US images in this paper have a resolution of 640×480 pixels, the reduced resolutions for images should be 320×240, 160×120, 80×60, 40×30 and 20×15 pixels, respectively.

This experiment was executed to visually and quantitatively compare the proposed LTSA-based method to the LEM-based one [21]. According to the first two experiments, the number of the nearest neighbors is set as a constant of 64 and the image downsampling level fixed as 1/16. In addition to the number of the nearest neighbors, LEM has another important parameter: namely kernel width, which is used to weight the influence of neighbors and experimentally given as 10 to obtain good results.

We also performed an experiment to compare our method to another classic image-region-based signal tracking method [18], which is based on template matching (TM) technique. For the TM-based method, a template block is at first manually specified from the reference image (often the first image of an image sequence). This image block should contain some salient features different from the image background, such vessels or liver boundaries. Afterwards, this method sequentially searches each frame of the image sequence for the block best matching the template block, and calculates 2D displacement between the matched block and the template block. Finally, this process will produce a sequence of 2D displacements, which represents local in-plane 2D respiratory motion of the liver. For the sequence of 2D displacements, either of both directional components, with greater motion, will be used as the respiratory signal. The TM-based method is quite simple in principle and fairly easy in implementation, but have to select a proper template block which contains some prominent anatomical structures.

Since the TM-based method only extracts the respiratory motion by tracking a small region of the liver images, for fair comparison, the input data of our method are not the entire frame images but image blocks selected from each frame of the image sequence. These blocks have the same size as the template block used in the TM-based method, and their positions for all the images are fixed as the position of the template block. In this experiment, the image block has the size of 65×65 pixels, which was demonstrated by repeated experiments to be a good choice. Since the template block is fairly small, no image downsampling is required when using our LTSA-based method. The number of the nearest neighbors is fixed as 64.

We performed an initial experiment to prove the possibility to create respiration-corrected 3D ultrasound images from 2D ultrasound images. The US probe was regularly tilted to acquire 48 image sequences with different scanning angles from one volunteer. These sequences cover a angle of 30.84°, and each sequence consists of 128 frames.

@&#RESULTS@&#

The experimental results are displayed in Fig. 3
                            for visual inspection, where two typical image sequences (S6 and S7) are used. It is observed when the number of the nearest neighbors is small (for instance 16 and 32), the extracted respiratory signals (in red) are not sufficiently accurate and have severe distortions at some peaks and valleys, in comparison to the EM-tracked reference signals (in green). However, the respiratory phases at peaks and valleys are usually vital for respiratory gating and other applications, and, therefore, too small neighbors (16 and 32) are not suitable options. When the number of the nearest neighbors increases to 64, the extracted breathing signals are very close to the reference signals in key respiratory phases as well as whole signal profiles. As the neighborhood size is further increased to 128, the extracted signals start to become unsmooth and have distortions in the peaks and valleys. More importantly, we also performed a quantitative analysis on the signal tracking accuracy under different number of nearest neighbors by calculating the CC values between the extracted signals to the EM-tracked reference signals, where results are listed in Table 1
                           . Here, eight image sequences corresponding to different volunteers are utilized for analysis. The mean and standard deviation (STD) of the CC values were also calculated over these sequences. It is observable that the quantitative results, on the whole, support the aforementioned analysis in Fig. 3. The proposed method gains highest mean CC values and lowest STD values for 64 nearest neighbors.

We also analyzed the computing time of the proposed method under different number of neighbors, which results are listed in Table 2
                           . As the neighborhood size gradually increases, the time for extracting the respiratory signals also sharply boosts, from about 80s up to nearly 20min. Therefore, by careful evaluation on both the signal accuracy and computing time, the number of the nearest neighbors of each feature vector on the manifold should be set as 64, which is fixed in the following experiments.


                           Fig. 4
                            gives visual inspection about the extracted signal accuracy using different levels of image downsampling, where two typical image sequences (S6 and S7) are used. As the downsampling levels are set as 1/2×1/2, 1/4×1/4, 1/8×1/8 and 1/16×1/16, the extracted breathing signals (in red) have similar phases and shapes with the EM-tracked reference signals (in green). When the level is increased to 1/32×1/32, the extracted signals start becoming distinctive from the EM-tracked reference signals in shapes and smoothness. More importantly, we also quantitatively evaluated the signal tracking accuracy under different levels of image downsampling by comparing the extracted signals to the EM-tracked reference signals using the CC metric, where results are listed in Table 3
                           . Here, eight image sequences corresponding to different volunteers are utilized for evaluation. The statistical mean and STD of the CC values were also calculated over these sequences. In most of the cases, the proposed method can gain relatively high CC values from level 1/2×1/2 to 1/16×1/16. The CC values begin to apparently decrease while the level is given as 1/32×1/32.

We also investigated the computing time of the proposed method under different downsampling levels, with corresponding results shown in Table 4
                           . We can notice from this table that the computing time for the signal extraction will sharply decrease as the image size decreases. Therefore, by simultaneously considering both the signal accuracy and computing efficiency, the downsampling level 1/16×1/16 (corresponding image size, 40×30 pixels) will be best suitable for the signal extraction and kept constant in the following experiments.

The experimental results are displayed in Fig. 5
                           , where two typical image sequences (S6 and S7) are used. It is noticeable from this figure that the signals (in red) extracted by the LEM-based method are quite different from the EM-tracked reference signals (in green), especially in the peaks and valleys, which corresponds to vital respiratory phases, ends of inhalation (EI) and exhalation (EE). The inaccuracy in detecting key phases limits clinical application of the LEM-based method in respiratory-gating situations. By contrast, the signals detected by our method are highly similar to the EM-tracked ground-truth signals. By viewing their overlapping graphs, we observe nearly perfect matching effects, which indicate our method is able to detect the respiratory signals highly consistent to the reference ones in key phases (EI and EE) as well as entire signal profiles. A quantitative analysis on the signal detection accuracy was also done to calculate the CC values between the signals, extracted by our LSTA-based method and the LEM-based one, and the ground-truth signals. The mean and STD of the CC values were also calculated over these eight sequences. The experimental results are given in Table 5
                           . Apparently, our method obtains the higher CC values than the LEM-based method for all the eight image sequences. The lower STD values also mean that our method is more robust in the signal extraction than the LEM-based method.

We also compared the computing performance between our method and LEM-based one, and the results are also listed in Table 5. The LEM-based method takes less than 1 second to process an image sequence of 256 frames, whereas our method needs more than 2seconds to complete the same task. It is evidently seen that our method trades larger calculation cost for higher signal accuracy. However, the increased computing time is acceptable to some extent for achieving higher signal accuracy and robustness.

The experimental results are illustrated in Fig. 6
                           , where two typical image sequences (S6 and S7) are used. We can observe that the breathing signals (in red) detected by the TM-based method are fairly inaccurate in comparison to the EM-tracked reference signals (in green). For instance, there are a large number of noises, distortions in peaks and valleys, and evident mismatch in signal profiles with the reference ones. Furthermore, we can see that the TM-based method can detect much better signals in S7 than S6. This is because that the selected anatomical feature (liver boundary) in S6 has relatively low contrast and the TM-based method seriously depends on properly choosing a template block containing salient anatomical features. In contrast, our LTSA-based method does not have such preference on anatomical features and is able to extract smoother and more accurate respiratory signals with relatively small noise. Furthermore, we as well performed a quantitative analysis on the signal tracking accuracy by calculating the CC values between the extracted signals, by our method and the TM-based one, and the EM-tracked reference signals. The mean and STD of the CC values were also calculated over these eight sequences. The experimental results are displayed in Table 6
                           , where the higher mean values and lower STD values further demonstrate that our method always gains more accurate and robust breathing signals than the TM-based one.

In addition, the comparison for the computing performance between our method and the TM-based one was also executed, and the corresponding results are placed into Table 6. It is noted that our method spends much less than 5s to extract the signals from image sequences of 256 frames, but the TM-based method needs more than 5s to do the same task. Therefore, in contrast to the TM-based one, our method is able to extract more accurate signals at higher computing efficiency.


                           Fig. 7
                            illustrates two reconstructed 3D US volumes from these image sequences: one volume being created by combining 2D images with the same position in these image sequences (the left side in this figure), and another being reconstructed by merging 2D images with the same expiration phase (the right side of this figure). From the lateral views in this figure, it is observed that, for the non-corrected volume, there are severe jagging effects around the liver boundary and three vessels. Due to application of our gating method, the breathing-corrected volume is well reconstructed, and, especially, the liver boundary and vessels are clearly visible.

@&#DISCUSSION@&#

As stated in the data acquisition subsection, the US images and corresponding EM positions are always acquired in pairs to ensure an approximate synchronization, and, especially, an US image is scanned immediately after an EM position is recorded. Therefore, the latency for each pair of US image and EM position roughly includes transmission and acquisition time of each EM position. Since each EM position occupies small data throughout (at most tens of bytes), the latency (mainly including the transmission and acquisition time) is very small and ignorable. Generally, this is a simple but practical technique for synchronizing US and EM data, similar to Barratt's work [30]. Quantitative measurement of the latency is quite difficult and needs special devices and complex calibration process, which is not in the scope of this paper. In fact, the experiments in this paper show that the EM-tracked respiratory signals nearly have no phase shift with respect to the signals extracted from US images, which also implies that the latency between US images and EM positions has been reduced to an acceptable level.

According to the description in the method section above, our signal extraction algorithm has only one controllable parameter: the number of the nearest neighbors of each data point on the manifold. The neighborhood of a data point delineates its local geometrical characteristic on the manifold and is usually utilized to map the nonlinear manifold in the high-dimension space to the corresponding one in the low-dimension space [24]. Theoretically, the number of the nearest neighbors should be moderate. The reason is that if the neighborhood size is too small, it will be unable to collect sufficient local information and incur incorrect embedding results; otherwise great neighborhood will also lose the locality and degenerate the embedding results. In addition, when the neighborhood of a data point becomes bigger, the time consumption for identifying the nearest neighbors and constructing the sparse alignment matrix will increase accordingly. Therefore, reducing the computing time as far as possible is another important consideration while choosing the number of the nearest neighbors. The visual inspection in Fig. 3 and quantitative results in Table 1 show that 64 nearest neighbors are most suitable options for a sequence of 256 frames in this paper.

It is also noticed from Table 1 that the differences for different number of nearest neighbors are not quite evident in the quantitative accuracy. However, we can still see great visual differences in the key peaks and valleys (corresponding to ends of expiration and inspiration, EE and EI), as illustrated in Fig. 3. The accuracy of the key respiratory phases plays an important role in breathing-gated applications, which often utilize the key phases for guiding 3D ultrasound reconstruction, radiation dose delivery and so forth. In fact, the trade-off between the computing time and signal accuracy is subtle, and often varies under different conditions. Under some conditions, if the time performance is critical, it is usually better to choose the smaller number of neighbors, for instance 16 neighbors. In this paper, when using 64 neighbors, we are still able to extract the respiratory signal in a very short time (in Table 5, about 2.3 for an image sequence of 256 frames, nearly 110Hz).

Our method takes an US image sequence as input and serializes each frame image as one feature vector in a row-majored way, so direct use of original images as features vectors will incur large time consumption. For example, as shown in Table 2, if the number of nearest neighbors is fixed as 64, it takes more than 5min to extract the respiratory signal for an image sequence consisting of 256 frames. Therefore, downsampling US images before serializing them will be able to speed up the signal extraction process. Furthermore, as the input images are reduced to some extent, dominant respiration-induced motions in these images will be preserved and other minor intensity variations and noise, which are inherent in the US imaging process, will be eliminated or weakened. Hence, image downsampling will help detect more accurate and robust breathing signals while reducing the time consumption. However, if reducing the images too much, respiratory information appearing in US images will also be partially missing and the accuracy of the extracted signals will be also deteriorated. The visual inspection in Fig. 4 and quantitative results in Table 3 already demonstrated the theoretical analysis.

In addition to be used for breathing gating from liver US images, manifold learning techniques have recently been applied for other gating situations, such as breathing-gated 4D CT imaging for the lung [31,32], breathing-gated fluoroscopic imaging for lung cancer radiotherapy [33], breathing-gated MR [22,34,35] and heart-beating-gated intravascular ultrasound (IVUS) [36]. Therefore, it is rationally expected that the proposed LTSA-based method in this paper is also able to find more value in other clinical fields.

@&#CONCLUSION@&#

This paper has presented a new approach for accurate and fast detection of surrogate respiratory signals of the moving liver directly from 2D US B-mode image sequences. This algorithm makes use of the LTSA-based nonlinear dimensionality reduction technique to extract intrinsic low-dimensional respiratory phase information embedded inside high-dimensional image data. LTSA uses a linear approximation for local geometry of each data point to construct a local coordinate system, and then aligns these overlapping local coordinate systems to obtain a global coordinate system to represent the data vectors in a low-dimensional space, which is finally projected as the respiratory signal. Multiple experiments have demonstrated that the proposed method surpasses other typical image-based methods in signal tracking accuracy and robustness at relatively high computing efficiency. Although only implemented and experimented using 2D US images, our method can also naturally be extended to operate on native 3D US images for respiratory gating. In future, we plan to integrate the proposed respiratory gating method into our ongoing image-guided robotic system for 3D/4D US imaging to capture the moving liver.

@&#ACKNOWLEDGEMENT@&#

This work is supported by a research grant (Grant No. 1431AFG099) from the Joint Council Office (JCO), Agency for Science, Technology and Research (ASTAR), Singapore.

@&#REFERENCES@&#


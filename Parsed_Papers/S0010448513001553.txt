@&#MAIN-TITLE@&#Improving spatial coverage while preserving the blue noise of point sets

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Local smoothing to optimize Voronoi cell aspect ratios.


                        
                        
                           
                           Simultaneously achieve random and well-spaced points.


                        
                        
                           
                           Image filtering applications.


                        
                        
                           
                           Meshing applications.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optimization

Voronoi aspect ratio

Disk

Triangulation

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Many applications desire a distribution of points that are not too close to one another, yet are evenly distributed throughout the domain. Such points are well-spaced, or separated yet dense. The separation distance improves efficiency; close points often add little information, yet they consume time and memory. Well-spaced points reduce the interpolation and simulation error in scientific applications. Points spread uniformly can help reduce noise or variance. Graphics applications often desire randomness to help reduce aliasing or bias. Blue noise refers to distributions that are roughly uniform random with no preferred inter-point directions or distances. Note that well-spacedness is a local measure of nearby points. In contrast, blue noise is a global measure dependent on the distances between far points. Some methods for well-spaced points often do not produce blue noise: e.g. periodic tilings such as lattices and structured meshes; raw low discrepancy sequences; and Delaunay Refinement (DR).

In the 1990s, the fracture mechanics community studied the effects of mesh structure in finite element fracture simulations where the crack directions are limited to mesh edges  [1]. They concluded that uniform random points lead to uniform random edge orientations, and more physically realistic simulations. Both Delaunay and dual Voronoi elements are of interest. The initial techniques for generating such meshes included simple jittering, perturbing the position of points. Interest in the topic recently revived, and researchers have developed more sophisticated techniques, including random sampling  [2–6]. Computer graphics has a long-standing interest in techniques for blue-noise distributions, for applications such as rendering  [7,8], animation  [9], modeling  [10,11], and imaging  [12,13]. Graphics provides standardized methods for determining if a distribution has blue noise  [14].

The well-spacedness of a distribution can be characterized by two measures: conflict, which is about the spacing between samples, and coverage, which is about how samples collectively cover the underlying domain. The conflict distance 
                        
                           
                              r
                           
                           
                              f
                           
                        
                      is the minimum distance between two samples, the coverage distance 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      is the maximum distance between a domain point and a sample, and 
                        β
                        =
                        
                           
                              r
                           
                           
                              c
                           
                        
                        /
                        
                           
                              r
                           
                           
                              f
                           
                        
                      is our spacing measure. The allowed (or target) values in an algorithm and the achieved values in its output are different concepts. In typical algorithms, these distances are enforced a priori by placing disks around sample points. On output, sample points might be farther apart than the enforced minimum, and domain points might be closer to a sample than the enforced maximum. See Figs. 1–3
                     
                     
                     
                       for illustrations and Section  4 for formulations.

Different methods achieve various degrees of conflict and coverage. Dart throwing  [7] enforces 
                        
                           
                              r
                           
                           
                              f
                           
                        
                     , and attempts to have output 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      close to it, but usually falls short. Maximal Poisson-disk Sampling (MPS)  [16] enforces both and has 
                        
                           
                              r
                           
                           
                              f
                           
                        
                        =
                        
                           
                              r
                           
                           
                              c
                           
                        
                     . Two-radii MPS  [15] also enforces both, but encourages more randomness (and less uniformity) by using 
                        
                           
                              r
                           
                           
                              c
                           
                        
                        >
                        
                           
                              r
                           
                           
                              f
                           
                        
                     . In practice, for even a few thousand points, MPS output 
                        
                           
                              r
                           
                           
                              f
                           
                        
                      is just slightly larger than the enforced 
                        
                           
                              r
                           
                           
                              f
                           
                        
                     , and output 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      is just slightly smaller than the enforced 
                        
                           
                              r
                           
                           
                              f
                           
                        
                     , because a local case similar to Fig. 3(b) or (c) is very likely. That is, MPS guarantees output 
                        β
                        ≤
                        1
                     , and usually achieves 
                        β
                      very close to 1. Two-radii MPS guarantees output 
                        β
                        ≤
                      target 
                        β
                     , and typically achieves something close to it.

There is some correlation between coverage/conflict and randomness, but the two are not proportional. At one extreme, uniform random points (also known as white noise or Poisson Sampling PS without disks) has unbounded coverage and conflict. Spectrum plots of MPS and two-radii distributions  [15] and Opt-
                        
                           
                              β
                           
                           
                              i
                           
                        
                       (Fig. 9) show a strong correlation between larger achieved 
                        β
                      and more randomness.

However, this is not the full story. In two dimensions, the vertices of equilateral triangle tiling achieve the minimum possible 
                        β
                     , with 
                        
                           
                              r
                           
                           
                              c
                           
                        
                        =
                        
                           
                              r
                           
                           
                              f
                           
                        
                        /
                        
                           
                              3
                           
                        
                     . It is the only distribution achieving this value, and distributions coming close to this value bear some resemblance to it. The vertices of its dual, hexagonal tiling, have 
                        
                           
                              r
                           
                           
                              c
                           
                        
                        =
                        
                           
                              r
                           
                           
                              f
                           
                        
                     . Square tiling gives a value of 
                        1
                        /
                        
                           
                              2
                           
                        
                     , somewhere in between. By adding or moving a single point of any of these, one can generate a periodic tiling with any larger 
                        β
                      desired, 
                        ∞
                        >
                        β
                        >
                        1
                        /
                        
                           
                              3
                           
                        
                     . Delaunay Refinement DR  [17,18] is a deterministic process for generating a triangulation. Its output vertices achieve 
                        
                           
                              r
                           
                           
                              c
                           
                        
                        ≤
                        
                           
                              r
                           
                           
                              f
                           
                        
                     , and its spectra show features of both regularity and MPS. None of the tilings or algorithms mentioned in this paragraph are random. However, a random algorithm such as MPS or even PS could in principle produce one of these, albeit with very small probability. The possible 
                        β
                      achieved by different distribution types are shown in Fig. 2.

Any random sampling method that only considers local criteria when placing points, and never moves them, cannot be guaranteed to achieve any target value of 
                        
                           
                              β
                           
                           
                              t
                           
                        
                        <
                        1
                     . The alternatives are to consider global constraints, or to adjust point locations, as Opt-
                        
                           
                              β
                           
                           
                              i
                           
                        
                       does in this paper. The reason that local decisions and fixed locations are insufficient is that it is easy to “paint yourself into a corner”, meaning that selecting points independently can create a subregion that is impossible to cover without placing points too close together. This can easily happen for any value of 
                        β
                        <
                        1
                     ; see Fig. 3. Achieving 
                        β
                        <
                        1
                      is actually more challenging than achieving 
                        β
                        =
                        1
                        [16] or 
                        β
                        >
                        1
                        [15].

To summarize, 
                        
                           –
                           
                              
                                 β
                                 >
                                 1
                               is produced by two-radii MPS  [15], and the user may select 
                                 β
                              . Uniform sampling without disks produces white noise, which may have 
                                 β
                               approaching 
                                 ∞
                              .


                              
                                 β
                                 =
                                 1
                               is produced by traditional maximal Poisson-disk sampling  [16]. Stopping short of maximality produces 
                                 β
                                 >
                                 1
                              .


                              
                                 β
                                 <
                                 1
                               is produced by Opt-
                                 
                                    
                                       β
                                    
                                    
                                       i
                                    
                                 
                                and it tends to make the distribution more uniform. Incremental insertion rarely achieves 
                                 β
                               significantly below 1.

The smaller the 
                                 β
                              , the more uniform a point set tends to be, but this is a feature of both the random process generating the points and 
                                 β
                              . In two dimensions, 
                                 β
                                 =
                                 1
                                 /
                                 
                                    
                                       3
                                    
                                 
                               indicates a periodic equilateral triangle tiling. A periodic structure can be tuned to any larger value of 
                                 β
                              . The minimum achievable 
                                 β
                               is dimension dependent, but 
                                 β
                                 ≥
                                 1
                                 /
                                 
                                    
                                       3
                                    
                                 
                               in two dimensions, and 
                                 β
                                 ≥
                                 0.5
                               by definition.

There are prior formulations quantifying both conflict and coverage, such as minimal spacing 
                        
                           
                              r
                           
                           
                              f
                           
                        
                      in dart throwing  [7], normalized spacing 
                        ρ
                        [19], and coverage radius 
                        
                           
                              r
                           
                           
                              c
                           
                        
                        [15]. Discrepancy measures spatial uniformity by comparing the fraction of points in any box to the fraction of the domain (volume) in that box  [20]. In spatial statistics, in the hard-core Strauss disk process, 
                        
                           
                              r
                           
                           
                              f
                           
                        
                      is known as the inhibition radius and 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      is known as the coverage radius. In biological system analysis, e.g. forestry image analysis  [21], one usually observes a (non-maximal) point distribution that is assumed to come from this process, then seeks to estimate the hidden generating parameters.

In computational geometry, 
                        
                           
                              r
                           
                           
                              f
                           
                           
                              i
                           
                        
                      is twice the inradius of the 
                        i
                     th Voronoi cell. And 
                        
                           
                              r
                           
                           
                              c
                           
                           
                              i
                           
                        
                      is known as the outradius of the Voronoi cell, the distance from a seed point to the furthest Voronoi vertex of its cell. The outradius/inradius ratio is the Voronoi cell aspect ratio, 
                        A
                        =
                        2
                        
                           
                              β
                           
                           
                              i
                           
                        
                     . Since outradius ≥ inradius, 
                        A
                        ≥
                        1
                      and 
                        
                           
                              β
                           
                           
                              i
                           
                        
                        ≥
                        0.5
                      in any dimension. A point set with maximum aspect ratio 
                        A
                      is called an 
                        A
                     -well-spaced set  [22]. Much effort  [23,24] has been devoted to generating 
                        A
                     -well-spaced sets, for both uniform and spatially varying densities. Usually the upper bound on 
                        A
                      is greater than 2, but we strive for 
                        A
                        <
                        2
                     .

In graphics, a common measure of point distributions is the relative radius 
                        ρ
                        [19]. Its definition starts with non-overlapping disks with constant 
                        
                           
                              r
                           
                           
                              f
                           
                        
                        /
                        2
                      radius. The packing density 
                        η
                      is the fraction of the domain area covered by these disks; 
                        η
                      is itself a popular measure in physics. Given a unit-area periodic domain containing 
                        N
                      disks, 
                        
                           
                              r
                           
                           
                              
                                 max
                              
                           
                        
                      is the radius achieved by the densest (in terms of 
                        η
                     ) known arrangement, assuming that 
                        N
                      divides evenly into that tiling. In two dimensions, 
                        
                           
                              r
                           
                           
                              
                                 max
                              
                           
                        
                        =
                        
                           const
                        
                        /
                        
                           
                              N
                           
                        
                     . We define 
                        ρ
                        =
                        
                           
                              r
                           
                           
                              f
                           
                        
                        /
                        
                           (
                           2
                           
                              
                                 r
                              
                              
                                 
                                    max
                                 
                              
                           
                           )
                        
                     , where 
                        ρ
                        ∈
                        
                           [
                           0
                           ,
                           1
                           ]
                        
                     . Thus 
                        ρ
                      is directly related to 
                        
                           
                              r
                           
                           
                              f
                           
                        
                     , but only indirectly related to 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      through 
                        N
                     . For example, if we create a gap by removing one vertex (disk) from an equilateral triangle tiling, then 
                        ρ
                      decreases by a factor of 
                        
                           
                              N
                              −
                              1
                           
                        
                        /
                        
                           
                              N
                           
                        
                     , a negligible change if 
                        N
                      is large, but 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      and 
                        β
                      almost double from 
                        1
                        /
                        
                           
                              3
                           
                        
                      to 1. In our context, the number of points 
                        N
                      is fixed, so we have 
                        β
                        ∝
                        
                           
                              r
                           
                           
                              c
                           
                        
                        /
                        ρ
                     . Area coverage and 
                        
                           
                              r
                           
                           
                              
                                 max
                              
                           
                        
                      are global averages over the disks, whereas 
                        
                           
                              r
                           
                           
                              c
                           
                           
                              i
                           
                        
                      is a maximum achieved in a local neighborhood of a point, its Voronoi cell. We think that 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      is a better measure of local spacing than 
                        ρ
                     , because 
                        β
                      measures local gaps and 
                        ρ
                      does not.

We compare our method against three alternative sampling techniques. While they all strive to improve the spatial quality of a distribution, none optimize 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      directly as we do.

A CVT  [25] is defined as a distribution in which each point is at the center of mass of its Voronoi cell. The earliest technique to achieve a CVT is Lloyd’s iteration  [26], iteratively moving each point to the center of its Voronoi cell. Recently, Liu et al.  [27] improved the speed of converging to a CVT by recognizing the second-order smoothness of its energy function, and optimizing it using a quasi-Newton method. But the converged solution is the same. The CVT converges to an equilateral triangle tiling, absent boundary effects. For this reason, many applications stop short of convergence.

Based on the iterative method definition, one might expect CVT to improve 
                           
                              
                                 r
                              
                              
                                 c
                              
                              
                                 i
                              
                           
                        , and not degrade 
                           
                              
                                 r
                              
                              
                                 f
                              
                              
                                 i
                              
                           
                        , at least in the average sense. Our experience is that CVT tends to decrease the maximum coverage radius 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                        , but does not provide any control over the minimum disk-free radius 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                        .

DistMesh is a popular point relocation technique that aims to make the Delaunay edge length distribution match a user-specified sizing function  [28]. This technique simply treats each Delaunay edge as a spring that can expand or contract; but if its length is less than the user-specified sizing function it can only expand. For the uniform case, the sizing function is constant and is usually chosen to be 20% more than the desired edge length. While this technique is good for improving the quality of the majority of the elements, it is not as good for improving the worst-quality elements.

In contrast to CVT, DistMesh tends to increase the disk-free radius 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         of an MPS; however, it does not provide any control over the coverage radius 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                        .

Farthest neighbor  [29,30] is an iterative technique that moves each point to the Voronoi vertex farthest from its immediate neighbors. As such, it locally optimizes 
                           
                              
                                 r
                              
                              
                                 f
                              
                              
                                 i
                              
                           
                        , and ignores 
                           
                              
                                 r
                              
                              
                                 c
                              
                              
                                 i
                              
                           
                        . The algorithm works by finding the Delaunay neighbors 
                           N
                           =
                           
                              {
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              }
                           
                         of sample 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                        , computing the Voronoi vertices of 
                           N
                         (without 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                        ), then reinserting 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                         at the Voronoi vertex with the maximum minimum distance to 
                           N
                        . If the points are not in convex position, there will be some Voronoi vertices far from the convex hull of 
                           N
                        ; these vertices are ignored.

This technique tends to increase all Delaunay edge lengths, not only the short ones.

We propose Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                        , local optimization of the 
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                         of the initial MPS sample positions, stopping when a user-specified ratio 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                           =
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                           /
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         is achieved. By tuning 
                           β
                        , our method can produce sample distributions with a level of uniformity and randomness as desired by the users. There is no guarantee that our method can achieve any value of 
                           β
                           <
                           1
                        , or even that 
                           β
                         will not increase, but in practice we can obtain 
                           β
                           ≈
                           0.75
                        .

In the sampling methods of Section  1, at least one of 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                         or 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         is a fixed enforced value. Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          is different, in that these are both measured quantities of the output. We simultaneously adjust both 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                         and 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         in pursuit of optimizing their ratio 
                           β
                        . Moving points might increase 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         or decrease 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                        . Experiments show that, despite this possibility, we usually simultaneously achieve both an increased 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         and a reduced 
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                        , while maintaining good spectra; see Table 1
                         and Fig. 5
                        
                        . Fig. 4 compares the methods over a periodic square.

Our paper has the following main contributions. 
                           
                              –
                              Introducing and formalizing the notion of Well-spaced Blue-noise Distributions (WBDs).

Proposing an algorithm, Opt-
                                    
                                       
                                          β
                                       
                                       
                                          i
                                       
                                    
                                 , to generate a WBD with controllable uniformity and randomness through 
                                    
                                       
                                          β
                                       
                                       
                                          t
                                       
                                    
                                 .

Demonstrating the benefits of a WBD and Opt-
                                    
                                       
                                          β
                                       
                                       
                                          i
                                       
                                    
                                   through applications in geometry meshing and image filtering.


                     
                        
                           Conflict radius   
                              
                                 
                                    r
                                 
                                 
                                    f
                                 
                              
                           .
                        
                           The minimum achieved spacing between any pair of samples in the set 
                                 S
                              . For example, for MPS, at least the enforced Poisson-disk radius.

Any point in the domain 
                                 Ω
                               will be at most 
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                 
                               away from the nearest sample in 
                                 S
                              . Equivalently, the set of spheres with radius 
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                 
                               will cover the entire domain.

The ratio between conflict and coverage is measured by 
                                 β
                                 =
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                 
                                 /
                                 
                                    
                                       r
                                    
                                    
                                       f
                                    
                                 
                              . This is the ultimate objective of our method.

The input (MPS) point set has 
                                 
                                    
                                       r
                                    
                                    
                                       
                                          MPS
                                       
                                    
                                 
                                 =
                                 
                                    
                                       r
                                    
                                    
                                       f
                                    
                                 
                                 =
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                 
                              .

During the local optimization procedure, we only consider the local values of these quantities, i.e. 
                        
                           Adjusted point   
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                           .
                        
                           We move one point at a time, 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 ∈
                                 S
                              .

Distance from 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                               to its nearest 
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 ∈
                                 S
                              .

Distance from 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                               to the farthest vertex of its Voronoi cell, i.e. the distance to the domain point farthest from 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                               that is not closer to some other sample 
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                              .

This is 
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                    
                                       i
                                    
                                 
                                 /
                                 
                                    
                                       r
                                    
                                    
                                       f
                                    
                                    
                                       i
                                    
                                 
                              . Note that 
                                 
                                    (1)
                                    
                                       β
                                       =
                                       
                                          
                                             
                                                
                                                   max
                                                
                                                
                                                   i
                                                
                                             
                                             
                                                
                                                   r
                                                
                                                
                                                   c
                                                
                                                
                                                   i
                                                
                                             
                                          
                                          
                                             
                                                
                                                   min
                                                
                                                
                                                   j
                                                
                                             
                                             
                                                
                                                   r
                                                
                                                
                                                   f
                                                
                                                
                                                   j
                                                
                                             
                                          
                                       
                                       ≥
                                       
                                          
                                             max
                                          
                                          
                                             i
                                          
                                       
                                       
                                          (
                                          
                                             
                                                β
                                             
                                             
                                                i
                                             
                                          
                                          )
                                       
                                       =
                                       
                                          
                                             max
                                          
                                          
                                             i
                                          
                                       
                                       
                                          (
                                          
                                             
                                                
                                                   
                                                      r
                                                   
                                                   
                                                      c
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      r
                                                   
                                                   
                                                      f
                                                   
                                                   
                                                      i
                                                   
                                                
                                             
                                          
                                          )
                                       
                                       .
                                    
                                 
                              
                           

We now describe our algorithm in detail. We start with an MPS, or some other distribution with blue noise, with 
                        β
                        =
                        1
                     . (Recall that the MPS output might have 
                        β
                        <
                        1
                     , but in practice 
                        β
                      is so close to 1 that we just say that 
                        β
                        =
                        1
                     .) It is possible to start with other distributions, such as the output of DR, but, since our method removes noise, the output will be limited by the noise in the input. In principle it is also possible to start with a distribution with 
                        β
                        >
                        1
                     ; in this paper we assume that such distributions are enriched to maximality with an MPS algorithm so that 
                        β
                        =
                        1
                     .

The user specifies the target 
                        β
                        =
                        
                           
                              β
                           
                           
                              t
                           
                        
                     , the desired trade-off between spacing and randomness. For two dimensions, 
                        
                           
                              β
                           
                           
                              t
                           
                        
                        ∈
                        
                           [
                           
                              
                                 1
                              
                              
                                 
                                    
                                       3
                                    
                                 
                              
                           
                           ,
                           1
                           ]
                        
                     .

Let 
                        
                           
                              β
                           
                           
                              i
                           
                        
                        =
                        
                           
                              r
                           
                           
                              c
                           
                           
                              i
                           
                        
                        /
                        
                           
                              r
                           
                           
                              f
                           
                           
                              i
                           
                        
                      denote the local coverage/conflict ratio. Ideally, one might wish to simultaneously adjust the location of all points to find a global minimum for 
                        β
                     , or at least to minimize the maximum of 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      over all 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     . A more practical method is to iteratively move each 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      towards its local optimum  [31].

We iteratively reposition each sample point 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      to locally minimize its 
                        
                           
                              β
                           
                           
                              i
                           
                        
                     , until globally 
                        β
                        <
                        
                           
                              β
                           
                           
                              t
                           
                        
                     .

To reposition 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , we perform ten iterations of Nelder–Mead  [32]. Nelder–Mead is a downhill-traveling optimization heuristic that requires only function values, not derivatives. Its state consists of three candidate points 
                        
                           
                              c
                           
                           
                              
                                 {
                                 1
                                 ,
                                 2
                                 ,
                                 3
                                 }
                              
                           
                        
                     , and the 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      function values if 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      was repositioned at those locations. To get started, we select the first candidate point 
                        
                           
                              c
                           
                           
                              1
                           
                        
                      at 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , the second 
                        
                           
                              c
                           
                           
                              2
                           
                        
                      at 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      shifted in the 
                        x
                     -axis direction by 
                        
                           
                              r
                           
                           
                              
                                 MPS
                              
                           
                        
                        /
                        10
                     , and the third 
                        
                           
                              c
                           
                           
                              3
                           
                        
                      at 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      shifted in the 
                        y
                     -axis direction by 
                        
                           
                              r
                           
                           
                              
                                 MPS
                              
                           
                        
                        /
                        10
                     . These 
                        
                           
                              c
                           
                           
                              
                                 {
                                 1
                                 ,
                                 2
                                 ,
                                 3
                                 }
                              
                           
                        
                      define a triangle, tilted in three dimensions by assigning the respective height 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      to its corners. Nelder–Mead replaces the high corner by some point on the other side of its opposite triangle edge, and recomputes a new triangle and its tilt. We flip-flop through ten triangles and stop.

Each candidate may have different Delaunay neighbors than the original point; we calculate 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      using the candidate’s Delaunay neighbors, rather than the original points’ neighbors. Sometimes, especially in initial iterations, 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      moves outside of the convex hull of its initial Delaunay neighbors: 
                        
                           
                              r
                           
                           
                              c
                           
                           
                              i
                           
                        
                      decreases as 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      moves towards the convex hull, but it may happen that 
                        
                           
                              r
                           
                           
                              f
                           
                           
                              i
                           
                        
                      increases more rapidly, yielding a local improvement in 
                        
                           
                              β
                           
                           
                              i
                           
                        
                     . We experimented with preventing this from happening, but found it was faster to allow this to happen.

Often, improving 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      causes a nearby point’s 
                        
                           
                              β
                           
                           
                              j
                           
                        
                      to get worse. This is a common phenomenon in mesh smoothing algorithms, and the common approach is to allow this to happen, and attempt to remedy it later during the optimization of 
                        
                           
                              x
                           
                           
                              j
                           
                        
                     .

We sweep over all 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , locally optimizing and updating their positions. Each update happens immediately. That is, for a neighbor 
                        
                           
                              x
                           
                           
                              j
                           
                        
                      of 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , we use the updated position of 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      rather than its initial position at the start of the sweep. Our input comes from Simple MPS  [33]. The output of that algorithm provides a nice ordering to the points, by scan lines. Simple MPS divides the domain into boxes of side length 
                        
                           
                              r
                           
                           
                              
                                 MPS
                              
                           
                        
                     , and each box has at most one point. On output the points are lexicographically ordered by the box they lie in, first by row then by column. This is the order the points are visited during our Opt-
                        
                           
                              β
                           
                           
                              i
                           
                        
                       sweep, regardless of where they later migrate to. This is better than considering points in random order.

In each sweep, we optimize the position of all 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , even if their local 
                        
                           
                              β
                           
                           
                              i
                           
                        
                      is already small. We tried iterating over just the large-
                        
                           
                              β
                           
                           
                              i
                           
                        
                      points, but this tended to get us stuck in a local minimum.

For large targets, e.g., 
                        
                           
                              β
                           
                           
                              t
                           
                        
                        >
                        0.9
                     , we often get far below it in one or two iterations. To prevent that, we use a damping factor, moving 
                        
                           
                              x
                           
                           
                              i
                           
                        
                      only about half-way (0.6–0.8) of the distance from its initial to its Nelder–Mead optimized position.

Local patch smoothing is common for unstructured meshes  [34]. Unlike patch smoothing, the connectivity of the implied mesh, the set of Delaunay neighbors of each sample, changes throughout our algorithm, and in our comparison methods.

@&#ANALYSIS@&#

Here, we recall the relationship between 
                           β
                           =
                           
                              
                                 r
                              
                              
                                 c
                              
                           
                           /
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                         and the edge lengths 
                           
                              |
                              e
                              |
                           
                        , empty circumcircle radius 
                           R
                        , and angles 
                           α
                         in a Delaunay Triangulation (DT) of the point set. The relationships are well known, and they form the basis for the Delaunay refinement [17] family of algorithms. We restate the succinct summary from Mitchell et al.  [15]:
                           Proposition 6.1
                           
                              
                                 
                                    |
                                    e
                                    |
                                 
                                 ∈
                                 
                                    [
                                    
                                       
                                          r
                                       
                                       
                                          f
                                       
                                    
                                    ,
                                    2
                                    R
                                    ]
                                 
                               
                              and 
                              
                                 R
                                 ≤
                                 
                                    
                                       r
                                    
                                    
                                       c
                                    
                                 
                              
                              .
                           


                        
                           Proposition 6.2
                           
                              
                                 sin
                                 α
                                 ≥
                                 
                                    |
                                    e
                                    |
                                 
                                 /
                                 2
                                 R
                              
                              .
                           

Normalizing by 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                        , and noting that the largest angle in a triangle is the supplement of the two smaller ones, we get the following. 
                           Proposition 6.3
                           
                              
                                 
                                    |
                                    e
                                    |
                                 
                                 /
                                 
                                    
                                       r
                                    
                                    
                                       f
                                    
                                 
                                 ∈
                                 
                                    [
                                    1
                                    ,
                                    2
                                    β
                                    ]
                                 
                              
                              .
                           


                        
                           Proposition 6.4
                           
                              
                                 α
                                 ∈
                                 
                                    [
                                    arcsin
                                    1
                                    /
                                    
                                       (
                                       2
                                       β
                                       )
                                    
                                    ,
                                    18
                                    
                                       
                                          0
                                       
                                       
                                          ∘
                                       
                                    
                                    −
                                    2
                                    arcsin
                                    1
                                    /
                                    
                                       (
                                       2
                                       β
                                       )
                                    
                                    ]
                                 
                              
                              .
                           

For example, 
                           β
                           <
                           0.75
                         gives 
                           
                              |
                              e
                              |
                           
                           /
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                           ∈
                           
                              [
                              1
                              ,
                              1.5
                              ]
                           
                         and 
                           α
                           ∈
                           
                              [
                              41
                              .
                              
                                 
                                    8
                                 
                                 
                                    ∘
                                 
                              
                              ,
                              96
                              .
                              
                                 
                                    4
                                 
                                 
                                    ∘
                                 
                              
                              ]
                           
                        . A value of 
                           β
                           <
                           1
                           /
                           
                              
                                 2
                              
                           
                           ≈
                           0.71
                         provides a non-obtuse triangulation.

These hold locally; i.e., if the local value of 
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                         for 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                         is smaller, it provides tighter bounds for the edges and triangles of 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                        .

The main result is that Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          generates the smallest 
                           β
                         values and the best blue noise (the most random spectra). We get a smaller 
                           β
                         simultaneously with a better spectrum. Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          is the best, followed by CVT, DistMesh, and then Far-Point.

Unfortunately, the speed of one iteration roughly reverses this order: DistMesh is the fastest, followed by Lloyd’s iteration (CVT without Liu et al.’s faster optimization  [27]), Far-Point, and then Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                        . One iteration of Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          is 15× slower than one iteration of standard CVT. For all methods, the overall runtime is roughly linear in the number of iterations. However, Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          is competitive with respect to the overall runtime. For 10,000 points in the periodic cube, to reach 
                           β
                           =
                           0.85
                        , Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          took 3.3 s and CVT took 10 s, because CVT required more iterations.

Since we only locally optimize the local 
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                           =
                           
                              
                                 r
                              
                              
                                 c
                              
                              
                                 i
                              
                           
                           /
                           
                              
                                 r
                              
                              
                                 f
                              
                              
                                 i
                              
                           
                        , a somewhat surprising result is that the global 
                           
                              
                                 r
                              
                              
                                 f
                              
                           
                           =
                           
                              
                                 min
                              
                              
                                 i
                              
                           
                           
                              
                                 r
                              
                              
                                 f
                              
                              
                                 i
                              
                           
                         is actually improved above 
                           
                              
                                 r
                              
                              
                                 
                                    MPS
                                 
                              
                           
                        . Since we improved 
                           β
                        , this implies that we have also reduced the maximum 
                           
                              
                                 r
                              
                              
                                 c
                              
                              
                                 i
                              
                           
                        . These features can be seen from the third and fourth columns of Table 1.

Each 
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                         is smaller than 
                           β
                        , so how small 
                           β
                         can be and still have randomness depends on the sample size. A larger sample size is more likely to have a local case stuck at a larger value of 
                           β
                        . One alternative would be to consider average 
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                        .


                        Figs. 7 and 9
                         analyze the Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          output for different 
                           β
                         values, over the periodic unit box domain. We use common spatial and spectral measures  [35,19,36,13,37,38]. For spatial analysis in Fig. 7, the zone-plate patterns are input, and we produce Gaussian-filtered output via our sample sets. Since the pattern contains a variety of spatial frequencies in different directions, it is a good stress test to detect any sampling pattern anomalies. We also plot the spatial samples directly for visual inspection. Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          exhibits the classic noise/alias trade-off: the smaller the 
                           β
                        , the more uniform the distribution, and thus there is less noise but more aliasing. Fig. 9 shows the Fourier spectra, radial mean, and anisotropy. We start to lose blue noise between 
                           β
                           =
                           0.75
                         and 
                           β
                           =
                           0.7
                        . The noise/alias trade-off does not apply across methods: for example, even though CVT has a higher 
                           β
                         than our Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                           
                           β
                           =
                           0.8
                         case, it still produces more aliasing.

Our experience is that, for values of 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                         above about 
                           1
                           /
                           
                              
                                 2
                              
                           
                           ≈
                           0.71
                        , the repositioning problem is mostly a geometry problem. For most local configurations, changing point positions to achieve this 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                         is eventually possible. Below about 0.71, we see oscillatory behavior in Fig. 6, and the problem becomes a discrete configuration problem. To achieve 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                           =
                           1
                           /
                           
                              
                                 3
                              
                           
                        , each point must have exactly six neighbors, evenly spaced on a circle around it. The six-neighbor pattern appears at about 
                           β
                           =
                           0.7
                         in the hexagonal shape of the rings in the spectrum, bottom left of Fig. 9. Even with five or seven neighbors, it is difficult to obtain a 
                           β
                         close to 
                           1
                           /
                           
                              
                                 3
                              
                           
                        . In the rightmost Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          example in Fig. 8
                        
                        , with 
                           β
                           =
                           0.75
                        , all vertices have valences between 5 and 7.

Besides this local discrete configuration constraint, small 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                         introduces global geometric constraints. The equilateral triangle tiling has points aligned along three sets of parallel lines. These lines constrain points that are far from one another. This is another reason for slow (or no) convergence for small 
                           
                              
                                 β
                              
                              
                                 t
                              
                           
                        . Fig. 11 shows that little progress is made beyond a certain number of iterations.

We perform ten Nelder–Mead steps for each local optimization. Using seven or fewer steps causes the overall algorithm to get stuck at a larger value of 
                           β
                        . Using more steps requires more runtime; ten steps ensures both convergence and efficiency.

We generated Well-spaced Blue-noise Distributions (WBDs) for the bounded non-convex domain in Fig. 10
                        
                        . This is more challenging than for a periodic square, and all four methods suffered from boundary constraints. All methods tended to improve the quality of most of the Voronoi cells. However, CVT and DistMesh violated the disk-free condition. On the other hand, Far-Point violated the coverage condition. Only Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          was able to reduce the value of 
                           β
                         while preserving both properties. The other methods increased 
                           β
                         over unity within their first few iterations. The problem is harder for the coarse mesh, because the boundary has an increased effect. Statistics after convergence (or more precisely, after stagnation) are given in Table 1. For Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          we solved a one-dimensional version of Nelder–Mead optimization to keep points on the boundary.

We applied Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          to a sphere and the Fertility sculpture. The disk-free and coverage distances are geodesic. For the uniform sphere, Fig. 14, Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          reduced 
                           β
                         significantly, from 1.0 to 0.73. This is reflected in more regularity in the Voronoi and Delaunay meshes. Using CVT, the minimum 
                           β
                         achieved was 0.81. Fig. 13 shows the quality measure distributions for valence, Delaunay angle, and Delaunay edge length.

For the non-uniform sphere, Fig. 12
                        
                        
                        , we used a linear sizing function in the 
                           z
                        -direction, varying from 0.21 to 0.01. We define the conflicts based on the smaller-disk criteria  [15]. Fig. 12 shows that neither the Delaunay angle bounds nor the maximum global 
                           β
                         have changed much; instead, their distributions have changed within about the same intervals.

We took the same approach with the Fertility model, a more complex shape. Fig. 15
                        
                         shows that we reach convergence after a few iterations, and achieve a better angle and local 
                           β
                         distribution.

Bilateral filtering is a core filtering method with a variety of applications in graphics, vision, and image processing  [39]. Similar to traditional linear filtering, e.g. Gaussian blur, bilateral filtering strives to reduce noise through blending nearby pixels. However, unlike linear filtering, which assigns filter weights based on domain information (spatial pixel locations) only, bilateral filtering also considers range information, such as pixel colors. This allows better preservations of image features such as region boundaries.

The downside is that bilateral filtering is slower and more difficult to accelerate than linear filtering. Many methods have been proposed to accelerate it  [40]. Among these, subsampling  [41] is simple and effective. Instead of using all pixels, Banterle et al.  [41] select only a subset of the kernel pixels. A properly chosen subset yields faster computation without a noticeable loss in output quality. The authors of  [41] experimented with various subsampling methods, and concluded that Poisson-disk sampling can be an excellent choice, due to its uniformity (reducing filtering noise) and randomness (low aliasing). Their paper suggests that maximal Poisson-disk sampling could be even better.

Here, we explore maximal Poisson-disk sampling with different 
                           β
                         for subsampling-accelerated bilateral filtering. Intuitively, since a smaller 
                           β
                         will produce more uniform and more regular distributions, it has the potential to reduce noise but increase aliasing in the filtering output. This is confirmed in Fig. 16
                        , in which we experiment through a range of 
                           β
                        , using Opt-
                           
                              
                                 β
                              
                              
                                 i
                              
                           
                          (
                           β
                           <
                           1
                        ) and other methods (
                           β
                           ≥
                           1
                        )  [15]. In our experiments it seems that 
                           β
                           ∈
                           
                              [
                              0.85
                              ,
                              0.75
                              ]
                           
                         strikes the right balance between uniformity (reducing noise) and randomness (avoiding bias).

@&#CONCLUSIONS@&#

This paper introduced a Well-spaced Blue-noise Distribution (WBD), with 
                        β
                        =
                        
                           
                              r
                           
                           
                              c
                           
                        
                        /
                        
                           
                              r
                           
                           
                              f
                           
                        
                      measuring coverage uniformity or well-spacedness. We proposed the Opt-
                        
                           
                              β
                           
                           
                              i
                           
                        
                       algorithm to change a random point set to a WBD; blue noise is preserved up to 
                        β
                        ≈
                        0.75
                     . We demonstrated Opt-
                        
                           
                              β
                           
                           
                              i
                           
                        
                     ’s efficacy in geometry meshing and image filtering applications. We believe that the main contribution of this paper is on the introduction and measurement side, and we envision fruitful future directions for both algorithm and application development. For example, generating a WBD with 
                        β
                        <
                        1
                      from scratch is an open problem.


                     Adaptive and anisotropic sampling. We kept 
                        
                           
                              r
                           
                           
                              c
                           
                        
                      and 
                        
                           
                              r
                           
                           
                              f
                           
                        
                      constant throughout the domain, except for the sphere. In principle, we could extend both to spatially varying functions of sample positions, for adaptive or anisotropic sampling  [42]. The spatial and spectral properties of such adaptive/anisotropic distributions can be analyzed by the differential domain method  [37] through local warping. It remains to formulate an optimization objective function.


                     Tiling. We currently compute entire sample sets. A potential extension is generating sample tiles  [43,44,35] for acceleration.


                     Higher dimensions and meshing. We would like to address 
                        d
                        >
                        2
                     . Recall that MPS  [33] can produce 
                        β
                        =
                        1
                      in any dimension, but the lower limit achieved by the densest packing is dimension dependent. In this paper we focused on planar meshing. Volumetric and general curved surface meshing would be interesting and important extensions. Lower 
                        β
                      provides better angles in 
                        d
                        =
                        2
                     , and better radius-edge condition in 
                        d
                        ≥
                        2
                     , which are helpful for a variety of scientific and engineering applications.


                     Lower   
                        β
                     . Our current algorithm can reach 
                        β
                        ≈
                        0.75
                     . We would like to investigate the theoretical potential of reaching even lower values, even though these distributions may have limited utility due to excessive regularity, as is evident from the hexagonal spectrum bias of the 
                        β
                        =
                        0.70
                      case in Fig. 9. Also, the local optimization approach may require too much computation for small 
                        β
                     .

@&#ACKNOWLEDGMENTS@&#

Sandia National Laboratories is a multi-program laboratory managed and operated by Sandia Corporation, a wholly owned subsidiary of Lockheed Martin Corporation, for the U.S. Department of Energy’s National Nuclear Security Administration under contract DE-AC04-94AL85000.

@&#REFERENCES@&#


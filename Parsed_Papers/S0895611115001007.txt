@&#MAIN-TITLE@&#Automated compromised right lung segmentation method using a robust atlas-based active volume model with sparse shape composition prior in CT

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We proposed the robust shape atlas built upon the output of SSC.


                        
                        
                           
                           The 3D AVM with SSC prior is applied on compromised lung segmentation.


                        
                        
                           
                           Our proposed method can achieve better segmentation accuracy.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Image segmentation

Lung cancer

Compromised lung segmentation

Sparse shape composition

Atlas-based active volume model

@&#ABSTRACT@&#


               
               
                  To resolve challenges in image segmentation in oncologic patients with severely compromised lung, we propose an automated right lung segmentation framework that uses a robust, atlas-based active volume model with a sparse shape composition prior. The robust atlas is achieved by combining the atlas with the output of sparse shape composition. Thoracic computed tomography images (n
                     =38) from patients with lung tumors were collected. The right lung in each scan was manually segmented to build a reference training dataset against which the performance of the automated segmentation method was assessed. The quantitative results of this proposed segmentation method with sparse shape composition achieved mean Dice similarity coefficient (DSC) of (0.72, 0.81) with 95% CI, mean accuracy (ACC) of (0.97, 0.98) with 95% CI, and mean relative error (RE) of (0.46, 0.74) with 95% CI. Both qualitative and quantitative comparisons suggest that this proposed method can achieve better segmentation accuracy with less variance than other atlas-based segmentation methods in the compromised lung segmentation.
               
            

@&#INTRODUCTION@&#

Lung cancer remains one of the leading causes of cancer-related deaths in the United States [1]. The prognosis of patients with lung cancer has improved over recent years, in part as a result of a range of significant improvements in imaging and computer technology as well as technical advances in radiation therapy planning and delivery, including techniques such as image-guided radiotherapy (IGRT) [2].

One continuing challenge in IGRT planning is segmentation of lungs in thoracic computed tomography (CT) images. Difficulties associated with segmentation can be classified into three broad categories [3]. The first involves the presence of specific diseases, such as lung cancer, pneumonia and interstitial lung disease. The pathologies associated with these specific diseases, particularly as they affect the chest wall or mediastinum, show no obvious differences in Hounsfield units (HUs) on CT. The result can be the exclusion of a large portion of lung from the treatment planning volume and/or the segmentation of the lung into isolated parts (Fig. 1
                     ). The second category is anatomical variability, such as the excision of one side of the lungs because of existence of lung cancer. The third category is the external factors, such as the improper field-of-view, improper patient position or orientation information in the DICOM header, metal artifacts, or damaged CT datasets. The presence of specific lung diseases mentioned above is the primary issue in computerized lung segmentation. The segmentation failures caused by anatomy variety and external factors are relatively infrequent but unavoidable in practice.

A large number of lung segmentation methods have been already developed in the non-compromised lungs, where the obvious differences in HU between the lung and the chest wall, mediastinum and liver form the basis for the majority of the lung segmentation schemes. Lung segmentation methods for compromised lung volumes with severe pathological lungs have not been fully addressed [4,5].

Segmentation of compromised lung is complex and challenging. First, pathological structures, such as large lung tumors, and normal adjacent organs, such as the chest wall, mediastinum, and the liver, do not show obvious differences in the distribution of Hounsfield units (HU) numbers, causing the majority of lung segmentation schemes to fail. Second, the original ground truth used for training data in lung segmentation comes from actual lung cancer patients, including those with right or left lung cancer, right- or left-side mediastinum cancer, etc. The original ground truth derived from patients with right lung cancer and those with right-side mediastinum cancer with compromised right lung may not contain the whole right lung volume. To address the first challenge, shape priors are helpful, because they can assist in differentiating and separating pathological structures from normal adjacent organs. To address the second challenge, the original ground truth from the compromised right lung can be viewed as a shape instance derived from image appearance cues with gross errors. Robust shape models that handle gross errors can be helpful, because they can detect, reject, or remove the influence of gross errors.

Here we proposed an automated and robust segmentation framework which uses robust atlas-based active volume model (AVM) with sparse shape composition (SSC) prior. Sparsity has been widely employed for medical image analysis tasks, such as segmentation, registration and reconstruction [6–16]. The main contribution the work on which we report here is threefold: (1) To address the challenge of the original ground truth for the compromised right lung, we generate the robust shape atlas with the refined ground truth from the output of SSC. We assumed the original ground truth from the compromised right lung can be viewed as a shape instance derived from image appearance cues with gross errors and also these gross errors are sparse in spatial space. The SSC explicitly models gross errors, so that erroneous information from the compromised right lung can be effectively detected and removed and the original ground truth can be refined. (2) To address the challenge to separate the pathological structures from attached and/or adjacent organs with the similar Hounsfield units (HU), a 3D AVM with SSC prior was employed. The SSC model makes no assumption about the parametric distributions of right lung shapes while preserving local details of right lung shapes. As a result, AVM with SSC prior is patient-specific and sufficiently accurate to model the complex variations of right lung shapes. (3) The novel segmentation framework was successfully demonstrated in clinic applications in compromised right lung segmentation. The framework is sufficiently robust to deal with complex cases of right lung cancer in the clinical environments.

The paper is organized as follows. Section 2 reviews the relevant work on lung segmentation methods which include the thresholding based methods, edge model based methods and deformable model based methods. Section 3 presents the framework of an automated and robust segmentation framework which uses robust atlas-based AVM with SSC prior for compromised right lung in thoracic CT. Section 4 shows training and testing datasets, the results on the testing dataset and discussions. Section 5 presents the conclusion.

@&#RELATED WORK@&#

A large number of lung segmentation methods have been already developed in the non-severe pathological lungs [5]. The existing techniques for lung segmentation can be classified into three categories, the thresholding-based methods [17–22], edge-based methods [23,24], and deformable model based methods [25–39].

A threshold was computed iteratively to get a raw lung region. Then the computed raw lung region was refined by various morphological operations in [17]. The similar process was also implemented in the pre-processing step to segment both lung fields in [18]. Region growing and connected-component analysis were implemented to segment the lung areas in [20]. Level thresholding is automatically applied to select the threshold in [21]. Then region filling method was used to segment the lung areas.

The edge-based segmentation of lung areas was implemented using edge detectors, such as the first derivative of Gaussian filters, or wavelet transformations. The rectangular ROIs that tightly surrounded the lung areas were obtained. Then edges were detected by the edge detectors and connected to create closed lung boundaries [23]. The lung borders were first detected by 2D wavelet transformation in 2D images. Then, an optimal threshold was implemented to the 3D stacks processed by wavelet to segment lung areas [24].

The deformable model based lung segmentation methods use active contours, active shape model (ASM) or level sets methods. An atlas was constructed consisting of various lung features and an average lung shape. The ASM pose parameters were calculated by transforming the average lung shape using the affine transformation [38]. The 2D parametric deformable model was initiated by a threshold based method and deformed using the external forces from the lung borders. The segmentation results were used to classify abnormal areas in lung [25]. Geometric level sets method was initially implemented at the boundary of the chest areas. Then the model was automatically split into the left and right lung areas [26]. The lungs were segmented using two steps. First, a rough initial lung borders was segmented using the 3D ASM. Second, a refined smoothed was applied by a global optimal surface searching method [27,28]. A graph-based search based automatic lung segmentation method was developed. The cost function incorporates various feature information including the intensity, edges, boundary, and the ribs [29].

The lung segmentation methods on compromised lung volumes with severe pathological lungs have not been fully addressed [4,5]. The segmentation method based on robust active shape model (RASM) was developed for patients with compromised lung volumes in thoracic CT [30]. However, RASM needs a large amount of training samples to handle multimodal distribution of shapes which cannot be represented by the mean shape and variations. The RASM uses M-estimator which does not have enough robustness against non-Gaussian outliers [31–34]. RASM has difficulties to preserve the local detail information of the input shape when the details are presented in the training data but not statistically significant.

@&#METHODOLOGY@&#

In this section, first, we will describe the construction of statistical image atlas and robust shape atlas, and the sparse shape prior representation. Then, we will introduce our framework for right lung segmentation using a 3D AVM with SSC prior.

The flow chart of our framework is shown in Fig. 2
                        . The statistical image atlas containing one reference intensity image and a corresponding spatial probability map (SPM) image is built for the right lung using the volumes of training dataset. At the same time, a robust shape atlas for the shape representation model is constructed with the refined ground truth from the output of SSC. The SPM and shape model are in the source image domain. After nonrigidly registering the source image to target image, the SPM and shape model are deformed to the target image space using the same transformation. Then the AVM is initialized from an atlas-based alignment and evolves to segment the target right lung volume. The deformation is based on the image context information and is regulated by shape constraint as well as the initial SPM.

For atlas construction, a statistical image atlas and a shape atlas will first be built. The statistical image atlas contains the mean intensity image representing a group of training dataset and a corresponding spatial probability map. The probabilistic right lung map is encoding the spatial distribution and variance of right lung in the training dataset. The statistical image atlas is used for initialization as well as a constraining energy term of the AVM. The shape atlas is a set of mesh models built from the output of SSC of the shapes of training data that shows the shape prior of the right lung in the AVM.

The probabilistic right lung atlas from CT images is built using a state-of-the-art symmetric diffeomorphic normalization (SyN) method [40]. Let 
                              T
                              (
                              
                                 I
                                 source
                              
                              ,
                              D
                              (
                              x
                              )
                              ,
                              
                                 I
                                 target
                              
                              )
                              →
                              
                                 
                                    
                                       I
                                       ˆ
                                    
                                 
                                 source
                              
                            denote a nonrigid transformation T from source image I
                           
                              source
                            to target image I
                           
                              target
                            by deformation field D(x), which results in a warped image 
                              
                                 
                                    
                                       I
                                       ˆ
                                    
                                 
                                 source
                              
                            in the image space of I
                           
                              target
                           .


                           
                              Algorithm 1
                              Build statistical image atlas


                                 
                                    
                                       
                                          
                                          
                                          
                                             
                                                
                                                   Input:
                                             
                                             
                                                
                                                The training simple atlases {I
                                                   
                                                      i
                                                   , L
                                                   
                                                      i
                                                   }, i
                                                   ∈{1, …, W};
                                             
                                             
                                                
                                                   Output:
                                             
                                             
                                                
                                                The statistical atlas {I
                                                   
                                                      mean
                                                   , L
                                                   
                                                      mean_prob
                                                   };
                                             
                                             
                                                1:
                                                
                                                   k
                                                   =0
                                             
                                             
                                                2:
                                                pick an arbitrary m, where m
                                                   ∈{1, …, W}
                                             
                                             
                                                3:
                                                re-sample 
                                                      
                                                         I
                                                         m
                                                      
                                                    to get isotropic voxel size 2mm× 2mm×2mm
                                             
                                             
                                                4:
                                                initialize template 
                                                      
                                                         I
                                                         mean
                                                         
                                                            (
                                                            0
                                                            )
                                                         
                                                      
                                                    by normalized I
                                                   
                                                      m
                                                   
                                                
                                             
                                             
                                                5:
                                                
                                                   I
                                                   
                                                      i
                                                   
                                                   (0)
                                                   =
                                                   I
                                                   
                                                      i
                                                   , L
                                                   
                                                      i
                                                   
                                                   (0)
                                                   =
                                                   L
                                                   
                                                      i
                                                   
                                                
                                             
                                             
                                                6:
                                                
                                                   while 
                                                   k
                                                   <
                                                   MAXIMUMITERATION 
                                                   do
                                                
                                             
                                             
                                                7:
                                                
                                                   
                                                   for 
                                                   i
                                                   =1 to W 
                                                   do
                                                
                                             
                                             
                                                8:
                                                
                                                   compute the optimal diffeomorphic deformation D
                                                   
                                                      i
                                                   
                                                   (k) to get warped I
                                                   
                                                      i
                                                   
                                                   (k+1)
                                                
                                             
                                             
                                                9:
                                                
                                                   
                                                   end for
                                                
                                             
                                             
                                                10:
                                                
                                                   
                                                   
                                                      
                                                         I
                                                         mean
                                                         
                                                            (
                                                            k
                                                            +
                                                            1
                                                            )
                                                         
                                                      
                                                      =
                                                      
                                                         1
                                                         W
                                                      
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            W
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                                     I
                                                                     i
                                                                  
                                                               
                                                               
                                                                  (
                                                                  k
                                                                  +
                                                                  1
                                                                  )
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                11:
                                                
                                                   
                                                   k
                                                   =
                                                   k
                                                   +1
                                             
                                             
                                                12:
                                                
                                                   if converge, break
                                             
                                             
                                                13:
                                                
                                                   end while
                                                
                                             
                                             
                                                14:
                                                
                                                   for 
                                                   i
                                                   =1 to W 
                                                   do
                                                
                                             
                                             
                                                15:
                                                
                                                   compute D
                                                   
                                                      i
                                                   
                                                   (k) to get warped 
                                                      
                                                         
                                                            
                                                               I
                                                               ˆ
                                                            
                                                         
                                                         i
                                                      
                                                    and 
                                                      
                                                         
                                                            
                                                               L
                                                               ˆ
                                                            
                                                         
                                                         i
                                                      
                                                   
                                                
                                             
                                             
                                                16:
                                                
                                                   end for
                                                
                                             
                                             
                                                17:
                                                
                                                   
                                                      
                                                         I
                                                         mean
                                                      
                                                      =
                                                      
                                                         1
                                                         W
                                                      
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            W
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                                     I
                                                                     ˆ
                                                                  
                                                               
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                18:
                                                
                                                   
                                                      
                                                         L
                                                         
                                                            mean
                                                            _
                                                            prob
                                                         
                                                      
                                                      =
                                                      
                                                         100
                                                         W
                                                      
                                                      
                                                         
                                                            ∑
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                            W
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                                     L
                                                                     ˆ
                                                                  
                                                               
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Given W training simple atlases, our statistical atlas is built following the Algorithm 1. The I
                           
                              i
                            and L
                           
                              i
                            are the ith image and its ground truth labeled image. In the output, I
                           
                              mean
                            is the mean image that is the unbiased representative of the training images. L
                           
                              mean_prob
                           (x) is the right lung probabilistic map that represents the probability of right lung appearing at x. Note that we do not preprocess the training dataset to normalize into a common size and spacing. Instead, normalization is implicitly performed after the first iteration, because all the images are transformed to the normalized template 
                              
                                 I
                                 mean
                                 
                                    (
                                    0
                                    )
                                 
                              
                           . The result of our atlas construction is shown in Fig. 3
                           . During the construction, each nonrigid (deformable) registration is performed after an affine registration. Mutual information (MI) and cross-correlation (CC) are among the most common image similarity metrics used in registration problems. MI estimates globally optimal matching between images but may not be a good option in cases in which nonstationary patterns require locally adaptive similarity measurement. CC depends only on local estimates and is suitable when locally varying intensities occur. In [41], the authors evaluated the different similarity metrics in the Advanced Normalization Toolkit (ANT) [42] and showed that MI-based affine registration provides the best initialization for deformable registration. They recommended MI or normalized MI (NMI) as the best similarity metric in dealing with scanner variations and pathomorphological changes. Thus, we use MI metric in affine registration. To ensure the robustness of registration in extreme lung inhomogeneity, we choose CC as the similarity metric to perform nonrigid registration.

With the statistical image atlas, a binary template label image can be estimated by thresholding after smoothing and morphological operations. Then a high-quality surface mesh [43] is built in the template domain.

Similarly, all the training label images are converted to high-quality mesh models. As noted in Section 1, the original ground truth used for training data are from real lung cancer patients. The original ground truth of right lung cancer patients and right side mediastinum patients with compromised right lung may not have the whole right lung volume. We assume that the original ground truth from the compromised right lung can be viewed as a shape instance derived from image appearance cues with gross errors and also that these gross errors are sparse in spatial space.

Gross errors usually degrade the prior information from shape atlases and also introduce inaccurate or misleading shape constraints for the deformable model. The SSC model explicitly models gross errors, so that the erroneous information from the compromised right lung can be effectively detected and removed [6].

Thus, we utilize the SSC model to remove gross errors and refine the ground truth training shapes.

Suppose each constructed shape atlas is represented by a vector of vertex coordinates y
                           
                              i
                           
                           ∈
                           R
                           
                              DN
                           , where D is the degree of freedom and N is the number of vertices in the mesh model. We use a leave-one-out strategy to compute the approximation of shape y
                           
                              i
                            by all the other shapes. Let A
                           
                              i
                           
                           ∈
                           R
                           
                              DN×(W−1) denote the matrix of training shape vectors except y
                           
                              i
                           , so that the refined 
                              
                                 
                                    
                                       y
                                       ˆ
                                    
                                 
                                 i
                              
                            is defined by:
                              
                                 (1)
                                 
                                    
                                       
                                          
                                             y
                                             ˆ
                                          
                                       
                                       i
                                    
                                    =
                                    
                                       G
                                       
                                          −
                                          1
                                       
                                    
                                    (
                                    
                                       A
                                       i
                                    
                                    
                                       
                                          
                                             c
                                          
                                       
                                       i
                                    
                                    ,
                                    β
                                    )
                                 
                              
                           where c
                           
                              i
                           
                           ∈
                           R
                           (W−1) is the sparse coefficient vector. Let e
                           
                              i
                           
                           ∈
                           R
                           
                              DN
                            be a sparse error vector, so that c
                           
                              i
                            is computed by:


                           
                              
                                 (2)
                                 
                                    
                                       
                                          
                                             c
                                          
                                       
                                       i
                                    
                                    ,
                                    
                                       
                                          
                                             e
                                          
                                       
                                       i
                                    
                                    =
                                    
                                       argmin
                                       
                                          
                                             
                                                c
                                             
                                          
                                          ,
                                          
                                             
                                                e
                                             
                                          
                                       
                                    
                                    ∥
                                    
                                       G
                                       (
                                       
                                          
                                             y
                                             i
                                          
                                       
                                       ,
                                       β
                                       )
                                       −
                                       
                                          A
                                          i
                                       
                                       
                                          
                                             c
                                          
                                       
                                       −
                                       
                                          
                                             e
                                          
                                       
                                    
                                    
                                       ∥
                                       2
                                       2
                                    
                                    +
                                    
                                       
                                          λ
                                          1
                                       
                                    
                                    
                                       ∥
                                       
                                          
                                             c
                                          
                                       
                                       
                                          ∥
                                          1
                                       
                                    
                                    +
                                    
                                       
                                          λ
                                          2
                                       
                                    
                                    
                                       ∥
                                       
                                          
                                             e
                                          
                                       
                                       
                                          ∥
                                          1
                                       
                                    
                                 
                              
                           
                        

To build the shape prior model, we first prealign all the refined ground truth training shapes to the reference shape, based on the generalized Procrustes analysis [44] to ensure that they are all in the same coordinate space. Then the one-to-one correspondence of vertices on different meshes is obtained by registering the reference mesh to all the training shapes. Here, we employ the mesh quality-preserved deformable models to create the one-to-one correspondence.

After the 3D AVM is initialized by image atlas registration, it evolves to segment the target right lung. Deformation is based on the image context information and regularized by learnt shape prior. The energy function of the robust AVM is defined as:
                           
                              (3)
                              
                                 E
                                 =
                                 
                                    E
                                    int
                                 
                                 +
                                 
                                    κ
                                    1
                                 
                                 
                                    E
                                    ext
                                 
                                 =
                                 
                                    E
                                    int
                                 
                                 +
                                 
                                    κ
                                    1
                                 
                                 (
                                 
                                    E
                                    edge
                                 
                                 +
                                 
                                    κ
                                    2
                                 
                                 
                                    E
                                    region
                                 
                                 +
                                 
                                    κ
                                    3
                                 
                                 
                                    E
                                    atlas
                                 
                                 )
                              
                           
                        In this equation, κ
                        1, κ
                        2 and κ
                        3 are scalar parameters used as balances of different energy terms. E
                        
                           int
                         is the internal energy term constraining shape tension and rigidity. E
                        
                           ext
                         is the set of external energy terms used to introduce forces to deform the model toward object boundary, which includes image edge energy E
                        
                           edge
                        , object region energy E
                        
                           region
                        , and atlas prior energy E
                        
                           atlas
                        . E
                        
                           edge
                         introduces external force using gradient magnitude map, edge distance map or gradient vector flow (GVF). E
                        
                           region
                         provides two-way balloon force and comes from the ROIs’ interior and exterior intensity statistics [45]. E
                        
                           atlas
                         is the energy term used to encode the constraints by the spatial probability map, which has been computed in image atlas construction and nonrigidly transformed to target image space. (Note that the transformed image atlas also provides a reliable initialization to the deformable model.) All the energy terms above are designed differentiable with respect to the model parameter. Thus the mesh deformation can be solved as a dynamic system using a gradient descent algorithm. In each time step, this is a linear system like standard finite element method (FEM) [46].

However, several factors often cause ambiguous boundaries and may mislead the energy term encoding. These factors include image noise, intensity inhomogeneity, and similar intensity distributions of nearby organs. In order to deal with such misleading cues, we incorporated a shape prior constraint into our deformable model to create a unified framework. SSC prior preserves local detail information and provides the ability to preserve the boundary information between the large lung tumors and the attached chest wall or mediastinum, which have the similar HUs. Assuming the evolving model shape vector is y
                        
                           t
                         at a time t, we solve the following optimization to obtain the sparse shape approximate of y
                        
                           t
                         from the training shapes.


                        
                           
                              (4)
                              
                                 
                                    c
                                    t
                                 
                                 ,
                                 
                                    e
                                    t
                                 
                                 =
                                 
                                    argmin
                                    
                                       
                                          
                                             c
                                          
                                       
                                       ,
                                       
                                          
                                             e
                                          
                                       
                                    
                                 
                                 ∥
                                 
                                    T
                                    (
                                    
                                       
                                          y
                                          t
                                       
                                    
                                    )
                                    −
                                    
                                       
                                          A
                                          ˆ
                                       
                                    
                                    
                                       
                                          c
                                       
                                    
                                    −
                                    
                                       
                                          e
                                       
                                    
                                 
                                 
                                    ∥
                                    2
                                    2
                                 
                                 +
                                 
                                    
                                       λ
                                       1
                                    
                                 
                                 
                                    ∥
                                    
                                       
                                          c
                                       
                                    
                                    
                                       ∥
                                       1
                                    
                                 
                                 +
                                 
                                    
                                       λ
                                       2
                                    
                                 
                                 
                                    ∥
                                    
                                       
                                          e
                                       
                                    
                                    
                                       ∥
                                       1
                                    
                                 
                              
                           
                        where T(y
                        
                           t
                        ) is the transformation (i.e. Procrustes transformation) from target domain to training template domain, 
                           
                              A
                              ˆ
                           
                         is the matrix that has columns consist with training shapes 
                           
                              
                                 
                                    y
                                    ˆ
                                 
                              
                              i
                           
                           ,
                           ∀
                           i
                           ∈
                           {
                           1
                           ,
                           …
                           ,
                           W
                           }
                        . The regularized shape representation is 
                           
                              
                                 A
                                 ˆ
                              
                           
                           
                              
                                 
                                    
                                       c
                                       t
                                    
                                 
                              
                           
                        , which is then transformed back to target space with the inverse transformation of T.

To summarize, the segmentation by evolution of AVM with shape constraint starts from registering and warping the image atlas to the target domain. We construct the initial surface model by extracting an isosurface from the warped SPM. Then the energy terms and force fields are computed for the AVM before it evolves. To keep up the efficiency of the evolution, shape regularization is conducted every δt iterations. The evolution is stopped when the deformation is sufficiently small. At last, the 3D surface model is converted to a binary mask image as the segmentation result.

@&#RESULTS@&#

In this section, we describe the clinic dataset and different comparison segmentation methods in the experiments, as well as the evaluation criteria. Then the detailed results are presented which include the visualization of segmentation errors and quantitative and statistical accuracy comparison. Finally, we discuss the issues and limitations observed in the experiments.

Thoracic computed tomography images (n
                        =38) from patients with lung tumors were collected and used in the experiments, including eight compromised right lung volumes and 30 normal right lung volumes. Data were acquired using a Philips Brilliance Big Bore CT Simulator system (Philips Healthcare; Andover, MA) with the following scanning protocol: slice thickness = 3mm, image resolution = 512×512, pixel spacing = 1.0332mm×1.0332mm, number of slices = 101–121.

In this application, the labels of the ground truth were all from real lung cancer patients contoured by two experts. The labels of ground truth of right lung cancer patients with compromised right lung did not include the tumor volume.

We compared the proposed method with our implemented automatic graph cut (AGC) method based on probabilistic atlas [47]. To make a fair comparison, the atlas construction was the same as the method presented in Section 3.2. The atlas-to-target nonrigid registration was the same. The graph cut was based on the in-cut/max-flow algorithm [48] assuming 6-neighborhood connectivity. All methods were implemented in Matlab and tested on 2.3GHz Intel Core i3 computer with 6GB RAM.

We report the mean value of Dice similarity coefficient (DSC), accuracy (ACC) and relative error (RE) compared to the ground truth to show the overlapping accuracy, as follows:
                           
                              (5)
                              
                                 DSC
                                 =
                                 
                                    
                                       2
                                       TP
                                    
                                    
                                       2
                                       TP
                                       +
                                       FP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 ACC
                                 =
                                 
                                    
                                       TP
                                       +
                                       TN
                                    
                                    
                                       TP
                                       +
                                       TN
                                       +
                                       FP
                                       +
                                       FN
                                    
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 RE
                                 =
                                 
                                    
                                       FP
                                       +
                                       FN
                                    
                                    
                                       TP
                                       +
                                       FN
                                    
                                 
                              
                           
                        Here, TP, TN, FP and FN are numbers of voxels correctly identified, correctly rejected, incorrectly identified, and incorrectly rejected as right lung tissue, respectively. The symmetrical surface distance error and Hausdorff distance are also measured between the surface of segmentation results and the ground truth [49].

@&#RESULTS@&#

Before comparing with different approaches, we first showed the final segmentation effect of the 3D AVM with SSC prior in our proposed method. As shown in Fig. 4
                        , green lines represent the refined ground truth boundaries, blue lines are the initial segmentations, and the red lines are the final results from our proposed approach. We observe that despite inaccuracy, robust atlas-based registration provides reliable initialization for the final segmentation. With automatic initialization, the 3D AVM refines segmentation to accurately fit the real object boundary.

Because large lung tumors have HUs similar to the chest wall or mediastinum, the deformable model can easily leak to the large tumor region, chest wall or mediastinum which causes the under- or over-segmentation of the right lung. Fig. 5
                         demonstrates that the sparse shape representation can provide the ability to preserve the boundary information between large lung tumors and attached chest wall or mediastinum.

After showing the effectiveness of our proposed 3D AVM, we compared the quantitative performances of different approaches. Quantitative comparisons are shown in Table 1
                        , where the first row shows the results of AGC method; the second row is the proposed method without the SSC prior; and the third row is the final results from the proposed method with the SSC prior.

Quantitative results of AGC method achieved mean Dice similarity coefficient (DSC) of (0.52, 0.67) with 95% CI, mean accuracy (ACC) of (0.95, 0.96) with 95% CI, and mean relative error (RE) of (0.98, 1.97) with 95% CI. Quantitative results of our proposed segmentation method without the SSC achieved mean DSC of (0.70, 0.76) with 95% CI, mean accuracy of (0.95, 0.96) with 95% CI, and mean relative error of (0.60, 0.84) with 95% CI. Quantitative results with our proposed segmentation method with the SSC achieved mean Dice similarity coefficient of (0.72, 0.81) with 95% CI, mean accuracy of (0.97, 0.98) with 95% CI, and mean relative error of (0.46, 0.74) with 95% CI.

These data suggest that our proposed method with SSC prior produces the best performance with respect to the overlapping measurements, with the largest average Dice similarity coefficient, greatest accuracy, and smallest relative error. These comparison results indicate that the proposed method is more accurate and robust than the other approaches.


                        Fig. 5 shows that the differences are great between the proposed 3D AVM with or without the SSC prior, because the 3D AVM without the SSC prior does not provide the ability to preserve the boundary information between the large lung tumors and the attached chest wall or mediastinum which have the similar Hounsfield units (HU). Also, the more normal lung shapes in the training dataset the sparse shape composition should be more accurate to represent the target.


                        Fig. 6
                         shows the visual comparison of the surface distance errors for one subjects. First row shows the results between the proposed 3D AVM without the SSC prior and the ground truth. Second row shows the results between proposed 3D AVM with the SSC prior and the ground truth.


                        Fig. 7
                         shows the comparison of the Hausdorff distance between the proposed 3D AVM with SSC prior and the ground truth and that between the proposed method without the SSC prior. This figure shows that the proposed method with SSC prior has the best performance in terms of the surface distance errors.

@&#DISCUSSION@&#

We discuss the running time, parameter sensitivity, and limitations here:
                           
                              (1)
                              Most of the time with this method is spent on the nonrigid registration of the trained statistical atlas to the testing sample in the segmentation process (8min per subject). In total, AGC method needs about 15min in total, and the proposed method uses about 14min. Because the AGC is based solely on a graph cut algorithm, the cost of memory and time increase dramatically as the image size increases. In our experiments, to ensure isotropic energy measurement, the testing samples were re-sampled to 2mm×2mm×2mm resolution. The memory and time cost are relatively stable in the proposed method, since the 3D AVM has a fixed number of vertices independent to image size.

The parameters used in the methods, including nonrigid registration, 3D AVM and sparse shape constraint, were tuned experimentally for a single case and then applied for all the testing samples. Thus, the above comparison results indicate that our proposed approach has better and more robust performance with the potential to benefit many clinical analyses in the future.

Some segmentation errors in the proposed approach result from the inaccurate initialization from atlas-to-target registrations because of the respiratory motion of the lung in CT images. If the initial segmentation is too large, containing the liver region as well as the part of the mediastinum region inside its boundary, the AVM cannot shrink to the correct boundary. This is the main limitation of the proposed framework. In practice, this could be improved by using the dataset of 4D CT lung and also a more accurate nonrigid registration to align atlas to target sample (at the cost of more computation time).

@&#CONCLUSION@&#

In this paper we proposed a novel framework to segment compromised right lung in CT using a robust atlas-based AVM with SSC prior. The methods utilize symmetric diffeomorphic image registration to learn a statistical image atlas, and uses mesh quality-preserved 3D AVM to build robust shape atlases from the output of the SSC. The statistical image atlas is used to obtain a rough initialization, which is fed into the AVM for accurate segmentation of right lung. In addition to reliable initialization, the statistical atlas also contributes in a region potential energy and a constraining energy for AVM. The learned robust shape atlases can be used to generate a shape representation model (i.e. sparse shape composition or shape statistics) as a shape prior in the active volume model. Such a robust AVM enables efficient and accurate right lung segmentation. We extensively validated this method in clinical dataset. The results demonstrate that our approach is more robust to various anatomical shapes than other methods. It is a general framework which can be easily applied to segmentation other organs, e.g. left lung, liver, and heart.

@&#REFERENCES@&#


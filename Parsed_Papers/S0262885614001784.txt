@&#MAIN-TITLE@&#Discriminative and generative vocabulary tree: With application to vein image authentication and recognition

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A joint discriminative and generative vocabulary tree model


                        
                        
                           
                           A non-parametric image patch layout model and matching method


                        
                        
                           
                           Evaluation in vein authentication and recognition tasks with good performance


                        
                        
                           
                           Comprehensive in-depth discussion of the technique


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Vein identification

Vocabulary tree

@&#ABSTRACT@&#


               
               
                  Finger vein identification is a new biometric identification technology. While many existing works approach the problem by using shape matching which is the generative method, in this paper, we introduce a joint discriminative and generative algorithm for the task. Our method considers both the discriminative appearance of local image patches as well as their generative spatial layout. The method is based on the popular vocabulary tree model, where we utilize the hidden leaf node layer to calculate a generative confidence to weight the discriminative vote from the leaf node. The training process remains the same as building a conventional vocabulary tree, while the prediction process utilizes a proposed point set matching method to support non-parametric patch layout matching. In this way, the entire model retains the efficiency of the vocabulary tree model, which is much lighter than other similar models such as the constellation model (Fergus et al., 2003). The overall estimation follows the Bayesian theory. Experimental results show that our proposed joint model outperformed the purely generative or discriminative counterpart, and can offer competitive performance than existing methods for both the vein authentication and recognition tasks.
               
            

@&#INTRODUCTION@&#

Finger vein authentication and recognition are new biometric identification technologies based on the fact that different fingers have different vein patterns [17,31], as illustrated in Fig. 1
                     . Using vein image for recognition and authentication is non-intrusive and robust against finger surface condition [23]. The most attractive attribute is the strong immunity to forgery because the underline pattern is invisible inside the human body and only appears under the infrared light.

A critical step in finger vein recognition is to match the query vein pattern to a set of database fingers, each with a set of example vein images. Many existing methods work by converting the vein image into shape representation and then performing shape matching. For example, Miura et al. [18] extracted the finger vein from unclear image using line tracking. Song et al. [26] proposed a mean curvature method to represent the vein image as a geometric shape and find valley-like structures with negative mean curvatures for matching. In [13], finger vein patterns were extracted by combining morphological operation and maximum curvature points in image profiles. In [35], from each raw vein image a best bit map was extracted for vein verification and recognition. Since shape can also be represented by the geometrical layout of feature points, local feature matching based vein recognition methods were also attempted. For instance, Yu et al. [41] extracted minutiae features for geometric representation of the vein shape and used the Hausdorff distance algorithm to evaluate possible relative positions of minutiae features. Wang [32] applied the Hausdorff distance based scheme to analyze interesting points for vein recognition.

These above-mentioned works based on shape consistency can all be categorized as generative approaches, because the shape similarity tells how likely the query image can be observed given a hypothesized object class, i.e., given observation X, the posterior probability P
                     
                        o
                     (l|X) for class l is estimated using Bayes rules P
                     
                        o
                     (l|X)∝
                     P(X|l)P
                     
                        r
                     (l), where P(X|l) is measured using shape similarity. For vein recognition problem, these methods rely on the consistency of the vein shape. Although the assumption holds in general, segmentation errors may occur due to poor finger vein image quality and severely degrade the recognition accuracy. To overcome the problem, multi-biometric systems were reported. For example, Yang et al. [36] exploited finger vein features in local moments, topological structure and statistics for recognition. Yang et al. [40,39] used the multimodal biometric approach to fuse the binary vein patterns and the normalized dorsal textures into one feature image for personal authentication. Methods based on score-level fusion have also been reported, such of [14] where finger veins, fingerprints, and finger geometry features were individually recognized and then combined. The difficulty in the fusion based approach is how to select the optimal combination weight, especially when multiple modalities are considered, the feature space grows exponentially.

Another major category of approaches for visual recognition is the discriminative approaches where P
                     
                        o
                     (l|X) is estimated directly from a classification function l
                     =
                     f(X). In the general image classification domain, the popular Bag of Feature (BoF) approach [6,25] and the more recent sparse-coding based method [30] both belong to the category. For vein recognition, Xi et al. [34] extracted PHOG based local image pattern to construct the discriminative “hyperinformation” for vein identification. There is yet no conclusion whether one is better than the other. For instances, although the asymptotic error of discriminative methods is lower than for generative ones, in binary classification problems, generative approaches often have better performance for smaller number of training examples [19]. For this reason, both discriminative and generative approaches are popular in research literature.

The situation has attracted many studies on proposing hybrid methods to marry the benefits of both approaches. Some work by combining discriminative and generative information at the feature level. For example, Harr-like features can be used for training discriminative classifiers and also for reconstruction [29]. Tao et al. [27] showed that binary basis functions can be used in either discriminative or generative systems [11]. Fidler et al. [8] used LDA to construct discriminative basis which also contains sufficient reconstructive information. Grabner et al. [11] combined the errors from both discriminative and generative models to perform feature selection in the boosting framework. Yang et al. [38] applied the discriminative “soft-biometric” information in addition to the generative shape template for finger vein recognition.

Systems based on using both discriminative and generative models at the classifier level have also been introduced by adopting multi-stage approaches. For instances, Lin et al. [16] computed the distribution of positive samples in the first stage and a new distribution for the negative samples in the second stage by learning a linear projection. Roth et al. [24] proposed the conservative learning framework by first learning generative PCA models to then supervise the boosted discriminative models. Qin et al. [22] combined the decision from local SIFT feature, vein shape and orientation feature using weighted SUM and SVM fusion rules. Asaari et al. [2] considered the matching scores from both the Band Limited Phase Only Correlation and the Centroid Contour Distance for finger identification.

The situation has motivated us to also attempt the vein image recognition problem using joint discriminative and generative approaches. In this paper, we focused on performing recognition based on local image descriptors [6,25], because the appearance of these descriptors is discriminative, while their geometrical layout is generative. The scenario recalls the constellation model [33,7,12]. For example, Fergus et al. [7] modeled both appearance and shape in a scale-invariant space using respective Gaussian density function, and training for both Gaussian parameters was implemented using an iterative EM algorithm. Holub et al. [12] further extracted the discriminative Fisher score from the constellation model as image feature to train SVM with non-linear kernel.

Possibilities include not only the constellation model. In this paper, we extend the vocabulary tree model [20] to also consider the geometrical layout of local image patches, making the algorithm jointly discriminative and generative. The reason for choosing the vocabulary tree model is due to its high efficiency in both training and recognition, and its wide adoption in large scale visual recognition problems. In this paper, by introducing a slightly different data structure and a novel prediction algorithm that turns the image-wise geometrical alignment error into per-leaf node estimation weight, we present a joint discriminative and generative vocabulary tree model for finger vein analysis. The introduced tree model presents several advantages. First, the learning process remains the same as building a conventional vocabulary tree. Second, in the prediction stage, a novel point set matching algorithm is designed for non-parametric matching of patch layout to retain the high efficiency of tree model; and third, the discriminative and generative information collaborate at the hidden leaf node layer under the Bayesian framework, and no heuristic rules are needed for fusion. Besides, we have also shown that, the proposed joint model is a generalization of tree model, where its discriminative end produces the vocabulary tree, and its generative end reduces to purely shape matching. In addition, as demonstrated by our comprehensive experimental evaluation, our proposed method obtained satisfactory accuracy on both the vein authentication and recognition problems.

The vocabulary tree model is widely adopted for object recognition with local image descriptors, due to its efficiency and scalability. The advantages allow its performance to be further boosted by simply increasing the training sample size [20]. On the other side, in applications where it is difficult to provide large number of training samples, such as biometric identification or face recognition, other types of information should be explored. In this section, we introduce a method to enable a tree based model to consider both discriminative descriptor appearance and their generative geometrical layout. This is useful if the descriptors are noisy, or when the training data is insufficient.

A typical vocabulary tree can be built in two steps: First a construction step that builds a tree with all descriptors from the training images; and second a registration step that creates a record-level Inverted Index (II) for each leaf node. The II records attributes of image class with at least one descriptor that reaches the leaf node. The query process works by first quantizing each descriptor to the closest leaf node. Assuming the number of leaf node is N, given the set of M descriptors X
                        =[x1;x2;…;x
                           M
                        ] from the query image, the tree predicts posterior P
                        
                           o
                        (l|X) by factorizing it into per-leaf node estimation, i.e.
                           
                              (1)
                              
                                 
                                    P
                                    o
                                 
                                 
                                    
                                       
                                          l
                                       
                                       X
                                    
                                 
                                 =
                                 
                                    
                                       ∑
                                       i
                                       N
                                    
                                    
                                       P
                                       
                                          
                                             
                                                l
                                             
                                             
                                                n
                                                i
                                             
                                             ,
                                             X
                                          
                                       
                                       P
                                       
                                          
                                             
                                                
                                                   n
                                                   i
                                                
                                             
                                             X
                                          
                                       
                                       ,
                                    
                                 
                              
                           
                        where ni
                         represents the ith leaf node. P(n
                        
                           i
                        |X) denotes the probability to observe node ni
                         given X, and
                           
                              (2)
                              
                                 P
                                 
                                    
                                       
                                          
                                             n
                                             i
                                          
                                       
                                       X
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             X
                                             
                                             has
                                             
                                             descriptor
                                             
                                             that
                                             
                                             reaches
                                             
                                             
                                                n
                                                i
                                             
                                             
                                                
                                                   find
                                                   
                                                   
                                                      n
                                                      i
                                                   
                                                   
                                                   a
                                                   s
                                                   
                                                   nearest
                                                   
                                                   neighbor
                                                
                                             
                                             
                                             ,
                                          
                                       
                                       
                                          
                                             0
                                          
                                          
                                             otherwise
                                             
                                             .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     


                        P(l|n
                        
                           i
                        ,
                        X) is the vote from leaf ni
                        . Simply letting P(l|n
                        
                           i
                        ,
                        X)=
                        M
                        
                           i
                        /M, where Mi
                         is the number of descriptors that reaches leaf ni
                        , generates a strict histogram. [20] instead applied the TF–IDF scheme to calculate P(l|n
                        
                           i
                        ,
                        X), where each leaf node i has a “path vector” 
                           d
                           li
                         for class l. Given v the path vector from the query image,
                           
                              (3)
                              
                                 P
                                 
                                    
                                       
                                          l
                                       
                                       
                                          n
                                          i
                                       
                                       ,
                                       X
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      v
                                                      
                                                         v
                                                      
                                                   
                                                   −
                                                   
                                                      
                                                         d
                                                         
                                                            l
                                                            i
                                                         
                                                      
                                                      
                                                         
                                                            d
                                                            
                                                               l
                                                               i
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          
                                             
                                             l
                                             
                                             in
                                             
                                             the
                                             
                                             I
                                             I
                                             
                                             of
                                             
                                             
                                                n
                                                i
                                             
                                          
                                       
                                       
                                          
                                             0
                                             
                                          
                                          
                                             otherwise
                                             
                                             .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

According to Eq. (1), the voting process with a hidden leaf node layer is discriminative, and its graphical model is illustrated in Fig. 3a.

Modeling the geometrical layout of local descriptors [25] is another popular line of local descriptor based object recognition approaches. The transformations f(⋅) between the query and the training images are firstly estimated, and then the one that leads to minimal alignment error signifies the detected/recognized object. This process is generative because the alignment error is used to obtain the likelihood P(X|l) such that
                           
                              (4)
                              
                                 
                                    P
                                    o
                                 
                                 
                                    
                                       
                                          l
                                       
                                       X
                                    
                                 
                                 =
                                 
                                    
                                       P
                                       
                                          
                                             
                                                X
                                             
                                             l
                                          
                                       
                                       
                                          P
                                          r
                                       
                                       
                                          l
                                       
                                    
                                    
                                       P
                                       
                                          X
                                       
                                    
                                 
                                 =
                                 
                                    
                                       P
                                       
                                          
                                             
                                                X
                                             
                                             l
                                          
                                       
                                       
                                          P
                                          r
                                       
                                       
                                          l
                                       
                                    
                                    
                                       
                                          ∑
                                          k
                                       
                                       
                                          P
                                          
                                             
                                                
                                                   X
                                                
                                                k
                                             
                                          
                                          
                                             P
                                             r
                                          
                                          
                                             k
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where P
                        
                           r
                        (l) is the prior of label l. Pr(X|l) can be derived from the alignment error, e.g. assuming an a prior Gaussian distribution of descriptor location as
                           
                              (5)
                              
                                 P
                                 
                                    
                                       
                                          X
                                       
                                       l
                                    
                                 
                                 =
                                 exp
                                 
                                    
                                       
                                          
                                             
                                                
                                                   f
                                                   
                                                      P
                                                   
                                                   −
                                                   
                                                      Q
                                                      l
                                                   
                                                
                                             
                                             F
                                             2
                                          
                                       
                                       /
                                       σ
                                    
                                 
                                 
                                 ,
                              
                           
                        where {P,
                        Q
                        
                           l
                        } are the matched pairs of descriptor locations between the query and database image class l. Note that usually we have multiple images {Q
                        
                           lj
                        },
                        j
                        =1,…,
                        K
                        
                           l
                         from the same class l. We simply take the maximal likelihood from all images of a class as the final likelihood score.

It is important to have an efficient way to obtain the set of matched descriptor pairs between the query and the database images to solve f(⋅). This can be well supported by a tree model if each leaf node keeps an image-level II in addition to the record-level II as in the standard vocabulary tree. The image-level II records not only the class label, it also records from which database image each descriptor is from, as well as its 2D location in the original vein image. In this way, during the query process, when a descriptor x finds the nearest leaf node, it also finds the locations of matched image patches from the database at no additional search cost. In our model, the image-level II at each leaf node stores the following information for each image descriptor: The class label l, the database image index j, path vector dl
                        , and the 2D locations q
                        
                           1
                        
                        
                           1
                           In practice, if multiple descriptors from the same image get quantized to leaf node j, we will keep one of them. Also, if multiple descriptors from different images of the same Id get quantized to leaf node j, we will record the image Id in addition to the finger Id, as our spatial layout matching is per-image based (Subsection 2.2).
                        . As illustrated from Fig. 2
                        , our constructed tree model contains information to fully resemble the layout of image patches.

Since the same tree model can implement either discriminative or generative classifier for vein recognition, it is interesting to examine if the tree can be further extended into a joint discriminative and generative model to improve performance. In this section we introduce a method to combine the two models under the Bayesian theory.

In either the vocabulary tree or the generative tree-based classifier, the importance of the hidden leaf node layer has not been fully explored: In the generative tree-based classifier (Subsection 2.2), the leaf node layer does not contribute because the alignment is calculated at the image level; in the discriminative vocabulary tree (Subsection 2.1), the hidden leaf node layer is only related to a binary value for P(n
                        
                           i
                        |X). In fact, the leaf node layer is a bridge between the discriminative and generative models, because the discriminative estimation from a leaf node that has been identified as an outlier in the generative alignment process should be lower-weighted. This provides the key idea in presenting our joint discriminative and generative tree model.

To elaborate, to utilize P(n
                        
                           i
                        |X) to evaluate the reliability of the estimation from leaf ni
                        , the global geometrical alignment error should be decomposed into per-leaf node error. Hence, define
                           
                              (6)
                              
                                 
                                    P
                                    r
                                 
                                 
                                    
                                       
                                          
                                             n
                                             i
                                          
                                       
                                       l
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             1
                                          
                                          
                                             if
                                             
                                             l
                                             
                                             is
                                             
                                             in
                                             
                                             the
                                             
                                             image
                                             ‐
                                             level
                                             
                                             I
                                             I
                                             
                                             of
                                             
                                             
                                                n
                                                i
                                             
                                             
                                             ,
                                          
                                       
                                       
                                          
                                             0
                                          
                                          
                                             otherwise
                                             
                                             .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Revisiting Eq. (1), assuming the prior distribution of each leaf node P
                        
                           r
                        (n
                        
                           i
                        ) and each class P
                        
                           r
                        (l) to be uniform, then
                           
                              (7)
                              
                                 
                                    
                                       
                                          P
                                          
                                             
                                                
                                                   
                                                      n
                                                      i
                                                   
                                                
                                                X
                                             
                                          
                                          =
                                          
                                             
                                                
                                                   ∑
                                                   k
                                                
                                                
                                                   P
                                                   
                                                      
                                                         
                                                            X
                                                         
                                                         k
                                                         ,
                                                         
                                                            n
                                                            i
                                                         
                                                      
                                                   
                                                   
                                                      P
                                                      r
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               n
                                                               i
                                                            
                                                         
                                                         k
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   ∑
                                                   j
                                                   N
                                                
                                                
                                                   
                                                      
                                                         ∑
                                                         k
                                                      
                                                      
                                                         P
                                                         
                                                            
                                                               
                                                                  X
                                                               
                                                               k
                                                               ,
                                                               
                                                                  n
                                                                  j
                                                               
                                                            
                                                         
                                                         
                                                            P
                                                            r
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                                     n
                                                                     j
                                                                  
                                                               
                                                               k
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                          =
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      k
                                                      ∈
                                                      N
                                                      
                                                         i
                                                      
                                                   
                                                
                                                
                                                   P
                                                   
                                                      
                                                         
                                                            X
                                                         
                                                         k
                                                         ,
                                                         
                                                            n
                                                            i
                                                         
                                                      
                                                   
                                                
                                             
                                             
                                                
                                                   ∑
                                                   j
                                                   N
                                                
                                                
                                                   
                                                      
                                                         ∑
                                                         
                                                            k
                                                            ∈
                                                            N
                                                            
                                                               j
                                                            
                                                         
                                                      
                                                      
                                                         P
                                                         
                                                            
                                                               
                                                                  X
                                                               
                                                               k
                                                               ,
                                                               
                                                                  n
                                                                  j
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where 
                           N
                           
                              i
                           
                         denotes the set of class labels that exist in the II of leaf node ni
                        .

Taking Eqs. (6) and (7) into Eq. (1), we have
                           
                              (8)
                              
                                 
                                    P
                                    o
                                 
                                 
                                    
                                       
                                          l
                                       
                                       X
                                    
                                 
                                 =
                                 
                                    1
                                    C
                                 
                                 
                                    
                                       ∑
                                       i
                                       N
                                    
                                    
                                       
                                          
                                             
                                                P
                                                
                                                   
                                                      
                                                         l
                                                      
                                                      
                                                         n
                                                         i
                                                      
                                                      ,
                                                      X
                                                   
                                                
                                             
                                             ︸
                                          
                                          Discriminative
                                       
                                       
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      k
                                                      ∈
                                                      N
                                                      
                                                         i
                                                      
                                                   
                                                
                                                
                                                   P
                                                   
                                                      
                                                         
                                                            X
                                                         
                                                         k
                                                         ,
                                                         
                                                            n
                                                            i
                                                         
                                                      
                                                   
                                                
                                             
                                             ︸
                                          
                                          Generative
                                       
                                       
                                       ,
                                    
                                 
                              
                           
                        where 
                           C
                           =
                           
                              
                                 ∑
                                 j
                                 N
                              
                              
                                 
                                    
                                       ∑
                                       
                                          k
                                          ∈
                                          N
                                          
                                             j
                                          
                                       
                                    
                                    
                                       P
                                       
                                          
                                             
                                                X
                                             
                                             k
                                             ,
                                             
                                                n
                                                j
                                             
                                          
                                       
                                    
                                 
                              
                           
                         is a constant to normalize Eq. (8) into a probability.

Note that the term 
                           k
                           ∈
                           N
                           
                              i
                           
                         shows that, although we are to estimate the probability of image label l, the layout can also be generated through other image labels in the II of ni
                        . Intuitively one should expect the layout to be generated from the stated image label l only, and hence if other labels are ignored, the following simpler equation can be obtained:
                           
                              (9)
                              
                                 
                                    P
                                    o
                                 
                                 
                                    
                                       
                                          l
                                       
                                       X
                                    
                                 
                                 ≃
                                 
                                    
                                       ∑
                                       i
                                       N
                                    
                                    
                                       
                                          
                                             
                                                P
                                                
                                                   
                                                      
                                                         l
                                                      
                                                      
                                                         n
                                                         i
                                                      
                                                      ,
                                                      X
                                                   
                                                
                                             
                                             ︸
                                          
                                          Discriminative
                                       
                                       
                                          
                                             
                                                P
                                                
                                                   
                                                      
                                                         X
                                                      
                                                      l
                                                      ,
                                                      
                                                         n
                                                         i
                                                      
                                                   
                                                
                                                /
                                                P
                                                
                                                   
                                                      
                                                         X
                                                      
                                                      l
                                                   
                                                
                                             
                                             ︸
                                          
                                          Generative
                                       
                                       
                                       .
                                    
                                 
                              
                           
                        
                     


                        P(X|l,
                        n
                        
                           i
                        ) can be calculated by considering only the alignment error of descriptors quantized to leaf node ni
                        . Based on Eq. (5),
                           
                              (10)
                              
                                 P
                                 
                                    
                                       
                                          X
                                       
                                       l
                                       ,
                                       
                                          n
                                          i
                                       
                                    
                                 
                                 /
                                 P
                                 
                                    
                                       
                                          X
                                       
                                       l
                                    
                                 
                                 =
                                 exp
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      f
                                                      
                                                         P
                                                      
                                                      −
                                                      
                                                         Q
                                                         l
                                                      
                                                   
                                                
                                                F
                                                2
                                             
                                             −
                                             
                                                
                                                   
                                                      f
                                                      
                                                         
                                                            P
                                                            i
                                                         
                                                      
                                                      −
                                                      
                                                         Q
                                                         
                                                            l
                                                            i
                                                         
                                                      
                                                   
                                                
                                                F
                                                2
                                             
                                          
                                       
                                       /
                                       σ
                                    
                                 
                                 
                                 ,
                              
                           
                        where {P,
                        Q
                        
                           l
                        } and {P
                        
                           i
                        ,
                        Q
                        
                           li
                        } are the matched pairs of all descriptors and those at leaf i respectively.

Eqs. (8) and (9) are jointly discriminative and generative, because P(l|n
                        
                           i
                        ,
                        X) is a discriminative score from Eq. (3), and P(n
                        
                           i
                        |X) is the generative alignment error contributed by leaf ni
                        . The underlining intuition is that, Eq. (3) applies the TF–IDF scheme to obtain a vote from leaf ni
                        , and Eq. (10) further provides a confidence for this vote. For instance, if any descriptor is detected as an outlier, the estimation by Eq. (3) will be automatically lower-weighted by Eq. (10).

Now the original Eq. (1) is generalized to a joint discriminative and generative approach, and we can flexibly switch between the discriminative approach, generative approach, and joint approach by the following strategies:
                           
                              
                                 Discriminative approach By setting σ to a sufficiently large number, P(n
                                 
                                    i
                                 |X)→1, and Eq. (10) reduces to Eq. (2) which makes Eq. (8) purely discriminative.Generative approach By setting P(l|n
                                 
                                    i
                                 ,
                                 X)=
                                 M
                                 
                                    i
                                 /M instead of Eq. (3), which is equivalent to giving each descriptor a constant weight 1/M, Eq. (8) reduces to Eq. (4) which is purely generative.Discriminative and generative approach By applying Eqs. (3) and (10) with suitable σ, Eq. (8) is a discriminative approach with generative weight.

The wide adoption of the tree based fast search framework is largely due to its capacity at indexing the search database to allow highly efficient pattern search. By making use of such advantage, the vocabulary tree model presents a discriminative classification method, and in this paper, we further extend the classification process to be jointly discriminative and generative. At the same time, the tree construction process remains the same as constructing a conventional tree, and hence several existing tree construction algorithms can be applied. Below in Algorithm 2.1 we illustrate a K-mean tree construction process to obtain the joint discriminative and generative tree model in this paper. In fact, since the requirement to generate the generative weight is only to store the image-level II, in practice, many other nearest neighboring search algorithms can also be applied to index the database. Fig. 4
                         illustrates the structure of a constructed tree, which stores both the discriminative appearance as well as the spatial layout as that logically presented in Fig. 2.

@&#DISCUSSION@&#

Surprisingly, although they originated from different motivations, Eq. (8) has a similar form as the constellation model [33,7]. In this section, we discuss the connection and difference between our method and the constellation model.
                           Algorithm 2.1
                           Construction of the joint discriminative and generative tree.


                              
                                 
                                    
                                 
                              
                           

The constellation model calculates [7]
                        
                           
                              (11)
                              
                                 
                                    
                                       
                                          P
                                          
                                             
                                                
                                                   P
                                                   S
                                                   A
                                                
                                                θ
                                             
                                          
                                          =
                                          
                                             
                                                ∑
                                                
                                                   h
                                                   ∈
                                                   H
                                                
                                             
                                             
                                                P
                                                
                                                   
                                                      
                                                         X
                                                         S
                                                         A
                                                         h
                                                      
                                                      θ
                                                   
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                          =
                                          
                                             
                                                
                                                   ∑
                                                   
                                                      h
                                                      ∈
                                                      H
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            P
                                                            
                                                               
                                                                  
                                                                     A
                                                                  
                                                                  X
                                                                  ,
                                                                  S
                                                                  ,
                                                                  h
                                                                  ,
                                                                  θ
                                                               
                                                            
                                                         
                                                         ︸
                                                      
                                                      Appearance
                                                   
                                                
                                                
                                                   
                                                      
                                                         P
                                                         
                                                            
                                                               
                                                                  X
                                                               
                                                               S
                                                               ,
                                                               h
                                                               ,
                                                               θ
                                                            
                                                         
                                                      
                                                      ︸
                                                   
                                                   Shape
                                                
                                                
                                                   
                                                      
                                                         P
                                                         
                                                            
                                                               
                                                                  S
                                                               
                                                               h
                                                               ,
                                                               θ
                                                            
                                                         
                                                      
                                                      ︸
                                                   
                                                   
                                                      R
                                                      e
                                                      l
                                                      .
                                                      
                                                      Scale
                                                   
                                                
                                                
                                                   
                                                      
                                                         P
                                                         
                                                            
                                                               
                                                                  h
                                                               
                                                               θ
                                                            
                                                         
                                                      
                                                      ︸
                                                   
                                                   Other
                                                
                                                
                                                ,
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where P, A and S are location, appearance and scale respectively, and θ is the model parameter.

In Eq. (11), h is a latent object part indicator which plays a similar role as the leaf node index in our tree model. Hence the appearance in Eq. (11) gives similarly a local estimation of the object class as the discriminative term P(l|n
                        
                           i
                        ,
                        X) in Eq. (9). The shape and scale in Eq. (11) together obtain a multiplicative weight for calculating the overall probability, which is similar to the generative layout term P(X|l,
                        n
                        
                           i
                        )/P(X|l) in Eq. (9). P(h|θ) acts similarly as the prior distribution of the leaf node in our model which we simply assumed to be uniform distribution.

The differences between our model and the constellation model are: First, Eq. (11) assumed a multivariate Gaussian distribution for all appearance, shape and scale models, which makes the overall objective function non-convex, and an iterative algorithm such as EM is needed for training. Our model is implemented entirely on a tree, hence both training and prediction require light computation; second, although the leaf node layer plays a similar role as the object part indicator h in Eq. (11), it's dimension doesn't need to be pre-assumed. While objects with 6–8 defined parts are common, the number of leaf nodes in our model easily exceeds 10,000 in many problems; and thirdly, in our model we do not require the shape (and scale) information to follow a Gaussian distribution, and hence the shape model doesn't need to be trained. Instead, we resort to a non-parametric approach as presented in the next section.

In our joint model, the generative term is obtained through non-parametric matching of patch layout between the query and training images stored in the tree. This task is related to classical point set matching problem but differs in that, since candidate matching locations are returned from the tree, multiple query patches may get quantized to leaf node containing multiple patches from the same training image, which therefore forms a many-to-many matching problem, not to mention the existence of outliers. Selecting only the closest patch for each query descriptor may falsely reject inliers. Alternatively, one can regard such many-to-many matching to multiple one-to-one matching at the cost of additional computation for outlier detection, or by imposing strict limitations on the transformation space. For instance, Kim and Grauman introduced the “region-to-image” matching [15] where descriptors from image segment are matched to database image using Dynamic Programming, and no rotation and only small amount of scaling were allowed. In this section, to be more general, we assume the 2D similitude transform to allow scaling, rotation and translation transforms. We introduce a novel algorithm to solve each of the primitive transform separately to allow for efficient computation in quadratic time.

To depict, given a set of M image patches with 2D locations P
                     =[p
                     1;
                     p
                     2;…;
                     p
                     
                        M
                     ]∈
                     
                        R
                     
                     2, the tree finds the set of matching candidates for each image label l denoted as Q
                     
                        l
                     
                     =[{q}1;{q}2;…;{q}
                        M
                     ]
                        l
                      where each {q}
                        li
                      can be a set of points. For simplicity, the subscript l is omitted. Similitude transform requires q
                     =
                     αxR
                     +
                     t where α is a scalar representing scaling, t is the translation vector, and 
                        R
                        =
                        
                           
                              
                                 
                                    cos
                                    
                                       θ
                                    
                                 
                                 
                                    sin
                                    
                                       θ
                                    
                                 
                              
                              
                                 
                                    −
                                    sin
                                    
                                       θ
                                    
                                 
                                 
                                    cos
                                    
                                       θ
                                    
                                 
                              
                           
                        
                      is the rotation matrix, with θ being the rotation angle. In order to handle multiple matching candidates and detect outliers in our problem, the next subsections introduce a novel matching algorithm.

The key idea in our matching algorithm is based on the fact that, the scaling and the rotation can be calculated separately from the translation, because the former two are invariant to the origin. Specifically, α and R (or θ) can be solved by
                           
                              (12)
                              
                                 
                                    
                                       
                                          
                                             R
                                             *
                                          
                                          ,
                                          
                                             α
                                             *
                                          
                                          =
                                          
                                             
                                                argmin
                                                
                                                   R
                                                   ,
                                                   α
                                                
                                             
                                          
                                          
                                             
                                                
                                                   α
                                                   
                                                      P
                                                      ¯
                                                   
                                                   R
                                                   −
                                                   
                                                      Q
                                                      ¯
                                                   
                                                
                                             
                                             F
                                             2
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                          s
                                          .
                                          t
                                          .
                                          
                                          R
                                          
                                             R
                                             ⊤
                                          
                                          =
                                          I
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        where 
                           
                              P
                              ¯
                           
                         is the centralized version of query P, and 
                           
                              Q
                              ¯
                           
                         is the corresponding centralized matching point. As an Weighted Orthogonal Procrustes problem [28,5],
                           
                              (13)
                              
                                 
                                    
                                       
                                          
                                             R
                                             *
                                          
                                          =
                                          
                                             
                                                argmax
                                                R
                                             
                                          
                                          T
                                          r
                                          
                                             
                                                
                                                   P
                                                   ¯
                                                
                                                R
                                                
                                                   
                                                      Q
                                                      ¯
                                                   
                                                   ⊤
                                                
                                             
                                          
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                          s
                                          .
                                          t
                                          .
                                          
                                          R
                                          
                                             R
                                             ⊤
                                          
                                          =
                                          I
                                          
                                          ,
                                       
                                    
                                 
                              
                           
                        which can be solved using Orthogonal Approximation [10]
                        
                           
                              (14)
                              
                                 
                                    R
                                    *
                                 
                                 =
                                 U
                                 
                                    S
                                    ˜
                                 
                                 
                                    V
                                    ⊤
                                 
                                 
                                 ,
                              
                           
                        where {U,
                        S,
                        V} are the Singular Vector Decomposition (SVD) of 
                           
                              
                                 P
                                 ¯
                              
                              ⊤
                           
                           
                              Q
                              ¯
                           
                        , and 
                           
                              S
                              ˜
                           
                           =
                           
                              
                                 
                                    
                                       1
                                    
                                    
                                       0
                                    
                                 
                                 
                                    
                                       0
                                    
                                    
                                       det
                                       
                                          
                                             U
                                             
                                                V
                                                ⊤
                                             
                                          
                                       
                                    
                                 
                              
                           
                        . Finally
                           
                              (15)
                              
                                 
                                    
                                       
                                          
                                             α
                                             *
                                          
                                          
                                          =
                                          mean
                                          
                                             
                                                
                                                   Q
                                                   ¯
                                                
                                                /
                                                
                                                   P
                                                   ¯
                                                
                                                
                                                   R
                                                   *
                                                
                                             
                                          
                                          
                                          ,
                                       
                                    
                                    
                                       
                                          
                                             θ
                                             *
                                          
                                          
                                          =
                                          arctan
                                          
                                             
                                                
                                                   R
                                                   *
                                                
                                                
                                                   1
                                                   1
                                                
                                                /
                                                
                                                   R
                                                   *
                                                
                                                
                                                   1
                                                   2
                                                
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     

Eq. (15) shows that, given two matched pairs, the optimal scaling and rotation can be solved in constant time. Hence it is possible to find the dominate scaling and rotation from noisy candidates using Hough transform [4]. To depict, defining a 2D parameter space of scale α and rotation angle θ, we sample multiple subsets, each with two matching pairs between P and Q, to accumulate score for a {α,
                        θ} combination. For n subsamples, the complexity is 
                           O
                           
                              
                                 n
                                 2
                              
                           
                        . Fig. 5
                         illustrated a parameter space when the inlier/outlier ration is 1:50. The maxima are highlighted in Fig. 5(b).

Next to detect outliers and calculate translation, we rely again on the property that scaling and rotation are invariant to origin, such that translation with respect to arbitrary origin should project inliers to locations with constant offset from the matched targets, while outliers should have inconstant offsets. With such property, the translation can be calculated in constant time.

Our idea is based on two additional facts: First, if the arbitrary origin is set to one of the inliers, then the constant offset becomes zero because scaling and rotation transformation with respect to this point would project all the inliers exactly onto the matched target; second, the maxima available in the scaling/rotation parameter space (Subsection 3.1) guarantee the existence of at least one “inlier”.

Denoting the inlier as p
                        0 and the corresponding target as q
                        0, the optimal transformation should project each query point p
                        
                           i
                         to
                           
                              (16)
                              
                                 
                                    
                                       p
                                       ˜
                                    
                                    i
                                 
                                 =
                                 α
                                 
                                    
                                       
                                          p
                                          i
                                       
                                       −
                                       
                                          p
                                          0
                                       
                                    
                                 
                                 ∗
                                 R
                                 +
                                 
                                    q
                                    0
                                 
                                 .
                              
                           
                        
                     

Now, outliers can be detected by simply thresholding the alignment error between 
                           
                              
                                 p
                                 ˜
                              
                              i
                           
                         and q
                        
                           i
                        . After all the inliers P* and Q* are detected, the optimal translation vector can be calculated as
                           
                              (17)
                              
                                 
                                    t
                                    *
                                 
                                 =
                                 
                                    
                                       q
                                       ¯
                                    
                                    *
                                 
                                 −
                                 
                                    α
                                    *
                                 
                                 
                                    
                                       p
                                       ¯
                                    
                                    *
                                 
                                 
                                    R
                                    *
                                 
                                 
                                 ,
                              
                           
                        where 
                           
                              
                                 p
                                 ¯
                              
                              *
                           
                         and 
                           
                              
                                 q
                                 ¯
                              
                              *
                           
                         are the centers of P* and Q* respectively.

The strategy can also apply for the case where p
                        
                           i
                         has multi-candidate targets {q}
                           i
                        . We simply threshold the distance between p
                        
                           proj
                         and the closest q
                        
                           i
                        .

In the vein identification application, besides one single optimal transformation between point sets, there are chances that additional transformations exist in the “outliers”, which causes the multiple mode matching problem (Fig. 6
                        ). This happens very often for the grip-type vein authentication process where, for example, the vein image sensor is installed on the car door handle, and the user accidentally put two fingers on the sensor. The local patches from both fingers would form two transformations. Both these transforms should be detected to identify a more complete set of “inlier”, and hence to improve performance.

Identifying transformation with multi-mode can be well achieved in the scaling/rotation parameter space (Subsection 3.1), because each local maximum corresponds to one mode, and the value of the maxima tells the lower bound of the number of matched pairs that can be covered by the transformation. In this way, a user can specify the minimal number of points to form a transform, such as 5 points to define a conic, or 3 points to define 2D affine. By iterating local maxima that satisfy the criteria, all modes that exist in the point set can be identified. The complexity to calculate k transformations is simply 
                           O
                           
                              
                                 
                                    n
                                    2
                                 
                                 +
                                 k
                              
                           
                         because the scaling/rotation space doesn't need to be reconstructed (Fig. 7
                        ).

@&#DISCUSSION@&#

We compared the proposed point set matching method with two widely used methods that are good against outliers, the RANSAC method [1] and the LMedS method [42]
                        
                           2
                        
                        
                           2
                           Implementation from the Matlab computer vision system toolbox.
                        . The query and matching point pairs are synthesized with different inlier/outlier ratios. Each different setting was repeated 10 times. The performance was evaluated using inlier detection accuracy. As can be seen from Fig. 8(a), the accuracy of RANSAC started to decrease when the outlier/inlier ratio is greater than 10, and LMedS even started to approach zero accuracy. Our proposed method is very robust against outliers and could achieve over 80% accuracy even when the ratio increased to over 200.

To examine the proposed point set matching algorithm for the multiple candidate case (Subsection 2.3), we further tested the method with respect to different numbers of candidates for each query point. Of the many candidates for each query descriptor, there was no more than one inlier, while the rest were all outliers. The average outlier/inlier ratio was 200. As can be seen from Fig. 8(b), the proposed matching method handled the multi-candidate case well. Almost all inliers could still be detected even with 32 candidates per inlier.

Meanwhile, although seldom observed in real-world data, it is possible that there exist several groups of point pairs that share the same scaling and rotation transform but with different translations, such that they contribute to the same parameter space location in Subsection 3.1. An iterative process can be applied to solve the problem, where in each iteration, the scaling/rotation parameter space is re-constructed, and then the detected inliers are removed before the next iteration. The process stops until no further local maxima exist in the parameter space.

In finger vein analysis, both the discriminative local image patches and their geometrical composition are of interest. Hence the task is very suitable for evaluating our proposed method. In this section, we report experimental results based on different data conditions. In all the experiments, the processing modules were implemented in c++ and run on a Dell OptiPlex 780 computer with a 2.9GHz CPU and 2GB memory.

There are not many common benchmark datasets due to privacy reasons, but in general larger sets are more difficult [36]. Our dataset 1 contains 232 fingers from 116 subjects, each with 10 vein images collected by a 280×400 ccd image sensor. The database, as well as the database used in the following section, was collected through a three month span to remove any potential bias towards the condition of each individual subject in a short time period. Although no limitation was imposed as which finger should be used, we observed that the participants applied only the index finger, middle finger and ring finger during data collection, while the thumb or baby finger did not appear in the dataset.

To apply our method for vein image authentication, we simply derive a confidence score from the histogram from the tree, by calculating conf
                        =
                        P
                        
                           o
                        (l*|X)−
                        P
                        
                           o
                        (l
                        2nd
                        |X), i.e. the difference between the top-most bin and second-best bin values. We applied a Harris–Laplacian feature point detector and adopted a Sift descriptor as local image descriptor. In this experiment, we treat 232 fingers as 232 different Ids. Table 1
                         lists the results with 100 fingers registered and accordingly the rest as unauthorized. Each registered user contributed 5 images for training. The constructed tree has branches of 2 to 22 levels, with 13,242 leaf nodes in total. As can be seen from Table 1, our method achieved the smallest error rate in most benchmark works except [39]. Note that [39] takes multi-modality input of both vein image and dorsal texture for finger authentication. When only vein image is applied, the EER score of [39] is 2.14% which is comparable to our score. [2] also utilized score-level fusion of both vein image and geometry recognition results.

In more practical applications, usually only a small number of users are authorized compared to the entire set of users. This makes the number of registered users and unregistered users highly unbalanced. To evaluate our system for such scenario, we further tested dataset 1 with only 50, 20, 10 and even 5 registered users, while all the rest are unregistered users that should get unauthenticated. We compared our results between pure discriminative or generative approaches. As can be seen from the results in Fig. 9
                        , the proposed joint approach achieved the best performance in most cases.

Another practical issue is that the authentication sensor may be smaller than the sensor used to collect training data. We collected vein image dataset 2 where the same 280×400 ccd image sensor was used to collect training images from 21 subjects, each contributed images from two neighboring fingers. Again the 42 fingers were treated as 42 different Ids. The testing set was collected using a smaller 200×200 sensor, and the subjects were not required to center their fingers on the small sensor. Hence the collected testing image comes from part of one entire finger, and accordingly it will only be partially matched to training images at one of the 9 different sub-regions, from top-left (1) to bottom-right (9), as illustrated in Fig. 10
                        . In the experiment, 10 users were registered, and results are reported based on 1–5 training image per registered user. When there were 5 vein images registered per user, the constructed tree has branches of 2 to 18 levels, with 5198 leaf nodes in total. The performance of sub-regions 4, 5 and 6 is relatively higher because from these sub-regions, the testing image has more descriptors that could get matched. According to Fig. 10, our proposed joint model achieved the best performance over the pure discriminative or generative approach.

The third practical issue is that, the user may occasionally put two fingers on the sensor, as we explained in Subsection 4.3. To test our algorithm for this issue, we collected vein image dataset 3 where the same 21 subjects in dataset 2 were asked to put two fingers on the small authentication sensor each time. The collected vein image is illustrated in Fig. 6. In this way, every testing image should be matched to two images in the training set of dataset 2. Without multi-mode support, the ERR for the set was 0.88%, while after we allowed two modes to be identified, ERR reduced to 0.05%.

The vein image recognition application further identifies the Id of each authorized finger. This is similar to image classification, and the recognized Id corresponds to the one with the maximal posterior estimated by the tree. Table 2
                      compares our proposed method with the pure discriminative or generative approach. We performed the experiments respectively using dataset 1 and the dataset from [35,2] with 1–5 images for training, and the rest for testing. Table 2 lists the average recognition accuracy. With 5 vein images registered per user, the constructed tree has branches of 2 to 24 levels, with 14,337 leaf nodes in total. We have also listed in Table 2 the results based on the dataset from [39] which has 1–3 images per Id for training. It is observed that the discriminative method outperformed the generative method when more than 3 training images were provided, while the generative method works better with less training samples. Our proposed method combines the advantages of both method and hence led to the best performance in both cases. At the same time, it can be noticed from Table 2 that, our proposed approach performs best when there are at least two training images provided per finger Id. This is due to the limitation that with only one image, the number of extracted local descriptor is not sufficient. Although applying pre-processing to enhance the vein image quality is helpful, obtaining optimal pre-processing performance requires careful parameter tuning.

@&#DISCUSSION@&#

Two additional aspects of the above experiment process are further investigated in this section, specifically the effect of the pre-processing step and the type of local descriptors.

As can be seen from Fig. 1, the raw vein image is of poor quality for feature point detection and local descriptor extraction. Hence preprocessing is required to firstly enhance the vein image before recognition. In this subsection, we examine several existing techniques for vein image enhancement, including Histogram Equalization, median filtering, Local Histogram Equalization (LHE) [43], Adaptive Histogram Equalization (AHE) [21], Automatic Color Enhancement (ACE) [9], and Short-time Fourier Transform (STFT) [3]. For the same input image in Fig. 11a, the pre-processed images using different methods are shown in Fig. 11b–g.

We compared the effect of different pre-processing methods for both vein image authentication and recognition tasks using the same two datasets in Section 5. The authentication and recognition performances are shown in Figs. 12 and 13
                        
                         respectively. As can be seen, directly using the original un-processed image led to very poor performance, because the extracted local descriptor is very noisy. LHE, AHE and STFT gave the best performance, because these local methods are able to enhance the vein pattern at the local region to assist in detecting discriminative image descriptors. This clearly shows the support from the generative part of our proposed model, where by detecting and extracting descriptors from informative location, the geometrical layout between finger Ids can be accurately modeled in the joint tree model. This result is consistent with reported works [41,32] that rely on matching the shape of vein patterns. In addition, STFT gave superior performance than LHE and AHE because the enhancement led to a clearer local pattern that can further help the discriminative part in the proposed joint model.

This subsection lists experimental results based on different types of local image descriptors, including Sift, Hog, ORB and Freak and Surf
                           3
                        
                        
                           3
                           Implementation based on OpenCV 2.4.
                        . Using the same two datasets as in Section 5, vein image authentication and recognition results are listed in Figs. 14 and 15
                        
                         respectively. In this experiment we are most interested in comparing the rotation-robustness and discrimination power of different descriptors. The scale-robustness is not studied because no scale variation exists in the typical vein image collection process. Regarding rotation-robustness, it is noticed that those descriptors with rotation-invariance, including Sift, Freak and Surf, achieved better performance in both authentication and recognition tasks. Although the ORB descriptor is also theoretically rotation invariant, its performance is only slightly better than the Hog descriptor which is not rotation invariant. Regarding the discriminative power between descriptors, Sift, Freak or Surf does not lead to significantly different performances. This is reasonable because since the location of feature points has been determined by the same Harris–Laplacian detector, the type of descriptor for each local image patch is not critical as long as they are sufficient for matching, where Sift, Freak and Surf are all capable of.

In this paper we introduce a joint discriminative and generative vocabulary tree based model for finger vein identification. The method consists of a modified tree structure to allow non-parametric matching of local image descriptor's layout, and a novel algorithm to combine the discriminative and generative information at the hidden leaf node layer of a vocabulary tree, under Bayesian probability.

The future work includes the following aspects: First, the idea to factorize global alignment error into per-leaf node score can also be applied to other similar problems such as feature selection or code-word selection. Hence extending the framework to other models is on-going; and second, motivated by the connection between the vocabulary tree model and the Bag of Word (BoW) model [6], we are examining the possibilities to improve the method for general image classification tasks by using the hidden leaf node layer as a sparse encoder of local image descriptors. In this way, many existing sparse-coding based image representations [37,30] that only emphasize the generative reconstruction error of local descriptors can be further improved.

@&#ACKNOWLEDGEMENTS@&#

This work is supported by National Natural Science Foundation of China under Grant No. 61102100, and the National High Technology Research and Development Program of China (863 Program) under Grant No. 2014AA015205.

@&#REFERENCES@&#


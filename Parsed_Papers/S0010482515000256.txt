@&#MAIN-TITLE@&#Maximizing clinical cohort size using free text queries

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We demonstrate the value of free text queries in cohort identification.


                        
                        
                           
                           Incremental value is added compared to structured data queries alone.


                        
                        
                           
                           We determine the value of free text using 3 disparate use cases.


                        
                        
                           
                           Use case specific values and limitations are identified in large data sets.


                        
                        
                           
                           Exploratory value of a direct search tool in contrast with heavier NLP systems.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Gingko

Warfarin

Overweight

Diabetes

Text query

Structured data

Cohort identification

Unstructured data

Clinical notes

@&#ABSTRACT@&#


               
               
                  Background
                  Cohort identification is important in both population health management and research. In this project we sought to assess the use of text queries for cohort identification. Specifically we sought to determine the incremental value of unstructured data queries when added to structured queries for the purpose of patient cohort identification.
               
               
                  Methods
                  Three cohort identification tasks were evaluated: identification of individuals taking gingko biloba and warfarin simultaneously (Gingko/Warfarin), individuals who were overweight, and individuals with uncontrolled diabetes (UCD). We assessed the increase in cohort size when unstructured data queries were added to structured data queries. The positive predictive value of unstructured data queries was assessed by manual chart review of a random sample of 500 patients.
               
               
                  Results
                  For Gingko/Warfarin, text query increased the cohort size from 9 to 28,924 over the cohort identified by query of pharmacy data only. For the weight-related tasks, text search increased the cohort by 5–29% compared to the cohort identified by query of the vitals table. For the UCD task, text query increased the cohort size by 2–43% compared to the cohort identified by query of laboratory results or ICD codes. The positive predictive values for text searches were 52% for Gingko/Warfarin, 19–94% for the weight cohort and 44% for UCD.
               
               
                  Discussion
                  This project demonstrates the value and limitation of free text queries in patient cohort identification from large data sets. The clinical domain and prevalence of the inclusion and exclusion criteria in the patient population influence the utility and yield of this approach.
               
            

@&#INTRODUCTION@&#

Recently healthcare has come to embrace the potential of ‘analytics’ on large datasets for operations, quality improvement and clinical and biomedical research [1]. With the increase in the availability of large healthcare datasets, there are significant challenges in accessing and making use of these data. There is a need for tools and protocols to harness and ‘tame’ these big data so that they can be converted to information and ultimately into actionable knowledge. Otherwise, there is a real danger of amassing large datasets that never fulfill the potential of improving patient care and increasing healthcare efficiency.

One critical component of big data analysis is cohort identification, i.e. the reliable identification of a group of patients of interest. Cohort identification is typically an iterative process in which the goal is to separate definite ‘cases’ of interest from possible cases and then find appropriate controls [2]. Determining whether a given patient meets the definition of a case is often challenging and requires accurate and reliable data. Current database search capabilities support cohort identification within electronic medical record (EMR) systems, however, these are limited to cohort identification based on structured data [3–8]. Recently, there is increasing interest in the use of clinical notes for cohort identification [9–14].

In this study, we sought to determine the value of adding free text search to structured data queries as compared to structured data query alone for cohort identification from an extremely large dataset (>17 million unique individuals). The study employed Voogo, a user-friendly clinical data search engine that executes key word searches of clinical free text. We compared the cohorts identified using free text search to structured-data-only queries, and did so in three cases of increasingly complex inclusion criteria. A random sample of electronic medical notes from 500 patients was then evaluated by human review to estimate the positive predictive value of correctly identifying cases using free text queries. Our overall goal was to determine the value of free text queries in cohort identification by answering the question: how many additional patients and observations can be identified through free-text queries as compared to using structured data queries only?

The Veterans Health Administration (VHA) operates one of the largest integrated healthcare systems in the United States. The VHA has seen a steady increase in enrollment in recent years with 8.6 million total living enrollees in fiscal year 2012. With regard to volume of patient care, in 2012 there were 79.8 million outpatient visits across VHA׳s hospital-based clinics and 827 community based outpatient clinics, and VHA׳s 151 hospitals handled more than 692000 inpatient admissions [16].

The VA was at the forefront of the development of Electronic Health Records with its nationwide implementation of VistA in 1996. Therefore, VA now has extensive longitudinal records on its millions of enrolled veterans.

Recognizing the opportunities for research using this aggregated data, the VA Health Services Research and Development (HSR&D) office funded the Veterans Informatics and Computing Infrastructure (VINCI), which began operations in June 2008 [15]. VINCI is a service-level collaboration between the Office of Information and Technology (OI&T) and the Office of Research and Development (OR&D), designed to serve the data and IT needs of the VA research community. VINCI provides centralized access to VA data resources in a high-performance computing environment with secure access to comprehensive VA healthcare data. VINCI׳s mission is to provide researchers with an environment for efficient, secure analysis of patient level data, and to provide tools and coordination for research in basic and applied medical informatics.

The VINCI database is hosted on a Microsoft SQL Server DBMS installation. It is extremely large, at the time of this study providing access to structured and unstructured electronic medical data on 17,543,172 unique patients, living or deceased, since Oct. 1999. VINCI data is updated from raw VistA electronic health records on a nightly basis, and also provides snapshots at the end of the fiscal year [16]. The document corpus consists of 2,096,957,070 clinical documents from providers. The dataset also includes 1,611,284,360 diagnostic codes (ICD9), data on 1,654,598,048 pharmacy prescriptions, and 5,856,426,293 lab tests (both orders and results). Many other types of administrative and clinical data are also available for exploration and discovery. In order to access data, researchers request a VINCI workspace and submit a data access request form after acquiring approval from the institutional review board. The data request indicates the criteria and domains being requested. If approved, data managers provide access to the approved data set.

@&#METHODS@&#

The use cases for this study were derived from real world inquiries we received from clinicians and researchers across the VA system during the first half of 2013. They are representative of the progressively complex cohorts requested by researchers in a US large healthcare system.

The first cohort identification task involves identifying patients who are concurrently taking the herbal remedy Ginkgo biloba and the anticoagulant warfarin. There seems be a high potential for patients to take these two substances simultaneously: a recent article reports that 49% of Americans use dietary supplements [17], with Ginkgo being a popular herbal supplement. In addition warfarin is a commonly prescribed anticoagulant. The interaction between Ginkgo and warfarin is considered to be potentially severe [18]. This cohort identification task therefore represents an attempt to address the important question of the safety of a potentially common drug–supplement interaction.

Though ICD-9-CM codes exist for adverse drug reactions [19], currently, there are no codes for identifying the concurrent usage of Ginkgo and warfarin or their interactions. Thus, for this cohort identification task, the only available data source for identifying patients taking Ginkgo concurrently with warfarin is through text data as recorded by the medical provider. Ginkgo was noted to be dispensed by certain pharmacies in the VA system, thus it was possible to identify prescriptions through the pharmacy databases. 
                        Table 1 shows the availability of data elements in the VA electronic medical record to identify this cohort of patients. We used all clinical notes, which include over 2000 note types. The most frequent included “Nursing Note”, “Primary Care Note”, “Telephone Encounter Note”, “Nursing Inpatient Note”, and “Primary Care Outpatient Note” [20].

The second cohort identification task involved classifying individuals as either overweight or obese based on their recorded measurements such as weight, height and abdominal girth (or waist circumference). While the majority of evidence has pointed to a clear linear relationship between weight and health, a recent report found a 6% reduction in morbidity among overweight individuals as compared to normal weight individuals (the “obesity paradox”) [21]. The seemingly complex association between weight and health is complicated by the many potential effect modifiers: including physical fitness [22], physical activity [22,23], visceral vs. subcutaneous fat depots [24], and genetics [23]. Any study that sets out to examine these complex relationships will need to first classify individuals by their weight status and then account for the time varying nature of this measure (e.g. describe the weight trajectories of individuals in the cohort). This cohort identification task therefore represents an attempt to both capture additional individuals by including free text data but also to increase the number of measures within individuals with which to improve the classification of their weight trajectory.

In principle, height, weight, and abdominal girth should always be captured as structured data elements and should be available in the vital statistics table. However several reports using VA structured data have found a significant percentage of individuals are missing these data. Littman et al. reported that among the records of 173,127 veterans, 32.8% had missing data for weight or height [25]. Similarly, Das et al. reported that among 1.8 million veterans who received outpatient care at VA facilities in 2000, 50.4% had no recorded height or weight as structured data [26]. This situation is likely to improve as the VA seeks meaningful use certification [27]. It appears that some of the missing data is the result of clinicians entering these measurements as text in their notes rather than structured data in the EHR (personal communication Ken Jones, VA National Program Director for Weight Management, June 30, 2013). This data occurs in narrative discussions as well as in semi-structured sections of notes, such as those labeled Physical Exam (PE), Review of Systems (ROS), etc., however these sections are not consistently named and do not have a consistent structure. Therefore to define this cohort we sought to supplement the structured data in the vitals table with extraction of free text mentions of these measures in the medical note.

The third cohort identification task involved identifying patients whose diabetes was uncontrolled. Diabetes is a common condition among veterans served by VHA [28], and it is of the utmost urgency that the factors associated with lack of control are identified to inform strategies and policies to improve control. While some of these factors are known in the general population, it is important that we study these in specific veteran populations that are particularly at high risk of the complications of uncontrolled diabetes.

Several structured data sources are readily available for assembling this cohort: there are ICD-9-CM codes for uncontrolled diabetes, and a query of the laboratory database would identify patients whose hemoglobin A1C (HbA1C) is >7.0% indicating poorly controlled diabetes. We hypothesized that the free text in the clinical note would provide additional evidence for uncontrolled diabetes and help identify veterans who did not have relevant ICD codes and lab values in the VA system. This is possible because VA patients may receive care from outside VA either on a routine or emergent basis [29].

These three uses are a convenience sample representing three different contexts of cohort identification: (1) Gingko/Warfarin – we have prior knowledge of the low prevalence of Gingko in coded data; (2) overweight – we have prior knowledge of the limitation of coded data, though coded data do exist; (3) UCD – we have prior knowledge of the limitation of one kind of coded data (ICD) but not that other kind (HbA1C). In all three cases, there is a need to explore the added value of text.

Voogo is a search engine developed in house by our research group specifically to query VINCI data [30,31]. It supports both free text and structured data searches and provides document, patient, and population-level results (
                        Fig. 1). Searchable fields include document text, document type, age, gender, county, state, Veterans Integrated Service Network (VISN), ICD-9, medication, Current Procedural Terminology (CPT) code, and deceased status. Both Boolean operators and wildcards are supported in query criteria. Query expansion, using synonyms from several UMLS sources (i.e. SNOMED, MeSH, and ICD) and lexical variants from the SPECIALIST lexicon, is also implemented [30]. Results can be saved as lists of patient and document identifiers, or complete result summaries with sample documents and include the geographical distribution and detailed patient and document views of results (Fig. 1). Other query summaries include age distribution, living/deceased, gender, and prescribed VA medications. Voogo is currently configured to either directly query the VINCI database tables or query through the Solr/Lucene search engine (
                        Fig. 2) [32].

Prior to the initiation of Voogo development, other tools were explored that were available or could be made available in the VINCI environment. None were found that met our criteria of a graphical user interface for search construction on both structured and unstructured data; integration with the existing VA corporate data warehouse; allowance for integration of new, flexible indexing; result visualization; flexible result sampling; and a query expansion function. Voogo takes advantage of full-text search features of Microsoft SQL Server as well as the Solr/Lucene search platform. No suitable search tools were found that supported negation assertions. Voogo is not an in depth NLP tool like V3NLP, HITEx, Sophia, cTAKES, etc. which are part of eMERGE, CHIR, and SHARP [33–36]. Rather it is intended for text and coded data exploration and cohort identification. Negation assertion is planned for the near future. Voogo is open source software in the process of being released through the VA/OSEHRA mechanism.

The research team developed structured and free-text queries for each of the cohort identification tasks. The queries were iteratively revised after reviewing interim results until the researchers were satisfied that an appropriate population was identified. For example, based on initial results the queries for Ginkgo biloba use were revised to include two spelling variants: “Gingko” and “Ginko”. 
                        Table 2 shows the final queries used in the study. Ultimately, researchers who request cohorts determine the termination point in query formation. During the iterative process, the investigators are discovering new query terms and assess the usefulness of terms for the tasks, in an informal fashion. While standard vocabularies exist (and are taken advantage of by our query recommendation service), the vocabularies are far from perfect and clinical judgments are required.

For each of the three cohort identification tasks, a random sample of all clinical notes for 500 veterans (100 each for Gingko, height, weight, girth, and uncontrolled diabetes) was drawn from the full set of documents identified by the free text queries. A total of 6425 documents were extracted for human review (Ginkgo=433, weight=3043, height=2086, girth=356, UCD=507). These records were reviewed to determine whether free text queries identified (1) true positives (TP) or false positives (FPs); (2) the same patients as structured data queries. The records were raw, not de-identified; the local institutional review board (IRB) approved all data access and use in this study, and no data was accessed or shared without prior IRB approval.

The positive predictive values (PPVs) of using text for case identification were calculated based on chart reviews. Experienced reviewers developed guidelines to establish true positive cases for each of the three use cases. For Gingko and warfarin usage, we relied on chart review alone to determine if Gingko was actively being used (or had been discontinued). In the weight-related use case, manual review determined the presence of a specific value for weight, height, and abdominal girth. For the review of charts related to diabetes, we deemed the record a positive if there was at least one instance of mention of uncontrolled diabetes based on the terms used for the free text query. Two experienced researchers reviewed a random sample of query search results. The inter-reviewer agreement was calculated for each chart review; discordances were adjudicated by discussion among the reviewers until consensus was reached.

The overall workflow for the cases is (1) Use Voogo to iteratively preview data and refine query; (2) perform query and assess potential value in addition to structured data; (3) if free text adds value, obtain cohort and assess specificity; (4) if specificity is not satisfactory, train NLP to refine cohort; (5) analyze data, using NLP results in the analysis if necessary (e.g. the weight value). The general use of text to maximize cohort size is applicable to other EHR systems, although the specific Voogo tool is designed for the VINCI system.

In order to compare query results with what can be accomplished with additional NLP, we performed NLP analysis of Gingko and weight notes. Using the 433 cases that had been manually reviewed for Gingko, we first manfully crafted a set of processing rules to highly prevalent templates. We then trained a support vector machine (SVM) model using the notes not covered by the template rules. The SVM developed was conducted using WEKA SMO algorithm along the default parameters. The final NLP module first applies the template rules and then applies the SVM model. We tested the NLP module on 200 randomly selected notes retrieved by the Gingko query and calculated accuracy measures. Because the evaluation results are good, the NLP module was then applied to all retrieved notes to filter out FP cases. We also developed an NLP module for extraction of weight values from free text notes retrieved by the weight query. We used a novel Regular Expression Discovery (RED) algorithm to automatically discover regular expressions to extract weight values. We trained the RED Extraction model using 571 manually reviewed primary care outpatient notes, and applied the model to 5716 notes of from 1000 random patients.

@&#RESULTS@&#

Large numbers of patients were identified for all three cohorts (
                        Table 3). In most cases, text searches identified more patients than structured data queries alone. Using structured-data alone, only nine patients were found to be taking both Gingko and warfarin. Free text queries returned over 28,000 patients. Free text queries returned roughly the same number of patients for weight and height as structured data queries. More patients with girth information or diabetes complications were identified through text queries.

There were a total of 6425 documents reviewed for the 500 patients randomly selected for the three cohort identification tasks (100 each for Gingko, height, weight, girth, and uncontrolled diabetes). Inter-rater agreement for the reviews and positive predictive values for each of the queries are presented in 
                        Table 4. The highest PPVs were found for height and weight, while the lowest PPV was associated with girth. Structured data were poor in identifying true positives for Ginkgo+warfarin and abdominal girth. The increase in cohort size was dramatic for Gingko and warfarin (167,116 fold increase), and of practical significance for abdominal girth (29%). It was interesting to note that even for situations where structured data exist (ICD codes and laboratory results for uncontrolled diabetes), there was a significant increase in cohort size. This was likely due to inconsistent capture of structured data. 
                        Table 5 provides examples of true positives (TPs) and false positives (FPs) found in these cohort identification tasks.

In the use case involving patient weight and height, free text queries essentially doubled the number of observations (
                        Table 6). However, most of the cases from free text queries were also identified by structured data.

On the 200 randomly selected Gingko notes, the NLP model reached a PPV of 90%, sensitivity of 97%, specificity of 78%, and F measure of 93%. 10-fold cross-validation of the Weight model gave a PPV of 98.8%, sensitivity of 98.3%, specificity of 98.1%, and F measure of 98.5%. Comparison to weights from structured vital signs data showed that 7.7% of the weight measurements from text were not available in the structured data.

@&#DISCUSSION@&#

In this study we examined the incremental value of free text queries for identification of cohorts of patients from a very large clinical dataset. Our results suggest that free text queries on big clinical data can add value to the task when compared with searches using structured data alone, especially in cases where structured data do not exist. In all three-cohort identification tasks, text queries increased the size of patient cohorts. In some cases, the percentage of increase was relatively small (8% of the true positive patients identified by height text query had no height recorded in vital signs). While in other cases the increase was truly dramatic: virtually all of the true positive concurrent Gingko-warfarin users were identified by text queries. Finally, tracking patient weight using both structured data and free text notes not only identified more patients but also increased the number of observations per patient. This suggests that certain clinical variables are more consistently recorded in both text and structured data (e.g. height and weight), while text might be the only source for other data such as Ginkgo biloba use. When high quality structured data are available as in the case of HbA1C, the added value of text query is clearly more limited. However, we observe that not all structured data are of equal quality. Using ICD codes to identify uncontrolled diabetes, for instance, failed to identify many patients.

Simply stated, we found that free text queries can be fruitfully combined with structured data search to yield a more complete patient cohort from the electronic medical record. In looking at the different use cases, the utility of free text queries varies by the clinical domain and the prevalence of the inclusion and exclusion criteria in the patient population. Furthermore, the key to reliable and complete patient identification is the availability of individual data elements in the EMR and the ability to access them.

We acknowledge several limitations. In this study, the precision and recall of text queries varied by the query. High precisions were observed for height and weight. Lower rates were found for Gingko, uncontrolled diabetes, and abdominal girth. Through our experience in using this tool we have developed several strategies to filter out false positives (FPs). In certain queries, the FPs or TPs are concentrated in specific document types or notes from certain facilities. Determining these sources of error and applying appropriate filters has the potential to reduce false positives. For instance, many of the Gingko FPs were noted to be in pre- and post-operative instructions to patients. Excluding those types of documents could improve the PPV. Complex natural language processing (NLP) may be required to filter out other source of FPs such as negation, templating within the notes, hypotheticals (e.g. if you have high blood sugars, then increase your insulin), clinical plans, instructions (e.g. please stop your warfarin at least 7 days prior to your surgery), family history, and past history. In evaluating additional NLP on both Gingko and weight we showed that NLP is able to increase accuracy measures, more so with Gingko than weight, demonstrating that NLP is necessary where higher accuracy measures are required, although at much higher cost.

Our chart review was limited to only 100 randomly selected patients for each text query (500 patients total); even though this included 6425 documents, the results of our manual review may not be representative of the full document corpus. With several million patients in each cohort and several hundred million documents, a human review of even a meaningful sample is a daunting task. The human review effort utilized approximately 150 person hours for the 6425 documents from 500 patients. By simple extrapolation, manual annotation of these features for the over 17 million patients in the entire data corpus would equate to roughly 5,000,000 person hours, or over 500 person years. The chart review was conducted on positively identified cases, since the number of negatives cases is very large and the prevalence of any given condition is low. This makes estimating the recall or sensitivity particularly challenging when working with such a large dataset, and points to the pressing need to develop better methods of evaluating results of analyses of big data. Since we cannot fully assess false negatives (FNs), text search generally casts a wide net. In our use cases the queries are the product of iterative search and revision to minimize FNs at the cost of higher FPs. Although more FPs increases the NLP burden, NLP can correct for this. Loss of TPs at the stage of cohort identification cannot be reversed by NLP. At each step of the process, quality evaluation is important as errors can be accumulated and passed on to subsequent steps in the process.

In conclusion, this study demonstrates the power of adding free text queries to the task of cohort identification using a large clinical dataset. The result is the ‘taming’ of these big data to a manageable size. Using this efficient free text query approach requires minimal human and computing resources and may be the endpoint for some cohort identification tasks, while for more detailed and sophisticated projects it may serve as a starting point.

None declared.

@&#ACKNOWLEDGMENTS@&#

Funding for this project was provided by U.S. Department of Veterans Affairs, Veterans Health Administration HSR and D, Office of Research and Development, Health Services Research and Development Projects CHIR HIR 08-374, VINCI HIR-08-204 and HIR 10-002. Further support was provided by NIH grants 1R01LM011334 and 1R01AT006548-01A1. Resources and administrative support were provided by the VA Salt Lake City Health Care System (IDEAS Center). We thank our various team members for their assistance with this project. We appreciate and acknowledge our colleagues at VA Informatics and Computing Infrastructure (VINCI) for their assistance with accessing VA ‘big data’. The views expressed in this paper are those of the authors and do not necessarily represent the views of the Department of Veterans Affairs or the United States Government.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#UHD TV image enhancement using example-based spatially adaptive image restoration filter

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This paper presents restoration method using examples and TCLS filter for UHD image.


                        
                        
                           
                           The proposed method can be used for wide range of consumer imaging systems.


                        
                        
                           
                           In order to reduce the search-time, patch is classified based on the edge orientation.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Patch-based image restoration

Truncated constrained least-squares filter

Super-resolution

Dictionary generation

Orientation estimation

@&#ABSTRACT@&#


               
               
                  This paper presents a novel image restoration algorithm using examples and truncated constrained least squares (TCLS) filter for ultra-high definition (UHD) television systems. The proposed approach consists of three steps: (i) generation of the patch dictionary using multiple-step image blurring, (ii) selection of the optimum patch based on the orientation and the amount of blurring, and (iii) combination of the selected patch in the dictionary and its filtered version by the TCLS restoration filter for reducing the patch mismatch error. In the proposed algorithm, a complicated point-spread-function (PSF) estimation process is replaced with the generation of multiple, differently blurred patches. Furthermore, the patch dictionary is made by orientation-based classification to reduce the time to search the optimum patch. Experimental results show that the proposed algorithm can restore more natural images with less synthetic artifacts than existing methods. The proposed method provides a significantly improved restoration performance over existing methods in the sense of both subjective and objective measures including peak-to-peak signal-to-noise ratio (PSNR) and structural similarity measure (SSIM).
               
            

@&#INTRODUCTION@&#

Recently, classical image restoration faces a new opportunity to improve image quality in modern digital imaging devices such as ultra-high definition (UHD) TVs, intelligent video surveillance systems, and mobile phone cameras. In order to overcome the limitations of optical lenses, imaging sensors, and image processing algorithms, an image restoration algorithm estimates the cause of image degradation, and removes them in various ways: a frequency-domain filtering, iterative regularization, statistical optimization, and example-based methods, to name few.

Frequency-domain image restoration algorithms are conceptually simple, and easy to implement using the fast Fourier transform (FFT) [1]. However, they usually exhibit ringing artifacts since abrupt changes at the edge of an image do not satisfy the periodic assumption of the Fourier bases. Regularized iterative image restoration can provide better restored results than the frequency-domain filtering in the spatially adaptive manner at the cost of the indefinite processing time for the iterative minimization of the regularized objective function [2–4]. For this reason, these two methods are not suitable for modern consumer imaging devices.

A UHD TV, for example, is the state-of-the-art digital television in the consumer market. It adopts various image restoration algorithms to enhance the quality of low-resolution image contents. A low-end UHD TV uses a finite impulse response (FIR) type image restoration filter for cheap, easy implementation, while a high-end UHD TV with sufficient amount of memory may adopt an example-based image restoration algorithm. In practice, the truncated constrained least squares (TCLS) filter is suitable for enhancing the UHD TV images because of the finite filtering support for real-time restoration [5,6]. However, the TCLS restoration filter is sensitive to the accuracy of estimating the point spread function (PSF). Since a perfectly accurate estimation of the PSF is almost impossible, the TCLS restoration filter cannot successfully restore the high-quality image in the commercialization level by itself. Alternatively, example-based algorithms are widely used in image restoration and super-resolution (SR) [7–9]. Although example-based image restoration can provide well-restored images by replacing the low-resolution patch with the appropriately selected high-resolution patch, its disadvantage is twofold: (i) generation of the patch dictionary and search of the best patch require high computational load, and (ii) patch mismatch error produces undesired artifacts in the restored image.

This paper presents a novel image restoration method using both example-based and TCLS filtered patches for high-quality, fast restoration in various consumer imaging devices. The proposed method first generates the patch dictionary using multiple, differently blurred patches for successful restoration without an accurate estimation of the PSF. In the proposed dictionary, each patch is classified by the orientation to reduce the time to search. Given the patch dictionary, the proposed restoration algorithm searches the closest patch to the given input patch, and combines it with the restored patch by the TCLS filter to correct the patch mismatch error.

This paper is organized as follows. Section 2 describes the image degradation model and theoretical basis of example-based image restoration. Section 3 presents the combined example-based and TCLS restoration methods. Section 4 summarizes experimental results, and Section 5 concludes the paper.

When an image is acquired by a digital imaging device, it is degraded by various factors including: a diffraction-limited lens, inaccurate focusing, limited-resolution image sensor, lossy compression, and down-scaling. In a UHD TV system, for example, the image degradation model is shown in Fig. 1
                     , where the natural scene is first degraded by a camera system and the compression process to produce a high-definition (HD) image. In order to use the HD image in the UHD TV, up-scaling is performed by interpolation.

The M
                     ×
                     N HD image is a degraded version of the natural scene f, and is mathematically expressed as
                        
                           (1)
                           
                              
                                 
                                    g
                                 
                                 
                                    H
                                 
                              
                              =
                              
                                 
                                    H
                                 
                                 
                                    1
                                 
                              
                              f
                              +
                              
                                 
                                    η
                                 
                                 
                                    1
                                 
                              
                              ,
                           
                        
                     where gH
                      represents the MN
                     ×1 row-ordered vector, H
                     1 the degradation matrix of the camera and compression systems, and η
                     1 the additive noise. In order to obtain the UHD image from gH
                     , upscaling is performed as
                        
                           (2)
                           
                              g
                              =
                              
                                 
                                    H
                                 
                                 
                                    2
                                 
                              
                              
                                 
                                    g
                                 
                                 
                                    H
                                 
                              
                              +
                              η
                              =
                              Hf
                              +
                              η
                              ,
                           
                        
                     where g represents the 4MN
                     ×1 row-ordered vector of the four times upscaled version of gH
                     , H
                     2 the MN
                     ×4MN upscaling matrix, and the η additive noise. The entire image degradation model is given by combining (1) and (2) as
                        
                           (3)
                           
                              g
                              =
                              
                                 
                                    H
                                 
                                 
                                    2
                                 
                              
                              (
                              
                                 
                                    H
                                 
                                 
                                    1
                                 
                              
                              f
                              )
                              +
                              η
                              =
                              Hf
                              +
                              η
                              ,
                           
                        
                     
                  

Based on the image degradation model given in Eq. (3), the corresponding image restoration process requires the accurate estimation of the point-spread-function (PSF) denoted by H
                     =
                     H
                     1
                     H
                     2. Since the degradation matrix H is the combination of H
                     1 and H
                     2, it can neither be defined in a mathematically closed form nor be estimated with sufficiently high precision. For this reason, a typical image restoration method that requires a closed form PSF cannot be used. For this reason, an example-based approach is an alternative solution to the restoration since it searches the optimum patch from the pre-generated dictionary under assumption that an image is composed by multiple patches.

Despite many advantages, existing example-based restoration produces unnaturally overamplified edges because there is no control to select different levels of edge sharpness in searching the optimum patch. Fig. 2
                      shows an example of different levels of edge sharpness in an image.

In order to restore edges with different magnitude of the gradient, the proposed method generates the patch dictionary using multiple, differently blurred patches.

This section describes the proposed restoration algorithm whose patch dictionary is made by multiple-step image blurring. A patch in the dictionary is classified by its orientation [10,11]. Given a patch in the input image, the corresponding patch is selected from the patch dictionary using the gradient. For obtaining a naturally looking result, the selected and restored patches are appropriately combined [6]. The proposed algorithm consists of three steps: (i) dictionary generation, (ii) selection of the optimum patch from the dictionary, and (iii) combination of the selected and restored patches as shown in Fig. 3
                     .

The patch dictionary is generated by multiple-step image blurring of the high-quality images in a priori given data set. Let fD
                         be an M
                        2
                        ×1 row-ordered vector representing the corresponding M
                        ×
                        M high-quality image in the data set, and Bi
                         be the M
                        2
                        ×
                        M
                        2 block-circulant matrix representing the ith step Gaussian blurring kernel, then the i-th step blurred image is given as
                           
                              (4)
                              
                                 
                                    
                                       g
                                    
                                    
                                       D
                                    
                                    
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       B
                                    
                                    
                                       i
                                    
                                 
                                 
                                    
                                       f
                                    
                                    
                                       D
                                    
                                 
                                 
                                 for
                                 
                                 i
                                 =
                                 0
                                 ,
                                 …
                                 ,
                                 s
                                 ,
                              
                           
                        where the subscript D represents the dictionary, and s the number of differently blurring steps. B
                        0 is the identity matrix, which implies that the standard deviation of the Gaussian blurring kernel is zero, or equivalently 
                           
                              
                                 
                                    g
                                 
                                 
                                    D
                                 
                                 
                                    0
                                 
                              
                              =
                              
                                 
                                    f
                                 
                                 
                                    D
                                 
                              
                           
                        . As i increases, the standard deviation, σ, of the Gaussian kernel also increases.

The j-th patch of size p
                        ×
                        p extracted from the i-th step blurred image patches are defined as 
                           
                              
                                 
                                    g
                                 
                                 
                                    DP
                                 
                                 
                                    ij
                                 
                              
                           
                        , for 
                           
                              j
                              =
                              1
                              ,
                              …
                              ,
                              [
                              
                                 
                                    M
                                 
                                 
                                    2
                                 
                              
                              /
                              
                                 
                                    p
                                 
                                 
                                    2
                                 
                              
                              ]
                           
                        , are extracted from the i-th step blurred image 
                           
                              
                                 
                                    g
                                 
                                 
                                    D
                                 
                                 
                                    i
                                 
                              
                           
                        , and is classified by the orientation [10,11]. Patches are classified according to the quantized orientations, such as 
                           
                              0
                              °
                           
                        , 
                           
                              45
                              °
                           
                        , 
                           
                              90
                              °
                           
                        , and 
                           
                              135
                              °
                           
                        , in order to reduce the searching time.


                        Fig. 4
                         shows the proposed dictionary generation method using hierarchically blurred images. A major advantage of the proposed approach is twofold: (i) the dictionary of multiple-step blurred patches enable successful restoration without accurately estimating the PSF and (ii) the fast processing because the patch is classified only by the orientation.

Let 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                        shown in Fig. 3 be patch of the input degraded image g shown in Fig. 1, then the most similar patch is searched from the dictionary. Since the dictionary is classified by the patch orientation, patch 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                         is compared with patches in the same orientation in the dictionary. Since this work classifies patches in four orientations, the computational amount of the orientation-based patch selection is significantly reduced. The most similar patch is selected by minimizing the patch mismatching error (PME) between the patch of input degraded image 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                         and the blurred dictionary patch 
                           
                              
                                 
                                    g
                                 
                                 
                                    DP
                                 
                                 
                                    ij
                                 
                              
                           
                         along the same patch direction, which is defined as
                           
                              (5)
                              
                                 d
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       σ
                                       
                                          
                                             2
                                             π
                                          
                                       
                                    
                                 
                                 exp
                                 
                                    
                                       
                                          -
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  g
                                                               
                                                               
                                                                  DP
                                                               
                                                               
                                                                  ij
                                                               
                                                            
                                                            -
                                                            
                                                               
                                                                  g
                                                               
                                                               
                                                                  P
                                                               
                                                               
                                                                  j
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                             
                                                2
                                                
                                                   
                                                      σ
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where σ is the smoothing parameter.

A high PME value tends to decrease the probability of existence of a similar patch in the dictionary. In searching the dictionary, not only the class of the same orientation is used, but the amount of blurring is also considered to determine 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          ̃
                                       
                                    
                                 
                                 
                                    DP
                                 
                                 
                                    ij
                                 
                              
                           
                        , where the superscript 
                           
                              i
                           
                         represents the level or step of blur. Given 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          ̃
                                       
                                    
                                 
                                 
                                    DP
                                 
                                 
                                    ij
                                 
                              
                           
                        , the corresponding patch with high-frequency details, denoted as 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          ̃
                                       
                                    
                                 
                                 
                                    DP
                                 
                                 
                                    i
                                    -
                                    k
                                    
                                    j
                                 
                              
                           
                         is selected. The amount of restoration is determined by selecting an appropriate k. If the number of degradation steps k is increased, the possibility to find a similar patch increases at the cost of increased amount of computation. In this work k
                        =3 was used for experimentally best result. For the real-time processing, it is recommended to set k
                        =1. More specifically, if k
                        =0, there will be no restoration effect. The larger k results in higher-frequency details restored. The j-th selected patch 
                           
                              
                                 
                                    f
                                 
                                 
                                    SP
                                 
                                 
                                    j
                                 
                              
                           
                         is replaced with 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          ∼
                                       
                                    
                                 
                                 
                                    DP
                                 
                                 
                                    i
                                    -
                                    k
                                    
                                    j
                                 
                              
                           
                         to 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                        . Three steps of the proposed patch selection algorithm is summarized in Table 1
                        .

The high PME value represents unnatural restoration results in the patch selection process. To reduce the PME value, the selected patch 
                           
                              
                                 
                                    f
                                 
                                 
                                    SP
                                 
                                 
                                    j
                                 
                              
                           
                         from the dictionary is combined with the restored patch 
                           
                              
                                 
                                    f
                                 
                                 
                                    RP
                                 
                                 
                                    j
                                 
                              
                           
                         that is the restored version of 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                        . The TCLS restoration filter is created by truncating the spatial domain constrained least-squares (CLS) filter using the Maxwell–Boltzmann distribution kernel and directional kernels [6]. The Maxwell–Boltzmann distribution kernel is defined as
                           
                              (6)
                              
                                 K
                                 (
                                 x
                                 ,
                                 y
                                 )
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       1
                                       +
                                       exp
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      +
                                                      
                                                         
                                                            y
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      -
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                   
                                                      σ
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                                 c
                                 =
                                 α
                                 L
                                 ,
                                 
                                 σ
                                 =
                                 β
                                 (
                                 L
                                 -
                                 2
                                 c
                                 )
                                 ,
                              
                           
                        where L represents the filter size, σ controls the slope gradient of the kernel, and c controls the position of the median value of slopes. The Maxwell–Boltzmann distribution kernel loses less energy in the center of the filter than the Gaussian kernel, and at the same time the boundary of truncation is smoother than the rectangular or raised-cosine kernel to avoid unnecessary ringing artifacts.

The Gaussian directional kernel Ks
                        (x,
                        y) is created by estimating covariance matrix W. The neighboring region created at (x,
                        y) is defined as 
                           
                              
                                 
                                    f
                                 
                                 
                                    L
                                 
                              
                              (
                              x
                              ,
                              y
                              )
                           
                        , where the 
                           
                              m
                              -
                              th
                           
                         pixel in the area is 
                           
                              (
                              
                                 
                                    x
                                 
                                 
                                    m
                                 
                              
                              ,
                              
                                 
                                    y
                                 
                                 
                                    m
                                 
                              
                              )
                           
                        . The Gaussian kernel can be expressed as
                           
                              (7)
                              
                                 
                                    
                                       K
                                    
                                    
                                       s
                                    
                                 
                                 (
                                 x
                                 ,
                                 y
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             det
                                             (
                                             W
                                             )
                                          
                                       
                                    
                                    
                                       2
                                       π
                                       
                                          
                                             σ
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 exp
                                 
                                    
                                       
                                          -
                                          
                                             
                                                
                                                   
                                                      (
                                                      
                                                         
                                                            x
                                                         
                                                         
                                                            m
                                                         
                                                      
                                                      -
                                                      x
                                                      )
                                                   
                                                   
                                                      T
                                                   
                                                
                                                W
                                                (
                                                
                                                   
                                                      x
                                                   
                                                   
                                                      m
                                                   
                                                
                                                -
                                                x
                                                )
                                             
                                             
                                                2
                                                
                                                   
                                                      σ
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              x
                              =
                              
                                 
                                    [
                                    
                                       
                                          x
                                       
                                       
                                          m
                                       
                                    
                                    ,
                                    
                                       
                                          y
                                       
                                       
                                          m
                                       
                                    
                                    ]
                                 
                                 
                                    T
                                 
                              
                           
                        , σ is the smoothing parameter to control the distribution of the Gaussian kernel, and W is the covariance matrix, which is determined by the product of a rotation matrix and a diagonal matrix.

The gradient of image 
                           
                              
                                 
                                    f
                                 
                                 
                                    L
                                 
                              
                              (
                              x
                              ,
                              y
                              )
                           
                         is defined as
                           
                              (8)
                              
                                 ∇
                                 
                                    
                                       f
                                    
                                    
                                       L
                                    
                                 
                                 (
                                 m
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             ∂
                                             
                                                
                                                   f
                                                
                                                
                                                   L
                                                
                                             
                                             (
                                             
                                                
                                                   x
                                                
                                                
                                                   m
                                                
                                             
                                             ,
                                             
                                                
                                                   y
                                                
                                                
                                                   m
                                                
                                             
                                             )
                                             /
                                             ∂
                                             x
                                             ,
                                             ∂
                                             
                                                
                                                   f
                                                
                                                
                                                   L
                                                
                                             
                                             (
                                             
                                                
                                                   x
                                                
                                                
                                                   m
                                                
                                             
                                             ,
                                             
                                                
                                                   y
                                                
                                                
                                                   m
                                                
                                             
                                             )
                                             /
                                             ∂
                                             y
                                          
                                       
                                    
                                    
                                       T
                                    
                                 
                              
                           
                        and the gradient map is divided into multiple local blocks to estimate the local orientation.
                           
                              (9)
                              
                                 G
                                 =
                                 
                                    
                                       [
                                       ∇
                                       f
                                       (
                                       1
                                       )
                                       ∇
                                       f
                                       (
                                       1
                                       )
                                       …
                                       ∇
                                       f
                                       (
                                       M
                                       )
                                       ]
                                    
                                    
                                       T
                                    
                                 
                              
                           
                        where M is the number of pixels in local blocks to find the direction, and G is an M
                        ×2 matrix. W is obtained by the singular value decomposition (SVD) on the matrix G.The selected and restored patches 
                           
                              
                                 
                                    f
                                 
                                 
                                    SP
                                 
                                 
                                    j
                                 
                              
                           
                         and 
                           
                              
                                 
                                    f
                                 
                                 
                                    RP
                                 
                                 
                                    j
                                 
                              
                           
                         are combined to make the finally restored j-th patch 
                           
                              
                                 
                                    
                                       
                                          f
                                       
                                       
                                          ̂
                                       
                                    
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                         as
                           
                              (10)
                              
                                 
                                    
                                       
                                          
                                             f
                                          
                                          
                                             ̂
                                          
                                       
                                    
                                    
                                       P
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 (
                                 1
                                 -
                                 α
                                 )
                                 
                                    
                                       f
                                    
                                    
                                       SP
                                    
                                    
                                       j
                                    
                                 
                                 +
                                 α
                                 
                                    
                                       f
                                    
                                    
                                       RP
                                    
                                    
                                       j
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              α
                              =
                              d
                              /
                              θ
                           
                        , d represents the patch mismatching error between 
                           
                              
                                 
                                    g
                                 
                                 
                                    P
                                 
                                 
                                    j
                                 
                              
                           
                         and 
                           
                              
                                 
                                    
                                       
                                          g
                                       
                                       
                                          ̃
                                       
                                    
                                 
                                 
                                    DP
                                 
                                 
                                    ij
                                 
                              
                           
                        , and θ an appropriate threshold value.


                        Fig. 5
                         shows the results of the proposed method using “light house” image with and without using the restored patch. In Fig. 5(a), the patch mismatch error is observed in the enlarged red rectangle region, whereas Fig. 5(b) shows the more naturally looking result.

The concept of the proposed restoration algorithm is illustrated in Fig. 6
                        .

Since the proposed SR algorithm consists of three modules including dictionary generation, patch selection, and patch combination, computational load of each module should be separately analyzed. Although the dictionary generation module requires a nontrivial amount of computation, it does not increase the processing time because the dictionary can be generated a priori. There are several options to implement the patch selection module. More specifically, the range of patch selection module. More specifically, the range of patch selection should be increased for higher performance, and vice versa. Since the processing power of a commercial UHD TV varies by model, each its TV can select the optimal patch selection range. Finally, patch combination can be performed by weighted averaging, which requires a trivial amount of computation.

@&#EXPERIMENTAL RESULTS@&#

This section presents experimental results to compare the restoration performance of the proposed algorithm with existing methods. For the experiment, two types of image degradation including photographically blurred image and down-sampled image degradation are tested. For the objective evaluation, peak-to-peak signal-to-noise ratio (PSNR) and structural similarity measure (SSIM) are used.


                        Fig. 7
                         shows the restored results of an out-of-focused photograph image. Fig. 7(a) shows the test image of size 2448×1624 acquired by using a digital single lens reflected (DSLR) camera. To compare with the proposed method, de-blurring algorithms [12,13] are used. Xu’s and Shen’s methods produce ringing artifacts. The proposed method better restores the image without restoration artifacts than Xu’s et al. [12] and Shen’s et al. [13] methods.


                        Table 2
                         summarizes PSNR and SSIM values of two different de-blurring algorithms and the proposed one. The proposed algorithm provides higher PSNR and SSIM values than all two existing de-blurring methods.

In order to compare with various restoration results of low-resolution image, input images are down-sampled by a factor of 4 and then up-sampled by the same factor. We evaluate the performance of the proposed restoration algorithm by comparing with bicubic interpolation and super-resolution algorithms as shown in Figs. 8 and 9
                        
                        . “Child” and little girl” images are enlarged by four times using three different methods. The bicubic interpolation method produced both jagging and blurring artifacts near the edge regions as shown in Figs. 8(a) and 9(a). Example-based super-resolution methods by Glasner et al. [8] and Yang’s et al. [9] better reduced the blurring artifact than the bicubic method, but inaccurately amplified edges make the result look unnatural as shown in Figs. 8(b), (c), and 9(b), (c). The proposed method can successfully restores the image with naturally looking edges as shown in Figs. 8(d) and 9(d).


                        Fig. 10
                         shows the result of 2K-to-4K upscaling results. Fig. 10(b) shows the 4K UHD image made by simply up-scaling the 2K full HD image, and Fig. 10(c) shows the restored results using the proposed method. As shown in Fig. 10, the proposed method produces sharper and more naturally looking edges.

@&#CONCLUSION@&#

This paper presents a spatially adaptive image restoration algorithm by combining the best example patch and its restored version. In order to restore the image without complicated estimation of the PSF, the proposed method generates the patch dictionary using multiple-step blurred patches. In order to speed up the searching time, each patch is classified based on the edge orientation in the dictionary. The optimally selected patch is combined with its restored version to minimize the patch-mismatch error. Experimental results demonstrate that the proposed method can be used for wide range of consumer imaging systems including digital cameras, mobile phone cameras, UHD TV up-scalers, and digital zooming systems.

@&#ACKNOWLEDGMENTS@&#

This work was supported in part by the Technology Innovation Program (Development of Super Resolution Image Scaler for 4K UHD) under Grant K10041900, by the ICT R&D program of MSIP/IITP [14-824-09-002,Development of global multi-target tracking and event prediction techniques based on real-time large-scale video analysis], and by the MSIP(Ministry of Science, ICT&Future Planning), Korea, under the ITRC (Information Technology Research Center) support program (NIPA-2014-H0301-14-1044) supervised by the NIPA(National ICT Industry Promotion Agency).

@&#REFERENCES@&#


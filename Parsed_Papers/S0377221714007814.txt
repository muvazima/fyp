@&#MAIN-TITLE@&#Dynamic reduction heuristics for the rectangle packing area minimization problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Propose a dynamic reduction heuristic for the rectangle packing area minimization problem (RPAMP).


                        
                        
                           
                           Propose a least injury first (LIF) heuristic for its sub-problem, the rectangle packing problem (RPP).


                        
                        
                           
                           Propose an algorithm to compact the layout and prove its feasibility, compactness, non-inferiority and halting properties.


                        
                        
                           
                           Find new and better solutions for most large-scale RPAMP instances with at least 100 items.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Packing

Floorplanning

Layout optimization

Area minimization

Open dimension problem

@&#ABSTRACT@&#


               
               
                  The rectangle packing area minimization problem is a key sub-problem of floorplanning in VLSI design. This problem places a set of axis aligned two-dimensional rectangular items of given sizes onto a rectangular plane such that no two items overlap and the area of the enveloping rectangle is minimized. This paper presents a dynamic reduction algorithm that transforms an instance of the original problem to a series of instances of the rectangle packing problem by dynamically determining the dimensions of the enveloping rectangle. We define an injury degree to evaluate the possible negative impact for candidate placements, and we propose a least injury first approach for solving the rectangle packing problem. Next, we incorporate a compacting approach to compact the resulting layout by alternatively moving the items left and down toward a bottom-left corner such that we may obtain a smaller enveloping rectangle. We also show the feasibility, compactness, non-inferiority, and halting properties of the compacting approach. Comprehensive experiments were conducted on 11 MCNC and GSRC benchmarks and 28 instances reported in the literature. The experimental results show the high efficiency and effectiveness of the proposed dynamic reduction algorithm, especially on large-scale instances with hundreds of items.
               
            

@&#INTRODUCTION@&#

The rectangle packing area minimization problem (RPAMP) is an NP-hard problem. It aims to place all the axis-aligned rectangular items of known sizes onto a plane completely and without overlapping to minimize the area of the enveloping rectangle. As a subproblem of floorplanning, the RPAMP has important applications in the area of VLSI design. For the floorplanning problem, we are given a set of rectangular modules and a net list specifying the interconnections among the modules. The goal is to find a feasible layout the same as RPAMP, such that the area of the enveloping rectangle and the total length of the interconnections among the modules is minimized.

Basically, there are two main approaches to the RPAMP: (1) a heuristic searching method based on layout representations and (2) a reduction method that transforms an instance of the RPAMP to a series of instances of the strip packing problem (SPP) or the rectangle packing problem (RPP). The RPAMP is a two-variable open dimension problem (Wäscher et al., 2007), while the SPP and the RPP are a one-variable open dimension problem and a two-dimensional (2D) knapsack problem. In addition to the searching method and the reduction method, other methods such as branch and bound (Chan and Markov, 2004), linear optimization (Kim and Kim, 2003) are also used to solve the RPAMP.

Layout representation is one of the most important techniques used in the first approach, as it determines the size of the searching space and the complexity of transformation between a representation and the corresponding layout. Layout representation can be classified into slicing representation and nonslicing representation. The layout coded by slicing representation should satisfy guillotine cutting, so slicing representation may miss optimal layouts; meanwhile, nonslicing representation can cover all the optimal layouts. Hence it is commonly believed that nonslicing representation can yield better results than slicing representation.

Numerous representations have been put forward in the past two decades, and there are four classical nonslicing representations. Murata et al. (1996) proposed a sequence pair representation that used two sequences to represent the geometric relation of the items, placed the items on a grid structure, and constructed the corresponding constraint graphs to evaluate the objective function. Lin and Chang (2005) presented a transitive constraint graph (TCG) by using two transitive closure graphs to identify the geometric relation of the items. TCG is equivalent to sequence pair because they share the same O((n!)2) solution space and there is a bijective mapping between them. Two representations based on tree structure, O-tree (Guo et al., 1999) and B*-tree (Chang et al., 2000), are the most widely used representations, because their solution space is in the size of O(n!22n − 2/n
                     1.5), which is the lowest complexity reported in the literature. B*-tree uses a binary ordered tree, while O-tree uses an ordered tree with an arbitrary vertex degree. Therefore, B*-tree is faster and easier to implement. Chang et al. (2000) presented the comparisons and analyses on different representations.

Simulated annealing (SA; Chen and Chang, 2006; Chen and Yoshimura, 2008; Chen et al., 2011; Pisinger, 2007) is the most popular searching strategy for the RPAMP, while memetic algorithm (MA; Tang and Yao, 2007), particle swarm optimization (PSO; Chen et al., 2010) and local search (Imahori et al., 2005; Li et al., 2010) have also been adopted by researchers. To reduce the searching complexity of SA, Fast-SA (Chen and Chang, 2006) integrated a random search with hill-climbing that divided the annealing process into three stages: the high-temperature random search stage, the pseudo-greedy local search stage, and the hill-climbing search stage. By enumerating all the possible inserted positions in the sequence pairs for a selected item, Chen and Yoshimura (2008) applied an insertion after remove (IAR) method to accelerate the SA. Chen et al. (2011) presented a hybrid simulated annealing (HSA) method based on a new operation on B*-tree. Tang and Yao (2007) proposed a memetic algorithm (MA) that used an effective genetic search method to explore the search space and an efficient local search method to exploit information in the search region.

The main idea of the second approach is to construct a set of candidate widths or heights of the enveloping rectangle to transform an RPAMP instance into a series of instances of the RPP or the SPP and then to design algorithms for the RPP and the SPP. Because various reduction methods adopt similar approaches to constructing candidate dimensions of the enveloping rectangle, the design of the reduction method focuses on seeking efficient RPP and SPP algorithms. By combining an improved least flexibility first principle and a greedy search, Wu and Chan (2005) introduced a deterministic optimization algorithm for the RPP. Based on the conceptions of corner action and smooth degree, He et al. (2012) proposed a best fit algorithm (BFA) for the RPP. Bortfeldt and Gehring (2001) proposed a hybrid genetic algorithm to generate layout with a layer-type structure for the RPP. To solve the SPP, (Leung et al., 2011) suggested a two-stage intelligent search algorithm that first constructed a solution greedily, then improved the solution by a local search and a simulated annealing algorithm. Bortfeldt (2006) introduced a layer building method best fit decreasing height* (BFDH*) algorithm, which worked without any encoding of solutions, but fully defined layouts are manipulated by means of specific genetic operators.

In this paper, we develop a dynamic reduction algorithm (DRA) for the RPAMP. First, DRA uses a constructive method (Bortfeldt, 2013) to generate a set of candidate widths for the enveloping rectangle and initializes a promising filling rate (the filling rate = the area of all the placed items divided by the area of the enveloping rectangle). Then, at each iteration, it constructs an RPP instance based on the current width dynamically selected from the candidate widths and current promising filling rate. Then, it uses a least injury first (LIF) algorithm, which is an algorithm developed from the BFA (He et al., 2012), to calculate the generated RPP instance. If LIF can place all the items on the enveloping rectangle, then we move all the items toward the left and bottom iteratively to adjust the obtained layout to a compact one. This process is repeated until the promising filling rate can no longer be improved. Fig. 1
                     shows the flow chart of LIF.

We implemented DRA and tested it on 11 MCNC (Microelectronic Center of North Carolina) and GSRC (Gigascale Systems Research Center) benchmarks and four other RPAMP benchmarks proposed by Imahori et al. (2005). The experimental results showed that DRA renovated the current best results on eight instances. At the same time it also matched the current best results on the other three instances. Then, we ran DRA on 24 RPAMP instances proposed by Bortfeldt (2013), and DRA renovated results on 10 of 12 instances having 200 items.


The subsequent sections are organized as follows. Section 2 gives a formal statement on the problem definition. Section 3 introduces the LIF algorithm. Section 4 describes the compacting algorithm, and DRA is introduced in detail in Section 5. Empirical studies on the DRA are presented in Section 6, and the conclusions are presented in the end.

Given a set of n rectangular items with each item i (1 ≤ i ≤ n) having width wi
                      and height hi
                     , the RPAMP requires determining a feasible arrangement of all the items on a larger rectangular plane with variable dimensions. The objective is to minimize the area of the enveloping rectangle (hereafter abbreviated as sheet). Let the sheet be embedded in the first quadrant of a 2D Cartesian reference frame in such a way that the bottom-left vertex coincides with the origin. For each item i, let (x
                     
                        i1, y
                     
                        i1) and (x
                     
                        i2, y
                     
                        i2) denote the coordinates of the bottom-left and upper-right vertexes, respectively. Let width wc
                      and height hc
                      represent the two dimensions of the sheet. Then, RPAMP can be formulated as follows:

min wchc
                     
                  


                     s.t.
                     
                        
                           (1)
                           (x
                              
                                 i2 − x
                              
                                 i1, y
                              
                                 i2 − y
                              
                                 i1) ∈ {(wi, hi
                              ), (hi, wi
                              )}

max(x
                              
                                 i1 − x
                              
                                 j2, x
                              
                                 j1 − x
                              
                                 i2, y
                              
                                 i1 − y
                              
                                 j2, y
                              
                                 j1 − y
                              
                                 i2) ≥ 0

0 ≤ xik
                               ≤ wc
                              , 0 ≤ yik
                               ≤ hc, k ∈ {1, 2}

In constraints (1)–(3), i, j apply to 1, 2, …, n and i ≠ j. Constraint (1) implies that each item should be placed orthogonally on the sheet; constraint (2) indicates that no overlap occurs between any two items; and constraint (3) means all the items are placed completely on the sheet.

According to the typology of cutting and packing problems (Wäscher et al., 2007), the RPAMP is an open dimension problem, while the RPP is a single 2D knapsack problem (SKP). Given a set of n rectangular items with fixed dimensions and a rectangular sheet with fixed dimensions, the objective of the RPP is to place as many items as possible onto the sheet to maximize the filling rate of the sheet, and all the placed items should satisfy the same three constraints of the RPAMP.

This section presents a least injury first (LIF) algorithm to address the rectangle packing problem (RPP). LIF is developed from the best fit algorithm (BFA; He et al., 2012), a greedy construction method; the main difference between them is the greedy rules. BFA defines the conception of the action space such that it describes the remaining empty space not occupied at the current step of the construction procedure. At each step, it gives priority to the placement that fills one action space as much as possible and leaves the remaining spaces to be as smooth as possible. LIF adopts the conception of the action space in BFA. Meanwhile, it proposes virtual degree parameter to evaluate placements based on the corners they occupied; it uses match degree parameter to predict the impact of different placements on their follow-up placements; finally, it suggests a conception of injury degree for the greedy strategy. In this section, we first provide definitions for the greedy strategy. Then, we present a basic algorithm LIF0, and introduce an enhanced algorithm LIF1 based on a tree search strategy.

At the current iteration, if we can feasibly place a dummy rectangular item on the sheet, and the item is sufficiently large such that each edge is overlap with at least one edge of the placed items or of the sheet, then the space occupied by the dummy item is called an action space.

For example, Fig. 2
                           (a) marks an action space a at the current iteration, which has four corners. We then further classify the corners into two categories.

A corner is called a real corner if it is formed by edges of other placed items or of the sheet; otherwise, it is a virtual corner.

For example, in Fig. 2(a), the upper-left corner of action space a is a real corner, while the other three corners of a are virtual corners.

At the current iteration, a corner action is an action that feasibly places an item into a corner of an action space such that one vertex of the item coincides with one corner of the space. If the item can not move through either of the two edges of the corner feasibly, then it is a real corner action, otherwise, it is a virtual corner action.

For example, Fig. 2(b) shows a virtual corner action, while Fig. 2(c) shows a real one.


The similarity degree determines the size similarity of an action space and an item. It is set to 1 if both of their edges have the same length. Its value is 2 if one of their edges has the same length, while the other edge of the action space is larger than that of the item. Otherwise, it is set to 3.

The injury degree of a corner action is defined as a quintuple variable Di
                            = 〈pi, ni, ci, vi, mi
                           〉

                              
                                 (1)
                                 Non-paste number pi
                                     refers to the number of edges (of the item being placed) that are not pasted by the current action space (two items are considered pasted if they have edges overlapping with each other).

The remaining action space number ni
                                     refers to the number of action spaces in the remaining space after the corner action has been implemented.

Corner priority ci
                                     is set to 1 if the item being placed occupies the bottom-left or bottom-right corner of the action space, otherwise it is 2.

Virtual degree vi
                                     is set to 1 if the occupied corner is a real corner; it is set to 2 if the occupied corner is a virtual corner and the corner action is a real corner action; it is set to 3 if the corner action is a virtual corner action.

Assume that the corner action has been implemented. Then, at least one action space is consumed, and 0 to multiple new action spaces may be generated. Match degree mi
                                     indicates the best size similarity of the new generated action spaces and the unplaced items. If at least one new action space is generated, then mi
                                     is set to the minimum similarity degree of all the new generated action spaces and unplaced items, otherwise it is set to 1.

Two injury degrees are compared in lexicographical order. The smaller the injury degree, the better the placement. Here, the non-paste number directly reflects the compactness between the item being placed and the current action space. The remaining action space number and the corner priority measure the smoothness of the remaining space by a general overview, where the former gives priority to the action whose remaining space is smoother, and the latter gives priority to the lower placement. The virtual degree reflects the smoothness of the local remaining space, and the match degree gives a forecast of the follow-up placements.

The basic algorithm LIF0 is a greedy construction method. Initially, it generates an action space list with only one action space coinciding with the sheet. Then, it places items iteratively onto the sheet by performing a corner action with the least injury degree, and it updates the action space list until a terminate pattern (the pattern in which all items have been placed or none of the remaining items can be placed is named a terminate pattern; otherwise, it is an intermediate pattern) is obtained. The pseudo-code of LIF0 is described in Algorithm 1
                        .

Herein, ↑ assigns priority to the larger value, whereas ↓ does the reverse. To update the action space list, we first remove action spaces that overlap with the item being placed, and find 0–4 new generated action spaces for each removed action space. We then insert the new generated action spaces not completely contained by other action spaces into the action space list. The main difference between the constructive BFA (He et al., 2012) and LIF0 is the way they evaluate the corner actions.



                        Fig. 3
                        illustrates an example of LIF0. Six items intended to be placed on a 4 × 4 sheet are shown in Fig. 3(a). In Fig. 3(b), a corner action is implemented as it has the least match degree. Then by comparing the remaining action space number, another corner action is performed as shown in Fig. 3(c). Because the corner action has less non-paste numbers to be given priority, two corner actions as shown in Fig. 3(d) and (e) are implemented sequentially. Finally, by placing an item with larger area, the layout obtained by LIF0 is given, as displayed in Fig. 3(f).

LIF1 is also an iterative construction method. Different from LIF0, LIF1 uses a tree search strategy to select a corner action to be executed to obtain the next level pattern. At each iteration, LIF1 first selects the first N candidate corner actions having a lesser injury degree, and then it pseudo executes them to obtain intermediate patterns and continues to pseudo execute LIF0 to obtain terminate patterns. As shown in Fig. 4
                        , the four circular nodes at the second level are intermediate patterns after pseudo executing four selected candidate corner actions, and the nodes drawn in a dashed line denote patterns generated by LIF0. In this way, each of the N candidate corner actions corresponds to a terminate pattern (the rectangular node drawn in a dashed line in Fig. 4), and we can calculate the filling rate of the terminate patterns to evaluate the N candidate corner actions. Finally, the candidate corner action with the highest filling rate is selected. The pseudo-code of LIF1 is in Algorithm 2
                        , where k, lowerbound and upperbound are parameters used to set an appropriate N.



                        Fig. 5
                        illustrates an example of LIF1. Six items intended to be placed on a 4 × 4 sheet are shown in Fig. 5(a). Fig. 5(b) shows the corner action implemented at the first step, whose corresponding terminate pattern as shown in Fig. 3(f) has a filling rate 87.5 percent larger than that of any other candidate corner action. Then four corner actions are implemented sequentially as shown in Fig. 5(c)–(f), as they all have a corresponding terminate pattern as shown in Fig. 5(f), whose filling rate is 100 percent.


By analyzing the number of action spaces and the time complexity of calculating the injury degree, we have proved that the time complexities of LIF0 and LIF1 are O(n
                        9) and O(n
                        10), respectively (for a detailed analysis, the readers are referred to Appendix A).

For a given feasible layout, the compacting algorithm (CA) moves all items toward the left and bottom iteratively, and it transforms the layout to a compact one whose enveloping rectangle sheet is no larger than that of the former. A layout is called compact if and only if the bottom and left edges of each item are pasted by other items or by one edge of the sheet, in other words, each item occupies a bottom-left corner.

For a given layout with n items, regard the two horizontal edges of the sheet as two dummy items with zero height, and regard the two vertical edges of the sheet as two dummy items with zero width. Then we can relate the layout with two digraphs Gh
                        (V, Eh
                        ) and Gv
                        (V, Ev
                        ).


                        Gh
                         (Gv
                        ) can be derived from a layout as follows. First, introduce a node ni
                         for each item i (i ∈ {1, …, n}) in the layout, and generate two nodes ns
                         and nt
                         to represent the left (bottom) and right (upper) boundaries of the sheet respectively. Second, add an edge 〈ni, nj
                        〉 in Gh
                         (Gv
                        ) if and only if i is on the left (bottom) side of j and their projections on the y-axis (x-axis) are overlapped. Finally, assign each edge 〈ni, nj
                        〉 a weight equaling the width (height) of item i.

An item is a bottom-left occupied item, if and only if its bottom and left edges are pasted by two other items and these two items are both bottom-left occupied items as well. The bottom and left edges of the sheet are two initialized bottom-left occupied items. Basing on the above definition, the nodes in the constraint graph can be classified into three categories: a stable node which corresponds to the bottom-left occupied item; a critical node whose precursor nodes are all stable nodes; or, otherwise, an unstable node.

For example, Fig. 6
                        (b) and (c) show the Gh
                         and Gv
                         for the layout in Fig. 6(a). Transitive edges are not drawn for simplicity. In Fig. 6(b), na
                         and nc
                         are stable nodes, nb
                         and nd
                         are critical nodes, and ne
                         is an unstable node. In Fig. 6(c), na
                         and nc
                         are stable nodes, nb
                         and ne
                         are critical nodes, and nd
                         is an unstable node.


The compacting algorithm (CA) compacts a layout by executing left-move and down-move actions alternatively. To move items toward the left, CA first constructs a Gh
                         for the current layout. Then it carries out a topological sorting on the Gh
                        , and for each item i, it calculates the weight of the longest path from ns
                         to ni
                        , which will be its x-coordinate of the bottom-left corner after the move action is completed. Similarly, we can compute the y-coordinate of each item after a down-move action. CA keeps executing the above move procedures until two consecutive actions no longer move any items. In the end, the width and height of the enveloping rectangle equal the weights of the longest path from ns
                         to nt
                         in Gh
                         and Gv
                        , respectively. The pseudo-code of CA is shown in Algorithm 3
                        .


                        Fig. 7
                        illustrates an example for CA. Given a layout in Fig. 7(a), Fig. 7(b) is the temporary pattern after a left-move action, where the left edges of all the items are pasted with other items or the edge of the sheet. Then, a down-move action is implemented to move all the items toward bottom as shown in Fig. 7(c). Finally, the compact layout shown in Fig. 7(d) is obtained by executing another left-move action.


For each item i, let (xi, yi
                        ) denotes its coordinate of the bottom-left vertex after a move action. Suppose the longest path from ns
                         to ni
                         in a constraint graph is (
                           
                              
                                 n
                                 s
                              
                              ,
                              
                                 n
                                 
                                    j
                                    1
                                 
                              
                              ,
                              …
                              ,
                              
                                 n
                                 
                                    j
                                    k
                                 
                              
                              ,
                              
                                 n
                                 i
                              
                           
                        ) and its weight is Li
                        . We obtain the following properties of the algorithm.

                           Property 1
                           
                              Starting from any feasible layout, the layout obtained by CA is still feasible.
                           

We only need to show that the layout is feasible after performing each move action. Without loss of generality, we discuss the left-move action.

For any two items i and j, if there is no edge connecting them in the current Gh
                              , then they do not overlap on the y-axis projection and would not overlap after performing a left-move action. Otherwise, if there is an edge 〈ni, nj
                              〉 in Gh
                              , let M = {k|〈nk, nj
                              〉 ∈ Eh
                              }, then

                                 
                                    
                                       
                                          
                                             x
                                             j
                                          
                                          =
                                          
                                             L
                                             j
                                          
                                          =
                                          
                                             max
                                             
                                                k
                                                ∈
                                                M
                                             
                                          
                                          
                                             (
                                             
                                                L
                                                k
                                             
                                             +
                                             
                                                w
                                                k
                                             
                                             )
                                          
                                          =
                                          
                                             max
                                             
                                                k
                                                ∈
                                                M
                                             
                                          
                                          
                                             (
                                             
                                                x
                                                k
                                             
                                             +
                                             
                                                w
                                                k
                                             
                                             )
                                          
                                       
                                    
                                 
                              Thus xj
                               ≥ xi
                               + wi
                              , indicating that items i and j do not overlap after performing a left-move action.□


                              The layout obtained by CA is compact.
                           

With the notation that 
                                 
                                    (
                                    
                                       n
                                       s
                                    
                                    ,
                                    
                                       n
                                       
                                          j
                                          1
                                       
                                    
                                    ,
                                    …
                                    ,
                                    
                                       n
                                       
                                          j
                                          k
                                       
                                    
                                    ,
                                    
                                       n
                                       i
                                    
                                    )
                                 
                               is the longest path from ns
                               to ni
                              , 
                                 
                                    (
                                    
                                       n
                                       s
                                    
                                    ,
                                    
                                       n
                                       
                                          j
                                          1
                                       
                                    
                                    ,
                                    …
                                    
                                       n
                                       
                                          j
                                          k
                                       
                                    
                                    )
                                 
                               is also the longest path from ns
                               to 
                                 
                                    n
                                    
                                       j
                                       k
                                    
                                 
                              . Thus

                                 
                                    
                                       
                                          
                                             x
                                             i
                                          
                                          =
                                          
                                             L
                                             i
                                          
                                          =
                                          
                                             ∑
                                             
                                                l
                                                =
                                                1
                                             
                                             k
                                          
                                          
                                             w
                                             
                                                j
                                                l
                                             
                                          
                                          
                                          and
                                          
                                          
                                             x
                                             
                                                j
                                                k
                                             
                                          
                                          =
                                          
                                             L
                                             
                                                j
                                                k
                                             
                                          
                                          =
                                          
                                             ∑
                                             
                                                l
                                                =
                                                1
                                             
                                             
                                                k
                                                −
                                                1
                                             
                                          
                                          
                                             w
                                             
                                                j
                                                l
                                             
                                          
                                       
                                    
                                 
                              
                           

Therefore, 
                                 
                                    
                                       x
                                       i
                                    
                                    =
                                    
                                       x
                                       
                                          j
                                          k
                                       
                                    
                                    +
                                    
                                       w
                                       
                                          i
                                          k
                                       
                                    
                                    ,
                                 
                               moreover the y-axis projections of jk
                               and i are overlapped, therefore, the left edge of item i is pasted by item jk
                              , which means the left edges of all the n items are pasted by other items after performing a left-move action. Similarly, the bottom edges of all the n items are pasted by other items after performing a down-move action. Therefore, each item occupies a bottom-left corner while two consecutive actions cannot move any items.□


                              The layout obtained by CA is no worse than the input layout.
                           

It is easy to see that CA only moves items toward the left and bottom.

                           Property 4
                           
                              CA halts in finite steps and the time complexity is O(n
                              6).
                           

After performing a left-move action, the left edges of all the critical nodes are pasted by the bottom-left occupied items. Let ni
                               denotes the critical node that has the least y-coordinate among all the critical nodes in the Gh
                              . Then the bottom edge of ni
                               would be pasted by bottom-left occupied items by subsequently executing a down-move action. Obviously, its bottom edge would not be pasted by any other critical node after executing a down-move action. For the unstable nodes, suppose there is a node nk
                               pasted the bottom edge of ni
                              , which means nk
                               is on the bottom of ni
                               and that their projections on the x-axis are overlapped. According to the definition of an unstable node, there exists a path (nj
                              , …, np
                              , …, nk
                              ) in the Gh
                               where nj
                               is a critical node. Because yj
                               ≥ yi, yk
                               + hk
                               ≤ yi
                               and the projections on the y-axis are overlapped for any two adjacent nodes in the path, there must be a node np
                               in the path, whose projection on the y-axis overlaps that of ni
                               and is positioned on the left of ni
                              , which contradict that ni
                               is a critical node. Therefore, ni
                               occupies a bottom-left corner that is constructed by two bottom-left occupied items after executing two sequential actions, and it might be turned into a bottom-left occupied item; or would be moved out from the bottom-left corner by executing another left-move action (as shown in Fig. 7(c) and (d), item c is moved out from a bottom-left corner).

Above all, an iteration of CA can move at least one item into a bottom-left corner, and it would not be the same item and bottom-left corner for any two different iterations. Because there are O(n
                              2) bottom-left corners (each pair of items can construct at most one bottom-left corner), it takes O(n
                              3) iterations to turn an item into a bottom-left occupied one, and because the complexity of constructing a constraint graph is O(n
                              2), CA would halt in O(n
                              6).□

By adopting a method of constructing the dimensions of the sheet dynamically, as suggested by Bortfeldt (2013), the dynamic reduction algorithm (DRA) transforms an instance of the RPAMP to a series of instances of the RPP, and calculates the generated RPP instances by the LIF algorithm. In this section, we first present the method to generate candidate widths for the sheet and then introduce the DRA in detail.


                        Bortfeldt (2013) proposed three variants of greedy strategies to generate candidate widths of the sheet. We adopt the third variant WV3 in the DRA. In WV3, a width combination for value w is defined as a set of dimensions of different items up to nc
                         summing up to w. Then, there are 
                           
                              
                                 C
                                 n
                                 1
                              
                              +
                              
                                 2
                                 2
                              
                              
                                 C
                                 n
                                 2
                              
                              +
                              ⋯
                              +
                              
                                 2
                                 
                                    n
                                    c
                                 
                              
                              
                                 C
                                 n
                                 
                                    n
                                    c
                                 
                              
                           
                         different width combinations for n items. The frequency n(w) for width value w is the number of width combinations in which the sum of item dimensions equal w. We assume that the width value with higher frequency would lead to higher quality solutions. By enumerating all the possible width values and sorting them in descending order by their frequencies, we can choose the first l values as candidate widths.


The layouts for the first l = 2 candidate widths are illustrated in Fig. 8
                        for an RPAMP instance with four items. If nc
                         is set to two, then the first two candidate widths are nine and eight, whose frequencies are six and four respectively. Their best possible solutions are shown in Fig. 8(b) and (c), respectively. The filling rate of the enveloping rectangle sheet in Fig. 8(b) is larger than that in Fig. 8(c).

DRA first determines a series of candidate widths, and initializes a promising filling rate (such as 50 percent). Then, at each step, DRA constructs an RPP instance based on the promising filling rate and the current width, and obtains a layout X by LIF0 or LIF1. If all items have been placed on the sheet, then DRA compacts X by CA and obtains a compact layout X′. It may update the current best layout if the filling rate of X′ is higher than the best filling rate obtained so far. Then, at the end of each iteration, DRA updates the promising filling rate and the current width. The above process is repeated until the current width is the last candidate width and the promising filling rate cannot be improved any more. In addition, if n lies in interval [100, 200], then a postprocessing will be carried out. In this postprocessing, the promising filling rate is initialized as the best promising filling rate obtained by the preceding process, and the sheet width is fixed as the corresponding candidate width. The same as the preceding process, the postprocessing then tries to improve the promising filling rate by iteratively constructing RPP instances and handling them with LIF1 and CA. The postprocessing halts when the promising filling rate cannot be improved any more.

The pseudo-code of DRA is as shown in Algorithm 4
                        , where fr(X) denotes the filling rate of layout X, and frbest and L
                        best denote the current best filling rate and the corresponding layout. We also use a list I(1, …, m) (like I = (0.1, 0.05.0.02.0.005, 0.001)) to save possible increment ▵ of the filling rate in descending order. Which LIF version is used is marked. If the instance contains less than 100 items, then LIF1 is used; if the scale of items lies in interval [100, 200], then LIF0 is used to select a sheet width from all the generated candidate widths in the first process, and LIF1 is used in the postprocessing; if the instance contains more than 200 items, then LIF0 is used.

We need to compute the packing layout each time when we increase the promising filling rate by ▵. If ▵ is too small, then there are too many unnecessary computations. However, if ▵ is too large, then we cannot find a feasible layout for the current sheet and we waste computing time. Thus, in performing the computation, ▵ is set to be sufficiently large that it is highly possible to find a feasible layout.

Both DRA and Bortfeldt (2013) belong to the second method for the RPAMP, where constructing dimensions of the sheet and algorithm for the RPP or the SPP are two core techniques. The differences between DRA and Bortfeldt (2013) are as follows. First, the algorithms they used to solve RPP or SPP instance are different. Bortfeldt (2013) used two algorithms (Bortfeldt and Gehring, 2001; Fanslau and Bortfeldt, 2010) for the RPP and one algorithm (Bortfeldt, 2006) for the SPP. However, DRA adapted an LIF algorithm for the RPP, which is based on our definition of injury degree. Second Bortfeldt (2013) subsequently utilized the generated candidate widths to improve the promising filling rate with an RPP or SPP algorithm; while dividing LIF into two ranks: LIF0 and LIF1. To address instances having the scale of items lying within [100, 200], DRA first utilized LIF0 to select a promising width from all the candidate widths, and then utilized LIF1 to calculate the promising width. Third, DRA adopted a compacting algorithm to compact the RPAMP layout obtained by LIF.

@&#EXPERIMENTAL RESULTS@&#

We implemented DRA in the C++ programming language on an AMD Athlon personal computer with 3.01 gigahertz and 2.0 gigabytes RAM (Windows XP environment), and we compared its performance with several representative algorithms published in the literature. To compare the performance of LIF and BFA, we also implemented the algorithm DRA*, which replaces LIF with BFA in DRA. We used two classic VLSI floorplanning benchmarks MCNC and GSRC, and 28 RPAMP benchmarks proposed by Imahori et al. (2005) and Bortfeldt (2013).

In LIF1, the values of k, lowerbound and upperbound are set as 25, 60 and 100 respectively. In DRA, the values of fr and m are set as 0.5 and 5 respectively, I(5) = (0.100, 0.050, 0.020, 0.005, 0.001), and nc
                      is set to 2 and 4 to select the first 50 candidate widths, respectively. Thus, we have l = 100 candidate widths for the computation.

We compare DRA with six representative algorithms for the RPAMP: a simulated annealing algorithm Pisinger (2007), two local search algorithms Imahori et al. (2005) and Li et al. (2010), two reduction algorithms Wu and Chan (2005) and Bortfeldt (2013), and a branch and bound algorithm Chan and Markov (2004). Bortfeldt (2013) observes the guillotine cutting constraint, while others do not. To date, Bortfeldt (2013) has computed most of the RPAMP instances and has achieved the current best results in general.

The results of the comparison are presented in Tables 1
                        and 2. The first two columns of Table 1
                        show 15 instances to be compared, among which Apte to Ami49 belong to MCNC, N10 to N300 belong to GSRC, and Rp100 to Pcb500 were proposed by Imahori et al. (2005). The following six columns of Table 1 are dedicated to the selected methods. The best filling rate for each instance achieved by the appropriate method is illustrated, and the running time of Bortfeldt (2013) is also illustrated. As an exception Imahori et al. (2005) only presents the average values over ten runs per instance. In the antepenultimate column, the highest filling rate published so far are collected. The DRA results are shown in the penultimate column, where new highest filling rate appears in bold. Table 2 shows the results of Bortfeldt (2013) and DRA on 24 RPAMP instances proposed by Bortfeldt (2013), where the first 12 instances and the second 12 instances are used to test the algorithms’ performances on small-scale and large-scale instances, respectively.

For the first set of 15 instances, Table 1 shows that DRA renovated the current best solutions on eight instances which contain four famous MCNC and GSRC instances. At the same time it also matched the current best solutions on three other instances. For the seven instances with no less than 100 items, DRA renovated the current best solutions on six instances. Moreover, DRA improved the current best average filling rate by 0.09 percent. For the second set of 24 instances, Table 2 illustrates that DRA renovated the current best solutions on 13 instances including three instances with 50 items and 10 instances with 200 items. Moreover, for the 12 instances with 200 items, DRA improved the average filling rate by 0.14 percent. Above all, DRA works very well on RPAMP, especially on large-scale instances with hundreds of items.


In Table 1, we only present the running time of Bortfeldt (2013), as it is the only algorithm that computed all the benchmarks, and its computational environment (implemented in the C programming language and tested on an AMD Athlon personal computer with 2.61 gigahertz, 2.0 gigabytes RAM and Windows XP) is similar to ours. Table 1 and 2 show that the average running time of DRA is approximately half that of Bortfeldt (2013).

The layouts obtained by DRA for instances Ami49 and N30 are plotted in Fig. 9
                        and Fig. 10
                        , respectively. We rotate the layout by 90 degrees for convenient display. The layout for Ami49 has a width of 2192 and a height of 12,348, and the layout for N30 has a width of 325 and a height of 626. All the new obtained layouts can be download at the following web link (https://www.dropbox.com/s/c9f7rt37josw25k/new%20obtained%20layout.rar
).

To compare the performance of LIF and BFA, we replaced LIF0 and LIF1 with BFA0 (constructive stage) and BFA1 (tree search stage) He et al. (2012) in DRA respectively and we obtained an algorithm DRA*. Then we implemented it in the same programming language on the same platform for a fair comparison. The same as LIF1, BFA1 also has three parameters k, lowerbound, and upperbound to select the appropriate number of corner actions at each step, and we set them to 25, 100 and 150 respectively for BFA1 in the experiments. The other parameters in DRA* are set the same as that in DRA. The results of DRA* are presented in the last columns of Tables 1 and 2.


For the first set of 15 instances, Table 1 shows that DRA obtained better solutions on 12 out 15 instances, and matched the solutions on two other instances. The average filling rate of DRA is 0.38 percent higher than that of DRA*. For the second set of 24 instances, Table 2 illustrates that DRA obtained better solutions on 17 out 24 instances. The average filling rates for the 12 instances with 50 items and the 12 instances with 200 items obtained by DRA are 0.05 percent and 0.42 percent higher than that of DRA*, respectively. Meanwhile, the average running time of DRA is approximately one third that for DRA*.

LIF outperforms BFA for the following reasons. First, by defining the conception of virtual degree, LIF further refines the corner action. Second, according to the characters of the candidate widths (generated by summing up a set of dimensions of different items), LIF uses a match degree to make a forecast for the follow-up placements. Third, to evaluate a corner action, BFA computes the number of other-pasted items (i.e., the number of other placed items pasted with the item being placed), which is a time-consuming process, while LIF does not.

@&#CONCLUSION@&#

This paper presents a dynamic reduction algorithm (DRA) for the rectangle packing area minimization problem (RPAMP). By dynamically designing the two dimensions of the sheet, DRA reduces an RPAMP instance to a series of RPP instances. Then, we define an injury degree to evaluate different placements such that the corner action with the least injury for the remaining space and follow-up placement has a higher priority, and we design a least injury first (LIF) algorithm to solve the generated RPP instances. For each RPAMP layout obtained by LIF, a compacting algorithm (CA) is enforced to obtain a compact layout, where each item occupies a bottom-left corner. We also showed the feasibility, compactness, non-inferiority and halting of the CA whose time complexity is O(n
                     6). Experimental results showed the high effectiveness of the proposed DRA, especially on large-scale benchmarks with hundreds of items.

This section presents the worst-case and best-case time complexities of LIF.

                        
                           1.
                           
                              The worst-case complexity of LIF
                           

To analyze the worst-case complexity of LIF, we first analyze the number of action spaces in the pattern and the time complexity of calculating the injury degree.

                        
                           (1)
                           
                              Analysis of the action space
                           

Given a pattern with n items, the sheet can be partitioned into O(n
                     2) blocks by the extension cords of the edges of all the placed items. The segment of the sheet’s edges, which is partitioned by the extension cords, that can not be divided any more is defined as one unit. Fig. A1
                     (a) shows a divided pattern and marks one unit.

Given the bottom-left corner (i units, j units) of a block, we can construct at most one action space that has height k units (1 ≤ k ≤ 2n) correspondingly. The construction process is as follows. First set a parameter l to 0 units. Then, iteratively add 1 unit to l until the segment (l + i units, j units) − −(l + i units, j + k units) overlaps with some edges of the placed items or of the sheet. If the segment (i units, j + k units) − −(l + i units, j + k units) overlaps with some edges of placed items or of the sheet at the same time, then an action space with width l is constructed; otherwise, there is no action space that has height k units. Fig. A1(a) marks a bottom-left corner a, and Fig. A1(b) and (c) illustrates that the corresponding action spaces have height of 2 units and 5 units, respectively.


The total number of action spaces is O(n
                     3).

                        
                           (2)
                           
                              The analysis of injury degree
                           

Non-paste number pi: pi
                               refers to the number of edges (of the item being placed) that are not pasted by the current action space. Obviously, it can be calculated in O(1).

Remaining action space number ni
                              : for each action space that overlaps with the item being placed, four new blocks at most can be generated. For example, Fig. A2
                              (a) shows a corner action that places an item a on the sheet and an action space that overlaps with a. Fig. A2(b) and (c) marks the four new generated blocks. To determine whether a new generated block is an action space or not, it should take O(n) to check out whether all of its edges overlap with the edges of placed items or of the sheet. Because O(n
                              3) action spaces overlap with the item being placed, the time complexity of calculating the remaining action space numbers is O(n
                              4).

Corner priority ci
                              : it is easy to see that the time complexity of corner priority is O(1). The analyses for each of the five parameters in the injury degree are as follows.

Virtual degree vi
                              : the virtual degree can be determined by analyzing the overlaps among the items being placed and the action spaces. As shown in Fig. A3
                              (a), if there is an action space that completely contains the item being placed a, then the virtual degree is 3; it is 2 when there is an action space that only overlaps with the occupied corner as shown in Fig. A3(b); otherwise, it is 1. The time complexity of the virtual degree is O(n
                              3).

Match degree mi
                              : according to the analysis of the remaining action space number, there are O(n
                              3) new generated action spaces, therefore it should take O(n
                              4) to calculate the match degree.

Finally, the time complexity of calculating the injury degree is O(n
                     4).

                        
                           (3)
                           
                              The analysis of LIF
                           

In the LIF0, there are O(n) steps to place items on the sheet. At each step, it calculates the injury degree for O(n
                     4) corner actions, and selects a corner action with the least injury degree to implement. Thus, the time complexity of LIF0 is O(n
                     9).

In the LIF1, there are O(n) steps to place items on the sheet. At each step, it first calculates the injury degree for O(n
                     4) corner actions and then selects a constant number of candidate corner actions with less injury degrees to pseudo execute, and it continues to pseudo execute LIF0 to obtain terminate patterns. Therefore the time complexity of LIF1 is O(n
                     10).

                        
                           2.
                           
                              The best-case complexity of LIF
                           


                              The analysis of the action space
                           

The number of action spaces in the best-case is O(1) because LIF can construct the layout layer by layer with the items in each layer having equal height. as shown in Fig. A4
                     .

                        
                           (2)
                           
                              The analysis of injury degree
                           

Obviously, the best-case complexities of non-paste number pi
                     , corner priority ci
                      and virtual degree vi
                      are all O(1). Because we can determine whether a block that has been generated by action spaces that overlap with the item being placed, is an action space by checking whether it is completely contained by other action spaces, the complexity of the remaining action space number ni
                      is O(1). Moreover, because the process that compute a match degree halts, while a similarity degree equal to 1 is found, its complexity is O(1). Finally, the complexity of calculating the injury degree is O(1).

Because the number of action spaces is O(1) and the complexity of the injury degree is O(1), it is easy to see that the best-case complexities of LIF0 and LIF1 are O(n
                     2) and O(n
                     3) respectively.

By the above analysis, the number of action spaces is the key factor for the time complexity of LIF. The number of action spaces in the worst-case is O(n
                     3), and the corresponding time complexities of LIF0 and LIF1 are O(n
                     9) and O(n
                     10), respectively. However, the number of action spaces in the best case is O(1), and the corresponding time complexities of LIF0 and LIF1 are O(n
                     2) and O(n
                     3), respectively. As a heuristic algorithm, LIF selects actions having less injury for the follow-up placements, and it gives priority to corner actions with less remaining action spaces. Therefore, the actual time complexity of LIF is closer to the time complexity in the best case than to the time complexity in the worst case.

@&#REFERENCES@&#


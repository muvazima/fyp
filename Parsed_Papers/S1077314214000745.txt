@&#MAIN-TITLE@&#Active subclustering

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A novel algorithm is proposed for a new problem called subclustering.


                        
                        
                           
                           An active algorithm for subclustering (human in the loop) is also proposed.


                        
                        
                           
                           An evaluation criterion Subclustering Jaccard’s Coefficient is developed.


                        
                        
                           
                           Experiments on a face and a leaf image dataset are performed.


                        
                        
                           
                           Also a faster version of Partition Around Medoids clustering is proposed.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Subclustering

Clustering

Human in the loop

Active learning

Face images

Leaf images

Subclustering evaluation

@&#ABSTRACT@&#


               
               
                  Although there are many excellent clustering algorithms, effective clustering remains very challenging for large datasets that contain many classes. Image clustering presents further problems because automatically computed image distances are often noisy. We address these challenges in two ways. First, we propose a new algorithm to cluster a subset of the images only (we call this subclustering), which will produce a few examples from each class. Subclustering will produce smaller but purer clusters. Then we make use of human input in an active subclustering algorithm to further improve results. We run experiments on a face image dataset and a leaf image dataset and show that our proposed algorithms perform better than baseline methods.
               
            

@&#INTRODUCTION@&#

Humans often search for images in a large database. For example:
                        
                           •
                           Consider video surveillance data in airports. An analyst may want to search through the surveillance data to find out if person A was present in the airport on a particular day. She might have an image of A or textual descriptions of A. These can be used to perform image retrieval, but the results are often not good enough to guarantee that if A does not appear among the top retrieved images, A is not present in the database. That requires the analyst to exhaustively browse [1] through the database to determine whether A is present. Also retrieval results from an unlabeled database are often redundant as images of the same person may show up many times. However if we can create an organized collection of face images containing a few different images of each person present in the airport, it will be significantly easier for the analyst to browse them to detect the presence of A.

There has been interest recently in plant species identification (e.g.: Leafsnap [2–5]). These systems produce large collections of unlabeled images of organisms (e.g.: leaves in Leafsnap) uploaded by users. Biological enthusiasts are often interested in browsing the database to find a species of interest. In this scenario also, it is useful to create a leaf image collection from the unlabeled images that only contains a few images from each class present in the data, allowing easy browsing.

In both examples we start with a large collection of unlabeled images. These images can be clustered using traditional clustering algorithms [6–9] to facilitate browsing, allowing a user to examine meaningful subsets of images. Accurate clustering, though, is extremely difficult when there are a large number of clusters. Moreover, clustering based on automatically computed image distances inevitably produces errors, as current algorithms do not fully capture perceptual similarity.

To cope with this challenge, we introduce the idea of subclustering, in which we cluster only a small subset of images. Our goal is to create clusters that represent each object in the image set with a few images. For example, in the surveillance scenario, subclustering aims to create clusters containing a few images of each individual. Subclustering has the potential to produce more efficient algorithms, and to produce more accurate clusters by ignoring images that are hard to categorize.

We also assume that a modest amount of labeling effort can be obtained from humans to improve subclustering. Human input can take many forms. In this paper we abstract human input to the simple operation of providing constraints on whether or not two images come from the same class.
                        1
                        We will use classes/categories to imply the ground truth and clusters/subclusters to imply algorithms’ output throughout the paper.
                     
                     
                        1
                      This is a widely used assumption in active clustering 
                     [10–17]. It is a useful abstraction because often it is difficult for people to assign a label to an image (they may not be able to assign a name to a face in a surveillance video, or to a particular plant specimen), but much easier to assess whether two images come from the same class (humans can compare face images with 99% accuracy [18]). When class labels are available, they may be represented as sets of pairwise constraints.

Our two main contributions in this paper are:
                        
                           1.
                           We propose a new passive subclustering algorithm where no human input is required. We propose a cost function suitable for subclustering and optimize it with an algorithm motivated by the Partition Around Medoids (PAM) [7] algorithm. In experiments we show that our approach produces much better subclusters than those produced by several baseline algorithms. Our subclustering algorithm reduces run-time by 
                                 
                                    O
                                    (
                                    N
                                    )
                                 
                               compared to a similar complete clustering algorithm like PAM, where N is the total number of images in the dataset (Section 4).

We also propose a new active subclustering algorithm that uses pairwise constraints on the clusters. The algorithm repeatedly selects an image pair and asks a user whether they belong to the same category or not. Pairs of images are chosen such that existing errors in a subclustering are corrected with limited human interaction. In experiments we show that we can accurately subcluster a face image dataset with 51,418 images of 200 classes with around 143,000 pairwise constraints from humans (equivalent Mechanical Turk cost: $358). In general active algorithms for complete clustering require much more human supervision [10,17] and are often too slow to run on large scale datasets [16] (Section 5).

We run experiments in two different domains: face images (the complete Pubfig dataset [18]) and leaf images [2]. We show that our proposed algorithms perform much better than baseline algorithms. A pipeline of our proposed system for subclustering is depicted in Fig. 1
                     .

Clustering images has been an interesting problem for decades [9]. Although automatic clustering algorithms produce reasonable results for datasets with a few clusters, clustering datasets with a large number of clusters is still an open problem. Recently, active/semi-supervised clustering algorithms [10,16,17] where humans provide pairwise constraints (“must-link” and “can’t-link”), have produced much better clustering results. However, as the data size (number of images and classes) increases, the required number of pairwise constraints increases so much that human-in-the-loop clustering algorithms become impractical. Therefore we propose a new problem called subclustering. Subclustering aims to produce a clustering that contains n images from each category with 
                        
                           n
                           <
                           
                              
                                 N
                              
                              
                                 k
                              
                           
                        
                      (where 
                        
                           
                              
                                 N
                              
                              
                                 k
                              
                           
                        
                      is the actual number of instances of class k present in the full dataset). This will produce smaller but purer clusters and will require significantly less human input. Since large unlabeled image collections are highly prevalent these days subclustering can have a wide range of applications including browsing image databases, image search, summarizing image databases, category discovery, etc.

Input to a subclustering algorithm will include a pairwise distance matrix, the number of clusters and the number of images required (
                        
                           n
                           ⩾
                           1
                        
                     ) from each class. We emphasize that a subclustering algorithm’s goal is to extract any n images from each class. For large real world applications, where each class is expected to have many (more than 100) images, we find that 
                        
                           n
                           =
                           10
                        
                      is reasonable. It is not too large that subclustering becomes error-prone and also not too small that images from the same class do not show variation. In Fig. 2
                      we show some typical subclusters produced after using our passive and active algorithms. Although the number of examples from each class is small, they have enough intra-class variation that humans can determine how these people look and compare them to a new face image. We note that subclusters are not intended for training classifiers because they are small and may not represent the complete distribution of each class. Subclustering and its use for browsing large image databases is partially motivated by the fact that humans can learn reasonable object models even from a small set of examples [19].

Although it is possible to create subclusters from complete clusters, algorithms solely built to solve subclustering create purer subclusters. Intuitively it is clear that points that are difficult to cluster can affect the results of clustering algorithms in a way that degrades the clustering of easier points. That is, it is better to solve the problem we want to solve directly (subclustering), rather than trying to solve a harder problem (clustering) as an intermediate step.

@&#RELATED WORK@&#

As far as we know there is no previous work on subclustering. Perhaps the most similar work is Bregman Bubble Clustering proposed by Gupta et al. [20]. Their approach tries to find a robust and scalable clustering framework to find K dense clusters in the dataset, removing outliers. The authors in [21] propose a robust clustering algorithm that maximizes a total similarity objective function related to an approximate density shape estimation. However, these approaches show experimental results for a very small number of clusters. We implemented the BBC-S algorithm [20] but modified to our subclustering framework for comparison. The authors in [22] proposed a face annotation framework that involves partial clustering and interactive labeling. The partial clustering approach tries to model images that are not grouped tightly enough, using a uniform background noise distribution. However it is often hard to model these images, with only one uniform background distribution, especially if there are many classes. Note that our experiments are with 51,418 images from 200 clusters, where [22] uses only 1147 images from 34 clusters. The authors in [23] proposed a method for visual category discovery that focuses on the easiest examples first and then progressively expands its repertoire by including more complex objects. However this approach is initialized with a familiar set of category classifiers.

There are also a couple of recent works which try to enforce diversity in mixture models [24,25], such that mixture components do not represent redundant information. The authors in [26,27] proposed methods for discriminant analysis, where data from each class is represented by a mixture of Gaussians. These methods are useful when data from a single category belong to multiple clusters instead of a single cluster. Although these methods have shown to improve the classification results, finding the actual number of mixture components in each class still remains a difficult problem. Similar to these methods our approach also assumes that data from different categories do not form well-separated clusters, such that any single cluster will contain all the data points from a single category. However we note that our approach is developed for clustering problems, where no class labels are available. In subclustering instead of representing data from each category with multiple clusters, we find one small but dense group of points from each category.

Recently computer vision researchers have been interested in melding active learning [28,29] with computer vision. We will discuss a few recent works in this area. In [30], the authors propose a method for active selection of a batch of images for labeling using a SVM classifier where the total cost for labeling at each iteration is constrained by a predefined budget. The proposed method is shown to be useful for object recognition, activity recognition and image retrieval. The authors in [31] propose a method of training a large scale object detector in an active manner. The proposed algorithm iteratively poses annotation requests to humans and gathers relevant images for labeling from Flickr, where the true labels of the data are not known beforehand. In [32], the authors propose a method for active frame selection for labeling such that a video sequence is labeled (at the pixel level) with as little human input as possible. They propose two methods, one is a basic flow-based approach while the other is a more sophisticated approach that uses a flow model within a Markov Random Field [33]. Ref. [34] propose an interactive human-in-the-loop method for bird classification. Humans will answer simple questions on visual attributes of birds such that a bird can be classified with limited human interaction. In [35], the authors propose a method for large scale interactive learning of deformable part models [36]. The authors in [37] propose an active technique for learning appearance and contextual models for scene understanding simultaneously. This is the first multi-class active learning technique that takes contextual interactions between different parts of a scene image into account.

Active learning [29] for clustering by obtaining pairwise constraints has been a growing area of interest in recent years. Recently, Biswas et al. [16] proposed an algorithm that chooses an image pair for which the expected change in the overall clustering is maximal. Although their algorithm is effective for problems with a large number of clusters, it is not fast enough to scale to a dataset of size more than 1000. The problem of scalability comes from the fact that this algorithm exhaustively evaluates the effect of almost all possible (
                        
                           O
                           (
                           
                              
                                 N
                              
                              
                                 2
                              
                           
                           )
                        
                     ) pairwise constraints at each iteration. In earlier work, [10], Basu et al. also proposed an active clustering algorithm consisting of two major phases: “Explore” (this step initializes cluster centers using constraints) and “Consolidate” (data points are added to cluster centers). When the number of clusters is large, the “Explore” stage requires a large number of constraints. However this algorithm is fast and scalable to datasets with a large number of images but with only a few clusters. Mallapragada et al. [13] have proposed an approach that uses a min–max criterion to find informative questions. They rely on the “Explore” stage in the beginning as [10] does, with similar limitations. There are also a couple of active clustering algorithms [11,15] based on spectral eigenvectors, but they only apply to two-cluster problems. Very recently Xiong et al. [17] proposed an active spectral clustering algorithm with k-nearest neighbor graphs and that can be used for more than two-cluster problems. However their experiments only show results for small datasets with a few clusters. Huang et al. [12,14] also proposed a couple of approaches for clustering with constraints but with documents. It is not clear how we can adopt [14] for image clustering and [12] uses an “Explore” stage to build an initial skeleton structure, which we already know to be a potential problem when there are a large number of clusters.

Standard clustering algorithms usually perform a complete partition of the dataset. However, state of the art image features do not always map images to a space in which images from the same class remain close to each other and far from images from other classes. Consequently, standard clustering approaches [6–8], which optimize a cost function that takes into account all images, often end up with many impure clusters. In subclustering the cost function takes into account only a few examples from each class.

We formulate subclustering as a problem of maximizing the probability that all images in a cluster come from the same class, and that every pair of cluster centroids comes from a different class. Intuitively, this means that we want cluster centroids to be as far from each other as possible, while images assigned to each centroid should be as close to the centroid as possible in the feature space.

We now introduce some notation. We are given a set of N unlabeled images 
                           
                              U
                           
                         to be clustered into K clusters. 
                           
                              
                                 
                                    N
                                 
                                 
                                    k
                                 
                              
                           
                         denotes the number of images in the kth cluster 
                           
                              
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             k
                                             =
                                             1
                                          
                                          
                                             K
                                          
                                       
                                       
                                          
                                             N
                                          
                                          
                                             k
                                          
                                       
                                       =
                                       N
                                    
                                 
                              
                           
                        . T denotes the number of iterations an algorithm is run. We want to produce subclusters of size n (provided by the user) and we assume 
                           
                              n
                              ⩽
                              
                                 
                                    N
                                 
                                 
                                    k
                                 
                              
                           
                         for any k. 
                           
                              C
                           
                         (
                           
                              c
                              ∈
                              C
                           
                        ) represents the set of K cluster centroids and 
                           
                              C
                              ⊂
                              U
                           
                        , i.e., centroids are members of the dataset. 
                           
                              R
                           
                         (
                           
                              |
                              R
                              |
                              =
                              R
                           
                        ) denotes a restricted set of images (randomly chosen from 
                           
                              U
                           
                        ), which is larger than the number of clusters but smaller than the total number of images (
                           
                              R
                              ⊂
                              U
                           
                         and 
                           
                              K
                              <
                              R
                              <
                              N
                           
                        ). 
                           
                              P
                              (
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              )
                           
                         denotes the probability that images 
                           
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                           
                         are from the same class (
                           
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              ∈
                              U
                           
                        ).

In all our experiments we assume that we have access to pairwise distances between any pair of images. Any kind of image features and distance measures can be used to find a pairwise distance. We convert each pairwise distance to a pairwise probability by using a simple exponential function 
                           
                              P
                              (
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              )
                              =
                              exp
                              (
                              -
                              d
                              (
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              )
                              /
                              λ
                              )
                           
                         
                        [8], where 
                           
                              d
                              (
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              )
                           
                         denotes the distance between images 
                           
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                           
                         and 
                           
                              λ
                           
                         is a positive scaling parameter.

In subclustering we want to choose a set of centroids 
                           
                              
                                 
                                    C
                                 
                                 
                                    ˆ
                                 
                              
                           
                         such that the following product of probabilities is maximized:
                           
                              (1)
                              
                                 P
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∏
                                                   
                                                   
                                                      k
                                                      =
                                                      1
                                                   
                                                   
                                                      K
                                                   
                                                
                                                
                                                   
                                                      ∏
                                                   
                                                   
                                                      j
                                                      =
                                                      2
                                                   
                                                   
                                                      n
                                                   
                                                
                                                P
                                                (
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      k
                                                   
                                                
                                                =
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      k
                                                   
                                                   
                                                      j
                                                   
                                                
                                                )
                                             
                                             
                                                ︸
                                             
                                          
                                       
                                       
                                          
                                             
                                                P
                                             
                                             
                                                1
                                             
                                          
                                       
                                    
                                 
                                 ×
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      ∏
                                                   
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     k
                                                                  
                                                                  
                                                                     1
                                                                  
                                                               
                                                               ,
                                                               
                                                                  
                                                                     k
                                                                  
                                                                  
                                                                     2
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  
                                                                     k
                                                                  
                                                                  
                                                                     1
                                                                  
                                                               
                                                               ≠
                                                               
                                                                  
                                                                     k
                                                                  
                                                                  
                                                                     2
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                                (
                                                1
                                                -
                                                P
                                                (
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      
                                                         
                                                            k
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                   
                                                
                                                =
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      
                                                         
                                                            k
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                   
                                                
                                                )
                                                )
                                             
                                             
                                                ︸
                                             
                                          
                                       
                                       
                                          
                                             
                                                P
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    I
                                 
                                 
                                    k
                                 
                                 
                                    j
                                 
                              
                           
                         denotes the jth image assigned to cluster k. Note that the first image assigned to the kth cluster is 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         itself. The first part (
                           
                              
                                 
                                    P
                                 
                                 
                                    1
                                 
                              
                           
                        ) ensures that 
                           
                              n
                              -
                              1
                           
                         images 
                           
                              {
                              
                                 
                                    I
                                 
                                 
                                    k
                                 
                                 
                                    j
                                 
                              
                              }
                           
                         assigned to centroid 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         should be close to 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                        . The second part (
                           
                              
                                 
                                    P
                                 
                                 
                                    2
                                 
                              
                           
                        ) makes sure that the probability of dissimilarity between all pairs of centroids in 
                           
                              
                                 
                                    C
                                 
                                 
                                    ˆ
                                 
                              
                           
                         should be as high as possible.

Next we convert the maximization problem to a minimization problem by taking the negative log of (1), i.e., 
                           
                              Cost
                              =
                              -
                              log
                              (
                              P
                              )
                           
                         is:
                           
                              (2)
                              
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                 
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          j
                                          =
                                          2
                                       
                                       
                                          n
                                       
                                    
                                 
                                 log
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       k
                                    
                                 
                                 =
                                 
                                    
                                       I
                                    
                                    
                                       k
                                    
                                    
                                       j
                                    
                                 
                                 )
                                 -
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         k
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         k
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                                
                                                   
                                                      
                                                         k
                                                      
                                                      
                                                         1
                                                      
                                                   
                                                   ≠
                                                   
                                                      
                                                         k
                                                      
                                                      
                                                         2
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 log
                                 (
                                 1
                                 -
                                 P
                                 (
                                 
                                    
                                       c
                                    
                                    
                                       
                                          
                                             k
                                          
                                          
                                             1
                                          
                                       
                                    
                                 
                                 =
                                 
                                    
                                       c
                                    
                                    
                                       
                                          
                                             k
                                          
                                          
                                             2
                                          
                                       
                                    
                                 
                                 )
                                 )
                              
                           
                        The optimal centroid set is 
                           
                              
                                 
                                    C
                                 
                                 
                                    ˆ
                                 
                              
                              =
                              arg
                              
                              
                                 
                                    min
                                 
                                 
                                    C
                                 
                              
                              
                              Cost
                           
                        .

The cost function in Eq. (1) is formulated in a way such that images in the same subcluster are tightly grouped and are far from the images in other subclusters. Ideally we want to extract features from images such that images from the same category stay close to each other in the feature space and images from different categories are far from each other. However state-of-the-art computer vision image features are not accurate enough that all images will remain in the feature space in this way. However we expect that features from some of the images will follow the ideal structure in the feature space. Our cost function for subclustering is formulated in a way such that if optimized will output only those images. Although there are other possible ways to formulate cost functions to perform subclustering, they may not be as good as our approach. For example, one such possible cost function is the traditional complete clustering cost, where we assign each point to the nearest cluster center and then minimize the average distance between the images within each cluster. From the complete clustering solution, we can obtain n images (nearest to the center) from each cluster to get a subclustering output. We note that although such an approach can be used to create subclusters from complete clusters, cost functions solely built to solve subclustering create purer subclusters. Intuitively it is clear that points that are difficult to cluster can affect the results of clustering algorithms in a way that degrades the clustering of easier points. That is, it makes more sense to solve the problem we want to solve directly (subclustering), rather than trying to solve a harder problem (clustering) as an intermediate step. This is demonstrated in the experimental results in Section 8.

For each cluster centroid we have to find 
                           
                              n
                              -
                              1
                           
                         images {
                           
                              
                                 
                                    I
                                 
                                 
                                    k
                                 
                                 
                                    j
                                 
                              
                           
                        } to be assigned to centroid 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                        . This is achieved by simply assigning the 
                           
                              n
                              -
                              1
                           
                         closest images to 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         in cluster k. Since this can lead to overlapping subclusters we add an extra step in our algorithm to minimize the overlap between clusters, discussed later in this section. We denote a set of 
                           
                              n
                              -
                              1
                           
                         images assigned to a centroid c along with c itself as 
                           
                              
                                 
                                    S
                                 
                                 
                                    c
                                 
                              
                           
                         (we use 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         or c both as elements of 
                           
                              C
                              ,
                              
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         additionally implies that it is the kth centroid).

We optimize 
                           
                              Cost
                           
                         with an iterative algorithm. We initialize our algorithm with random cluster centers, assigning the 
                           
                              n
                              -
                              1
                           
                         closest images to each of these cluster centers. Then, at each iteration, we swap one of these cluster centers with a new cluster center, chosen from a pool of possible replacements in the restricted set, 
                           
                              R
                           
                        , choosing the replacement that most reduces 
                           
                              Cost
                           
                        . Now we explain our algorithm in detail:
                           
                              (a)
                              First, we precompute the change in the first part of 
                                    
                                       Cost
                                    
                                  if any 
                                    
                                       r
                                       ∈
                                       R
                                    
                                  is added to or removed from a centroid set. We can precompute that as we know which images will be assigned to each centroid due to our simple assignment procedure. We take advantage of this fact and significantly cut down computational cost.

Next, we randomly choose an initial centroid set 
                                    
                                       C
                                       ⊂
                                       R
                                    
                                 . We maintain an additional vector of size R, which stores the changes in the second part of 
                                    
                                       Cost
                                    
                                  if a centroid 
                                    
                                       r
                                       ∈
                                       R
                                    
                                  is added to the current centroid set 
                                    
                                       C
                                    
                                 . This vector needs to be updated at the start of each iteration.

We calculate the present subclustering cost using (2) and denote that as 
                                    
                                       
                                          
                                             Cost
                                          
                                          
                                             t
                                          
                                       
                                    
                                  at the tth iteration.

We consider replacing each centroid, 
                                    
                                       c
                                       ∈
                                       C
                                    
                                 , with each centroid from the restricted set, 
                                    
                                       r
                                       ∈
                                       R
                                    
                                 .
                                    
                                       (i)
                                       A replacement of c with r is valid only if 
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      r
                                                   
                                                
                                             
                                           has no more overlap with existing subclusters than 
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      c
                                                   
                                                
                                             
                                           does. We say there is an overlap between two subclusters if one or more images in those two subclusters are the same. We define an indicator function 
                                             
                                                1
                                                (
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                   
                                                
                                                ,
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                                )
                                             
                                          , which is 1 if there is an overlap between subclusters 
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                   
                                                
                                             
                                           and 
                                             
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                             
                                           and 0 otherwise. A valid centroid replacement must follow: 
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   
                                                      K
                                                      -
                                                      1
                                                   
                                                
                                                1
                                                (
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      c
                                                   
                                                
                                                ,
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                                )
                                                ⩾
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   
                                                      K
                                                      -
                                                      1
                                                   
                                                
                                                1
                                                (
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      r
                                                   
                                                
                                                ,
                                                
                                                   
                                                      S
                                                   
                                                   
                                                      
                                                         
                                                            c
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                   
                                                
                                                )
                                             
                                          , where 
                                             
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      j
                                                   
                                                
                                                ∈
                                                (
                                                C
                                                -
                                                c
                                                )
                                             
                                          .

We calculate the changed cost for all of these valid replacements (
                                             
                                                
                                                   
                                                      Cost
                                                   
                                                   
                                                      t
                                                      +
                                                      1
                                                   
                                                
                                                (
                                                r
                                                ,
                                                c
                                                )
                                             
                                          ) and see if any of them is less than the present cost 
                                             
                                                
                                                   
                                                      Cost
                                                   
                                                   
                                                      t
                                                   
                                                
                                             
                                          . If yes, we make the replacement for which the decrease in cost is maximum, i.e., replace the corresponding centroid 
                                             
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      ˆ
                                                   
                                                
                                             
                                           with 
                                             
                                                
                                                   
                                                      r
                                                   
                                                   
                                                      ˆ
                                                   
                                                
                                             
                                           in 
                                             
                                                C
                                             
                                          .

Go to step (c) until the algorithm converges, i.e., we do not find any replacement which decreases 
                                    
                                       
                                          
                                             Cost
                                          
                                          
                                             t
                                          
                                       
                                    
                                 . The centroid set at the final iteration along with the 
                                    
                                       n
                                       -
                                       1
                                    
                                  closest images to each centroid is the output of our subclustering algorithm.

Optimizing the subclustering cost function in Eq. (2) is a NP-hard problem
                           2
                           Solving traditional clustering is also known to be NP-hard.
                        
                        
                           2
                         and obtaining a global solution is not possible in polynomial time. We use an iterative algorithm that can find a locally optimal solution in polynomial time. We note that the iterative optimization method is motivated by the optimization used in Partition Around Medoid clustering algorithm [7]. Also note that our cost function is lower bounded by zero and at each iteration of our algorithm cost either decreases or remains the same, thus our proposed algorithm is guaranteed to converge.

We will make the code for this algorithm available upon publication. We demonstrate the proposed subclustering algorithm’s performance on a simple 2-d example in Fig. 3
                        .

The total computational cost of our proposed algorithm is 
                              
                                 O
                                 (
                                 RN
                                 +
                                 KRT
                                 )
                              
                            (see Appendix A for proof), where K is the number of clusters, T is the number of iterations the algorithm is run, R is the restricted set size and N is the total number of images. In our experiments we find that for any given K, our algorithm converges within a maximum 100 iterations, i.e., 
                              
                                 T
                                 =
                                 200
                              
                           . That is why in general KT remains typically similar to N; so our runtime is proportional to KRT. This is 
                              
                                 O
                                 (
                                 N
                                 )
                              
                            faster than PAM [7] (
                              
                                 O
                                 (
                                 KRNT
                                 )
                              
                           ) with the same sized restricted set. However, we note that PAM in general does not use a restricted set.

In active subclustering we improve our passive subclustering solution by asking humans if a pair of images is from the same class. In a subclustering solution we generally have two kinds of errors:
                        
                           •
                           
                              Between-class errors: One of our objectives in subclustering is to choose centroids covering as many different image classes as possible, so we want to eliminate centroids that are from the same class, using constraints provided by humans. We refer to these errors as between-class errors and a centroid pair of the form 
                                 
                                    (
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                    )
                                 
                               as a between-class pair.


                              Within-class errors: In subclustering we also want images in the same cluster to be from the same class. So we look for images with classes that are different from the classes of the centroids they are assigned to and correct them. They are called within-class errors and a centroid-image pair of the form 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   c
                                                
                                                
                                                   k
                                                
                                             
                                             ,
                                             
                                                
                                                   I
                                                
                                                
                                                   k
                                                
                                                
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                               is called a within-class pair.

One of the major challenges in active subclustering is that we want to correct both between-class and within-class errors simultaneously. In a subclustering solution we have K centroids with n images assigned to each of these centroids. At any iteration, we can ask about any of the 
                        
                           O
                           (
                           
                              
                                 K
                              
                              
                                 2
                              
                           
                           )
                        
                      between-class centroid pairs or 
                        
                           O
                           (
                           Kn
                           )
                        
                      within-class centroid-image pairs. We choose the image pair that is most useful (formally defined later as a utility function) for subclustering. One factor in determining the usefulness of an image pair is the likelihood that it reveals an error. So we ask about centroid pairs that are likely to be from the same class to correct between-class errors.

However the usefulness of within-class pairs not only depends on the similarity between image 
                        
                           
                              
                                 I
                              
                              
                                 k
                              
                              
                                 j
                              
                           
                        
                      and the centroid 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                     , but also depends on the likelihood that 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      will remain in the centroid set 
                        
                           C
                        
                      even after we correct the between-class errors. If 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      is very unlikely to remain in 
                        
                           C
                        
                      after between-class errors have been corrected, corresponding within-class pairs 
                        
                           
                              
                                 
                                    
                                       
                                          c
                                       
                                       
                                          k
                                       
                                    
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          k
                                       
                                       
                                          j
                                       
                                    
                                 
                              
                           
                        
                      are considered less useful (even if they are likely to be erroneous) for subclustering and we should not spend a good amount of human budget in correcting them. At each iteration we have to estimate the probability that a centroid 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      will remain in 
                        
                           C
                        
                     . This is hard to compute as it depends on other centroids, their pairwise similarity and also changes made to 
                        
                           C
                        
                      during between-class error correction. To estimate such probabilities we make an assumption that for each 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                     , its probability of remaining in 
                        
                           C
                        
                      will be determined by another centroid 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                              
                                 ′
                              
                           
                           ∈
                           (
                           C
                           -
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                           )
                        
                     , which is most likely to be similar to 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                     . We assume that high similarity between 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      and 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                              
                                 ′
                              
                           
                        
                      implies that 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      is unlikely to remain in set 
                        
                           C
                        
                      after between-class error correction. We note that there are other possible ways we can estimate this probability, however this method is very efficient and works well in practice.

Now, let us look at a toy example in Fig. 4
                      to understand intuitively what our estimation means. In this subclustering example, it is evident that 
                        
                           
                              
                                 I
                              
                              
                                 i
                              
                              
                                 1
                              
                           
                        
                      is less likely to belong to the same class as 
                        
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                        
                      than 
                        
                           
                              
                                 I
                              
                              
                                 j
                              
                              
                                 1
                              
                           
                        
                     ’s likelihood of being in the same class as 
                        
                           
                              
                                 c
                              
                              
                                 j
                              
                           
                        
                     . However since 
                        
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                        
                      is very close to 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                     , there is a good chance that 
                        
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                        
                      will be taken out of 
                        
                           C
                        
                      due to its similarity with 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                     . On the other hand 
                        
                           
                              
                                 c
                              
                              
                                 j
                              
                           
                        
                      is unlikely to be from the same class as 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                        
                      and should remain in 
                        
                           C
                        
                     . So in our approach we prefer to ask users about pairs like 
                        
                           
                              
                                 
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          j
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                           
                        
                      before 
                        
                           
                              
                                 
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          i
                                       
                                       
                                          1
                                       
                                    
                                 
                              
                           
                        
                     .

Based on our estimates as described above, we show either a between-class or a within-class pair to humans and update our subclustering solution with their response. We continue as long as the human budget permits.

As we get human input, pairwise probabilities 
                        
                           P
                           (
                           
                              
                                 I
                              
                              
                                 i
                              
                           
                           =
                           
                              
                                 I
                              
                              
                                 j
                              
                           
                           )
                        
                      also change, i.e., same-class image pairs are assigned a probability of 1 and different-class image pairs are assigned 0. We also update the subclustering solution using our passive algorithm and these new probabilities (details are provided later). We note that we want to build algorithms that depend only on pairwise image distances and not on image vectors. For this reason we do not learn a new distance metric as we obtain additional constraints. Also we believe the amount of pairwise supervision we obtain from users in active subclustering would not be enough to alter the distances significantly. For example, for a dataset of 51418 images, we eventually get supervision for only 
                        
                           0.0108
                           %
                        
                      of all possible pairs to reach almost perfect subclustering.

Now, we define a utility function 
                        
                           U
                           (
                           
                              
                                 I
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 I
                              
                              
                                 j
                              
                           
                           )
                        
                      for all within-class and between-class image pairs, where 
                        
                           
                              
                                 I
                              
                              
                                 i
                              
                           
                        
                      and 
                        
                           
                              
                                 I
                              
                              
                                 j
                              
                           
                        
                      are any pair of images. At each iteration we choose the image pair for which this functional value is maximum. For a between-class image pair the utility function is defined as, 
                        
                           U
                           (
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 c
                              
                              
                                 j
                              
                           
                           )
                           =
                           P
                           (
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                           ,
                           
                              
                                 c
                              
                              
                                 j
                              
                           
                           )
                        
                     , where 
                        
                           
                              
                                 c
                              
                              
                                 i
                              
                           
                        
                      and 
                        
                           
                              
                                 c
                              
                              
                                 j
                              
                           
                        
                      are centroids in 
                        
                           C
                        
                     . For a within-class pair 
                        
                           
                              
                                 
                                    
                                       
                                          c
                                       
                                       
                                          k
                                       
                                    
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          k
                                       
                                       
                                          j
                                       
                                    
                                 
                              
                           
                        
                     :
                        
                           (3)
                           
                              U
                              
                                 
                                    
                                       
                                          
                                             c
                                          
                                          
                                             k
                                          
                                       
                                       ,
                                       
                                          
                                             I
                                          
                                          
                                             k
                                          
                                          
                                             j
                                          
                                       
                                    
                                 
                              
                              =
                              
                                 
                                    
                                       1
                                       -
                                       P
                                       
                                          
                                             
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      k
                                                   
                                                
                                                =
                                                
                                                   
                                                      I
                                                   
                                                   
                                                      k
                                                   
                                                   
                                                      j
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                              
                                 
                                    
                                       1
                                       -
                                       P
                                       
                                          
                                             
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      k
                                                   
                                                
                                                =
                                                
                                                   
                                                      c
                                                   
                                                   
                                                      k
                                                   
                                                   
                                                      ′
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           
                              
                                 c
                              
                              
                                 k
                              
                              
                                 ′
                              
                           
                           =
                           
                              
                                 argmax
                              
                              
                                 c
                              
                           
                           P
                           (
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                           =
                           c
                           )
                        
                      and 
                        
                           c
                           ∈
                           (
                           C
                           -
                           
                              
                                 c
                              
                              
                                 k
                              
                           
                           )
                        
                     .

A priority queue 
                        
                           PQ
                        
                      of size 
                        
                           O
                           (
                           
                              
                                 K
                              
                              
                                 2
                              
                           
                           +
                           Kn
                           )
                        
                      is created that contains utility function (
                        
                           U
                        
                     ) values for 
                        
                           O
                           (
                           
                              
                                 K
                              
                              
                                 2
                              
                           
                           )
                        
                      within-class and 
                        
                           O
                           (
                           Kn
                           )
                        
                      between-class pairs. Highest priority is given to the maximum utility pair.
                        Algorithm 1
                        Active subclustering 
                              
                                 
                                    
                                    
                                       
                                          Given: 
                                                
                                                   PQ
                                                
                                              (Priority Queue), Max_questions
                                       
                                       
                                          
                                             while num_questions 
                                                
                                                   ⩽
                                                
                                             Max_questions do
                                          
                                       
                                       
                                          
                                             Pop from 
                                                
                                                   PQ
                                                
                                              and ask about the corresponding image pair
                                       
                                       
                                          
                                             
                                             if the selected pair is a between-class pair 
                                                
                                                   (
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         i
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                   )
                                                
                                              
                                             then
                                          
                                       
                                       
                                          
                                             
                                             
                                             if User says “no” then
                                          
                                       
                                       
                                          
                                             
                                             
                                             Update the corresponding probability.
                                       
                                       
                                          
                                             
                                             
                                             else
                                          
                                       
                                       
                                          
                                             
                                             
                                             Update the corresponding probability.
                                       
                                       
                                          
                                             
                                             
                                             The current solution is no longer locally optimal.
                                       
                                       
                                          
                                             
                                             
                                             we return to the optimization procedure used in the passive algorithm until we find another optimal centroid set.
                                       
                                       
                                          
                                             
                                             
                                             end if
                                          
                                       
                                       
                                          
                                             
                                             else
                                          
                                       
                                       
                                          
                                             
                                             The selected pair is a within-class pair (
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                   ,
                                                   
                                                      
                                                         I
                                                      
                                                      
                                                         k
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                             )
                                       
                                       
                                          
                                             
                                             
                                             if User says “yes” then
                                          
                                       
                                       
                                          
                                             
                                             
                                             Update the corresponding probability.
                                       
                                       
                                          
                                             
                                             
                                             else
                                          
                                       
                                       
                                          
                                             
                                             
                                             Update the corresponding probability.
                                       
                                       
                                          
                                             
                                             
                                             Replace 
                                                
                                                   
                                                      
                                                         I
                                                      
                                                      
                                                         k
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                              with another image in the database 
                                                
                                                   
                                                      
                                                         
                                                            
                                                               I
                                                            
                                                            
                                                               k
                                                            
                                                            
                                                               j
                                                            
                                                         
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                              that is the next closest to 
                                                
                                                   
                                                      
                                                         c
                                                      
                                                      
                                                         k
                                                      
                                                   
                                                
                                              and has not already been assigned to any other centroid.
                                       
                                       
                                          
                                             
                                             
                                             end if
                                          
                                       
                                       
                                          
                                             
                                             end if
                                          
                                       
                                       
                                          
                                             Update the utility functions and the priority queue 
                                                
                                                   PQ
                                                
                                             .
                                       
                                       
                                          
                                             end while
                                          
                                       
                                       
                                          Output: An improved subclustering solution.
                                       
                                    
                                 
                              
                           
                        

The pseudocode of our active algorithm is described in Algorithm 1 and the details are provided in Appendix B. The steps of our active approach are designed such that we can correct both between-class and within-class errors simultaneously, with minimum human interaction. The image pair selection for active input is based on a utility function for image pairs. This utility function indicates the likelihood that an error will be revealed by asking about that image pair and also whether detecting that error is at all required, as the clustering solution changes while we get human feedback.

Many methods exist for evaluating the quality of a clustering of data relative to ground truth. We feel that these are not ideal for evaluating subclustering, however. We propose a novel metric to evaluate subclustering called Subclustering Jaccard’s Coefficient (SJC), which is motivated by Jaccard’s coefficient [38] for complete clustering. SJC mainly captures two properties of a subclustering solution:
                        
                           •
                           
                              Coverage: We want K subclusters to represent K different ground truth classes.


                              Purity: When a subcluster represents a ground truth class, it should be as pure as possible.

We first compute a simple mapping between the subclusters and the ground truth classes. For each class, we match it with the subcluster that contains the most elements from this class. This selects at most one subcluster for each class. Then we evaluate the quality of these subclusters using a metric similar to the Jaccard’s coefficient. Specifically, subclustering S is evaluated with respect to the ground truth G
                     
                        
                           (4)
                           
                              
                                 
                                    SJC
                                 
                                 
                                    G
                                 
                              
                              (
                              S
                              )
                              =
                              
                                 
                                    
                                       
                                          ∑
                                       
                                       
                                          k
                                          =
                                          1
                                       
                                       
                                          K
                                       
                                    
                                    
                                       
                                          ind
                                       
                                       
                                          k
                                       
                                    
                                    ∗
                                    
                                       
                                          
                                             
                                                SS
                                             
                                             
                                                k
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                                n
                                             
                                          
                                          
                                             
                                                C
                                             
                                             
                                                2
                                             
                                          
                                       
                                    
                                 
                                 
                                    K
                                 
                              
                           
                        
                     For each class, 
                        
                           k
                           ,
                           
                           
                              
                                 SS
                              
                              
                                 k
                              
                           
                        
                      is the number of pairs of elements from class k in the subcluster associated with k, and 
                        
                           
                              
                              
                                 n
                              
                           
                           
                              
                                 C
                              
                              
                                 2
                              
                           
                        
                      is the total number of pairs of elements present in that subcluster. For example, if for class k there is a subcluster with six out of ten elements from class k, the fraction in this sum will be 
                        
                           
                              
                                 
                                    
                                    
                                       6
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                              
                              
                                 
                                    
                                    
                                       10
                                    
                                 
                                 
                                    
                                       C
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                     , i.e., 
                        
                           
                              
                                 15
                              
                              
                                 45
                              
                           
                        
                      (Fig. 5
                     ). Additionally, we require that a subcluster can only represent a class if it contains a sufficient number of elements from that class. In our experiments, we require a subcluster to have greater than half of its elements from a single class; subclusters without this minimal level of purity will not be very useful for browsing. If a subcluster of size ten contains less than six elements of class k it is considered not to be useful. 
                        
                           
                              
                                 ind
                              
                              
                                 k
                              
                           
                        
                      is an indicator variable that will be zero if there is no subcluster that contains a sufficient number of elements from class k. This also ensures that a subcluster can only represent one class.

Because there are no prior algorithms for subclustering, we will adapt other clustering algorithms to the problem so that we may use them as baselines. K-medoids algorithms are easy to adapt to subclustering, by selecting each cluster’s medoid, and the 
                        
                           n
                           -
                           1
                        
                      closest other points in the cluster as a subcluster. We see that PAM [7] is much more effective on large image sets than a baseline K-medoids algorithm
                        3
                        A baseline K-medoids is similar to K-means [6] but the medoid is calculated instead of the mean in the update step.
                     
                     
                        3
                      and we provide some experimental evidence regarding that in Appendix C. However PAM is slow and not scalable to medium or large datasets. A contribution of this paper is to provide a faster algorithm that optimizes the same cost as PAM. This can be used to cluster datasets of size over 10,000 in around 7min (Matlab implementation), and could be further sped up with an optimized C implementation. We provide the implementation details of Fast-PAM in Appendix C.

@&#EXPERIMENTAL RESULTS@&#

We run experiments in two different domains: face images from Pubfig [18] and leaf images from Leafsnap [2]. In Fig. 6
                      we show some images from the datasets that we used. Unlike most other face datasets, images in Pubfig are taken in completely uncontrolled settings with non-cooperative subjects. Thus, there is a large variation in pose, lighting, expression, scene, camera, imaging conditions and parameters, etc. For the passive algorithm, we create several subsets of Pubfig [18] containing 
                        
                           40
                           ,
                           80
                           ,
                           120
                           ,
                           160
                        
                      and 200 clusters. These face image sets are called Face-40, Face-80, Face-120, Face-160 and Face-200 respectively. Face-200 is the complete Pubfig dataset containing 51418 images from 200 classes.
                        4
                        Note that the total number of images we use is less than the actual number of images (58797) in Pubfig because of inactive links to images.
                     
                     
                        4
                      The number of images in each class in Face-200 vary from 56 to 1434 and we use subcluster size of 
                        
                           n
                           =
                           10
                        
                     . We also create a leaf image dataset containing 1535 images from 27 classes to test our algorithms in a different image domain and we call this dataset Leaf-27. Each class in this case has at least 50 or more images and we use a subcluster size of 5. This is a subset of the leaf image data used in Leafsnap [2]. We also create a small face dataset containing 250 images from 10 classes (called Face-10) and a leaf dataset containing 250 images from 25 classes (called Leaf-25). We use a subcluster size of 5 and 3 for Face-10 and Leaf-25 respectively. In our experiments we required pairwise distances between all images. The distance matrix for face images and leaf images are calculated based on algorithms in [39,2] respectively. Scaling parameter 
                        
                           λ
                        
                      is chosen based on a small holdout training dataset and we use 
                        
                           λ
                           =
                           5
                        
                      for the face images and 
                        
                           λ
                           =
                           0.2
                        
                      for leaf images.

Our passive algorithm is compared with four other algorithms, Fast-PAM (Section 7), K-medoids baseline, Normalized Cut [8] and BBC-S [20], where the first three are traditional complete clustering algorithms. From complete clustering results, the centroid of each cluster along with the 
                           
                              n
                              -
                              1
                           
                         nearest images from the centroid create a subcluster. This seems to be a natural way of creating subclusters from clusters and provides useful baselines for comparisons. We use SJC as the evaluation metric. Each algorithm is run 10 times for each dataset and mean SJC is reported. From Fig. 7
                         and Table 1
                        , we can see that our proposed algorithm significantly outperforms other baselines. For example, our algorithm achieves 
                           
                              26
                              %
                           
                         higher SJC than that of Fast-PAM and is 30 times faster than Fast-PAM (even with the fast implementation) for Face-200.

One of the important innovations that allows our algorithm to run efficiently is to select the set of centroids from a restricted set only. If the restricted set size is smaller, our algorithm will be efficient but results may not be accurate. On the other hand with a larger restricted set we are likely to get a much better solution but at the cost of efficiency. We empirically find that selecting restricted sets of size 5K–25K (K is the number of clusters) gives reasonable trade-off between efficiency and accuracy. In Fig. 8
                        a we show how the clustering performance varies (after the passive algorithm) for all the face datasets as we change the restricted set size. The runtime increases as we increase the restricted set size, e.g., for Face-40 runtime increases from 19s to 95s, as we increase the restricted set size from 
                           
                              5
                              K
                           
                         to 
                           
                              40
                              K
                           
                        .

We expect that a user will provide the subcluster size based on her requirements. Subcluster size of 10 seems reasonable for most of the possible applications of subclustering such as browsing, categorization, summarization. This size is not too large that the subclusters will be erroneous and not too small that there will be no intra-class variation in each subcluster. However we performed some experiments where the subcluster size is varied to see how sensitive our approach is with respect to the subcluster size. In Fig. 8b–f, we compare the proposed approach with other approaches, where the subcluster size varies from 5 to 25. As we increase the subcluster size, all algorithms’ performance become a little worse, but our algorithm still outperforms other approaches by a significant margin.


                        
                           
                              •
                              We compare our active algorithm to three previous active clustering algorithms [10,16,17], adapted to subclustering by selecting n images from each cluster to use as subclusters.


                                 Face-200: Our approach requires around 143,000 questions to reach a SJC of 
                                    
                                       0.92
                                    
                                  (equivalent to 120 perfect subclusters and 80 subclusters with only one mistake) for Face-200. We note that asking 143,000 questions in Mechanical Turk costs only around $358. Basu et al.’s algorithm [10] achieves SJC of just 
                                    
                                       0.44
                                    
                                  after 143,000 questions. The “Explore” stage itself takes more than 200,000 questions and complete clustering of the dataset takes as many as 
                                    
                                       2.3
                                    
                                  million questions (Mturk cost: $5800). Xiong et al.’s approach [17] also falls short producing SJC of only 
                                    
                                       0.2
                                    
                                  after 143,000 questions. In Fig. 9
                                 a we plot SJC against the number of questions for Face-200. We could not run [16] on Face-200, because their approach is not fast enough for such a large dataset.


                                 Leaf-25 and Face-10: Although our active algorithm is aimed at problems with a large number of clusters, we run our approach in datasets (Leaf-25 and Face-10 in Fig. 9b and c respectively) with a small number of clusters for comparison and we still outperform all approaches. For example, we reach perfect subclustering by asking just 654 and 161 questions for Leaf-25 and Face-10 respectively, where the next best approaches take 876 and 639 questions respectively.

While we feel that these comparisons with previous active clustering algorithms provide a useful baseline, we stress that these prior approaches were not designed for subclustering, and poor performance on these tasks should not be taken as a criticism of the overall algorithms.

@&#CONCLUSION@&#

We propose a novel clustering problem called subclustering and show its application in large image datasets. We presented a passive and an active algorithm for subclustering. We compare our passive algorithm with several baselines and show that our proposed algorithm is better and scalable to large datasets. We compare our active subclustering algorithm with active complete clustering algorithms and demonstrate that the proposed algorithm is much better. We also present a metric for subclustering evaluation. Although experimental results are shown only for images, this idea can be extended to any clustering domain.

In this section we calculate the computational complexity of our passive algorithm. Notations used in this section are same as used in the main paper. We assume that we are given the distance between all pairs of images in 
                        
                           U
                        
                     . Actually, our algorithm only requires distances between images in 
                        
                           U
                        
                      and images in 
                        
                           R
                        
                     ; if these are not available a priori they may be computed in 
                        
                           O
                           (
                           RND
                           )
                        
                      time (where D is the dimension of feature vectors).

For step (a) (Section 4.2 in the paper) in our algorithm we have to find the 
                        
                           n
                           -
                           1
                        
                      closest points to each centroid in the restricted set. Finding the 
                        
                           n
                           -
                           1
                        
                      smallest elements in an array of size N can be done in 
                        
                           O
                           (
                           N
                           )
                        
                      time using a linear time selection algorithm [40] (subcluster size n is assumed to be constant). So, this takes 
                        
                           O
                           (
                           RN
                           )
                        
                      time for R centroids. For step (b), we maintain a vector of size R and update at every iteration, which takes 
                        
                           O
                           (
                           R
                           )
                        
                     ; total cost is 
                        
                           O
                           (
                           RT
                           )
                        
                     . Another major computational cost comes from tracking the overlap between clusters in step d (i). We can do this by maintaining a matrix of size K-by-R and updating it at every iteration. This requires 
                        
                           O
                           (
                           KR
                           )
                        
                      time in each iteration; total 
                        
                           O
                           (
                           KRT
                           )
                        
                     . For each replacement overlapping can be checked in constant time. The final major computational cost comes from considering KR replacements (step d (ii)); this is carried out T times and takes 
                        
                           O
                           (
                           KRT
                           )
                        
                      time. Each replacement is done in constant time with the precomputed cost of addition or removal of a centroid (see steps (a) and (b)). Other steps in our algorithm are not significant with respect to computational cost. So the total computational cost for the proposed algorithm is 
                        
                           O
                           (
                           RN
                           +
                           KRT
                           )
                        
                     . In our experiments we find that KT is typically similar to N; so our runtime is proportional to KRT. This is 
                        
                           O
                           (
                           N
                           )
                        
                      faster than PAM [7] (
                        
                           O
                           (
                           KRNT
                           )
                        
                     ) with a same sized restricted set. However, we note that PAM in general does not use a restricted set.

Here we formally describe our active algorithm for correction of between-class and within-class errors:
                        
                           (a)
                           A priority queue 
                                 
                                    PQ
                                 
                               of size 
                                 
                                    O
                                    (
                                    
                                       
                                          K
                                       
                                       
                                          2
                                       
                                    
                                    +
                                    Kn
                                    )
                                 
                               is created that contains utility function (
                                 
                                    U
                                 
                              ) values for 
                                 
                                    O
                                    (
                                    
                                       
                                          K
                                       
                                       
                                          2
                                       
                                    
                                    )
                                 
                               within-class and 
                                 
                                    O
                                    (
                                    Kn
                                    )
                                 
                               between-class pairs. Highest priority is given to the maximum utility pair.

We pop from the priority queue and ask about the corresponding image pair.

If the selected pair is a between-class pair 
                                 
                                    (
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                    )
                                 
                              :

User says “no”: Cost of the present centroid set decreases (because a positive cost component contributed by 
                                 
                                    -
                                    log
                                    (
                                    1
                                    -
                                    P
                                    (
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                    )
                                    )
                                 
                               will be zero after we know 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                 
                               and 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                 
                               are from different classes), so it still remains locally optimal. We update the corresponding pairwise probability.

User says “yes”: The cost of the current centroid set blows up (as 
                                 
                                    -
                                    log
                                    (
                                    1
                                    -
                                    P
                                    (
                                    
                                       
                                          c
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          c
                                       
                                       
                                          j
                                       
                                    
                                    )
                                    )
                                 
                               becomes infinite) and the current solution is no longer locally optimal. At that point we return to the optimization procedure used in the passive algorithm until we find another optimal centroid set.

If the selected pair is a within-class pair (
                                 
                                    
                                       
                                          c
                                       
                                       
                                          k
                                       
                                    
                                    ,
                                    
                                       
                                          I
                                       
                                       
                                          k
                                       
                                       
                                          j
                                       
                                    
                                 
                              ):

User says “yes”: Update the pairwise probability.

User says “no”: Replace 
                                 
                                    
                                       
                                          I
                                       
                                       
                                          k
                                       
                                       
                                          j
                                       
                                    
                                 
                               with another image in the database 
                                 
                                    
                                       
                                          
                                             
                                                I
                                             
                                             
                                                k
                                             
                                             
                                                j
                                             
                                          
                                       
                                       
                                          ′
                                       
                                    
                                 
                               that is the next closest to 
                                 
                                    
                                       
                                          c
                                       
                                       
                                          k
                                       
                                    
                                 
                               and has not already been assigned to any other centroid (to avoid any overlapping induced by our active algorithm).

Within-class thresholding: we keep a threshold (
                                 
                                    
                                       
                                          q
                                       
                                       
                                          th
                                       
                                    
                                 
                              ) on the maximum number of questions we ask to correct one particular image assignment for a centroid in a within-class pair. Once we decide to replace a cluster element this is always the highest priority in the queue, until we find a good replacement. However, we do not want to get stuck repeatedly asking questions about one cluster when finding a replacement is difficult. So after the 
                                 
                                    
                                       
                                          q
                                       
                                       
                                          th
                                       
                                    
                                 
                               questions, we do not ask about a 
                                 
                                    
                                       
                                          
                                             
                                                
                                                   c
                                                
                                                
                                                   k
                                                
                                             
                                             ,
                                             
                                                
                                                   
                                                      
                                                         I
                                                      
                                                      
                                                         k
                                                      
                                                      
                                                         j
                                                      
                                                   
                                                
                                                
                                                   ′
                                                
                                             
                                          
                                       
                                    
                                 
                               pair and adjust the corresponding probability to ask about it later. 
                                 
                                    
                                       
                                          q
                                       
                                       
                                          th
                                       
                                    
                                 
                               is updated at every iteration such that when we have corrected most of the between-class errors, we will gradually shift our emphasis to within-class errors and start asking more questions about them (see Appendix B.1 for details).

Update the utility functions and the priority queue 
                                 
                                    PQ
                                 
                              . Goto step (b).

Continue asking about image pairs until the human budget is exhausted.

We define variables 
                           
                              
                                 
                                    H
                                 
                                 
                                    bc
                                 
                              
                           
                         and 
                           
                              
                                 
                                    H
                                 
                                 
                                    wc
                                 
                              
                           
                        , which keep track of how often humans agree with the algorithm regarding between-class pairs and within-class pairs respectively. If more questions are required to get a disagreement (a same-class centroid pair for between-class and a different-class centroid-image pair for within-class) from users, that implies humans are agreeing more with the present subclustering. 
                           
                              
                                 
                                    H
                                 
                                 
                                    bc
                                 
                              
                           
                         is defined as the average number of questions asked for between-class pairs to obtain a between-class disagreement. 
                           
                              
                                 
                                    H
                                 
                                 
                                    wc
                                 
                              
                           
                         is defined in similar way but corresponds to questions asked for within-class pairs only. These variables are updated after every iteration.


                        Within-class thresholding (step (e) in active subclustering): we keep a threshold (
                           
                              
                                 
                                    q
                                 
                                 
                                    th
                                 
                              
                           
                        ) on the maximum number of questions we ask to correct one particular image assignment for a centroid in a within-class pair. Replacing a cluster element is always the highest priority in the queue, until we find a good replacement. However, we do not want to get stuck repeatedly asking questions about one cluster when finding a replacement is difficult. So after the 
                           
                              
                                 
                                    q
                                 
                                 
                                    th
                                 
                              
                           
                         questions, we do not ask about a 
                           
                              
                                 
                                    
                                       
                                          
                                             c
                                          
                                          
                                             k
                                          
                                       
                                       ,
                                       
                                          
                                             
                                                
                                                   I
                                                
                                                
                                                   k
                                                
                                                
                                                   j
                                                
                                             
                                          
                                          
                                             ′
                                          
                                       
                                    
                                 
                              
                           
                         pair and adjust the corresponding probability to ask about it later. 
                           
                              
                                 
                                    q
                                 
                                 
                                    th
                                 
                              
                           
                         is set to be 
                           
                              
                                 
                                    
                                       
                                          H
                                       
                                       
                                          bc
                                       
                                    
                                 
                                 
                                    
                                       
                                          H
                                       
                                       
                                          wc
                                       
                                    
                                 
                              
                           
                         and is updated at every iteration. This intuitively means, as we keep correcting between-class errors, we will gradually shift our emphasis to within-class errors and start asking more questions about them.

@&#RELATED WORK@&#

We use PAM [7] proposed by Kaufman and Rousseeuw in 1987 as one of our major baselines. Although PAM is slow for large scale datasets, in general K-medoids algorithms like PAM are known to be more robust to outliers and are invariant to translations and orthogonal transformations to data points [41]. There have been several approaches to make PAM faster like CLARA [7], CLARANS [41,42]. We provide a faster implementation of PAM which we call Fast-PAM.

First, we introduce some notation to be used in this section. We are given a set of N unlabeled images 
                           
                              U
                           
                         to be clustered into K clusters. 
                           
                              
                                 
                                    N
                                 
                                 
                                    k
                                 
                              
                           
                         denotes the number of images in the kth cluster 
                           
                              
                                 
                                    
                                       
                                          
                                             ∑
                                          
                                          
                                             k
                                             =
                                             1
                                          
                                          
                                             K
                                          
                                       
                                       
                                          
                                             N
                                          
                                          
                                             k
                                          
                                       
                                       =
                                       N
                                    
                                 
                              
                           
                        . T denotes the number of time-steps or iterations an algorithm is run. 
                           
                              C
                           
                         (
                           
                              c
                              ∈
                              C
                           
                        ) represents the set of K cluster centroids and 
                           
                              C
                              ⊂
                              U
                           
                        , i.e., centroids are members of the dataset only. 
                           
                              R
                           
                         (
                           
                              |
                              R
                              |
                              =
                              R
                           
                        ) denotes a restricted set of images (randomly chosen from 
                           
                              U
                           
                        ), which is larger than the number of clusters but smaller than the total number of images (
                           
                              R
                              ⊂
                              U
                           
                         and 
                           
                              K
                              <
                              R
                              <
                              N
                           
                        ). 
                           
                              d
                              (
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              )
                           
                         is the distance between images 
                           
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                           
                         and 
                           
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                           
                         (
                           
                              
                                 
                                    I
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    j
                                 
                              
                              ∈
                              U
                           
                        ).

The state of the art implementation of PAM has computational cost 
                           
                              O
                              (
                              
                                 
                                    TKN
                                 
                                 
                                    2
                                 
                              
                              )
                           
                         
                        [41], where our implementation takes only 
                           
                              O
                              (
                              TRN
                              )
                           
                        . Our approach uses some additional data structures and precomputation which helps to carry out each centroid replacement of PAM (c with r) in only 
                           
                              O
                              (
                              
                                 
                                    n
                                 
                                 
                                    avg
                                 
                              
                              )
                           
                         time, where 
                           
                              
                                 
                                    n
                                 
                                 
                                    avg
                                 
                              
                           
                         is the average number of images in each cluster; this helps to reduce the run time of PAM by 
                           
                              O
                              (
                              K
                              )
                           
                        . For simplicity, we will assume 
                           
                              N
                              =
                              
                                 
                                    Kn
                                 
                                 
                                    avg
                                 
                              
                           
                        . Also in Fast-PAM we use a restricted set of images to choose the replacements from unlike using all non-centroids in PAM; this gives additional speed up of 
                           
                              O
                              (
                              
                                 
                                    N
                                 
                                 
                                    R
                                 
                              
                              )
                           
                        . In experiments we see that as the number of clusters increase, Fast-PAM is more efficient than PAM.

The cost function in clustering is of the form 
                           
                              Cost
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    k
                                    =
                                    1
                                 
                                 
                                    K
                                 
                              
                              
                                 
                                    ∑
                                 
                                 
                                    
                                       
                                          I
                                       
                                       
                                          k
                                       
                                       
                                          j
                                       
                                    
                                    ∈
                                    
                                       
                                          S
                                       
                                       
                                          k
                                       
                                    
                                 
                              
                              d
                              (
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                              ,
                              
                                 
                                    I
                                 
                                 
                                    k
                                 
                                 
                                    j
                                 
                              
                              )
                           
                        , where d measures the distance between two images, 
                           
                              
                                 
                                    c
                                 
                                 
                                    k
                                 
                              
                           
                         is the kth centroid, 
                           
                              
                                 
                                    I
                                 
                                 
                                    k
                                 
                                 
                                    j
                                 
                              
                           
                         is the jth image assigned to the kth cluster and 
                           
                              
                                 
                                    S
                                 
                                 
                                    k
                                 
                              
                           
                         is the set of images in cluster k.

In PAM, at each iteration, a cluster center is replaced by the data point that reduces the 
                           
                              Cost
                           
                         by the maximum amount. This continues until convergence, that is until no such replacement is found that decreases the 
                           
                              Cost
                           
                        .

In original implementation of PAM [41] each replacement (c with r) takes 
                           
                              O
                              (
                              N
                              )
                           
                         (since 
                           
                              N
                              ≫
                              k
                           
                        ) time. We reduce this replacement cost from 
                           
                              O
                              (
                              N
                              )
                           
                         to 
                           
                              O
                              (
                              
                                 
                                    n
                                 
                                 
                                    avg
                                 
                              
                              )
                           
                        . When we take out a centroid 
                           
                              c
                              ∈
                              C
                           
                         from the present set of centroids and add 
                           
                              r
                              ∈
                              R
                           
                         to 
                           
                              C
                           
                        , the cost changes mainly because of two sets of points. First, the points that were earlier assigned to c as the closest centroid now need to be reassigned to some other centroid. We call these set of points 
                           
                              
                                 
                                    I
                                 
                                 
                                    1
                                 
                              
                           
                        . Second, there is a set of points which will change their present assignment and will be assigned to r, because they are closer to r than their present assignments. We call these set of points 
                           
                              
                                 
                                    I
                                 
                                 
                                    2
                                 
                              
                           
                        . As we mentioned earlier, for simplicity we assume 
                           
                              |
                              
                                 
                                    I
                                 
                                 
                                    1
                                 
                              
                              |
                              =
                              |
                              
                                 
                                    I
                                 
                                 
                                    2
                                 
                              
                              |
                              =
                              
                                 
                                    n
                                 
                                 
                                    avg
                                 
                              
                           
                         to calculate the complexity of our implementation in a simpler way. Now we discuss the additional matrices, which we maintain to reduce the cost of replacements. Given a set of centroids 
                           
                              C
                           
                         we maintain couple of matrices 
                           
                              
                                 
                                    CL
                                 
                                 
                                    1
                                 
                                 
                                    R
                                    ×
                                    N
                                 
                              
                           
                         and 
                           
                              
                                 
                                    CL
                                 
                                 
                                    2
                                 
                                 
                                    R
                                    ×
                                    N
                                 
                              
                           
                        . 
                           
                              
                                 
                                    CL
                                 
                                 
                                    1
                                 
                              
                              (
                              i
                              ,
                              j
                              )
                           
                         and 
                           
                              
                                 
                                    CL
                                 
                                 
                                    2
                                 
                              
                              (
                              i
                              ,
                              j
                              )
                           
                         hold the first and second closest centroid for an extended centroid set 
                           
                              
                                 
                                    C
                                 
                                 
                                    ′
                                 
                              
                              =
                              C
                              ∪
                              r
                           
                         for the jth point in the dataset (say r is the ith element in 
                           
                              R
                           
                        ). Before we start each iteration of the total KR replacements, we also create a list for each 
                           
                              r
                              ∈
                              R
                           
                        , which holds the points closest to r, given centroid set 
                           
                              
                                 
                                    C
                                 
                                 
                                    ′
                                 
                              
                           
                        . We call the list set RL. Now we look at how we reassign the points in 
                           
                              
                                 
                                    I
                                 
                                 
                                    1
                                 
                              
                           
                         and 
                           
                              
                                 
                                    I
                                 
                                 
                                    2
                                 
                              
                           
                         below when a centroid replacement is made.
                           
                              •
                              
                                 For 
                                 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             1
                                          
                                       
                                    
                                 : For each 
                                    
                                       I
                                       ∈
                                       
                                          
                                             I
                                          
                                          
                                             1
                                          
                                       
                                    
                                 , we have to see what is the second closest assignment given r and the other centroids except c. This can be done using matrices 
                                    
                                       
                                          
                                             CL
                                          
                                          
                                             1
                                          
                                       
                                    
                                  and 
                                    
                                       
                                          
                                             CL
                                          
                                          
                                             2
                                          
                                       
                                    
                                  in constant time for each image. So total computational cost for these set of points is 
                                    
                                       O
                                       (
                                       
                                          
                                             n
                                          
                                          
                                             avg
                                          
                                       
                                       )
                                    
                                 .


                                 For 
                                 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             2
                                          
                                       
                                    
                                 : We already have set 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             2
                                          
                                       
                                    
                                  from lists RL, which we compute before the replacements stage starts in each iteration. Although we have to remove some points from 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             2
                                          
                                       
                                    
                                 , which were in 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             1
                                          
                                       
                                    
                                  as they have already been taken care of. Now for each 
                                    
                                       I
                                       ∈
                                       
                                          
                                             I
                                          
                                          
                                             2
                                          
                                       
                                    
                                 , we have to update corresponding old cost 
                                    
                                       d
                                       (
                                       I
                                       ,
                                       
                                          
                                             c
                                          
                                          
                                             old
                                          
                                       
                                       )
                                    
                                  (
                                    
                                       
                                          
                                             c
                                          
                                          
                                             old
                                          
                                       
                                    
                                  is the earlier assignment of I) with its new cost 
                                    
                                       d
                                       (
                                       I
                                       ,
                                       r
                                       )
                                    
                                 . Total computational cost for 
                                    
                                       
                                          
                                             I
                                          
                                          
                                             2
                                          
                                       
                                    
                                  is 
                                    
                                       O
                                       (
                                       
                                          
                                             n
                                          
                                          
                                             avg
                                          
                                       
                                       )
                                    
                                 .

At the end of each iteration centroid set 
                           
                              C
                           
                         will be updated. So we have to update 
                           
                              
                                 
                                    CL
                                 
                                 
                                    1
                                 
                              
                              ,
                              
                              
                                 
                                    CL
                                 
                                 
                                    2
                                 
                              
                           
                         and RL. But the computational cost to update these is 
                           
                              O
                              (
                              RN
                              )
                           
                         because each element in 
                           
                              
                                 
                                    CL
                                 
                                 
                                    1
                                 
                              
                           
                         and 
                           
                              
                                 
                                    CL
                                 
                                 
                                    2
                                 
                              
                           
                         can be updated in constant time. List RL can be obtained from 
                           
                              
                                 
                                    CL
                                 
                                 
                                    1
                                 
                              
                           
                         in 
                           
                              O
                              (
                              RN
                              )
                           
                         time. So the total computational cost for each iteration becomes 
                           
                              O
                              (
                              RN
                              +
                              
                                 
                                    KRn
                                 
                                 
                                    avg
                                 
                              
                              )
                              =
                              O
                              (
                              RN
                              )
                           
                         because we assume 
                           
                              N
                              =
                              
                                 
                                    Kn
                                 
                                 
                                    avg
                                 
                              
                           
                        . So total computational cost for the complete algorithm becomes 
                           
                              O
                              (
                              TRN
                              )
                           
                        , which is 
                           
                              O
                              (
                              
                                 
                                    KN
                                 
                                 
                                    R
                                 
                              
                              )
                           
                         faster than the original PAM implementation.

Since the implementation is complex we will make the code for Fast-PAM publicly available upon publication of our paper.

@&#EXPERIMENTAL RESULTS@&#

We compare Fast-PAM with two other algorithms CLARANS [41] and a K-medoids baseline [6] (similar to K-means but in the update step we calculate the medoid instead of the mean) for performance and running time. We note that we can also use a restricted set in original PAM; complexity is 
                           
                              O
                              (
                              TKRN
                              )
                           
                        . If we use the same restricted set (used in Fast-PAM) in PAM, Fast-PAM produces the exact same result as that of PAM but 
                           
                              O
                              (
                              K
                              )
                           
                         faster. So we do not run PAM with a restricted set in our experiments. Also PAM without a restricted set (complexity is 
                           
                              O
                              (
                              
                                 
                                    TKN
                                 
                                 
                                    2
                                 
                              
                              )
                           
                        ) is too slow to run for these datasets. Fast-PAM is 
                           
                              O
                              (
                              
                                 
                                    KN
                                 
                                 
                                    R
                                 
                              
                              )
                           
                         faster than PAM without a restricted set, i.e., the original PAM implementation [7].

We use several subsets of the face image dataset Pubfig [18]. We vary the number of clusters from 5 to 50 with each cluster containing 200 images. Jaccard’s Coefficient (JCC) [38] is used as the evaluation metric. Each algorithm is run 20 times and mean JCC and time are plotted in Fig. C.10
                        .

Although CLARANS produces results comparable to Fast-PAM, it requires a couple of parameters (numlocal and maxneighbour) to be set. We used 
                           
                              numlocal
                              =
                              100
                           
                         and 
                           
                              maxneighbour
                              =
                              1000
                           
                         (selected after trying several sets) for CLARANS. Although the K-medoids baseline algorithm is fast its performance is not on a par with Fast-PAM. The difference between Fast-PAM and K-medoids baseline is more pronounced towards the beginning of the performance curve (Fig. C.10a). As the size of the dataset increases, clustering performance degrades for all the algorithms. So the difference in JCC between Fast-PAM and K-medoids is not very significant. However we see that as the number of clusters increases Fast-PAM tends to produce better (2–3% lower) local minimum of 
                           
                              Cost
                           
                         than produced by the K-medoids baseline. For example, in the dataset with 50 clusters and 10000 images, the value of local minimum achieved by Fast-PAM is 34007 compared to 34873 achieved by K-medoids baseline. Overall, we feel that Fast-PAM is comparable with CLARANS but better than the K-medoids baseline in terms of performance for complete clustering.

@&#REFERENCES@&#


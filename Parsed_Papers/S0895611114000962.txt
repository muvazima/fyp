@&#MAIN-TITLE@&#Automatic spinal canal detection in lumbar MR images in the sagittal view using dynamic programming

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Introduction to CAD framework for characterizing/diagnosing lumbar spine pathology.


                        
                        
                           
                           Proposing dynamic programming-based spinal canal boundary detection algorithm.


                        
                        
                           
                           Performance of the algorithm is quantitatively evaluated.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Boundary extraction

Lumbar spine

Magnetic resonance imaging

Computer-aided diagnosis

@&#ABSTRACT@&#


               
               
                  As there is an increasing need for the computer-aided effective management of pathology in lumbar spine, we have developed a computer-aided diagnosis and characterization framework using lumbar spine MRI that provides radiologists a second opinion. In this paper, we propose a left spinal canal boundary extraction method, based on dynamic programming in lumbar spine MRI. Our method fuses the absolute intensity difference of T1-weighted and T2-weighted sagittal images and the inverted gradient of the difference image into a dynamic programming scheme and works in a fully automatic fashion. The boundaries generated by our method are compared against reference boundaries in terms of the Euclidean distance and the Chebyshev distance. The experimental results from 85 clinical data show that our methods find the boundary with a mean Euclidean distance of 3mm, achieving a speedup factor of 167 compared with manual landmark extraction. The proposed method successfully extracts landmarks automatically and fits well with our framework for computer-aided diagnosis in lumbar spine.
               
            

@&#INTRODUCTION@&#

There has been a concern about a shortage of diagnostic radiologists [1] and it was reported that the insufficiency was eased by delaying retirement of radiologists or working longer hours [2]. On the other hand, the workload of radiologists has continuously increased. According to the American College of Radiology Survey of Radiologists, workload has grown by 7% in terms of procedures and 10% in terms of physician work relative value units from 2002–2003 to 2006–2007 [3]. As a solution to reduce radiologists’ workload, there have been several efforts to increase the productivity of radiologists while securing an accurate diagnosis. To this end, we have developed a computer-aided diagnosis (CAD) framework, LumbarDiagnostics, for computer-aided characterization and diagnosis of lumbar spine pathology using multi-protocol magnetic resonance imaging (MRI) in a reliable and rapid manner, allowing to enhance the effectiveness and efficiency of examining procedures of lumbar pathology.

MRI becomes a primary diagnostic tool as it has several unique advantages over other imaging modalities. Differently from computed tomography (CT), single photon emission computed tomography, and positron emission tomography, MRI operates at radio-frequency range. Thus, it does not involve hazardous radiation. Second, the content of MR images contains much richer information compared to other modalities. Especially, it depicts excellent soft tissue contrast. In addition, volume renderings from MRI data can be created for a thorough investigation of diseases, while CT is limited to axial slices and images in other planes are reconstructed by postprocessing.

CAD has become one of the major research topics in medical imaging and diagnostic radiology. CAD has continuously evolved as a supportive tool in clinical environments [4,5]. In the past decades, a lot of CAD research and developments have been conducted for detection and classification of various lesions utilizing several imaging modalities for radiologists to use the output from computers as a second opinion in making their final decisions. Although the performance of computers is not as exact as that of physicians, CAD still plays complementary roles in diagnostic decision-making processes. Recent clinical studies indicate that CAD enhances the number of breast cancer detection by about 10% which is comparable to double reading by two radiologists [4].

The spinal cord is a vital communication link between the brain and the body that relays information between them. It also forms the elongated, cylindrical part of the central nervous system. As in Fig. 1
                     (a), it is 40–45cm long and 1–2cm in diameter on average. In a sagittal view, the spinal cord extends from the brain to vertebrae L1 or L2. The majority of dural sacs that encase the spinal cord terminate around the level S2 with a range from S1 to S3. Both the spinal cord and the dural sac are housed within the spinal canal. In our CAD framework, the spinal canal is used as a landmark to locate a region of interest (ROI) and to localize neighboring vertebrae and intervertebral discs since it gives constantly a sharp contrast between the canal and across the set of sagittal images. In other words, the exact spinal canal segmentation in an automated manner is one of the crucial prerequisites for localization and characterization of bordering organs.

In our previous work [6], we confirmed that the absolute pixel intensity difference between a T1-weighted sagittal image and its corresponding T2-weighted sagittal image gives an excellent outline of the spinal canal boundary as T1-weighted images and T2-weighted images are co-registered by technicians as in Fig. 1(b)–(d). Different from the previous method [6] that finds the left or the right boundary or somewhere between the two at random depending on the characteristics of an image, the proposed algorithm more accurately finds the left boundary of the spinal canal that connects the spinal cord, vertebrae, and intervertebral discs in sagittal plane. That is, while the previous method roughly finds the boundary that resides within the spinal canal, the proposed method in this paper finds exactly the left boundary between the spinal canal and the vertebral column that can be used as a landmark region. When compared with the right boundary, the left boundary can be used as a clue to diagnose the degree how much vertebra is slipped, so the accurate delineation of it is crucial. Based on the intensity difference of each pixel in two co-registered planes, in this paper we propose a method to extract a landmark region, i.e., the left spinal canal boundary for computer-aided diagnosis in lumbar spine by applying dynamic programming to the inverted gradient of the pixel intensity difference of the image. In other words, dynamic programming traces the boundary of the left spinal canal without interruption albeit disc herniation or spinal stenosis blocks the canal in the sagittal plane. In the dynamic programming procedure, the inverted magnitude of the difference image gradient is used as the cost function. The optimal solution of the cost function is found by backtracking, resulting in the desired boundary. This approach runs faster than our previous one that used interpolation to connect the spinal canal pieces into the one [7]. In our framework, this automated spinal canal detection in an accurate, fast manner is a prerequisite for localizing neighboring vertebrae and intervertebral discs, for background removal, and for feature generation that will be used in the task of pathology diagnosis in lumbar spine as stated earlier.

Recently, some advanced techniques and developments have been reported in computerized spine analysis including vertebra detection and segmentation and spinal canal detection from MRI. Chevrefils et al. [8] developed a watershed-based technique for segmenting intervertebral discs and spinal canal from MRI. A qualitative analysis of the results was compared favorably with other fast and unsupervised techniques including Canny and Marr–Hildreth edge detectors. They claimed that the method was robust to handle variability of shapes and topologies characterizing MRI images of scoliotic patients. Huang et al. [9] developed a fully automatic vertebra detection and segmentation system consisting of three stages: Adaboost-based vertebra detection, detection refinement via robust curve fitting, and vertebra segmentation by an iterative normalized cut algorithm. They claimed that the proposed system achieved nearly 98% vertebra detection rate and 96% segmentation accuracy. Horsfield et al. [10] proposed a semi-automatic method for segmentation of the spinal cord in MRI. The method utilized an active surface model that was generated based on the approximated cord centerline marked by a human. It was applied to assessing the multiple sclerosis and was evaluated in terms of the intra-observer reproducibilities. Lootus et al. [11] presented a histogram of oriented gradients (HOG)-based algorithm to automatically localize vertebrae in lumbar spine MRI scans. It was based on Deformable Part Model (DPM) object detector and inference using dynamic programming on chain and claimed to be simple, accurate and efficient. The method was evaluated quantitatively and they claimed that the method could cope with pathologies such as scoliosis, joined vertebrae, deformed vertebrae and discs, and imaging artifacts. Suzani et al. [12] proposed a semi-automatic method for segmenting vertebral bodies in multi-slice MR images. Adding a statistical model to the existing multi-vertebrae shape+pose model to accommodate, it was applied to volumetric MR images. They claimed that it is fast and can accommodate largest inter-slice gaps. Their segmentation results were quantitatively evaluated against the manual segmentation. That is, they claimed that the proposed method can segment the lumbar vertebral bodies in MRI with a mean error of 3mm.

In addition, boundary tracking and extraction has been studied by many researchers using diverse modalities. Geiger et al. [14] provided methods to detect, track and match deformable contours based on dynamic programming that can be applied to a wide variety of shapes. The algorithm with the boundary tracking techniques had been comprehensively tested on MRI cardiac data. Kirbas and Quek [15] gave a literature survey of vessel extraction techniques and algorithms based on several modalities. They classified vessel extraction techniques and algorithms into the following main classes: (i) pattern recognition techniques, (ii) model-based approaches, (iii) tracking-based approaches, (iv) artificial intelligence-based approaches, (v) neural network-based approaches, and (vi) tube-like object detection approaches. Lam and Yan [16] proposed a technique by which the user-defined initial curve moves towards the object data by combining a level set method and an affine transform method. They claimed that the method could handle corrupted data effectively by noise having sets of spurious points. Qian et al. [17] presented an accurate cardiac boundary tracking framework for 2D tagged MRI. This method integrated the boundary appearance, the shape constraints and the dynamic model naturally in a boosting and nonparametric tracking framework. The method required a training step. Sargin et al. [18] proposed a constrained optimization method to extract curvilinear structures from live cell fluorescence images. They argued that the method worked well in noisy images, showing its robustness to frequent intersections, intensity variations along the curve. Garibotto and Garibotto [19] described a method for computer-assisted contour tracking and following method by local profile matching using MR images. The contour tracking was performed with adaptive control of the local direction along with a continuous update of the gradient profile model. They insisted that this semi-automatic tracking model was very promising to allow accurate and fast processing of multiple images. Socher et al. [20] presented a hierarchical learning based vessel detection and segmentation method that was driven by data. They argued that this method was automatic, fast and robust against noise often observed in low quality X-ray images. Their boundary detection and segmentation task was formulated as a hierarchical learning problems over three levels: border points, cross-segments and vessel pieces, corresponding to the vessel's position, width and length. Bhole et al. [7] presented a method to detect lumbar vertebrae and disc structure from MR images. By combining information from T1-weighted sagittal, T2-weighted sagittal, and T2-weighted axial MR images, they automatically detected the boundary of spinal column and vertebral columns, achieving 98.8% accuracy.

The above algorithms do not work automatically, are not compared with manually extracted boundaries or require a training phase. Thus, the advantages of the proposed framework using our novel framework are as summarized as follows: (i) it works fully automatic requires no human intervention, (ii) it does not require a training phase, and (iii) the tracked boundaries are quantitatively evaluated.

The rest of the paper is organized as follows. In Section 2, our CAD framework and the left boundary detection method are presented. In Section 3, experimental results and discussion will be given. Finally Section 4 concludes the paper.

@&#PROPOSED METHOD@&#

The proposed method works within LumbarDiagnostics framework to detect the left boundary of the spinal canal.

The framework comprises 6 components as in Fig. 2
                        : meta data analysis, inter- and intra-slice analysis, preprocessing, regions of interest determination, reference generation, and validation. Each step performs specific tasks as follows.

In this step, protocol-related information is extracted from the Digital Imaging and Communications in Medicine header of each MR slice image. The slice number of each image makes it possible to sort slice images in sagittal plane.

One patient image data consist of MR images in multiple protocols and in each protocol there are usually tens of slice images. So among a set of multiple slice images, the selection of a proper image is crucial for subsequent processes and for fast image analysis. As in the previous approach [6], we use the mid-sagittal image in sagittal plane for characterization and diagnosis.

Image quality improvement and initial background marking is performed at this step along with image resizing. In addition, the absolute intensity difference of each pixel between a T1-weighted sagittal slice and a T2-weighted sagittal slice is calculated.


                           Image resizing. The slice image is resized to a 512×512 image as different scanners produce images of diverse matrix size.


                           Image quality enhancement and noise attenuation. Image quality is improved by median filtering with a window size of 3. The window size is chosen heuristically for fast image data processing. Median filtering also reduces the impacts of noise on image analysis. As Fig. 3
                            shows, median filtering works better than a Gaussian blur since Gaussian smoothing blurs both boundaries and noise.


                           Initial background marking. The spinal canal is positioned in the middle of a sagittal image in the image acquisition stage, so marking pixels on far left and far right sides as background reduces a large amount of noise as well as makes the successive processes faster. Fig. 4
                            compares the original T2-weighted slice image to the image after the initial background marking is done. Heuristically, the width of the foreground is set to 182 pixels.


                           Computation of the absolute intensity difference between co-registered sagittal slices. Our previous study [7] demonstrated that the absolute pixel intensity difference between the T2-weighted sagittal slice image and the corresponding T1-weighted sagittal one gives a clearer snapshot of the spinal canal contours than the T1-weighted sagittal one and the T2-weighted sagittal one as in Fig. 1(b)–(d). Thus, we use the absolute pixel intensity difference result for subsequent processing.


                           Computation of the magnitude of image gradient. The gradient of an image, I, is defined by the vector
                              
                                 (1)
                                 
                                    ∇
                                    
                                       
                                          
                                             I
                                             (
                                             x
                                             ,
                                             y
                                             )
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                I
                                                x
                                             
                                             =
                                             
                                                
                                                   ∂
                                                   I
                                                
                                                
                                                   ∂
                                                   x
                                                
                                             
                                             ,
                                             
                                                I
                                                y
                                             
                                             =
                                             
                                                
                                                   ∂
                                                   I
                                                
                                                
                                                   ∂
                                                   y
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           The elements of the vector are the partial derivatives of the image. This vector points in the direction along which the rate of change of I is maximum. The magnitude of the gradient is given by
                              
                                 (2)
                                 
                                    ∥
                                    ∇
                                    I
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    ∥
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   I
                                                   x
                                                   2
                                                
                                                +
                                                
                                                   I
                                                   y
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    .
                                 
                              
                           
                        

After computation of the magnitude of the image gradient, to find the minimal cost path, the gradient magnitude matrix is inverted by taking the additive inverse of ∥∇
                           I(x, y)∥ as follows:
                              
                                 (3)
                                 
                                    −
                                    ∥
                                    ∇
                                    I
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    ∥
                                    .
                                 
                              
                           This is required as the strong edges give larger magnitude values in the image domain but the dynamic programming finds the optimal path by minimizing the cost. Then the boundary tracing is performed by dynamic programming.

Reference is a left boundary of the spinal canal manually marked by two humans.

Similarity of two curves is compared using two distance metrics between two curves: the Euclidean distance and the Chebyshev distance. Specifically, the Euclidean distance D
                           
                              E
                            between two points with coordinates (x
                           1, y
                           1) and (x
                           2, y
                           2) is defined by
                              
                                 (4)
                                 
                                    
                                       D
                                       E
                                    
                                    
                                       
                                          
                                             (
                                             
                                                x
                                                1
                                             
                                             ,
                                             
                                                y
                                                1
                                             
                                             )
                                             ,
                                             (
                                             
                                                x
                                                2
                                             
                                             ,
                                             
                                                y
                                                2
                                             
                                             )
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   x
                                                   1
                                                
                                                −
                                                
                                                   x
                                                   2
                                                
                                                )
                                             
                                             2
                                          
                                          +
                                          
                                             
                                                (
                                                
                                                   y
                                                   1
                                                
                                                −
                                                
                                                   y
                                                   2
                                                
                                                )
                                             
                                             2
                                          
                                       
                                    
                                    .
                                 
                              
                           In the Euclidean distance, each point on one curve computes the distance metric and find the closest point in a set of points on the other curve. For example, in Fig. 5
                           , the point pair (a, y), gives the shortest distance among others. Also, the Chebyshev distance D
                           
                              C
                            (also called maximum value distance) between two points with coordinates (x
                           1, y
                           1) and (x
                           2, y
                           2) is defined by
                              
                                 (5)
                                 
                                    
                                       D
                                       C
                                    
                                    
                                       
                                          
                                             (
                                             
                                                x
                                                1
                                             
                                             ,
                                             
                                                y
                                                1
                                             
                                             )
                                             ,
                                             (
                                             
                                                x
                                                2
                                             
                                             ,
                                             
                                                y
                                                2
                                             
                                             )
                                          
                                       
                                    
                                    =
                                    max
                                    
                                       
                                          
                                             |
                                             
                                                x
                                                1
                                             
                                             −
                                             
                                                x
                                                2
                                             
                                             |
                                             ,
                                             |
                                             
                                                y
                                                1
                                             
                                             −
                                             
                                                y
                                                2
                                             
                                             |
                                          
                                       
                                    
                                    .
                                 
                              
                           In the Chebyshev distance, the distance between two sets of points on a curve is the longest distance between a pair of points. In other words, the Chebyshev distance gives the maximum distance between two vectors taken on any of the coordinate dimensions.

The distance between a boundary curve by the proposed method is compared against two reference boundaries by two medical specialists.

Dynamic programming for detecting, tracking, and matching deformable contours are comprehensively studied by Geiger et al. [14]. The basic idea behind dynamic programming is whatever the path to the node p was, there exists an optimal path between node p to the end node [21]. The advantage of it is that it runs fast and exact.

If a graph has R layers and C nodes, and m is the current layer and p is the current node, then the optimal path to the next level is computed by
                           
                              (6)
                              
                                 D
                                 
                                    
                                       
                                          
                                             x
                                             p
                                             
                                                m
                                                +
                                                1
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    min
                                    i
                                 
                                 
                                    
                                       
                                          D
                                          
                                             
                                                
                                                   
                                                      x
                                                      p
                                                      m
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             f
                                             m
                                          
                                          (
                                          i
                                          ,
                                          p
                                          )
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           D
                           
                              
                                 
                                    
                                       x
                                       p
                                       
                                          m
                                          +
                                          1
                                       
                                    
                                 
                              
                           
                         is the updated cost to the node 
                           
                              x
                              p
                              
                                 m
                                 +
                                 1
                              
                           
                         from the first layer and f
                        
                           m
                        (i, p) is a cost between nodes 
                           
                              x
                              p
                              m
                           
                         and 
                           
                              x
                              p
                              
                                 m
                                 +
                                 1
                              
                           
                        . For simplicity and fast computation, we assume that we only consider three neighboring nodes in the next layer, i.e., i
                        ∈{−1, 0, 1} as in [21]. This also keep from jumping between nodes when moving to the next layer. This computation is continued until one of the end point is reached. Then the optimal path is computed by
                           
                              (7)
                              
                                 min
                                 
                                    
                                       
                                          D
                                          
                                             
                                                
                                                   
                                                      x
                                                      1
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      x
                                                      R
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    ∑
                                    
                                       l
                                       =
                                       1
                                    
                                    R
                                 
                                 S
                                 
                                    
                                       
                                          
                                             D
                                             l
                                          
                                       
                                    
                                 
                              
                           
                        where
                           
                              (8)
                              
                                 S
                                 
                                    
                                       
                                          
                                             D
                                             l
                                          
                                       
                                    
                                 
                                 =
                                 
                                    min
                                    
                                       k
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       C
                                    
                                 
                                 
                                    
                                       
                                          D
                                          
                                             
                                                
                                                   
                                                      x
                                                      k
                                                      l
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              x
                              k
                              R
                           
                         are the end nodes, R the number of layers, and 
                           D
                           
                              
                                 
                                    
                                       x
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       x
                                       R
                                    
                                 
                              
                           
                         the cost of a path between the first and the last layer. In other words, the optimal path is obtained by back-tracking the node from the last layer to the first layer. Fig. 6
                        (a) and (b) shows snapshots of computing the minimum cost function at column p with layer m in the graph domain and in the image domain, respectively.

Based on this basic idea, the left boundary extraction of spinal canal is performed as follows.


                        Left boundary of spinal canal extraction algorithm
                     


                        Given: The matrix of the pixel intensity difference between a T1-weighted sagittal image and a T2-weighted sagittal image.


                        Step 0. Compute the inverted magnitude of the image gradient.


                        Step 1. Set the initial cost 
                           D
                           (
                           
                              x
                              j
                              1
                           
                           )
                         for each nodes j
                        =1, …, C in the first layer to the inverted magnitude of the image gradient computed by Eqs. (1), (2), and (3). In addition, set distance matrix f
                        
                           m
                        (j, p) to 0 where m
                        =1, …, R
                        −1 and R is the number of layers. The distance matrix stores the cumulative cost and is used in back-tracking. Note that rows, columns in the image domain correspond to layers, nodes, respectively.


                        Step 2. For each m
                        =1, …, R
                        −1, do the following. For each nodes p
                        =1, …, C in the corresponding layer m compute
                           
                              (9)
                              
                                 D
                                 
                                    
                                       
                                          
                                             x
                                             p
                                             
                                                m
                                                +
                                                1
                                             
                                          
                                       
                                    
                                 
                                 =
                                 
                                    min
                                    
                                       i
                                       ∈
                                       {
                                       −
                                       1
                                       ,
                                       0
                                       ,
                                       1
                                       }
                                    
                                 
                                 
                                    
                                       
                                          D
                                          
                                             
                                                
                                                   
                                                      x
                                                      p
                                                      m
                                                   
                                                
                                             
                                          
                                          +
                                          
                                             f
                                             m
                                          
                                          (
                                          i
                                          ,
                                          p
                                          )
                                       
                                    
                                 
                                 .
                              
                           
                        Update the distance matrix accordingly. Set pointer from node 
                           
                              x
                              p
                              
                                 m
                                 +
                                 1
                              
                           
                         back to node 
                           
                              x
                              i
                              
                                 
                                    m
                                    *
                                 
                              
                           
                         where * means the optimal predecessor. Let us do an example using Fig. 6(b). Suppose we are in the first layer. The cumulative cost to the first layer is set to −∥∇
                        I(x, y)∥. In the second layer, each node looks at three neighbors in the first layer and find the index that gives the smallest path cost. In case of the node (2, 2), the cumulative cost is computed by min{−2+(−10), −3+(−10), −7+(−10)}=−17 and the pointer is set to “shift to left by one pixel.” Fig. 6(b) shows how the cumulative cost is computed as the algorithm moves from the first layer to the last layer. Also it shows how the optimal boundary is formed. The total number of cost computations of this approach is 3C(R
                        −1) whereas the brute-force method requires C(3
                           R−1) computations. Obviously, the dynamic programming approach is cost-effective than the brute-force one.


                        Step 3. Find the optimal node 
                           
                              x
                              p
                              
                                 
                                    R
                                    *
                                 
                              
                           
                         in the last layer R and find the optimal path from node 
                           
                              x
                              p
                              
                                 
                                    R
                                    *
                                 
                              
                           
                         to the node 
                           
                              x
                              j
                              1
                           
                         by back-tracking. That is, the optimal path is found by looking at the pointers from the node 
                           
                              x
                              p
                              
                                 
                                    R
                                    *
                                 
                              
                           
                         to the node 
                           
                              x
                              j
                              
                                 
                                    1
                                    *
                                 
                              
                           
                        .

In Fig. 6(b), backtracking is performed by looking for the smallest cumulative cost. The first node of the last layer gives the smallest cumulative cost, −38. Then using pointer that means “shift one pixel to right,” the algorithm moves one pixel to right and gets the cumulative cost of −27. Using pointers as shown above, it finds the set of column indices of a node in each layer that forms the spinal boundary.

Note that the boundary can be formed in two ways. First, the boundary can be formed by finding the node having the smallest cumulative cost at the last layer and backtracking using the pointer. Let us take an example using Fig. 6(b). Once the cumulative cost is computed, the algorithm starts backtracking. At layer 4, the pair, (R, C), that gives the minimum cumulative cost is (4, 1). Subsequently, the pairs that give the minimum cumulative cost are (3, 2), (2, 2), (1, 3) at layer 3, 2, 1, respectively. The series of pairs from the last layer to the first forms the boundary.

In addition, the boundary can be constructed by connecting the nodes that give the minimum cumulative cost in each row. At layer 4, the pair, (R, C), that gives the minimum cumulative cost is (4, 1). At layer 3, the pair, (R, C), that gives the minimum cumulative cost is determined to (2, 2) after “shifting one pixel to right” from the pair that gives the minimum cumulative cost at layer 4. At layer 2, there is no need to shift. At layer 1, it is required to shift one pixel to right. Using the cumulative cost and the pointer information, the boundary is formed.

These two approach actually gives the same boundary. This answers to why the location of the first layer and the last layer match with the peak of the gradient profiles in the first layer and the last layer in Fig. 10.

Clinical MRI data are obtained from the affiliated radiology group and 85 subjects are used in this experiment. Each data contains images in T1-weighted sagittal and T2-weighted sagittal protocol and each slice in different protocols is co-registered. All MR images were taken by a 3 Tesla (3T) Philips scanner of 512×512 matrix size. The detailed scanning parameters are shown in Table 1
                        .

As we are only concerned with the lumbar spine region, we restrict our attention to the lumbar spine when generating referential boundaries and computing similarity metrics. This is due to the fact that doctor's reports we have used as reference only diagnosed the lumbar spine. Note that we can assume that the lumbar region is selected manually as the reference boundaries are drawn manually by two humans and the lumbar region is defined based on the two. In addition, some mid-sagittal slices do not capture the spinal canal clearly in the top row as shown in Fig. 7
                         (refer to green arrows) and our method finds the incorrect location caused by an incorrect gradient profile. This issue can be overcome by analyzing only the lumbar spine region in which the gradient profile clearly captures the strong boundaries that have high gradient magnitude (refer to yellow arrows). This restriction also gets rid of computational overhead that requires considering additional slice images that clearly depict the spinal canal in the top row.

@&#EXPERIMENTS@&#

The code for the experiments is implemented using MATLAB and the experiments are conducted on a machine with an Intel(R) Core i7CPU at 2GHz speed, and 6GB physical memory.

@&#RESULTS AND DISCUSSION@&#


                        Fig. 8
                         shows the whole process of the boundary extraction. Fig. 8(a) shows the absolute pixel intensity difference between the T1-weighted sagittal slice image and its corresponding slice in T2-weighted sagittal view. As we saw previously, the contrast of the intensity between the spinal canal and the neighboring regions is enhanced. In Fig. 8(b) the magnitude map of the gradient of the absolute intensity difference is shown. In Fig. 8(c) the magnitude map of the gradient of absolute pixel intensity difference in Eq. 2 is overlaied on the T2-weighted sagittal image as a 1-D profile. The green profile represents the distribution of the gradient magnitude of the absolute pixel intensity difference in the first layer of the lumbar spine region. As Fig. 9
                         depicts, in the first layer the pixel corresponding to the boundary between the vertebral column and the spinal canal has the largest magnitude (i.e., the brightest point).

−∥∇
                        I(x, y)∥ provides the starting cost to the dynamic programming. That is, it is fed to a path finding process as dynamic programming seeks a minimum cost path. The location of the path at the last layer matches to the peak of the distribution of the gradient magnitude at the last layer in magenta. Fig. 10
                         shows several boundary extraction results from many patients. Note that in each slice the distribution of the gradient magnitude spans the center region specified by the initial background marking step. Usually the spinal canal is positioned in the middle since the location is adjusted by medical specialist in image acquisition phase. Once the peak location of the gradient magnitude is chosen, the distance matrix is updated as the dynamic programming iteratively forms the path. In the experiments, the mean number of layers in the lumbar spine area is 257.8±20.4 and each layer has 512 nodes across all datasets. In addition, three nodes are considered for updating costs in each layer.


                        Fig. 11
                         shows some cases when the extracted boundary is a bit away from the referential boundaries. A blurry or unclear boundary causes the small gradient magnitude and results in an incorrect boundary. This leads to about a 2.7 times larger distance metric between the computer and a human than the metric between two humans. In most cases, however, our method automatically finds the desirable boundary as in Fig. 12
                        .


                        Table 2
                         shows the mean, standard deviation, and maximum between the computer-generated boundary and reference of two distance metrics in millimeter defined by Eqs. (4) and (5). In case of the Euclidean distance, about 1.3mm are off between two reference boundaries whereas about 3.6mm are apart between a model-generated boundary and a manually-drawn boundary. Table 3
                         compares the current method and the previous method in terms of a mean error. As the previous method finds the boundary within the spinal canal, the error is relatively large and the standard deviation is also high. On the other hand, the proposed method finds the boundary improving the accuracy about two times compared with the previous method [6].

Since the image domain is in two dimensions, the Chebyshev distance is computed base on one of two absolute differences while the Euclidean distance is calculated based on two differences. This makes the Chebyshev distance give a smaller or equal distance value than the Euclidean one for all comparisons. For example, when reference data by human 1 are used, 3.21±0.56mm of the Chebyshev distance is better than 3.61±0.63mm of the Euclidean distance. Considering the maximum Euclidean distance between two references that is 1.96mm and the Euclidean distance between reference 1 and computer output, we can conclude that the computer output is off about 1mm more.

Differently from the previous results for the spinal canal segmentation [22,23], the extracted boundary does not show any discontinuity regardless of the image quality and some pathology such as intramedullary tumors that blocks the spinal canal. Fig. 13
                        (a) shows a synovial cyst, that is sometimes related to tumors, in the T2-weighted sagittal view arising from the right L4–L5 facet joint severely compressing the dural sac. Our method extracts the desirable boundary in the presence of an obstacle, the cyst. On the other hand, Fig. 13(b) shows Sobel edges and its zoomed-in version. The cyst kept the boundary from being correctly formed. In this case, to get the desirable boundary, interpolation needs to be followed. The previous ones extract the spinal canal only when the distinction of the intensity of gradients are obvious in the border between the vertebral column and the spinal canal. The extracted boundary can be used as a landmark to mark background areas, to localize neighboring vertebrae and intervertebral discs, and to diagnose spondylolisthesis.


                        Table 4
                         gives the elapsed time of automated boundary extraction and manual boundary extraction. For the left boundary extraction of the spinal canal, Bhole's method takes about 13.64s, giving an average speedup factor of 1.5, whereas the proposed method takes an average of 0.13s, achieving a speedup factor of 167. Obviously, our method outperforms Bhole's method as it does not require computationally intensive interpolation algorithms. Our method also gives the smaller standard deviation in terms of the elapsed time. We expect that our method would achieve a higher speedup factor if it could run on a faster machine.

@&#CONCLUSION@&#

There have been a concern about the increasing workload of radiologists. Due to technological advancements and the digitization of scanned images, the need for computer-aided diagnosis has been increased recently. To meet the need for the automated management of the lumbar spine pathology, we have developed a computer-aided diagnosis framework. In this paper, we propose an automated method to extract the left boundary of the spinal canal in the lumber spine MRI that fits into our CAD framework. Our method incorporates the gradient magnitude of the absolute intensity difference of two co-registered images in T1-weighted and T2-weighted sagittal planes into a dynamic programming in a fully automatic way. The boundaries generated by our method is compared against reference boundaries in terms of the Euclidean distance and the Chebyshev distance. Experimental results on 85 clinical data show that our method finds the boundary with a mean Euclidean distance of 3mm and works about 167 times faster than the manual boundary extraction.

@&#ACKNOWLEDGEMENTS@&#

This research was supported in part by grants from NSF and NYSTAR.

@&#REFERENCES@&#


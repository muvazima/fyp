@&#MAIN-TITLE@&#Self-supervised, mobile-application based cognitive training of auditory attention: A behavioral and fMRI evaluation

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Mobile devices are feasible platforms for self-supervised cognitive training.


                        
                        
                           
                           Mobile cognitive training increases performance in selective auditory attention.


                        
                        
                           
                           Mobile cognitive training induces neural plasticity.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Mobile application

Self-supervised

Cognitive training

Auditory attention

Dichotic listening

Neural plasticity

fMRI

@&#ABSTRACT@&#


               
               
                  Emerging evidence of the validity of collecting data in natural settings using smartphone applications has opened new possibilities for psychological assessment, treatment, and research. In this study we explored the feasibility and effectiveness of using a mobile application for self-supervised training of auditory attention. In addition, we investigated the neural underpinnings of the training procedure with functional magnetic resonance imaging (fMRI), as well as possible transfer effects to untrained cognitive interference tasks. Subjects in the training group performed the training task on an iPod touch two times a day (morning/evening) for three weeks; subjects in the control group received no training, but were tested at the same time interval as the training group. Behavioral responses were measured before and after the training period in both groups, together with measures of task-related neural activations by fMRI. The results showed an expected performance increase after training that corresponded to activation decreases in brain regions associated with selective auditory processing (left posterior temporal gyrus) and executive functions (right middle frontal gyrus), indicating more efficient processing in task-related neural networks after training. Our study suggests that cognitive training delivered via mobile applications is feasible and improves the ability to focus attention with corresponding effects on neural plasticity. Future research should focus on the clinical benefits of mobile cognitive training. Limitations of the study are discussed including reduced experimental control and lack of transfer effects.
               
            

@&#INTRODUCTION@&#

In health and sickness, humans are preoccupied with their cognitive abilities and programs have been developed to train these abilities (Berry et al., 2010; Fisher et al., 2010; Kesler et al., 2013; Klingberg et al., 2005). However, many training programs are impracticable since participants need to visit the laboratory or have to sit behind a personal computer. Mobile devices (e.g., smartphones, iPod touches), on the other hand, offer greater flexibility for self-supervised training, allowing the individual to train his/her cognitive abilities at any time or location (e.g., on the bus, in a café, at the hospital) and without direct supervision. Although, in recent years, mobile devices have found their way into psychological research, allowing for the collection of self-administered experimental data in real-life settings (e.g., Bless et al., 2013b; Dufau et al., 2011; Killingsworth and Gilbert, 2010, for a review, see Miller, 2012), little is known about the applicability of these devices for training of cognitive functions.

The aim of the present study was to assess the feasibility of using a mobile application for self-supervised training of attention in healthy individuals. For this purpose, we have developed a mobile auditory attention training application for the iPhone/iPod touch, which is based on the forced-attention conditions of the consonant–vowel dichotic listening (CV-DL) paradigm (Hugdahl, 2003; Hugdahl and Andersson, 1986), and which has been validated in a previous study (Bless et al., 2013b). This paradigm requires participants to focus attention on syllables played in the right ear or left ear, while ignoring those played simultaneously in the other ear. In general, when confronted with two speech sounds at the same time, individuals tend to report the right-ear stimulus more often than the left-ear stimulus (e.g., Bryden, 1988; Hugdahl, 1995; Kimura, 1967), a phenomenon termed right-ear advantage (Shankweiler and Studdert-Kennedy, 1967). Thus, attending to and reporting the left-ear stimulus is considered to be more difficult than attending to and reporting the right-ear stimulus, posing different processing demands on auditory attention and cognitive control (Hugdahl et al., 2009; Kompus et al., 2012). As such, the paradigm serves as an analogue to everyday life situations, in which one auditory event, e.g. the response of our conversation partner, competes with multiple auditory streams, such as verbal utterances of other speakers or environmental sounds (traditionally referred to as the cocktail-party phenomenon) (Cherry, 1953). The ability to master such situations, however, is prone to individual differences (Conway et al., 2001), since deficits in auditory attention abilities have been reported in aging (Hugdahl et al., 2001; Passow et al., 2012; Takio et al., 2009), and in various clinical groups, e.g. schizophrenia patients (Hugdahl et al., 2013), preterm-born adolescents (Bless et al., 2013a), and children with dyslexia (Facoetti et al., 2003). Thus, the results of the current study, although based on healthy individuals, may offer new solutions for administering cognitive training in these patient groups. For example, feasibility of home-based cognitive training in schizophrenia patients has recently been reported (Hegde et al., 2012; Ventura et al., 2013).

Measuring the success of cognitive training can be approached on different levels of analysis. Certainly, improvement on the trained task itself has to be achieved. This has been shown previously using the CV-DL task (Soveri et al., 2013). However, such improvement is substantiated by investigating the neural correlates of the training effects in order to reveal underlying mechanisms (see Nyberg et al., 2003). For the present task and for mobile-application based cognitive training in general, this has to our knowledge not been explored previously. At the latest since Donald Hebb's theory of learning (Hebb, 1949), which has found due support by animal models (e.g., Bliss and Lomo, 1973; Kandel and Schwartz, 1982), behavioral changes (learning) are linked to neural mechanisms in the brain, mainly reflected in synaptic growth and neuronal firing. However, in recent years, this picture has been enriched by the notion that “less could be more” on both the anatomical (synaptic pruning) and the functional level (neural activation). One way of directly addressing this question is by examining training effects with functional magnetic resonance imaging (fMRI). Indeed, studies have shown that cognitive training results in both activation increases (e.g., Dahlin et al., 2008, Exp.1) as well as decreases (e.g., Schneiders et al., 2011); sometimes the same study reports increases in some and decreases in other regions (for a review, see Buschkuehl et al., 2012; Klingberg, 2010).

Thus, in the present study we expect successful training to be reflected by, (a) performance increase on the trained task, as well as (b) corresponding changes (increases or decreases) in neural activation in brain areas associated with speech perception and attention. In addition, to explore possible transfer of the trained task to other attentional tasks, we also included two cognitive interference tasks, one in the visual and one in the auditory domain.

@&#METHODS@&#

The study was approved by the Regional Committee for Medical Ethics in Western Norway (REK-Vest). All subjects gave written informed consent before the experiment and received financial compensation for their participation.

Twenty-eight healthy subjects were recruited through university mailing lists and flyers posted on student blackboards. Subjects were randomly assigned to either the non-training control group (N
                        =15) or the training group (N
                        =13) in consecutive order, while accounting for a balanced sex distribution in both groups. Initially, subjects passed a screening for right-handedness (Edinburgh Handedness Inventory), no hearing impairment (Hughson–Westlake audiometric screening test), and no history of psychiatric disorder or neurological disease (self-report). There were no significant differences between the groups with regard to hearing acuity/asymmetry and handedness (all t<1.2, all p
                        >.23). For group characteristics, see Table 1
                        . The reason for only including right-handers is to reduce between-subjects variations in lateralization, since evidence suggests that right-handers have more left-lateralized brains, as indicated by a stronger right-ear advantage compared to left-handers (see Van der Haegen et al., 2013).

Subjects in the training group performed the auditory attention training with the mobile application for a period of 21days, while control subjects did not receive training for the same time period. In order to assess the effectiveness of training, identical assessments were conducted in both groups on the first and last day of training/waiting. See Table 2
                         for an overview.

The training was conducted on iPod touch devices (4th generation) equipped with an in-house developed application, programmed in Xcode 4.2 (Apple Inc., Cupertino, CA). The sound stimuli were delivered via standard iPod earphones, which deliver output quality comparable to professional Sennheiser headphones (HD 280) with regard to interaural intensity differences [mean right–left differences for speech-relevant frequencies of 250Hz–2kHz are 0.32dB (Apple) and −0.12dB (Sennheiser)] (see Bless et al., 2013b). This is important for dichotic listening (DL) experiments since interaural differences above 6dB affect the size of the ear advantage (Hugdahl et al., 2008). Subjects were instructed to adjust the main sound level with respect to the ambient noise condition during self-administration. The training task was based on the forced-attention conditions of the standard CV-DL paradigm (Hugdahl, 2003; Hugdahl and Andersson, 1986). In this paradigm, the stimulus material consists of six CV-syllables /ba/, /da/, /ga/, /ka/, /ta/, and /pa/ presented in pairs of all possible combinations, with different syllables presented simultaneously via earphones, one to the subject's right, and one to the left ear. The duration of the syllables was between 400 and 500ms with an inter-stimulus interval of 4000ms in which the subject had time to respond. The syllables were spoken by a male, native Norwegian speaker with constant voice intonation and intensity. The instructions were presented on the iPod touch screen to focus attention on and report the syllable heard in the right ear (forced-right condition, FR) only, or left ear (forced-left condition, FL) only. Responses were recorded by pressing the corresponding “button” on the touch screen (see Fig. 1
                        ). Conditions were presented in six blocks (3 FR, 3 FL) with five trials per block and each trial consisted of a different CV pair (see above). Thus, one training session included 60 trials. Feedback in terms of percentage correct reports was displayed on the device's screen following each session.

The training period was 21days, and subjects were instructed to train in two sessions per day, one in the morning and one in the evening. On each occasion, the subjects themselves could decide where they would perform the training. Each training session lasted approx. 6min, yielding a total training time of ca. 12min per day. Results were saved on the iPod touch and later extracted for analysis. The entire training period included an average number of 40.7 (±2.5) sessions, which is 97% of the required sessions. Fig. 2
                         shows the training course over the period of 21days averaged across all members of the training group.

Transfer of the training was assessed with two cognitive interference tests (visual and auditory; computer-based), which were chosen for their similarity to the DL forced-attention conditions paradigm, in that they measure the ability to inhibit responses to irrelevant aspects of a stimulus situation. The visual interference test was based on the Stroop color–word test (MacLeod, 1991) with incongruent (e.g., the word “red” written in blue ink) and neutral stimuli (non-words written in various colors, e.g., “ba” written in red). The instruction to the subject was to report the color of the words, while ignoring their meaning. For each condition, there were 52 trials with stimulus durations of 2.0s and inter-stimulus-intervals of 3.0s. The auditory transfer task consisted of words presented via headphones in a congruent (e.g., hearing the word “low” spoken in a low pitch), incongruent (e.g., hearing the word “high”, spoken in a low pitch) or neutral (e.g., hearing “ba” spoken in a high pitch) manner. The instruction was to report whether the words were spoken with a high or low pitch, while ignoring their meaning. The auditory transfer task consisted of 20, 52 and 52 trials respectively, with stimulus duration of 1.0s and inter-stimulus-interval of 2.0s. For both the visual and auditory training tasks, the interference effect was calculated by subtracting the mean response time of the neutral trials from the mean response time of the incongruent trials. Both transfer tests were administered from a laptop PC with the use of the E-Prime (2.0 Psychology Software Tools, Inc.) stimulus presentation software.

The task selected for the fMRI evaluation was the same as the training task. However, it included a third condition (non-forced, NF) with the instruction to listen to and report the syllable that was heard best (no attention focus). This served as a control condition, while the two forced-attention conditions (FR, FL) served as both training and outcome measures. Behavioral data recorded during scanning was scored as the number of correct reports for the right and left ear, respectively, and for the three conditions.

MR imaging was performed on a 3T GE Signa HDx scanner at Haukeland University Hospital in Bergen. Functional images were acquired using a T2-weighted gradient echo-planar imaging (EPI) sequence (TE=30ms; 90° flip angle) and were oriented to the structural image. A sparse sampling protocol was used [repetition time (TR)=4.5s, acquisition time (TA)=1.5s] with a silent gap for oral response of 3.0s. All EPI volumes effectively covered the whole brain with 25 axial slices (0.5mm interslice gap, 5.0mm slice thickness, FOV 220×220, 64×64 scan matrix) and a voxel size of 3.44mm×3.44mm×5.0mm. A T1-weighted FSPGR sequence, with standard parameters, was applied for 3D anatomy image acquisition.

The experimental conditions were presented in blocks of 10 syllable-pairs and in two different orders, although always starting with the NF blocks, followed by alternating FR and FL blocks (order A: NF–NF–NF–FL–FR–FR–FL–FR–FL; order B: NF–NF–NF–FR–FL–FL–FR–FL–FR). The DL syllables were presented via MR compatible headphones (NordicNeuroLab Inc. http://nordicneurolab.com/) and subjects responded orally directly following stimulus presentation, still during the silent gap and before the next scan, thus avoiding interference of scanner noise and movement artifacts related to response articulation. The responses were recorded with an MR-compatible microphone and an MP3 player. The timing of the stimulus-presentations was controlled and synchronized with fMRI image acquisitions with the E-Prime software (Psychology Software Tools Inc., Pittsburgh, PA, USA).

The pre-processing of the fMRI data and all following analyses was performed with the Statistical Parametric Mapping (SPM 8) analysis software package (Wellcome Department of Cognitive Neurology, London, UK) running under MATLAB 2010b (Mathworks Inc., Natick, MA, USA). The EPI images were realigned to the first image in each time series and un-warping was performed to correct for the interaction of susceptibility artifacts and head movements. The unwarped mean images were then normalized to the MNI standard template and re-sampled to an isometric voxel size 2×2×2mm. Finally, using a 3D Gaussian filter of 8-mm FWHM, the normalized images were smoothed in order to compensate for the remaining inter-individual anatomical differences and increase the signal-to-noise-ratio.

For the analysis of activations for each individual, a SPM first-level analysis was done. This analysis was set up as a statistical model with one predictor for each of the three experimental conditions (NF, FR, FL). The predictors were convoluted with the canonical hemodynamic response function (hrf) and a temporal high pass filter (cutoff: 512s) was applied. Individual movement parameters created during realignment were entered as multiple regressors into the first-level analysis as covariates of non-interest, in order to account for residual movement artifacts. The estimated beta maps for the FR and FL predictors of each subject were submitted to second-level analysis (see next section).

In order to explore the effects of the auditory attention training on a behavioral level, the fMRI task results were analyzed using a 2×3×2×2 analysis of variance (ANOVA) with repeated-measures factors Time point (2 levels: pre- and post-training), Condition (3 levels: NF, FR, FL) and Ear (2 levels: RE, LE), as well as a between-subjects factor Group (training, control). The factorial ANOVA was followed up with appropriate lower-level ANOVAs and t-tests to test for simple main- and interaction-effects. The effects of interest were the interaction effects that included the factors Group and Time point for the dependent variable of the number of correct reports. Effect-sizes were calculated as eta-squared (η2) statistics.

Data from the transfer tasks were analyzed with a 2×2 factorial ANOVA with repeated-measures factors Time point (2 levels: pre, post), and a between-subjects factor Group (training, control). The effect of interest was a Group
                           ×
                           Time point interaction. The behavioral data was analyzed in SPSS 20.0 (IBM Corp., New York, USA).

In order to investigate the neural response to the training, functional imaging data was analyzed based on a 2×2 factorial design with the repeated-measure factor Time point (pre- and post-training) and a between-subjects factor Group (training, control). A family-wise error correction (FWE) was applied to obtain a corrected significant threshold of α=0.05 and with an extent threshold of k=15voxels (approximated based on expected voxels per cluster: 12.6). The effect of interest was a Group
                           ×
                           Time point interaction in the forced-attention conditions (FR, FL). As a follow-up to the whole-brain voxel-wise analysis and in order to explore and visualize the effect in the regions that showed significant interactions, we extracted the hemodynamic response of the activation peaks using the MarsBaR toolbox (Brett et al., 2002).

@&#RESULTS@&#

Analysis of the fMRI task revealed a significant 4-way interaction of Time point (pre/post)×
                        Group (control, training)×
                        Condition (NF, FR, FL)×
                        Ear (RE, LE) [F(2,52)=8.02, p
                        =.001, η2
                        =.01]. When the two groups were analyzed separately in two 3-way ANOVAs as follow-up of the significant 4-way ANOVA, the training group showed a significant 3-way interaction between Time point (pre/post)×
                        Condition (NF, FR, FL)×
                        Ear (RE, LE) [F(2,24)=13.21, p
                        <.001, η2
                        =.06], while no significant 3-way interaction was found in the control group [F(2,28)=0.57, p
                        =.572, η2
                        <.01]. Thus, only the training group was further analyzed which showed significant effects for the 2-way interactions of Time point (pre/post)×
                        Ear (RE, LE) in the FR condition [F(1,12)=14.34, p
                        =.003, η2
                        =.04], and in the FL condition [F(1,12)=12.58, p
                        =.004, η2
                        =.22], respectively. Post-hoc paired t-tests of the pre–post correct ear report comparison showed significant differences for both the FR and FL conditions. This showed that the FR right-ear score was increased after training [t(12)=4.03, p
                        <.01, d
                        =1.01], as was the FL left-ear score [t(12)=3.51, p
                        <.01, d
                        =1.23], while the performance for the unattended ear was correspondingly suppressed [FR left-ear score: t(12)=−2.67, p
                        =.02, d
                        =−0.85, and FL right-ear score: t(12)=−2.52, p
                        =.03, d
                        =−0.68, respectively]. Fig. 3
                         shows the changes of ear scores from pre- to post-training in both groups.

Analysis of the transfer tasks showed no significant Time point
                        ×
                        Group interaction effects, neither in the auditory [F(1,26)=0.80, p
                        =.380, η2
                        <.01], nor in the visual interference test [F(1,26)=0.94, p
                        =.341, η2
                        =.01].

The whole-brain fMRI analysis revealed significant effects of interest, i.e. interactions between Group
                        ×
                        Time point, in several clusters corresponding to the forced-attention DL task (see Table 3
                        , Fig. 4a). The FR condition showed significant left-hemisphere interactions in the posterior inferior temporal gyrus (ITG) extending into the middle temporal gyrus (MTG), in the fusiform gyrus (FG) extending into the lingual gyrus (LG), and an additional cluster in the precentral gyrus (PG). The FL condition showed two significant interactions, one in the left posterior ITG bordering the MTG and another in the right middle frontal gyrus (MFG). The follow-up region-of-interest analysis showed that, in all clusters, the activation was decreased in the training group after training and increased in the control group (see Fig. 4b).

@&#DISCUSSION@&#

The present findings showed that self-supervised training of auditory attention with a mobile application is both feasible and successful. An improvement in attention performance was accompanied by corresponding change in brain activation, thus revealing a neural correspondence to the behavioral training effect. However, transfer of the training to other tasks tapping into similar mechanisms was not observed.

Beneficial effects of the training were reflected in the behavioral data at the end of the 21-day period, where the training group showed better performance in both forced-attention DL conditions compared to the control group. At the same time, no changes in the untrained, NF condition were observed, suggesting that training did not affect the right-ear advantage in the NF control condition. The forced-attention instruction may have an effect on two different stages of stimulus processing (Westerhausen et al., 2013). It may “proactively” interact with early auditory processing, e.g., by selectively attenuating the weight of the not-to-be-attended auditory input during encoding into working memory (e.g., Alho et al., 1999; Treisman, 1964). However, the paradigm also relies on “reactive” executive control processes, necessary to resolve the competition between the two stimuli in working memory and follow the instruction to report the stimulus presented to a specific ear (Hiscock et al., 1999; Hugdahl et al., 2009). Accordingly, the observed training effects could have come from either or both stages, improving early attention processes and/or later executive control operations during stimulus selection. Interestingly, the effect-sizes indicate that training was particularly effective when attention was directed to the left ear. This may be the result of a ceiling effect in the less demanding FR condition, since the focus is on the dominant right-ear stimulus, already showing a high number of correct reports before the training. In the more effortful FL condition (Hugdahl et al., 2009), there is more room for improvement with the focus being on the “weaker” left-ear stimulus. This makes the FL task more susceptible for cognitive deficits (for a review, see Westerhausen and Hugdahl, 2010), yet also more receptive for training effects (see Soveri et al., 2013).

Regarding the fMRI findings, the training group displayed a post-training decrease in activation in regions associated with sensory and cognitive processing. Decreased activation after training is in line with the neural efficiency theory (Haier et al., 1992), interpreted to reflect more efficient use of cognitive resources as an effect of training, with fewer neurons and/or brain circuits necessary to meet the task demands. Training-induced decrease in activation in some areas has been reported previously (Erickson et al., 2007; Schneiders et al., 2011), and has also been observed in combination with increases in other areas (Dahlin et al., 2008; Olesen et al., 2004). The training-induced activation decreases may reflect more efficient processing at the neural level while the increases observed in the control group may be related to re-test effects. Thus it could be speculated that both groups followed an inverted U-shaped course with activation decreases after three weeks of training (training group) and activation increases as a result of repeated exposure to the task (control group) (see Hempel et al., 2004).

Relating the present training effects to previous studies using the same CV–DL paradigm in a conventional (non-training) fMRI experiment, substantial spatial overlap was found. The main cluster, located in the ITG/MTG region and modulated by training in both forced-attention conditions, has previously been associated with selective attention in DL (Hugdahl et al., 2000; Pugh et al., 1996). This regions also receives input from the planum temporale (Griffiths and Warren, 2002), an important region for phonetic processing (e.g., Binder et al., 1996; Jäncke et al., 2002; Uppenkamp et al., 2006). The FL condition revealed an additional significant cluster in the right MFG that stretched into the IFG. Generally, this region of the brain has been implicated in executive control functions such as inhibition (e.g., Aron et al., 2003; Rubia et al., 2003, for a review, see Verbruggen and Logan, 2008). Inhibition plays a role in the forced-attention conditions, since the signal from not-to-be-attended ear (e.g. the right ear during FL) needs to be suppressed. More specifically, the present training effects in the right frontal lobe is in line with previous CV–DL studies showing activation in the right IFG in response to instruction to focus on the left ear (Hugdahl et al., 2000; Jäncke and Shah, 2002; Thomsen et al., 2004). The observation that the frontal region only emerges in the FL supports the notion that processing of the FL condition taps into executive resources to a greater extent than the FR instruction (Hugdahl et al., 2009; Westerhausen and Hugdahl, 2010). Applied to the two-stage model (see above, Westerhausen et al., 2013), these findings suggest that training affects both early (temporal) and late (frontal) stages of auditory attention (see also, Ross et al., 2010; Larson and Lee, 2013).

The activation in the FG/LG was less intuitive given that the task is in the auditory domain. However, occipital lobe activations during auditory attention tasks have been reported previously using CVs (Kompus et al., 2012; Westerhausen et al., 2010) and tones (Cate et al., 2009). One explanation may be that these activations are the result of eye movements caused by the expectancy of a visual stimulus on the side of the attended ear. This might also explain the cluster in the PG and part of the primary motor cortex. It is unclear, however, why the effect is only seen in the FR condition.

The present results contribute to the growing body of research demonstrating the feasibility and effectiveness of mobile devices as platforms for self-administered behavioral intervention, previously assessed in a range of clinical contexts, e.g. management of alcohol abuse (Dulin et al., 2014), smoking cessation (Valdivieso-López et al., 2013), stress and mood problems (Lappalainen et al., 2013), and anxiety (Lindner et al., 2013; Pramana et al., 2014). Since interventions should be independent of time and place, and be available to individuals as they go about their daily lives, mobile devices appear to be the ideal instrument for delivery of these (Dagöö et al., 2014; Heron and Smyth, 2010, for a review, see Trull and Ebner-Priemer, 2013). In addition, mobile devices may be used to monitor the fluctuations of clinical symptoms, with a higher temporal resolution than the standard clinical interview. First attempts have been made to validate this method for assessment of mood and behavioral changes in outpatients with schizophrenia (Granholm et al., 2008; Palmier-Claus et al., 2012).

@&#LIMITATIONS@&#

A limitation to the use of mobile applications for cognitive training is the lack of control over the environment in which the training takes place, making results susceptible to unknown and potentially confounding factors. Nevertheless, it has recently been shown that results collected with a similar paradigm in real-life settings are comparable to those obtained in the laboratory (e.g., Bless et al., 2013b). For more control, one could use smartphone sensors to record contextual variables such as location, movement and ambient noise, and use these as covariates in the analysis, however, one should also be aware of the ethical implications of recording such data. Another challenge is the lack of control over the subject's training schedule. In order to minimize data omissions, it would be possible to schedule daily alarms on the training device. However, this would restrain the subjects' freedom to train wherever/whenever, the main advantage of using mobile devices in preference to stationary solutions.

Another question concerns the duration of the training. The observed performance plateau after 10days suggests that a shorter period of training may be sufficient to induce plasticity effects. This could be addressed in future studies by including an intermediate fMRI assessment. Alternatively, to avoid ceiling effects, the task may include adjustments of difficulty level. For dichotic stimuli, this could be achieved by presenting the left and right ear stimuli with different intensities (Hugdahl et al., 2008; Westerhausen et al., 2009).

Furthermore, transfer to the untrained interference tasks was not observed despite the similarity of the tasks, i.e. both trained and transfer tasks tap into the inhibitory component of executive control, as outlined by Miyake et al. (2000). It may be speculated that the current sample size was too small: however, the lack of transfer may also be related to the specificity of the training task. According to the reverse hierarchy model proposed by Ahissar and Hochstein (2004), the degree of transfer or specificity indicates the level on which learning has occurred, i.e. training-induced neural changes on late stages of task processing yield clearer transfer effects. Although the present fMRI results showed that training affected both early and late stages of processing, early stages of auditory attention appeared to be affected in both conditions (ITG), suggesting that the training paradigm resulted in more specific and less general learning. This leads into an open discussion about what tasks are more likely to generalize to others and what factors facilitate transfer and why (see Green and Bavelier, 2008; Jaeggi et al., 2013; Melby-Lervåg and Hulme, 2013; Shipstead et al., 2012), which lies beyond the scope of this study. It should be noted, that, using a similar training paradigm, Soveri et al. (2013) found a transfer effect to an untrained auditory spatial attention task (in terms of decreased response errors).

@&#CONCLUSIONS@&#

The present findings suggest that mobile devices are feasible platforms for self-supervised cognitive training. The ability to focus on auditory input during competing stimulus conditions was increased as a result of training and accompanied by decreases in neural activation indicating more efficient stimulus processing at early and late stages of selective auditory attention. The greater flexibility that mobile-application based cognitive training offers over laboratory or PC-based training may be particularly beneficial in clinical settings where patients often have to follow strict routines and may not be able to leave the hospital facilities. This should encourage future research into the use of mobile applications for cognitive training with an emphasis on aging and various clinical populations with prominent auditory attention deficits.

@&#ACKNOWLEDGMENTS@&#

The present research was funded by the European Research Council (ERC) Advanced Grant #249516 to Prof. Kenneth Hugdahl. We wish to thank the MR-technicians at the Department of Radiology, Haukeland University Hospital for their support during data acquisition.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Virtual Reality Social Cognition Training for children with high functioning autism

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           The VR-SCT provides an interactive and stimulating approach for children with ASD.


                        
                        
                           
                           The VR-SCT can improve social cognitive skills in children with ASD.


                        
                        
                           
                           Training improved emotion recognition, social attribution, and executive function.


                        
                        
                           
                           The training is a safe and socially non-threatening platform.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Autism

Virtual reality

Social cognition

Pediatric

Intervention

@&#ABSTRACT@&#


               
               
                  Virtual reality appears to be a promising and motivating platform to safely practice and rehearse social skills for children with Autism Spectrum Disorders (ASD). However, the literature to date is subject to limitations in elucidating the effectiveness of these virtual reality interventions. This study investigated the impact of a Virtual Reality Social Cognition Training to enhance social skills in children with ASD. Thirty children between the ages of 7–16 diagnosed with ASD completed 10, 1-h sessions across 5 weeks. Three primary domains were measured pre-post: emotion recognition, social attribution, attention and executive function. Results revealed improvements on measures of emotion recognition, social attribution, and executive function of analogical reasoning. These preliminary findings suggest that the use of a virtual reality platform offers an effective treatment option for improving social impairments commonly found in ASD.
               
            

@&#INTRODUCTION@&#

Individuals with autism demonstrate impairment in social functions including difficulties in social interactions, social communication, and emotion recognition (American Psychiatric Association, 2000; Hooper, Poon, Marcus, & Fine, 2006). The DSM-V characterizes autism spectrum disorders (ASD) into 3 severity levels with level 3 representing the most severe functional impairment in social communication and needing “very substantial support.” Level 3 individuals exhibit severe deficits in verbal and nonverbal communication and extreme difficulty coping with change. The higher functioning, level 1 individuals with ASD, tend to have difficulty processing social cues and as a result may become overwhelmed and anxious in social interactions, especially with unfamiliar individuals (Bernard-Opitz, Sriram, & Nakhoda-Sapuan, 2001; Hobson, Ouston, & Lee, 1989; Volkmar, Cohen, Bergman, Hooks, & Stevenson, 1989). Additional social difficulties include trouble inhibiting thoughts and regulating emotions (Pelphrey & Carter, 2008), both of which are relevant to executive function.

While research has shown that children with high functioning ASD (HFA) perform lower on measures of attention and executive function (Joseph, McGrath, & Tager-Flusberg, 2005; Sanders, Johnson, Garavan, Gill, & Gallagher, 2008), display language abnormalities, and often engage in stereotyped repetitive patterns of interests and/or behavior compared to age-matched typically developing children (Frith, 2003; Hooper et al., 2006), they may demonstrate average to above average intellectual abilities. They may also perform well on explicit social cognitive measures because of compensatory strategies, but often struggle in situations requiring the ability to spontaneously understand emotions of others and predict others' actions (Senju, Southgate, White, & Frith, 2009). This strong contrast between their strong academic performance and impaired social competency can lead to frustration (Hooper et al., 2006; Rinehart, Bradshaw, Brereton, & Tonge, 2001). Consequently, they are at increased risk for social isolation and loneliness compared to their typically developing counterparts (Bauminger & Kasari, 2000; White, Keonig, & Scahill, 2007). Overall, the impairments in social communication, theory of mind, and executive function can negatively influence both peer relationships and schoolwork (DiGennaro Reed, Hyman, & Hirst, 2011; White et al., 2007). Social deficits may impede academic performance in school due to low self-esteem (Welsh, Parke, Widaman, & O'Neil, 2001), despite their average to above average intellectual abilities. Therefore, developing and testing the effectiveness of social cognition interventions in children with HFA may contribute to protocols that serve to improve their social interactions and quality of life as they move from childhood to adulthood (DiGennaro Reed et al., 2011).

Recent research highlights the benefits of using virtual reality (VR) interventions, such as computer-based simulations of reality, in which individuals with HFA can practice difficult or individually challenging social interactions in a less-anxiety producing platform (Kandalaft, Didehbani, Krawczyk, Allen, & Chapman, 2013; Maskey, Lowry, Rodgers, McConachie, & Parr, 2014; Parsons & Mitchell, 2002; Wainer & Ingersoll, 2011). VR social training offers several advantages compared to traditional social skills interventions such as simple emotion recognition tasks or role-play. First, it can provide safe, unlimited, and commonly encountered day-to-day contexts to practice social scenarios, such as finding someone to sit with in the lunchroom or inviting someone to your birthday party (Kandalaft et al., 2013; Parsons, Mitchell, & Leonard, 2005; Wallace, Parsons, Westbury, White, & Bailey, 2010). It can help reduce the social anxiety as demonstrated by Maskey et al. (2014) with a virtual reality intervention in conjunction with CBT. Second, VR interventions provide the opportunity for repeated practice in dynamic, constantly changing social exchanges. The therapeutic benefit is that there is substantially less focus on rote learning and responses across multiple training sessions since no two social interactions are ever exactly the same. Moreover, this dynamic practice recast in different VR contexts may facilitate the generalization of social skills learned in VR to everyday life interactions (Bellani, Fornasari, Chittaro, & Brambilla, 2011; Parsons & Cobb, 2011; Tzanavari, Charalambous-Darden, Herakleous, & Poullis, 2015). Third, it can provide a supportive environment for individuals with ASD to make social mistakes without the intense anxiety or fear of rejection that is commonly associated with face-to-face social interactions. VR sessions provide a controlled environment to meet the individual's needs with the option of real-time feedback capable of enhancing the learning experience. Finally, computer technology is often highly motivating and rewarding for individuals with ASD, especially children with HFA (Parsons & Mitchell, 2002). Overall, VR offers an engaging, interactive, and individualized platform for training and improving social cognition in children with ASD.

Several studies have examined the feasibility and effectiveness of VR as a treatment option for individuals with ASD (Bernard-Opitz et al., 2001; Mitchell, Parsons, & Leonard, 2007; Ozonoff & Miller, 1985; Parsons, Mitchell, & Leonard, 2004). As summarized in a review article by Wainer and Ingersoll (2011), 12 studies focused on the use of technology to train children and adolescents with ASD. The majority of the articles focused on teaching emotion recognition and simple language skills such as learning vocabulary words and receptive language. Only four of the studies described in the review reported evaluations of training social skills and social awareness. Bernard-Opitz et al. utilized static pictures to teach problem solving and asked children to choose an appropriate solution to a social conflict. Results indicated that children with ASD between the ages of 5–8 years were able to increase the number of possible solutions to problems from an overall average of less than one to more than three. Beaumont and Sofronoff (2008) used a “Junior Detective” computer game to teach emotion recognition and social problem solving and found improvements on knowledge of emotion recognition in children with Asperger's syndrome. Parsons et al. (2004) used a VR café with 12 adolescents with ASD between the ages of 13–18 years to teach social awareness and then conducted a follow up study with six adolescents between the ages of 14–15 (Mitchell et al.). Upon completion of the VR café training, participants showed improvement in their social understanding in these settings (i.e., choosing appropriate seats, knowing when to initiate a conversation) as measured by their interactions and responses to the video questions. Separate case studies have also shown that participants with ASD can enhance their social understanding using a VR social training platform (Cheng & Ye, 2010; Herrera et al., 2008).

Although these studies provide support for VR as an effective platform to practice and teach social skills for individuals with ASD, there are limitations. Most platforms train specific subskills of social competency in isolation (e.g., emotion recognition, spatial awareness, problem solving). Another drawback is that generalization of learning to untrained measures or real life has not been adequately addressed in previous VR interventions designed for ASD (Parsons & Cobb, 2011). This is often due to the limited skills trained in the VR studies which often incorporate one specific social skill such as recognizing emotions repeatedly in a rote manner. Only a handful of prior VR studies have examined performance in social environments that are representative of the conditions that individuals typically encounter in daily life. Another constraint is that many VR designs involve passive social activities that are not initiated by the individual and the interactions can be overly scripted without encouraging the spontaneity of natural communication. The participants are not typically engaged in a “live” social interaction with other participants along with a “coach” who can provide immediate feedback. Schilbach et al. (2013) discussed the importance of using real-time social interactions that involve emotional engagement by the individual in order to enhance social cognition learning. This “second-person” approach, which incorporates multiple people engaged in real time, is needed to understand and improve social cognitive deficits. Schilbach, Eickhoff, Cieslik, Kuzmanovic, and Vogley (2012) distinguished the differences between being engaged in a social situation (online social cognition) versus passively observing an interaction (offline social cognition). They noted that “online” social cognition involves an integrative understanding of social perception and reciprocal communication, which is difficult for students with HFA who often succeed at “offline” social cognitive tasks (i.e., making social judgments based on static stimuli or observation). Another limitation of existing VR social training is the single-user virtual environment design (SVE), which makes it difficult to practice social interactions that occur on a day-to-day basis. Few studies are investigating the potential to train social cognitive skills for HFA in a multi-user or collaborative virtual intervention environment (CVE) such as the isocial platform, a virtual reality environment used for social training (Schmidt, Laffey, Schmidt, Wang, & Stichter, 2012; Stichter, Laffey, Galyen, & Herzog, 2014) and the use of Second Life by Keet al. (2015). The CVE design from the above mentioned studies report promising results from small sample sizes. The multi-user design warrants investigation since it allows for a more realistic and engaging interaction that can help teach social skills for individuals with HFA.

Finally, most of the VR interventions are designed to train either young children, adolescents, or adults, without describing potential implications of utilizing one VR platform across all ages. Whereas interventions should accommodate specific developmental stages; the design of a single platform has potential to reach a wider age spectrum. Overall, VR appears to offer a promising, innovative, and motivating platform to safely practice and rehearse social skills for children with ASD. However, the evidence to date is subject to limitations in elucidating the effectiveness of VR interventions because of limited sample size, lack of generalizability and standardized outcome measures and single user design.

The Virtual Reality Social Cognition Training (VR-SCT) was designed to address some of the limitations of previous VR interventions by providing a social training platform for both children and adults with ASD. The VR-SCT can be used across ages using varying contexts and complexity of social scenarios with adjustments made to fit the developmental age. For example, both the adult and child version of VR-SCT involve meeting a peer for the first time, confrontation with a bully, and dealing with someone who cheats. The contexts are similar, but the content and complexity of discussion between the participants and clinicians will vary depending on the developmental age of the individuals with HFA. The VR-SCT uses an interactive VR environment for participants to practice social scenarios in real-time with trained clinicians across 1-h sessions. It offers an opportunity for individuals with ASD to engage in everyday social situations, in which participants and clinicians guide a personalized avatar in real-time. Two age matched participants completed the training together as instructed by two trained clinicians (one clinician served as “coach” the other played numerous “confederates” depending on the social scenario). This allowed the peers to learn from one another and from the feedback given by the “coach” clinician. The VR-SCT has previously been shown to improve social cognition on measures of theory of mind and affect recognition in young adults (aged 17–35) with HFA (Kandalaft et al., 2013).

In the current pilot study, we extended Kandalaft and colleagues' (2013) investigation of VR-SCT efficacy to examine a 10-session VR-SCT intervention in children with HFA. Our primary aim was to assess feasibility of VR-SCT in children with ASD and measure changes in affect recognition, social attribution, and executive function pre and post training. Based on the findings of Kandalaft et al. (2013), we hypothesized that participants would show significant improvements on measures of social cognition emotion recognition and social attribution, as these were the primary domains that showed improvement in the prior adult study of the VR-SCT. Whereas social cognition measures provide the strongest potential for change, we were also interested in examining transfer effects from the targeted social cognition training to a non-trained domain of executive function. We hypothesized improvement on other areas of cognition such as attention and executive function due to the problem solving and reasoning nature of the VR social interactions. Additionally, many children with ASD have comorbid ADHD diagnosis which could have a detrimental impact on social attention (Jarold et al., 2013) and social information processing (Sinzig, Morsch, & Lekmkuhl, 2008) for this subgroup. For this reason, secondary analyses were conducted to explore possible differential benefits between participants with only ASD diagnosis compared to those diagnosed with both ASD and ADHD.

@&#METHODS@&#

Thirty participants ranging in age from 7 to 16 years were recruited at the Center for BrainHealth® at The University of Texas at Dallas (UTD). The group included 26 males and 4 females. This ratio is roughly consistent with the overall gender ratio of 5:1 (male: female) diagnosed with autism according to both the CDC report and the Texas Council on Autism and Pervasive Developmental Disorders 2014 Report. All procedures were approved by the Institutional Review Boards at UTD and the University of Texas Southwestern Medical Center. A parent or legal guardian of each participant provided written informed consent to participate in the research study and each participant provided assent to participate. All participants held a primary diagnosis of either Asperger Syndrome or PDD-NOS, and diagnoses were confirmed by trained clinicians using the Autism Diagnostic Observation Schedule (ADOS; Lord, Rutter, DiLavore, & Risi, 2002). Participants were excluded if they had an acute psychiatric condition or Axis I psychopathology, except managed ADHD, or a history of neurologic disorders. Thirteen children reported a diagnosis of ADHD in combination with an ASD diagnosis. Since many of the participants had comorbid diagnosis with ADHD, secondary analyses were conducted to examine the differences in change between participants with only autism spectrum diagnosis (ASD) compared to those with autism and ADHD.

All participants fell within the average-to-above average estimated IQ score ranges on the Wechsler Abbreviated Scale of Intelligence (WASI; Wechsler, 1999). See Table 1
                        .

All measures were administered prior to the start of the intervention and within two weeks of completion of the social intervention (2 sessions twice a week for 5 weeks).

(NEPSY-II AR; Korkman, Kirk, & Kemp, 2007) used a series of colored photographs of a child's face in three different tasks. In the first task, the participant selected one of the four faces that depicted the same emotion as a child's face at the top of the page. In a second task, the participant selected two photographs of faces that displayed the same affect from a selection of four photographs. Finally, the participant examined a photograph of a child's face for 5 s, and then from memory, selected two photographs that matched the same emotion as the face previously shown. NEPSY-II AR has high reliability coefficients (rs = 0.85 to 0.87) and moderate test retest coefficients (rs = 0.50 to 0.58; Brooks, Sherman, & Strauss, 2010). Facial Expressions of Emotion Stimuli and Tests (Ekman60; Young, Perrett, Cabler, Sprengelmeyer, & Ekman, 2002) also measured affect recognition. However, items from the Ekman60 are presented a series of black and white pictures of adults projected on a computer screen. Participants were asked to choose from the following basic emotions; happy, sad, fear, surprise, anger, and disgust. Ekman60 has high test–retest reliability rs = 0.77 (Williams, Daley, Burnside, & Hammond-Rowley, 2009).


                           Triangles, also known as the Social Attribution Task (Abell, Happé, & Frith, 2000) measured a person's understanding of social intentionality. In this experimental measure, adapted from the original videos of Heider and Simmel (1944), participants were asked to narrate the movements of blue and red triangles presented in six separate brief videos. Narratives were recorded, transcribed, and double-scored by two blind raters. More points were awarded when the participant stated “mentalizing” or emotional words to the description of the moving triangles. Each video from the Triangles task was given an intentionality score based on the 6-point Likert scale methods of Castelli, Happé, Frith, and Frith (2000). Participants describing higher levels of intentional and mental states of the stimuli were awarded higher scores (e.g., parent encouraging a child to go outside versus a triangle moving around in a box). Possible scores ranged from 0 to 36. Triangles has a high test-retest reliability r = 0.76 to 0.88 and concurrent validity r = 0.78 to 0.93 (Hu, Chan, & McAlonan, 2010). Inter rater reliability for the raters on total score was Kappa = 0.80 (p < 0.001), and for intentionality score was Kappa = 0.83 (p < 0.001). Videos were randomized and different videos were administered pre and post intervention for each participant.


                           The Developmental Neuropsychological Assessment Second Edition (NEPSY-II)-Auditory Attention and Response Set (Korkman et al., 2007) used auditory presentation of a list of words and the participant touched the appropriate circle when he or she heard the target word. NEPSY-II Auditory Attention measured selective attention and the ability to maintain attention. Response set assessed a more complex ability to shift and inhibit previously learned responses. Both tasks have high reliability coefficients (r = 0.81 to 0.88) and moderate to high test retest coefficients (r = 0.53 to 0.84; Brooks et al., 2010). The Analogical Reasoning Task used a stimulus set of analogies to examine reasoning ability, a measure strongly linked to executive functioning (Krawczyk et al., 2010). We implemented a task that was developed for a study of typically developing children (Richland, Morrison, & Holyoak, 2006) with some modifications, as reported in Krawczyk et al. (2014). The analogies consisted of two pictures of scenes with each scene containing five items representing objects, people, or animals. Two or three of these items had relational correspondences, such as chasing, pulling, etc. An arrow pointed to a match item in the source scene (top picture) and this item was to be matched to a similar item in the target scene (bottom picture) in order to complete an analogy between the top and bottom scenes. The prior task (Richland et al., 2006) had been designed to investigate the effects of relational complexity and feature distraction on the reasoning abilities of children. We modified the task in two ways. First, in the original version of the task, some distractor items in the target scene were visually identical to the match item in the source scene, while other distractors appeared in a different position or orientation compared to the match item. In our modified version all distractor items were presented in a new position or orientation in the target scene. We developed four separate versions of the task. These were counterbalanced such that each of the 24 problems appeared as a one- and a two-relation problem and appeared both with and without a distractor across the four versions in order to control for specific item effects. Among the 24 items there were three items representing each possible combination.

All procedures were conducted at the Center for BrainHealth® at the University of Texas at Dallas. Individuals completed a pretesting battery within two weeks before starting the training program. Each participant completed 10 VR-SCT sessions, 2 per week, 1 h each with a peer. Approximately 5 min were used for setup of the two peers in different rooms and to login, 5 min to sign off and about 45 min for the interactions. Each session allowed for 3 scenarios each lasting about 10 min, followed by a 5 min feedback/discussion from the “coach” clinician. Before the VR-SCT commenced, each participant was trained how to navigate in the VR environment with the use of a standard keyboard and mouse. No participants exhibited any difficulty navigating in the VR. Post-testing occurred no more than two weeks following the last training session. Three clinicians trained in ASD were involved in this study.

A password-protected Second Life™ version 2.1 (Linden Lab, 2003) was used as the platform for this intervention design. Second Life™, three-dimensional virtual world software available to the public, was displayed on Microsoft Windows XP or newer, graphics cards of ATI Radeon 8500 or better and 1.5 GHz ×86 CPU using a 24-inch monitor with a resolution of 1920 × 1200.

The customized Second Life™ VR island used in this study included the following locations: a school classroom, a school lunchroom, a playground, a campground, a race-track, a fast food restaurant, a technology store, an apartment, a coffee house, a sports store, and a central park. Avatars, representing the user in the virtual world, were modeled to resemble each participant and training clinician by changing the body figure, height, eye color, hair color, and clothes. In addition to altering physical appearance, an audio voice manipulation software MorphVox™ (Screaming Bee, 2005), was used by the confederate clinician to morph her voice to match her avatar character. For example, in some scenarios, the “confederate” clinician portrayed another child in the VR environment. The MorphVox software would alter the adult clinician's voice to sound like a young child and at times would alter the voice to the opposite gender. A female clinician could play a young boy with a morphed voice to match the avatar's character. Avatars were able to run, walk, jump and use a variety of arm and body gestures using a standard keyboard and mouse.

The VR-SCT was developed at the Center for BrainHealth at the University of Texas at Dallas by licensed speech pathologist and licensed psychologists. It provided realistic and dynamic opportunities to engage in, practice, and attain immediate feedback on relevant and true-to-life social scenarios. The graphics for the social scenes and avatars were realistic enough for the participants to feel as though they were in the social context interacting in real time with 2–3 live people. The computer interface did not provide full immersion as used in a 3D virtual reality designs to prevent the participants from becoming too overwhelmed or experience unpleasant symptoms by the sensory input. Research has indicated that individuals can experience “cyber-sickness” as a result of immersion VR (Cobb, Nichols, Ramsey, & Wilson, 1999; Sharples, Cobb, Moody, & Wilson, 2007), especially those with sensory processing deficits commonly found in ASD. The focus of the VR-SCT was to provide a social context to practice social communication and social cognition skills, without inducing negative symptoms. All sessions took place in a VR environment (Figs. 1–5
                           
                           
                           
                           
                           ) with a peer and two trained clinicians, a lead clinician as the “coach” and a confederate clinician who played various parts in social interactions. Initially, the “coach” described each session with the participants in person, helped set him or her up on the computer, and moderated each session in the VR by providing individualized verbal feedback via her avatar. Feedback was given in response to each participant's interaction. Participants logged onto the computer and were instructed by the “coach” inside the VR that directed them to a social situation at a specific location and with a specific person with whom to interact (confederate clinician).

Each social scenario was designed to emphasize a targeted social learning objective in varying contexts, such as meeting new people, dealing with a bully, bonding with friends, confronting conflict, consoling a friend, or handling social dilemmas (i.e., meeting a stranger, catching someone cheating). The scenarios were specifically constructed to represent commonly experienced real-world social situations faced by children. Table 1 describes the learning objectives and social situations of each session. The learning objective in each session became progressively more complex with initial sessions focused on learning to initiate and follow a conversation with a new friend and later sessions focused on maintaining relationships and handling dilemmas. A VR-SCT manual provided the procedure, standardized prompts, and questions for both clinicians (coach and confederate) involved in each session. The confederate clinician changed avatars (e.g., older to younger peers, male and female) and morphed her voice to match the gender, age, and race of the avatar being portrayed in each scenario. Clinicians followed a manualized training, in which each session had specific scenario-based encounters and social objectives. Each participant would be prompted by a pre-established social prompt (e.g., you are going to meet a friend in the lunchroom) and it was up to the individual to choose how to respond based upon pre-established responses from the confederate clinician (e.g., social hints that included an emotional feeling in their tone of voice, information about that confederate or an event that would be taking place). Confederate clinician's would engage the participant in a loosely-scripted conversation that provided such social “hints” in which the participant was expected to respond or follow. Both the participant and confederate could independently respond based upon the pre-established social prompts. For example, in Session 4 “Sad Puppy,” a coach avatar greeted the participants in the VR and instructed them to go to the park to meet a friend (see Fig. 1 of a screenshot of the scenario). The confederate clinician (logged in as an avatar), who was unknown to the participants, took on the role as an age-matched friend who just lost her puppy. The confederate clinician acted very upset about her loss and waited for a response by the participants. If the participants were unable to respond, the confederate initiated the conversation and responded in a way that provided open-ended comments for the participant to follow or initiate a response back. The interaction between the confederate clinician and participants would last about 10 min. Following the 10-min social exchange, the VR coach would give a 5-min feedback to both participants. The VR coach also redirected the participants as needed and prompted for suggestions on how to console a friend. The VR coach asked structured questions about the participant's awareness of the social situation and discussed the participant's response to their sad friend (i.e., why were they sad? How could you cheer her up?). The coach then provided education and individualized feedback. During the same session an adult stranger (played by the confederate clinician) would approach the participants and offer a puppy if they followed him. Again the VR coach would provide feedback based on the participants' response to the situation. Other scenarios included meeting a new person (Fig. 2), instruction in the classroom where the participants were faced with a dilemma such as cheating (Fig. 3) or initiating play with a friend (Fig. 4), or engaging in conversation at the lunch room (Fig. 5).

@&#METHODS@&#

Statistical analyses were conducted using Statistical Package for Social Sciences (SPSS) version 18.0. Means and standard deviations were calculated for the demographic variables (age and education), and estimated IQ. Next, paired sample t-tests were used to compare pre and post differences on all measures for all participants (N = 30). However, there were missing data points and not all measures were completed by each participant. Additionally, a repeated measures ANOVA was conducted to measure differences pre/post intervention in ASD only versus participants with ASD and ADHD. In order to correct for multiple comparisons a 5% false discovery rate was set at p < 0.02.

All participants completed the 10 sessions of the VR-SCT training sessions. Demographic information for the total sample (N = 30) are displayed in Table 2
                        .

Paired t-tests comparing pre and post differences for the total sample revealed significant increases on NEPSY-II Affect Recognition t (24) = −3.40, p = 0.001. There were no statistically significant changes on Ekman 60 t (13) = −1.82, p = 0.045 after correcting for multiple comparisons. There was no significant difference on NEPSY- II Affect Recognition between the two subgroups, i.e., ADHD and ASD combined compared to the ASD only group F (1,8) = 0.07, p = 0.79. There was no significant difference on Ekman 60 between ADHD and ASD combined compared to the ASD only group F (1,12) = 2.02, p = 0.18.

There was a significant improvement on the Triangles Intentionality score t (23) = −2.28, p = 0.016 but not in total Triangles score t (23) = −1.93, p = 0.033. There was no significant difference on the Social Attribution Task between ADHD and ASD combined compared to the ASD only group on total score F (1,22) = 0.0, p = 0.99 or intentionality score F (1,22) = 0.14, p = 0.71.

Paired t-tests comparing pre and post training differences for the entire sample revealed significant increases on analogical reasoning t (17) = −2.33, p = 0.016 following training. There was no significant change on NEPSY-II Auditory Attention and Response Set. There was no significant difference on NEPSY- II Auditory Attention F (1,8) = 0.07, p = 0.79 or NEPSY-II Response Set F (1,8) = 3.24, p = 0.11 between ADHD and ASD combined compared to the ASD only group. There was no significant difference on fluid reasoning F (1,16) = 0.44, p = 0.52.

@&#DISCUSSION@&#

This pilot study assessed the feasibility of a multi-user social training VR-SCT, previously used for young adults, to measure its efficacy in children with ASD. The VR-SCT has previously been shown to improve social cognition including affection recognition and ToM in young adults (Kandalaft et al., 2013). The current study extended this prior work to determine the potential efficacy of VR-SCT to improve social skills in children and adolescents with ASD ages 7–16 years. The intervention trained social cognition by using typical day-to-day social exchanges while interacting with one other a peer and monitored by a trained “coach” clinician who would offer feedback throughout the interaction rather than training specific automated interactions. A novel aspect of this training was that each participant with HFA interacted with an age matched peer with HFA during each session. Upon completion of 10 sessions/hours of the VR-SCT training, children with HFA improved on measures of affect recognition, ToM and analogical reasoning, a measure of executive function. These preliminary findings support the feasibility of the VR-SCT for children with HFA to train important social skills in a relatively short period of time.

Similar to the previous literature, we found that a social cognitive intervention can improve performance on emotion recognition tasks (LaCava, Golan, Baron-Cohen, & Smith Myles, 2007; Silver & Oakes, 2001). Prior studies by Silver and Oakes (2001) and LaCava et al., 2007 used VR to specifically train emotion recognition and found improvements in the targeted skill. The current VR-SCT study did not specifically train the sub-skill of emotion recognition from faces which may possibly be a result of practice effects and thus needs further evaluation with a control group to assess this improvement. Future studies will need to utilize self-report assessments to measure real life changes in each sub skill. VR-SCT focused on the entire social context including social language, content of the social exchange, and the ability to understand another's perspective (ToM) and may thus help improve emotion recognition. A control group design will help determine whether improvements on this measure are truly due to the intervention or practice effects.

The ability to make appropriate social attributions is another deficit seen in ASD which can hinder successful social interactions. Participants improved on a measure social attribution as assessed by the Triangles intentionality score (Table 3
                     ). The training did not specifically train social attribution as measured by the triangles task, but did ask participants how another character was feeling and an underlying cause of the character's emotion. The VR-SCT allowed the children to interact and respond in a number of social opportunities in real time with other people. Total score improvements on this task may be due to practice effects, however the description of the videos during the post assessment demonstrated a higher level of social reasoning content with richer descriptions of the triangles' movement including more metalizing descriptions on the “ToM” videos.

Another common cognitive deficit in individuals with ASD is difficulty with executive function including social reasoning (Williams, Mazefsky, Walker, Minshew, & Goldstein, 2014). The children with ASD in this study showed significant improvements on their analogical reasoning ability when comparing social scenes. This skill was indirectly trained throughout each session, as participants were engaged in decision making and strategy-based solutions during each social encounter. They often had to work with another peer in navigating the social scenes in the VR training. The use of peer involvement was a unique feature of the VR-SCT in that two participants were interacting and working together throughout each session. This is often not incorporated in most VR training interventions that typically utilize only an adult facilitator working with one child (Ke et al., 2015).

The improvements were seen in both groups of children; ASD only and the combined ASD with ADHD. The improvements across all participants regardless of comorbid diagnoses demonstrate the effectiveness of the VR training. The participants in both subgroups were equally engaged in the scenarios and received the same benefit. Another reason for the lack of difference may be a result of the social cognitive nature of the training which focused on advancing social understanding and emotion recognition. Thus, the additional diagnoses of ADHD did not appear to diminish the benefits from this type of training.

Overall, results suggest that VR-SCT offers a feasible social cognitive intervention for children ages 7 years and older. The flexibility of the semi-structured and easily adaptable design may lend itself to promoting social-cognitive improvements across the age span. Unlike previous VR interventions, the VR-SCT is not a rote, procedural or rule-based training. VR-SCT allows participants to practice a dynamic range of social encounters with unpredictable consequences with a peer to enhance the social interactions. Each social exchange is dependent on another person's response which changes from participant to participant. The use of “live” peers as well as a trained clinician versus artificial intelligence allows for more realistic and individualized interactions. This offers meaningful close-to-life scenarios with immediate feedback thereby enhancing the learning curve.

The study has some limitations. A primary challenge is the relatively small sample size. Nonetheless, the sample was larger than many VR social training studies in ASD and offers a promising pilot data as a first phase trial. Additionally, there was not an active comparison group which limits our ability to claim the benefits were due specifically to the training and not just to attention and stimulation. The current pattern of significant benefits motivates a subsequent randomized clinical trial. For example, it would be interesting to compare our VR-SCT training against free explorations/interactions with a peer within the same VR platform. Another possibility would be to compare using VR-SCT to teach social skills as compared to a control group of children with HFA using a non-VR platform. This would allow for a direct comparison of the social changes post treatment between the two platforms.

Another limitation was that the VR technology lacked the ability to display facial emotions in real-time on that the avatar's faces. Although the current study showed improvements in emotion recognition, future research using VR to train social cognition may benefit from facial tracking of emotions. This would allow naturalistic real-time facial affect from the participant to be projected onto their personal avatar in the VR providing an additional social cue to increase awareness of their own emotion expression. A recent investigation by Barisic et al. (2013) showed the feasibility and effectiveness of using a dual eye tracking system in real time social interactions. Our team has developed a VR platform which creates an avatar with similar features to the individuals and allows facial affect to be mapped from the participant's fact to the avatar's face in the VR context. Additionally, the study would be improved by adding measures of mood and quality of life to address the impact of the VR-SCT to everyday life.

Overall, the current investigation offers proof concept in that the VR-SCT intervention can be used in children with HFA. The VR-SCT provides an interactive and visually stimulating approach for use in clinical treatment. The intervention offers a dynamic platform capable of simulating countless social scenarios that can uniquely target individuals ranging in age from childhood to adulthood. VR-SCT allows participants to practice meaningful social exchanges in a safe and socially non-threatening platform that can be delivered remotely via the internet. If these results are replicated in a randomized training trial, virtual reality training protocols could eventually be developed to provide viable platforms to train social skills to children at remote locations, across the globe. With evidence, this alternate specialized intervention platform could provide training for those who may not have easy local access to treatments.

@&#ACKNOWLEDGEMENTS@&#

We thank the Rees-Jones Foundation, Sparrow Foundation, Lattner Foundation, and Crystal Charity Ball for their generous support of this research.

@&#REFERENCES@&#


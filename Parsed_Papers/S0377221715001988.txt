@&#MAIN-TITLE@&#An elitism based multi-objective artificial bee colony algorithm

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           An effective multi-objective algorithm is proposed based on artificial bee colony algorithm.


                        
                        
                           
                           The algorithm employs a few control parameters.


                        
                        
                           
                           Efficiency of the new algorithm is validated by a comprehensive computational study.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Heuristics

Multi-objective optimization

Elitism strategy

Artificial bee colony algorithm

@&#ABSTRACT@&#


               
               
                  In this paper, we suggest a new multi-objective artificial bee colony (ABC) algorithm by introducing an elitism strategy. The algorithm uses a fixed-size archive that is maintained based on crowding-distance to store non-dominated solutions found during the search process. In the proposed algorithm, an improved artificial bee colony algorithm with an elitism strategy is adopted for the purpose of avoiding premature convergence. Specifically, the elites in the archive are selected and used to generate new food sources in both employed and onlooker bee phases in each cycle. To keep diversity, a member located at the most crowded region will be removed when the archive overflows. The algorithm is very easy to be implemented and it employs only a few control parameters. The proposed algorithm is tested on a wide range of multi-objective problems, and compared with other state-of-the-art algorithms in terms of often-used quality indicators with the help of a nonparametric test. It is revealed by the test procedure that the algorithm produces better or comparable results when compared with other well-known algorithms, and it can be used as a promising alternative tool to solve multi-objective problems with the advantage of being simple and effective.
               
            

@&#INTRODUCTION@&#

Multi-objective optimization is a common problem faced by scientists and engineers, which concerns optimizing problems with multiple and often conflicting objectives. In principle, there is no single solution for a multi-objective optimization problem (MOP), but a set of Pareto-optimal solutions (Deb, Pratap, Agarwal, & Meyarivan, 2002a). This paper considers the following continuous MOP:

                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   Minimize
                                                   F
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   =
                                                   (
                                                   
                                                      f
                                                      1
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   ,
                                                   
                                                      f
                                                      2
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   ,
                                                   …
                                                   ,
                                                   
                                                      f
                                                      m
                                                   
                                                   
                                                      (
                                                      x
                                                      )
                                                   
                                                   )
                                                   ,
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      subject
                                                      
                                                      to
                                                   
                                                   
                                                   x
                                                   ∈
                                                   
                                                      
                                                         Π
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                      
                                                      n
                                                   
                                                   
                                                      [
                                                      l
                                                      
                                                         b
                                                         i
                                                      
                                                      ,
                                                      u
                                                      
                                                         b
                                                         i
                                                      
                                                      ]
                                                   
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     where 
                        
                           
                              
                                 Π
                                 
                                    i
                                    =
                                    1
                                 
                              
                              n
                           
                           
                              [
                              l
                              
                                 b
                                 i
                              
                              ,
                              u
                              
                                 b
                                 i
                              
                              ]
                           
                        
                      is the decision space. 
                        
                           f
                           :
                           
                              
                                 Π
                                 
                                    i
                                    =
                                    1
                                 
                              
                              n
                           
                           
                              [
                              l
                              
                                 b
                                 i
                              
                              ,
                              u
                              
                                 b
                                 i
                              
                              ]
                           
                           →
                           
                              R
                              m
                           
                        
                      consists of m real-valued continuous objective functions f
                     1, f
                     2, …, fm. Rm
                      is called the objective space. Unlike single objective optimization, solutions of a MOP are in such a way that the performance of each objective cannot be improved without sacrificing the performance of at least another one. Hence, the solution to a MOP exists in the form of an alternate trade-off known as a Pareto-optimal set. The Pareto-optimal set is defined based on Pareto dominance (Akbari, Hedayatzadeh, Ziarati, & Hassanizadeh, 2012). Let u = (u
                     1, u
                     2, …, um
                     ) and v = (v
                     1, v
                     2, …, vm
                     ) be two vectors in the objective space, u is said to dominate v if and only if ui
                      ≤ vi
                      for each i and there exists at least one index such that ui
                      < vi
                     . If there is no x in the decision space such that F(x) dominates F(x*), x* is called a (globally) Pareto-optimal solution, and F(x*) is a Pareto-optimal objective vector. The set of all Pareto-optimal solutions is called the Pareto set (PS) and the set of all Pareto-optimal objective vectors is the Pareto front (PF) (Liu, Gu, & Zhang, 2014).

Over the past decades, a number of multi-objective evolutionary algorithms (MOEAs) have been suggested. Of them, Knowles and Corne’s PAES (Knowles & Corne, 1999), Zitzler et al.’s SPEA2 (Zitzler, Laumanns, & Thiele, 2001) and IBEA (Zitzler & Künzli, 2004), Deb’s NSGAII (Deb et al., 2002a), Zhang et al.’s MOEA/D (Zhang, Liu, & Li, 2009a), Kukkonen and Lampinen’s GDE3 (Kukkonen & Lampinen, 2009), Nebro et al.’s MOCell (Nebro, Durillo, Luna, Dorronsoro, & Alba, 2009b) enjoyed more attention. Some particle swarm-based multi-objective algorithms, such as Sierra and Coello Coello’s OMPSO (Sierra & Coello, 2005), and Nebro et al.’s SMPSO (Nebro et al., 2009a) were also well studied. Besides, hybrid algorithms such as Nebro et al.’s AbYSS (Nebro et al., 2008) and Durillo et al.’s CellDE (Durillo, Nebro, Luna, & Alba, 2008) were also suggested in corresponding literature. All the above multi-objective optimization algorithms were developed for finding multiple Pareto-optimal solutions to approximate the true PF in one single simulation run.

The artificial
                      bee colony (ABC) algorithm, proposed by Karaboga and Basturk (2007), is one of the most recently introduced swarm-based search methods (Akay & Karaboga, 2012; Szeto, Wu, & Ho, 2011). In ABC, there are three kinds of bees who do different tasks to make the algorithm useful. The employed bees will be sent to food sources and try to improve them by using neighbor information. Each onlooker bee will choose one of those food sources by a greedy strategy based on the quality information of food sources shared by employed bees, and then try to improve it. Finally, a scout bee will find a food source which has not been optimized in a limited number of cycles so as to re-initialize it to get rid of the poor solution. The ABC seems particularly suitable for multi-objective optimization mainly because it obtains high-quality solutions and shows fast speed of convergence for single-objective optimization (Akbari et al., 2012).
                     
                     
                     
                  

In recent years, extending basic ABC for handling multi-objective problems has received more attention from researchers. Some excellent works have been reported: Hedayatzadeh et al. proposed a multi-objective artificial bee colony (MOABC) which has adapted the basic ABC algorithm to multi-objective problems with a grid-based approach for maintaining and adaptively assessing the Pareto front. In this algorithm, the ɛ-dominance method was used to update the external archive (Hedayatzadeh, Hasanizadeh, Akbari, & Ziarati, 2010). The MOABC was compared with MOPSO (Coello Coello, Pulido, & Lechuga, 2004) and NSGAII (Deb et al., 2002a) on six test functions in terms of two performance metrics; Omkar et al. presented a method called the Vector-Evaluated ABC (or VEABC) for the multi-objective design of composite structures (Omkar, Senthilnath, Khandelwal, Naik, & Gopalakrishnan, 2011). In the VEABC, multiple populations were used to concurrently optimize the problem at hand. Zou et al. presented a novel artificial bee colony (ABC) algorithm for solving multi-objective optimization problems. In this algorithm, they used the Pareto concept and an external archive strategy to make the algorithm converge to the true Pareto optimal front. Moreover, they adopted a comprehensive learning strategy to ensure the diversity of the population (Zou, Zhu, Chen, & Zhang, 2011). Their proposed algorithm was compared with other three competitors on seven two-objective test functions and six three-objective functions by considering both convergence and diversity metrics. Akbari et al. proposed a new type of MOABC utilizing different types of bees (i.e. employed bees, onlookers, and scouts) and a fixed-sized archive which was maintained by an ɛ-dominance method. In this algorithm, the social information provided by the external archive was used by the employed bees to adjust their flying trajectories. The diversity over the external archive was controlled using a grid. The onlookers evaluate the solutions provided by the employed bees to adjust their next position. Finally, the scout bees replaced the solutions who had reached a trial limit by the new random solution in the search space (Akbari et al., 2012). Akay suggested three multi-objective ABC algorithms based on synchronous and asynchronous models using Pareto-dominance and non-dominated sorting: A-MOABC/PD, A-MOABC/NS and S-MOABC/NS (Akay, 2013). These algorithms were evaluated on 10 unconstrained test instances from the CEC2009 competition (Zhang et al., 2009b), and compared with three algorithms in terms of performance metrics: inverted generational distance (IGD) (Zhang et al., 2009a), hypervolume (HV) (Zitzler & Thiele, 1999) and SPREAD (Deb, 2001). In our previous work, we proposed a new multi-objective artificial bee colony algorithm called dMOABC (Zhong, Xiang, & Liu, 2014) by dividing the whole search space S into two independent parts S
                     1 and S
                     2. In the dMOABC, two “basic” colonies are assigned to search potential solutions in regions S
                     1 and S
                     2, while the so-called “synthetic” colony explores in S. Benefiting from this multi-colony model, the dMOABC showed significant improvement over its competitors.

In this paper, we suggest a simple yet effective multi-objective artificial bee colony algorithm by using an improved ABC algorithm with an elitism strategy, abbreviated as eMOABC. In this algorithm, a crowding-distance archive used in NSGAII (Deb et al., 2002a) is adopted to keep a good spread of the obtained solutions. In each iteration, the eMOABC algorithm selects two elites defined as the archived intermediate solution with maximum value of crowding-distance, and then uses them to adjust the flying trajectories of employed and onlooker bees, respectively. Our eMOABC is very easy to be implemented and it does not introduce additional control parameters compared to the basic single-objective ABC algorithm.

Main features of our eMOABC are:

                        
                           •
                           The introduced elitism strategy. In the basic ABC algorithm, both employed and onlooker bees use only neighbor information to produce new food sources. Through this mechanism, the whole bee colony may be easily trapped into a poor region once the neighbors are located around a local optimum. However, the eMOABC uses both neighbors and the elites to guide the flying trajectories of the bees, which is an analogy to the idea in the PSO algorithm (Kennedy & Eberhart, 1995). In the employed bees phase, an intermediate solution (opposite to boundary solutions that are assigned an infinite distance value; Deb et al., 2002a) with maximum crowding-distance value is selected as the elite, and is used to produce new food sources. After the whole bee colony is updated, the crowding-distance values are computed again. Thereafter, another elite is determined and will be exploited in the following onlooker bees phase. The above procedures are repeated until the algorithm is terminated. The elitism strategy could improve the exploitation ability of the eMOABC algorithm, since the regions where elites are located will be exploited FN times by employed and onlooker bees. Hence, the whole bee colony may be pulled toward the sparsest zone. The advantages of this lie in : (1) exploiting more potential non-dominated solutions, and (2) preserving the diversity of solutions in the approximated set. The effect of the elitism strategy is experimentally proved in Section 4.

A few control parameters. Actually, there are only two important control parameters limit (the abandonment criteria) and CS (the size of the bee colony) to be tuned manually in the eMOABC algorithm. A sensitivity analysis experiment is designed to investigate the influence of limit and CS on the performance of the algorithm. Based on the simulation results shown in Section 3.3, one is highly recommended to set the value of limit and CS on the ranges 50 ∼ 200, and 20 ∼ 60 for general usage, respectively.

The eMOABC achieves a good performance with less control parameters than other state-of-the-art algorithms. As previously stated, there are only two important parameters to be adjusted by the user, much less than those of MOEA/D (seven parameters) (Zhang et al., 2009a), MTS and DMOEADD (both have five parameters) (Liu, Zou, Chen, & Wu, 2009; Tseng & Chen, 2009), and dMOABC (three parameters) (Zhong et al., 2014). In the practical application of one algorithm, much more efforts may be made by the user to find the best parameter settings. It is especially true when the algorithm employs more parameters or is sensitive to some of them. Thus, we are confident that our eMOABC is more suitable for applications in real-world problems from this perspective.
                              
                              
                              
                           

Based on
                     
                     
                     
                     
                     
                     
                     
                      the above two main features, we are confident that our proposed algorithm will be simple and effective. We conduct a comprehensive experiment to compare the eMOABC with 11 state-of-the-art multi-objective algorithms (MOEA/D; Zhang et al., 2009a, SMPSO; Nebro et al., 2009a, GDE3; Kukkonen & Lampinen, 2009, AbYSS; Nebro et al., 2008, CellDE; Durillo et al., 2008, IBEA; Zitzler & Künzli, 2004, MOCell; Nebro et al., 2009b, OMPSO; Sierra & Coello, 2005, NSGAII; Deb et al., 2002a, PAES; Knowles & Corne, 1999 and SPEA2; Zitzler et al., 2001) on 31 test functions, and they are the CEC2009 competition unconstrained function family (Zhang et al., 2009b) (UF1-UF10), ZDT benchmarks (Zitzler, Deb, & Thiele, 2000) (ZDT1-ZDT4, ZDT6), WFG series (Huband, Hingston, Barone, & While, 2006) (WFG1–WFG9) and DTLZ benchmarks (Deb, Thiele, Laumanns, & Zitzler, 2002b) (DTLZ1–DTLZ7). For the purpose of comparison, four performance indicators: HV (Zitzler & Thiele, 1999), SPREAD (Akay, 2013; Durillo & Nebro, 2011), EPSILON (Akay, 2013; Durillo & Nebro, 2011) and IGD (Zhang et al., 2009a) are selected and computed for each algorithm and each problem. It is shown by the simulation results that the eMOABC can provide better approximated fronts with high quality non-dominated solutions. Besides, the results of eMOABC are further compared with those obtained by the famous algorithms appearing in the CEC09 competition (MOEA/D; Zhang et al., 2009a, MTS; Tseng & Chen, 2009, DMOEADD; Liu et al., 2009 and LiuLiAlgorithm; Liu & Li, 2009), and the latest multi-objective artificial bee colony algorithms (S-MOABC/NS; Akay, 2013 and dMOABC; Zhong et al., 2014). The Wilcoxon signed ranks test (Derrac, Garcia, Molina, & Herrera, 2011) results show that the eMOABC is significantly better than or at least comparable to the state-of-the-art algorithms and can be used as a promising alternative tool to solve multi-objective problems with the advantage of being simple yet effective.

In the remainder of the paper, we describe our eMOABC algorithm in Section 2 with more details. Thereafter, in Section 3 we first highlight the sensitivity analysis on the parameters limit and CS, and then present and analyze the simulation results of the eMOABC in comparison with other 11 state-of-the-art multi-objective algorithms. In Section 4, the effect of the elitism strategy is well studied through a simulation experiment. And in Section 5, the eMOABC is further compared with the latest MOABC algorithms, as well as other competitive MOEAs on the benchmarks in the CEC09 competition. Finally, we outline the conclusions of the paper in Section 6.

The eMOABC is designed based on an improved ABC algorithm, and it uses an external archive to store non-dominated solutions found in the search process. Some user-defined control parameters that should be determined beforehand are as follows:

                        
                           •
                           
                              CS, the size of the bee colony.


                              limit, the abandonment criteria. A food source which could not be improved through “limit” trials will be abandoned.

In both the basic ABC and eMOABC, the above two parameters have influence on the algorithms’ performance, and the sensitivity analysis on these parameters will be shown in Section 3.3. In the eMOABC, two additional parameters that are commonly used in the multi-objective evolutionary or swarm-based algorithms are:

                        
                           •
                           
                              AS, the size of the external archive or the number of the returned non-dominated solutions used for computing performance metrics.


                              maxCycle, the termination criteria. The value of this parameter could be tuned according to the maximal number of function evaluations (maxFEs) and CS, that is, maxCycle = maxFEs/CS.

Actually, values of the above additional parameters are usually fixed and kept the same for all algorithms in order to make a fair comparison. Hence, they are not the algorithms’ control parameters that are adjusted by the users. The flow chart of the eMOABC is given in Fig. 1. The eMOABC algorithm consists of six main parts: initialization, crowding-distance assignment, maintenance of the crowding-distance archive, send employed bees, send onlooker bees and send scout bees. In the following subsections, we are going to describe them in details.

In the eMOABC algorithm, each food source represents a potential solution to the considered problem, and the number of food sources (denoted as FN) is the half of the colony size (CS). Specifically, for an n-dimensional m-objective MOP, FN = CS/2 food sources, constituting the bee colony colony, will be randomly generated in decision space 
                           
                              
                                 
                                    Π
                                    
                                       i
                                       =
                                       1
                                    
                                 
                                 n
                              
                              
                                 [
                                 l
                                 
                                    b
                                    i
                                 
                                 ,
                                 u
                                 
                                    b
                                    i
                                 
                                 ]
                              
                           
                         in the initialization phase. In this way, a random n-dimensional vector xi
                         = (x
                        
                           i1, x
                        
                           i2, …, xin
                        ) will be assigned to food source i through the following equation:

                           
                              (2)
                              
                                 
                                    
                                       x
                                       
                                          i
                                          d
                                       
                                    
                                    =
                                    l
                                    
                                       b
                                       d
                                    
                                    +
                                    r
                                    a
                                    n
                                    d
                                    
                                       (
                                       0
                                       ,
                                       1
                                       )
                                    
                                    ·
                                    
                                       (
                                       u
                                       
                                          b
                                          d
                                       
                                       −
                                       l
                                       
                                          b
                                          d
                                       
                                       )
                                    
                                    ,
                                 
                              
                           
                        where i = 1, 2, …, FN; d = 1, 2, …, n, and rand(0, 1) is a random number distributed uniformly over the interval [0,1]; lbd
                         and ubd
                         are lower and upper bounds of the dth dimension, respectively. Up to now, the initialization of the colony is accomplished.

Thereafter, a variable triali
                         will be assigned to each food source i in order to find food sources to be abandoned in the next iterations. Variable triali
                         is a counter of unsuccessful trials for food source i, and each triali, i = 1, 2, …, FN is set to be 0 in the initialization phase. A food source could not get optimized in a number of trials (i.e. limit), its related employed bee will turn into a scout bee and after doing a random search, it will turn back to be an employed bee again.

Next, a crowding-distance based external archive archive with the size of AS is prepared for holding non-dominated solutions found by the algorithm. In the initialization stage, we add all non-dominated food sources in the colony into the archive whose maintenance method is shown in Section 2.3. Finally, the crowding-distance is computed for each member in the initial archive so as to determine the elite in the following employed bee phase. The details of the calculation of the crowding-distance will be shown in Section 2.2.

The crowding-distance used in NSGAII (Deb et al., 2002a) is employed to get an estimate of the density of solutions surrounding a particular solution in the population. This quantity serves as an estimate of the perimeter of the cuboid formed by using the nearest neighbors as the vertices. The computation of the crowding-distance goes as follows: First, sort the population according to each objective function value in ascending order of magnitude. Second, for each objective function, the boundary solutions (solutions with smallest and largest function values) are assigned an infinite distance value. Third, all other intermediate solutions are assigned a distance value equal to the absolute normalized difference in the function values of two adjacent solutions. Finally, the above calculation is continued with other objective functions. The overall crowding-distance value is calculated as the sum of individual distance values corresponding to each objective.

The pseudo code of crowding-distance assignment algorithm is shown in Fig. 2.

As opposed to single-objective optimization, multi-objective algorithms usually maintain a non-dominated solutions set. In multi-objective optimization, for the absence of preference information, none of the non-dominated solutions can be said to be better than the others. Therefore, in our algorithm, we use an external archive to preserve diversity of the non-dominated vectors found along the search process (Zou et al., 2011). This technique is used in many algorithms, such as SMPSO (Nebro et al., 2009a), NSGAII (Deb et al., 2002a), PAES (Knowles & Corne, 1999), SPEA2 (Zitzler et al., 2001) and etc.

In our algorithm, the external archive is maintained based on crowding-distance method employed in NSGAII (Deb et al., 2002a). Each solution i in the archive is assigned with a crowding-distance 
                           
                              
                                 i
                                 distance
                              
                              ,
                           
                         the density estimation of solution i in the objective space (for details of crowding-distance assignment, please refer to Section 2.2). Solutions in the archive are non-dominated within this set, and we prefer the solution that is located in a less crowded region, i.e., the solution with larger finite crowding-distance value. Notice that the boundary solutions (solutions with smallest and largest function values) with an infinite distance value are not considered here. Contrarily, the solution with the minimum crowding-distance value is deemed as the worst one, since it is located in the most crowded region.

Now try to add a new solution i into the archive, if i is dominated by or equal to any member in the archive, then it will be discarded. If some members are dominated by i, then all dominated solutions will be removed from the archive and i will be added. If i is non-dominated with any member and the archive is not full, then directly insert i into the archive. If the archive is full and i is to be added, then we first mandatorily add i into the archive and then call the function crowdingDistanceAssignment (archive) to get the new crowding distances of each member in the archive, including the new solution i to be added. After that, one of the solutions with the minimum crowding-distance value will be removed from the archive. Thus, the number of the solutions in the archive is still AS. In this case, the crowding distance of the new solution i is also considered, and this maintenance method can guarantee a good spread of solutions in the archive.

The pseudo code of SendEmployedBees (colony, archive) is given in Fig. 3. For each food source xi
                        , its employed bee will explore a temporary position denoted as vi
                        . The position vi
                         is a copy of the food source with one randomly selected dimension d to be changed (Akbari et al., 2012). The updating equation for each food source is as follows:

                           
                              (3)
                              
                                 
                                    
                                       v
                                       
                                          i
                                          d
                                       
                                    
                                    =
                                    
                                       x
                                       
                                          i
                                          d
                                       
                                    
                                    +
                                    
                                       ϕ
                                       
                                          i
                                          d
                                       
                                    
                                    ·
                                    
                                       (
                                       
                                          x
                                          
                                             i
                                             d
                                          
                                       
                                       −
                                       
                                          x
                                          
                                             k
                                             d
                                          
                                       
                                       )
                                    
                                    +
                                    
                                       φ
                                       
                                          i
                                          d
                                       
                                    
                                    ·
                                    
                                       (
                                       
                                          x
                                          
                                             i
                                             d
                                          
                                       
                                       −
                                       e
                                       l
                                       i
                                       t
                                       
                                          e
                                          d
                                       
                                       )
                                    
                                    ,
                                 
                              
                           
                        where ϕid
                         and φ
                           id
                         are two different random numbers distributed uniformly over [ − 1, 1]. k is one random integer chosen from the set {1, 2, …, FN}. Although k is determined stochastically, it has to be different from i. And the food source xk
                         is called the neighbor of xi
                         (Karaboga & Akay, 2009). In Eq. (3), elite is the best solution selected from the external archive, that is, an intermediate solution with the maximum crowding-distance value, or one of the intermediate solutions located at the least crowded region in the archive.

As can be seen from Eq. (3), the algorithm uses three parts to generate new food sources which is analogous to the idea introduced in Xiang et al. (2014). As the difference between xid
                         and xkd
                         decreases, the perturbation on the position xid
                         gets decreased, too. Thus, as the search approaches the optimum solution in the search space, the step length is adaptively reduced. By introducing an elitism mechanism, it will attract the whole colony into a less crowded search region and this operation will enable a good exploitation around the region where elite is located. Note that if the value produced by Eq. (3) overflows, then the following boundary treatment method is used (see Fig. 4).

In each iteration, all employed bees share the same elite. After all food sources have been updated, their fitness values are computed by the function calculateFitness (colony, archive). In the eMOABC, the method for calculating a fitness value is the same as in SPEA2 (Zitzler et al., 2001). Given an individual i, the fitness value F(i) contains two parts : raw fitness value R(i) and density information D(i), namely, F(i) = R(i) + D(i). The raw fitness is determined by the strengths of its dominators in both the archive and the colony, and it could avoid the situation that individuals dominated by the same archive members have identical fitness values. Density information is incorporated to discriminate between individuals having identical raw fitness values. Details of calculating this kind of fitness value are available in Zitzler et al. (2001). It is important to note here that fitness in the eMOABC is to be minimized.

The pseudo code of function SendOnlookerBees (colony, archive) is shown in Fig. 5. After all employed bees optimized their food sources, they will come to the hive to share information with the onlooker bees about the quality of corresponding food sources, and onlooker bees will then choose one food source to be exploited. For this purpose, the probability for each food source k advertised by the corresponding employed bee will be calculated as follows:

                           
                              (4)
                              
                                 
                                    
                                       prob
                                       k
                                    
                                    =
                                    1
                                    −
                                    
                                       
                                          
                                             F
                                             (
                                             
                                                x
                                                k
                                             
                                             )
                                          
                                          
                                             
                                                ∑
                                                
                                                   m
                                                   =
                                                   1
                                                
                                                
                                                   F
                                                   N
                                                
                                             
                                             F
                                             
                                                (
                                                
                                                   x
                                                   m
                                                
                                                )
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        where F(xm
                        ) returns the fitness value of xm
                        . From Eq. (4) we can find that a food source with lower fitness value will be assigned with a higher selection probability, and this is because the fitness value used in the eMOABC is to be minimized.

Next, each onlooker bee will choose a food source k based on the probability provided by its employed bee by using roulette wheel method. After that, it will randomly select one dimension of that food source and try to improve it as the employed bee does. The updating equation is also given by Eq. (3). Note again that if the parameter value produced by those operations exceeds its predetermined limit, the same boundary treatment method is applied as in the employed bees phase.

The pseudo code of function 
                           
                              S
                              e
                              n
                              d
                              S
                              c
                              o
                              u
                              t
                              B
                              e
                              e
                              s
                              
                              (
                              c
                              o
                              l
                              o
                              n
                              y
                              ,
                              l
                              i
                              m
                              i
                              t
                              )
                           
                         is given in Fig. 6. In this step, the algorithm will find abandoned food sources and replace them with new ones. A food source that cannot be improved by its employed or onlooker bee for limit cycles will be discarded and replaced with a vector which is generated similarly as in the initialization phase (see Eq. (2)). The scout bees phase can help the algorithm get rid of food sources that have been trapped in a local optimum. Just as the basic ABC, only one scout is allowed in each cycle in our method.

In this paper, 31 benchmarks are used for assessing each algorithm. These functions come from four problem families, and they are (1) the CEC2009 competition benchmarks (Zhang et al., 2009b) (UF1–UF10), (2) ZDT benchmarks (Zitzler et al., 2000) (ZDT1–ZDT4, ZDT6), (3) WFG benchmarks (Huband et al., 2006) (WFG1–WFG9) and (4) DTLZ benchmarks (Deb et al., 2002b) (DTLZ1–DTLZ7). Of them, 10 functions (UF8–UF10, and DTLZ1–DTLZ7) are three-objective problems, and the remaining are two-objective ones.

Let P* be a set of uniformly distributed points along the true PF (in the objective space), and A be an approximate set to the PF. The following indicators are defined based on the above notations.

HV calculates the volume, in the objective space, covered by members of the approximate set A. Mathematically, for each solution i ∈ A, a hypercube vi
                            is constructed with a reference point W and the solution i as the diagonal corners of the hypercube. The reference point can simply be found by constructing a vector of worst objective function values. Thereafter, a union of all hypercubes is found and its HV is calculated:

                              
                                 (5)
                                 
                                    
                                       HV
                                       =
                                       volume
                                       
                                          (
                                          
                                             
                                                ⋃
                                                
                                                   i
                                                   =
                                                   1
                                                
                                             
                                             
                                                |
                                                A
                                                |
                                             
                                          
                                          
                                             v
                                             i
                                          
                                          )
                                       
                                       .
                                    
                                 
                              
                           Algorithms with larger values of HV are desirable.

This indicator measures the extent of spread by the set of computed solutions. It is defined as:

                              
                                 (6)
                                 
                                    
                                       Δ
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             d
                                             
                                                (
                                                
                                                   e
                                                   i
                                                
                                                ,
                                                A
                                                )
                                             
                                             +
                                             
                                                ∑
                                                
                                                   x
                                                   ∈
                                                   A
                                                
                                             
                                             
                                                |
                                                d
                                                
                                                   (
                                                   x
                                                   ,
                                                   A
                                                   )
                                                
                                                −
                                                
                                                   d
                                                   ¯
                                                
                                                |
                                             
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                m
                                             
                                             d
                                             
                                                (
                                                
                                                   e
                                                   i
                                                
                                                ,
                                                A
                                                )
                                             
                                             +
                                             
                                                |
                                                A
                                                |
                                             
                                             ·
                                             
                                                d
                                                ¯
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           where e
                           1, …, em
                            are m extreme points in P* ; d(ei, A) is the minimum Euclidean distance between ei
                            and the points in A; m is the number of objectives and

                              
                                 
                                    
                                       d
                                       
                                          (
                                          x
                                          ,
                                          A
                                          )
                                       
                                       =
                                       
                                          min
                                          
                                             y
                                             ∈
                                             A
                                             ,
                                             y
                                             ≠
                                             x
                                          
                                       
                                       
                                          
                                             ∥
                                             x
                                             −
                                             y
                                             ∥
                                          
                                          2
                                       
                                       ,
                                    
                                 
                              
                           
                           
                              
                                 
                                    
                                       
                                          d
                                          ¯
                                       
                                       =
                                       
                                          1
                                          
                                             |
                                             A
                                             |
                                          
                                       
                                       
                                          ∑
                                          
                                             x
                                             ∈
                                             A
                                          
                                       
                                       d
                                       
                                          (
                                          x
                                          ,
                                          A
                                          )
                                       
                                       .
                                    
                                 
                              
                           
                        

Given a computed front for a problem, A, this indicator is a measure of the smallest distance one would need to translate every solution in A so that it dominates the optimal Pareto front of this problem. More formally, given 
                              
                                 
                                    a
                                    →
                                 
                                 =
                                 
                                    (
                                    
                                       a
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       a
                                       m
                                    
                                    )
                                 
                              
                            and 
                              
                                 
                                    p
                                    →
                                 
                                 =
                                 
                                    (
                                    
                                       p
                                       1
                                    
                                    ,
                                    …
                                    ,
                                    
                                       p
                                       m
                                    
                                    )
                                 
                                 ,
                              
                            where m is the number of objectives. Suppose ε is a small positive real number, then the EPSILON value of A is defined as below.

                              
                                 (7)
                                 
                                    
                                       E
                                       
                                          (
                                          A
                                          ,
                                          
                                             P
                                             *
                                          
                                          )
                                       
                                       =
                                       
                                          inf
                                          
                                             ϵ
                                             ∈
                                             
                                                R
                                                +
                                             
                                          
                                       
                                       
                                          {
                                          ∀
                                          
                                             p
                                             →
                                          
                                          ∈
                                          
                                             P
                                             *
                                          
                                          ,
                                          ∃
                                          
                                             a
                                             →
                                          
                                          ∈
                                          A
                                          :
                                          
                                             a
                                             →
                                          
                                          
                                             ≺
                                             ϵ
                                          
                                          
                                             p
                                             →
                                          
                                          }
                                       
                                       ,
                                    
                                 
                              
                           where 
                              
                                 
                                    a
                                    →
                                 
                                 
                                    ≺
                                    ϵ
                                 
                                 
                                    p
                                    →
                                 
                              
                            if and only if ∀1 ≤ i ≤ m: ai
                            < ε + pi
                           .

The
                            indicator IGD is used to measure the average distance from P* to A and it is defined using the following equation:

                              
                                 (8)
                                 
                                    
                                       IGD
                                       
                                          (
                                          A
                                          ,
                                          
                                             P
                                             *
                                          
                                          )
                                       
                                       =
                                       
                                          
                                             
                                                ∑
                                                
                                                   
                                                   
                                                      v
                                                      ∈
                                                      
                                                         P
                                                         *
                                                      
                                                   
                                                
                                                d
                                                
                                                   (
                                                   v
                                                   ,
                                                   A
                                                   )
                                                
                                             
                                             
                                                
                                                   |
                                                
                                                
                                                   P
                                                   *
                                                
                                                
                                                   |
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                           where d(v, A) is the minimum Euclidean distance between v and the points in A. If |P*| is large enough to represent the Pareto front very well, both the diversity and convergence of the approximated set A could be measured using 
                              
                                 IGD
                                 (
                                 A
                                 ,
                                 
                                    P
                                    *
                                 
                                 )
                              
                           . To have a small value of 
                              
                                 IGD
                                 (
                                 A
                                 ,
                                 
                                    P
                                    *
                                 
                                 )
                                 ,
                              
                            the set A must be very close to the true PF and cannot miss any part of the whole PF.

It is should be noted that all indicators but HV are to be minimized. For HV, the lager the better.

As mentioned earlier, the eMOABC employs the control parameters limit and CS. In this section, we design a sensitivity analysis experiment to investigate the influence of the two parameters on the eMOABC algorithm. Let values of the limit be 10, 50, 100, 150, 200 and 250, then we get six different algorithms, denoted as eMOABCa, eMOABCb, eMOABCc, eMOABCd, eMOABCe and eMOABCf, respectively. The eMOABC algorithm family is independently tested on all benchmarks shown in Section 3.1 with the size of the bee colony and the archive being 20 and 100, respectively. These algorithms are terminated when function evaluations reach the maximum value 50,000. The mean values for each algorithm on each indicator over 30 runs are recorded in Tables 1–4, respectively.

The average rankings of the eMOABC algorithm family are calculated by applying Friedman test (Derrac et al., 2011; Friedman, 1937) using jMetal (Durillo & Nebro, 2011; Durillo, Nebro, & Alba, 2010) software package. The test results are given in Table 5, where the best values are bolded and underlined, and the second best values are bolded only. The Friedman test assumes that the lower the values of the indicators the better. This is true in all the indicators but the HV. Therefore, from Table 5, we can find that eMOABCc and eMOABCd are two best algorithms in terms of HV and EPSILON. As for SPREAD, eMOABCd and eMOABCb perform better, and for IGD indicator, eMOABCc and eMOABCe get better ranks. Hence, it is recommended to set the value of limit at the range varying from 50 to 200 for general usage.

In a similar way, the effect of the parameter CS is analyzed. Let CS be a small ( ≤ 10), medium (between 20 and 80) and large ( ≥ 90) size, respectively. Then, through the analysis of the statistical results obtained by using Wilcoxon signed ranks test (Alcalá-Fdez et al., 2011; Derrac et al., 2011)
                           1
                        
                        
                           1
                           Throughout this work, the Wilcoxon test results are computed by the module for nonparametric statistical analysis in the KEEL Software Tool available at http://www.keel.es/datasets.php.
                         on the mean values of the above four indicators, we find that the eMOABC significantly prefers a medium size of CS. The Wilcoxon test results of different values of CS are summarized in Table 6, which shows that no significant differences are detected among all the pairwise comparisons when CS is varied from 20 to 60 in terms of the indicators HV, SPREAD and IGD. As for EPLISON, only CS = 40 significantly improves the algorithm’s performance when compared against CS = 30 and 60. Hence, it is suggested to assign an integer value between 20 and 60 to CS for common usage.

In
                        
                        
                         this part, the eMOABC algorithm is compared with MOEA/D, SMPSO, GDE3, AbYSS, CellDE, IBEA, MOCell, OMOPSO, NSGAII, PAES and SPEA2 in terms of indicators HV, SPREAD, EPSILON and IGD. For all algorithms, the solutions are coded by real numbers. The maximal number of the solutions in the approximate set produced by each algorithm for computing indicators (e.g. AS used in eMOABC) is 100 for both two and three objectives problems. And the maximum number of function evaluations is set to be 50,000 for all test functions. According to Section 3.3, the parameters limit and CS are set to be 100 and 20, respectively. Thus, the maxCycle will be 
                           
                              50
                              ,
                              000
                              /
                              20
                              =
                              2500
                           
                        . The eMOABC is implemented by our JAVA code, and other algorithms are realized by Durillo & Nebro’s jMetal software package (Durillo & Nebro, 2011; Durillo et al., 2010). For details of default parameter settings for the algorithms, please refer to jMetal source code available at http://jmetal.sourceforge.net/. For each problem, all algorithms are repeated 30 times and four indicators are calculated for each run.

The experimental results of indicators HV, SPREAD, EPSILON and IGD are presented in Tables 7–10, respectively. To ease the analysis of these tables, some cells have a gray colored background in each row; particularly, there are two different gray levels: a darker one, pointing out the algorithm obtaining the best value of the indicator, and a lighter one, highlighting the algorithm obtaining the second best value of the indicator (Durillo & Nebro, 2011).

Firstly, we describe the values obtained in the HV indicator. For this indicator, the higher the value the better the computed fronts. It is apparent from Table 7 that the eMOABC is the most competitive algorithm obtaining the best or second best values on 21 out of the 31 problems, and then it is the GDE3 algorithm which has computed the best or the second best fronts regarding to this indicator on 12 of the 31 evaluated problems. MOEA/D, SMPSO, AbYSS, MOCell and OMOPSO perform similarly, while CellDE and PAES give poor results regarding this indicator.

Next, we pay attention to the SPREAD indicator (Table 8). In this case, the best algorithm is OMOPSO that has obtained the best or the second best values on 10 evaluated problems. Roughly, SMPSO, eMOABC, AbYSS, CellDE, MOCell, SPEA2 and GDE3 give competitive results regarding this indicator. The rest of the algorithms (MOEA/D, PAES, IBEA and NSGAII) obtain worse fronts compared to other algorithms.

We now analyze the computed fronts in terms of the EPSILON values (Table 9). Regarding this indicator, the eMOABC has been also the best algorithm obtaining the best or the second best values in 16 cases, followed by SMPSO algorithm, which performs the best or the second best on 13 evaluated problems. GDE3 may be the third best algorithm which outperforms other algorithms on considerable number of problems. CellDE, IBEA and PAES are three worst algorithms in terms of this indicator.

Finally, we compare algorithms in terms of IGD indicator (Table 10). Definitely, in this case, the eMOABC has performed the best. Other promising algorithms are MOEA/D, SMPSO, GDE3, MOCell, OMOPSO and SPEA2. At last, IBEA and PAES are two algorithms performing the worst on this indicator.


                        Table 11 lists the average rankings of all algorithms computed by applying the Friedman test. It is shown by the test results that eMOABC, SMPSO, GDE3 and OMOPSO are four promising algorithms that perform the best or the second best in terms of at least one indicator. Specially, our eMOABC gets the first ranking on three indicators: HV, EPSILON and IGD, indicating its great superiority over its competitors. By observing Tables 7–10 carefully, we find that the eMOABC is especially effective when approximating the Pareto fronts of CEC09 benchmarks (UF1–UF10), which are generally deemed to be the most difficult MOPs to be optimized. That is to say, the eMOABC is able to compute high-quality Pareto fronts when dealing with more difficult multi-objective problems.

The Wilcoxon test results for each pairwise comparison between the eMOABC and one of the referred algorithms are provided in Table 12. It gives the R
                        +, R
                        −, p-value and significance (Sig.) sign for all pairwise comparisons associated with the eMOABC. It can be seen from this table that the eMOABC significantly improves all referred algorithms on indicators HV, EPSILON and IGD, with a level of significance α = 0.01 in most cases, and α = 0.05 for the pairwise comparisons: eMOABC VS SMPSO on EPSILON, and eMOABC VS GDE3 on IGD. As for indicator SPREAD, the eMOABC shows an improvement over MOEA/D, IBEA, NSGAII and PAES, with a level of significance α = 0.01, and achieves comparable results compared with SMPSO, GDE3, AbYSS, CellDE, MOCell, OMOPSO and SPEA2.

To evaluate the speed of the algorithms, Table 13 records the mean of the runtime over 30 runs. It is shown by the table that PAES is the fastest algorithm, then it is OMOPSO and SMPSO. The eMOABC gets second best results when optimizing UF5 and UF6. Although PAES, OMOPSO and SMPSO are better than our algorithm in terms of the runtime, the eMOABC achieves much better results than its competitors as for indicators HV, EPSILON and IGD (see Table 12). On the whole, the eMOABC is an effective algorithm with an acceptable running speed.

For the purpose of intuitional comparison, we plot the computed fronts with the lowest IGD indicator values obtained in 30 runs of four promising algorithms (eMOABC, SMPSO, GDE3 and OMOPSO), together with NSGAII and SPEA2, on problems UF1, UF3, UF5–UF9 and WFG1 (see Figs. 7 and 8). NSGAII and SPEA2 are chosen because the newly proposed eMOABC uses the same fitness calculation method as in SPEA2, and the same crowding-distance based archive as in NSGAII. The reason of choosing the above eight problems is that the differences among the mentioned six algorithms on them are more obvious.

It can be seen from Figs. 7 and 8 that the eMOABC can well converge to the true Pareto fronts with better distribution on the considered problems. More detailed information can be obtained if we display the results by using box plots, which constitutes a useful way of depicting groups of numerical data. In Figs. 7 and 8, the left is the computed fronts of the mentioned algorithms, and the right is the box plots of IGD indicator over 30 runs. Some interesting facts can be worked out by observing the figures.

We first take a look at Fig. 7. It is observed that the eMOABC clearly outperforms other algorithms on problems UF1, UF3 and UF5. For problem UF3, GDE3 is the best algorithm, and the performances of eMOABC, NSGAII and SPEA2 are similar. However, the eMOABC is more stable than NSGAII and SPEA2 since it gets less extreme values over the 30 runs. Next, it can be seen from Fig. 8 that eMOABC ranks the first on UF7, UF8 and UF9. For problem WFG1, the best algorithm is GDE3, followed by the eMOABC. But, GDE3 archives unsteady results because of some observed extreme values.

Box plot graphs for indicators HV, SPREAD and EPSILON are also provided in Figs. 9 and 10. By observing these figures, we could find the eMOABC obtains the best results in most cases, indicating its great superiority when compared to the state-of-the-art multi-objective algorithms.

In this section, we are going to show the effect of the elitism strategy introduced in eMOABC algorithm by a simulation experiment. As mentioned before, the eMOABC will select an elite from the archive which is defined as the intermediate solution with maximum crowding-distance value, and then use it to generate new food sources by Eq. (3) in the employed bees phase. Next, a greedy strategy is used to update each food source. Thereafter, the crowding-distance values of solutions in the archive are re-computed. In the following onlooker bees phase, another elite is determined and adopted to guide the flight of the whole bee colony. If one food source’s trial value exceeds limit, then the scout bee phase is carried out. The above procedures are repeated until the number of iterations reaches the maximum value maxCycle.

From the flowchart of the eMOABC, we can find there are two elites in each cycle, and each of them is used to update food sources FN times in the employed or onlooker bees phases. This operation could ensure more sufficient exploitation around the region where elites locate, and pull the whole bee colony toward the sparsest zone. The advantages of this lie in that it could: (1) exploit more potential solutions around the less crowded regions, and (2) maintain the diversity of solutions in the approximated set. Hence, benefiting from this elitism strategy, the eMOABC will produce the results not only have good convergence but also have an appropriate distribution over the Pareto front in the objective space.

Now, we prove the above analysis through a simulation experiment. The performance of the eMOABC is compared against three MOABC variants: (1) the MOABCrandElite that uses randomly selected members as the elites; (2) the MOABCcrowdedElite that defines elites as the member located at the most crowded region (i.e. the solution with the minimum crowding-distance) , and (3) the MOABCnoElite which uses no elite at all. Tables 14–17 present the simulation results of the above four algorithms on each indicator and each problem under the same algorithm configurations. The Wilcoxon test results of each pairwise comparison between the eMOABC and its variants are summarized in Table 18, showing that the eMOABC significantly improves over MOABCcrowdedElite and MOABCnoElite in terms of all indicators, and over MOABCrandElite on the indicator HV. That is to say, the elitism strategy used in eMOABC algorithm indeed improves the algorithm’s performance, and achieves better effects than other strategies as employed in MOABCcrowdedElite and MOABCrandElite.

The average rankings of the eMOABC and its variants are calculated by the Friedman test procedure and are shown in Table 19, indicating that the eMOABC is the most competitive algorithm which obtains the best rankings on four indicators. Besides, all MOABC variants with elitism get better average rankings than MOABCnoElite, implying the positive effect of introducing an elitism strategy in our MOABC framework. As a summary, it is true that the elitism strategy improves the performance of the MOABC algorithms which is depended on the selection method of elites. In each cycle, selecting the member located at the sparsest region as the elite will produce better results.

In
                      this section, the results of the eMOABC are further compared with some state-of-the-art algorithms on benchmarks in the CEC09 competition. We run the eMOABC algorithm under the standard configurations described in CEC09 technical report (Zhang et al., 2009b). Specifically, the maximal number of the solutions in the approximate set for computing the IGD indicator is 100 for two objective problems, and 150 for three objective problems. The maximal number of function evaluations is set to be 300K for all the problems. The eMOABC algorithm is run independently 30 times for each test problem, and the mean values of IGD are presented in Table 20. In this table, the data for the algorithms MOEA/D (Zhang et al., 2009a), MTS (Tseng & Chen, 2009), DMOEADD (Liu et al., 2009) and LiuLiAlgorithm (Liu & Li, 2009) are directly taken from the final report on the CEC09 MOEA competition (Zhang & Suganthan, 2009). The results for S-MOABC/NS are provided by Akay in Akay (2013), and those for dMOABC and NSGAII are obtained by running our JAVA codes and the jMetal software package under the standard CEC09 competition configurations, respectively. The S-MOABC/NS and dMOABC are two relatively new heuristic algorithms that are based on the artificial bee colony algorithm. In the table, the best results are underlined and bolded, and the second best results are bolded only.
                     
                  

It is shown by Table 20 that our eMOABC achieves the best results on UF2 and UF9, and obtains the second best results on UF1, UF4, UF5 and UF7. MOEA/D ranks the first on five problems (UF1, UF3, UF6, UF7 and UF8), and MTS gets the best or the second best results in four cases (UF4, UF5, UF6 and UF10). As far as the number of the best and the second best results one algorithm obtained, the DMOEADD and dMOABC are better than LiuLiAlgorithm, NSGAII and S-MOABC/NS.

Again, by using Wilcoxon test procedure, we get the R
                     +, R
                     −, exact and asymptotic p-values for each pairwise comparison between eMOABC and the referred algorithms (see Table 21). The table states that the eMOABC shows a significant improvement over S-MOABC/NS and NSGAII with a level of significance α = 0.01, and over LiuLiAlgorithm with α = 0.05. The eMOABC achieves comparable results when compared with the famous MOEA/D, MTS, DMOEADD and dMOABC. However, our eMOABC algorithm employs less control parameters than its competitors. Besides two common parameters, i.e., the number of returned non-dominated solutions used for computing indicators (or the size of the external archive) and the number of maximum function evaluations (or the termination condition), the algorithms’ additional parameters are listed below: eMOABC (two parameters): CS and limit; dMOABC (three parameters): depth, ColonySize and limit (Zhong et al., 2014); MOEA/D (seven parameters): T, nr, δ, CR, F, η and pm
                      (Zhang et al., 2009a); MTS (five parameters):BONUS1, BOUND2, 
                        
                           #
                           o
                           f
                           L
                           o
                           c
                           a
                           l
                           S
                           e
                           a
                           r
                           c
                           h
                           T
                           e
                           s
                           t
                           ,
                        
                     
                     
                        
                           #
                           o
                           f
                           L
                           o
                           c
                           a
                           l
                           S
                           e
                           a
                           r
                           c
                           h
                           ,
                        
                     
                     
                        
                           #
                           o
                           f
                           F
                           o
                           r
                           e
                           g
                           r
                           o
                           u
                           n
                           d
                        
                      (Tseng & Chen, 2009); DMOEADD (five parameters): the number of multi-parent crossover, the number of the new individuals by crossover, the mutation rate, the temperatureT and the number of subdomains N (Liu et al., 2009). In the practical application of one algorithm, much more efforts may be made by the users on the adjustment of the control parameters. It is especially true when the algorithm employs more parameters or it is sensitive to some of them. Thus, we are confident that our eMOABC is more suitable for applications in real-world problems from this perspective. What is more, the eMOABC gets better results than both MOEA/D and MTS on five problems, and outperforms dMOABC and DMOEADD on six and seven test functions, respectively. As a summary, our proposed eMOABC can be a prime choice when dealing with practical problems for its inherent properties of being simple and effective.

Beside the quantitative comparisons of the investigated algorithms, the graphical representations of the Pareto fronts produced by the eMOABC algorithm are given in Figs. 11
                      and 12
                     . These figures show the quality of the Pareto fronts produced by the eMOABC algorithm. It can be seen from Fig. 11 that the Pareto front produced by the eMOABC algorithm over the UF1 test problem not only have good convergence but also have an appropriate distribution over the Pareto front in the objective space.

The eMOABC algorithm performs well when optimizing the UF2 test problem. The eMOABC algorithm obtains the first rank on this test problem. Fig. 11 shows that the Pareto front produced can converge to the true front well, but does not have an appropriate distribution. The bottom-right corner of the Pareto front is not successfully covered by the eMOABC algorithm.

For the UF3 test problem, the best convergence is obtained by the MOEA/D algorithm. The results in Fig. 11 show that the approximated Pareto front obtained by the eMOABC covers some parts of the objective space, but the number of returned non-dominated solutions is not sufficient. Hence, the value of the IGD indicator increases over this test problem.

The eMOABC algorithm obtains the second rank on the UF4 test problem compared to other considered algorithms. The best results are found by the MTS algorithm. It is apparent from Fig. 11 that the eMOABC produces a set of solutions which have both good convergence and an appropriate distribution along the true Pareto front.

It seems that the UF5 is a hard problem to be solved. The UF5 has a discontinuous Pareto front. The proposed eMOABC algorithm obtains the fourth rank among eight algorithms. As can be seen from Fig. 11, the eMOABC algorithm produces considerable solutions in the archive which are well distributed. However, it has difficulties in converging to the true Pareto front.

The UF6 has a discontinuous Pareto front, too. The results show that most of the algorithms have difficulty in optimizing this type of test problems. The MOEA/D obtains the best performance on the UF6 test problem. The MTS and DMOEADD algorithms produce competitive results on this test problem. Our eMOABC and dMOABC achieve similar results. Fig. 11 shows that the produced front contains a smaller number of points in the objective space, but has an acceptable distribution.

The eMOABC algorithm obtains the second rank on the UF7 test problem. As shown in Fig. 12, the front produced by the eMOABC has both good convergence and good distribution over the optimal Pareto front.

The UF8 is the first three objectives test problem. Usually, the complexity of multi-objective problems increases by the number of objectives to be optimized. The eMOABC obtains the third rank on this test problem. The best result is obtained by the MOEA/D algorithm. The quality of the approximated Pareto front is shown in Fig. 12. It is apparent from the results that the eMOABC produces a set of solution points which have an appropriate distribution in the three dimensional objective space.

The eMOABC algorithm has the ability to solve the UF9 test problem well, and it gets the first rank. The second rank is obtained by the MTS algorithm. The quality of the approximated Pareto front can be seen in Fig. 12. The results show that the eMOABC produces a set of well distributed non-dominated points which cover many parts of the objective space. Thus, the IGD value for this problem decreases naturally.

The MTS algorithm obtains the best result on the UF10 test problem. The eMOABC produces competitive results compared to the dMOABC algorithm. Our eMOABC algorithm obtains the third rank. Fig. 12 shows the quality of the approximated Pareto front by the eMOABC algorithm. The results show that the approximated solutions converge to the true front well, but they only cover a small part of the objective space, resulting in a worse distribution of the computed front.

@&#CONCLUSIONS@&#

This paper suggests a new multi-objective artificial bee colony algorithm, denoted as eMOABC. In this proposed algorithm, a crowding-distance based archive is used to keep and maintain the non-dominated solutions found so far. In order to keep the diversity of the archive, the solution to be added will automatically replace the member with the minimum value of the crowding-distance in the case when the archive is full. For the purpose of avoiding premature convergence, we adopt an improved ABC algorithm which uses an elitism strategy, that is, the member located at the least crowded region (called the elite) will be selected and used to generate new food sources in both employed and onlooker bees phases. We design a sensitivity variation analysis experiment to explore the parameter selection of limit and CS.

The eMOABC is evaluated on 31 test problems and compared with 11 state-of-the-art algorithms in terms of five often-used indicators: HV, SPREAD, EPSILON, IGD and RUNTIME. It is proved by the simulation results that our eMOABC is the most salient algorithm since it could provide approximated fronts with good convergence and appropriate distribution in an acceptable runtime.

The results produced by the eMOABC on problems from UF1 to UF10 are compared with those obtained by some well-known algorithms in the CEC09 competition, and by the latest artificial bee colony based multi-objective algorithms. It is shown by the Wilcoxon test procedure that the proposed eMOABC gets comparable results compared to the famous MOEA/D, MTS, DMOEADD and dMOABC, and shows a significant improvement over LiuLiAlgorithm, NSGAII and S-MOABC/NS. However, the number of control parameters used in the eMOABC is less than those employed in MOEA/D, MTS, DMOEADD and dMOABC. In the practical application of one algorithm, it is not an easy work for the users to find the best configurations of the algorithm if it employs many control parameters. It is especially true when the algorithm is sensitive to some of these parameters. Thus, we are confident that our eMOABC is more suitable for applications in real-world problems from this perspective.

Summarizing, according to the problems, the number of parameters, and quality indicators used, the eMOABC is the most promising algorithm in our study. In our future work, we will focus on the practical applications of the eMOABC. Furthermore, it is also a meaningful work to extend the algorithm for many-objective optimization.

@&#ACKNOWLEDGMENT@&#

The authors would like to thank the anonymous reviewers for providing valuable comments to improve this paper, and add special thanks to Durillo and Nebro for their excellent jMetal software package.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Benchmarking human epithelial type 2 interphase cells classification methods on a very large dataset

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Benchmarking of 14 HEp-2 cell images classification methods on a very large dataset.


                        
                        
                           
                           Six HEp-2 staining patterns considered: four common patterns plus two challenging rare patterns.


                        
                        
                           
                           Best methods use features extracted from local statistics of an image.


                        
                        
                           
                           SVM is the most effective classifier for this problem.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Large-scale benchmarking

Computer-aided diagnosis systems

Indirect immunofluorescence

Hep-2 cell classification

@&#ABSTRACT@&#


               
               
                  Objective
                  This paper presents benchmarking results of human epithelial type 2 (HEp-2) interphase cell image classification methods on a very large dataset. The indirect immunofluorescence method applied on HEp-2 cells has been the gold standard to identify connective tissue diseases such as systemic lupus erythematosus and Sjögren's syndrome. However, the method suffers from numerous issues such as being subjective, time consuming and labor intensive. This has been the main motivation for the development of various computer-aided diagnosis systems whose main task is to automatically classify a given cell image into one of the predefined classes.
               
               
                  Methods and material
                  The benchmarking was performed in the form of an international competition held in conjunction with the International Conference of Image Processing in 2013: fourteen teams, composed of practitioners and researchers in this area, took part in the initiative. The system developed by each team was trained and tested on a very large HEp-2 cell dataset comprising over 68,000 images of HEp-2 cell. The dataset contains cells with six different staining patterns and two levels of fluorescence intensity. For each method we provide a brief description highlighting the design choices and an in-depth analysis on the benchmarking results.
               
               
                  Results
                  The staining pattern recognition accuracy attained by the methods varies between 47.91% and slightly above 83.65%. However, the difference between the top performing method and the seventh ranked method is only 5%. In the paper, we also study the performance achieved by fusing the best methods, finding that a recognition rate of 85.60% is reached when the top seven methods are employed.
               
               
                  Conclusions
                  We found that highest performance is obtained when using a strong classifier (typically a kernelised support vector machine) in conjunction with features extracted from local statistics. Furthermore, the misclassification profiles of the different methods highlight that some staining patterns are intrinsically more difficult to recognize. We also noted that performance is strongly affected by the fluorescence intensity level. Thus, low accuracy is to be expected when analyzing low contrasted images.
               
            

@&#INTRODUCTION@&#

Recently there has been a growing interest in introducing automated pattern classification systems for microscopy images [1–5]. The results from these systems may offer a more objective classification which would improve result consistency and resolve any discrepancies in the subjective analyses.

The anti-nuclear antibodies (ANA) test is commonly used to diagnose connective tissue diseases (CTD) such as systemic lupus erythematosus (SLE) and Sjögren's Syndrome [6]. The gold standard for performing this test is the indirect immunofluorescence (IIF) protocol using human epithelial type 2 (HEp-2) cells [6,7] due to the expression of a wide range of antigens on HEp-2 cells. Nevertheless, the protocol is time and labor intensive [8,9]. In addition, there is high intra- and inter-laboratory variation of the test [8,10,11].

One way to address these issues is by applying computer-aided diagnosis systems. These provide a more objective analysis which could be incorporated into the overall test results. In recent years, we have seen significantly growing interest in developing such systems [2,10–20]. Nevertheless, the use of private datasets with non-standard evaluation protocols makes it difficult to draw meaningful conclusions from the existing works. Therefore, it is critical to develop a standard evaluation platform in order to advance the domain [2]. One notable example is the first contest initiative held in conjunction with the International Conference on Pattern Recognition (ICPR) 2012, here denoted ICPR2012Contest [2], which is then followed by publications of a Pattern Recognition journal special issue on the same theme [21].

Despite the merit of being the first initiative in this research area and the attention received from the scientific community, there were some shortcomings in the benchmarking platform introduced through the ICPR2012Contest. Among such issues, the most relevant were:
                        
                           •
                           Small size of the dataset: the dataset provided in ICPR2012Contest has six classes: centromere, coarse speckled, cytoplasmic, fine speckled, homogeneous and nucleolar. It has a total of 1457 cell images extracted from 28 specimen images. It is assumed that each specimen image comes from a unique patient serum and a specimen image contains a distribution of HEp-2 cells. The specimen images are equally divided for training and testing. Although at first glance the number of cell images may appear significant, larger numbers of images are required to draw more meaningful conclusions [2]. In fact, the overall analysis is mainly affected by the number of specimen images, as the cell images from the same specimen are similar. More specifically, the classes in both training and test sets only have two or three specimen images, thus, the evaluation protocol is limited to the variation generated from two specimen images. This also renders a biased view during the cross validation training process which may have misled participants in designing their systems.

Focusing only on common patterns: whilst in general there are four ANA patterns commonly found in day-to-day operation – homogeneous, speckled, centromere and nucleolar – correctness in identifying less common patterns is equally significant as they may have clinical significance. Unfortunately, the ICPR2012Contest dataset did not include these less common patterns.

In the present work, we address the above two issues by constructing a very large dataset consisting of 68,429 cell images extracted from 419 patient sera. In particular, there are now six classes: homogeneous, speckled, centromere, nucleolar, nuclear membrane and Golgi. Nuclear membrane and Golgi patterns are less common than the other four patterns. This not only offers a more realistic evaluation protocol, but also, more flexibility for doing cross validation. These factors allow the present work to offer a more realistic benchmarking of systems in this domain.

We note that, unlike ICPR2012Contest that considers the cytoplasmic pattern, we exclude the cytoplasmic pattern from our current benchmarking platform as it is not considered an ANA pattern [7]. In addition, our benchmarking platform also does not differentiate between the fine and coarse speckled classes for two reasons. Firstly, the speckled pattern subdivision is generally more complex than simply dividing it into fine and coarse speckled groups. In general, the subdivision is done by relating each individual sub-group with specific antibodies [7]. For instance, fine speckled could be further divided into several sub-groups with distinct characteristics such as fine speckled patterns caused by SSA(Ro)/SSB(La) and DFS-70 [22]. Secondly, given the above fact, a better analysis would be to consider the fine-grained classification scheme [23,24] on the sub-groups of the speckled patterns once a specimen is identified as speckled.

Our benchmarking platform is not aimed to evaluate the performance of CAD systems in the fine-grained speckled classification problem. Thus, using only one speckled class gives us an advantage to avoid confusion in analyzing the evaluation results (e.g. whether the classification mistakes are due to the inability of a method in addressing the fine-grained speckled classification problem or the general ANA HEp-2 cell classification problem).

Finally, it is worth to highlight that the benchmarking platform presented here refers to the classification of the HEp-2 cells in the interphase, as the ICPR2012Contest, and does not consider the issue of the recognition of the cells in the mitotic stage.

The paper is organized as follows: Section 2 provides a brief description on methods to perform the ANA test; in Section 3, we describe our dataset that has been used for the benchmarking; in Section 4, we first define formally the pattern recognition task that was proposed to the participants in the initiative and then provide a short summary of each method. The results and analysis of the benchmarking work are presented in Section 5. Finally, we draw conclusions and delineate future work in Section 6.

The ANA test is used for screening a wide range of CTDs [6,7]. Methods to detect ANA include indirect immunofluorescence using HEp-2 cells, enzyme immunosorbent assay (EIA)/enzyme-linked immunosorbent assay (ELISA), farr assay, multiplex immunoassay (MIA) and western blot [25].

Amongst these methods, the IIF using HEp-2 cell method is considered the gold standard as the method has high sensitivity due to the expression of wide range of antigens on HEp-2 cells [6]. Generally, other techniques are used as secondary/confirmatory tests. For instance, EIA/ELISA are specifically designed to target single autoantigens (e.g. dsDNA and SSA-A/Ro). The Farr assay is a radio-labeled assay for quantifying anti-dsDNA [25]. In western blot, antigens are separated according to their molecular weight and then transferred onto strips or a membrane [25]. The strips are then incubated with the patient serum. Positive reactions are compared to a positive control strip. For MIA, serum is incubated with a suspension of multi-colored polystyrene micro-spheres coated with a range of antigens. The binding, determining the test result, is then quantified using a specific instrument platform.

For the IIF method, the slides are examined under a fluorescent microscope by two scientists. The analysis starts by determining the specimen positivity from the observed fluorescent signal. The guidelines established by the Center of Disease Control and Prevention, Atlanta, Georgia (CDC) suggest the use of a scoring system ranging from 0 to 4+ wherein 0 represents negative (no fluorescent signal observed), and 4+ represents the strongest positive (very bright fluorescent signal observed) [26]. As this process is subjective, it is possible to reduce the scoring system into merely determining whether the fluorescence intensity level of the sample is positive, intermediate or negative [12]. Positive ANA patterns are then titred by serial dilution to obtained a more objective fluorescence intensity level [26]. Finally, the last step in the analysis is to determine the visual pattern appearing in the positive and intermediate specimens.

Generally, scientists consider at least three visual cues when examining positive and intermediate specimens: (1) at least one or two mitotic cells can be found in the specimen [26]; (2) the visual features of the mitotic cells and (3) the visual features of the interphase cells.

Unlike the interphase cells, the amount of cell chromatin in mitotic cells is doubled. The cells undergoing the mitosis stage may express different antigens or antigens in different concentrations to those in the interphase stage [27,28]. Thus, in some cases, scientists need to consider the mitotic cell visual cues before correctly identifying an ANA pattern. For instance, the mitotic spindle pattern, where the mitotic spindle is positively stained, can only be observed in mitotic cells.

While it is important to study the automated mitotic pattern classification which is shown in a number of recent works [29,20], in this work, we primarily focus on the interphase cell classification problems. Addressing the interphase cell classification problems is one of the early steps to develop a CAD system for the ANA IIF HEp-2 test.

The dataset was obtained between 2011 and 2013 at Sullivan Nicolaides Pathology laboratory, Australia.
                        1
                     
                     
                        1
                        We name this dataset as ICIP2013 dataset as the benchmarking campaign was held at the International Conference on Image Processing 2013 (ICIP2013).
                      The dataset contains the following six classes [7] (see Fig. 1
                      for examples):
                        
                           •
                           
                              homogeneous: a uniform diffuse fluorescence covering the entire nucleoplasm sometimes accentuated in the nuclear periphery;


                              speckled: this pattern is generally divided into two groups
                                 2
                              
                              
                                 2
                                 In this dataset, we consider these two sub-categories as one category, while in the ICPR2012Contest they were kept distinct.
                              :
                                 
                                    –
                                    
                                       coarse speckled: densely distributed, variously sized speckles, generally associated with larger speckles, throughout the nucleoplasm of interphase cells; nucleoli are negative;


                                       fine speckled: fine speckled staining in a uniform distribution, sometimes very dense so that an almost homogeneous pattern is attained; nucleoli may be positive or negative;


                              nucleolar: brightly clustered large granules corresponding to decoration of the fibrillar centers of the nucleoli as well as the coiled bodies;


                              centromere: rather uniform discrete speckles located throughout the entire nucleus;


                              Golgi: staining of a polar organelle adjacent to and partially surrounding the nucleus, composed of irregular large granules. Nuclei and nucleoli are negative. Diffuse staining of the cytoplasm of dividing cells sometimes with accentuation around chromosomal material;


                              nuclear membrane: a smooth homogeneous ring-like fluorescence of the nuclear membrane in interphase cells.

The dataset
                        3
                     
                     
                        3
                        The dataset is available to interested researchers and practitioners by issuing a request at http://mivia.unisa.it/datasets/icip2013-hep2-dataset/ (Accessed: May 15, 2015)
                      utilizes 419 unique positive sera extracted from 419 different patients randomly selected which were prepared on 18-well slides of HEP-2000 IIF assay from Immuno Concepts N.A. Ltd. using a screening dilution 1:80. As per the manufacturer's description, the assay contains at least one or two mitotic cells. In our dataset, each image is guaranteed to have at least one or two mitotic cells. The specimens, one for each patient serum, were then automatically photographed using a monochrome high dynamic range cooled microscopy camera which was fitted on a microscope with a plan-Apochromat 20×/0.8 objective lens and an LED illumination source. Approximately 100–200 cell images were extracted from each patient serum. In total there were 68,429 cell images extracted. We divided these into 13,596 images for training and 54,833 for testing. The division was deliberately made so that the test set only contained cells from patients who were not included in the training set. Specifically, the training set contains the specimen images from 83 patients, while the images from remaining 336 patients were reserved for the test set. The adopted subdivision between train and test set is motivated by the fact that it represents a good trade-off between on one side the need of having a large train set (its size is one order of magnitude larger than the size of the whole ICPR2012Contest) and on the other side the opportunity of resembling the real world situation where the field validation of a designed method is done on a set of data that is unknown and much larger than the train set.

The labeling process involved microscopic reading by two experienced scientists. A third opinion was sought to adjudicate any discrepancies. We used each specimen label as the truth label of cells extracted from it. Furthermore, the labels were investigated further using secondary tests such as extractable nuclear antigens (ENA), and anti-ds-DNA to confirm specificity of the ANA pattern.


                     Figs. 2 and 3
                     
                      present the number of exemplars for each pattern class in both training and test sets. The more common patterns such as centromere, homogeneous, nucleolar and speckled have a similar number of exemplars. However, the less common patterns such as the nuclear membrane and Golgi have fewer exemplars. In particular, Golgi has significantly fewer exemplars than the other patterns. This depicts a more realistic condition where the system needs to perform reasonably well on both common patterns and significantly less common patterns.

We note that the creation of this benchmarking platform is possible due to the recent advancements that sufficiently address several practical problems in the automated acquisition of HEp-2 images which allows us to capture high quality images of a patient specimen in approximately 20s [28]. In particular, the acquisition system uses two channels: (1) the fluorescein-isothiocyanate (FITC) channel that is normally used in ANA tests and (2) the 4′,6-diamidino-2-phenylindole (DAPI) channel that is used in the cell image segmentation. DAPI, which is a fluorescent stain that binds strongly to cell DNA [30], specifically delineates the HEp-2 cell nuclei (i.e.  the area of interest in the ANA test). Therefore, this may be used to perform high precision HEp-2 cell segmentation regardless of the patient pattern exhibited in the FITC channel [28,27] (refer to Fig. 4
                      for some challenging examples where the HEp-2 cell boundary and shape are not clearly defined, but are still successfully segmented in high precision). This approach addresses issues such as misclassifications due to poor segmentation, stemming from imperfections in the manual segmentation process in the previous benchmarking set, ICPR2012Contest.

We note that, whilst DAPI is widely known as carcinogen substance, in general, the health risk can be significantly reduced by utilizing automated slide preparation systems that handles the high concentrated DAPI solution. In addition, the DAPI concentration applied on each slide is considered low and will not impose immediate health risk.

We now describe the methods which participated in the benchmarking activity held at ICIP 2013. For the sake of brevity, the description is intentionally short so as to focus on the most relevant aspects of each method. However, interested readers may find more details about each individual method in the ICIP 2013 competition report
                        4
                     
                     
                        4
                        The report is available at http://nerone.diem.unisa.it/contest-icip-2013/ICIP2013_report.pdf. (Accessed: May 15, 2015)
                      where each participant provides an extended description of their method. In the following, each method is reported using the first three letters of the surname of its first author.

Recall that the classification goal for each team was to develop a classifier φ that classifies a set of HEp-2 cell images. Each image is represented by the three-tuple (I, M, δ) [19]: (1) I represents the cell fluorescence image in FITC channel; (2) M is the cell mask which is automatically extracted from the DAPI channel; and (3) δ represents the cell positivity strength which has two values weak/borderline (intermediate) or strong (or simply positive). To avoid confusion, here we use the terms intermediate and weak positive interchangeably. In addition, we refer strong positive samples as simply positive samples.

Let Y be a test image, ℓ be its true class label and 
                        G
                        =
                        {
                        
                           
                              (
                              
                                 
                                    I
                                 
                              
                              ,
                              
                                 
                                    M
                                 
                              
                              ,
                              δ
                              )
                           
                           1
                        
                        ,
                        …
                        
                           
                              (
                              
                                 
                                    I
                                 
                              
                              ,
                              
                                 
                                    M
                                 
                              
                              ,
                              δ
                              )
                           
                           n
                        
                        }
                      be a given gallery set. The classifier task was to predict the test label, 
                        
                           ℓ
                           ˆ
                        
                     . In other words, 
                        φ
                        :
                        
                           
                              Y
                           
                        
                        ×
                        G
                        ↦
                        
                           
                              ℓ
                              ˆ
                           
                        
                     , where ideally 
                        
                           
                              ℓ
                              ˆ
                           
                        
                        =
                        ℓ
                     .


                     CHA – The rationale of the method is to selectively exploit texture information from different regions of an image. To this end each cell is divided into six partially overlapped regions which extend from the cell boundary to the inner circle area. In total 18 features are calculated from each region: region brightness, contrast and 16 one-dimensional bispectral invariants [31]. These are successively concatenated to form a vector of 108 features which are used to train a set of classifiers (each HEp-2 cell class has one corresponding classifier). For each pattern class, Adaboost [32] is used to generate a 10-stage binary classifier, combined with a hand-crafted decision tree. In particular, the authors evaluated the performance of each binary classifier and constructed a decision tree that placed them in the order of performance, highest first. If all of the binary classifiers reject a query image, it is then assigned to a default class.


                     HAN – The proposed method uses the distribution of local pixel neighborhoods (denoted micro-texton) with Gaussian mixture model as its histogram encoding method. For the image representation, they compute and concatenate the gradient with respect to the model parameters. The final representation can be considered as a Fisher Vector. A random forest classifier is adopted as the classifier.


                     LAR – In the preprocessing stage each image is augmented with its logarithmic representation [33]. Then, each representation is mapped linearly to [0,1] such that their minimum attains a value of zero and their maximum a value of one. The features are extracted from both representations of each image. For each cell, a feature vector is built consisting of the intensity information, morphological features extracted from the provided mask (including area, eccentricity, major and minor axis length, perimeter), and the “annulus” shape index histogram feature. The latter is the most significant descriptor and consists of weighted histograms of second order image features derived from the local Hessian eigenvalues [34] over a number K of band-shaped regions. Each region is defined by its distance to the center pixel of the image, while the weight for each pixel is assigned based on a Gaussian distribution centered on the radial band. Classification is performed through a multi-class support vector machine (SVM) with radial basis function (RBF) kernel using a one-vs-one scheme.


                     LIU – The proposed method initially normalizes the brightness of the input image. Then, local patches of size 9×9 pixels are extracted on a dense sampling grid. In the training phase, these patches are projected through PCA and a codebook with N codewords is created, as described in [35]. This codebook is used to partition all of the local patches into N groups. Then, discriminative projections are obtained for each group by a partial least square analysis in order to re-project the image patches to low dimensional vectors. According to the bag-of-word (BoW) pipeline, the final image representation is obtained by concatenation of the histograms from different groups. A linear SVM is used for the classification stage.


                     MAR – The proposed approach [36] builds upon the use of square subwindows randomly extracted from the original image with respect to the position, the rotation angle and the size. The subwindows are resized to 16×16 pixels and encoded in normalized red-green-blue (RGB) color space. A very large set of visual features is generated using randomized trees. In particular, an ensemble of 50 trees is built according to [37] and then is used to generate an image-level signature inspired by the bags of visual words [38] or textons [39]. Each terminal node of an individual tree is a real-valued feature corresponding to the number of subwindows that reach the terminal node, divided by the number of subwindows extracted in the image. Each cell image is represented by these sparse and high-dimensional signatures. Finally, a linear SVM, adopting a one vs one multi-class strategy, is used for the final class prediction.


                     NAN – The method is based on the combination of three texture descriptors: the multiscale pyramid local binary pattern (PLBP) [40], which is based on the local binary pattern (LBP) operator applied to each of the l
                     =(0, …, L) levels of the gaussian pyramid built from the original image; the Strandmark's morphological features (STR), which are a reduced version of the features in [41]; and the canonical Haralick features (HAR) defined in [42]. The classification is performed using a multiclass SVM with RBF kernel, according to the one-vs-all approach. The SVMs are trained for each of the three sets of features and the results are combined according to the sum rule.


                     PAI – After a preprocessing phase that includes denoising (median filtering) and normalization (histogram equalization), the proposed approach relies on three different sets of features in addition to the information regarding the image intensity level: (1) region covariance of image statistics, the first and second order derivative in the vertical and horizontal directions, and the magnitude of the gradients; (2) co-occurrence among adjacent linear binary pattern (CoALBP) features, which is the extension of LBP [43]; and (3) STR features [41]. Finally, the classification is carried out using a multi-class boosting algorithm that can adaptively select the most discriminative feature in each boosting iteration and combine these into an effective classifier.


                     POM – In the preprocessing stage the cell image is binarized and resized to a canonical size. The employed features are based on the complete linear binary pattern (CLBP) approach [44]. The CLBP approach is based on the assumption that the local appearance and textural structure can be defined by the histogram of the local sign, magnitude and central pixel defined on a dense grid. The CLBP histograms of the sign magnitude and central pixel combine structural and statistical information, and capture the distribution of the classified structures. Classification is performed using K nearest neighbor (K-NN).


                     PON – The proposed method relies on the characterization of the morphological properties of the stained regions of the HEp-2 cells such as nucleoli, nucleous and chromosomes. The authors suggest two different preprocessing steps depending on the type of the descriptor: (1) the image is thresholded using Otsu binarization; and (2) the image is normalized in the range [0,255]. Twenty-one features belonging to the following logical groups are used which include number of stained regions (also called objects by the authors), object size, holes inside objects, holes intensity depth, foreground/background intensity properties, normalized image intensity properties, object localization and object shape. Final image classification is carried out through a kernel SVM and includes two independently trained classification models, one for the positive level of the image intensity and the other for the intermediate level.


                     SAR – The method first applies histogram equalization on the foreground part of the image. After that, the image is resized to 100×100 pixels. The following features are then extracted: statistical features as average intensity, average contrast, smoothness, skewness, uniformity and entropy [45], invariant moments [45], Haralick features [42], and discrete wavelet frame texture descriptors [46] with three resolution levels. The classification is performed using the maximum probability normal classifier.


                     SHE – As described in [47], each cell image is represented through the combination of two rotationally invariant descriptors based on scale invariant feature transform (SIFT) [48] and co-occurrence LBP [49]. In particular, for the SIFT approach, a large number of SIFT features are clustered to form a dictionary, which is then used for cell representation. For co-occurrence LBP, the uniform pattern LBP operator was applied to two neighboring points for feature extraction. Finally, the two features are fused and input to a multi-class SVM with linear kernel trained with one vs one strategy.


                     STO – In the preprocessing stage, image denoising, normalization and enhancement are performed. For each type of adopted image descriptor a separate feature space with its proper metric is employed. More specifically, the LBP descriptor, the Haralick features, the color structure, the surface descriptor, and the radial cell structure descriptor are used with L1 metric. The author defines a specific distance function for the granulometry descriptor. The final classification is obtained via a custom combination of k−NN searches over the considered feature spaces.


                     THE – The proposed method preprocesses the input image by denoising and normalization. Then, a set of binary images are constructed by thresholding the image using a set of 14 equally spaced threshold values in the range [0,1]. Connected component analysis is performed in each binary image, and the following set of morphological features is applied: number of detected objects, density in binary image and mean objects’ solidity. Objects of size less than 1% of the mean objects’ size detected in each binary image are considered as noise and ignored during the calculation of the above features. Finally, the complexity of the cell's contour is considered and modeled as the difference between the cell's contour and the perimeter of the equivalent circle. The resulting feature vector is normalized to zero mean and unit variance using the training set. The final classification is performed using the k−NN classification rule.


                     THI – The proposed method is based on two different statistical descriptors. The first descriptor is the Fuzzy Size Zone Matrix, a fuzzy version of Gray Level Size Zone Matrix [50]. This matrix is obtained by estimation of a bivariate conditional probability density function of the image pixel values. Features are then derived from this matrix. More precisely, moments of order −2 and 2 are computed from the matrix. The second descriptor is the multi-resolution local binary patterns which is a rotation and gray level invariant descriptor. The feature vector is derived from the histogram of the codes. Classification is performed according to a one-vs-all scheme. In particular, for each class, two classifiers (one per descriptor) are built with Random Forests [51] and the probabilities provided by the model are averaged in order to provide a final probability that the cell under study belongs to the class. The cell is then labeled with the class corresponding to the highest probability.

@&#EXPERIMENTS@&#

In this section, we analyze the results of the benchmarking activity that we conducted within the ICIP 2013 competition on IIF images. The analysis is focused on the following aspects: first, we briefly review the adopted experimental protocol. We then consider the classification results at the cellular and specimen levels
                        5
                     
                     
                        5
                        As in [2], we use here the expression at the cell level when we refer to a single cell without the surrounding part of the specimen image, while we use the expression at the specimen level as a synonym of the expression at the image level, used in [2], when we refer to the specimen image as a whole.
                      of the fourteen submitted methods over the test set of the ICIP2013 dataset by analyzing in detail the behavior of the methods with respect to the different cellular staining patterns. Finally, we compare the results with those presented in [2] with the aim of drawing several general conclusions.

We briefly summarize the protocol as follows. Each participant receives the train set containing the original images of the automatically segmented cells. In particular, for each cell image, we provide the bounding box and the foreground mask. The cells are provided along with the information about the intensity pattern and the ID of the specimen image they belong to. This information is critical for creating unbiased cross-validation splits during training. More specifically, in order to construct the unbiased cross-validation splits during training, one needs to ensure that cell images extracted from the same patient are not in both training and testing sets. We note that this information is not available in the ICPRContest2012, thus, severely disadvantaging the contest participants in training their systems. Therefore, the adopted experimental protocol in this work is not identical to the ICPRContest2012 widely described in [2].

The participants use the train set provided to tune their systems before releasing an executable file for independent evaluation on the test set. Finally, submitted executables are run on the train and test sets. The results are discussed below.

Each team performance is evaluated based on the correct classification rate (CCR), CCR
                        =(TP
                        +
                        TN)/(P
                        +
                        N), where TP, TN, P and N are the number of true positive, true negative, positive and negative samples, respectively. We note that this performance evaluation might be biased toward the method performance on common classes. To that end, we also analyze the accuracy for each class.


                        Fig. 5
                         shows the cell recognition accuracy attained by each method on both the train and test sets. We firstly observed that performance varied in a wide range, from 47.19% to a maximum value at 83.65%. However, it is interesting to note that the top seven performing methods are contained within a much smaller range (approximately 5 percentage points). In fact, the performance difference between the best and the second best methods are markedly similar (i.e. 83.65% vs 83.54%). We further confirm that the top two methods are similar by applying the Cochran's Q test [52] where the null hypothesis cannot be rejected at 5% significance level (i.e. p
                        =0.5065).

Generally, the best performing methods make use of two ingredients: (1) features extracted from the local statistics of an image and (2) using a strong classification framework. For instance, the contest winner, SHE, employs two local feature descriptors based on SIFT and Co-occurrence LBP. The method uses the SVM training framework that represents a strong classification maximizing margin between the classes. Furthermore, for the case of linear SVM, the weights on the SVM model indicate the importance of a particular feature to the classifier output. This could provide an implicit feature selection. Another example is the second best method, LAR, which uses a novel descriptor namely “annulus” shape index histogram features which introduces a rotation-invariant spatial pooling scheme over the shape index histograms. Again, they use a strong classifier such as a multi-class one-vs-one SVM in conjunction with the RBF Kernel. From this observation, we conjecture that the combination of the local descriptor and a strong classifier has significant relevance. The SVM seems to be an effective classifier for this problem as it offers good the system generalization error as well as an effective feature selection process.

We observe that for the second tier methods, the above two ingredients either only appear individually or not in the right balance. For example, although STO does use local feature descriptors such as LBP, it does not employ a strong classifier. Instead, it uses the K-NN method as the classifier. Another example is the THI method. In this method both ingredients are present but not in the right balance. The feature selection is done via a probabilistic framework which may be prone to over training (refer to Fig. 5) when the cross-validation training protocol is not carefully constructed.

Results reported in Fig. 5 highlight that in a large number of cases there is a very high discrepancy between the cell level recognition accuracy attained by each method in both the train and test sets. In fact, such a difference is generally around or above 10%, reaching the maximum values in the cases of THI and HAN (41.97% and 36.52%, respectively). The unique exception is represented by CHA: in this case the difference is only 1.21%. This could be attributed to the method's simplicity (e.g. the fact that the binary classifiers adopted in the classification stage are combined in a hand-crafted decision tree). This choice could potentially avoid overfitting, thus achieving by far the highest generalization level with respect to the other submissions, despite its low overall accuracy on the test set.

In order to focus the attention on the recognition capabilities of the methods with respect to six staining patterns of the cells, we report in Fig. 6
                         the confusion matrices of all the methods. A first observation is that the method by SHE, while obtaining the highest global accuracy, never achieves the highest class accuracy In fact, the method by LAR (the 2nd ranked) is the best performing over the centromere, nucleolar and nuclear membrane patterns, and the methods by PAI (the 3rd ranked), MAR (the 4th ranked), and CHA (the 14th ranked) have the highest value of accuracy on the speckled, Golgi and homogeneous patterns, respectively.

We note that the best two methods show similar behaviors with respect to all the classes (the difference of the class accuracies of the two methods is always below 3%), further confirming the statistical significance test performed previously. When focusing again on the best seven approaches we notice that all share a common behavior over the six classes. This observation is supported by the data reported in Fig. 7
                         where each entry contains the average value of the cell classification performance and, in parentheses, the standard deviation calculated over the values of the homologous entries of the confusion matrices of the best seven methods. It is noteworthy to mention that in most cases the standard deviation is below 3% confirming that at least for the best seven methods there is a common trend in the recognition capabilities. The best seven approaches recognize the centromere, the nucleolar and the nuclear membrane patterns in around 9 cases out of 10, performing worst on the remaining classes with a class accuracy ranging within 60% and 70%.

From the data in Fig. 7 we notice that the homogeneous pattern is often confused with the speckled and the nuclear membrane, and partially with the nucleolar. Such behavior is not surprising because the homogeneous pattern visually appears as a smoothed version of the speckled (both coarse and fine). A similar consideration stands for the nuclear membrane pattern that visually resembles the homogeneous pattern (noticed as a large fraction of errors on the nuclear membrane pattern due to misclassification with the homogeneous). Furthermore, the speckled pattern is almost equally confused with the homogeneous and centromere patterns. The first type of error is coherent with the previous finding regarding the errors with the homogeneous patterns. The confusion with the centromere can be justified through the observation that both patterns are characterized by the presence of small dots on a quite homogeneous cellular background, with the only difference that the dots are darker than the background in the case of the speckled while are lighter in the case of the centromere. The confusion between speckled and centromere patterns seems to have originated from the use of features which do not explicitly encode the gradient directionality. Thus, future research efforts should also be directed toward the development of appropriate descriptors for addressing this issue. Finally, in the case of the Golgi pattern, we deem that the low recognition rate is due to a combination of three factors: (1) the skewness of the dataset (the number of images belonging to Golgi pattern is significantly less than the other patterns); (2) the visual similarity with other patterns (in particular with nuclear membrane); and (3) the fact that the discriminating visual cues for Golgi pattern occurring at the periphery of the cell are outside the provided binary masks. This may need a dedicated directive in the future benchmarking campaigns.

From previous discussions, we observed that the top seven methods were similar in terms of their performance (i.e. ranging from 78% to 83%). However, it is not clear whether their performance is indicative of a similar error profile. In other words, we cannot draw any conclusions on whether these methods generally have mistakes on the same images.

Again, we performed the Cochran's Q test, this time against the top seven methods. The test concluded that the null hypothesis can be rejected at the 5% significance level indicating that these methods have different error profiles. We note that unlike in the previous section where the Cochran's Q test was performed against the top two methods, for this time, we performed the test against the top seven methods.

To further confirm this result, we introduced a fusion rule whose input is the output of selected participant classifiers.

Formally, we define the fusion rule φ
                           
                              f
                            as follows. Let 
                              
                                 
                                    X
                                 
                              
                              ∈
                              
                                 
                                    
                                       ℝ
                                    
                                 
                                 k
                              
                            be a vector whose ith component is the output of the i-th participant method φ
                           
                              i
                           
                           ;
                           k
                           ={1, 3, 5, 7, 9, 11, 13} be the number of selected participant methods. The fusion rule is described as:


                           
                              
                                 (1)
                                 
                                    
                                       φ
                                       f
                                    
                                    (
                                    
                                       
                                          x
                                       
                                    
                                    )
                                    =
                                    
                                       argmax
                                       
                                          c
                                          ∈
                                          C
                                       
                                    
                                    
                                    ξ
                                    (
                                    
                                       
                                          X
                                       
                                    
                                    ,
                                    c
                                    )
                                 
                              
                           where ξ(X, c) is the function that counts the number of c in X; 
                              C
                            is the set of pattern classes 
                              C
                              ∈
                            {centromere, homogeneous, nucleolar, speckled, nuclear membrane, Golgi}. For instance, ξ ([homogeneous, homogeneous, speckled], homogeneous) equals 2 since there are two homogeneous patterns in X.

We first ranked the participant methods according to their recognition performance as presented in Fig. 5. Then, we evaluated the fusion rule performance by progressively selecting the methods ordered by their performance in descending order. Fig. 9
                            reports the results of the study. We found that it was possible to improve the performance of the ICIP2013 winner by 2% points. The fusion rule reached its optimal performance (85.60%) when the top seven methods were employed, thus, corroborating our previous observation that these methods are heading in the right direction to solve the classification problem. This also indicates that each participant does not have the same classification errors suggesting that there could be more room to improve performance.

The Cochran's Q test was also performed to further analyze whether the error profile of the fusion rule differed from the top seven methods. More precisely, the test was applied to the output of the fusion rule and each of the top seven methods. This resulted in seven tests. All tests rejected the null hypothesis indicating that the error profile and the performance gains of the fusion rule over the top seven methods were statistically significant.


                           Fig. 10
                            shows the performance of each method in positive and intermediate fluorescence intensity images. All methods consistently have lower performance on intermediate fluorescence intensity images than the positive fluorescence intensity images. This indicates that the classification problem in intermediate fluorescence intensity images is more complex than in positive ones.


                           Fig. 11
                            reports the specimen-level performance of the considered methods. The label of a specimen image is simply determined by the most dominant cell pattern in the image. It is noteworthy to mention that the top performing methods could not achieve 100% performance despite their excellent performance in the test set. Upon closer examination of the top seven methods, we found that in most cases, the error was associated with the speckled patterns. This can be observed in Fig. 8
                            that reports the specimen classification performance of the top seven methods. In addition, this is consistent with the previous finding that considers speckled as the second most difficult pattern to classify due to misclassification with other patterns such as centromere, nuclear membrane, homogeneous and nucleolar.

One cannot make a direct comparison of the classification performance of the methods that were analyzed at the ICIP 2013 and at the ICPR2012Contests [2]. This is because the datasets are different and the cellular staining patterns under consideration only partially overlap. Despite this, some general considerations could still be drawn. Moreover, although a detailed discussion regarding the differences in methodology between the contributions reported in this paper and those published in [2,11] might be expected, nevertheless, it cannot be accomplished in a way that would be really useful for the reader. As a matter of fact, there are roughly 40 methods in [2,11] that should be compared with 14 methods in this submission: the variety of adopted features and classification architectures is too large to make a one-vs-one comparison among all the methodologies. We deem that it is much more useful for the reader to catch the general trends on the performance, on the methods and the most relevant issues: these points are addressed in this subsection and in the final conclusions reported in Section 6.

A first observation is that we immediately notice a general increase in the recognition rates and a reduction of the performance variability for the newly considered methods. Both phenomena can be explained by the availability of a larger dataset which allowed more reliable training and testing of the approaches, and by the experience gained through the ICPR2012Contest that provided important cues for designing more effective methods.

We note that most methods can reliably classify the centromere pattern. In fact, cells belonging to this class were recognized with the highest accuracy also in the ICPR2012Contest. In both current benchmarking work and ICPR2012Contest, the centromere cells were correctly recognized in more than 9 cases out of 10. The class accuracy of the nucleolar pattern increases by almost 10% (90.3% of the best method of ICIP 2013 competition, SHE, versus 80.6% of the best method of ICPR2012Contest). The homogeneous and the speckled patterns still remain more difficult to recognize, confirming the outcomes of the previous competition although significant improvements can be observed. The class accuracy of the best method of the ICPR2012Contest with respect to the above two patterns was slightly over 50% while the method by SHE in 2013 improved by around 15 percentage points (speckled) and 25 percentage points (homogeneous).

In this paper we have presented an in-depth analysis of the benchmarking results from the international competition on HEp-2 cell classification held in conjunction with the International Conference of Image Processing 2013. The benchmarking platform described here overcomes some limitations of the previous benchmarking platform (ICPR2012Contest) through the adoption of a novel dataset consisting of a significantly larger number of images and offering a more realistic evaluation by providing more than one specimen image for each pattern and by introducing less common pattern images such as nuclear membrane and Golgi. We have performed an evaluation of 14 methods on the same test set, which was not released to the contest participants.

From this evaluation, we found several significant findings:
                        
                           •
                           The first seven top performing methods such as SHE, LAR, PAI, MAR, NAN, LIU and PON are closely matched in terms of performance;

We found that top performing methods normally employ two ingredients: (1) features extracted from local statistics of an image (e.g. bag-of-words approach) and (2) a strong classifier. We conjecture that the most effective solution for the latter point is to employ an SVM classifier;

We observed that there is a significant discrepancy amongst most participant performance on training and test sets. This may suggest that, in most cases participants overtrained their system;

On closer observation we found that although the seven top performing methods have similar performance, they do not have the same error profile. This was shown in further evaluation using a fusion rule which was able to achieve better performance (85.36%) than the competition winner (83.65%).

We also had some confirmations from the experience of the ICPR2012Contest.
                        
                           •
                           The classification problem on intermediate fluorescence intensity images is still considered more difficult as the performance of all participants on this set of images is lower than their performance on the positive fluorescence intensity images. We envision that the future methods will give different treatment for images with different fluorescence intensity;

We verified that some staining patterns are simpler to recognize. This is the case for centromere and for nucleolar patterns that are recognized in more than 9 cases out of 10;

We found the speckled pattern to be a source of confusion for the participant methods when classifying specimen images. The speckled pattern has been noted as the second most confused pattern class in cell image classification problems.

The substantial and systematic effort to solve HEp-2 image classification problems started since the previous benchmarking work at the ICPR2012Contest led to a series of high quality publications in numerous venues. The present work provides insight into how far we are from the prescribed goal: to develop a reliable and robust HEp-2 ANA test CAD system that can be used for routine operation in pathology laboratories. From the present analysis, we found several important ingredients to make CAD systems successful in performing the classification task. We also found several potential issues wherein solving these could significantly improve the classification success rate of CAD systems. Some of the issues are also linked to the previous benchmarking work which then should receive more attention from the community. Among these issues, we deem that the most noteworthy ones that should be considered in the future are related to the classification problems on intermediate fluorescence intensity images, possibly investigating the impact that the explicit use of the fluorescence intensity information might have over the achievable accuracy.

There are also several other questions worth exploring that could significantly advance the field such as how we can effectively classify HEp-2 specimen images. Currently, the specimen image classification is merely carried out by using the dominant cell pattern presence in the image. Despite the high performance exhibited in the present evaluation, this approach may not be appropriate for other ANA patterns that do not have a dominant pattern such as mitotic spindle pattern and cell cycle dependent patterns. This warrants further investigation of the mitotic cell pattern classification problem. It is also not clear how current CAD systems deal with cases where multiple ANA patterns exist within a patient serum.

We also believe that future benchmarking initiatives in this area should take into account issues related to the reproducibility of the research, to allow validation of methodologies on other datasets, to assess the robustness with respect to the choice of input parameters and to analyze the computational burden.

Given the steady advancement witnessed in the present work, we are confident that despite the long road to accomplishing the goal, we are getting closer to solving the problems posed in this challenging area.

@&#ACKNOWLEDGEMENTS@&#

The authors thank the teams that participated to the competition held at the International Conference on Image Processing in 2013, whose members are reported below.


                  CHA: V. Chandran, J. Banks, B. Chen, I. Toneo-Reyes, Queensland University of Technology, Australia. HAN: X. Han, J. Wang, Y. Chen, Ritsumeikan University, Japan. LAR: A.B.L. Larsen, J.S. Vestergaard, R. Larsen, Technical University of Denmark, Denmark. LIU: L. Liu1, J. Zhang2, L. Wang2, 1
                  Australian National University, Australia, 2
                  University of Wollongong, Australia. MAR: R. Marée, University of Liège, Belgium. NAN: L. Nanni1, M. Paci2,3, J. Hyttinen2,3, S. Severi4, 1
                  University of Padua, Italy, 2
                  Tampere University of Technology, Finland, 3
                  BioMediTech, Finland, 4
                  University of Bologna, Italy. PAI: S. Paisitkriangkrai, R. Hill, C. Shen, A. den Hengel, University of Adelaide, Australia. POM: V. Pomponiu, H. Hariharan, University of Pittsburgh, USA. PON: G.V. Ponomarev, M.S. Gelfand, M.D. Kazanov, Institute for Information Transmission Problems, Russia. SAR: O. Sarrafzadeh, H. Rabbani, Isfahan University of Medical Sciences, Iran. SHE: L. Shen, J. Lin, S. Yu, Shenzhen University, China. STO: R. Stoklasa, Masaryk University, Czech Republic. THE: I. Theodorakopoulos, D. Kastaniotis, University of Patras, Greece. THI: G. Thibault, Oregon Health & Science University, USA.

This work has been partly funded by Sullivan Nicolaides Pathology, Australia and the Australian Research Council (ARC) Linkage Projects Grant LP130100230.

@&#REFERENCES@&#


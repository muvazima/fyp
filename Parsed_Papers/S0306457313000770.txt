@&#MAIN-TITLE@&#Evaluating books finding tools on social media: A case study of aNobii

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A user study of the book finding tools on aNobii was conducted.


                        
                        
                           
                           A set of performance measures were tested on these exploratory tools.


                        
                        
                           
                           Browsing friends’ bookshelves was more conducive to novelty and serendipity.


                        
                        
                           
                           Users’ preference structure shown to impact on the performance of the tools.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Social navigation

System evaluation

Reading preference

aNobii

Social media

@&#ABSTRACT@&#


               
               
                  A user study of aNobii was conducted with an aim to exploring possible criteria for evaluating social navigational tools. A set of measures designed to capture various aspects of the benefits provided by the tools was proposed. To test the applicability of these measures, a within-subject experimental design was adopted where fifty regular aNobii users searched alternately with three book-finding tools: browsing “friends’ bookshelves”, “similar bookshelves”, and “books by known authors”. Other than the self-report user experience and search result measures, the “choice set” model was used as a novel framework for navigational effectiveness. Further analyses were conducted to explore whether three aspects of reader preference, “preference insight”, “preference diversity”, and “reading involvement” might influence the performance of the tools.
                  Some major findings are as follows. While the author browsing function was shown to be most efficient, browsing friends’ bookshelves was shown to generate more interesting and informative browsing experiences. Three evaluative dimensions were derived from our study: search experience, search efficiency, and result quality. The disagreement of these measures shows a need for a multi-faceted evaluative framework for these exploration-based navigational tools. Furthermore, interaction effects on performance were found between users’ preference characteristics and tools. While users with high preference insight relied more heavily on author browsing to obtain more accurate results, highly involved readers tended percentage wise to examine and select more titles when browsing friends’ bookshelves.
               
            

@&#INTRODUCTION@&#

The growing popularity of social media has captured the public imagination and attracted attention from academic and industry researchers. For information scientists, the study of social media carries a special sense of urgency as they have rapidly become the main venues where information is consumed and exchanged. Socially-enabled navigational tools embedded in social media afford novel modes of access beyond those of traditional bibliographic means. For example, on aNobii, a social networking site for avid readers, users can now explore previously unknown items through socially-enabled navigational tools such as browsing friends’ and system-generated similar bookshelves. These book-finding tools can greatly complement traditional subject access devices in two ways. Firstly, they are particularly effective when users’ information needs are ill-defined and inexpressible, such as is often the case in searching for leisure reading. Secondly, they greatly increase opportunities for serendipitous finds through associative browsing. Fellow readers’ comments and ratings can also provide important judgment cues for book quality.

The newly emerging information environment on social media presents a fertile ground for information behavior research as new tools often engender new user information behaviors. Users now can rely on socially-enabled cues such as recommendations and reviews by others to come to know items of interest. Yet so far little research has been done to study users’ information behaviors in such a cue-rich environment, nor has there been a consensus on how to evaluate the tools embedded in these sites. The exploratory, as opposed to keyword-matching, mode of access on social media also presents a great challenge to evaluation methodology. It remains unclear what evaluative criteria, other than relevance-based precision and recall measures, can be used to validate the benefits provided by these exploration based tools. Other than search results, the user experience might be an important aspect of value provided by these tools. For example, researchers have pointed out exploratory systems can prove beneficial to support an interactive learning process beyond search results (Marchionini, 2006; White, Kules, Drucker, & Schraefel, 2006; White, Marchionini, & Muresan, 2008).

Furthermore, what really matters in users’ searching of information items for leisure on these sites is users’ preference rather than topic relevance (Koolen, Kamps, & Kazai, 2012). While in marketing research users’ responses to customized offers have been shown to be influenced by their knowledge and involvement with the products (Franke, Keinz, & Steger, 2009; Kwon, Cho, & Park, 2009; Shen & Ball, 2011; Simonson, 2005). Yet little has been investigated, from a system evaluation perspective, on how different user traits might influence their seeking behaviors and system performance with these socially-based recommendation tools. In the book finding environment on social media, users are constantly exposed to novel and sometimes serendipitous items. Thus, their willingness and ability to explore items might turn out to be an important factor on the effectiveness of these tools. One can imagine that readers with a more refined preference mightreact differently than more casual readers. It might also be relatively more difficult to recommend novel and potentially interesting items for well-read readers and more resourceful readers who rely on their own information resources for book finding. Among cultural product consumers, a distinction is often made between sophisticated and casual consumers (Caves, 2002). When examining online DVD rental data, Elberse (2008) found that consumers who have ever chosen obscure products tended to consume a much wider range of alternatives, including popular items, while those who knew of few alternatives tended to stick with more popular offerings. It is reasonable to hypothesize that users’ knowledge and involvement with cultural products influence their response to customized recommendations. Therefore besides testing various evaluation criteria in this study, we also wish to explore how different aspects of users’ preference might influence user behaviors and tool effectiveness.

In the following sections, we will begin with a discussion of the impact of socially-based book-finding tools on users’ access to readings for leisure, followed by elucidating the procedures and results of the experiment.

@&#LITERATURE REVIEW@&#

Community-based navigational tools can be especially effective where keyword-based subject access is less successful (Koolen et al., 2012). An area where subject access has been found to be inadequate is access to imaginary work. With imaginary works, what is sought is the emotive reading experience that the work evokes rather than the subject it addresses. The difficulty of subject access to imaginary works lies in the fact that the relationship between the features in the work and the types of experiences they might evoke are often vague and indirect at best. As Lancaster pointed out, “The criteria by which imaginative works are sought by library users may be more personal and idiosyncratic than the criteria and characteristics usually associated with subject searches in bibliographic databases covering, say, journal articles (Lancaster, 2003, p. 207)”.

In the traditional library setting, complicated bibliographic mechanisms have been built with the objectives of helping users to find, identify, select, and acquire intended information items. Yet as Svenonius (2000)pointed out, what is often overlooked is the “navigational” objective that aims to accommodate search situations where users find it difficult to express their information needs. This is especially the case when searching for leisure readings. As Ross (1999) pointed out, readers often rely on other information sources such as friends and reviews to help them discover and decide what to read.

To help users navigate, that is, to move from one information item to another, some sort of relationship between items has to be established to provide the necessary pathways. In social media sites, especially those involving content sharing such as YouTube or aNobii, the types of work-work relationships are greatly expanded beyond traditional bibliographic mechanisms (e.g. author and subject search). Users are now able to discover previously unknown information items through social networks of either friends or strangers who share similar interests. The dynamic link structure of users and information items on these sites constitute numerous routes by which one can traverse and discover interesting titles along the way. Reading, though often thought of as a solitary activity, is in fact often taking place within a network of social relations, which can now be greatly expanded through connections on social media sites (Dieberger, 1997; Dourish & Chalmers, 1994; Perugini, Gonçalves, & Fox, 2004; Svensson, Höök, Laaksolahti, & Waern, 2001).

With the growing visibility of recommender systems in e-commerce sites, researchers have started looking into individual traits that might influence consumer response to personalized recommendations. For example, it was found that individuals of different cultural orientations responded differently to different recommendation methods. Individuals with higher individualistic or independent tendencies respond more favorably to personalized recommendations, compared to targeted recommendations (Kramer, Spolter-Weisfeld, & Thakkar, 2007). Customers’ cognitive differences have been shown to influence recommender success (Wang & Doong, 2010). Individuals with higher adaptive-innovation style and involvement level toward recommendation agents were found to give more deliberation to the recommendation agent’s advice. In Liang, Lai, and Ku (2007), an experimental personalized news service was shown to perform better than a non-personalized one in terms of both prediction accuracy and user satisfaction. More noticeably, their study went beyond simple comparison of system performance to include several contextual variables such as degree of user participation and motivations for information access that might affect the effectiveness of the system. It was also found that the effects of personalized news service on user satisfaction were moderated by different motivations for information access.


                        Simonson (2005) challenged the fundamental assumption of customization that individuals have well-defined and stable preferences and can always identify the options best fitting their preferences. Furthermore, when users do not have stable and well-defined preferences, they often have to rely on various proxies or cues to assess the value of recommendations. He speculates that users’ responses to recommendations are subject to influences from various contextual factors including users’ preference development, trust, presentation format, and nature of the goods recommended. He proposed the theoretical construct of “preference development” to be an important antecedent to the success of a customized service. According to Simonson, users’ preference development could be characterized along two dimensions: preference stability, that is, whether users have a well-defined and reasonably stable preference; and self-insight into preference, the ability of users to be able to define their preference and recognize the best fit among available options. The notion of preference development has since been picked up by several subsequent studies. In Kwon et al. it was found that users’ preference development influenced the effectiveness of different recommendation approaches for a movie database (Kwon et al., 2009). In Franke et al. (2009), it was found that customization created higher value if customers have (1) more knowledge about their own preference, (2) better ability to express their preferences, and (3) greater product involvement. In Shen and Ball (2011), it was found that users who have higher self-assessed preference stability (1) appreciate customized recommendation more, (2) are better at recognizing whether recommendations are customized or not, and (3) have a more favorable attitude to the learning relationship when recommendations are customized than when not.

The three preference characteristics we considered were: “preference insight”, “reader involvement with reading”, and “preference diversity”. For “preference insight” we meant to capture how knowledgeable a person is about her/his reading interest. It has been shown (West, Brown, & Hoch, 1996) that increasing knowledge in product language in an unfamiliar domain led to higher preference stability. In Simonson (2005), “preference insight” was coined to refer to consumers’ ability to know and express what they want. While preference insight is essential for customized recommendations to be effective, people with more knowledge about what they want might also enjoy greater independence and rely less on recommenders. This might particularly be the case in cultural consumption where avid readers often accumulate substantial cultural capital to help them navigate through the cultural landscape (Caves, 2002). With more consumption of cultural products, individuals tend to become more discerning and also more knowledgeable about sources where they can find works of interest. It was found in Ross (1999) that experienced readers—because of their knowledge about genres, authors, and trusted information sources—often have well-developed heuristics for making choices. Therefore besides knowledge about what they want, in the study we also included knowledge they have about the trusted information sources as part of the preference insight we believe is particularly relevant for the domain of leisure reading.

Closely associated with knowledge is the emotion one invests in reading. Highly involved readers are more motivated to seek out interesting readings and therefore might be more willing to explore recommended items and consider novel recommendations as valuable. In marketing, the construct of involvement has been defined as personal significance the individual consumer invests in a certain product (Celsi & Olson, 1988; Greenwald & Leavitt, 1984; Krugman, 1965). Involvement can be situational or enduring. Situational involvement is a temporary elevation of interest that fluctuates, while enduring involvement represents a stable attachment to or interest in a product class over a long period of time (Bettman, Luce, & Payne, 2008). Involvement has been shown to be an important moderate variable on consumers’ response to advertising messages (Greenwald & Leavitt, 1984), online consumer reviews (Park, Lee, & Han, 2007), as well as personalized offers (Franke et al., 2009). We believe that degree of involvement is a crucial factor in determining users’ receptiveness to previously unknown books, authors, or genres. Regular users are known to be very sensitive to search and transaction cost incurred in finding information, so it is reasonable to assume that highly involved readers are more willing to spend the effort to interact with exploration-based book finding tools. They might also be more likely to derive pleasure from tools that help expand their reading horizon.

A novel concept of users’ “preference diversity” was also proposed in this study that aimed to represent how narrow/wide or diverse/convergent one’s reading interests are. There is a similarity between reading homogeneity and stability as both reflect how changeable an individual’s reading interests are. But there are also significant differences. One can imagine a reader who has diverse yet stable reading interests and a person who has a very discerning taste yet at the same time is open to trying new things. While as Simonson pointed out, “preference stability” is essential for the recommender system to establish an effective learning relationship with its users, we are more interested in this study in how the users with different ranges of reading interests might respond to the recommended items. We speculated that readers with diverse reading interests might be more open to non-obvious recommendations. One of the consistent issues in the design and evaluation of recommender systems is the balance between accuracy and “nonobviousness” of recommendations (Herlocker, Konstan, Terveen, & Riedl, 2004). While the recommendation of accurate, yet previously known items might foster user confidence, their presence represents less novelty and serendipity. The proper balance between the two might very much lie in how willing an individual is to try novel recommendations. We therefore wish to use the concept of preference diversity to represent how willing a reader is to venture into previously unfamiliar areas in terms of subject matters, genres, and authors. More adventurous readers might prefer novelty and serendipity over accuracy and vice versa.

The aims of the study are twofold: Firstly, to explore possible criteria for evaluating the social navigational tools. A set of measures designed to capture various aspects of the benefits provided by the tools was proposed. An experiment was then conducted using a modified interface of aNobii so that we could compare performance of these tools against the traditional author browsing function on these measures. Secondly, the study examines how three aspects of preference, “preference insight”, “preference diversity” and “reading involvement”, might influence users’ response to the three book finding tools. The three aspects of user preference were therefore introduced as factors that mediate users’ responses to the recommendations made by the aforementioned three book finding tools. See Fig. 1
                      for a graphic representation of the analytical model. We thus summarize our research questions as:
                        
                           1.
                           What are the potential benefits to the users provided by the socially based navigational tools based on which proper evaluation criteria can they be created? Other than traditional result quality measures, are there search experience measures that can be used to validate the value of these exploratory-based tools?

How do the three book finding tools: the two socially-based: browsing friends’ and similar bookshelves, and the traditional author-based browsing, compare with one another against these evaluation criteria?

How might the three dimensions of user reading preferences influence the users’ behaviors and search effectiveness with these tools?

@&#METHODOLOGY@&#

The study set out to explore potential criteria by which the social navigational tools on social media can be evaluated. The online book sharing website aNobii was chosen as the test site for our study, for a couple of reasons. Firstly, it has attracted a relatively large user community in Mandarin in Taiwan (where the study was conducted) among all the book-sharing platforms. Secondly, it also provides a wide range of social navigational tools that enable us to draw rich user-interaction data. Besides allowing users to manage their reading list, write reviews, and assign ratings, aNobii also make it possible for its users to connect and form online communities with others who share similar reading interests. With aNobii, a dense network of navigational pathways are made available that allow users to browse others’ bookshelves and items similar to those in one’s own bookshelf.

To test the feasibility of our evaluation criteria, a modified aNobii interface was created where three book-finding tools are made available: the author-browsing, the “friends’ bookshelves” and the “similar bookshelves” browsing functions. The latter two social-based functions were embedded in aNobii. While a “friend” is someone you are acquainted with in real life, a “neighbor” is someone who you do not know in real life but with whom you share a similar reading profile. As for the author-browsing, we modified the interface so that when the user clicks on a particular author name appearing in her bookshelves (which was originally intended for the purpose of managing one’s bookshelf instead of finding new books), all the books by that author, including those not previously listed in one’s bookshelf, will be presented to her for browsing (see Fig. 2
                         for a screenshot of the modified interface).

To control the treatment, all other links not produced by the specific function tested were dynamically removed (see Fig. 3
                        ).

Subject recruiting information was posted in the aNobii social network and book related forums in a campus-based online bulletin board system, popular among college students. A total of fifty regular aNobii users were eventually recruited to participate in the study, all of whom met the criteria of having at least five “friends” and eighty titles in their bookshelves. The qualification was meant to guarantee rich enough user profiles for the connection-based system to be effective. Participants who met the selection criteria were asked to finish a background questionnaire concerning their past experiences with aNobii and reading preferences upon their arrival.

A within-subject design was adopted where all participants would interact with all three book-finding approaches in each of three different search sessions. The search order was alternated to avoid order effect. The participants were instructed that they would have a maximum of 10min to browse and save books in the “wish list” that they would like to read in the future, and that they may stop browsing if they feel the method is unlikely to bring up more interesting items. When searching with each tool, the participants were able to re-rank the results by attributes such as title, rating, published date, and finished reading date (see Fig. 4
                        ).

After they completed all three search sessions, the participants were then asked to fill out a post-search questionnaire where they would judge the quality of the saved items and assess the value of each tool.

As there has not been a widely agreed-upon evaluation methodology for systems where users search in a highly interactive, exploratory manner, a set of measures was designed for this study. The desirable evaluative criteria should be able to take into account the quality of both the search experience and search results. Four aspects of user experience were measured using post-search questionnaire: the degree to which the tool is able to broaden one’s reading horizon, how interesting it is to use, intention for future use, and the extent to which items shown match one’s reading preferences.

As for search effectiveness, in their review of recommender evaluation, Herlocker et al. (2004) pointed out that an ideal recommendation method should be able to balance accuracy and “nonobviousness” of the recommendations. We also wished to capture both the accuracy and the “nonobviousness” dimension of quality. Without the benefits of a “relevant set” in traditional IR evaluation, we depended on users’ judgment and behaviors as evidence of result quality. The user judgment measurement is based on questions asked for each item saved in the post-search questionnaire. They were asked at the end of the search, how confident they were that the saved item would turn out to be satisfactory (expected result satisfaction measure) and how unlikely they were able to find it by alternative means (serendipity measure), both on a 0–100 scale.

Further measurement of accuracy was made by recording users’ book visiting and saving behaviors. A transition log was used to record books presented to, visited, and saved by the participants. Here the “choice set” model originated in retailing (Crompton, 1992; Shocker, Ben-Akiva, Boccara, & Nedungadi, 1991; Spiggle & Sewall, 1987; Woodside & Lysonski, 1989) was borrowed to analyze how effective the system was able to generate items of interest to the users (see Fig. 5
                        ). The choice set model in marketing was conceptualized to formally represent the process of choosing among alternative retailers: from the total of all retailers (the total set) to those known to (awareness set), considered (consideration set), and chosen by the consumer (choice set). We found it useful in the book finding situation where the users also face an overabundance of alternatives that are beyond their capacity to thoroughly evaluate and process. The model highlights the essential role of recommendation in bringing up potentially interesting books to the user’s awareness.

Here the awareness set was defined as the total number of books each participant was exposed to by each tool on the screen; the consideration set, the number of books visited; and choice set, the number of titles eventually saved by the participant. Within the awareness set, a further distinction was made among items between titles that had been previously unknown (true awareness) and previously known to the user (see Fig. 5). As it is impossible to exhaust all the books that had been previously known to the user, the set of books that had been listed in one’s bookshelf before the study was used as a rough approximation of the titles previously known. Therefore using visiting and saving books as evidence of showing interest, we were able to generate two accuracy oriented measures: the consideration set ratio and the choice set ratio, which are defined by the number of books visited, the and number of books saved, respectively, to the number of books each tool brings to a users’ attention. These two measures should give us indications of how effective these tools were in bringing up potentially interesting items to the user and therefore are equivalent to precision measures in IR evaluation (see Table 1
                         for a summarization of the consideration set based measures).

As for the dimension of “nonobviousness”, a distinction was made between “novelty” and “serendipity” (Herlocker et al., 2004). A novel item is something new to the user at a point in time but which they will very likely encounter eventually in the future, whereas a serendipitous find is a surprisingly interesting item that the user would not have otherwise discovered. The novelty measure was obtained by the transaction log, defined by the ratio between true and total awareness sets. The serendipity measure was derived from users’ judgment of the books saved. For each saved item the users were asked in the post-search questionnaire, to assess “had it not been for this book-finding method, how unlikely they were able to encounter it eventually through their regular information sources”. The more unlikely the users are able to encounter the books in their usual information sources, the higher the serendipity the book represents. Taking the average score of all the books saved would then give us a measure of the “serendipity” of the results generated by each tool (see Table 2
                         for a summary of performance measures).

@&#RESULTS@&#


                        Table 3
                         provides the descriptive statistics of the participants’ gender, time since joining aNobii, and frequency of use. Over 82 percent of the participants have joined for more than one year. The numbers of books owned in the “bookshelf” ranged greatly from 81 to 2528, with a mean of 431.65 and SD of 495.30; the numbers of friends ranged from 5 to 52, with a mean of 15.6 and SD of 11.53. A significant correlation was found between the number of books owned and total friends, r
                        =.31, p
                        <.05 (see Fig. 6
                        ).

After completing searching with each tool, the participants were asked, on a 0–6 scale (0 standing for strongly disagree, 6 meaning strongly agree), to indicate the degree to which each book-finding tool was able to “broaden their reading experience” and “match their reading preference”, as well as “how interesting it was to use” and their “revisit intention”. Table 4
                         provides the descriptive statistics of these overall user experience measures.

Repeated measure ANOVAs were conducted to compare the performance of the three book-finding tools on these four measures. A significant difference was found in “broadening reading horizons” (F
                        (2,98)
                        =11.62, p
                        =.000). The paired comparisons showed that author browsing (M
                        =3.02) did significantly poorer than similar bookshelves (M
                        =3.84) and friends’ bookshelves (M
                        =4.3), although the difference between the latter two was not significant.

A significant difference was also found for “how interesting it was to use” (F
                        (2,9)
                        =7.24=.001). Author browsing (M
                        =3.60) did significantly poorer than browsing similar bookshelves (M
                        =4.22) and friends’ bookshelves (M
                        =4.54), but the difference between the latter two was not significant.

No significant differences were found in revisit intention (F
                        (2,98)
                        =2.28, p
                        =.11). A significant difference was also not found in “preference matching” among the book-finding tools (F
                        (2,94)
                        =2.64, p
                        =.08), though author browsing scored slightly higher than the other two methods (see Fig. 7
                        ).

Other than self-reported data, we also collected users’ click stream data to provide the base for objective measures for search effectiveness. Fig. 8
                            shows the numbers of each set averaged over all the 50 participants broken down by tools used. Not surprisingly, the author searching tool produced the least genuinely new items (Mean=95) as considerably more books shown by the author search were redundant (Mean=25). On average, the users saved equivalent amount of books as the average size of the choice sets were 6 for the author browsing, 6 for browsing friends’ bookshelves, and 5 for browsing similar bookshelves. Notice that significantly more items were shown to the users by browsing “friends’ bookshelves” function (F
                           (2.144)
                           =5.41, p
                           =.005), suggesting that participants were more willing to explore using this tool.

The “choice set ratio”, and “consideration set ratio” referred to the proportion of the items saved, and visited, respectively, to the total numbers of titles shown by the tool. These two measures gave us an indication of how effective the tool was in bringing interesting books to the user’s attention. The “true awareness set” ratio refers to the proportion of titles that had previously not been included in the user’s bookshelf to the total number of titles shown by the tool, which gave us an indication of “novelty”. “True” consideration and choice sets were calculated by taking the “true awareness” set as the denominator, instead of the raw number of books shown by each tool. Table 5
                            shows the Mean and standard deviation (SD) of the different user-behavior based measures across three different tools.

Repeated measure ANOVAs were conducted to test whether the three book-finding tools differed in these measures. For the novelty measure represented by “true awareness set ratio”, a significant difference was found among the three tools (F
                           (2,88)
                           =30.22, p
                           =.000). Paired comparison showed that author browsing (M
                           =.79) did significantly poorer than similar bookshelves (M
                           =.93) and friends’ bookshelves (M
                           =.91), while the difference between the latter two was not significant.

The results showed no significant difference in the “consideration” set ratio (F
                           (2,90)
                           =2.93, p
                           =.058). However, a significant difference was found in “true consideration” set ratio (F
                           (2,88)
                           =7.2, p
                           =.001). Paired comparisons showed that author browsing (M
                           =.13) did significantly better than similar bookshelves (M
                           =.09) and friends’ bookshelves (M
                           =.09), while the difference between the latter two was not significant. The results in “choice set ratio” was not significant (F
                           (2,94)
                           =.35, p
                           =.89); nevertheless, a significant difference was found in “true choice set” ratio (F
                           (2,88)
                           =3.22, p
                           =.045). The paired comparisons show that author browsing (M
                           =.08) did significantly better than friends’ bookshelves (M
                           =.05).

To assess the search effectiveness of these tools, two search effectiveness measures, “serendipity” and “expected satisfaction”, were created based on the average scores the participants gave to the titles saved in their “wish list”. A one-way repeated measure ANOVA showed a significant difference in “serendipity” among the different book-finding tools (F
                           (2,92)
                           =7.22, p
                           =.001). The serendipity of author browsing (M
                           =33.07) did significantly poorer than similar bookshelves (M
                           =40.7) and friends’ bookshelves (M
                           =44.93), while the difference between the latter two was not significant.

A significant difference was also found in “expected satisfaction” (F
                           (2,92)
                           =4.49, p
                           =.023). Follow-up paired comparisons showed that author browsing (M
                           =73.75) did significantly better than similar bookshelves (M
                           =68.13) and friends’ bookshelves (M
                           =69.90), while the difference between the latter two was not significant (see Table 6
                           ).

The participants were asked a series of questions aimed to elicit their preference structure. The dimensionality of the 12 questions was analyzed using maximum likelihood factor analysis. As shown in Table 7
                        , the rotated Varimax solution yielded three interpretable preference factors, “insight”, “diversity”, and “reader involvement”, each of which accounted for 22.52%, 21.67%, and 19.43% of variance, respectively. The three factors were then saved as variables that represent three dimensions of individual reader’s preference structure, which were then inducted later as the mediating variables to system performance Fig. 9
                         shows the distribution of the participants along the preference dimensions of “insight” and “reader involvement”.

We first looked into whether users’ preference structure would influence their overall book finding behaviors, regardless of search tools used. Correlation analyses were conducted between users’ three preference characteristics and their behavioral statistics. Table 8
                         shows that users with higher reader involvement also tended to save more items in the choice set, as measured both by choice set ratio, and “true” choice set ratio. The results also showed that it is relatively more difficult to recommend truly novel items to users with higher preference insight and users with higher reading involvement, both of which were negatively correlated with true awareness set ratio.

We next looked into whether there are interaction effects between the three preference variables, based on our hypothesis that users of different preference characteristics are better served by different tools. Instead of ANOVA generally used in system evaluation studies, this part of the analysis was conducted using general linear model which allowed us to tease out the relative impacts on system performance of the experiment components, such as system, task, and user characteristics (Sun & Kantor, 2006; Wacholder et al., 2007). Therefore to investigate our research question regarding the interaction effects between preferences and tools, a GLM repeated measure analysis was conducted using the size of the choice set as dependent variable, the tools as within-subject factor and “preference insight” as the covariance (see formula below). A significant interaction effect was found between tools and preference insight (F
                        (2,90)
                        =3.77, p
                        <.05). Similarly, two more GLM analyses were conducted, using “reading involvement” and “preference diversity”, respectively, as the covariance. A significant interaction effect was found between tools and involvement (F
                        (2,90)
                        =3.92, p
                        <.05), but not between preference diversity and the tools (F
                        (2,90)
                        =.95, p
                        =.39).
                           
                              
                                 Choice set
                                 =
                                 
                                    
                                       β
                                    
                                    
                                       0
                                    
                                 
                                 +
                                 
                                    
                                       β
                                    
                                    
                                       1
                                    
                                 
                                 ∗
                                 (
                                 Tool
                                 )
                                 +
                                 
                                    
                                       β
                                    
                                    
                                       2
                                    
                                 
                                 ∗
                                 (
                                 Preference
                                 )
                                 +
                                 
                                    
                                       β
                                    
                                    
                                       3
                                    
                                 
                                 ∗
                                 (
                                 Tool
                                 )
                                 (
                                 Preference
                                 )
                                 +
                                 
                                    
                                    
                                       +
                                    
                                 
                                 
                                    
                                       ε
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        
                     

Closer examination revealed that when browsing friends’ bookshelves, preference involvement had a significantly higher correlation with the choice set (β
                        =.02, t
                        =2.40, p
                        <.05) than the other two preference variables, whereas when browsing known authors’ works, preference insight had a significantly higher correlation with the choice set (β
                        =.02, t
                        =3.19, p
                        <.01) than the other two preference variables. The results suggest that, when using choice set as the performance criterion, the highly involved users were best served by browsing friends’ bookshelves, while the more knowledgeable users were best served by browsing authors’ works.


                        Table 9
                         shows the correlations between the preference characteristics and choice set based performance criteria in three different tools. A significant correlation indicated the influence of the preference variables on book finding performance of the tools.

The first thing worth noticing are the consistent significant correlations between preference insight and results accuracy, as measured by consideration and choice set ratios, in browsing known authors’ works. On the other hand, author browsing did especially poorly to suggest novel titles to high preference insight and high reader involvement users as both scores had a negative correlation with novel measure (i.e. true awareness set ratio), which did not come as a surprise as knowledgeable and highly involved readers were more likely to know or follow certain authors. More interestingly, reader involvement was shown to be correlated with result accuracy only in browsing friends’ bookshelves. In other words, browsing friends’ bookshelves seemed to be a more effective browsing strategy for users with high reader involvement in terms of search accuracy. Preference diversity was shown to correlate with none of the measures.

@&#DISCUSSION@&#

Our results showed that while the similar bookshelf did consistently the poorest, the other two book-finding tools, author search and friends’ bookshelves exchanged leads in different measures, depending on the underlying criteria these measures represented. In the search experience category, “friends’ bookshelves” did better in all but one measure, “preference matching”. The advantage of the browsing known- author approach in preference matching was also reflected in users’ visiting and saving of the books. The author-browsing did slightly better than the other two in terms of consideration and choice set ratios, measures equivalent to precision in IR evaluation as it reflected how effective the tool was able to bring potentially interesting items to users’ attention. Yet, perhaps not surprisingly, it also produced the lowest “true awareness” ratio, a measure representing result novelty, in that many of the works by the same authors had already been included in their bookshelves. A pattern emerged from our results that, while the accuracy-oriented measures favored the author search, the search experience measures tended to favor browsing friends’ bookshelves. The author browsing method matched better with users’ reading preference and generated more interesting items for close examination. On the other hand the friends’ bookshelves function was more interesting to use, more conducive to learning (i.e. broadening one’s reading horizon), and led to a slightly higher revisit intention.

The same contrast between author based browsing and the two socially-enabled tools also manifested itself in the two search results quality measures, namely serendipity and expected satisfaction of the saved items. Our results showed that the two socially-enabled tools were, in general, more conducive to serendipitous finds, while items saved by author browsing were judged to be more likely to turn out to be satisfactory. Apparently, author is an important cue base and an important factor for making confident judgments about their interest in a book; it gave the users higher confidence in their judgment (Mikkonen & Vakkari, 2012). It should be noted that, though browsing similar bookshelves did rather poorly in most of the measures, one should not generalize the poor result to other collaborative filtering contexts. Our observation is that, at the time the study was conducted, the bookshelf similarity measure in aNobii was based simply on the number of shared titles, which biased the larger bookshelves, a shortcoming that can be fixed by more sophisticated bookshelf similarity measures (e.g. Bobadilla, Ortega, & Hernando, 2012). It would be interesting, for future study, to conduct similar evaluative studies with more advanced collaborative filtering algorithms to generate similar bookshelves. Besides exploring different evaluative criteria, another important research goal is to examine the influence of users’ preference on their searching behaviors and tool effectiveness. In general, higher degree of involvement tended to lead to a larger choice set, indicating a stronger willingness to explore more items. Two aspects of the preference, insight and reader involvement, were shown to be significant moderating factors to the effectiveness of the tools. While author browsing worked particularly well for users with higher preference insight, probably due to the fact that more knowledgeable readers tended to rely more on authors as distinctive markers of styles, browsing friends’ bookshelves was shown to be most effective for highly involved readers. We suspect that this is because highly involved readers also tended to have more friends of compatible reading interests. Notice that when browsing friends’ bookshelves, highly involved readers were much more likely to encounter previously known titles (i.e. low true awareness ratio). Yet, as reported earlier, browsing friends’ bookshelves produced the highest true awareness ratio overall, and was therefore most conducive to novelty finds (see Table 5). The fact that highly involved readers tended to encounter more redundant recommendations when using the supposedly most novelty generating tool seemed to support our speculation. It was found in Ross (1999) that avid readers not only read a lot themselves but often support, and sometimes initiate others’ reading. She pointed out that, rather than a solitary activity, reading often occurs within a network of social relations. A longitudinal network analysis of aNobii conducted by Aiello, Barrat, Cattuto, Ruffo, and Schifanella (2010) lends empirical evidence to our observation that a social network site like aNobii facilitates the communal aspect of reading. It was found in Aiello et al. that bookshelf similarity between users increased significantly after a link between them was formed. In other words, users took inspiration from others members for new books to read and new groups to join, and as a consequence the alignment of their reading profile.

As for preference diversity, even though none of the correlations involving preference diversity was significant, we nonetheless noticed consistently negative correlations between preference diversity and the accuracy measures in author search. This seems to suggest that readers with high preference diversity were particularly ill-served by author searching as they were more willing to explore previously unknown authors.

@&#CONCLUSION@&#

The growing availability of social navigational tools on social media presents a challenge to evaluative methodology. The first main contribution of our research is to propose and test a set of subjective and objective evaluative measures by which the benefits of these tools can be validated and compared. Other than the usual self-report user experience and result based measures, the “choice set” model from retailing was used to provide a framework by which navigational effectiveness can be assessed. Another important finding in this study is that two aspects of users’ preference structure, “ insight”, and “readerinvolvement”, were found to influence users’ behaviors and tool performance.

On the evaluative aspect of the research, it was found that not all the criteria agreed with each other, which indicates that the benefits of these tools are multi-faceted and should be evaluated as such. At least two dimensions of evaluative criteria can be distinguished from our results: users’ search experience and the quality of search results. Some of the benefits provided by social navigational tools, most noticeably the knowledge gained and pleasure acquired in the browsing process, cannot be captured by the results-based evaluation measures. Our results indicate the importance of including different aspects of user experiences, especially those related to learning and pleasure (Novak, Hoffman, & Duhachek, 2003; O’Brien & Toms, 2012; Qu & Furnas, 2008; Webster, Trevino, & Ryan, 1993), when evaluating the performance of social navigational tools. Though performingless favorably in terms of search efficiency, the friends’ bookshelves function was shown to engender more informative and interesting browsing experiences. The acts of search and browsing, once considered means to the end of finding relevant results now can also have value of its own in the context of book finding on social media sites.

In terms of search effectiveness and quality of the results, the author search proved to be the most effective tool as percentage-wise it triggered more examining of items. However, the accuracy gained by author searching comes at the expense of less novelty. Among the three tools, it was also the least capable of “broadening” one’s reading horizon. On the other hand, the two socially-enabled tools, browsing friends’ and similar bookshelves, were shown to produce more novel items, and generated more serendipitous choice sets than those by the author browsing, though the latter instilled more confidence in users’ judgment. In a sense, the contrast between author browsing and borrowing friends’ bookshelves reflects a constant trade-off between accuracy and “nonobviousness”, which can also be observed in the evaluation of a recommender system (Herlocker et al., 2004).

We suspect that a proper trade-off between the two might very likely depend on various aspects of users’ preference structure. Three aspects of users’ preference, insight, diversity, and reader involvement, were measured and their influence on users’ book seeking behaviors and effectiveness of different tools were tested. To test the interaction effects between user trait and system, analytical models that went beyond the comparison-driven approach that mainly consider the system main effect were conducted. Our study demonstrated the feasibility of a carefully thought-out analytical model to tease out the interaction effects between user preference characteristics and system. The regression analyses showed that both preference insight and involvement were found to negatively impact on the novelty measure, especially when author browsing was attempted. Interaction effects were found between the navigation tools and two of our preference characteristics, insight and reader involvement, on the choice set ratio. It was shown that, insight and emotional attachment, though conceptually related, were two distinctive dimensions of readers’ preference. Interestingly, while users of high preference insight relied more heavily on author browsing to obtain more accurate results, highly involved readers tended to visit and select more books, percentage wise, when browsing friends’ bookshelves. It seems that involvement, rather than preference diversity as we had expected, was the more salient factor in determining users’ willingness to explore unfamiliar territory.

A few limitations should be noted. Firstly, an estimation of the books previously known to the user is needed for the purpose of calculating novelty score. Yet as it was unfeasible to exhaust all the possible works known to the user, the books that had already been saved in the user’s bookshelf were used as the approximation. This might be problematic if the completeness of the previously known title list is correlated with the preference factors of insight or reader involvement. One might point out that, for example, highly involved users might be more diligent in updating and saving titles in their bookshelves, which presents an alternative explanation to the negative correlation between involvement and true awareness set ratio, though correlation analyses performed between the number of books in the bookshelf and all three preference characteristics revealed no significant correlation. Another inherit limitation is the representativeness of our samples. It is reasonable to suspect that aNobii users are more involved and knowledgeable than the population at large; therefore one should refrain from generalizing the finding regarding the impact of user preference to the general population. One might, however, justify the study of avid readers by the fact that, though a relative small group in the general population, they account for a disproportionally large amount of reading activities. In order to establish vigor for comparison, the participants were asked to search only one tool at a time, which might diverge from the real life situation where they might mix tool use. Without rich qualitative data, we still know very little about users’ decision making processes when interacting with these navigational tools, It might be interesting in the future to conduct a user study in a naturalistic setting that records both users’ behaviors and thinking processes in the information-rich environment of social media.

@&#REFERENCES@&#


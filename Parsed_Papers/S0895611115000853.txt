@&#MAIN-TITLE@&#Alzheimer's disease diagnosis on structural MR images using circular harmonic functions descriptors on hippocampus and posterior cingulate cortex

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           The combination of hippocampus and PCC atrophy captured by CHF features gives a good indicator to AD diagnostics.


                        
                        
                           
                           The method is less time consuming.


                        
                        
                           
                           The proposed method is fully automatic and do not require the intervention of an expert.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Alzheimer's disease

Bag-of-Visual-Words

Circular harmonic functions

Local features

PCA

Support vector machines

Hippocampus

Posterior cingulate cortex

Visual similarity

CBVIR

@&#ABSTRACT@&#


               
               
                  Recently, several pattern recognition methods have been proposed to automatically discriminate between patients with and without Alzheimer's disease using different imaging modalities: sMRI, fMRI, PET and SPECT. Classical approaches in visual information retrieval have been successfully used for analysis of structural MRI brain images. In this paper, we use the visual indexing framework and pattern recognition analysis based on structural MRI data to discriminate three classes of subjects: normal controls (NC), mild cognitive impairment (MCI) and Alzheimer's disease (AD). The approach uses the circular harmonic functions (CHFs) to extract local features from the most involved areas in the disease: hippocampus and posterior cingulate cortex (PCC) in each slice in all three brain projections. The features are quantized using the Bag-of-Visual-Words approach to build one signature by brain (subject). This yields a transformation of a full 3D image of brain ROIs into a 1D signature, a histogram of quantized features. To reduce the dimensionality of the signature, we use the PCA technique. Support vector machines classifiers are then applied to classify groups. The experiments were conducted on a subset of ADNI dataset and applied to the “Bordeaux-3City” dataset. The results showed that our approach achieves respectively for ADNI dataset and “Bordeaux-3City” dataset; for AD vs NC classification, an accuracy of 83.77% and 78%, a specificity of 88.2% and 80.4% and a sensitivity of 79.09% and 74.7%. For NC vs MCI classification we achieved for the ADNI datasets an accuracy of 69.45%, a specificity of 74.8% and a sensitivity of 62.52%. For the most challenging classification task (AD vs MCI), we reached an accuracy of 62.07%, a specificity of 75.15% and a sensitivity of 49.02%. The use of PCC visual features description improves classification results by more than 5% compared to the use of hippocampus features only. Our approach is automatic, less time-consuming and does not require the intervention of the clinician during the disease diagnosis.
               
            

@&#INTRODUCTION@&#

Alzheimer's disease (AD) is a progressive, neurodegenerative disease characterized by severe deterioration in cognitive function, especially by memory loss. Nowadays, it represents a major public health problem. An early diagnosis of AD will allow patients to benefit from new treatments that may slow down neurodegeneration.

Actually, neuroimaging appears as a useful tool in dementia diagnosis, and whether evaluation of magnetic resonance imaging (MRI) data alone has value for early detection of AD remains an important question. In particular, structural MRI is an integral part of the clinical assessment to detect and to follow the evolution of brain atrophy. With this aim, several methods and techniques for images analysis have been proposed to quantify morphological characteristics of human brain. Whole brain morphometric methods were proposed to compare relevant anatomical brain structures by assuming one-to-one correspondence between subjects: voxel-based morphometry (VBM) [4,55] is an automatic volumetric method for studying the differences in local concentration of gray and white matter. Tensor based morphometry (TBM) [52] was proposed to identify local structural changes from the gradients of deformations fields. Object based morphometry (OBM) [38] was introduced for shape analysis of anatomical structures. Nevertheless, due to the variability of subjects, features-based methods have become popular thanks to their statistical redundancy and selectivity of salient image areas. Scale-invariant feature transform (SIFT) [37] has recently demonstrated to be promising in features based morphometry [54]. Furthermore, there is a growing interest to region of interest (ROI)-based methods which focus on extracting features from a brain region known to be involved in the disease. Indeed, ROI's manual segmentation performed by an expert or performed by a specific software are the most accurate in brain atrophy measurements. However, they are challenging and have some major drawbacks. In fact, they are time-consuming and can present poor results in a boundary detection of brain regions. Moreover, atlas-based parcellisation can be used as a standard and automated method for automatically labelling ROIs on MR brain images. However, the latter reveals less inter-subject variability and then is not able to represent atrophy information.

Numerous structural analysis involved hippocampus ROI as the most efficient hallmark of AD. In research studies that analyze hippocampus morphology structure, many surface-based shape description approaches have been proposed. In [27,25], shape information in the form of spherical harmonics (SPHARM) has been used as a feature for the support vector machines (SVM) classification. In [46], statistical shape models (SSMs) which capture a morphological variation on surface regions, have been used to improve the discrimination between AD and normal controls (NC). However, automatic description of the structural local features remains challenging. Indeed, the overall volumetric analysis or the global shape description of the hippocampus does not describe the local change of structure.

Moreover, fusion of measurements from many different regions or biomarkers can potentially build patterns of high discriminative power and improve diagnostic decisions. In addition to hippocampal atrophy, PCC hypometabolism has been considered as a hallmark of early stage of AD. Indeed, many studies have shown PCC hypometabolism in incipient AD [10,41,28] associated with PCC atrophy [9,31,11,32,24,47]. Here, the question which arises whether atrophy of both the hippocampus and the PCC could be a more efficient criterion in Alzheimer's disease diagnosis than hippocampus atrophy alone.

In terms of clinical diagnosis, structural MRI provides visual information regarding the brain ROI atrophy, which results from the cell neurodegeneration process. In that respect, content-based visual information retrieval (CBVIR) has become an attractive technique for computer-aided diagnosis [19,21,5,33,42,53,40,54,51]. Actually, CBVIR consists in retrieving the most visually similar images based on the characteristics of their visual content. It has been recently explored for research in medical diagnostics of Alzheimer's disease [2,26,57,36,29,23]. In this area, the approaches used are fundamentally features-based. Here, features are the characteristic vectors computed on small areas-patches in images according to a chosen prior model. These patches can be selected around the so-called characteristic points in image that exhibit signal singularities, or on the contrary, they can be chosen arbitrarily in an image space. Hence, features-based MR image comparison techniques are being established. The specific nature of MRI vs general purpose image databases requires in-depth studies of specific features which have to be designed to explain visible and invisible abnormalities in a diagnostics process. Attempts to follow the CBVIR approach with features-based similarity were made for subject discrimination and showed performances that argue for pursuit of features-based approaches [2,1,39,18,57].

Despite the reported success of SIFT features [54,44], on the basis of our successful previous experience [39,7] we resort to circular harmonic functions (CHFs). Actually, they give interesting approximations of blurred and noisy signals in MRIs. CHFs were first introduced in the pattern recognition domain [50]. CHF descriptors have several advantages over other descriptors particularly for MRI. Indeed, they do not contain a histogram-based part as it is the case for SIFT, SURF and other descriptors. They are invariant to luminance and changes in a local patch and due to their polynomial nature they capture the smooth variations of image signal. According to [50,49], these descriptors in some cases are superior to SIFT. Furthermore, computing the CHF descriptors on densely sampled patches in brain brings the statistical variety necessary for overcoming the problem of inter-subject instability of signal singularities. An important issue here lies in the representation of extracted features for comparison purpose. One of the most popular models in CBVIR is the Bag-of-Visual-Words (BoVW) [16,48]. This model represents a whole image or a ROI as a histogram of occurrence of quantized visual features, which are called “visual words”. The histogram received the name of “visual signature” of an image/ROI. Some works in MRI classification for diagnostics of AD evaluate the suitability of the BoVW approach. In [18], the authors use SIFT features extracted from the whole subjects brain to classify brains with and without AD. Successful results with BoVW approach are also reported in [44]. The two last mentioned works use an SVM to classify signatures obtained by BoVW representation on the open-access dataset OASIS. However, [18,44,54] have not addressed the MCI case which has become important in studies of AD. In order to perform individual diagnosis, pattern classification methods have been proposed. Besides, the most popular pattern classification approaches used for AD diagnostics are support vector machines (SVM) [22,38,60,12,61,34,17,20,58,35]. To increase classification performance, some works typically use techniques to reduce the dimensionality of neuroimaging data and to select the most discriminative features before applying SVM. Principal component analysis (PCA) [30] is often used for this type of application [12]. We opted for PCA as well, as the visual signatures can be sparse and of a high dimensionality. In terms of prior information, classification can be improved by focusing on local visual features extraction from ROIs known to be involved in AD. Thus, in this work we hypothesize that hippocampal and PCC structures are more efficient than hippocampus alone to detect insidious case of AD.

We design a pattern recognition approach in the paradigm of CBVIR to help early diagnosis of Alzheimer's disease from structural MRI. The idea consists in refuting the hypothesis that morphological atrophies appear at the same voxel location for all subjects. Indeed, we characterize brain abnormalities in terms of intra-ROI local patterns using consistent neuroanatomical features for the disease. Therefore, every brain scan is represented by one global signature using the Bag-of-Words (BoW) approach. The main contributions of our work can be summarized as follows: (1) we extract distinctive local pattern of AD-related atrophy using an atlas based approach without the need of a tedious segmentation. (2) We represent signal variations inside the ROI anatomy by a set of local features. Here, we employ a multiresolution approach based on the circular harmonic functions (CHFs), which is suitable for extracting the most relevant image features. Extracted features are leveraged to distinguish normal from abnormal local ROI tissue. (3) We apply an early fusion of visual signatures from two selected characteristic regions, Hpc and PCC to improve discrimination power. We apply this approach not only to discriminate between AD and NC, but to recognize the more challenging class of subjects (MCI) as well. (4) For classification purposes, the well-studied and efficient tool SVM is used, and for dimensionality reduction of description space, principle component analysis is applied. We applied the method on a subset from the ADNI dataset and then on a small group of a French subset of AD subjects, “Bordeaux-3City” dataset. The rest of the paper is organized as follows: in Section 2 we detail materials and methods. In Section 3, we present experiments and results. Discussion is given in Section 4 and finally, Section 5 concludes this work and outlines its further perspectives.

Different data with different number of subjects and variable MMSE values were used in the literature. A recent work [17] compares 10 classification methods applied to 509 baseline structural MRIs from the ADNI database. Hence, we selected, from the ADNI database, the same data as those used in this work. The data contain 137 AD patients, 162 normal control and 210 subjects with mild cognitive impairment (MCI). Although the images are not exactly the same we selected the same subjects number by group with closed ages and MMSE values from the ADNI database. More detailed information about MRI acquisition procedures is available on the ADNI website.
                           2
                        
                        
                           2
                           
                              http://adni.loni.ucla.edu/.
                         The ADNI was launched in 2003 by the National Institute on Aging (NIA), the National Institute of Biomedical Imaging and Bioengineering (NIBIB), the Food and Drug Administration (FDA), private pharmaceutical companies and non-profit organizations, as a 60 million, 5-year public-private partnership. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers, and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease (AD). Determination of sensitive and specific markers of very early AD progression is intended to aid researchers and clinicians to develop new treatments and monitor their effectiveness, as well as lessen the time and the cost of clinical trials. Images are standard 1.5T screening baseline T1 weighted obtained using the volumetric 3D MPRAGE protocol. Then, we applied our method to a real cohort called “Bordeaux-3City”. This database contains 37 structural MRI (16 AD and 21 NC), in order to evaluate how our method would perform in clinical practice, when a little data are available and prior knowledge about the progression of the disease are limited. MRI examination was performed using a 3Tesla Achieva system (Philips Medical Systems, Netherlands) equipped with an eight-channel SENSE head coil. Anatomical high resolution MRI volumes were acquired in transverse plan using a 3D MPRAGE T1-weighted sequence (TR/TE 8.2/3.5ms, flip angle 7, matrix size 256×256, FOV 256mm, yielding 180 slices of 1mm). The study was approved by the institutional human ethics review board and all individuals in the sample provided written informed consent to participate. Tables 1 and 2
                        
                         present a summary of the demographic characteristics of the selected subjects (including the number, age, gender and mini mental state examination (MMSE) of the subjects).

@&#METHODS@&#

We are focusing only on images of patients with the common disease, AD. It causes particular changes in a brain structure. Our approach initially consists in brain image normalization, which is a standard step in brain image comparison. Then, hippocampus and PCC regions are extracted from brain images using a brain template. Image decomposition on the basis of circular harmonic functions is then realized on those areas to extract representative features. A Bag-of-Visual-Words approach is applied to the obtained features and then a signature is generated for each ROI. The global image signature of a subject is obtained by concatenating both hippocampus and PCC signatures into a single individual brain signature. In order to reduce the (high) dimensionality of signatures, a principle component analysis (PCA) is applied. Eventually, SVM classifiers are used to classify the subject's brain into NC, MCI and AD categories. Fig. 1
                         depicts a block-diagram of the method.

The first stage of visual features extraction aligns MRI scans to a standard brain template. The alignment is mandatory for ROIs extraction. Two types of alignment: linear or non-linear can be applied accordingly to the common practices. The linear transform, either “rigid body” or affine, allows only a coarse registration of global geometrical differences, e.g. rotation and magnification. Fine anatomical structures will not be aligned precisely by the linear transform because of natural inter-subject anatomical variance. Non-linear deformable registration allows a more precise alignment of fine brain structures. However, it is hard to guarantee that images are not “over-aligned”, which would mean the loss of the individual patterns in brain structures. A more detailed analysis of this problem is presented in [43]. The authors note several shortcomings of the voxel-based morphometry (VBM) approach, which is based on nonlinear registration. First, the deformable registration is not desirable for features-based approaches, as it deforms the features itself, while we want to preserve specific local patterns. Second, our approach analyzes the brain ROIs slice-by-slice. Linear registration gives us roughly corresponding slices for the selection of ROIs. The similar slice-based technique was used in [2]. In addition, affine registration preserves specific local patterns. Thus, in our work we apply an affine registration of all scans to the MNI 152 brain template [24], developed by the Montreal Neurological Institute (ICBM, NIH), through using the freely available VBM8 toolbox.
                           3
                        
                        
                           3
                           
                              http://dbm.neuro.uni-jena.de/vbm/.
                         This is done with 12 degrees of freedom, minimizing the least-square distance between each subject image and the brain template.

Since each brain image is affinely registered with a digital atlas in 3D space and resliced in the same way as the atlas, we are able to identify a region of interest (ROI) by specifying a stack of 2D slices on the atlas. In this initial work, only a portion of the 3D brain volume is used. The regions investigated in this work are suggested by our medical partners. These are regions which may have potential relevance to disease classification of individual MR scans. To select the two ROIs (hippocampus and PCC), we used a brain atlas called automated anatomical labeling (AAL) [56]. The selection process consists in superimposing geometrically aligned individual brain volume and the AAL. As we stated in the previous section, this selection is rough, as a fine segmentation of brain structures is not a part of our approach. We propose to classify the brains on the basis of features. Indeed, feature-based approaches thanks to their statistical nature can handle the imperfections in the brain structures selection. Furthermore, in order to limit the processing only to brain tissues, we also generated a mask to remove skull voxels. This segmentation was performed with the SPM8 software (Welcome Trust Centre for Neuroimaging, Institute of Neurology, UCL, London UK
                           4
                        
                        
                           4
                           
                              http://www.fil.ion.ucl.ac.uk/spm/.
                        ) the resulting mask and the labeled template being both registered to the MNI standard space.

After brain alignment and ROIs selection, we compute image features. As it was already noted, we need to extract only those features that contain visual information related to the presence or absence of the Alzheimer's disease. The high tissue contrast offered by T1-weighted MRI enables to obtain accurate structural neuroimaging analysis, which may be used as a possible surrogate biomarker for diagnosing and predicting AD. In this work, CHFs are used for selection of contrasted patterns in brains, and their coefficients form the descriptors of these patterns. In the current research we use a “dense sampling” strategy as well; that is we compute the signal decomposition on the CHF basis on patches of a regular circular grid. The 2D descriptors are extracted from the segmented ROI on a slice-by-slice basis.

However, the AAL has not been specifically designed for studying patients with AD. Thus, its areas do not necessarily represent pathologically homogeneous region. Here we extract anatomical variation by building distinctive patterns of disease-related atrophy across the AAL generated mask. Referring to the domain knowledge, with shrinkage of the hippocampus, cerebrospinal fluid (CSF) gradually fills up the space left over. These can be expressed as areas of signal changes or tissue atrophy. Therefore, signal variations inside the ROI anatomy can be represented as a set of local CHFs coefficients. Then these features are leveraged to distinguish normal from abnormal scans.

Dense feature placement is illustrated in Fig. 2
                        : the support regions of the fixed size are first generated with their centers on the regular grid including the mask and then only regions overlapping with the mask are selected. CHF coefficients extracted from several areas overlapping with the mask may be different and depend on the signal presented in the ROI (atrophy or not). In the following we will briefly present the underlying mathematical formulation of CHFs.

Descriptor computation is detailed in [50]. We note that these features are computed on each 2D slice separately. Fig. 3
                         illustrates the descriptors extraction from both hippocampus (a) and PCC (b) from three projections.

Circular Harmonic Functions are those from a family of complex orthonormal and polar separable functions.


                           
                              
                                 (1)
                                 
                                    Ψ
                                    (
                                    r
                                    ,
                                    θ
                                    ;
                                    σ
                                    )
                                    =
                                    
                                       Ψ
                                       n
                                       
                                          |
                                          α
                                          |
                                       
                                    
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      r
                                                      2
                                                   
                                                
                                                σ
                                             
                                          
                                       
                                    
                                    
                                       e
                                       
                                          i
                                          α
                                          θ
                                       
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       Ψ
                                       n
                                       
                                          |
                                          α
                                          |
                                       
                                    
                                    (
                                    x
                                    )
                                    =
                                    
                                       1
                                       
                                          
                                             
                                                n
                                                !
                                                Γ
                                                (
                                                n
                                                +
                                                α
                                                +
                                                1
                                                )
                                             
                                          
                                       
                                    
                                    
                                       x
                                       
                                          
                                             α
                                             2
                                          
                                       
                                    
                                    
                                       e
                                       
                                          
                                             
                                                −
                                                x
                                             
                                             2
                                          
                                       
                                    
                                    
                                       L
                                       n
                                       α
                                    
                                    (
                                    x
                                    )
                                 
                              
                           
                        

where n
                           =0, …;
                           α
                           ±1, ±2… and 
                              
                                 L
                                 n
                                 α
                              
                              (
                              x
                              )
                            are Laguerre polynomials. r, θ are polar coordinates, σ is a scale parameter and Γ is a gamma function.


                           
                              
                                 (3)
                                 
                                    
                                       L
                                       n
                                       α
                                    
                                    (
                                    x
                                    )
                                    =
                                    
                                       
                                          (
                                          −
                                          1
                                          )
                                       
                                       n
                                    
                                    
                                       x
                                       
                                          −
                                          α
                                       
                                    
                                    
                                       exp
                                       x
                                    
                                    
                                       d
                                       
                                          
                                             dx
                                             n
                                          
                                       
                                    
                                    (
                                    
                                       x
                                       
                                          n
                                          +
                                          α
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          x
                                       
                                    
                                    )
                                 
                              
                           
                        

The Laguerre functions 
                              
                                 Ψ
                                 n
                                 α
                              
                              (
                              x
                              )
                            can be calculated using the following recurrence relations:


                           
                              
                                 (4)
                                 
                                    
                                       Ψ
                                       
                                          n
                                          +
                                          1
                                       
                                       α
                                    
                                    (
                                    x
                                    )
                                    =
                                    
                                       
                                          (
                                          x
                                          −
                                          α
                                          −
                                          2
                                          n
                                          −
                                          1
                                          )
                                       
                                       
                                          
                                             
                                                (
                                                n
                                                +
                                                1
                                                )
                                                (
                                                n
                                                +
                                                α
                                                +
                                                1
                                                )
                                             
                                          
                                       
                                    
                                    
                                       Ψ
                                       n
                                       α
                                    
                                    (
                                    x
                                    )
                                    −
                                    
                                       
                                          
                                             
                                                n
                                                (
                                                n
                                                +
                                                α
                                                )
                                             
                                             
                                                (
                                                n
                                                +
                                                1
                                                )
                                                (
                                                n
                                                +
                                                α
                                                +
                                                1
                                                )
                                             
                                          
                                       
                                    
                                    
                                       Ψ
                                       
                                          n
                                          −
                                          1
                                       
                                       α
                                    
                                    (
                                    x
                                    )
                                    ,
                                    
                                    n
                                    =
                                    0
                                    ,
                                    1
                                    .
                                    .
                                    .
                                    ,
                                    
                                    
                                       Ψ
                                       0
                                       α
                                    
                                    (
                                    x
                                    )
                                    =
                                    
                                       1
                                       
                                          
                                             
                                                Γ
                                                (
                                                α
                                                +
                                                1
                                                )
                                             
                                          
                                       
                                    
                                    
                                       x
                                       
                                          α
                                          /
                                          2
                                       
                                    
                                    
                                       e
                                       
                                          −
                                          x
                                          /
                                          2
                                       
                                    
                                    ,
                                    
                                       Ψ
                                       
                                          −
                                          1
                                       
                                       α
                                    
                                    (
                                    x
                                    )
                                    ≡
                                    0
                                 
                              
                           
                        

These functions 
                              
                                 Ψ
                                 n
                                 α
                              
                           , called Laguerre–Gauss circular harmonic (LG–CH) functions, are referenced by integers n (referred by “radial order”) and α (referred by “angular order”).

The LG–CH functions are self-steerable, i.e. they can be rotated by the angle ϕ using multiplication by the factor e
                           
                              iαϕ
                           . They also keep their shape invariant under Fourier transformation and they are suitable for multi-scale and multicomponent image analysis.

For a brain scan slice S(x, y) defined on the real plane from one projection plane R
                           2, due to the orthogonality of the 
                              
                                 Ψ
                                 n
                                 α
                              
                            family, the slice S(x, y) can be expanded in the analysis points (x
                           0, y
                           0) for fixed σ in Cartesian system as follows:


                           
                              
                                 
                                    (5)
                                    
                                       S
                                       (
                                       
                                          x
                                          0
                                       
                                       ,
                                       
                                          y
                                          0
                                       
                                       )
                                       =
                                       
                                          ∑
                                          
                                             α
                                             =
                                             −
                                             ∞
                                          
                                          ∞
                                       
                                       
                                          ∑
                                          
                                             n
                                             =
                                             0
                                          
                                          ∞
                                       
                                       
                                          g
                                          
                                             α
                                             ,
                                             n
                                          
                                       
                                       (
                                       
                                          x
                                          0
                                       
                                       ,
                                       
                                          y
                                          0
                                       
                                       ;
                                       σ
                                       )
                                       
                                          Ψ
                                          n
                                          α
                                       
                                       (
                                       ρ
                                       ,
                                       ω
                                       ,
                                       σ
                                       )
                                       ,
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                             
                                                where
                                             
                                          
                                          
                                             
                                             
                                                
                                                   g
                                                   
                                                      α
                                                      ,
                                                      n
                                                   
                                                
                                                (
                                                
                                                   x
                                                   0
                                                
                                                ,
                                                
                                                   y
                                                   0
                                                
                                                ;
                                                σ
                                                )
                                                =
                                                
                                                   ∫
                                                   
                                                      −
                                                      ∞
                                                   
                                                   ∞
                                                
                                                
                                                   ∫
                                                   
                                                      −
                                                      ∞
                                                   
                                                   ∞
                                                
                                                S
                                                (
                                                
                                                   x
                                                   0
                                                
                                                ,
                                                
                                                   y
                                                   0
                                                
                                                )
                                                
                                                   
                                                      
                                                         Ψ
                                                         n
                                                         α
                                                      
                                                      (
                                                      ρ
                                                      ,
                                                      ω
                                                      ,
                                                      σ
                                                      )
                                                   
                                                   ¯
                                                
                                                dxdy
                                                ,
                                             
                                          
                                          
                                             
                                             
                                                and
                                             
                                          
                                          
                                             
                                             
                                                ρ
                                                =
                                                
                                                   
                                                      
                                                         
                                                            (
                                                            x
                                                            −
                                                            
                                                               
                                                                  x
                                                                  0
                                                               
                                                            
                                                            )
                                                         
                                                         2
                                                      
                                                      +
                                                      
                                                         
                                                            (
                                                            y
                                                            −
                                                            
                                                               
                                                                  y
                                                                  0
                                                               
                                                            
                                                            )
                                                         
                                                         2
                                                      
                                                   
                                                
                                                ,
                                             
                                          
                                          
                                             
                                             
                                                ω
                                                =
                                                arctg
                                                (
                                                
                                                   
                                                      y
                                                      −
                                                      
                                                         
                                                            y
                                                            0
                                                         
                                                      
                                                   
                                                   
                                                      x
                                                      −
                                                      
                                                         
                                                            x
                                                            0
                                                         
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

For more details on the use of these functions in image analysis we refer the reader to [50].

For the description of key-points, which are in our case the centers of a regular grid of patches, each point 
                              
                                 
                                    K
                                    ¯
                                 
                              
                              =
                              (
                              
                                 
                                    x
                                    ¯
                                 
                              
                              ,
                              
                                 
                                    y
                                    ¯
                                 
                              
                              ,
                              
                                 
                                    σ
                                    ¯
                                 
                              
                              )
                            is associated to a local descriptor 
                              
                                 
                                    χ
                                    ¯
                                 
                              
                              =
                              {
                              
                                 
                                    
                                       χ
                                       ¯
                                    
                                 
                                 (
                                 n
                                 ,
                                 α
                                 ,
                                 j
                                 )
                              
                              }
                           . This is a complex valued vector consisting of local image projection to a set of LG–CH functions 
                              
                                 Ψ
                                 n
                                 α
                              
                            at 2j
                           
                              max
                            scales neighbor to the keypoint 
                              
                                 K
                                 ¯
                              
                            reference scale 
                              
                                 σ
                                 ¯
                              
                           . The 
                              
                                 χ
                                 ¯
                              
                            elements are defined as:


                           
                              
                                 
                                    (6)
                                    
                                       
                                          
                                             χ
                                             ¯
                                          
                                          (
                                          n
                                          ,
                                          α
                                          ,
                                          j
                                          )
                                          =
                                          
                                             A
                                             
                                                norm
                                             
                                          
                                          ⋅
                                          g
                                          (
                                          x
                                          ,
                                          y
                                          ;
                                          
                                             σ
                                             j
                                          
                                          )
                                          
                                             e
                                             
                                                −
                                                i
                                                α
                                                
                                                   ϕ
                                                   j
                                                
                                             
                                          
                                       
                                    
                                 
                                 
                                    
                                       
                                          
                                             
                                             
                                                n
                                                =
                                                0
                                                ,
                                                …
                                                ,
                                                
                                                   n
                                                   max
                                                
                                                ,
                                                α
                                                =
                                                1
                                                ,
                                                …
                                                ,
                                                
                                                   α
                                                   max
                                                
                                                ,
                                             
                                          
                                          
                                             
                                             
                                                j
                                                =
                                                −
                                                
                                                   j
                                                   max
                                                
                                                ,
                                                …
                                                ,
                                                
                                                   j
                                                   max
                                                
                                                .
                                             
                                          
                                       
                                    
                                 
                              
                            where σ
                           
                              j
                            is the jth scale following 
                              
                                 σ
                                 ¯
                              
                            if j
                           >0, or preceding the 
                              
                                 σ
                                 ¯
                              
                            if j
                           <0 in discretized scale space. A
                           norm is the normalization coefficient that makes descriptor invariant to illumination changes. The phase shift e
                           −iαϕ
                              
                                 j
                              
                            is used to make descriptors invariant to the keypoint pattern orientation, where 
                              
                                 ϕ
                                 j
                              
                              =
                              arg
                              (
                              
                                 g
                                 
                                    1
                                    ,
                                    0
                                 
                              
                              (
                              
                                 
                                    x
                                    ¯
                                 
                              
                              ,
                              
                                 
                                    y
                                    ¯
                                 
                              
                              ;
                              
                                 σ
                                 j
                              
                              )
                              )
                           .

In our work, we treat each ROI as a set of local features. Hence, the BoVW approach model is applied separately to the two ROIs (hippocampus and PCC). The first stage of BoVW approach is to cluster extracted features from the whole database in order to build the so-called visual vocabulary (codebook). As the shapes of PCC and hippocampus differ, each ROI requires its proper codebook. Moreover, the region's shape differs from one projection to another. Thus, we choose to perform the clustering process 3 times from different projections (sagittal, axial and coronal) and to generate one visual vocabulary per projection and per ROI. The size of the resulting brain signature is 3*2*
                        codebook
                        
                           size
                        .

First, all features 
                           
                              f
                              
                                 n
                                 ,
                                 i
                              
                              s
                           
                        , where n and i stand respectively for slice and feature indexes, are extracted from the ROI on all slices from the sagittal projection then the features are quantized by the k-means algorithm.

The centers 
                           
                              c
                              k
                              s
                           
                        , k
                        ∈[K], are then calculated, where K is the codebook size given as a parameter to the k-means algorithm. The same is done for axial and coronal projections. All features 
                           
                              f
                              
                                 n
                                 ,
                                 i
                              
                              s
                           
                           ,
                           
                              f
                              
                                 n
                                 ,
                                 i
                              
                              a
                           
                           ,
                           
                              f
                              
                                 n
                                 ,
                                 i
                              
                              c
                           
                         and centers 
                           
                              c
                              k
                              s
                           
                           ,
                           
                              c
                              k
                              a
                           
                           ,
                           
                              c
                              k
                              c
                           
                         here have the same dimensionality of the descriptor being used. For CHF, it is 150. Once the cluster centers have been determined, the image signature per projection is generated. Each feature is assigned to the closest center using the distance 
                           d
                           (
                           
                              f
                              
                                 n
                                 ,
                                 i
                              
                              s
                           
                           ,
                           
                              c
                              k
                              s
                           
                           )
                        . Here we use the Euclidean distance. Then each projection is represented by a normalized histogram of visual words occurrence. The image signature per ROI h is acquired by the concatenation of the histograms from all projections: h
                        =[h
                        
                           s
                        , h
                        
                           a
                        , h
                        
                           c
                        ]. The final signature is obtained by concatenating hippocampus and PCC signatures.

To reduce the resulting image signature dimension, we use the principal components analysis (PCA) [30] which is a useful mathematical technique for reducing vector dimensionality and finding an optimal combination of variables in a smaller set. Neuroimaging data are heavily impacted by noise. In order to avoid modelling noise, less significant components produced by PCA are excluded from the feature set based on the assumption that these components tend to account more for noise than for meaningful information. To reduce dimensionality, we consider percentages of total energy which is obtained from cumulative energy vector. As the percentage of energy is reduced, the number of coefficients required also drastically reduces, and accordingly the candidate feature vector size is reduced for classification.


                        Figs. 4 and 5
                        
                         present the cumulative energy as a function of the number of components used for ADNI and “Bordeaux-3City” signatures. For the ADNI subset, the size of signature is equal to 1800 (300*3*2) with 300 is the optimal codebook size while the size of features for the “Bordeaux-3City” data as 100*3*2=600 with 100 is the optimal codebook size. Therefore, the signature size was reduced respectively to 278 and 32 for ADNI and “Bordeaux-3City” datasets by keeping 95% of energy. Here, using PCA dramatically enables us to reduce the input data dimension for SVM for a better and effective classification. In the following subsection, we will present the classification framework by SVM.

Several machine-learning approaches have gained attention in analyzing MR images. Support vector machines classifiers (SVMs) have shown to improve detection and differentiation of Alzheimer's disease classification methods [3,17,14]. SVM separates a given set of training data of instance label pairs (x
                           
                              i
                           , y
                           
                              i
                           ), i
                           =1, …, l, where x
                           
                              i
                           
                           ∈
                           R
                           
                              n
                            and y
                           ∈{1, −1} by maximizing the distances to the hyper plane that separates the two classes. For more details on SVMs, we refer the reader to [8,45]. In this paper the libSVM package
                              5
                           
                           
                              5
                              
                                 http://www.csie.ntu.edu.tw/~cjlin/libsvm/.
                            was used for the classification. Different kernels were applied, we used linear, sigmoid and radial basis functions (RBF) kernels. Note that typically an SVM requires a fixed length vector that characterizes globally the subject to be classified. This is the case in our method: due to the BoVW representation, a subject brain is encoded by a set of quantized local features.

SVM searches to find the optimal hyperplane that best separates the positive and negatives training samples. The optimization problem to resolve, in the case of the so-called “soft margin” classification, is the following:


                           
                              
                                 (7)
                                 
                                    
                                       
                                          
                                             minimize
                                          
                                          
                                             
                                                w
                                                ,
                                                ξ
                                             
                                             
                                                1
                                                2
                                             
                                             ∥
                                             w
                                             
                                                ∥
                                                2
                                             
                                             +
                                             
                                                
                                                   C
                                                   n
                                                
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                n
                                             
                                             
                                                ξ
                                                i
                                             
                                          
                                       
                                       
                                          
                                             subject to
                                          
                                          
                                             
                                                y
                                                i
                                             
                                             (
                                             
                                                w
                                                T
                                             
                                             
                                                x
                                                i
                                             
                                             +
                                             b
                                             )
                                             ≥
                                             1
                                             −
                                             
                                                ξ
                                                i
                                             
                                             ,
                                             
                                                ξ
                                                i
                                             
                                             ≥
                                             0
                                          
                                       
                                    
                                 
                              
                           
                        

The ξ
                           
                              i
                            are the so-called slack variables relaxing class-separators constraints and C is a cost parameter that controls the trade-off between allowing training errors and forcing rigid margins. The kernel function may transform the data into a higher dimensional space to make the separation possible. In this paper, several kernels are tested:
                              
                                 •
                                 Linear kernel: 
                                       γ
                                       
                                          u
                                          T
                                       
                                       *
                                       v
                                    , γ
                                    =1

Radial basis function: 
                                       exp
                                       (
                                       −
                                       γ
                                       *
                                       |
                                       u
                                       −
                                       v
                                       
                                          |
                                          2
                                       
                                       )
                                    
                                 

Sigmoid: 
                                       
                                          tanh
                                          (
                                          γ
                                          *
                                          
                                             u
                                             T
                                          
                                          *
                                          v
                                          +
                                          r
                                          )
                                       
                                    
                                 

The value of C and γ are exponentially varied (C
                           =2e
                           −6, 2e
                           3, …, 2e
                           14
                           ;
                           γ
                           =2e
                           −15, ..., 2e
                           10).

Thus, the grid search has built dozens of SVM models with various parameter settings, and optimal parameters relatively to the training data were selected. Fig. 6
                            illustrates an example of the results (optimal parameters to separate between AD and MCI groups using a visual vocabulary size of 300 (Fig. 10).

We computed overall classification accuracy, sensitivity, and specificity to evaluate classifier performance.
                              
                                 •
                                 
                                    
                                       Accuracy
                                       =
                                       
                                          
                                             (
                                             TP
                                             +
                                             TN
                                             )
                                          
                                          
                                             (
                                             TP
                                             +
                                             TN
                                             +
                                             FN
                                             +
                                             FP
                                             )
                                          
                                       
                                    
                                 


                                    
                                       Sensitivity
                                       =
                                       
                                          TP
                                          
                                             (
                                             TP
                                             +
                                             FN
                                             )
                                          
                                       
                                    
                                 


                                    
                                       Specificity
                                       =
                                       
                                          TN
                                          
                                             (
                                             TN
                                             +
                                             FP
                                             )
                                          
                                       
                                    
                                 


                                    BAC
                                    =0.5*(Sensitivity
                                    +
                                    Specificity)

@&#RESULTS@&#

Pattern classification with SVM was applied separately in each of two groups (NC vs AD, NC vs MCI and MCI vs AD). We used 10-fold cross validation to evaluate classification performance. This approach has become increasingly popular in neuroimaging. Cross-validation is primarily a way of measuring the predictive performance of a model. Therefore, the original sample set was randomly divided into k folds. Then, one fold was used as test and the remaining k
                     −1 folds were used as training data. We repeated the 10-fold cross-validation 50 times for a more general performance estimation of the classifier. Each time the 10 randomly selected folds were generated and the final result is the average accuracy, sensitivity and specificity of the 50 experiments. Tables 3–5
                     
                     
                      summarize the averaged results. We reported the 95% confidence interval of accuracy, sensitivity and specificity. We tested classification methods on Hpc features alone and then on Hpc and PCC features combined together.

Experiments were conducted first on the ADNI scans and then on the structural MRI data from the “Bordeaux-3City” dataset (Table 6
                     ). It should be noted that metric values presented in Tables 3 and 4 as well as confidence interval's boundaries are rounded to the nearest decimal number using the Gaussian rounding method.

When comparing performance of classification methods, we select the best results according to the BAC metric. Comparing AD with normal controls on the ADNI dataset, the best results achieved with hippocampus ROI alone are 80.63% accuracy, 81.93% specificity and 78.54% sensitivity. The best results achieved with early fusion of hippocampus and PCC features are better. Namely, we obtain an increase of 3.14% in accuracy, 6.27% in specificity and 0.55% in sensitivity. In both cases, results have been achieved with an RBF kernel. For the “Bordeaux-3City” dataset (see Table 6), the performance improvements when using the fusion of ROIs features are even stronger. Indeed, the reported increase in all metrics is more than 11% (Figs. 7 and 8
                        
                        ).

We also classified NC vs MCI subjects of the ADNI subset using hippocampus and PCC visual features. When using the proposed fusion method, the accuracy increases by 5.49%. Specificity and sensitivity are respectively 1.4% and 10.79% higher (Fig. 9
                        ).

Comparing AD with MCI on the ADNI subset, the use of combined visual features extracted from two ROIs increases accuracy by 1.06% specificity by 2% and sensitivity by 7% (Fig. 10
                        ). We note that when the MCI category is considered, the fusion of visual features derived from both Hpc and PCC regions gives strong increase in reported results. Heterogeneity of MCI class accounts for such results. In fact, the MCI is a transition state between the normal and Alzheimer state and structural changes on hippocampus are not yet clearly pronounced. We can clearly conclude that the fusion of both ROIs features outperforms the use of Hpc features alone. It is noteworthy that we made higher improvements in the more challenged and important tasks: classifying MCI vs AD and MCI vs NC for early diagnosis and treatment.

To further evaluate our method, we compare the achieved results with those obtained when extracting features from the whole brain images. Performance comparison of the three classifications: (i) classification with whole brain features, (ii) hippocampus features and (iii) the combined signature of both PCC and hippocampus ROIs, are presented in figures below. Whole brain atrophy description discriminates AD from NC with an accuracy of 82.4% a specificity of 84.85% and a sensitivity of 79.09%. These figures are close to results achieved when using the hippocampus ROI only but they are lower than those obtained using the fusion schemes. However, it should be noted that extracting features from the whole brain scan is space-time consuming since we extract a huge number of features from all slices and all the image. For MCI vs NC and MCI vs AD classification problems, we reported respectively, 55.46% and 64.97% accuracies, 63.39% and 76.93% specificities and 42.39% and 26.99% sensitivities. Here, the whole brain scheme gives low sensitivity values which means that it fails in discriminating persons with AD or MCI from NC. Therefore, combined PCC and hippocampus features proved to be more discriminative than whole brain features especially in the NC vs MCI and AD vs MCI cases. Hence, our proposed ROIs method performed more accurately than the whole-brain classification. The use of the domain knowledge by selecting ROIs involved in the disease makes the created vocabularies more region-specific and thus makes the signature more disease-specific.

To further validate the effectiveness of fusion scheme, we also assessed the statistical significance of differences between values of accuracy, sensitivity and specificity obtained when using Hpc alone vs the fusion of Hpc with PCC. Paired Student's t-tests were conducted using the classification measures values corresponding to each of cross validation runs, with the null hypothesis being no improvement in performance when we use the two ROIs fusion. The tests were performed with the results obtained with an RBF kernel.

We found that p-value<0.001 for all binary classification tasks (AD vs NC, MCI vs NC and AD vs MCI) (see Table 7
                        ). This means that we can confidently reject the null hypothesis and declare that adding the PCC features has shown a statistically significant improvement in the experiment compared to the use of hippocampus features alone. This suggests that integrating structural features from both hippocampus and PCC offers optimal results for AD subjects classification.

Our platform is implemented in C/C++. The average computation time for each step of the proposed method is reported in Table 8
                        . Tests are done using a 2.4GHz Intel Core i7 with 8 GO memory. In our experiments the average spread for one query is following: 2.5min for preprocessing, 0.8min for features computation and 1.3min for classification. The signature generation step using the BoVW approach depends on the size of vocabulary (K
                        =300 in our case). Less time is taken in classifying a new subject because of the reduced dimensionality of features (From (300*2*3) to 278 using the PCA technique). It is to note that computational time depends on the number of scans, software and used hardware. Also, only 617 features are densely extracted from each scan (all slices from three projections) which explains the low feature extraction time.

@&#DISCUSSION@&#

In this paper, we proposed a visual feature-based framework to provide clinical researchers with semantic similarity and then help for AD diagnosis. We used visual similarity between baseline MRI to classify three groups of subjects (AD, NC and MCI). The approach was applied to the ADNI subjects and to another real cohort (“Bordeaux-3City”). An exact comparison with previous works is complicated since most of the proposed works have used different statistical methods and several image analysis methods on different datasets. In addition, the differences demographic and clinical information of the subjects, the size of used data, severity of disease, duration of disease might account for the discrepancy between the current work and previous works. Furthermore, since the ADNI study is still ongoing, several subjects labeled as MCI will progress in the future to the AD group. In the following, we start by comparing our proposed method with a volumetric method proposed in [59].

We compare our proposed method with a volumetric method proposed in [59]. Hence, we used the same data Yang et al. [59] and we follow the same classification protocol. These data come from the ADNI data and contain 35 AD, 72 NC and 111 MCI. Although the images are not exactly the same, we used the same data partition with a closed demographic characteristic as in [59]. The authors in [59] use the hippocampal volume to distinguish MCI and AD from NC as well as AD from MCI. Our CHFs description of hippocampus performs well in separating AD vs NC. Table 9
                         presents the different results reported in Yang et al. [59] compared to ours.

In fact, we obtained 80.4% accuracy, 82.8% specificity and 74.2% sensitivity compared to respectively 65.5%, 73.3% and 57.8% reported in [59]. For MCI vs NC, we obtained better accuracy and sensitivity but lower specificity. In addition, for the most challenging classification task (AD vs MCI) we obtained much better results with 74.2% accuracy and higher sensitivity and specificity. It should be noted that the hippocampus ROI is extracted in [59] using the Freesurfer software which is time-consuming and depends on preliminary segmentation guided by expert knowledge of the location of the ROI. In this work, we used an automatic atlas-based parcellisation method and we obtained highly efficient classification results compared to the time-consuming manual segmentation executed by human experts, or by a specific software.

Furthermore, volumetric analysis only assesses global changes of the ROI. On the other hand, content-based analysis methods can unveil local atrophy of the ROI and then give more information about the disease. In addition, volumetric methods are often applied to measuring group differences, their use for classifying individuals is more challenging.

Each individual subject's scan is represented as a collection of discrete features on two characteristic ROIs: hippocampus and PCC. This information was used to discriminate the MCI and AD subjects from normal controls, as well as between the MCI and AD patients. To position our contribution with regard to other features-based approaches, we would cite the work [54]. Here, the authors proposed a features-based morphometry method to analyze the structural local changes of the brain. The method is based on learning a probabilistic model of local SIFT descriptors that reflect group-related anatomical characteristics. Only classification results for AD vs NC were provided in their paper. It was performed on the OASIS dataset. Indeed, SIFT or their approximated version SURF [6] features, are not optimal for MRI with the lack of pronounced high frequency texture and highly contrasted structures.

We used image descriptors better adapted to the MRI in the content-based approach: the CHF features. As shown, the results of CBVIR by similarity-search approach (Ben Ahmed et al. [7]), outperformed conventional SIFT descriptors on both ADNI and ``Bordeaux-3City'' datasets. That is why we choose to use them with a machine learning approach based on the SVM classifiers to classify patients. CHFs have a good property of capturing smooth contrasts which are characteristic of the structural brain MRI. Furthermore, these features are computed on patches inside the ROI or selected on the whole brain. They convey local structural information of image signal.

All combinations for patients classification were considered on ADNI database: AD vs NC, NC vs MCI and AD vs MCI. The MCI category is the most difficult to recognize, as the structural changes in the characteristic brain regions are very unequal. Nevertheless, AD research has shifted to MCI in recent years, in the hope of tracking AD progression and resisting it, before individual progress to AD. We showed that the use of two characteristic regions (hippocampus and PCC) systematically outperforms the classification results obtained when only the hippocampus is used. According to Table 4, the BAC quality metric is increased by at least 5% when classifying groups with MCI. The similarity between MCI and AD categories was supported by the complementary description of PCC. Furthermore, compared to other works that used the hippocampus ROI only [15], where the authors proposed an individual classification based on the hippocampus volume, our method performs better. Indeed, [15] achieved a 73% of correct classification rate between MCI patients and AD, while we achieved 74.2% accuracy at least for this case. Even if two ROIs were used in previous research, such as hippocampus and entorhinal cortex [22], our approach performs better. The most likely reason for this is that the hippocampus region is less spatially correlated with PCC than the entorhinal cortex, which makes highest discriminative patterns for AD diagnostics. Indeed, in [22], the cross validation accuracy of voxel-based approach for the classification of AD vs MCI is 74,3%. In our case applied to two ROIs together, it is 76.5% on the ADNI dataset.

If we compare our approach with two ROIs: hippocampus and PCC, with the approach of [60], which uses the gray matter maps, we can state the following. In their work [60], extract volumetric features from the 93 ROIs in the gray matter maps and classify them using SVM (as this is the case of our classification framework). The accuracies of the proposed methods on classifying NC vs MCI are 72% along with 78.5% sensitivity and 59.5% specificity. Our figures on ADNI dataset are (see Table 4) 69.45% accuracy, 74.8% specificity and 62.52% sensitivity respectively. Therefore, based on this analysis, we can conclude that the choice of hippocampus and PCC is better for the classification problem we have addressed.

To compare with a voxel-based approach, we select the work of [34]. In this work, the authors used temporal lobe and hippocampus regions features analysis. For MCI vs NC classification, the authors obtained lower accuracies than us in case of the whole brain 63%, compared to 69.45% achieved by our proposed approach. Their results with ROI are indeed better (71%). Nevertheless, the ROI approach requires a segmentation step which is time-consuming (using an automated software) and for practical diagnostics we need a system that gives a quick decision. The draw-back of their approach is also in the fact that the authors use the whole ROI/brain voxels and generate a huge size feature vector. Thus the approach suffers from curse of dimensionality as size of data used was small. Furthermore, finer classification performances (specificity, sensitivity) are not available in their paper. The AD group patients in their work are with 16.7 mean MMSE (more severe Alzheimer's disease) which is easier to detect.

The advantage of our approach which performs on ROIs consists in the fact, that features-based description compensates inaccuracies of selection of the ROIs with an atlas based approach. It does not require any segmentation of ROI, but only a rough selection as ensured by AAL. The AAL can model different structures with similar intensity values. In contrast, accurate manual segmentation techniques are time-consuming and present delimitation imprecision. Other proposed techniques are computationally expensive (run-time of hours to days) [13] or require expert neuroanatomical knowledge [17]. Therefore, they are not always practical in a clinical setting. Using a simple atlas based method, we built a fast framework to classify AD subjects. Although AAL was not designed for studying patients with AD, through the use of local CHF descriptors, we can adequately capture the pathological structure (e.g. shrunken hippocampus) vs a normal one thanks to different signal types captured by CHFs inside the ROI. The main advantage of our method is its ability to capture atrophy patterns of progressive neurological disorders and then overcome the drawbacks of the Atlas based segmentation methods.

Our platform is implemented in C/C++. The average diagnosis time per scan (including the preprocessing step done with matlab) is about 6.4min and 11s. Indeed, the results are obtained with a lower number of features. Also, the proposed framework is able to classify new subjects based on a single time point contrary to longitudinal studies.

@&#CONCLUSION@&#

In fine, in this paper, we introduced a new approach to automatically classify subjects in epidemiological studies of AD using structural MRI. The approach does not require a precise segmentation of ROIs, and belongs to the features-based family of methods. The features we used, circular harmonics functions, convey 2D information in each scan. This information was used to effectively discriminate the MCI and AD patients from normal controls, as well as between the MCI and AD patients. Compared to our previous works, the method used two characteristic ROIs: hippocampus area and posterior cingulate cortex. Despite difficulties in visual inspection of the latter in the diagnosis process, the fusion of features from both regions improves classification results.

Unlike the method requiring precise segmentation of ROIs our approach is less time-consuming, computer-based and does not require the intervention of an expert during the classification phase. These first results are promising and indicate that the combination of hippocampus and PCC atrophy captured by specific CHF features gives a good indicator to the diagnostics. Obviously, as in any approach, there is still a place for improvement. Our work is in progress. In its perspectives we consider the use of other MRI modalities and visual descriptors adapted to MRI characteristics in order to improve the classification.

@&#ACKNOWLEDGEMENTS@&#

Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health Grant U01 AG024904). ADNI is funded by the National Institute on Aging, The National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: Alzheimers Association; Alzheimers Drug Discovery Foundation; BioClinica, Inc.; Biogen Idec Inc.; Bristol-Myers Squibb Company; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; F. Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; GE Healthcare; Innogenetics, N.V.; IXICO Ltd.; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Medpace, Inc.; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Synarc Inc.; and Takeda Pharmaceutical Company. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the study is coordinated by the Alzheimer's Disease Cooperative Study at the University of California, San Diego. ADNI data are disseminated by the Laboratory for Neuro Imaging at the University of California, Los Angeles.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An automated confirmatory system for analysis of mammograms

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This paper presents an integrated system for the automatic analysis of mammograms to assist radiologists in confirming their diagnosis in mammography screening.


                        
                        
                           
                           The proposed system consists of four off-line stages:
                                 
                                    
                                    Image pre-processing and segmentation


                                 
                                 
                                    
                                    Feature extraction


                                 
                                 
                                    
                                    Selection of fundamental features using Rough Set theory


                                 
                                 
                                    
                                    Training of an Artificial Neural Network.


                                 
                              
                           


                        
                        
                           
                           Once the system is trained and tuned, is ready for its on-line use. Here the system is successfully tested on two independent databases.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Computer-aided diagnosis

Mammogram

Breast-cancer

Texture-feature

Rough-set theory

Artificial Neural Networks

@&#ABSTRACT@&#


               
               
                  This paper presents an integrated system for the automatic analysis of mammograms to assist radiologists in confirming their diagnosis in mammography screening. The proposed automated confirmatory system (ACS) can process a digitalized mammogram online, and generates a high quality filtered segmentation of an image for biological interpretation and a texture-feature based diagnosis. We use a serial of image pre-processing and segmentation techniques, including 2D median filtering, seeded region growing (SRG) algorithm, image contrast enhancement, to remove noise, delete radiopaque artifacts and eliminate the projection of the pectoral muscle from a digitalized mammogram. We also develop an entire-image texture-feature based classification method, by combining a Rough-set approach to extract five fundamental texture features from images, and then an Artificial Neural Network technique to classify a mammogram as: normal; indicating the presence of a benign lump; or representing a malignant tumor. Here, 222 random images from the Mammographic Image Analysis Society (MIAS) database are used for the offline ACS training. Once the system is tuned and trained, it is ready for the automated use for the analysis and diagnosis of new mammograms. To test the trained system, a separate set of 100 random images from the MIAS and another set of 100 random images from the independent BancoWeb database are selected. The proposed ACS is shown to be successful in confirming diagnosis of mammograms from the two independent databases.
               
            

@&#INTRODUCTION@&#

Screening mammography is an effective tool for early detection of breast cancer [1]. However, the accuracy of diagnosis depends on both the quality of the mammographic images and the ability of the radiologist to interpret those images [2]. Currently, some radiologists misdiagnose mammograms as mentioned by some recent media reports. For example, in 2013, radiologists’ errors in a Toronto hospital contributed to delays in diagnosing and treating eleven patients, the death of two of them, and the subsequent reassessment of 3537 CT scans and mammograms [3]. It is estimated that radiologists fail to detect 10–30% of cancer cases [4,5].

With the wide availability of digital images, computer-aided diagnosis (CAD) has emerged as a tool to assist radiologists in rapidly detecting, locating, and characterizing suspicious breast lesions, estimating their probability of malignancy, and quantifying their cancer risk [2,6–8]. Such a CAD software can be used by radiologists as a “second opinion” or a confirmatory tool of diagnostic decision. However, the development of CAD in mammography is still in an early stage, and most of the suggested approaches of CAD systems follow the two-step scheme of pixel-level detection and region-level classification. For example, Kegelmeyer et al. [9] used the standard deviation of a local edge orientation histogram to detect spiculated masses on mammograms in pixel-level, i.e., the lump of tissue with surface spikes or points indicating a high likelihood of malignant tumor. Kopans [10] characterized a spiculated mass by lines radiating from the margins of a mass. Kobatake et al. [11] modeled suspicious objects as rounded convex regions by measuring the average convergence of the gradient over the region, which is a region-level classification. Liu et al. [12] developed a multi-resolution algorithm for the detection of spiculated masses using the discrete wavelet transform, which also is pixel-level detection. Similar works were reported by Zouras et al. [13], Petrick et al. [14], Te Brake et al. [15], Tourassi et al. [16], and Madabhushi et al. [17]. CAD software, based on these methods and others, is used in about 75% of screening mammography in USA, but it is of very little help in detecting breast cancer in practice [18]. This is mainly because classifying suspicious regions and selecting image features on the mammogram are extremely difficult and complex, due to the similarity of the image attributes of a malignant tumor and those of clusters of micro-calcification, and the superposition of normal tissue over tumors [1]. Moreover, pixel level image features are difficult to be biologically interpreted by radiologists [19].

Pattern recognition has also been introduced to deal with the complex classification and feature selection problems associated with CAD. The most commonly utilized algorithms are Artificial Neural Networks, Bayesian classifier, genetic algorithms, decision trees, and fuzzy-set theory [20–23]. For example, Li et al. [21] used a fuzzy binary decision tree to classify suspicious regions. The Rough set theory has been successfully applied to region-level classification of medical images [24–27]. The Rough set approach normally deals with uncertainty and vagueness in data mining by analyzing the facts that are hidden in data, and finds a minimal knowledge representation without additional information. For example, Hassanien and Slezak [27] applied directly the Rough-set approach for attribute reduction and rule generation on the classification of breast cancer images, where “attribute” refers to cluster-based image properties in the regions of interest (ROI). However, this ROI classification may not capture completely the information of an entire image [19,28]. That is, a Rough set approach is applied directly to some particular regions of the images to obtain some relevant features.

In this paper, we propose a hybrid approach that combines image processing techniques, pattern-recognition methods, and computational intelligence techniques, which produce a high quality filtered segmentation of image for biological interpretation and a texture-feature based diagnosis. Our approach relies on the extraction of texture features from mammograms that best describe their characteristics. Next, some fundamental features are selected using Rough-set theory. Afterwards, the fundamental features are used to train an Artificial Neural Network that is able to classify these mammograms. That is, in the proposed approach, feature extraction is based on the entire-image, instead of attribute extraction based on particular image clusters of ROI as in [27]. Subsequently, a Rough set approach is used to select some fundamental features. In a final stage these fundamental features are used to train an Artificial Neural Network. The proposed approach leads to an integrated system consisting of three components that are tuned off line, as shown in Fig. 1
                     .

In the first component, a digitalized mammogram, chosen from an available image database is subjected to automated pre-processing and segmentation, to remove noise, delete radiopaque artifacts, and eliminate the projection of the pectoral muscle. The filtered-segmented image is then used for the extraction of 16 texture distinguishing features. In the second component, a Rough-set approach is applied to reduce the number of distinguishing features to the minimal knowledge representation of hidden data to only five fundamental features: energy, inverse difference moment, difference entropy, directionality, and contrast. In the third component, the five fundamental features are used to train an Artificial Neural Network against independently diagnosed images, classifying mammograms as either being normal, indicating the presence of a benign lump, or representing a malignant tumor. Once the system is tuned and trained as above; it is ready for automated use in the analysis and diagnosis of new mammograms online. The proposed automated confirmatory system has been tested on two independent databases.

In Section 2, we present the automated pre-processing and segmentation methods; describe the image feature extraction and selection process; and give an introduction to the Rough-set theory and demonstrate how the application of the Rough-set method reduces the number of redundant features. Additionally, we also present in Section 2, the Artificial Neural Networks’ training necessary for performing an efficient mammogram diagnosis. In Section 3, we present the results of experiments and related discussion. Section 4 provides conclusions on the proposed methodology.

@&#METHODOLOGY@&#

The proposed Automatic Confirmatory System methodology is based on several off-line stages: Image Preprocessing and Segmentation; Image Texture Feature Extraction; Feature Selection using Rough-Set Reduction; and Artificial Neural Network training for mammogram classification (Fig. 1). Each one of these stages is described in the following sections.

Image noise (such as horizontal/vertical straight lines introduced by scanning sensors), radiopaque artifacts (such as marks, wedges, labels, etc.), and projections of the pectoral muscle can affect the accuracy of mammography diagnosis. They are removed by image preprocessing and segmentation [29,30]. Image pre-processing aims at removing image noise, while the goal of image segmentation is to delete the artifact suppressions and eliminate the projection of pectoral muscle in a mammogram.

In order to illustrate the image preprocessing and segmentation processes, a digitalized mammogram with a vertical line noise (shown in Fig. 2(a)) is chosen from the image database of the Mammographic Image Analysis Society (MIAS) [31]. This image database consists of 322 digitalized mammograms with Medio Lateral Oblique (MLO) view; each image is in a Portable Gray Map (PGM) format, with 8-bit gray scale of 1024×1024pixels. The intensity range of a pixel is from 0 to 255, in which a value of 0 is completely black, and a pixel with a value of 255 is completely white.

The two-dimensional (2D) median filtering approach was applied to remove noise in a mammogram. This approach replaces each pixel value in a mammogram by the median of the 3×3 neighborhood pixels, except the edge pixel of the image for which the values are changed into zeros (empty). These zero pixel values do not affect the detection of breast cancer, because breast regions are always located at the central area of the image. Fig. 2(b) demonstrates the effect of the 2D median filtering approach, showing its ability to remove the vertical line noise from a digitalized mammogram.

Radiopaque artifacts, in the form of identification labels, radiopaque markers, and wedges such as the marker in the top left of Fig. 2, are removed using a series of morphological methods. The process is illustrated in Fig. 3
                           . The noise filtered gray scale image is first converted into a binary [0,1] image (shown in Fig. 3(b)). The binary image is then sequentially subjected to the following operations: first dilation, hole-filling, erosion, second dilation, and opening (shown in Fig. 3(c)–(g)). Then, the radiopaque artifacts are removed from the original mammogram, and the pre-processed image is shown in Fig. 3(h). It is important to mention that the above operations are conducted automatically and efficiently for all mammograms.

The presence of projection of the pectoral muscle is removed using the seeded region growing (SRG) segmentation algorithm described by Adams and Bischof [32]. It starts with a seed mark, which iteratively increases in size until the marked area is filled up. Prior to applying this algorithm, the contrast of the image is enhanced (as shown in Fig. 3(i)) to increase the pixel-value difference between the muscle area and the breast region. Knowing that, the pectoral muscle area contains the brightest pixels and always lies on the left or right top corner of a MLO mammogram, depending on the view of the image. As such, a pixel in the upper portion of the image with intensity value higher than a threshold pixel value is designated as the seed. The region is then iteratively grown from the allocated pixels (the seed is the first allocated pixel) to their adjacent pixels until a termination criterion is met. The criterion is defined as the intensity difference between the allocated region mean and a new unallocated pixel which is larger than a certain (threshold) value. The region growing is terminated at the boarder of the pectoral muscle where the intensity difference is larger than a certain value (shown in Fig. 3(j)). The resulting image is then segmented by removing the seeded region (shown in Fig. 3(k)) and producing the breast profile in Fig. 3(l). The filtered-segmented and contrast-enhanced images alone, without further processing, can aid the radiologist in biological interpretation, without being burdened with noise and artifacts.

The filtered-segmented mammogram, such as that shown in Fig. 3(l), has feature information solely reflecting breast tissue that can be used for detecting breast cancer. An image feature is defined here as a numerical value that encodes a discriminatory property. One example of a primary feature is one that measures tissue texture coarseness, which can be used to distinguish a tumor from a healthy tissue in an image. These texture features of an image can be numerically measured using the spatial distribution of the gray levels in a neighborhood.

Haralick et al. [33] introduced a method to calculate second-order statistical parameters related to texture features based on a pre-computation of the gray-level co-occurrence matrix (GLCM). This matrix measures the relationships between two neighboring pixels at a distance d (usually set as d
                           =1) and distance θ (usually set as θ
                           =0°, 45°, 90° and 135°). Once this matrix is calculated for an image, 14 Haralick texture features can be estimated, see Table 1
                           . Tamura et al. [34] defined three important features: “directionality,” “coarseness,” and “contrast,” which successfully coincide with the human visual perception of texture. The directionality feature is used to statistically measure the distribution of gradient directions of an image. If two images differ only in the direction, they will have the same value of directionality. The coarseness feature relates the distances of notable spatial variations of gray levels, which represent the size of the primitive elements forming the texture. The contrast feature is also one of Haralick texture features described in Table 1. Applying both Tamura and Haralick textures, 16 features can be extracted for each image.

In this section, first we provide a brief introduction to Rough Set Theory. Afterwards, we describe the feature reduction in detail.

Most of the texture features are highly correlated [15], leading to redundant features that do not aid in representing image characteristics. To select the most discriminating features, some algorithms have been introduced, such as Artificial Neural Networks, Bayesian classifiers, genetic algorithms, decision trees, and fuzzy theory [20]. However, Rough-set theory [35] normally has an advantageous ability to deal with both uncertainty and vagueness, because it focuses on the underlying facts hidden in data and can find a minimal knowledge representation. In addition, Rough-set theory does not need additional information, such as the probability distribution in statistical techniques or grade thresholds of membership in fuzzy-set theory [36].

In the Rough-set theory, feature values of sample objects are collected in a table called the information table. Rows of such table correspond to objects, and columns correspond to object attributes. The attribute columns can further be classified into condition attribute columns and decision attribute columns. The Rough-set method can then be preformed based on the following properties [35,37]:
                              
                                 (1)
                                 
                                    Indiscernibility: defines the relationship between two objects or more, where all the values are identical in relation to a subset of considered attributes. It is an equivalence relation, where all identical objects of a set are considered as elementary [37].


                                    Approximation: used to deal with inconsistency. A Rough-set approximates common sets using a pair of sets, named the lower and upper approximations of the set. The lower approximation contains all objects which are certainly classified, while the upper approximation contains all the objects which can be probably classified. The roughness of a set can be quantitatively measured by the ratio of the cardinalities of the lower and upper approximations. Roughness is a representation of the accuracy of an approximation set. For example, if there is a small similarity and high features variability in the neighborhood, the value of roughness would tend to be 0.


                                    Reduction: defined as the minimum condition attribute sets, which do not contain redundant condition attributes and ensure correct decision attributes. Reduction is achieved by comparing the indiscernibility relations and values of roughness generated by sets of attributes.

In order to select the most discriminating features from the 16 texture features using the Rough-set reduction algorithm, an information table was built for collected digitalized mammograms. In this information table, each mammogram index refers to a row of information in the table, while the 16 texture features of mammograms correspond to 16 condition attribute columns and diagnosis results of mammograms correspond to a decision attribute column. We used MIAS image database [31], which consists of 322 digitalized mammograms, in which each mammogram was independently identified as one of three states: normal, containing a benign lump, or having a malignant tumor. Therefore, the information table has 322 rows of mammograms with three decision attributes. Table 2
                            demonstrates partial contents of the information table, with the 16 textural features and associated diagnosis decision.

The reduction program based on the Rough-set theory was then applied on the information table. It started with an empty set and added attributes in turn. These attributes resulted in the greatest increase in the roughest dependency metric, until the maximum possible value for the dataset was produced. The results of this fundamental feature selection showed that only five features are needed to describe each mammogram. These are: energy, inverse difference moment, difference entropy, directionality, and contrast. Table 3
                            illustrates the partial results of feature selection.

The provided five image features, without further processing or automation, provide radiologists with numerical values that can further help in arriving at correct diagnosis.

In contrast to precise sets, the Rough-sets method, though a powerful tool to select the most discriminating features in an existing database, it cannot certainly classify a newly supplied mammogram because of its approximate nature. In order to do an efficient classification we utilize an Artificial Neural Network approach.

Here, we choose the feed-forward back-propagation Artificial Neural Network (ANN) technique to aid in building an automatically confirmatory system for mammograms, since it is a very efficient and successful as a pattern classification tool [38]. It is well known that the implementation of an ANN technique consists of two main stages: the ANN training and the ANN testing/verification. That is, once an ANN is trained with sufficient data and tested, it can be used as a “black box” tool; here, it is used for classification. The utilized ANN is devised as a three-layer architecture. A five-dimensional input has been designated for the first layer, using the five fundamental features, as described in Table 3. For the second layer (hidden layer), ten hidden nodes were designed with reference to some successful experiments, i.e. Lippmann [39] obtained good results by 8-hidden nodes for an ANNs of 2D input and 200 input training patterns set. Finally, a three-class output was used for the third layer, namely the available pre-determined diagnosis decision of “normal,” indicating the presence of a benign lump, or representing a malignant tumor.

The ANN training was performed on a set of 222 images that were randomly obtained from MIAS [31]. For each training image, the pre-processed and segmented were conducted and five fundamental features were extracted. Therefore, the input was a 5×222 matrix, and the target output vector (decision attributes) was the radiologist's interpretation of each of the 222 images.

As previously mentioned, normally after the ANN is trained it goes through a testing/verification stage. Here this ANN testing/verification become in fact a testing of the entire automated confirmatory system.

@&#RESULTS AND DISCUSSION@&#

The automated confirmatory system (ACS) described above is first tested using images from a subset of the MIAS database [31] that was not used in the ANN training. Subsequently, the system was applied to mammograms images from the completely different and independent BancoWeb database [40].

After the ANN training, 100 images of a subset of MIAS not previously used for training were tested, generating 100 numerical outputs. Fig. 4
                         illustrates a frequency distribution of these 100 continuous values, to demonstrate how often they fall into different sub-intervals (the length of each sub-interval was 0.25). For example, about 28% of outputs fell into sub-interval [2.25:2.5]. The frequency curve of the points joined by a smooth curve showed three curve distributions, with mean values of 1.3, 2.3 and 3 corresponding to normal, malignant, and benign tumors. Using 1.5 and 2.5 as separating values between these three distributions, we classified the numerical output of each test into the following three classes: <1.5 as normal, >2.5 as a malignant tumor, and between 1.5 and 2.5 for a benign tumor.

The 100 testing results are then compared with their radiologist interpretations to check the diagnosis accuracy of the ANN. These 100 results were classified into one of four categories: (1) true positive (TP): a correct diagnosis of either a benign lump or malignant tumor; (2) true negative (TN): a correct diagnosis of a normal condition; (3) false positive (FP): a wrong identification, either a diagnosis of malignant tumor based on the presence of a benign lump or a normal condition, or a diagnosis of benign lump based on the presence of a normal condition; and (4) false negative (FN): a wrong identification, either a diagnosis of normal condition based on the presence of a benign lump or a malignant tumor, or a diagnosis of benign lump based on the presence of a malignant tumor. We also measure the sensitivity, specificity, and accuracy of the examination results. The sensitivity measures the proportion of actual positive cases which are correctly identified. The specificity measures the proportion of negative cases which are correctly identified.


                        Table 4
                         shows statistical measurements of three testing results. In this table, Test 1 (an actual testing of our proposed ACS) is the test of 100 mammograms that are randomly selected from the MIAS database, and using the five features determined by the Rough-set reduction process as inputs. Test 1 demonstrates three false positive diagnosis results and one false negative diagnosis results. The accuracy of this test is 96%.

To demonstrate the advantage of the Rough-set algorithm; a comparison test was performed using all the 16 texture features (from Section 2.2, without using the Rough Set reduction process) as inputs in the ANN process. The Test 2 in Table 4 shows the results of this comparison test, where the 100 mammograms were randomly selected from the MIAS database but using 16 input features. It demonstrates four false positive diagnosis results and four false negative diagnosis results. The accuracy of this test is 92%. This indicates that the 16 texture features are correlated, resulting in lower diagnosis accuracy, while using Rough-set algorithm reduces the number of feature inputs and increases the diagnosis accuracy of the ANN.


                        Fig. 5
                         illustrates, as a particular example, three mammograms (diagnosed as normal, benign and malignant tumors) from the testing subset of the MIAS database after the removal of noise, deleting radiopaque artifacts, and eliminating the projection of the pectoral muscle. Table 5
                         demonstrates the five texture features extracted from the mammograms shown in Fig. 5. These features led to ACS values that enable correct diagnosis as the last three columns of the showed.

Furthermore, as shown in Table 4, in Test 3, also 100 cases from the independent BancoWeb database have been considered. The details are discussed next.

Once the proposed ACS is tuned as above, it is ready for its application on any independent database. Here the BancoWeb database [40] is considered, which contained 1704 (up to 2048×2833pixel) mammograms from several hospitals in Brazil using different types of X-ray equipments and scanners. Each image was associated with patient information, exams data (when available), and radiologist report (when available). These images were categorized into as either “No Finding” or “Finding”, which means normal and abnormal mammograms respectively. Therefore, we used the developed automated confirmatory system to confirm the provided results and determine the severity of abnormal mammograms of the BancoWeb, based on the ANN that was trained by the images of MIAS.

The automated confirmatory system was applied on 100 mammograms randomly selected from the BancoWeb database. The Test 3 in Table 4 illustrates the test results for these 100 images with using 5 input features. It demonstrates five false positive diagnosis results and three false negative diagnosis results. The accuracy of this test is 92%. The developed automated confirmatory system not only give a good accuracy for detecting the mammograms into either “Normal” or “Abnormal” but also further provides diagnosis suggestion for the abnormal images as either “Benign” or “Malignant”.


                        Fig. 6
                         illustrates as an example an original image from the BancoWeb database, along with the corresponding filtered-segmented and contrast-enhanced images. Table 6
                         lists the original information of the tested mammograms and the test results obtained from the developed automated confirmatory system. The table shows a case value of 2.616, which according to the distributions of Fig. 4 indicates a malignant abnormality that is in agreement with the physician's labeling of this mammogram as abnormal (Calcification).

@&#CONCLUSIONS@&#

An ACS has been devised for detecting breast cancer in mammograms. Its output provides a diagnosis that can serve to radiologists as a “second opinion”. The system is suitable for rapid processing of a large number of mammograms. The system relies on five fundamental textural features, which are determined using a Rough Set theory approach for feature reduction. The fundamental characteristics of a mammogram are: energy, inverse difference moment, difference entropy, directionality, and contrast. These fundamental features are then used off-line to train an Artificial Neural Network to classify mammograms as: normal, benign, or malignant tumor. Even without automation, the system provides clear filtered-segmented and contrast-enhanced images; in addition to five distinct numerical features, that should aid radiologists in arriving at more reliable diagnosis. The proposed automated confirmatory system is tested using images from two databases completely independent of the one used in its development, and is shown to produce diagnosis results that correspond quite well with those noted by radiologists.

@&#ACKNOWLEDGEMENT@&#

The paper research has been supported by two grants (Nos: 4116-2013 and 155147-2013) from the Natural Sciences and Engineering Research Council of Canada (NSERC).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#The effect of volumetric (3D) tactile symbols within inclusive tactile maps

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We compare two tactile maps, one of them includes Volumetric (3D) tactile symbols.


                        
                        
                           
                           Improving the interaction between users and tactile maps using 3D symbols together with 2D ones.


                        
                        
                           
                           3D symbols can be located in less time and, generally, cause fewer errors than flat relief symbols-2D.


                        
                        
                           
                           3D printing opens new horizons for the design and production of tactile maps for blind users.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Tactile symbols

Visually impaired

3D printing

@&#ABSTRACT@&#


               
               
                  Point, linear and areal elements, which are two-dimensional and of a graphic nature, are the morphological elements employed when designing tactile maps and symbols for visually impaired users.
                  However, beyond the two-dimensional domain, there is a fourth group of elements – volumetric elements – which mapmakers do not take sufficiently into account when it comes to designing tactile maps and symbols.
                  This study analyses the effect of including volumetric, or 3D, symbols within a tactile map. In order to do so, the researchers compared two tactile maps. One of them uses only two-dimensional elements and is produced using thermoforming, one of the most popular systems in this field, while the other includes volumetric symbols, thus highlighting the possibilities opened up by 3D printing, a new area of production.
                  The results of the study show that including 3D symbols improves the efficiency and autonomous use of these products.
               
            

@&#INTRODUCTION@&#

Tactile maps are a group of resources that show graphic information using relief (Picture 1
                     ). Tactile symbols are included within this type of resources and are normally used with their corresponding legends. These products help persons with visual impairment to understand features of the environment around them through the sense of touch and are often used, for instance, to communicate and teach geography or in the acquisition of orientation skills for facilitating mobility through specific environments (Edman, 1992).

According to the literature, there are three types of morphological element used in the design of tactile maps (Picture 2
                     ), tactual symbols, or any tangible graphic for the visually impaired, namely: point, linear and areal elements (Amick et al., 2002; Correa Silva, 2008; Edman, 1992; Welsh and Blasch, 1980).

However, a fourth category of design elements, volumetric (3D) elements (Wong, 1993), is barely used in the design and production of these types of products. This is partly due to some limitations of the most commonly used production systems (Picture 1): microencapsulation and thermoforming (Perkins, 2002; Rowell and Ungar, 2003b).

In line with this, several notable studies have been conducted to compare these two, or other, methods of production, with varying results. Ungar et al. (2005) or Dacen Nagel and Coulson (1990) suggested that the microencapsulation method was a more appropriate system to produce tactile maps than thermoforming, although other researchers such Pike et al. (1992) obtained similar results in their experiments with children involving both types of systems. Finally, Gardiner and Perkins (2002) noted important advantages of thermoformed over microencapsulated paper maps, among others, because in their studies well-designed thermoformed maps offered consistently better results than microencapsulated ones. One of the main problems of the thermoforming system is the time cost involved in generating a master to produce the map. On the other hand, the microencapsulated system is cheaper than thermoforming if a single copy of the map or a short series of them needs to be produced; its resistance, however, is not enough for continued or critical use due to the known degradation of the swell paper used in their manufacture. In any case, both techniques allow light, flexible and, therefore, portable maps to be produced, for use in real contexts or in indoor situations.

The novelty presented by this work is the study of some possible applications for volumetric elements, basic prisms (Picture 3
                     ), applied as punctual tactile symbols in order to improve the usability of tactile maps. In this case, 3D printing is the technique used to manufacture these symbols since it can produce more complex geometries than traditional methods (Chua et al., 2003).

Through 3D Printing it becomes possible to produce final maps in short series or even rapid master pieces to evaluate the product before launching it. Nowadays, the price is constantly decreasing and the final cost of one piece consumes less time and expense than producing, for example, an industrial master (thermoforming system). Although they are not portable because the tactile maps produced by 3D Printing are rigid, they are durable.

In any case, the use of one system or another to produce a tactile map depends on the aims and the requirements, and any system can be useful depending on the intended purpose of the map.

In this study the researchers have selected the thermoform process to compare it with the 3D Printing system. The decision to choose thermoforming is mainly due to the fact that it offers better control over the height contrast of the elements of the map than in the case of the microencapsulation process; according to Gardiner and Perkins “establishing the relative height of features in multilevel design is an important part” (of the process of designing tactile maps and symbols) (Gardiner and Perkins, 2002). This fact makes it possible to produce more similar conditions between the selected methods in terms of geometry. Microencapsulation, however, does not allow the production of a multilevel of heights within the relief elements on the tactile map. This is why it was not considered in this experiment.

Some of the most important factors to be mentioned for the design and use of these products are:
                           
                              •
                              In general, the lower tactile acuity of the sense of touch, in comparison with the sense of sight (Schiff and Foulke, 1982).

Secondly, the need for verbal assistance from a Mobility Instructor. These devices are normally used in audio guidance to make it easier to understand the tactile stimulus explored.

Thirdly, user familiarity (previous experience) with these products. The ability to read a tactile map depends on the skills, exploration strategies, experience and training of the people using it (Jover et al., 2008). These factors allow blind users to recognize the information offered by a tactile product more accurately and effectively, even in real contexts (Perkins and Gardiner, 2003).

Finally, it is worth noting that using haptic memory is necessary when exploring a tactile map, since blind people explore tactile graphics sequentially. In contrast, visual perception is simultaneous and less time is required to assimilate the same amount of information (Ballesteros, 1993). Thus, simplicity is an important requirement for tactile maps and symbols (Amick et al., 2002; Edman, 1992; Rowell and Ungar, 2003c).

In addition, another factor worth noting is the context of use of the maps. As Blades, Ungar and Spencer demonstrated, tactile maps contribute to the correct construction of a cognitive map of a new area or route, i.e. to the learning of new environments for visually impaired people (Blades et al., 2010). A tactile map can be used in real contexts, although the main advantage for visually impaired persons is that they can explore and learn an unknown area before actually travelling through it. In fact, they prefer to use the maps quietly at home, before undertaking the real route, since in this way they reduce the anxiety caused by the experience of contact with unknown areas (Jacobson, 1998a,b; Rowell and Ungar, 2005). Obviously, they can also use a tactile map before and during the route, although the logical sequence to use a tactile map is, first, to learn the route at home (indoors) with the aid of a Mobility Instructor and then to try to follow the real route with the guidance of the Mobility Instructor several times until the route has been learnt. The time consumed depends on the complexity of the area and the skills and experience of the user, but finally, once the new area or route has been assimilated in accordance with this protocol, the visually impaired user will feel safer following the route or travelling through the area alone.

The symbology of tactile maps has been widely studied taking into account the aspects mentioned above (Rener, 1993; Perkins, 2002; Rowell and Ungar, 2003a). Recognition, legibility and discrimination of symbols are the factors that are most widely examined in various studies conducted to verify the usability of these types of product and their efficient use on maps (Berlá, 1982; Lambert and Lederman, 1989).

As regards the classification of the symbols, Edman talks about point, linear and areal texture symbols (Picture 2). Each of these is used to present specific information (Edman, 1992). On mobility maps, point symbols represent particular locations and lines can communicate direction, while areal symbols cover specific areas (Welsh and Blasch, 1980).

Consequently, the representation of symbols on conventional tactile maps follows the guidelines established by the use of the three design elements or categories cited earlier. As a result of this, the symbols used on current tactile maps incorporate 2D features. A user can perceive the symbols through the sense of touch thanks to the contrasting heights of slight elevations of these shapes. In Berlá's studies this elevation ranged between 0.38 and 0.89 mm (Berlá, 1982).

However, other fields of knowledge such as that of ergonomics (Pheasant and Haslegrave, 2006), which are also focused on the study of displays adapted to human use, show that it is possible to utilize volumetric elements in tasks where one of the requirements is a high degree of tactile discrimination. This is the case with the controls of an aircraft, which should be distinct and easy to discriminate by touch so that pilots can avoid fatal errors. These controls use keypads, which ergonomics studies from the standpoint of efficiency of use (Sanders and McCormick, 1987).

In conclusion, it is important to mention that this study is focused on the use of the final category of design elements, that is, volumetric (3D) elements (Wong, 1993; Ching, 2007), as applied to tactile symbology. Volumetric symbols have not been addressed very extensively in the literature, although the work of Don McCallum, Simon Ungar and Sandra Jehoel (McCallum et al., 2006) should be noted as it deals with the analysis of different symbols using the TIMP (Tactile Inkjet Mapping Project) tactile process. The symbols studied included some with quite complex relief and volume (2.5D and full 3D features), such as a stairs symbol made up of three steps, each at a different height, or a ramp symbol produced in the form of a slope. The results of the study on these volumetric symbols were ambiguous, although they suggested a possible path of research on the possibilities of three-dimensional shapes (Z axis) for improving the usability of tactile maps.

Thus, this paper presents new results and findings about the use of a new category of tactile symbols, i.e. 3D symbols (Picture 3), on a real tactile map. The selection of this sort of symbols was carried out in previous studies, in which the researchers observed how, from a set of 80 different and varied 3D and 2D shapes tested, simple volumetric symbols were easy to recognize by the sense of touch (Gual et al., 2012). The 3D symbols tested in the previous experiment had no literal meaning – they were abstract shapes without any type of translation from the visual domain. They could therefore be interpreted with the aid of a key with their corresponding meaning, and without the need for visual memory.

On the other hand, the flat (2D) symbols selected in this study are conventionally used and described in the literature (Meihoefer, 1969; Lockwood, 1995; McCallum et al., 2006; Rener, 1993; Goodrick, 1987).

The objective of this study is to analyse the effect, as regards the speed of identification and error rates, of the use of 3D symbols on a tactile map.

The main research question is whether it is possible to improve the usability of tactile maps by including 3D symbols or, at least, if this inclusion does not have a detrimental effect on the performance of a tactile map, that is to say, whether they have the same level of usability as the traditional tactile symbols with 2D features.

@&#MATERIAL AND METHODS@&#

@&#METHODOLOGY@&#

The methodology used in this study is fundamentally experimental, based on tasks carried out with users and prototypes (mock-ups) and on the time spent on those tasks (Courage and Baxter, 2005; Laurel, 2003; Sanders and McCormick, 1987).

Two similar tactile devices (i.e. two independent groups, see Section 2.3) were compared, a control group being used as a reference (see Section 2.2). In order to analyse the effect of these symbols on the use of tactile maps, that is to say, to answer the research question, two quantifiable variants (dependent variables) were chosen, namely: time spent on tasks by users, and errors obtained when participants perform the tasks in a controlled context (see Section 2.4).

All tests were recorded on videotape and then the results of the tasks were obtained from carefully viewing the videos. The data from the experiment were then submitted to a thorough analysis using inferential statistical techniques. Due to the non-normal distribution of the data, a non-parametric test was used; more specifically, the Mann–Whitney U test was conducted for both variables, i.e. time spent on location and discrimination errors (see Section 3), using statistical data processing software, namely IBM SPSS Statistics 21 and G*Power 3.1.2, the latter being employed to calculate the effect size and power.

The experimental test in this study has two independent groups of users: Group 1 (Map A) and Group 2 (Map B-control group). The sample consisted of 46 persons, 23 per group.

The distribution of user profiles (blind, low vision and sighted participants) was similar within each of the two groups in order to be able to compare two independent but homogeneous samples.

The average age of those in Group 1 was 41.74 years (SD 13.45), ranging between 21 and 61 years. For Group 2, the average age was 41.04 (SD 11.69), with a range of ages between 20 and 63 years. Sighted and low-vision users were blindfolded in order to ensure that they used only the sense of touch to carry out the tasks (see Section 2.4). Table 1
                         below shows the distribution of the different types of participants, including aspects related with those with no visual experience, i.e. congenitally blind participants.

In addition, and regarding their previous experience with tangible graphics, both groups can be divided into three blocks: experienced users, i.e. subjects who often use tactile graphics and Braille; users with some experience, i.e. those who know how to read Braille, although they only occasionally use tactile devices; and participants with no experience, such as the sighted ones, for example (Table 2
                        ).

Two different tactile map prototypes were compared in this study, one per group.

The first tactile map, Map A (Picture 4
                        ) was produced using polychrome 3D Printing. The second, Map B (Picture 5
                        ), was based on the same version as Map A, but was made using polychrome thermoforming.

Both Map A and Map B depict the same area, the Main Hall of Antoni Gaudí’s Casa Batlló in Barcelona, catalogued as a UNESCO World Heritage site. Both maps have the same size and scale (450 × 140 mm; 1:125), present the same distribution of the elements and include the same amount of information. Large contrasted text is featured for low-vision users, while Braille is included for blind users, thus making the maps inclusive, so that any type of reader can read the information.

Both maps contain a key of 9 or 10 symbols, depending on the map, and 5 labels. Map A includes 9 symbols because there is a window represented in a realistic way, while Map B shows the same window in an abstract way.

The content that is shown, and which corresponds to the symbols, is as follows (Picture 6
                        ):
                           
                              •
                              Beginning of the Visit

End of the Visit

Itinerary

Stairs

Lift

Column

Window (except on Map A)

Access not allowed

Fireplace

Tactile Area

The labels contain Braille and represent the following items:
                           
                              •
                              Fireplace hall

Main hall

Sewing hall

Terrace

Shop

Map A contains volumetric (3D) symbols combined with flat relief (2D) symbols, while Map B contains only flat relief (2D) symbols. The position of the symbols and labels is the same for both maps.

Five tasks involving the location of symbols were conducted in this study. These tasks are routine practice when a tactile map has to be used. The tasks were designed to simulate the real conditions of reading a tactile map at home in order to learn about a new place before visiting it. Subjects performed the experiment sitting on chairs, while maps and legends were placed on a table in front of them. They were free to touch the map as they wished, following their preferences and knowledge or reading strategies (Picture 7
                        ).

Participants did not see or touch the material under study before doing the test in order to prevent them from memorizing anything. Initially the researchers used their hands to guide the participants when introducing them to the experiment, offering general descriptions of the context and meanings of the tactile elements of the maps and keys, and the features and format, although the target symbols that the tasks were to be performed with were not specified.

Firstly, users were asked to recognize each symbol shown on the key, one by one, looking for a match on each map, in accordance with the group they were in (key of Map A-Group 1; key of Map B-Group 2). Once participants were aware of the corresponding key in general terms, and had memorized it haptically, without any visual stimuli and using only the sense of touch, they had to begin the five proposed tasks (Table 3
                        ) one by one. In this case, participants had to individually memorize a target tactile symbol using the corresponding key. Once it had been memorized using only the sense of touch, researchers revealed the corresponding tactile map and asked participants to locate the symbol they had touched previously. The symbols were always shown to each participant in a specific order in accordance with their position on the key, from top to bottom. Verbal assistance was provided to participants who could not read Braille in order to inform them about the meanings of each tactile symbol before starting each task. Participants had to say when they had located the symbols, and once they had begun their search on the map they were not allowed to consult the symbols of the key and they did not receive any further help. The same method was followed until they had completed the five tasks.

The main data collected in this experiment were the time employed and the errors committed while searching for each symbol in the location tasks.

For Tasks 1, 3 and 4, the symbols to be located had different characters, 3D on Map A and 2D on Map B. For Tasks 2 and 5, the symbols to be located were the same on both maps (2D) (Table 3).

@&#RESULTS@&#

This section shows and describes the results obtained in the experiment. The description has been organized based on the similarity of the contents analysed, with the data structured into two cases, depending on the nature of the tasks:
                        
                           •
                           Case 1: Tasks 1, 3 and 4. Tasks in which the time spent locating and discriminating errors was measured for symbols whose shapes (2D vs. 3D) differ depending on the map.

Case 2: Tasks 2 and 5. Tasks in which the time spent locating and discriminating errors were measured for symbols that have similar shapes for both maps.

The details of the results in the case of different profiles of users have also been described, more particularly, the data corresponding to Braille and non Braille readers, and also Visually Impaired and Sighted subjects.

It must be mentioned here that the difference between N (valid) and the total number of participants per group, N = 23, for the time measurement in the different cases is due to the fact that some measurements were not included because of errors made by users.


                        Table 4
                         offers a summary of the type of task (see Section 2.4) and the symbol used in this case.

The tables displaying the results obtained for Case 1 are shown below (Tables 5 and 6
                           
                           ).

When assessing the time that participants needed to perform the three tasks analysed, it can be seen that Group 1, which corresponds to Map A, conducted the three tasks in a shorter time (Table 5).

Regarding the time measurement for Task 1, there is a reduction of 77.01% between the independent groups; for Task 3 this decrease is 63.27% and for Task 4 the decrease is 63.68%.

Regarding the discrimination errors, it can be seen that there were fewer errors in Group 1 (Table 6). For Task 1, Group 1 obtained an average of 90.70% fewer discrimination errors than users from Group 2. For Task 4, Group 1 registered an average of 84.41% fewer errors. No errors were registered for Group 1, with 23 users, in Task 4.

From the point of view of their previous knowledge of Braille (Table 7
                           ), both profiles, i.e. Braille readers and non Braille readers from Group 1, reduced the time spent on performing the tasks. Moreover, the users who knew Braille obtained the best results within each respective group.

On the other hand, when the error variable was analysed (Table 8
                           ) the behaviour was found to be similar to that in the case of the time spent variable, i.e. Group 1 obtained better results than Group 2 in both profiles of participants, Braille and Non Braille readers. Surprisingly, Non Braille readers from Group 1 performed the tasks with the same mean of errors, 0.03, as the experienced users in the same group, whereas the Braille readers from Group 2 reduced the mean of errors in relation to the inexperienced users in the same group: 0.36 (SD 0.35) vs. 0.47 (SD 0.17).

When the time variable was compared taking into account the visual capabilities of the participants, i.e. Visually Impaired vs. Sighted users (Table 9
                           ), again participants from Group 1 spent less time on performing the tasks than participants from Group 2. In both cases, sighted participants obtained a bigger mean for time spent on performing the tasks. The sighted subjects reduced the time spent on locating the symbols by over 80%: 18.19 s (SD 10.76) vs. 98.33 s (SD 41.80), using the 3D printed version of the map.

Finally, regarding the error variable and the type of participant (Table 10
                           ), it is remarkable that the sighted participants in Group 1 performed all the tasks without any mistakes, and both types of users, i.e. visually impaired and sighted, from Group 1 obtained a notable reduction in errors in relation to Group 2.

In Case 1, p-values are less than 0.05 for all cases.

Taking the sample as a whole, the effect size for the time variable is high: 1.57 (Task 1), 1.47 (Task 3) and 0.83 (Task 4), while the power for Task 1 is 0.99, 0.98 for Task 3, and 0.75 for Task 4. Regarding the size and power effect for the error variable, results show a high effect in Task 1 (1.02) and a medium effect in Task 4 (0.64). There were no mistakes in Group 1 for Task 3. The power obtained in this case was 0.97 for Task 1 and 0.73 for Task 4.

On analysing the data in terms of the participants' knowledge of Braille, all the mean differences between groups show a high effect size and power: in the Non Braille readers-time variable (effect size = 2.16; power = 1.00); in the Braille readers-time variable (effect size = 2.39; power = 0.99); in the Non Braille reader-error variable (effect size = 3.07; power = 0.99); and in the Braille readers-error variable (effect size = 1.28; power = 0.89).

According to their visual capabilities, both variables displayed a high effect size and power when the data for each group were compared: in the Visually Impaired-time variable (effect size = 2.15; power = 0.99); in the sighted participants-time variable (effect size = 2.15; power = 0.99); in the Visually Impaired-error variable (effect size = 1.42; power = 0.98); and in the sighted participants, there were also no errors within Group 1.


                        Table 11
                         shows the type of task (see Section 2.4) and the target symbol searched for in Case 2.


                           Tables 12 and 13
                           
                            below show the results obtained for Case 2.

For both tasks it can be seen that Group 1 took less time to carry them out (Table 12). As for the time spent on completing Task 2, the decrease was 31.89%, while for Task 5 it was 26.88%.

Regarding errors in this case, Group 1 obtained better results than Group 2 in both tasks. There was a 62.85% decrease in errors in Task 2, and 49.91% in Task 5 (Table 13).

If we analyse the time spent when subjects performed Tasks 2 and 5, in terms of their knowledge of Braille (Table 14
                           ), those who were able to read Braille obtained better results than non Braille readers in both groups. Nevertheless, it is worth noting that Braille readers broke the positive tendency of Group 1 because, in this case, the best mean time spent was obtained using the thermoform map in Group 2: 20.80 s (SD 15.04) vs. 28.33 s (SD 10.86) in Group 1.

Conversely, when previous knowledge of Braille was taken into account to compare the error rates in these tasks (Table 15
                           ), similar data rates can be observed between participants except for the case of Braille readers, who executed the tasks almost without errors (0.08) in Group 1. Group 2 Braille readers obtained the highest mean of errors in this comparison.

On another level of analysis, taking into account the possible differences between sighted and visually impaired subjects, Tasks 2 and 5 were performed by participants in the experiment with similar results, only a small difference being found for these two groups when they used the 3D Printing map, that is, in Group 1. In any case, the differences between types of users in terms of the mean amounts of time spent were minimum (Table 16
                           ): 29.94 s (SD 20.98) in Visually impaired vs. 30.75 s (SD 24.70) in Sighted in Group 1; and 36.92 s (SD 41.42) vs. 40.06 s (SD 34.95) in Group 2.

Finally, following the analysis with this type of users under the error-rate perspective (Table 17
                           ), a clear difference of errors was found among the visually impaired participants. When they performed the tasks with the 3D printed map, they obtained a greater result with this device, 0.06 (SD 0.17), than when using the thermoform copy of Group 2, 0.32 (SD 0.32).

Generally, the p-values obtained were higher than 0.05. This means that despite the perceptual and data differences, time and error variables are not significant from a statistical point of view. It is worth noting, however, that in two cases notable differences were found between the types of participants in the error variable. The first difference was produced when Braille readers conducted the two tasks: the Braille readers from Group 1 obtained a positive result, almost without mistakes (0.08 (SD 0.19)), with a p value = 0.055, effect size = 0.87 and not enough power (0.63) to be able to state that this different means was statistically significant. The second one was produced with the visually impaired participants using the 3D printed map, who also conducted the tasks with almost no mistakes, 0.06 (SD 0.17), with a p value = 0.01; effect size = 1.01 and enough power to take this statistical difference into account (0.84).

@&#DISCUSSION@&#

Positive results were apparent when volumetric symbols were added to the maps. This can be clearly observed on the tactile map (Map A), since both variables analysed improved (Case 1). In contrast, the behaviour of the group in the planned tasks was almost similar when conditions were maintained, leaving only 2D symbols on the map (Case 2), especially in the time variable.

Results obtained show statistically significant differences between Maps A and B, regarding both time spent on location and discrimination errors (see Section 3.1.2).

The results obtained show that the use of volumetric symbols on tactile maps combined with other morphological elements of symbol design (points, lines and areas-textures) (Amick et al., 2002; Correa Silva, 2008; Edman, 1992; Welsh and Blasch, 1980) improves the task time for autonomous location by the users, according to the results for Group 1. In addition, it can be observed that the size of symbols plays a fundamental role in location tasks. This can be seen quite clearly, for instance, in Task 4, where both groups obtained better results because the symbols evaluated were larger than those used for Tasks 1 and 3 on each corresponding map, thereby facilitating their perception (Table 5), and in accordance with the lower tactile acuity of the sense of touch (Schiff and Foulke, 1982).

Just as with the error variable, Group 1 significantly reduced the number of errors of perception of these symbols with respect to the 2D symbols used on Map B. Only the results obtained in Task 4 for the Fireplace symbol indicated a lower power (0.73) in the comparison between groups, although at the same time, on Map B this Fireplace symbol was confused with the Tactile Area symbol (texture). As these are both areal symbols and belong to the same category, they are presented as textures. This problem did not occur on Map A, since the texture was replaced with a volumetric tactile symbol (Picture 8
                        ), and this new category is difficult to confuse with elements from the other categories, that is, points, lines and areas. Some participants also highlighted the difficulties in perceiving the Lift symbol on Map B, given its complexity. This symbol is configured almost in the shape of a square, and consists of three lines, with two additional diagonal lines crossing the vertex, thus totalling five relief lines, which are too numerous to be perceived by the sense of touch, since tactile acuity is lower than that of the sense of vision (Schiff and Foulke, 1982). Therefore, in the design of tactile maps and symbols it is necessary to heed the principle of simplicity (Amick et al., 2002; Edman, 1992; Rowell and Ungar, 2003c).

In addition, it is important to mention the role of contrasting heights in tactile perception to facilitate the process of location in the case of volumetric tactile symbols. Without doubt, these specific symbols can be used to show significant parts or meanings of the maps (landmarks). This fact is based on their low index of errors and their easy location compared to the 2D tactile symbols used in the experiment.

Finally, all types of participants – Braille and non Braille readers, Visually Impaired and Sighted – obtained significantly better results using Map A than Map B with only two-dimensional elements. They benefited from the inclusion of a greater variety of tactile attributes, in this case, a bigger contrast height. Even non Braille-reader participants, i.e. non-experienced subjects, obtained similar results to experienced ones (Table 8), and sighted users were able to complete these location tasks with no errors.

For Case 2, in which symbols of similar characteristics (2D) were used on both maps, generally no significant differences were detected between groups, except those related to the use of different systems of production. 3D printing (Chua et al., 2003) has better geometric precision and resolution than thermoforming (Rowell and Ungar, 2003b) and this fact is reflected in a better tactile perception of the shape.

As in Case 1, with the confusion of similar design elements used on Map B (two areal symbols-textures), some specific symbols used for Map B in Case 2 also caused confusion. This was the case of the End of Visit symbol and at least one of the four Column symbols. These symbols are similar in shape, as they are circular, although they vary noticeably in size (Picture 9
                        ). The Tactile Area symbol was also confused with the Fireplace symbol on Map B (Picture 8). This did not occur with Map A due, as we mentioned above, to the improved tactile diversity features of the map with the inclusion of volumetric tactile symbols.

Finally, in Case 3, significant differences were found among the profiles of participants, especially in the cases of Braille readers and the visually impaired, in terms of the measurements of error variable, although these differences were not found in the time variable. This sort of subjects improved their error rates when they used Map 1 to search for similar types of symbols, probably due to their being less likely to confuse these 2D symbols within the context of the 3D printed map and a better definition of the geometry of the 3D Printing method.

@&#CONCLUSIONS@&#

Following the results, the study shows that it is possible to improve the interaction between users and tactile maps using volumetric symbols together with two-dimensional morphological elements of design (points, lines and areas). Volumetric symbols are easily identified, recognized and discriminated. They can be located in less time and cause fewer errors. Thus, this combination caused a positive effect on the usability of the map studied.

When a symbol is correctly located, it is not only detected, but recognized and discriminated from the rest of the symbols on the map as a whole. Some of the most important factors when correctly locating a symbol are size, shape and texture (Berlá, 1982; Edman, 1992). However, using large contrasts in height could be another important factor, given the data compiled in this experiment as regards volumetric tactile symbols. Nevertheless, this should always follow a basic principle: ensuring simplicity for the sense of touch when designing (Amick et al., 2002; Edman, 1992; Rowell and Ongar, 2003c).

Hence, it seems difficult to confuse the different morphological design elements (Amick et al., 2002; Correa Silva, 2008; Edman, 1992; Welsh and Blasch, 1980). For example, it is difficult to confuse a line with an area or a point. Similarly, volumetric symbols are difficult to confuse with other categories. In contrast, as this study shows, the inclusion of volumetric symbols on a map has an overall positive effect because it increases the variety of shapes and tactile attributes such as contrast height. Even so, this fact does not mean that a suitable tactile symbol in 3D could always be better than a 2D symbol. But at least they can assimilate the same level of usability as the current ones, thereby answering the research question of the study.

On the other hand, although traditional systems of production of tactile maps like thermoforming (Rowell and Ungar, 2003b) enable the reproduction of volumetric symbols in some cases, such as cones and pyramids, 3D printing (Chua et al., 2003) opens up new horizons for the design and production of this type of maps, as it offers Mobility Instructors the chance to personalize the production of maps with complex and polychrome geometry at a higher resolution than current techniques.

Despite the improvement explained here, it is necessary to meet the challenges of producing usable and autonomous tactile maps.

@&#ACKNOWLEDGEMENTS@&#

The work reported here is part of the research project entitled ‘Estudio y diseño de elementos de orientación, soportes de comunicación y otros accesorios para la mejora de la accesibilidad en distintos ámbitos de interpretación del patrimonio natural y/o construidos’ supported by the Spanish Ministry of Science and Innovation (project DPI2008-03981/DPI). The authors wish to thank the Centre de Recursos Educatius (Organización Nacional de Ciegos Españoles-ONCE) and the Associació Discapacitat Visual Cataluña B1+B2+B3 in Barcelona, as well as the ONCE offices in Castellón, Tarragona and Valencia for supporting this research. Finally, this work has also been supported by the Programa de Mobilitat del Personal Investigador de la Universitat Jaume I (E-2010-32) and the Fundació Caixa Castelló-Bancaixa.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Feature selection and classification methodology for the detection of knee-joint disorders

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We proposed RQA, ApEn, SampEn and wavelet based energy as feature extraction techniques.


                        
                        
                           
                           We have proposed feature selection algorithm to extract the most significant and relevant features.


                        
                        
                           
                           We have used LS-SVM and random forest as classifiers.


                        
                        
                           
                           Performance among feature selection algorithms are compared.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Vibroarthographic signal

Biomedical signal processing

Feature selection

Apriori algorithm

Genetic algorithm

Wavelets

@&#ABSTRACT@&#


               
               
                  Vibroarthographic (VAG) signals emitted from the knee joint disorder provides an early diagnostic tool. The nonstationary and nonlinear nature of VAG signal makes an important aspect for feature extraction. In this work, we investigate VAG signals by proposing a wavelet based decomposition. The VAG signals are decomposed into sub-band signals of different frequencies. Nonlinear features such as recurrence quantification analysis (RQA), approximate entropy (ApEn) and sample entropy (SampEn) are extracted as features of VAG signal. A total of twenty-four features form a vector to characterize a VAG signal. Two feature selection (FS) techniques, apriori algorithm and genetic algorithm (GA) selects six and four features as the most significant features. Least square support vector machines (LS-SVM) and random forest are proposed as classifiers to evaluate the performance of FS techniques. Results indicate that the classification accuracy was more prominent with features selected from FS algorithms. Results convey that LS-SVM using the apriori algorithm gives the highest accuracy of 94.31% with false discovery rate (FDR) of 0.0892. The proposed work also provided better classification accuracy than those reported in the previous studies which gave an accuracy of 88%. This work can enhance the performance of existing technology for accurately distinguishing normal and abnormal VAG signals. And the proposed methodology could provide an effective non-invasive diagnostic tool for knee joint disorders.
               
            

@&#INTRODUCTION@&#

The human knee joint is one of the most complicated and largest joints in a human body. It not only provides flexible movements but also sustains the weight of the body and withstands pressure loads during routine/sports activities. These activities could lead to softening of the articular cartilage, tendons and ligaments of the kneecap which leads to substantial injuries and various kinds of knee joint disorders [1]. This has lead to exploring the early diagnosis of the knee joint disorders. Both, invasive and non-invasive procedures are available for the evaluation of the knee joint. Imaging techniques such as MRI, fMRI, Computer Tomography (CT) offer non-invasive detection but fail to provide an earlier diagnosis [2]. Whereas a semi-invasive technique such as Arthroscopy, offer considerable information about the diagnosis. But a conventional Arthroscopy would not be feasible for a patient's repetitive or periodic checkups. Both of these procedures, are cost ineffective and are inefficient for a routine physician's checkups. Their inability to showcase the dynamic characteristic is one of the major disadvantages of these procedures [3]. These limitations lead us to explore for an alternative low-cost non-invasive detection of knee joint disorders.

During the active movements of the legs such as the flexion and extension, the vibration or auditory signals emits from the mid-patella are called Vibroarthographic (VAG) signals [4]. VAG signals are characterized by nonlinearity and nonstationary. The analysis of VAG signals could provide an early diagnostic tool for detecting knee joint disorders. The parameters computed from the VAG signal as features could provide a discriminant characteristic. Various signal processing techniques for feature extraction and classification have been carried out in the previous literature [5,6]. The techniques based on the time domain, frequency domain, time-frequency and nonlinear signal processing have been proposed for the analysis of VAG signal [4,7]. Recent works include an analysis of VAG signal by fractional analysis using power spectral analysis by Rangagayan [8]. The classification technique has been carried out using the k-nearest neighbor method. Wang Yu et al. have recently carried out the work by representation of fluctuation feature using kernel density modeling [9]. The literature review revealed that improvisation in signal processing technique would improve the feature extraction and classification techniques. This, in turn, could aid the medical experts to make accurate decisions on knee joint disorders. Therefore, to build an effective diagnostic system, it is essential to have effective distinct feature extraction techniques and a highly accurate classification algorithm. Hence, we propose an effective feature extraction and classification technique for the diagnosis of knee joint disorder by analysis of VAG signals.

In the recent studies, it has been concluded that wavelet decomposition based sub-bands signals may render substantial information about neuronal activities, especially in the case of EEG signals [10]. The study concluded that EEG signals are complex for analysis and could not differentiate between seizure and non-seizure signals effectively. These distinctions were quite visible in the sub-band signals obtained from wavelet decomposition of EEG signals. Hence, we propose a novel technique of wavelet decomposition for the analysis of VAG signals. With respect to nonlinearity and nonstationary nature of VAG signal, we propose three nonlinear features specified as recurrence quantification analysis (RQA), approximate entropy (ApEn) and sample entropy (SampEn). These three features are extracted from each of the sub-bands signals which are obtained from the wavelet decomposition of the main VAG signal. Wavelet based energy is also considered in this study. Once these features are extracted, a classifier technique is used for the decision-making stage of VAG signal.

A feature selection algorithm has also been proposed in order to identify the most stable, significant and discriminate features. Different techniques have been utilized for improving the accuracy of the classifier by discarding redundant and irrelevant features. These techniques have been employed in the domain of medical imaging, biomedical signals and power-quality disturbance evaluations. Techniques used for feature selection in the previous studies include the sequential forward selection method [11], wrapper method [12]and sequential backward feature selection method [13]. In our study, the K nearest neighbor based apriori algorithm and genetic algorithm has been used for selecting the most stable and significant features from the extracted features. The feature sets obtained by feature selection algorithms are given as input to two different classifiers, i.e., LS-SVM and random forest. Classification results are compared between the two feature selection algorithm. Hence, we propose a novel technique for feature extraction based on wavelet decomposition. Feature selection algorithms have been proposed in order to select the most significant, relevant and stable features. The selected features are then fed to the classifier as input in order to compare the performance. With the aim of improving the effectiveness and efficiency of the classification accuracy for knee joint disorders using VAG signals, a Computer Aided Diagnosis (CAD) system based on LS-SVM and random forest is introduced.

The article is organized as follows: Section 2 includes methodology adopted for the study that includes the feature extraction techniques, feature selection algorithms and classification methods. Section 3 shows the results obtained after computing feature extraction and classification. Section 4 concludes with the detailed discussion.

@&#METHODS@&#

The basic block diagram of the VAG detection system is shown in Fig. 1
                        . The original main VAG signals are decomposed into sub-band signals of different frequencies. For the quantification of the VAG signal, features such as RQA, ApEn, SampEn and wavelet-based energy is computed for the original main VAG signals as well as for the decomposed sub-band signals. In order to evaluate the predictability or repeatability within a time series mathematical algorithms such as ApEn and SampEn are used. Both of these algorithms are sensitive to input parameters: m (length of the data segment being compared), r (similarity criterion), and N (length of data).

To quantify the nonlinear information in a time series, Eckmann et al gave the concept of recurrence plots [14]. Recurrence plots are graphical techniques which visualize the recurrence behavior of the phase space trajectory of dynamical systems. This method was proposed by Eckmann et al and was later developed by Webber and Zbilut [15]. It aims to quantify differences appearing towards recurrence plots (RPs) based on the small-scale structures. Several recurrence quantification measures have been introduced in the recent past and have been successfully applied to analyze noisy and nonstationary data. In this research, we have studied three primary measures defined by Webber et al. [15]. Thus, RQA has been successfully applied for the analysis of physiological signals.

Pincus introduced the concept of ApEn to determine the information containing in time series data [17]. A time series is deterministic if computed ApEn value is low and high value of ApEn indicates randomness. SampEn is the modification of approximate entropy. It overcomes the drawback of the ApEn. It has been used extensively for diagnosing the physiological signal in the time-series [18,19]. Features such as RQA, ApEn, SampEn and wavelet based energy would be extracted from each of the wavelet decomposed sub-band signals. The extracted features are given as inputs to the build the classification model. Since most of the extracted features do not contribute for building an effective classification model, we propose a feature selection algorithm. The feature selection algorithm selects the most significant, relevant and stable features. The irrelevant or redundant features are discarded as these features would serve no purpose and may degrade the classification model. By retaining the most significant, relevant and stable features, a highly accurate classification model can be built. In this work, an apriori algorithm [20] and genetic algorithm [21] as feature selection algorithm has been proposed. The selected features would be provided as inputs to the classifier. LS-SVM and random forest are considered as the classifier and their performances are observed.

Since the VAG signal has been sampled at 2000Hz, therefore the maximum available frequency would be 1000Hz. The VAG signal is decomposed into eleven wavelets based sub-band signals (D1, D2, D3, D4, D5, D6, D7, D8, D9, D10, A10). The number of levels of decomposition and selection of suitable wavelet is very important in the analysis of signals. The selection of 11 sub-bands provides sufficient resolution for analyzing the frequency range of interest. This is due to fact that wavelet decomposition into more than 11 levels was found to be redundant and a smaller number of decomposition levels does not provide enough information to distinguish between the signals. Table 1
                         shows the decomposition of the VAG signal into different frequencies. Based upon the prominent frequency component of the VAG signal, the number of levels of decomposition is chosen. The levels are chosen in such a manner that, the frequencies required for the classification of the signal are correlated to the parts of the signal which are retained by wavelet coefficients. Slow baseline variation mainly caused by different artifacts are represented by D8, D9, D10, A10 sub-band signals, while D1 represents high frequency components caused by environmental noise or muscle contraction [22]. These sub-band signals D1, D8, D9, D10, A10 are not considered for computing the feature extraction. The Daubechies 4(db4) wavelet which is regarded as an efficient wavelet in the analysis of biomedical signal processing was selected as the mother wavelet function. Important information on the event types was obtained from coefficients of multi-resolution analysis.

Recurrence plots are advanced techniques to carry out the nonlinear data analysis. Recurrence plots are graphical techniques which represents the recurrence of the phase space trajectory of the dynamic system. Recurrence plots (RPs) are binary symmetric of N
                           ×
                           N arrays in which a spot is placed at (i, j) when the distance between X
                           
                              i
                            and X
                           
                              j
                            is less than a prescribed value ∈.
                              
                                 (1)
                                 
                                    
                                       R
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      0
                                                   
                                                   
                                                      if
                                                      ∥
                                                      
                                                         X
                                                         i
                                                      
                                                      −
                                                      
                                                         X
                                                         j
                                                      
                                                      ∥
                                                      <
                                                      ∈
                                                   
                                                
                                                
                                                   
                                                      b
                                                   
                                                   
                                                      if
                                                      ∥
                                                      
                                                         X
                                                         i
                                                      
                                                      −
                                                      
                                                         X
                                                         j
                                                      
                                                      ∥
                                                      ≥
                                                      ∈
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           Since graphically evaluation would be a difficult task, recurrence quantification analysis (RQA) was evolved in order to provide a quantification measure. In comparison to other methodologies, RQA requires no assumption about the linearity or stationary about the data for analyzing nonlinear signals. In the present study, recurrence rate (%REC), determinism (%DET) and Shannon entropy (ENTR) are considered [15] and they are defined as follows.
                              
                                 •
                                 Recurrence rate (%REC): It refers to the density of recurrence plots. It is the probability of a particular state of recurrence. Corresponds to the correlation sum.
                                       
                                          (2)
                                          
                                             %
                                             REC
                                             =
                                             
                                                1
                                                
                                                   
                                                      N
                                                      2
                                                   
                                                
                                             
                                             
                                                ∑
                                                
                                                   i
                                                   ,
                                                   j
                                                   =
                                                   1
                                                
                                                N
                                             
                                             R
                                             (
                                             i
                                             ,
                                             j
                                             )
                                             .
                                          
                                       
                                    
                                 

Determinism (%DET): It relates to determinism/passivity of the system. It is the ratio of recurrence spots placed on the diagonals to all recurrence spots.
                                       
                                          (3)
                                          
                                             %
                                             DET
                                             =
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         l
                                                         =
                                                         
                                                            l
                                                            min
                                                         
                                                      
                                                      N
                                                   
                                                   lP
                                                   (
                                                   l
                                                   )
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         i
                                                         ,
                                                         j
                                                      
                                                      N
                                                   
                                                   
                                                      R
                                                      
                                                         i
                                                         ,
                                                         j
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                    P(l) is the histogram of the lengths l of the diagonal lines.

ENTR: In a recurrence plot, it refers to measure of complexity. It is also known as Shannon entropy. The Shannon entropy of the probability distribution of the diagonal line lengths p(l):
                                       
                                          (4)
                                          
                                             ENTR
                                             =
                                             −
                                             
                                                ∑
                                                
                                                   l
                                                   =
                                                   
                                                      l
                                                      min
                                                   
                                                
                                                N
                                             
                                             p
                                             (
                                             l
                                             )
                                             lnp
                                             (
                                             l
                                             )
                                          
                                       
                                    where
                                       
                                          (5)
                                          
                                             p
                                             (
                                             l
                                             )
                                             =
                                             
                                                
                                                   P
                                                   (
                                                   l
                                                   )
                                                
                                                
                                                   
                                                      ∑
                                                      
                                                         l
                                                         =
                                                         
                                                            l
                                                            min
                                                         
                                                      
                                                      N
                                                   
                                                   P
                                                   (
                                                   l
                                                   )
                                                
                                             
                                          
                                       
                                    
                                 

To quantify levels of complexity within a time series, Pincus introduced the concept of ApEn. ApEn measures the “likelihood that runs of patterns that are close remain close on next incremental comparisons” [25]. ApEn was initially developed to analyze physiological data, such as heart rate. The details about the algorithm are introduced in Pincus [17] and Al-Angari and Sahakian [26]. For a given N data points from a time series x(n)=
                           x(1), x(2), …, x(N) where N is the length, Two parameters, m (length of the data segment being compared) and r (similarity criterion) are specified. For a finite length of data points N, the approximate entropy is estimated as
                              
                                 (6)
                                 
                                    ApEn
                                    (
                                    m
                                    ,
                                    r
                                    ,
                                    N
                                    )
                                    =
                                    [
                                    
                                       ϕ
                                       m
                                    
                                    (
                                    r
                                    )
                                    −
                                    
                                       ϕ
                                       
                                          m
                                          +
                                          1
                                       
                                    
                                    (
                                    r
                                    )
                                    ]
                                 
                              
                           
                        

SampEn was developed to reduce the bias caused by self matching. SampEn demonstrates comparatively consistent and is an independent of the data length. Recently, SampEn has been applied for the analysis of various other biomedical signals. Especially, in the analysis of the epileptic activities using EEG signals. Song et al. [27] used SampEn to reveal the characteristics of epileptic EEG signals and identify the EEG signals regarding the existence of seizure or not. Sample Entropy is given as:
                              
                                 (7)
                                 
                                    SampEn
                                    (
                                    m
                                    ,
                                    r
                                    ,
                                    N
                                    )
                                    =
                                    ln
                                    [
                                    
                                       ϕ
                                       m
                                    
                                    (
                                    r
                                    )
                                    −
                                    
                                       ϕ
                                       
                                          m
                                          +
                                          1
                                       
                                    
                                    (
                                    r
                                    )
                                    ]
                                 
                              
                           Although m and r are critical in determining the outcome of ApEn and SampEn, no guidelines exist for optimizing their values [17]. For most of the research studies the values of m and r are usually m
                           =1 or m
                           =2 and r between 0.1 and 0.25 times the standard deviation of the original time series, as suggested by Pincus [25]. In present study, we have computed ApEn and SampEn based on the work concluded by Jennifer et al. [28]. In our studies we have taken m
                           =2 and r is equal to 20% of the standard deviation of the amplitude of time series. And N is set to 8000 (data length of the VAG signal).

With the three nonlinear methods introduced above, wavelet based energy of the sub-band signals (D2,D3, D4, D5, D6, D7) are computed and results are compared. The sub-band signals (D2, D3, D4, D5, D6, D7) are not used directly as entries of the feature vector [22]. Instead, the energy in each of the sub-band signals (D2, D3, D4, D5, D6, D7) are used. The wavelet based energy for each sub-band can be represented as:
                              
                                 (8)
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      X
                                                      2
                                                   
                                                
                                                
                                                   
                                                      X
                                                      3
                                                   
                                                
                                                
                                                   
                                                      X
                                                      4
                                                   
                                                
                                                
                                                   
                                                      X
                                                      5
                                                   
                                                
                                                
                                                   
                                                      X
                                                      6
                                                   
                                                
                                                
                                                   
                                                      X
                                                      7
                                                   
                                                
                                             
                                          
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               2
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               3
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               4
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               5
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               6
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                                
                                                   
                                                      log
                                                      
                                                         
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               |
                                                               D
                                                               7
                                                               (
                                                               n
                                                               )
                                                               |
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Many factors contribute in degrading the performance of classification in machine learning algorithms. Among them are the irrelevant and redundant data which hampers the over classification model, thereby do contributing to discrimination among the classes. This challenge escalates when the data is of high dimensionality.

Thus, to overcome these factors, feature selection techniques play an important role for a successful building of the classification model [29]. The number of features is reduced as feature selection removes the irrelevant and redundant features and retains the most significant, relevant and stable features. The performance of the classifier's accuracy increases while using the feature selection algorithms.

Apriori algorithm is an influential algorithm for data mining and is especially known for learning association [20]. In data mining, association is usually referred as, for a given element set, the algorithm pursuits to find subset which are common to at least a minimum number. It follows a bottom up approach where predominant subsets are extended one element at a time and groups of candidates are tested against the data. When there is not any further successful extension, the algorithm terminates [30].

Genetic algorithms (GA) are one of the examples of evolutionary algorithms (EAs), which is derived from Darwin's theory of evolution associated with natural selection [21]. For an optimization problem in GA the population of strings also termed as chromosomes, are encoded as candidate solutions called individuals. Usually binary strings of 0s and 1s or bit string represent the genetic information that is chromosome and the solution is encoded by such sets of bits. For a new population of individuals or termed as next generation, genetic operators are then applied to the individuals. Crossover and mutation are two main genetic operators applied over here. In crossover, two offspring strings from two parent strings are created by copying selected bits from each parent. However, in mutation, the value of a single bit (with a small probability) changes randomly. Also, in order to increase the probability that the single bit can survive throughout the evolutionary process, a fitness function is used to measure the quality of an individual. Large search spaces are dealt efficiently by a GA, and other algorithms have less chance to arrive at a local optimal solution [31].

Support Vector Machine (SVM) is used for nonlinear estimation, function estimation, density estimation and classification proposed by Vapnik [32]. SVM is a machine learning algorithm based on statistical learning of Vapnik-Chervonenkis dimension [33]. One of the major drawback of SVM was its high computation load. Suykens suggested LS-SVM to single out this liability [34]. LS-SVM computes linear equation instead of solving the convex for quadratic programming problem in case of SVM. Due to the ease of its implementation, it has found lots of uses in the area of adaptive signal processing. In the present study, we focus on LS-SVM.

Random forest is based on the decision tree classification techniques. It is an ensemble modeling which combines the results from different models [35]. Random forest is defined by Breiman as “combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest” [36]. The problem of over-fitting found in decision tree is overcome by random forest.

The effectiveness of the classifier techniques can be evaluated using different performance parameters [37]. And they are as sensitivity (SEN), specificity (SPF), accuracy (ACC), positive predictive value (PPV), negative predictive value (NPV), Matthews correlation coefficient (MCC) and false discovery rate (FDR).

@&#EXPERIMENTS@&#

The experiment data set for data acquisition of VAG signal was performed at the university of Calgary, Canada. This setup was authorized by Conjoint Health Research Ethics Board of the University of Calgary. The setup required the subject to sit on an adamant surface table with leg dropping freely in the air. At the mid patella of the knee joint, an accelerometer was mounted. The subject was asked to perform flexion and extension of the knee joint. The active movements represented by VAG signal were captured in the form of electric voltage generated due to deceleration and acceleration. The signal acquired was pre-amplifiered to avoid anti-aliasing. Data acquisition board and National Instruments software LabVeiw were used for amplifying and digitizing the signal. The VAG signal was per-filter (10Hz to 1kHz) and amplified. The sampling frequency of VAG signal was 2000Hz and was digitized with a resolution of 12 bits [38].

In the current investigation, we have used data set as reported in the earlier literature. The data set contains a total of 89 VAG samples. 51 subjects having no physiological disorder condition were considered as normal while 38 subjects suffering from various kinds of knee joint disorders such as meniscal tears, anterior cruciate ligament and tibial chondromalacia injuries were considered as abnormal. A sample VAG signal of a normal and abnormal subject is shown in Fig. 2(a) and (b) respectively. We can observe that the abnormal signal exhibits a high level of irregularity in the time domain, as illustrated in Fig. 2(b).

@&#RESULTS@&#

In this study, we have implemented the proposed method of feature extraction, feature selection and classification techniques in MATLAB 2014A. Initially, the feature set was consisted of twenty-four features and they were extracted as follows:
                              
                                 (1)
                                 RQA features: percent recurrence, determinism and Shannon Entropy of the frequency distribution of the diagonal line lengths.

ApEn of main signal and sub-band D2–D7 signals.

SampEN of main signal and sub-bands D2–D7 signals.

Energy of the main signal and sub-band D2–D7 signals.


                           Fig. 3
                            represents the error plot for SampEn. Error bar represents the range and standard deviation (SD). They are called as descriptive error bars because they illustrate the data spread. Range error bars encompass the lowest and highest values. The figure represents error plot of sample entropy extracted from original VAG signal and its sub-band signals D2, D3, D4, D5, D6, D7. From the error plot, we can notice a substantial overlap of normal and abnormal VAG signal states computed from the original VAG signal. Thereby, these distinctions are apparently more visible in sub-band signals D2, D3, D4, D5, D6, D7. Similarly, error plots for ApEn and RQA's parameters have been plotted in Figs. 4 and 5
                           
                            respectively.

The twenty-four features extracted characterize a VAG signal and most of these features might be irrelevant or redundant to build an effective classification model. Thus, in order to develop a highly accurate classification model, the most significant, relevant and stable features should be selected. A K-means clustering followed by apriori algorithm analysis is performed over the twenty-four features to select most significant, relevant and stable features and thus, reduces the dimensionality of the feature set. The proposed method involves dividing each of the features of the data into two classes using K-means clustering followed by simple one bit encoding of each group. Feature data belonging to one group were indicated with zeros and those belonging to the other were denoted as ones. The encoded feature vectors for all the recorded signals were further analyzed for recurrences. Features that acted as primary key were chosen as most significant, stable and relevant features. The feature set consisted of six features, which showed the maximum recurrence. The compressed feature set constituted the following extracted features:
                                 
                                    (1)
                                    ApEn of the main signal.

ApEn of sub-band D6.

ApEn of sub-band D7.

Determinism (Recurrence Quantification Analysis).

Shannon Entropy (Recurrence Quantification Analysis).

SampEn Entropy of sub-band D6.

Similarly, to improve the performance of the classification model, a genetic algorithm as feature selection algorithm is also considered in the present study [39]. The genetic algorithm is able to choose most significant, relevant and stable features. The genetic algorithm chooses four features, which showed the maximum recurrence. The feature set constituted the following:
                                 
                                    (1)
                                    ApEn of the main signal.

SampEn of sub-band D2.

Wavelet Energy of sub-band D2.

Wavelet Energy of sub-band D5.

To further verify the discriminability between the features, the Kruskal–Wallis test is performed on the features extracted. Kruskal–Wallis is a test of variance using population variance among groups. The p-value returned from the test indicates the variation between the two data. Smaller p-value of 0.05 indicates a very strong presumption against the null hypothesis, i.e., it hints that two feature data belongs to sets and hence could be a useful feature in distinguishing the two classes. The results obtained from the Kruskal–Wallis test for the selected features are presented in Table 2
                              .

The extracted features are given as inputs to classifiers, LS-SVM and random Forest. Cross validation is used for selecting optimal kernel/model parameters for the classifiers. Radial basis function (RBF) is used as kernel function for LS-SVM classifier. The regularization constant is chosen appropriately to avoid over-fitting. Sensitivity, specificity, accuracy and area under receiver operating curve (ROC-AUC) are computed to compare the performance of the classifier. Targets are set as ‘1’ for abnormal signals and ‘0’ for normal signals. In present work, a 10-fold cross-validation [40] procedure has been used in order to assess the classification performance of the classifier. All classifiers considered in this study underwent a 10-fold cross-validation, with the same folds being used by each classifier.

In the random forest, a validation procedure is followed for finding the number of decision trees in the classifier. A part of the data-set is set aside for validation and the number of trees is alternated, till an ideal validation accuracy is obtained. The number of decision trees chosen for the ensemble is taken as five.

A receiver operating characteristic (ROC) curve was illustrated to compare the performance of the classifier. ROC curve is a graphical representation of the true positive rate (TPR, also named sensitivity) against the false positive rate (FPR, FPR=1−specificity) [41]. The area under the ROC curve (ROC-AUC) is an effective way of comparing the performance of different features (all 24 features, 6 features from apriori algorithm and 4 features from a genetic algorithm) using LS-SVM and random forest. The area under ROC curve (ROC-AUC) illustrates how considerably a parameter would be able to distinguish between two diagnostic groups. Larger ROC area implies a better classification accuracy [42]. The ROC plot for two classifiers using feature selection algorithms is observed in Fig. 6
                           .


                           Tables 3 and 4
                           
                            show the comparison between all twenty-four features and features selected by feature selection algorithms using LS-SVM and random forest respectively. The number of features selected vary with respect to the feature selection algorithm. Six features are selected by using the apriori algorithm, while four features are selected by genetic algorithm. For all the above cases, the classification is carried out by LS-SVM and random forest and are shown in Tables 3 and 4 respectively.

From Table 3, it is evident that using feature selection algorithms, the performance of the LS-SVM classifier increases. The accuracy of LS-SVM using all twenty-four features is 93.18% and by using apriori algorithm (six features) as feature selection algorithm, its accuracy increases to 94.31%. While using genetic algorithm (four features) its accuracy is 91.01%. Features obtained by using the apriori algorithm also provided a low FDR of 0.0892 than compared to all twenty-four features (0.1071) and genetic algorithm (0.1052). The high accuracy obtained from the apriori algorithm along with low FDR, provided a good classification tool to classify VAG signals more efficiently. Table 4 provided a similar case study of classifying the VAG signal using random forest. From the Table 4, it is evident that features obtained from feature selection algorithms perform better than the complete twenty-four features. The classification accuracy, using all twenty-four features is 86.52% while using the apriori algorithm, is 89.77% whereas classification accuracy is highest using genetic algorithm of 91.01%.

From Table 4, the ROC-AUC is also highest in genetic algorithm with 0.92 and standard error (S.E) of 0.0306. Using apriori algorithm, the ROC-AUC is 0.8863 S.E: 0.0388 whereas it was lowest for all twenty-four features. The MCC was also higher by using genetic algorithm (0.8159) while it was lowest for twenty-four features (0.7231). The features selected using genetic algorithm yielded a lower FDR in comparison to the features selected by the apriori algorithm and all twenty-four features. Considering the results obtained from Tables 3 and 4, it is evident that, genetic algorithm performs extremely well with random forest as classifier. Thus, four features obtained from the genetic algorithm have successfully classified more number of VAG signals into normal and abnormal classes using random forest.

From Tables 3 and 4 it is clear that LS-SVM performed much better with respect to random forest in terms of accuracy. The accuracy of LS-SVM using six features selected from the apriori algorithm with 94.31% was highest among other results. The proposed methodology would enable the instrument designer to design a highly accurate instrument. This feature selection technique can be applied to biomedical system as well.

@&#DISCUSSION@&#

VAG signals are characterized by multi-component, nonstationary and nonlinearity. The conventional signal processing techniques are not suitable for the analysis of VAG signal. The main objective of this paper is to enhance the classification accuracy by distinguishing abnormal signals from normal ones for diagnostic purposes. In the present work, we have proposed a wavelet decomposition based feature extraction and classification techniques for classifying the normal and abnormal VAG signals. Initially the original VAG signals were subjected to a wavelet decomposition into sub-band signals. Feature extraction based on nonlinear methods, i.e., RQA, ApEn and SampEn were computed for the original and sub-band signals distinctly. Additionally, a wavelet-based energy was also extracted. The extracted features from the sub-band signals D2, D3, D4, D5, D6, D7 provided a significant discrimination between normal and abnormal VAG signal than the original VAG signal. These distinction were quite observable from the error plot of SampEn and ApEn, as shown in Figs. 3 and 4 respectively. The proposed methodology characterized a VAG signal with twenty-four features.

Another important task for designing a low computing system is to develop a highly sensitive classifier with a low false detection rate. Since wavelet based feature extraction had extracted twenty-four features. Most of theses extracted features are irrelevant and redundant. Thereby, these features will not contribute in improving the classification model. Thus, feature selection algorithm contributes in selecting the most significant, relevant and stable features. And thus, the feature selection algorithm has improvised the classification accuracy.

Apriori algorithm and genetic algorithm were used as feature selection techniques. Six features were selected using the apriori algorithm, while four features were selected by genetic algorithm. The reluctant features were discarded by genetic and apriori algorithm. This distinction was also evident from Kurskal–Wallies test as shown in Table 2. The selected features were given as input to the proposed classifier algorithms (LS-SVM and random forest) and their performances were compared. The performance of LS-SVM using a feature selection algorithm using the apriori algorithm was highest. When compared to random forest, it gave an accuracy of 94.31% which can be observed from Tables 3 and 4. Results conveyed that, the performance of proposed methodology with apriori algorithm as feature selection algorithm was highest with an accuracy of 94.31% using the apriori algorithm.

The results obtained were also compared with the previous literature studies using the same set of data-set as shown in the Table 5
                     . The performance of the proposed LS-SVM method with feature selection algorithm using apriori algorithm is superior to the fluctuation feature which uses kernel density modeling with input parameters fractional scaling index and average envelope amplitude (Accuracy=88%, SEN%71.43%, SPE: 85.11%) [9]. The results of the proposed method are also compared with the k nearest neighbor classifier (k
                     =5) with features as form factor and variance of mean squared (VMS) (Accuracy=80%, SEN%71.43%, SPE: 85.11%) [6]. It also performed better when compared to the radial-basis function neural network using form factors, skewness, kurtosis and entropy features (ROC-AUC: 0.8172) [38]. From the table it is evident that the proposed wavelet based feature extraction along with feature selection algorithm using apriori provided the better classification accuracy and ROC-AUC.

This work was quite restricted for classification of normal and abnormal VAG signals only. The higher accuracy obtained from our methodology could provide an aid to establish a standard protocol for the discrimination and early stage detection of knee pathologies using the VAG signals. Thereby, developing a low cost based computer aided diagnosis (CADx) tool for knee joint disorders. This work could be further directed in classifying the various extent of knee joint disorders. This diagnosis could provide physician a benefit in clinical application.

@&#CONCLUSION@&#

In this paper, a new feature extraction technique based on wavelet decomposition has been proposed. The proposed methodology could provide a highly accurate diagnostic system for the non-invasive diagnosis and monitoring of knee joint disorders. Nonlinear features were able to differentiate much more effectively between normal and abnormal VAG signal. The differences were more pronounced in the sub-band signals (D2, D3, D4, D5, D6, D7). The proposed methodology characterizes twenty-four features for a VAG signal. Hence, to discard the irrelevant and redundant features, two feature selection algorithms were considered to select the most significant, relevant and stable features. The performance of the feature selection algorithm was evaluated by two classifiers. The results verified that the performance of the feature selection algorithms were superior to all twenty-four features in terms of accuracy and other parameters. Classifying parameters such as sensitivity, specificity, MCC, etc. also validated a higher performance of LS-SVM in comparison to random forest. The results obtained also provided much better performance in comparison with previous literature. The proposed methodology in our works could find a potential application in the knee-joint pathology for early detection and monitoring.

None declared.

@&#ACKNOWLEDGMENT@&#

The authors are extremely grateful to Prof. Rangaraj M. Rangayyan, Dr. Cyril B. Frank, Dr. Gordon D. Bell, Prof. Yuan-Ting Zhang and Prof. Sridhar Krishnan of University of Calgary, Canada for the work of data acquisition.

@&#REFERENCES@&#


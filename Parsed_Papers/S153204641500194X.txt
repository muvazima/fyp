@&#MAIN-TITLE@&#An automatic system to identify heart disease risk factors in clinical texts over time

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We proposed a hybrid system to automatically identify heart disease risk factors.


                        
                        
                           
                           We divided different types of risk factors into three categories according to their descriptions.


                        
                        
                           
                           Our system achieves an F-score of 92.86% on 2014 i2b2 corpus, which is top-ranked.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Risk factor identification

Clinical information extraction

Heart disease

Machine learning

@&#ABSTRACT@&#


               
               
                  Despite recent progress in prediction and prevention, heart disease remains a leading cause of death. One preliminary step in heart disease prediction and prevention is risk factor identification. Many studies have been proposed to identify risk factors associated with heart disease; however, none have attempted to identify all risk factors. In 2014, the National Center of Informatics for Integrating Biology and Beside (i2b2) issued a clinical natural language processing (NLP) challenge that involved a track (track 2) for identifying heart disease risk factors in clinical texts over time. This track aimed to identify medically relevant information related to heart disease risk and track the progression over sets of longitudinal patient medical records. Identification of tags and attributes associated with disease presence and progression, risk factors, and medications in patient medical history were required. Our participation led to development of a hybrid pipeline system based on both machine learning-based and rule-based approaches. Evaluation using the challenge corpus revealed that our system achieved an F1-score of 92.68%, making it the top-ranked system (without additional annotations) of the 2014 i2b2 clinical NLP challenge.
               
            

@&#INTRODUCTION@&#

Heart disease attracts much attention, given its history as the number one cause of death in both women and men throughout the world [1]. Several factors have been identified as risks related to heart disease, including hyperlipidemia, hypertension, obesity, and smoking status. In order to predict and prevent heart disease, it is necessary to first identify risk factors embedded in unstructured clinical documents. Over the last decade, many studies have been undertaken to identify these risk factors, resulting in the creation of publicly available tools, such as clinical Text Analysis and Knowledge Extraction System [2], an open-source tool capable of identifying smoking status. However, no study has investigated the identification of all risk factors associated with heart disease, possibly due to the diversity of their clinical descriptions.

Heart disease is often related to other diseases, such as diabetes, that share several observable characteristics, including obesity and smoking status, as well as some medications, such as metoprolol. All of these were regarded as heart disease risk factors for this study.

The main challenge in identifying all heart disease risk factors is that they are presented in a variety of forms in clinical texts. To comprehensively investigate the identification of all heart disease risk factors, the National Center of Informatics for Integrating Biology and Beside (i2b2) issued a risk factor identification track (track 2) in the clinical natural language processing (NLP) challenge in 2014 [3]. The goal was to identify information medically related to heart disease risk and track its progression over sets of longitudinal patient medical records. We participated in this track and developed a hybrid pipeline system based on both machine learning and rule-based approaches.

In our system, all heart disease risk factors were divided into three categories according to their descriptions, with each category identified individually. Evaluation using the challenge corpus revealed that our system achieved an F1-score of 92.86%, making it the top-ranked system (without additional annotations) for the 2014 i2b2 clinical NLP challenge.

@&#RELATED WORK@&#

The heart disease risk factor identification track of the 2014 i2b2 clinical NLP challenge consisted of two subtasks: risk factor extraction and time attribute identification. To the best of our knowledge, no study has ever been specifically designed for heart disease risk factor identification, although many related studies have been proposed. The most closely related study by Roy et al. developed a hybrid NLP pipeline system to extract Framingham heart failure criteria with time attributes from electronic health records [4].

Heart disease risk factor extraction is a typical information extraction task related to clinical concept recognition [5–9], phenotyping [10], smoking status identification [11–15], obesity identification [16,17], etc. clinical concept recognition is a named entity recognition (NER) task that extracts all problems, treatments, and tests, where problems include diseases and observable characteristics and treatments include medications. The most representative work concerning clinical concept recognition is the 2010 i2b2 clinical NLP challenge, where various machine learning-based, rule-based, and hybrid methods were proposed [18–20]. Phenotypes that include diseases and some observable characteristics have also been widely investigated. Chaitanya et al. summarized approaches for phenotyping [10]. The i2b2 clinical NLP challenges in 2006 and 2008 involved a track on smoking status identification and a track on obesity identification, respectively. The best system for smoking status identification used a method based on support vector machines (SVMs) [21], whereas the best system for obesity identification combined dictionary lookup, rule-based, and machine learning-based methods [17].

The time attribute of each heart disease risk factor represents the relationship between risk factor and the corresponding document creation time (DCT), which is similar to the temporal relationship between a clinical event and DCT in the 2012 i2b2 clinical NLP challenge [22], except that the value of the time attribute can be any combination of {“before”, “during”, or “after”} rather than a single variable consisting of {“before”, “during”, “after”}. Most state-of-the-art systems presented for the 2012 i2b2 clinical NLP challenge used machine learning-based methods to extract relationships between events and DCT [23,24]. For example, the best system proposed by Tang et al. adopted SVMs [23].

@&#MATERIAL AND METHODS@&#

The i2b2 challenge organizers manually annotated longitudinal records of 300 patients (1304 documents), from which 180 patients (790 documents) were used as a training set and the remaining 120 patients (514 documents) were used as a test set. The annotation guidelines defined a set of tags to indicate the presence and progression of diseases (diabetes, heart disease), associated risk factors (hyperlipidemia, hypertension, obesity status, family history, and smoking status), and associated medications. Each tag for the diseases and associated risk factors had one indicator value from its own set, while each tag for the associated medications could have two indicators (denoted by “type1” and “type2”) to identify its category.

A brief description of each tag type in the challenge data is presented in Table 1
                        . For more information, please refer to the annotation guidelines [25]. The challenge organizers released the data in two versions: complete and gold. The former provides the evidence (if any exists) for each tag and is used for system development. The latter only provides each tag itself without any evidence and is used for system evaluation.


                        Fig. 1
                         shows an example of a tag extracted from sample data (321-03.xml) in both versions, where the evidence associated with the tag is listed in the “text” field.

Our system identified each type of tag in the following order:
                           
                              1.
                              Extract evidence (if any exists) by type and indicator.

Determine attribute (i.e., time, if it exists).

By analyzing the evidence of tags, we found that the tags mainly fell into the following three categories:
                           
                              1.
                              Phrase-based tags, the evidence for which is provided explicitly in phrases.

Logic-based tags, the evidence for which is provided explicitly in phrases/sentences, but needs additional logical inferences, such as numerical comparisons.

Discourse-based tags, the evidence for which is not provided explicitly, but is embedded in clinical text fragments.


                        Table 2
                         lists these three categories of evidence-based tags, where the evidence is marked in bold and italics, followed by their tags in parenthesis. The evidence associated with phrase- and logic-based tags are very similar, with the difference being whether logical inference is further required after the phrases are located. For example, the blood pressure (BP) measurement “BP 140/80” is evidence of hypertension due to a high systolic pressure of 140 (Fig. 1). If the BP measurement of a patient is 120/80, “BP 120/80” will not qualify as evidence. Each tag listed in Table 1 may belong to multiple categories mentioned above based on the associated evidence and distinguished by its indicator(s).

The relationships between tag types listed in Table 1 and tag categories listed in Table 2 are shown in Table 3
                        , where each item indicates to which category a tag with an indicator belongs.

For example, a case of hypertension with a “mention” constitutes a phrase-based tag, while a case of hypertension associated with another indicator constitutes a logic-based tag, as observed in the example from Fig. 1. The proportions of the phrase-,logic-, and discourse-based tags in the training set are 85.33%, 8.10%, and 6.57%, respectively.

After all tags were mapped into the three categories in Table 2, we proposed a unified framework for each category. Fig. 2
                         shows an overview of our system consisting of six components: a preprocessing module, three tag extraction modules, a time attribute identification module, and a post-processing module.

Given a raw data file containing clinical text, the preprocessing module first performed sentence boundary detection and tokenization. Then the three tag extraction modules extracted evidence of tags from the three categories in Table 2 and determined their type and indicator. Subsequently, the time attribute identification module determined the time attribute of each piece of evidence (if any exists). Finally, the post-processing module converted the tags from the complete version into those from the gold version for evaluation. We used the tokenization module from MedEx [26],
                           1
                           
                              https://code.google.com/p/medex-uima/downloads/list.
                        
                        
                           1
                         a specific tool for medical information extraction, for sentence boundary detection and tokenization. The tag extraction modules and the time attribute identification module are described in detail in the following sections.

Extracting evidence of the phrase-based tags was treated as a NER task in our system. Each piece of evidence was represented by BIOES tags, where B, I, O, and E denote that a token exists at the beginning, middle, outside, or end of a piece of evidence, respectively, and S denotes that the token itself forms a piece of evidence. As an example of evidence from the phrase-based tag in Table 2, the sentence “Continue 
                           beta blocker, CCB
                        ” was labeled as “Continue/O; beta/B-medication_beta+blockers; blocker/E-medication_beta+blockers; ,/O; CCB/S-medication_calcium-channel+blockers”, where “medication” is a type of tag and {“beta blockers”, “calcium-channel blockers”} are two indicators of this type of tag. It should be noted that for those medications with two indicators, we only considered the first one (type1).

In this study, we developed an ensemble system for phrase-based tag extraction. The system first used conditional random fields (CRFs) [27] and structured SVMs (SSVMs) [28] to extract evidence from clinical notes individually and then returned the union of their results directly without any treatment of overlapping evidence. The features used in these two base classifiers included bag-of-words, part-of-speech (POS) tags, combinations of tokens and POS tags, sentence information, affixes, orthographical features, word shapes, section information, general NER information, word representation features, dictionary features, and negation information. Except for the dictionary features and negation information, all remaining features were similar to those used in our de-identification system for that challenge [29]. Here, we only introduced word shapes, section information, dictionary features, and negation information. For other features, please refer to our paper for de-identification [29].
                           
                              1.
                              Word shapes. We used two typical types of word shapes: one is generated by mapping any uppercase character, lowercase character, digit, or other character in the word to ‘A’, ‘a’, ‘#’, or ‘–’, respectively, while the other is generated by mapping consecutive uppercase characters, lowercase characters, digits, or other characters to ‘A’, ‘a’, ‘#’, or ‘–‘, respectively. For instance, the two types of word shapes for “PO/5mg” are “AA-#aa” and “A-#a”.

Section information. We extracted 29 section headers, such as “family history”, from the training set and determined to which section the word belonged.

Dictionary features. We extracted a heart disease-related drug dictionary from DrugBank [30],
                                    2
                                    
                                       http://www.drugbank.ca/.
                                 
                                 
                                    2
                                  found all drugs mentioned in the clinical text using dictionary lookup, and checked each token against any drug that we found. For each DrugBank record, we first checked whether it was heart disease-related according to the “name”, “synonyms”, “brands”, and “description” fields. If any medication indicator was mentioned in the “description” field or any medication evidence appeared in the other three fields, this record was regarded as a heart-disease-related record. We then extracted the “name”, “synonyms”, and “brands” fields of every heart-disease-related record as drug names and the corresponding indictor as the type associated with the drug names. No other dictionary was used in our system outside of this heart-disease-related drug dictionary.

Negation information. In order to determine the presence of any negative words in a given sentence, we used the negative word list from NegEx [31].
                                    3
                                    
                                       https://code.google.com/p/negex.
                                 
                                 
                                    3
                                 
                              

We first defined two criteria for extracting evidence of logic-based tags and then filtered them by polarity and sentence type. The criteria used for our system included:
                           
                              1.
                              Numeric constraints: Find all numerical evidence, such as “LDL measurement of over 100mg/dL”, which constitutes evidence of hyperlipidemia with high LDL as determined by “LDL>100mg/dL”. Each category of logic-based tags contains numerical evidence similar to this.

Co-occurrence constraints: Find all evidence determined by multiple keywords, such as “Early-onset CAD in mother”, which constitutes evidence of family history as determined by “early, CAD, mother”. Only evidence of family history tags were extracted using this criterion in our system.

For the evidence extracted, we removed those in negative or subjunctive mood. The negation information of evidence was determined using NegEx [31] and the subjunctive mood was determined using manually defined rules.

Given that evidence from discourse-based tags is not explicit, it is difficult to extract them directly, unlike the other two tag categories mentioned above. In this study, we first generated evidence candidate sentences with discourse-based tags according to indicator-related words/phrases, such as symptom-related phrases like “unstable angina”, and then checked their indicator-related status using SVMs. Fig. 3
                         illustrates the extraction process.

The features used in the classifier included term frequency–inverse document frequency (TF–IDF) of words, unigrams of words, bigrams of words, negation information of sentences mentioned in the phrase-based tag extraction module, and negation information of indicator-related words/phrases determined by NegEx. It should be noted that the negation information of words/phrases was used in the logic- and discourse-based tag extraction subsystems, while the negation information of sentences was used in the phrase-based subsystem. This is because target words/phrases have been extracted in advance in the logic- and discourse-based tag extraction subsystems, but they have not in the phrase-based subsystem.

Time attribute identification is actually temporal-relationship extraction for evidence and DCT pairs, which can be recognized as a classification problem similar to the previous study for the 2012 i2b2 challenge [22]. As the temporal relationship between a piece of evidence and DCT in this challenge can be any combination of {“before”, “during”, or “after”}, the time attribute identification problem is a multi-label classification problem. In this study, we used the label-powerset strategy [32] to convert the multi-label classification problem into a single-label classification problem and applied SVMs toward solving it. The features of a piece of evidence used for time attribute identification included TF–IDF of words, unigrams of words, bigrams of words, evidence tag type, evidence indicator, and temporal relationship between the evidence-related time and DCT. The evidence-related time was the temporal expression nearest to the evidence, such as “yesterday” and “2061/08/20” (a fictional date used for de-identification) in our system. The evidence-related times and DCT were extracted using customized NorMA [33],
                           4
                           
                              http://www.cs.man.ac.uk/∼filannim/.
                        
                        
                           4
                         which is a rule-based temporal-expression normaliser for clinical texts.

@&#RESULTS@&#

We used SVM
                        hmm
                     ,
                        5
                        
                           http://www.cs.cornell.edu/people/tj/svm_light/svm_hmm.html.
                     
                     
                        5
                      libshortText
                        6
                        
                           http://www.csie.ntu.edu.tw/∼cjlin/libshorttext/.
                     
                     
                        6
                      and CRFsuite [34] as the implementations of SSVMs, SVMs, and CRFs, respectively, and optimized parameters of all classifiers using 10-fold cross-validation on the training set.

Our system was evaluated using the evaluation script provided by the challenge organizers that outputs macro-/micro-precision, -recall, and -F1-score, of which micro-precision and -F1-score were used as the primary measurements. For this task, a participating team could submit three runs. The results of our best run are reported in this section and shown in Table 4
                     . The best micro-precision, -recall, and -F1-scores were 91.06%, 94.36%, and 92.68%, respectively, while the micro-precision, -recall, and -F1-scores following 10-fold cross-validation of the training set were 89.92%, 92.20%, and 91.05%, respectively. The micro-F1-score of our best run was slightly lower than the best results reported from the challenge (92.68% vs. 92.76%, respectively). Among all tag types, our system did not perform very well for coronary artery disease (CAD), obesity status, and smoking status, with micro-F1-scores of 82.53%, 88.57%, and 88.61%, respectively.

For heart disease risk factor extraction, there were three subsystems: phrase-based, logic-based, and discourse-based, corresponding to the three tag categories from Table 2. To test the contribution of each subsystem, we started with the phrased-based subsystem as a baseline and then added the other two subsystems gradually. The results are shown in Table 5
                     . The SSVM phrase-based subsystem (
                        
                           
                              
                                 Pb
                              
                              
                                 ssvm
                              
                           
                        
                     ) performed slightly better relative to the CRF phrase-based performance (
                        
                           
                              
                                 Pb
                              
                              
                                 crf
                              
                           
                        
                     ) because of higher recall. The performance of combinations of CRF and SSVM phrase-based systems (Pb
                        all
                     ) was superior to any of them individually. When the logic-based subsystem (Lb) was added, the micro-F1-score improved by 2.4%. By adding the discourse-based subsystem (Db), the micro-F-score improved by an additional 2.4%.

To further investigate the performance of our system on each tag category, we compared the performance of each subsystem individually without considering time attribution (Table 6
                     ). Among the three subsystems, the phrase-based subsystem (Pb
                        all
                     ) achieved the highest micro-F1-score (0.9441), higher than both logic- (Lb) and discourse-based subsystems (Db) by 8.79% and 14.95%, respectively, indicating that our system performed best on phrase-based tags relative to logic- or discourse-based tags.

To test the impact of the time attribute identification module, we compared our system to an upper-boundary system that used the same risk factor extraction module as ours and evaluated the return of correct time attributions (based on the gold standard). The micro-precision, -recall, and -F1-scores of the upper-boundary system were 0.9213, 0.9355, and 0.9283, respectively. The F1-score difference between the two systems was 0.15%, indicating that the impact of time attribute identification on the overall performance of our system was minimal.

@&#DISCUSSION@&#

We developed a pipeline system to identify heart disease risk factors from clinical texts over the course of time and participated in Track 2 of the 2014 i2b2 clinical NLP challenge. The task of this track was to identify diseases, risk factors, medications, and time attributes associated with their presentation relative to DCT. Our system first extracted these risk factors, then identified their time attributes. Based on the evidence characteristics associated with each risk factor, we divided the risk factors into three categories and proposed three individual subsystems for each.

Evaluation on the independent test set provided by the challenge organizers revealed that our system achieved promising results with the highest F1-score of 92.68%, which was 0.06% lower than the highest F1-score submitted to the challenge. It should be noted that our system performed comparable to that of the highest-performing system while using fewer annotations.

Although the overall performance was promising, our system did not perform well on several tag types, including CAD, obesity status, and smoking status. For the two tag types that contain a large number of discourse-based tags (CAD and smoking status), the proportion of negative samples (not indicator-related) in evidence candidates of discourse-based tags were very high. For example, the proportion of negative samples related to events was 68.4%. The high proportion of negative samples likely explains the relatively poor results. The obesity status tags account for only 2.4% of the tags in the data sets. Their low frequency makes them difficult to identify because of the class imbalance problem associated with machine learning methods. According to the overall report from the i2b2 2014 challenge, other participating systems experienced similar results related to these three tag types.

Possible reasons why the phrase-based tag extraction subsystem outperformed the logic-based tag extraction subsystem are as follows: we did not define accurate rules according to the evidence present in the training set individually and the rules developed from the training set did not completely cover the evidence present in the test set.

For further improvement, there are three possible directions. First, we can refine rules for logic-based tags. Second, given that the logic-based tag extraction subsystem is completely dependent upon rules, we can try machine-learning-based methods. Third, it is worth trying to integrate medical domain knowledge, such as Unified Medical Language System [35] and Systematized Nomenclature of Medicine-Clinical Terms [36], to avoid generating too many negative samples in the discourse-based tag extraction subsystem by limiting the candidates to those that contain certain concepts of medical domain knowledge.

@&#CONCLUSION@&#

In this study, we developed a hybrid pipeline heart disease risk factor identification system for clinical texts that can identify diseases, associated risk factors, associated medications, and the time they are presented. In our system, all heart disease risk factors were divided into three categories according to their descriptions, with each category identified individually. With this system, we participated in Track 2 of the 2014 i2b2 clinical NLP challenge. Our method achieved a micro-F1-score of 92.68%, which was competitive with other state-of-the-art systems.

None declared.

@&#ACKNOWLEDGMENTS@&#

The authors thank the anonymous reviewers for their valuable suggestions. This paper is supported in part by grants: NSFCs (National Natural Science Foundations of China) (Grant Nos.: 61402128, 61473101, 61173075, and 61272383) and Strategic Emerging Industry Development Special Funds of Shenzhen (Grant Nos.: JCYJ20140508161040764, JCYJ20140627163809422 and JCYJ201417172417105). We also thank the 2014 i2b2 NLP challenge organizers for making the annotated data set available.

@&#REFERENCES@&#


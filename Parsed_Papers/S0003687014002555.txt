@&#MAIN-TITLE@&#Hearing the way: Requirements and preferences for technology-supported navigation aids

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Technology-supported navigation aids can support users with sight problems.


                        
                        
                           
                           Users should have control over cues provided by the technology.


                        
                        
                           
                           The cues provided should be assimilated with the environment.


                        
                        
                           
                           The technology should support the environmental cues rather than replacing them.


                        
                        
                           
                           Information when users are not on the correct path is particularly important.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Blind and partially sighted

Wayfinding

Navigation

@&#ABSTRACT@&#


               
               
                  Many systems have been developed to assist wayfinding for people with sight problems. There is a need for user requirements for such systems to be defined. This paper presents a study which aimed to determine such user requirements. An experiment was also conducted to establish the best way of guiding users between locations. The focus group results indicated that users require systems to provide them with information about their surroundings, to guide them along their route and to provide progress information. They also showed that users with sight conditions interact with systems differently to sighted users, thereby highlighting the importance of designing systems for the needs of these users. Results of the experiment found that the preferred method of guiding users was a notification when they were both on and off track. However, performance was best when only provided with the off track notification, implying that this cue is particularly important. Technology has the potential to support navigation for people with sight problems. Users should have control over cues provided and for these cues should supplement environmental cues rather than replacing them.
               
            

@&#INTRODUCTION@&#

Blind and partially sighted people face difficulty in both navigating through environments and knowing what is in their environment. This can lead to reductions in their mobility, increased danger and decreased independence (Walker and Lindsay, 2006). Previous work has suggested that blind and partially sighted people heavily rely on help from other people in unfamiliar places and face particular challenges in navigation in noisy environments (Saenz and Sanchez, 1990). This suggests that orientation may be aided through the provision of directions along the person's route. In addition, there are instances where sighted people may be unable to use vision to aid navigation due to carrying out other tasks which require sight simultaneously (Walker and Lindsay, 2006).

Location based handheld technologies provide an opportunity to use technology to support navigation using non-visual presentations. This may therefore support blind, partially sighted and sighted users. This paper presents a study that developed some prototype methods to support blind and partially sighted users in a navigation task. The methods were derived using a user requirements exercise that considered technology capabilities and limitations, user preferences and needs and views of experts. The methods were then compared in an experiment that simulated the navigation task of moving from one checkpoint to the next for blind and partially sighted users. On the basis of the findings of this research, the way in which different user needs were met was considered along with any improvements to the prototypes methods and identification of areas for future research.

@&#LITERATURE REVIEW@&#

The population of blind and partially sighted people is on one level a seemingly homogeneous group in that they all, to some degree, cannot access information in the same way that the rest of the population do. However, the underlying story is quite different. Generally speaking no two people with the same eye condition have the same sight level and characteristics. This makes the population of blind and partially sighted people heterogeneous and therefore can be difficult to cater for user needs on an individualistic level. Bradley and Dunlop (2004), highlighted that blind and partially sighted fall into three main groups; total vision loss, central vision loss and peripheral vision loss. Within these categories are many sight conditions including glaucoma, retinitis pigmentosa and macular degeneration (RNIB, 2013a). Individuals suffering from a loss of central vision need to move their head to one side in order to see in their periphery. They also need additional support when reading and performing tasks. Unless treated, the area of central vision loss will increase until the individual cannot see anything (RNIB, 2013b). People who have a loss of peripheral vision, need to move their heads more in order to find things (RNIB, 2013c).

Once individual sight conditions are categorised more broadly into people with low vision (encompassing blind and partially sighted people but have some useful vision) and people with no vision (encompassing blind people who have no useful vision, e.g. can only see light or dark or nothing), solutions that would benefit the users of these two groups become more homogenous. For instance, when considering textual information, those with low vision will, generally speaking, benefit from clear visual information (e.g. large typeface and clear fonts) (RNIB, 2009). People with no vision need to access the same information in an alternative format (e.g. Braille, other tactile information or audio) (RNIB, 2012a). The same may be true of technology-supported navigation systems.

Sighted people use their vision when navigating and this has been suggested to support the development of mental maps (Lahav and Mioduser, 2004). When visual information is not available, other senses, such as hearing and touch, must be used. However, the mapping between a communication using hearing and touch does not always have such an accurate or detailed direct mapping between the user and the environment. Therefore there is a need for research to understand and propose appropriate methods of using non-visual media to communicate spatial information.


                        Strothotte et al. (1995) found that users have a need for information regarding landmarks, topographical information, the user's current location, roadworks, street names and directions. Previous work has suggested that in particular, it may be difficult to articulate descriptions of some environments, for example, irregularly shaped buildings and curving paths (Golledge et al., 1996). In addition, words used to describe spatial configurations (such as ‘near’, ‘around’ or ‘the red building’) may be ambiguous or inappropriate for use when describing environments to blind or partially sighted individuals (Golledge, 1993). An alternative approach of using the clock system (Sanchez, 2009) has been proposed and is consistent with the theory that people with sight problems generally understand spatial configurations with respect to their own bodies (Millar, 1994).

Tactile maps provide users with information regarding the relative locations of objects in space (Ungar, 2000). Maps that provide audio clues to location (e.g. sounds appropriate to the environment, such as the sound of traffic or people) have also been proposed to support understanding of spatial configurations. These have been demonstrated to support the formation of mental maps for blind and partially sighted users (Jacobson, 1998).

The opportunities presented by new technologies to support navigation have also been investigated. The System for Wearable Audio Navigation (SWAN) made use of non-verbal audio to portray information. It was found that the use of beeps was less distracting than speech and also easier to distinguish from environmental sounds (Discovery Channel Canada, 2007). This method used the concept of waypoints to guide users; with beeps increasing in frequency as they were approached. Goulding (2010) also used the concept of waypoints in a visually based system that used a mobile device to represent arches along a route. Walker and Lindsay (2006) proposed the use of a capture radius around waypoints to ensure that users were able to detect them when they were nearby.

The Personal Guidance System (PGS) has also been used to test a number of ways of portraying information to blind and partially sighted users using spatial displays. One study compared the use of non-verbal audio, synthesised speech and/or vibrations which were initiated either from the position of the hand or the torso. It was found that participants were able to complete the tasks faster with auditory cues and generally liked spoken information about the distance to the next waypoint (Loomis et al., 2005). Ertan et al. (1998) also developed a system of navigation which made use of a haptic directional display which was integrated into a wearable vest.

Beacon based technologies such as ORTI (Kemmerling and Schliepkorte, 1998) and RNIB REACT (RNIB, 2012b) have also been developed. These provide information to users about their locations via units which are situated in fixed places. Whist these systems can provide users with context-specific information, the usefulness of such systems has been questioned due to the need for users to be aware of the existence and location of these beacons (Worsfold and Chandler, 2010).

GPS technologies which can support navigation for blind or partially sighted people are also commercially available. These include the Trekker Breeze and the Kapten Plus. The Kapten Plus is voice activated and provides spoken turn-by-turn navigation (RNIB, 2012c). The Trekker Breeze uses speech to provide information about the user's surroundings including road names, junctions, and points of interest. It also allows users to record routes and landmarks and will provide step-by-step journey instructions (Humanware, 2012). Drishti, a research based system, took this one step further by optimising routes based on real-time information. It was designed to select routes based on user preferences as well as dynamic events and obstacles, for example, roadworks or high volumes of traffic. It also warned users of hazards in their locale (Helal et al., 2001).


                        Strothotte et al. (1995) found that users have a preference for information to be provided using synthetic speech rather than non-verbal audio or vibratory cues. Conversely, Holland et al. (2002) found that users were able to use non-verbal sounds to portray information regarding the direction, distance and location of landmarks with respect to the user. Their system used directional audio and trials indicated that users were able to discern the direction of sounds. However, the authors did note the challenges presented by multiple auditory cues that could quite quickly lead to a cluttered audio output. Spatial sound has also been suggested to be useful in allowing users to differentiate between multiple sounds being played simultaneously as well as in series (Brewster et al., 1995). Tran et al. (2000) suggested that in order for the perceived location of a sound to match the target location in the real world it should be: easy to localise and follow; different enough from environmental sounds; easy to hear over other noises; and should not distract or frustrate the user. Although users have been found to more accurately locate directional sound when it is of a higher frequency and relative wide-band, people tend to prefer lower frequency sounds as they are deemed to be less annoying (Tran et al., 2000). This demonstrates that it is important to consider both user preference and performance in developing and evaluating any navigational cues. Earcons, which are abstract sounds that can be used to represent parts of interfaces, have been demonstrated to be particularly effective at grabbing users' attention through changing the rhythm or pitch of a sound or by changing its tempo (Brewster et al., 1995) and so may be useful when providing cues which alert users to hazards and obstructions.

The work presented in this paper consists of two studies. For the first study, a series of focus groups was conducted to develop an understanding of the way in which blind and partially sighted travellers currently complete their journeys and to elicit user requirements for technology-supported navigation aids. This informed both the design of the navigation prototype cues, and also the task conducted within the experimental phase of the work. These requirements were then validated by technology experts, who provided insight into current and future capabilities of mobile technologies, and experts from the Royal National Institute for the Blind (RNIB), who contributed specific knowledge of the way in which visually impaired and blind users complete journeys. In the second study, a small set of prototype navigation aids were tested in a constrained experimental scenario with blind and visually impaired users.

Therefore the aims of the studies were:
                           
                              •
                              Study 1: to elicit user requirements for mobile location-based technologies to support navigation for blind and partially sighted users; and

Study 2: to evaluate some prototype tools that emerged from these requirements in a structured experimental setting.

Three categories of users participated in focus groups: people who were born with sight loss, people who have developed a sight problem and sighted people. Twenty three people participated in the focus groups and each focus group comprised between three and six people. All participants were either RNIB employees or were recruited through a database of RNIB volunteers. Eleven participants were born with sight loss, nine developed a sight problem and three were sighted. None of the participants had any other disabilities. All participants were independent travellers and all participants with sight conditions made use of either a guide dog or a cane. Although figures were not collected, it is estimated, from anecdotal evidence, that approximately 75% of all participants with sight conditions had experience using devices such as a Trekker Breeze or Kapten Plus. The participants were all aged between 26 and 82 with a mean age of 49.1 and a standard deviation of 16.51. Participants were asked to rate their experience using technology on a five point scale (where one was ‘no experience’ and five was ‘very experienced’). The median rating was 4 with an inter-quartile range of 1.

The participants were divided into four focus groups comprising between three and six people. One of these groups was made up of sighted people. The remaining groups were made up of a mixture of participants with regard to severity of sight condition and whether they were born with or had developed these conditions.

For all participants who were not sighted, research materials, including participant information sheets, consent forms and questionnaires were offered in alternative formats (e.g. audio or Braille). The focus groups were semi-structured and aimed to elicit understanding of the nature of cues that could be used, frequencies, as well as the way in which visually impaired people currently plan and navigate journeys. Sample audio cues were provided as described in Table 1
                           . It should be noted that the sounds provided were intended to prompt debate and to determine generic preferences for sounds rather than being examples of exact sounds to be used in a future wayfinding technology. A pilot study was conducted with five people with sight conditions to refine questions and session format. The focus groups were video recorded and the facilitator also made written notes during the sessions.

Data from the focus group was analysed using theme based content analysis (Neale and Nichols, 2001). The comments of the participants are described below, and the requirements summarised in tables at the end of this section.

It should be noted that no differences were found in terms of the categories of participants with sight conditions (i.e. severity of condition and whether the condition was present from birth or had developed). Therefore distinctions are only made between sighted participants and those with sight conditions. Unless otherwise stated, the term ‘participants’ refers to those who were blind or partially sighted.

The participants had a variety of methods of eliciting information in order to plan for journeys before carrying them out. The most common methods amongst the blind and partially sighted participants were speaking to people and using technology such as websites to plan routes. One participant stated that they would:
                                 
                                    “…familiarise yourself as much as you can using tools like the internet and word of mouth, phoning up”. – Participant 20
                              
                           

Another common method was to practise the route with a sighted person before going alone.
                                 
                                    “If I were going to unfamiliar places, I have a test run first so as I've got things to pick out”. – Participant 1
                              
                           

This comment also emphasises the use of waypoints, or landmarks (i.e.“things to pick out”). In contrast to these methods, the sighted participants tended to use maps to plan journeys.

The most common method of obtaining information when carrying out journeys for the blind and partially sighted participants was to ask people. This included members of the public and public transport staff as well as using station escorts to take them from the train to their destination. The use of technology including GPS and announcements on public transport were also used. Some participants made use of environmental cues such as sounds and noting the trajectory of the ground.
                                 
                                    “I can hear the sounds, different sounds between walls, fences and trees and things.” – Participant 9
                              
                           

In familiar locations, the participants also reported that they would use prior knowledge such as landmarks and counting the number of paces between points along the route. One participant commented that:
                                 
                                    “I've got a series of indicators of where I am that will get you to the place safely and easily… I tend to often use number of paces between point A and point B, corners, the end of a railing which has got some bushes on it, kerb…” – Participant 12
                              
                           

The most commonly mentioned navigation aid to use whilst carrying out a journey was the map. Other tools included GPS or asking other people for assistance.

A lack of help from other people was also one of the biggest problems encountered in making journeys for visually impaired people. It was found that people often forget to help having agreed to do so, are unable to help or offer assistance which is not helpful. Examples of unhelpful assistance included people providing incorrect information or directing people as if they could see. A participant said that:
                                 
                                    “The problem with asking people is that…it often doesn't work so you can ask people and they'll simply ignore you and carry on walking, you might ask people and English isn't their first language so you can't actually communicate, you might ask people and they simply don't know…you might ask people and they're willing to be helpful but are actually clueless,…sometimes if it's late at night, there might not be anyone to ask.” – Participant 14
                              
                           

Participants also reported problems with low quality announcements and signage in public transport hubs. Similarly to this, the sighted participants reported that poor signage can make journeys difficult.


                              Orientation, following the direction ‘straight ahead’ and walking in a straight line were also found to be problematic for people with sight loss as well as inconsistencies in their environments such as landmarks which are moved.

When carrying out a journey, the participants stated that it would be helpful if technology could notify them of and accurately pinpoint the locations of landmarks along their journeys. These included bus stops, entrances and exits, road names and crossings. They also reported that they would like information regarding their surroundings. This may include a ‘where am I?’ function, “A where am I button…you might want to know at any particular point exactly where you are” (Participant 2), or a function which allows the users to scan their environment to see what is around them. In addition to this, they said that they would like a system to provide information feeds relating to public transport services and shopping information. They also suggested that the notification of both permanent and temporary obstructions such as roadworks or unexpected objects would be useful.

As the system would guide users to their destination along a set route, the participants suggested that they would want information provided to them about the status of their journey. Suggestions for specific types of information included the distance to the next checkpoint, notification that the users were nearing a specific location and notification that the users were on or off the correct path. When asked what they would expect the system to do if they were veering off the set path, the participants suggested a combination of warning the user, re-routing the user or telling the user what was around them.

Various participants suggested different ways of providing directions to users from a given point. These included the use of compass directions, angles or clock positions. They also suggested methods of keeping the users on a straight path including a numerical system for knowing whether they had deviated to the left or the right and the distance they were from the path and the use of beeps which changed in pitch in order to determine which side of the path the user was standing.

The sighted participants also suggested that route status information, information feeds and information about their surroundings would be useful. They stated that they would expect a system to re-route them or warn them if they deviated from the set route.

Both the sighted participants and those who were blind or partially sighted requested that a system would allow them to change the preset routes. Some participants were also keen for a system to learn the routes that users took while they were walking. Others preferred the idea of manually inputting or adjusting routes. They also stated that they would either like to manually input points of interest or to ask the system to remember where they were.

The participants requested that they could change the amount of information that is provided to them depending on the nature of the journey that they are taking, stating that:
                                 
                                    “It would be useful to be able to switch from minimum to maximum information; maximum where you're in an area that you're not sure about, minimum where you're in an area that you absolutely know and you only want the basic facts.” – Participant 8
                              
                           

It was also requested that the sounds should be customisable and that they should be able to change the volume of the system or mute it. Where speech is used, this should also be customisable in terms of voice, speech speed and language. The participants also suggested that the system could change the routes it provides based on user preferences such as avoiding certain types of road or levels of strenuousness.

When asked where they would expect the system to be used, the visually impaired participants reported that they would like it to be usable in any environment which they might be in. This could include both urban and rural areas and both indoor and outdoor environments. Conversely, the sighted participants said that they would only want to use such a system in outdoor, urban environments as they would make use of signage when indoors and ordnance survey maps when in rural environments.

The most preferable methods of providing users with sounds were either through a single earpiece or through the use of a speaker. The participants stated that they would not like to use stereo headphones:
                                 
                                    “To have two headphones and be blind in the street isn't a great move” – (Participant 5)
                              
                           

When asked whether they would prefer the information to be presented in an audible or a tactile way, the participants' opinions differed. Some reported that they would prefer tactile information whilst others said that different vibrations may be hard to discriminate from one another and may be difficult to detect. When the participants were asked whether they would prefer continuous signals, discrete signals triggered by events in the environment or discrete signals triggered by the user, most participants stated that they would prefer discrete signals, making comments such as:
                                 
                                    “You can't have one that's going on all the time because that would get on your nerves after a bit” – Participant 4
                              
                           

In addition to this, many participants said that they would like to be in control of the signals and that they should be triggered by user inputs.

Both the participants with sight conditions and those with sight reported that they would feel confident using the system if they perceived it to be accurate in terms of getting the user to their destination and using up to date sources of information.

Many participants associated bell-like sounds with arriving somewhere or with alarms. It was felt that higher tones would be easier to hear over environmental noise however, lower tones were preferred. Longer tones were often associated with warnings, danger and errors.

The participants felt that it was important that any sounds provided were audible over any ambient sound. However, they also felt that it was important that the use of audio did not prevent them from hearing environmental noise, making comments such as:
                                 
                                    “…something that doesn't block out your ambient hearing because you are dependent on that” – Participant 7
                              
                           

It was suggested that speech should be used for details such as names of places or streets and non-verbal sound should be used for generic features such as predefined landmarks or arrival at a checkpoint. One participant gave the example of:
                                 
                                    “If you're interested in bus stops and you just want to know that you're passing a bus stop…you might just want the sound but as soon as you want to know, ‘is it the number two or the number eight?’, you want speech” – Participant 5
                              
                           

The sighted participants reported that they would not make use of audio and would prefer a system which vibrated as a notification that they needed to look at the device to carry out an action.


                           Tables 2–4
                           
                           
                            summarise the results of the focus groups from the perspectives of the participants who were blind or partially sighted. The results from those participants are not summarised in these tables.

It is acknowledged that the demographic of the blind and partially sighted participants is not necessarily representative of the wider target population. Whilst some participants were elderly, the average participant age was substantially younger than the average age of the blind and partially sighted population. With this difference in age, also comes a difference in terms of a lack of other age-related impairments such as loss of hearing. In this study, there was a lack of consensus as to whether blind and partially sighted people would prefer auditory or tactile information. However, if the participants were more representative of the target population, it is possible that the preferred method of information retrieval may differ (e.g. tactile information). The responses by those participants who were older or less familiar with technology indicated that although the preferred sensory modality through which the information is retrieved may differ, the types of information required would remain the same.

Four experts were consulted following the focus groups. Two were people with technical knowledge and expertise and two were experts from the RNIB with extensive experience using or evaluating existing assistive navigational technology. In order to prompt discussion, the experts were provided with a list of user requirements which had been produced following the analysis of the data obtained from the user focus groups.

The technical experts were asked to give specific feedback on requirements with the aim of determining whether the current capabilities of technology were able to fulfil these requirements. They confirmed that all suggested approaches were feasible either now or would be in the near future.

It is noted that a mixed method approach where observations were carried out in a field context would have been advantageous. However, due to time and budget constraints, rather than carrying out such observations, experts from RNIB with experience in the field of navigation and wayfinding were consulted. These experts were emailed a list of requirements and independently provided written feedback which was then discussed verbally.


                           Tables 5–12
                           
                           
                           
                           
                           
                           
                           
                            detail the requirements elicited from the user focus groups and expert consultations along with whether they are deemed to be essential or desirable and which source the requirement was obtained from. The requirements were classified as essential or desirable. The classifications were decided based on three factors:
                              
                                 1.
                                 the number of participants who suggested the requirement

the importance placed on the requirement by the participants

examination of the risk to the user if the requirement was not implemented in a future system (e.g. if a user is not notified if they are no longer on the correct path, they could continue walking in the wrong direction without knowing that this was the case)

Consultation also occurred with two members of RNIB staff with extensive experience of working with people with sight conditions in the field of navigation and wayfinding. These experts also have extensive experience of using existing navigational technologies designed for blind and partially sighted people and so were able to use this tacit knowledge when assessing the requirements. These experts independently assessed the requirements and were then brought together to discuss any conflicts.

The requirements concur to some extent with those elicited during the MOBIC study (Strothotte et al., 1995; Gill, 1997) with particular emphasis on the types of information which are required by blind and partially sighted travellers. However, there were also differences, in particular with regard to the use of speech in comparison to non-verbal audio and tactile cues. These requirements formed the basis of the elements that were then tested in study 2.

It should be noted that these requirements were derived through focus groups with blind and partially sighted people who were all independent travellers. The requirements for people who are currently not independent travellers but who have the potential to become independent travellers with improved technology may differ. Further investigation would need to take place to refine or validate these requirements for this user group.

The aim of the experiment presented in this paper was to determine the most effective timing of notifying users whether they were walking on the set path when walking in a straight line between two points. All notifications were auditory. The four conditions compared were:
                           
                              •
                              using a white cane or guide dog if the user normally does so; without any additional cues;

using a white cane or guide dog and providing sounds to notify the users if they are off track;

using a white cane or guide dog and providing sounds to notify the users if they are on track; and

using a white cane or guide dog and providing sounds to notify the users if they are on and off track.

As a result of the focus group finding that methods of interaction with a navigational device would differ for sighted users and those with a sight condition, the user trials only made use of blind and partially sighted participants. Eight blind or partially sighted people participated in the study. All participants were recruited through a database of RNIB volunteers. All participants were aged between 37 and 73 (with a mean age of 48.13 and a standard deviation of 10.78) with no additional disabilities. All were independent travellers and it is estimated, from anecdotal evidence, that approximately 75% of all participants had experience using devices such as a Trekker Breeze or Kapten Plus. Participants rated their experience using technology with a median rating of 4 (IQR = 1) where 1 was ‘no experience’ and 5 was ‘very experienced’. Table 13
                         summarises the participant demographics.

All participants who used a mobility aid while carrying out the experiment used a long cane. It is acknowledged that this sample size is relatively small (power of 0.69 as opposed to the 15 participants that would be required to achieve a power of 0.80). This small sample size was a result of time and budget constraints.

The study was carried out in a large, empty room. Whilst it is acknowledged that carrying out this study in an indoor environment lacks ecological validity, this location enabled the experimenters to control for confounding variables such as background noise or other distractions which would be present in an outdoor location.

The room was laid out such that there were four identical straight paths, along which the participants would be required to walk. These paths were nine metres in length and were spaced a metre apart from each other in the room. A chair was placed at each end the paths so that the participants would be able to determine the start and end points of the route. Sounds were played using an mp3 player and speakers. A foot mounted inertial system was used to provide accurate data relating to the position of the participants with respect to their starting location. A grid was also marked out on the floor with masking tape to assist with determining path deviation during latter video analysis. It was not possible to feel the grid with a long cane. Participants did not use guide dogs in the study (and were recruited on this basis) due to confounding factors which were highlighted during piloting this study with guide dog users. The most important of these factors was that a guide dog is trained to avoid obstacles such as the chairs which were used as markers of the start and end points of a walking route.

The experiment was of a within subjects design. In order to mitigate the potential for learning effects impacting on the data collected, the order of presentation of each condition was counterbalanced using a 4 × 4 Latin square design.

@&#PROCEDURE@&#

Initially, the participants were asked to complete a consent form and a pre-trial questionnaire consisting of classification data (e.g. age, gender, level of sight, length of time that the participant had experienced sight loss, experience using technology).

It was then explained to the participants that they would be required to walk to a specific chair which was somewhere on the marked grid area and that they would be allowed to use a white cane or guide dog if they normally use one. They were told that they would be asked to do this four times along four different routes. One task would be carried out without any additional aids and three tasks with different sets of sounds to help guide them. They were told that they should aim to follow the audio signals as accurately as possible and not attempt to reach their destination as quickly as possible. When the participants were provided with sounds, a stop sound was played at a point along the route in order to determine whether or not they were listening and reacting to the sounds. The sounds provided are described in Table 14
                        :

These sounds were selected to represent ideas that had received support in terms of meaningfulness or pleasantness in the requirements elicitation exercises. They were also chosen to examine a range of different types of prototype sounds that might be used in an audio based navigation system.

Before each condition, the participants were given time to practise using the sounds. They were allowed to practise using these sounds until they felt proficient in their use in terms of ability to distinguish them and understand their meanings. It was decided to train participants in this way rather than for a predefined amount of time so as to be representative of practising using new equipment in the home. Training participants for a standard amount of time would allow for a comparison of how easy it was to learn to use sounds for navigation. This study did not aim to do this but rather aimed to understand the most effective times at which participants require notification of where they are relative to the set route. Therefore, it was decided to allow participants to reach a standard level of proficiency before completing the task.

Following each condition, the participants were verbally administered a questionnaire in order to determine their opinions of each system. Between each task, the participants were guided to their next starting point by taking an indirect route in order to ensure that they did not know where their starting locations were.

A one-way ANOVA (within) was carried out in order to determine the effect of when sounds were presented to the participants on their deviation from the set path. Table 15
                            shows the descriptive statistics for this test.

Examination of variances and skew showed that transformations needed to be carried out due to substantial positive skew and heterogeneity of variance. The transformation applied was a logarithm.

The results of the ANOVA indicated that there was no significant main effect of sound on path deviation (F = 3.595; df = 3, 5; p > 0.05). It is possible that this is due to the large standard deviations. As Fig. 1
                            shows, there appears to be some difference between the participants' performances across the tasks. It appears that the mean path deviation was much greater when no sounds were provided but this was not found to be statistically significant.

When looking at the results of individual participants, it was found that there were considerable differences in their mean path deviations and this may explain why the ANOVA indicated that there was no significant difference. Looking at the path deviation data for each individual participant, it can be seen that the average path deviation was consistently low when sounds were provided when the participants were both on and off the set path. Fig. 2
                            shows the path deviation data for the individual participants.

The participants were asked to rank the four conditions in order of preference. Table 16
                            shows the mean rankings of the conditions. A lower number signifies a higher rank.


                           Fig. 3
                            shows the conversion of these mean rankings to an interval scale.

This shows that the preferred method of providing sounds was to notify users when they were both on and off the set path. The least preferred condition was when no sounds were provided. Although the participants preferred to be notified when they were on track only to when they were off track only, these methods of informing the users were relatively close in their rankings.

Following the completion of each task, the participants were asked to rate their agreement to statements on a five point ordinal scale. The results of these questions are presented below. A high score indicates a strong positive response.

A Friedman test was carried out in order to determine the effect of when sound is presented on the participants' ability to understand where they are going. The descriptive statistics for this can be found in Table 17
                            (Fig. 4
                           ).

No significant differences were found between the ratings (χ
                           2 = 4.50; df = 3; p > 0.05).

A Friedman test was carried out to determine the effect of when sounds were presented on the participants' abilities to make corrections using these sounds to get back on track (Table 18
                           , Fig. 5
                           ).

There was a significant difference between the participants' abilities to make corrections using the sounds received across the conditions (χ
                           2 = 7.60; df = 2; p < 0.05). Wilcoxon tests were conducted in order to determine the source of this difference. These found that there were no significant differences between when sounds were presented when off track only and when on and off track (W = 1; N = 2; p > 0.05) and when on track only and when on and off track (W = 2.5; N = 6; p > 0.05). Significant differences were found between when sounds were provided when off track only and when on track only (W = 0; N = 6; p < 0.05). This indicates that the participants felt that they were more able to make corrections when they were notified when they were off track only and less able to do so when they were told when they were on track only.

A Friedman test was carried out to ascertain whether when sounds were provided affected the ease of knowing which way to go. The descriptive statistics for this analysis can be found in Table 19
                            (Fig. 6
                           ).

A significant difference was found between the participants' rankings of the four conditions (χ
                           2 = 10.57; df = 3; p < 0.05). In order to determine the source of this difference, a series of Wilcoxon tests were performed on all six possible pairs of conditions. These tests found that the difference was due to the significant differences between when sounds were presented when the users were on track only and when they were both on and off track (W = 0; N = 6; p < 0.05) and when sounds were presented when they were on track only compared to off track only (W = 2.5; N = 8; p < 0.05). All other Wilcoxon tests resulted in no significant differences. This indicates that the participants felt it was easier to know which way to go when presented with sounds which notified them when they were both on and off track or when off track only and found it most difficult when they were only notified when they were on track.

Analysis of the open-ended questions asked revealed that the majority of the participants preferred to be provided with sounds when they were both on and off track. They felt that this combination of sounds provided a lot of information and was easy to understand with one participant commenting:
                              
                                 “I found that very good. I think for me that would be very useful”
                              
                           
                        

When the participants were provided with sounds when they were on the correct path only, they tended to be confused, disorientated and in some cases stated that they felt panicked. The participants tended to like the sound provided to notify them of when they were on the correct path but some felt that the frequency of the tones was too slow and either caused them to match their walking pace to the tones thereby leading them to walk slower than they usually would or caused confusion.
                              
                                 “The period of silence between the pips was too long…every time there was a pause between one and the next one, my brain was going ‘well is it now off?’ so it made me walk more slowly because I wasn't confident that I might take three steps before I've realised it's off.”
                              
                           
                        

When provided with sounds to tell the users when they were off track, one participant started:
                              
                                 “On two occasions, I didn't correctly identify the sound but when I heard the two sounds together, it was quite clear which one was left and which one was right.”
                              
                           
                        

There were also differences in the interpretations of the ‘move left’ and ‘move right’ sounds between the participants. Some participants said they thought the sounds should indicate that a hard turning was required whilst others interpreted the sounds to mean that a side step was needed. One participant also stated:
                              
                                 “I was struggling to remember whether left meant go left or I was left of track”.
                           
                        

Two participants suggested that the use of continuous sounds might be more effective than discrete ones. One participant also suggested the continuous use of the on track sound with variations in pitch to notify the user that they needed to move left or right and variations in frequency to provide information about the users' proximity to their destination.

One participant suggested that it would be more helpful if the system notified the user when the cane was on the set path rather than the user's body. This participant stated:
                              
                                 “I am used to using a long cane and therefore I tend to use it to tell me information about the environment. It's unfamiliar, therefore, to have my body telling me where I am because normally, if I wait until my body tells me, I've already stepped down the manhole so it's, if you like, counter learnt behaviour. I would be more interested in a device that told my stick where I was rather than my body because, in a sense, by the time the body gets the information, it's too late.”
                              
                           
                        

It was also felt that there needed to be some notification of orientation in a system and simply knowing whether or not the participants were on the correct path was not enough information.

In addition to the questionnaire responses and performance measures, observations were made from the video recordings of the user trials in order to investigate any issues that the participants had. Table 20
                            outlines these issues.

@&#DISCUSSION@&#

This study aimed to determine the most appropriate times to provide users with information regarding their position with relation to a set path in order to keep them on that path. The experiment conducted was made up of four conditions: no sounds provided, sounds provided when the participant was off track only, sounds provided when the participant was on track only and sounds provided when the participant was both on and off track. The participants were required to walk in a straight line between two set points under these conditions.

Analysis of the participants' deviations from the set path revealed that there were no significant differences across the four conditions. However, observations revealed that three participants were naturally able to walk in a straight line more accurately than the other five participants. In addition, one of the participants who was able to walk in a straight line appeared to test the responsiveness of the system by deliberately deviating from the set path. In addition, the three participants who were able to accurately walk in a straight line also had some useful residual vision. These factors, combined with the high standard deviations, which may have been overcome if a larger number of participants were used, may account for the lack of significant differences. When analysing the results of the individual participants, it was evident that for three of the participants with no residual vision, there was a positive effect of the provision of sounds in general on path deviation.

Analysis of the data relating to the participants' rankings of the four conditions found that they tended to prefer sounds to be provided when they were both on and off track. The participants least preferred the condition where no sounds were provided i.e. the way in which they currently navigate. The conditions where information was provided when the users were on track only and off track only were relatively close in their rankings.

It was expected that there may be differences between the participants' abilities to understand where they were going between the conditions. Although the differences were not found to be significant, it was evident that the participants tended to feel less able to understand where they were going when only provided with sounds when they were on track. In addition, the participants reported that they felt disorientated and on some occasions panicked when only provided with this information. Observations also showed that the participants appeared lost, apprehensive and confused under this condition. However, analysis of the participants' abilities to know which way to go found significant differences between the presentation of sounds when the participants were on track only and on and off track and also when sounds were provided when the participants were on track only compared to off track only. This contrasts with the above statistical analysis and indicates that they found it most difficult to know which way to go when only presented with sounds which notified them when they were on the correct path and found this easiest when provided with sounds when they were either off track only or on and off track.

Analysis of the participants' abilities to make corrections using the sounds received to get them back onto the correct path found that significant differences existed. Further analysis found that the participants felt less able to make corrections when only provided with sounds when they were on the correct path and felt most able to make corrections when notified when they were off track only.


                        Figs. 7–10
                        
                        
                        
                         show the paths taken by participant three under each condition. It is evident that this participant was most able to stay on the set path when they were provided with sounds when they were both on and off track. Many participants reported that this condition was the easiest to understand and would be useful. This is backed up by the preference rankings.

It can also be seen from the above diagrams that participant three had difficulty in locating the set path when only provided with sounds when they were on the set path. Observations found that the participants were often confused and disorientated under this condition. It is probable that this was because when no sounds were present, although they knew that they were not on the correct path, the participants had no way of knowing where the path was.

Looking at the path taken by participant three when provided only with sounds when they were off track, it can be seen that although their route centred on the set path, they tended to twist and turn around it. There were differences in the interpretations of the sounds played to signify ‘move left’ and ’move right’ between the participants. Some thought that these referred to a sharp turning whilst others interpreted them to signify side step in either direction. When the participants judged the sounds to indicate that a sharp turning was required, they tended to take routes which were similar to the one pictured above. It is therefore evident that future systems need to consider the orientation of the user when providing signals. It is also essential that the way in which the orientation is determined is considered. The SWAN system made use of a head tracker to determine the user's orientation (Discovery Channel Canada, 2007). Observations from the user trials showed that one participant expected the sounds to be determined by the location of his cane. It is therefore possible that the effectiveness of a system would vary if the direction was taken from the orientation of the user's body compared to their head or even compared to their mobility aid (guide dog or white cane).

The route pictured when no sounds were provided shows that the participant continued walking in an incorrect direction and did not reach the set destination. The participants received no information to notify them of whether their path way correct or incorrect and therefore they were unable to amend their route accordingly.

Considering the sounds which were provided to the participants, it was reported that the ‘on track’ sound was pleasant but the clicks were not frequent enough thereby causing the participants to walk slower than they usually would. Observations indicated a strong preference for the ‘on track’ sound compared to the ‘off track’ sounds. Many participants found it difficult to make absolute judgements of the meanings of the ‘off track’ sounds thereby causing them to move in the wrong direction. These sounds were designed as a family in that they were the same sound which was varied in pitch as suggested by the literature (Brewster et al., 1995; Blattner et al., 1989). However, it was evident that these sounds were not different enough to effectively discern when not presented relative to one another.

During the focus groups, the participants explicitly stated that they would want a system to provide them with discrete signals. However, when provided with these, some participants suggested that the use of continuous sounds would be more effective.

It is acknowledged that this study was carried out in a controlled, indoor environment which lacks ecological validity. Although this is the case, the findings of this study have shown that technology is able to support basic navigation tasks in controlled conditions. It is acknowledged that extraneous factors in field locations may have an effect on the findings. However, findings of the ARGUS project are congruent with those in this study, suggesting that binaural sound can be used to successfully navigate in outdoor environments (Otaegui et al., 2013). For example, ambient sounds may affect the participants' abilities to distinguish the auditory cues. Nevertheless, this study has identified that notification when a user is off a set track is important. It is likely that the effect of ambient sounds would be greater for the design of the specific cues (e.g. more easily distinguishable sounds or tactile information) than for the findings relating to when cues should be provided.

This paper has described a series of studies which were carried out in order to determine requirements for technology to support navigation for blind and partially sighted users and in order to evaluate some prototype tools which emerged from these requirements.

The results of the requirements elicitation study indicated that technology provides an opportunity to support navigation for blind and partially sighted people. It was found that it is important for users to have control over any cues provided by such technology. In addition, the technology should supplement the environmental cues rather than excluding or replacing them.

The data obtained from the second study indicated that there is a trend for users to have a preference when cues are provided when they are both on and off track. Conversely, performance was best when the participants were only provided with off track cues. This implies that the off track cue is particularly important. This also emphasises the importance of adopting a mixed method approach.

The results also highlighted the importance of relative sound comparison in order for users to effectively discern them. It is therefore important for sounds to repeat frequently and to have substantial differences in their characteristics. It is also evident that the value of the sounds provided is in their combinations and patterns rather than in the users' perceptual interpretations or memory of their meanings.

The need for the cues provided by technology to be assimilated with the user's environment was also found to be critical. For example, providing the cue from the location of the user's cane or guide dog rather than the user's position may impact on the system's effectiveness.

It is acknowledged that the studies presented in this paper are not without their limitations. These include the low average age of the participants compared to the average age of the blind and partially sighted population and therefore, a lack of other age-related impairments which are common for this demographic. In addition, all participants were independent travellers and therefore the findings should be treated with caution if applied to those people who do not travel independently. Finally, as the second study was carried out in controlled, indoor conditions, further study should be carried out to validate these findings outdoors.

Technology supported navigation aids have the potential to support blind and partially sighted users in making journeys. A structured approach to selection of appropriate non-visual cues to support navigation is a research priority that will improve the mobility, safety and independence of blind and partially sighted travellers.

@&#ACKNOWLEDGEMENTS@&#

The authors would like to thank Dr. Richard Eastgate from the Human Factors Research Group (HFRG) at the University of Nottingham and Dr. James Goulding from the Horizon Digital Economy Research Hub at the University of Nottingham for their technical advice. We would also like to thank Dr. Chris Hide from the Institute of Engineering Surveying and Space Geodesy (IESSG) at the University of Nottingham for providing access to and support in use of the foot mounted inertial system. The second author is supported by the RCUK Horizon Digital Economy Research Institute (RCUK Grant No: EP/G065802/1). We would also like to thank the volunteers provided by RNIB who participated in our studies.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Similarity-balanced discriminant neighbor embedding and its application to cancer classification based on gene expression data

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           A similarity-balanced discriminant neighborhood embedding (SBDNE) is proposed.


                        
                        
                           
                           SBDNE is applied to cancer classification using gene expression data.


                        
                        
                           
                           SBDNE constructs two adjacent graphs using a new similarity function.


                        
                        
                           
                           Experimental results on six microarray datasets show that SBDNE is promising.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Discriminant neighborhood embedding

Adjacent graph

Gene expression data

Cancer classification

Microarray data

@&#ABSTRACT@&#


               
               
                  The family of discriminant neighborhood embedding (DNE) methods is typical graph-based methods for dimension reduction, and has been successfully applied to face recognition. This paper proposes a new variant of DNE, called similarity-balanced discriminant neighborhood embedding (SBDNE) and applies it to cancer classification using gene expression data. By introducing a novel similarity function, SBDNE deals with two data points in the same class and the different classes with different ways. The homogeneous and heterogeneous neighbors are selected according to the new similarity function instead of the Euclidean distance. SBDNE constructs two adjacent graphs, or between-class adjacent graph and within-class adjacent graph, using the new similarity function. According to these two adjacent graphs, we can generate the local between-class scatter and the local within-class scatter, respectively. Thus, SBDNE can maximize the between-class scatter and simultaneously minimize the within-class scatter to find the optimal projection matrix. Experimental results on six microarray datasets show that SBDNE is a promising method for cancer classification.
               
            

@&#INTRODUCTION@&#

Recently, cancer classification using gene expression data has attracted a lot of attention in microarray data [1–11]. Usually, the gene expression data has only a few dozen sizes but has thousands to tens of thousands of genes among which only a very small fraction of them are informative for cancer classification. As a result, to achieve the analysis and visualization of gene expression data, we have to reduce the dimension of gene expression data. There are two ways to implement dimension reduction of gene expression data, feature selection [5–10] and feature extraction [1–4]. Here, we focus on feature extraction which maps the high-dimensional data into a low-dimensional feature subspace using a projection matrix.

In feature extraction, the most classical methods are principal component analysis (PCA) [12] and linear discriminant analysis (LDA) [13]. Both methods or their variants have been applied to gene expression data [1,5,14,15]. PCA obtains an optimal projection matrix by maximizing the total scatter of training samples. Since PCA aims to optimally represent training samples themselves in an unsupervised way, PCA may not provide a good discriminant projection for classification tasks. LDA can find an optimal discriminant projection matrix by maximizing the ratio of the between-class scatter to the within-class scatter. These projection directions would be of benefit to classification tasks. However, LDA fails to explore the manifold structure of the given data when projecting them into a lower-dimensional subspace and requires the data to obey a Gaussian distribution. Margin Fisher analysis (MFA) [16], an extension of LDA, is able to efficiently solve the drawbacks discussed above. For MFA, the local structure of samples can be preserved by constructing the homogenous and heterogeneous neighbor adjacency graphs, and the optimal projection directions are found by minimizing the ratio of the sum of distance between the samples with the same class and the sum of distance between the samples with the different classes.

PCA and LDA are linear methods, while MFA is a kind of manifold learning methods. It is well known that the classical manifold learning methods are locally linear embedding (LLE) [17], isometric feature mapping (ISOMAP) [18] and Laplacian eigenmap [19]. These methods shows that data may locate in some subspace and the nonlinearly inner structure of data cannot be learned by traditional methods. However, these classical manifold learning algorithms cannot perform mapping for an unseen data, which is also called the out-of-sample problem. To cover this shortage, many new methods have been proposed, such as locality preserving projection (LPP) [20], neighborhood preserving embedding (NPE) [21], and discriminant neighborhood embedding (DNE) [22]. Both NPE and LPP find an embedding to preserve local information and can be simply extended to unseen samples. The main difference between NPE and LPP is that they solve the generalized eigenvalue problem subject to different constraints. Since both LPP and NPE do not make full use of the class label information, they cannot work well in classification tasks. Thus, supervised methods for LPP and NPE have been developed, such as supervised locality preserving projections (SLPP) [23], discriminant locality preserving projection (DLPP) [24], neighborhood discriminant projection (NDP) [25], null space discriminant locality preserving projection (NDLPP) [26], and supervised neighborhood preserving embedding (SNPE) [27]. Different from LPP and NPE, DNE is a supervised manifold learning method itself. In DNE, the adjacency graph is constructed to distinguish between homogenous neighbor points and heterogeneous neighbors to keep the local structure. However, DNE cannot preserve the detailed position relationship between the samples and their neighbors. Thus, the recognition rate in the low-dimensional subspace is not good enough for a particular purpose when the data are unbalanced. Hidden space DNE [28] was developed to be a nonlinear version of DNE by introducing a nonlinear hidden function mapping into DNE. Locality-based discriminant neighborhood embedding (LDNE) was proposed in [29], which is to optimize the difference between the between-class distance and the within-class distance under constructing the adjacent graph being different from DNE and endowing different weights.

The application of manifold learning methods to the gene expression data have been reported in [3,4,30,31]. In [3], an improved supervised orthogonal discriminant projection (SODP) was presented based on LPP for tumor classification. SODP can not only maximize the weighted difference between the non-local scatter and the local scatter but also preserve the locality information of data. Locally linear discriminant embedding (LLDE) was proposed for performing feature extraction on gene expression data [30]. In [31], three discriminant analysis methods: locality sensitive discriminant analysis, spectral regression discriminant analysis, and supervised neighborhood preserving embedding are applied to microarray data classification. For the projected data, we still need a classifier to deal with them. Many methods have been applied to cancer classification, such as naive Bayes classifier (NBC) [32], partial least squares discriminant analysis (PLSDA) [33], support vector Machines (SVMs) [34], kernel sparse representation-based classifier (KSRC) [34], and k nearest neighbor (kNN) [3,4,30,31]. In theory, any existing classifier could be applied to cancer classification. Among these methods, kNN is widely used for its simplicity.

Since DNE-like methods have been successfully applied to face recognition tasks, it is possible to apply them to cancer classification using gene expression data. As far as we know, the possible application has not been reported. Here, we consider the application of a novel DNE algorithm to cancer classification. This paper proposes a new supervised dimension reduction method, called similarity-balanced discriminant neighborhood embedding (SBDNE), for cancer classification using gene expression data. By introducing a new similarity function, SBDNE deals with the between-class data and the within-class data in different ways. The homogeneous and heterogeneous neighbors are selected according to the new similarity function instead of the Euclidean distance. SBDNE constructs two adjacent graphs, or between-class adjacent graph and within-class adjacent graph, using the new similarity function. According to these two adjacent graphs, we can generate the local between-class scatter and the local within-class scatter, respectively. The goal of SBDNE is to find the optimal projection matrix by maximizing the difference between the between-class scatter and the within-class scatter.

The remainder of this paper is organized as follows. Section 2 introduces methods available and proposes the novel algorithm. Simulation experiments are presented in Section 3 and conclusions are provided in Section 4.

@&#METHODS@&#

In this section, we first describe data preprocessing, and then introduce DNE [22] and its variant LDNE [29]. Finally, SBDNE is presented.

DNE-like algorithms are dimension reduction methods for dealing with high-dimensional data and share a common formulation, such as keeping the local structure by means of graph embedding. Given a set of samples 
                        
                           
                              {
                              
                                 (
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                              }
                           
                           
                              i
                              =
                              1
                           
                           
                              N
                           
                        
                     , where sample 
                        
                           
                              x
                           
                           
                              i
                           
                        
                        ∈
                        
                           
                              R
                           
                           
                              d
                           
                        
                     , d is the dimension of samples, 
                        
                           
                              y
                           
                           
                              i
                           
                        
                        ∈
                        {
                        1
                        ,
                        2
                        ,
                        …
                        ,
                        c
                        }
                      is the class label of 
                        
                           
                              x
                           
                           
                              i
                           
                        
                     , c is the number of classes, and N is the number of samples, we try to learn a linear transformation mapping which can project the data in the original d-dimensional space to a new r-dimensional subspace in which the samples are denoted as 
                        
                           
                              {
                              
                                 (
                                 
                                    
                                       v
                                    
                                    
                                       i
                                    
                                 
                                 ,
                                 
                                    
                                       y
                                    
                                    
                                       i
                                    
                                 
                                 )
                              
                              }
                           
                           
                              i
                              =
                              1
                           
                           
                              N
                           
                        
                      with 
                        r
                        ≪
                        d
                     . Specifically, the linear transformation can be defined as
                        
                           (1)
                           
                              
                                 
                                    v
                                 
                                 
                                    i
                                 
                              
                              =
                              
                                 
                                    P
                                 
                                 
                                    T
                                 
                              
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                              i
                              =
                              1
                              ,
                              …
                              ,
                              N
                           
                        
                     where 
                        P
                        ∈
                        
                           
                              R
                           
                           
                              d
                              ×
                              r
                           
                        
                      is the projection matrix.

Since features may be not at the same order of magnitude, we preprocess data to avoid the difference between features. The training samples 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                           =
                           
                              
                                 [
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 …
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       d
                                    
                                 
                                 ]
                              
                              
                                 T
                              
                           
                           ,
                           i
                           =
                           1
                           ,
                           …
                           ,
                           N
                         are normalized to the interval 
                           [
                           0
                           ,
                           1
                           ]
                         according to the following steps. First, we find the maximum and minimum values for each feature. The maximum feature value for the jth feature Fmax
                        
                           j
                         is
                           
                              (2)
                              
                                 F
                                 
                                    
                                       max
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       max
                                    
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       j
                                    
                                 
                                 ,
                                 
                                 j
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 d
                              
                           
                        where x
                        
                           i
                        
                        
                           j
                         is the jth feature of the ith sample 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                        . The minimum feature value for the jth feature Fmin
                        
                           j
                         is
                           
                              (3)
                              
                                 F
                                 
                                    
                                       min
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       min
                                    
                                    
                                       i
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       N
                                    
                                 
                                 
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       j
                                    
                                 
                                 ,
                                 
                                 j
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 d
                              
                           
                        Then 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                         can be normalized by
                           
                              (4)
                              
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                          
                                             j
                                          
                                       
                                       −
                                       F
                                       
                                       
                                          
                                             min
                                          
                                          
                                             j
                                          
                                       
                                    
                                    
                                       F
                                       
                                       
                                          
                                             max
                                          
                                          
                                             j
                                          
                                       
                                       −
                                       F
                                       
                                       
                                          
                                             min
                                          
                                          
                                             j
                                          
                                       
                                    
                                 
                                 ,
                                 
                                 j
                                 =
                                 1
                                 ,
                                 …
                                 ,
                                 d
                              
                           
                        
                     

For an unseen data x, its normalization is also performed using (4). Note that the values of normalized x may be not in the interval 
                           [
                           0
                           ,
                           1
                           ]
                         since F
                        max
                           j
                         and 
                           F
                           
                           
                              
                                 min
                              
                              
                                 j
                              
                           
                           ,
                           j
                           =
                           1
                           ,
                           …
                           ,
                           d
                         are found using the training data.

DNE can form a compact submanifold for the data belonging to the same class in the embedded low-dimensional subspace. Simultaneously, DNE tries to make the gaps among submanifolds for different classes as wide as possible. The procedure of DNE can be described as follows. First, DNE constructs the adjacent graph using k-nearest neighbors. The adjacent weight matrix W can be expressed as
                           
                              (5)
                              
                                 
                                    W
                                    ij
                                 
                                 =
                                 {
                                 
                                    
                                       
                                          +
                                          ,
                                       
                                       
                                          if
                                          
                                          
                                             x
                                             i
                                          
                                          
                                          and
                                          
                                          
                                             x
                                             j
                                          
                                          
                                          are
                                          
                                          neighbors
                                          
                                          and
                                          
                                          
                                             y
                                             i
                                          
                                          =
                                          
                                             y
                                             j
                                          
                                       
                                    
                                    
                                       
                                          −
                                          ,
                                       
                                       
                                          if
                                          
                                          
                                             x
                                             i
                                          
                                          
                                          and
                                          
                                          
                                             x
                                             j
                                          
                                          
                                          are
                                          
                                          neighbors
                                          
                                          and
                                          
                                          
                                             y
                                             i
                                          
                                          ≠
                                          
                                             y
                                             j
                                          
                                       
                                    
                                    
                                       
                                          0
                                          ,
                                       
                                       
                                          otherwise
                                       
                                    
                                 
                              
                           
                        
                     

Then, DNE solves the following optimization problem to find the projection matrix P:
                           
                              (6)
                              
                                 
                                    
                                       min
                                    
                                    
                                       P
                                    
                                 
                                 
                                 tr
                                 (
                                 
                                    
                                       P
                                    
                                    
                                       T
                                    
                                 
                                 
                                    
                                       XLX
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 )
                                 s
                                 .
                                 t
                                 .
                                 
                                 
                                    
                                       P
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 =
                                 I
                              
                           
                        where 
                           tr
                           (
                           ·
                           )
                         is the trace of a matrix, 
                           X
                           =
                           [
                           
                              
                                 x
                              
                              
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 x
                              
                              
                                 N
                              
                           
                           ]
                           ∈
                           
                              
                                 R
                              
                              
                                 d
                                 ×
                                 N
                              
                           
                         is the sample matrix, I is the identify matrix, L=D−W and D is a diagonal matrix with 
                           
                              
                                 D
                              
                              
                                 ii
                              
                           
                           =
                           
                              
                                 ∑
                              
                              
                                 j
                              
                           
                           
                              
                                 W
                              
                              
                                 ij
                              
                           
                        . The optimization problem (6) can be cast into the following generalized eigen-decomposition problem:
                           
                              (7)
                              
                                 
                                    
                                       XLX
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 =
                                 λ
                                 P
                              
                           
                        The optimal projection P consists of r eigenvectors corresponding to the r smallest eigenvalues.

Different from DNE, LDNE adopts the adjacent graph with a heat kernel function instead of (5). Moreover, LDNE tries to find an optimal projection matrix by maximizing the difference between the aggregation of samples with the same class and the divergence of samples with the different classes.

The adjacent graph in LDNE is
                           
                              (8)
                              
                                 
                                    S
                                    ij
                                 
                                 =
                                 {
                                 
                                    
                                       
                                          −
                                          exp
                                          
                                             
                                                
                                                   −
                                                   ∥
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                   
                                                      ∥
                                                      2
                                                   
                                                
                                                β
                                             
                                          
                                          ,
                                       
                                       
                                          if
                                          
                                          
                                             x
                                             i
                                          
                                          ∈
                                          Γ
                                          
                                             
                                                x
                                                j
                                             
                                          
                                          
                                          or
                                          
                                          
                                             x
                                             j
                                          
                                          ∈
                                          Γ
                                          
                                             
                                                x
                                                i
                                             
                                          
                                          
                                          and
                                          
                                          
                                             y
                                             i
                                          
                                          =
                                          
                                             y
                                             j
                                          
                                       
                                    
                                    
                                       
                                          exp
                                          
                                             
                                                
                                                   −
                                                   ∥
                                                   
                                                      x
                                                      i
                                                   
                                                   −
                                                   
                                                      x
                                                      j
                                                   
                                                   
                                                      ∥
                                                      2
                                                   
                                                
                                                β
                                             
                                          
                                          ,
                                       
                                       
                                          if
                                          
                                          
                                             x
                                             i
                                          
                                          ∈
                                          Γ
                                          
                                             
                                                x
                                                j
                                             
                                          
                                          
                                          or
                                          
                                          
                                             x
                                             j
                                          
                                          ∈
                                          Γ
                                          
                                             
                                                x
                                                i
                                             
                                          
                                          
                                          and
                                          
                                          
                                             y
                                             i
                                          
                                          ≠
                                          
                                             y
                                             j
                                          
                                       
                                    
                                    
                                       
                                          0
                                          ,
                                       
                                       
                                          otherwise
                                       
                                    
                                 
                              
                           
                        where 
                           Γ
                           (
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                           )
                         means the set of neighbors of 
                           
                              
                                 x
                              
                              
                                 i
                              
                           
                        , 
                           β
                           >
                           0
                         is a heat kernel parameter, which can be automatically determined by [3]
                        
                           
                              (9)
                              
                                 β
                                 =
                                 
                                    
                                       1
                                    
                                    
                                       kN
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       i
                                       =
                                       1
                                    
                                    
                                       N
                                    
                                 
                                 
                                    
                                       ∑
                                    
                                    
                                       
                                          
                                             x
                                          
                                          
                                             j
                                          
                                       
                                       ∈
                                       Γ
                                       (
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       )
                                    
                                 
                                 ∥
                                 
                                    
                                       x
                                    
                                    
                                       i
                                    
                                 
                                 −
                                 
                                    
                                       x
                                    
                                    
                                       j
                                    
                                 
                                 
                                    
                                       ∥
                                    
                                    
                                       2
                                    
                                 
                              
                           
                        
                     

According to (8), we can obtain the adjacent matrix S. Then, we also need to solve the following optimization problem to find the projection matrix P. Namely
                           
                              (10)
                              
                                 
                                    
                                       max
                                    
                                    
                                       P
                                    
                                 
                                 
                                 tr
                                 (
                                 
                                    
                                       P
                                    
                                    
                                       T
                                    
                                 
                                 
                                    
                                       XHX
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 )
                                 s
                                 .
                                 t
                                 .
                                 
                                 
                                    
                                       P
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 =
                                 I
                              
                           
                        where H=D−S, and D is a diagonal matrix with 
                           
                              
                                 D
                              
                              
                                 ii
                              
                           
                           =
                           
                              
                                 ∑
                              
                              
                                 j
                              
                           
                           
                              
                                 S
                              
                              
                                 ij
                              
                           
                        . The optimization problem (10) can also be cast into a generalized eigen-decomposition problem:
                           
                              (11)
                              
                                 
                                    
                                       XHX
                                    
                                    
                                       T
                                    
                                 
                                 P
                                 =
                                 λ
                                 P
                              
                           
                        The optimal projection P consists of r eigenvectors corresponding to the r largest eigenvalues.

Here, we present similarity-balanced discriminant neighborhood embedding algorithm. As described above, the adjacent graph can be designed in different ways, such as (5) and (8). However, the adjacent graph (5) provides only the information on whether two samples are neighbors or not, and cannot describe the detailed position relationship between the samples and their neighbors. Although the adjacent graph (8) can describe the detailed position relationship between the samples and their neighbors, the between-class scatter could not be maximized when the adjacent graph is unbalanced. Thus, we need to construct two balanced graphs to guarantee that we can maximize the between-class scatter and minimize the within-class scatter at the same time.

Suppose we have the set of training samples 
                              
                                 
                                    {
                                    
                                       
                                          
                                             x
                                          
                                          
                                             i
                                          
                                       
                                       ,
                                       
                                          
                                             y
                                          
                                          
                                             i
                                          
                                       
                                    
                                    }
                                 
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    N
                                 
                              
                            and define a new similarity function between 
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                            and 
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                            as follows:
                              
                                 (12)
                                 
                                    G
                                    
                                       
                                          
                                             x
                                             i
                                          
                                          ,
                                          
                                             x
                                             j
                                          
                                       
                                    
                                    =
                                    {
                                    
                                       
                                          
                                             exp
                                             
                                                
                                                   
                                                      −
                                                      ∥
                                                      
                                                         x
                                                         i
                                                      
                                                      −
                                                      
                                                         x
                                                         j
                                                      
                                                      
                                                         ∥
                                                         2
                                                      
                                                   
                                                   β
                                                
                                             
                                             exp
                                             
                                                
                                                   1
                                                   +
                                                   exp
                                                   
                                                      
                                                         
                                                            −
                                                            ∥
                                                            
                                                               x
                                                               i
                                                            
                                                            −
                                                            
                                                               x
                                                               j
                                                            
                                                            
                                                               ∥
                                                               2
                                                            
                                                         
                                                         β
                                                      
                                                   
                                                
                                             
                                             ,
                                          
                                          
                                             i
                                             f
                                             
                                             
                                                y
                                                i
                                             
                                             =
                                             
                                                y
                                                j
                                             
                                          
                                       
                                       
                                          
                                             exp
                                             
                                                
                                                   
                                                      −
                                                      ∥
                                                      
                                                         x
                                                         i
                                                      
                                                      −
                                                      
                                                         x
                                                         j
                                                      
                                                      
                                                         ∥
                                                         2
                                                      
                                                   
                                                   β
                                                
                                             
                                             exp
                                             
                                                
                                                   1
                                                   −
                                                   exp
                                                   
                                                      
                                                         
                                                            −
                                                            ∥
                                                            
                                                               x
                                                               i
                                                            
                                                            −
                                                            
                                                               x
                                                               j
                                                            
                                                            
                                                               ∥
                                                               2
                                                            
                                                         
                                                         β
                                                      
                                                   
                                                
                                             
                                             ,
                                             
                                             
                                             
                                             i
                                             f
                                          
                                          
                                             
                                                y
                                                i
                                             
                                             ≠
                                             
                                                y
                                                j
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

According to (12), we deal with homogeneous and heterogeneous samples in different ways. Specifically, the homogenous samples are endowed with larger similarity degrees and the heterogeneous ones are endowed with smaller degrees. Fig. 1
                            shows the curves of similarity function 
                              G
                              (
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                              )
                            vs. the Euclidean distance between 
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                            and 
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                           . When two samples 
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                            and 
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                            belong to the same class, the similarity degree rapidly decreases with the increase of their distance. If 
                              
                                 
                                    x
                                 
                                 
                                    i
                                 
                              
                            and 
                              
                                 
                                    x
                                 
                                 
                                    j
                                 
                              
                            are not in the same class, the similarity degree slowly decreases with the increase of their distance. Note that the curve for y
                           
                              i
                           =y
                           
                              j
                            always lies above that of 
                              
                                 
                                    y
                                 
                                 
                                    i
                                 
                              
                              ≠
                              
                                 
                                    y
                                 
                                 
                                    j
                                 
                              
                           . Moreover, the similarity degree in the within-class situates between 0 and e
                           2, but in the between-class the interval changes from 0 to 1 so that the similarity degree in the between-class can be inhibited.

Consider the construction of adjacent graphs according to the new similarity function (12). Our scheme is to select the homogenous neighbors for samples to construct a within-class graph 
                              
                                 
                                    F
                                 
                                 
                                    w
                                 
                              
                           , and their heterogenous neighbors to build a between-class graph 
                              
                                 
                                    F
                                 
                                 
                                    b
                                 
                              
                           . The between-class graph can be constructed by
                              
                                 (13)
                                 
                                    
                                       F
                                       ij
                                       b
                                    
                                    =
                                    {
                                    
                                       
                                          
                                             G
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   ,
                                                   
                                                      x
                                                      j
                                                   
                                                
                                             
                                             ,
                                             
                                             i
                                             f
                                             
                                             
                                                x
                                                i
                                             
                                             
                                             and
                                             
                                             
                                                x
                                                j
                                             
                                             
                                             are
                                             
                                             neighbors
                                             
                                             and
                                             
                                             
                                                y
                                                i
                                             
                                             ≠
                                             
                                                y
                                                j
                                             
                                          
                                       
                                       
                                          
                                             0
                                             ,
                                             
                                             otherwise
                                          
                                       
                                    
                                 
                              
                           Similarly, the within-class graph has the form
                              
                                 (14)
                                 
                                    
                                       F
                                       ij
                                       w
                                    
                                    =
                                    {
                                    
                                       
                                          
                                             G
                                             
                                                
                                                   
                                                      x
                                                      i
                                                   
                                                   ,
                                                   
                                                      x
                                                      j
                                                   
                                                
                                             
                                             ,
                                             
                                             i
                                             f
                                             
                                             
                                                x
                                                i
                                             
                                             
                                             and
                                             
                                             
                                                x
                                                j
                                             
                                             
                                             are
                                             
                                             neighbors
                                             
                                             and
                                             
                                             
                                                y
                                                i
                                             
                                             =
                                             
                                                y
                                                j
                                             
                                          
                                       
                                       
                                          
                                             0
                                             ,
                                             
                                             otherwise
                                          
                                       
                                    
                                 
                              
                           
                        

By respectively building within-class and between-class graphs, each point is able to get the associations with the samples in the same or different classes. In other words, we can get two associations for a point, or the association with the same class and the association with the different classes. The goal of SBDNE is to maximize the difference between the between-class scatter and the within-class scatter. Namely, we need to maximize
                              
                                 (15)
                                 
                                    
                                       
                                          max
                                       
                                       
                                          P
                                       
                                    
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    ∥
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    −
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          x
                                       
                                       
                                          j
                                       
                                    
                                    
                                       
                                          ∥
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          F
                                       
                                       
                                          ij
                                       
                                       
                                          b
                                       
                                    
                                    −
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          ,
                                          j
                                       
                                    
                                    ∥
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          x
                                       
                                       
                                          i
                                       
                                    
                                    −
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          x
                                       
                                       
                                          j
                                       
                                    
                                    
                                       
                                          ∥
                                       
                                       
                                          2
                                       
                                    
                                    
                                       
                                          F
                                       
                                       
                                          ij
                                       
                                       
                                          w
                                       
                                    
                                 
                              
                           The objective in (15) can be rewritten in the following matrix form:
                              
                                 (16)
                                 
                                    
                                       
                                          max
                                       
                                       
                                          P
                                       
                                    
                                    
                                    2
                                    
                                    tr
                                    (
                                    
                                       
                                          
                                             P
                                          
                                          
                                             T
                                          
                                       
                                       X
                                       (
                                       
                                          
                                             D
                                          
                                          
                                             b
                                          
                                       
                                       −
                                       
                                          
                                             F
                                          
                                          
                                             b
                                          
                                       
                                       )
                                       
                                          
                                             X
                                          
                                          
                                             T
                                          
                                       
                                       P
                                       −
                                       
                                          
                                             P
                                          
                                          
                                             T
                                          
                                       
                                       X
                                       (
                                       
                                          
                                             D
                                          
                                          
                                             w
                                          
                                       
                                       −
                                       
                                          
                                             F
                                          
                                          
                                             w
                                          
                                       
                                       )
                                       
                                          
                                             X
                                          
                                          
                                             T
                                          
                                       
                                       P
                                    
                                    )
                                 
                              
                           which can be further reduced to the following optimization problem:
                              
                                 (17)
                                 
                                    
                                       
                                          max
                                       
                                       
                                          P
                                       
                                    
                                    
                                    tr
                                    (
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                    P
                                    )
                                    s
                                    .
                                    t
                                    .
                                    
                                    
                                       
                                          P
                                       
                                       
                                          T
                                       
                                    
                                    P
                                    =
                                    I
                                 
                              
                           where 
                              U
                              =
                              (
                              
                                 
                                    D
                                 
                                 
                                    b
                                 
                              
                              −
                              
                                 
                                    F
                                 
                                 
                                    b
                                 
                              
                              )
                              −
                              (
                              
                                 
                                    D
                                 
                                 
                                    w
                                 
                              
                              −
                              
                                 
                                    F
                                 
                                 
                                    w
                                 
                              
                              )
                           , and both 
                              
                                 
                                    D
                                 
                                 
                                    b
                                 
                              
                            and 
                              
                                 
                                    D
                                 
                                 
                                    w
                                 
                              
                            are diagonal matrices with 
                              
                                 
                                    D
                                 
                                 
                                    ii
                                 
                                 
                                    b
                                 
                              
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                 
                              
                              
                                 
                                    F
                                 
                                 
                                    ij
                                 
                                 
                                    b
                                 
                              
                            and 
                              
                                 
                                    D
                                 
                                 
                                    ii
                                 
                                 
                                    w
                                 
                              
                              =
                              
                                 
                                    ∑
                                 
                                 
                                    j
                                 
                              
                              
                                 
                                    F
                                 
                                 
                                    ij
                                 
                                 
                                    w
                                 
                              
                           , respectively. In order to solve the formulation (17), we give the following theorem. 
                              Theorem 1
                              
                                 If 
                                 U 
                                 is a real symmetric matrix, the optimization problem 
                                 (17) 
                                 is equivalent to the eigen-decomposition problem of the matrix 
                                 
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                 . Assume that 
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          1
                                       
                                    
                                    ≥
                                    ⋯
                                    ≥
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                          −
                                          1
                                       
                                    
                                    ≥
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    ≥
                                    ⋯
                                    ≥
                                    
                                       
                                          λ
                                       
                                       
                                          d
                                       
                                    
                                  
                                 are the eigenvalues of 
                                 
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                  
                                 and 
                                 
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                  
                                 is the corresponding eigenvector of the eigenvalue 
                                 
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                 . Given the dimension of the subspace r, the optimal projection matrix 
                                 P 
                                 is only composed of eigenvectors corresponding to the top r largest positive eigenvalues, or
                                 
                                    
                                       (18)
                                       
                                          P
                                          =
                                          [
                                          
                                             
                                                
                                                   p
                                                
                                                
                                                   1
                                                
                                             
                                             ,
                                             …
                                             ,
                                             
                                                
                                                   p
                                                
                                                
                                                   r
                                                
                                             
                                          
                                          ]
                                       
                                    
                                 
                              

The proof of Theorem 1 is given in Appendix. From Theorem 1, we know that the optimal projection matrix P is only composed of eigenvectors corresponding to the top r largest positive eigenvalues when r is appointed. Once the projection matrix P has been learned from the training data by SBDNE, the image of an unseen point 
                              x
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    d
                                 
                              
                            could be represented by 
                              v
                              =
                              
                                 
                                    P
                                 
                                 
                                    T
                                 
                              
                              x
                            with 
                              v
                              ∈
                              
                                 
                                    R
                                 
                                 
                                    r
                                 
                              
                           . The detail algorithm about SBDNE is given in Algorithm 1. 
                              Algorithm 1
                              Similarity-balanced Discriminant Neighborhood Embedding. 
                                    
                                       
                                          
                                          
                                             
                                                
                                                   Input: Training samples 
                                                      
                                                         
                                                            {
                                                            
                                                               
                                                                  
                                                                     x
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                               ,
                                                               
                                                                  
                                                                     y
                                                                  
                                                                  
                                                                     i
                                                                  
                                                               
                                                            
                                                            }
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                         
                                                         
                                                            N
                                                         
                                                      
                                                   , and the dimension of the subspace r.
                                             
                                             
                                                
                                                   Output: Projection matrix P.
                                             
                                             
                                                1. Construct the between-class adjacent graph 
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                    
                                                   (13) and the within-class adjacent graph 
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                    
                                                   (14), respectively.
                                             
                                             
                                                2. Calculate diagonal matrices 
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                    and 
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                    with 
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            ii
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            jj
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                    and 
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            ii
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                      =
                                                      
                                                         
                                                            ∑
                                                         
                                                         
                                                            j
                                                         
                                                      
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            jj
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                   , respectively. Let 
                                                      U
                                                      =
                                                      (
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                      −
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            b
                                                         
                                                      
                                                      )
                                                      −
                                                      (
                                                      
                                                         
                                                            D
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                      −
                                                      
                                                         
                                                            F
                                                         
                                                         
                                                            w
                                                         
                                                      
                                                      )
                                                   .
                                             
                                             
                                                3. Perform eigen-decomposition on the matrix 
                                                      
                                                         
                                                            XUX
                                                         
                                                         
                                                            T
                                                         
                                                      
                                                   , and obtain the eigenvalues λ
                                                   
                                                      i
                                                    and the corresponding eigenvectors 
                                                      
                                                         
                                                            p
                                                         
                                                         
                                                            i
                                                         
                                                      
                                                   . Assume that the eigenvalues are organized by descending order, namely 
                                                      
                                                         
                                                            λ
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      ≥
                                                      
                                                         
                                                            λ
                                                         
                                                         
                                                            2
                                                         
                                                      
                                                      ⋯
                                                      ≥
                                                      
                                                         
                                                            λ
                                                         
                                                         
                                                            d
                                                         
                                                      
                                                   .
                                             
                                             
                                                4. Take the r eigenvectors corresponding to the first r eigenvalues, and form the projection matrix 
                                                      P
                                                      =
                                                      [
                                                      
                                                         
                                                            p
                                                         
                                                         
                                                            1
                                                         
                                                      
                                                      ,
                                                      …
                                                      ,
                                                      
                                                         
                                                            p
                                                         
                                                         
                                                            r
                                                         
                                                      
                                                      ]
                                                   .
                                             
                                          
                                       
                                    
                                 
                              

Both SBNDE and LDNE are based on DNE. The goal of these methods is to find a potential subspace, being able to project the original high-dimensional data into a low-dimensional feature subspace. At the same time, the local structures between a sample and its neighbors in the original space are maintained in the subspace.

The main difference of the three methods is that they adopt different ways to construct the local structures in the original space. DNE uses a weight one to describe the neighbors׳ relationship, and LDNE adopts a heat kernel to express the structure. In theory, the heat kernel can concretely reflect the local structures. For SBDNE, we define a new similarity function which enhances the similarity degree for the homogenous neighbors and decreases the similarity degree for the heterogenous neighbors. In doing so, SBDNE maintains the local structures and generates better separability.

SBDNE has another difference from both DNE and LDNE which construct only one adjacent graph. In one adjacent graph, the local structures between each given sample and its heterogeneous neighbors may be lost. By constructing two adjacent graphs, SBDNE can avoid this drawback and produce a balanced link. Thus, homogenous neighbors are compact while heterogeneous neighbors become separable in the subspace.

Once we get the projected samples in the r-dimensional subspace, we can use a classifier to classify these projected samples. So far, many classifiers, such as naive Bayes classifier (NBC) [32], partial least squares discriminant analysis (PLSDA) [33] and K nearest neighbor (KNN) [7] have been applied to cancer classification. Since we do not focus on the design or selection of classifiers, we just use the nearest neighbor classifier to classify our data after dimension reduction due to its simplicity and efficiency.

@&#RESULTS AND DISCUSSIONS@&#

In this section, we discuss application of SBDNE to cancer classification using gene expression data and compare it with other discriminant methods. The nearest neighbor classifier is used to classify reduced data obtained by these methods.

Six public gene microarray datasets available are used to validate the performance of our proposed method, and summarized in Table 1
                        . These datasets are respectively Leukemia-ALLAML of Golub et al. [35], Breast Cancer of van׳t Veer et al. [36], Lung Cancer of Gordon et al. [37], Central Nervous System (CNS) dataset of Pomeroy et al. [38], Leukemia-subtype of Yeoh et al. [39], and Small Round Blue Cell Tumor (SRBCT) of Khan et al. [40]. The detailed description of these six datasets can be seen as follows:
                           
                              1.
                              Leukemia-ALLAML dataset has 72 samples belonging to two classes, or ALL (Acute Lymphoblastic Leukemia) and AML (Acute Myeloid Leukemia). The training set consists of 38 bone marrow samples (27 ALL and 11 AML), over 7129 probes from 6817 human genes. In addition, 34 test samples is provided, with 20 ALL and 14 AML.

Breast Cancer dataset has 97 samples belonging to two classes, or Relapse and Non-relapse. Each sample has 24,481 genes. The training set contains 78 patient samples, 34 of which are from patients who had developed distance metastases within 5 years (labelled as “relapse”), the rest 44 samples are from patients who remained healthy from the disease after their initial diagnosis for interval of at least 5 years (labelled as “non-relapse”). Correspondingly, there are 12 relapse and 7 non-relapse samples in the test set.

Lung cancer consists of 181 tissue samples of which 31 samples are malignant pleural mesothelioma (MPM), and 150 adenocarcinoma (ADCA) of the lung. The training set contains 32 of them, 16 MPM and 16 ADCA. The rest 149 samples are used for test, with 15 MPM and 134 ADCA. Each sample is described by 12,533 genes.

CNS dataset contains 60 patient samples, 21 are survivors (alive after treatment) and 39 are failures (succumbed to their disease). There are 7129 genes in the dataset. The training set consists of the first 10 survivors and 30 failures, the other 11 survivors and 9 failures are testing points.

Leukemia-subtype dataset contains 327 samples. The dataset has been divided into six diagnostic groups (BCR-ABL, E2A-PBX1, Hyperdiploid 
                                    >
                                    50
                                 , MLL, T-ALL and TEL-AML1, and one that contains diagnostic samples that did not fit into any one of the above groups (labelled as “Others”). Each sample has 12,558 genes. In the training set, there are 9 BCR-ABL, 18 E2A-PBX1, 42 Hyperdiploid 
                                    >
                                    50
                                 , 14 MLL, 28T-ALL, 52 TEL-AML1 and 52 others. The test set consists of 6 BCR-ABL, 9 E2A-PBX1, 22 Hyperdiploid 
                                    >
                                    50
                                 , 6 MLL, 15T-ALL, 27 TEL-AML1 and 27 others.

SRBCT dataset contains 83 samples belonging to four classes, or Ewing family of tumors (EWS), neuroblastoma (NB), Burkitt lymphoma (BL) and rhabdomyosarcoma (RMS). Each sample has 2308 genes. The training set has 63 samples, including 23 EWS, 20 RMS, 12 NB and 8 BL. The test set contains 6 EWS, 6 RMS, 6NB and 3 BL.

The first five datasets can be downloaded from , and the last one can be downloaded from http://www.biolab.si/supp/bi-cancer/projections/info/SRBCT.htm. All data here are normalized to the interval 
                           [
                           0
                           ,
                           1
                           ]
                         according to the way mentioned in Section 2.1.

The compared methods include here SBDNE, MFA [16], DNE [22], LDNE [29], LLDE [30] and NDLPP [26]. In these methods, the neighborhood parameter k would have an influence on experimental results. Therefore, we take different values of k from 1 to 5. In SBDNE, LDNE and NDLPP, the parameter β is acquired in advance, and could be determined according to (9). We first validate the feasibility of (9) for SBDNE in experiments on the SRBCT dataset. In addition, the performance of all methods is measured by classification accuracy which is calculated by
                           
                              (19)
                              
                                 
                                    
                                       The
                                       
                                       number
                                       
                                       of
                                       
                                       correctly
                                       
                                       classified
                                       
                                       test
                                       
                                       samples
                                    
                                    
                                       The
                                       
                                       number
                                       
                                       of
                                       
                                       all
                                       
                                       the
                                       
                                       test
                                       
                                       samples
                                    
                                 
                                 100
                                 %
                              
                           
                        
                     

In our experiments, all source codes are implemented with Matlab R2010a and experiments are conducted on a Pentium PC with 2.8GHz processor and 2GB main memory.

Since the SRBCT dataset has smaller genes than other datasets, we perform experiments on it to observe the performance of SBDNE vs. hyper-parameters β and r, respectively. In addition, we also validate the efficiency of the new similarity function (12).

We first validate the efficiency of the parameter selection method in [3] for β of SBDNE. β takes values in the set 
                           {
                           
                              
                                 2
                              
                              
                                 −
                                 2
                              
                           
                           ,
                           
                              
                                 2
                              
                              
                                 −
                                 1
                              
                           
                           ,
                           …
                           ,
                           
                              
                                 2
                              
                              
                                 10
                              
                           
                           }
                        . The accuracy curves with different dimensions r on the test set are shown in Fig. 2
                         when the neighborhood parameter k=3. For other k values, we have the similar situation. Furthermore, we choose five values for dimension of subspaces, or r=3, r=4, r=10, r=20, and r=40. From the five curves, we can see that SBDNE can get good performance when β is rather large. According to the method in [3], we can calculate 
                           β
                           =
                           112.83
                         which is between 26 and 27. In fact, the performance of SBDNE at 
                           β
                           =
                           
                              
                                 2
                              
                              
                                 6
                              
                           
                         is acceptable if a proper dimension is selected. Thus, we can use (9) to set β automatically.

In the following, we observe the relationship of accuracy vs. the dimension r and the corresponding eigen-decomposition. Theorem 1 shows that the projection matrix 
                           P
                         is composed of eigenvectors corresponding to the first r largest positive eigenvalues. Here, r varies from 1 to 2308. We give the final results of this experiment in Fig. 3
                        . Since the situation of k=3 is similar to that of k=1, and k=4 and k=5 are similar to k=2, we only show the results of k=1 in Fig. 3(a) and (b), and k=2 in Fig. 3(c) and (d), respectively. In both situations, the best accuracy of SBDNE is 100%. Note that the positive and zero eigenvalues have effects on the classification performance and the negative eigenvalues debase the performance. In Fig. 3(a), the small positive and zero eigenvalues depress the accuracy from 100% to 85%. On the contrary, the small positive or zero eigenvalues have no effect on the performance in Fig. 3(c). Thus, the best dimension still cannot be determined according to eigenvalues, which is an open problem for almost all dimension reduction methods.

Now, we compare two other similarity measurement ways defined in (5) and (8) with the new similarity one (12). For the sake of convenience, the similarity function defined in (5), (8) and (12) is called the 0/1 function, the heat kernel function, and the modified heat kernel function, respectively. β is automatically determined. r varies from 1 to 60. Fig. 4
                         shows the performance comparison of the three similarity measurements. When k=1, the heat kernel function is rather better than the 0/1 function. However, as the increase of k, the superiority of the heat kernel function over 0/1 decreases. Fortunately, the superiority of the modified heat kernel function over the other similarity functions is very obvious.

The best accuracies of compared methods are listed in 
                        Table 2, where the figure in the parentheses is the corresponding dimension of the subspace. We also list the results of the kNN classifier without feature extraction, thus the dimension of the subspace is still 2308. Note that only the NN classifier is used for feature extraction methods. From the results in this table, we can see that MFA and DNE-like methods (DNE, LDNE, and SBDNE) perform well on this dataset, which shows the efficiency of feature extraction compared with kNN. In addition, SBDNE and MFA can achieve the best performance even when k=1.

Since both MFA and SBDNE get the accuracy of 100%, we compare their ratio of the between-class scatter to the within-class scatter on the test set. Fig. 5
                         shows both the accuracy (left axis) and the ratio of the between-class scatter to the within-class scatter on the test set (right axis) vs. the dimension r with k=3, respectively. The accuracy curve of SBDNE is relatively stable and satisfactory with increasing r. But, the performance of MFA sharply decreases as the increase of r. The ratio curves obtained by the two methods are very similar to the probability density function of an F-distribution in shape. The curves of the ratio are very regular even for other k values, which are not shown for the limitation of space. Both methods have the greatest ratios, 4.42 for MFA and 3.52 for SBDNE at r=3, respectively. However, MFA has 100% accuracy not only at r=3, and SBDNE has 100% accuracy at r=4. Thus, the classification accuracy is not directly consistent with the ratio. The main reason is that the data reduced by different methods have different distributions. For example, the trace of covariance matrix is 27.17 for SBDNE and 2782.60 for MFA on the test set, respectively.

Since the dimension of these datasets except SRBCT is very high, the eigen-decomposition of matrix would be a problem for all compared methods here. Thus, we randomly select 1000 genes from the original ones for all six datasets, and repeat 50 trials. The average accuracy on the test sets are reported in Fig. 6
                         and Table 3
                        . We also list the performance of the kNN classifier without dimension reduction.


                        Fig. 6 shows the average classification accuracies on test sets with different neighborhood parameters k. We can see that DNE, LDNE and NDLPP are relatively sensitive to the parameter k. Naturally, the performance of kNN is also related to k. While LLDE, MFA and SBDNE are relatively stable. Table 3 gives the best classification results on test sets. For each dataset, two-tailed t-tests with the significant level 0.05 are performed to determine whether there is a significant difference between SBDNE and other methods. A Win–Loss–Tie (W–L–T) summarization based on mean and t-test is also attached at the bottom of Table 3. The conclusions are summarized as follows. There is no significant difference between SBDNE and LLDE (or kNN) in one out of six datasets, and between SBDNE and DNE or LDNE in three out of six datasets. MFA is significantly better than SBNEE only on the CNS System dataset, which is worse on three datasets, Breast Cancer, Leukemia-ALLAML, and Leukemia-subtype. SBDNE is significantly better than NDLPP in all six datasets.


                        Table 4
                         reports the ratio of the between-class scatter to the within-class scatter on test sets according to the condition of the best mean classification accuracies. These ratios can reflect the separability to a certain extent. NDLPP has a worse performance, so its ratios are relatively lower. However, the classification accuracy does not directly depend on the ratio. DNE, MFA, and LDNE have compared ratios on the Leukemia-ALLAML dataset, but these methods achieve different performance. In addition, although the ratios obtained by LLDE and SBDNE are less than that of LDNE, their classification accuracies are higher than its. In other words, a method achieves the best classification performance among the compared methods, but its ratio of the between-class scatter to the within-class scatter may be not the greatest, which supports the conclusion mentioned before.

@&#CONCLUSION@&#

This paper proposes an SBDNE method and apply it to cancer classification based on gene expression data. Compared to other DNE-like methods, SBDNE maintains the between-class and the within-class local structure by constructing two adjacency graphs, and gives some improvements in the position information of samples. As a result, we are able to give an overall consideration on the preservation of original geometric structure and utility of classification information. Through numerical experiments, the advantages of SBDNE are verified on six publicly available microarray datasets. SBDNE significantly outperforms other methods in three out of six datasets.

In theory, SBDNE can be applied to any high-dimensional data, such as face images and gene expression data. However, we cannot deal with a 
                        d
                        ×
                        d
                      matrix if d is too large in MATLAB, which would cause a problem of “Out of memory”. In experiments, we preprocess the data by selecting genes randomly to avoid the problem. In future, we will study the affection of preprocessing and find a good preprocessing method to improve on the cancer classification performance.

None declared.

@&#ACKNOWLEDGMENTS@&#

We would like to thank eight anonymous reviewers and Editor E.J. Ciaccio for their valuable comments and suggestions, which have significantly improved this paper. This work was supported in part by the National Natural Science Foundation of China under Grant no. 61373093, by the Natural Science Foundation of Jiangsu Province of China under Grant nos. BK20140008 and BK201222725, by the Natural Science Foundation of the Jiangsu Higher Education Institutions of China under Grant no. 13KJA520001, and by the Qing Lan Project.


                     
                        Proof 1
                        Proof Since 
                              
                                 
                                    D
                                 
                                 
                                    b
                                 
                              
                           , 
                              
                                 
                                    F
                                 
                                 
                                    b
                                 
                              
                           , 
                              
                                 
                                    D
                                 
                                 
                                    w
                                 
                              
                            and 
                              
                                 
                                    F
                                 
                                 
                                    w
                                 
                              
                            are all real symmetric matrices, according to [41], 
                              U
                              =
                              
                                 
                                    D
                                 
                                 
                                    b
                                 
                              
                              −
                              
                                 
                                    F
                                 
                                 
                                    b
                                 
                              
                              −
                              
                                 
                                    D
                                 
                                 
                                    w
                                 
                              
                              +
                              
                                 
                                    F
                                 
                                 
                                    w
                                 
                              
                            is also a real symmetric matrix. To maximize the problem (17), the Lagrange multiplier technique is adopted. Given the dimension of the subspace r, we construct the following Lagrangian function:
                              
                                 (20)
                                 
                                    L
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    ,
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          ∑
                                       
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          r
                                       
                                    
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    −
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    −
                                    1
                                    )
                                    )
                                 
                              
                           where 
                              
                                 
                                    λ
                                 
                                 
                                    i
                                 
                              
                              ,
                              i
                              =
                              1
                              ,
                              …
                              ,
                              r
                            are Lagrange multipliers. Then, the partial derivative of 
                              L
                              (
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                              ,
                              
                                 
                                    λ
                                 
                                 
                                    i
                                 
                              
                              )
                            with respect to 
                              
                                 
                                    p
                                 
                                 
                                    i
                                 
                              
                            is
                              
                                 (21)
                                 
                                    
                                       
                                          ∂
                                          L
                                          (
                                          
                                             
                                                p
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          
                                             
                                                λ
                                             
                                             
                                                i
                                             
                                          
                                          )
                                       
                                       
                                          ∂
                                          
                                             
                                                p
                                             
                                             
                                                i
                                             
                                          
                                       
                                    
                                    =
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    −
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           Let (21) be zero, we yield
                              
                                 (22)
                                 
                                    
                                       
                                          XUX
                                       
                                       
                                          T
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          λ
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                 
                              
                           Thus, the optimal matrix P in (17) can be obtained by computing the maximum eigenvalues with the generalized eigenvalue formulation.

This completes the proof. □

Supplementary data associated with this paper can be found in the online version at doi:10.1016/j.compbiomed.2015.07.008.


                     
                        
                           Application 1
                           
                        
                     
                  

@&#REFERENCES@&#


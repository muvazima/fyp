@&#MAIN-TITLE@&#Differenced maximum mutual information criterion for robust unsupervised acoustic model adaptation

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           The differenced-MMI (dMMI) is a discriminative criterion that generalizes MPE and BMMI.


                        
                        
                           
                           We discuss the behavior of dMMI when there are errors in the transcription labels.


                        
                        
                           
                           dMMI may be less sensitive to such errors than other criteria.


                        
                        
                           
                           We support our claim with unsupervised speaker adaptation experiments.


                        
                        
                           
                           dMMI based adaptation achieves significant gains over MLLR for 2 LVCSR tasks.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Discriminative criterion

Differenced maximum mutual information

Speech recognition

Acoustic model adaptation

Unsupervised adaptation

@&#ABSTRACT@&#


               
               
                  Discriminative criteria have been widely used for training acoustic models for automatic speech recognition (ASR). Many discriminative criteria have been proposed including maximum mutual information (MMI), minimum phone error (MPE), and boosted MMI (BMMI). Discriminative training is known to provide significant performance gains over conventional maximum-likelihood (ML) training. However, as discriminative criteria aim at direct minimization of the classification error, they strongly rely on having accurate reference labels. Errors in the reference labels directly affect the performance. Recently, the differenced MMI (dMMI) criterion has been proposed for generalizing conventional criteria such as BMMI and MPE. dMMI can approach BMMI or MPE if its hyper-parameters are properly set. Moreover, dMMI introduces intermediate criteria that can be interpreted as smoothed versions of BMMI or MPE. These smoothed criteria are robust to errors in the reference labels. In this paper, we demonstrate the effect of dMMI on unsupervised speaker adaptation where the reference labels are estimated from a first recognition pass and thus inevitably contain errors. In particular, we introduce dMMI-based linear regression (dMMI-LR) adaptation and demonstrate significant gains in performance compared with MLLR and BMMI-LR in two large vocabulary lecture recognition tasks.
               
            

@&#INTRODUCTION@&#

Discriminative criteria have been widely used for automatic speech recognition (ASR) for training acoustic models (Nadas et al., 1988; Povey and Woodland, 2002; McDermott et al., 2007; Heigold et al., 2012), language models (Kuo et al., 2002) or feature transforms (Povey et al., 2005, 2008; Droppo and Acero, 2005; Zhang et al., 2006). Discriminative criteria aim at the direct minimization of classification error. Therefore, they are better correlated to word error than conventional maximum likelihood (ML). Consequently, discriminative training has provided significant performance improvement for many tasks and has became the de facto procedure for training ASR systems.

Many discriminative criteria have been proposed, including maximum mutual information (MMI) (Nadas et al., 1988), minimum phone error (MPE) (Povey and Woodland, 2002), and minimum classification error (MCE) (Juang and Katagiri, 1992). More recently, margin-based extensions of these criteria have also been introduced such as soft margin (Li et al., 2006), boosted MMI (BMMI) (Povey et al., 2008) and boosted MPE (Heigold et al., 2008). These various discriminative criteria differ in their formulations, but they share the same principle of aiming at increasing the classification scores for the reference labels, while decreasing the scores for competing recognition hypotheses. As a consequence, discriminative approaches usually require to have high quality reference labels to work properly.

In many situations, it is difficult or costly to obtain reference labels without transcription errors. For example, transcribing large amounts of training speech data is not only very expensive but also difficult, especially when dealing with spontaneous speech. Semi-supervised training is a practical approach for addressing this issue. With semi-supervised training, only a part of the training data is transcribed manually, and labels for the rest of the training data are generated automatically using a pre-existing recognizer (Lamel et al., 2002; Wessel and Ney, 2005; Wang et al., 2007). A similar approach is used for the unsupervised adaptation of acoustic models where labels also need to be estimated automatically from the untranscribed adaptation data. In such cases, the estimated reference labels inevitably contain recognition errors. Therefore, using a conventional discriminative criterion in such situations is particularly challenging (Wang et al., 2007).

In this paper, we investigate the use of the recently proposed differenced MMI (dMMI) (McDermott et al., 2009, 2010) criterion in the presence of errors in the reference labels. We argue that dMMI is well suited for such situations. dMMI was first introduced as a generalization of existing criteria such as MPE and MMI. dMMI has been successfully used for training acoustic models (McDermott et al., 2010), discriminative feature transforms (Delcroix et al., 2012) and the weights of a weighted finite state transducer (WFST) used for ASR decoding (Kubo et al., 2012, 2012, 2013). dMMI can be derived as the integration over a margin interval of margin-based MPE objective functions. It can also be interpreted as a smoothed version of the BMMI objective function. With dMMI, the reference labels can be defined in a smoothed manner, i.e. as a summation of the contribution of each recognition candidate weighted by margin terms that emphasize the contribution of candidates close to the reference labels. In other words, the numerator of the dMMI objective function does not consist only of the contribution of the reference label, but also considers recognition candidates close to that reference label. Therefore, dMMI has an intrinsic mechanism for mitigating the influence of errors in the reference labels.

We demonstrate the robustness of dMMI to errors in the reference labels for unsupervised acoustic model adaptation. Acoustic models must be adapted to mitigate the mismatch that often occurs between training and testing conditions due to unseen speaker or acoustic conditions (Yoshioka et al., 2014). In many cases, the adaptation has to be performed in an unsupervised way because transcribed data may not always be available. There is a great interest in using a discriminative criterion for adaptation. Indeed, discriminative criteria can potentially improve performance compared with the ML criterion and can better preserve the discriminative capabilities of discriminatively trained acoustic models. Therefore, discriminative unsupervised adaptation is an important application in itself. Moreover, it is a good example of an application where the reference labels contain errors and therefore is directly related to semi-supervised training.

There have been many investigations of discriminative adaptation (Gunawardana and Byrne, 2001; Uebel and Woodland, 2001; Povey et al., 2003; Chien and Huang, 2006; Wu and Huo, 2007; Wang and Woodland, 2008; Matsuda et al., 2009; Gibson and Hain, 2012). Most approaches are based on the maximum likelihood linear regression (MLLR) (Leggetter and Woodland, 1995; Gales and Woodland, 1996) adaptation, but propose replacing the ML criterion with a discriminative one. Most studies target supervised adaptation. However, some have recognized the challenge of unsupervised discriminative adaptation and proposed approaches for handling the problem caused by inaccurate reference labels (Wang and Woodland, 2008; Gibson and Hain, 2012; Yu et al., 2009). For example, Wang and Woodland (2008) and Gibson and Hain (2012) proposed focusing on adaptation data that are expected to be correctly transcribed. This was achieved by weighting the MPE objective function with a word/phoneme correctness estimation.

In this paper, we introduce dMMI-based LR adaptation. We demonstrate both theoretically and experimentally that dMMI-LR is well suited for unsupervised adaptation. Indeed, the smoothed reference definition of dMMI can achieve a similar effect to Wang and Woodland (2008) and Gibson and Hain (2012) without the need for an explicit estimation of the word/phoneme correctness. This paper is an extension of our previous work (Delcroix et al., 2013) and includes additional derivations as well as new experiments using two large vocabulary continuous speech recognition (LVCSR) tasks. These experiments provide new insights and confirm the usefulness of dMMI-LR for various tasks.

In the remainder of this paper, Section 2 reviews conventional discriminative criteria and introduces dMMI. We then introduce LR-based adaptation in Section 3 and the proposed dMMI-LR adaptation. Some implementation issues and the relations with existing approaches are also discussed in Section 3. We report experimental results in Section 4 for the corpus of spontaneous Japanese (CSJ) and the MIT OpenCourseWare (MIT-OCW) tasks that demonstrate the robustness of dMMI-LR to errors in the reference labels, and finish with a conclusion.

Before introducing dMMI, we first review the main discriminative criteria used for acoustic model training, namely MMI and MPE. We will then present dMMI, which generalizes these criteria.

We consider the problem of finding a set of optimal parameters 
                        
                           θ
                           ˆ
                        
                      that maximizes an objective function 
                        F
                        (
                        θ
                        )
                     
                     
                        3
                     
                     
                        3
                        Note that in this paper, to clarify the relations between the different criteria, we express all criteria as a maximization problem in the form of Eq. (1) by negating the objective function of the original criteria if necessary.
                      as,
                        
                           (1)
                           
                              
                                 θ
                                 ˆ
                              
                              =
                              
                                 argmax
                                 θ
                              
                              F
                              (
                              θ
                              )
                              .
                           
                        
                     Here θ can represent acoustic model parameters such as the mean vectors and covariance matrices of a Gaussian mixture model (GMM)–hidden Markov model (HMM) acoustic model, feature transformation parameters, or adaptation parameters as described in Section 3.

To introduce the notations, we first present the ML objective function, 
                        
                           F
                           ML
                        
                        (
                        θ
                        )
                     , which is given as,


                     
                        
                           (2)
                           
                              
                                 F
                                 ML
                              
                              (
                              θ
                              )
                              =
                              
                                 ∑
                                 
                                    r
                                    =
                                    1
                                 
                                 R
                              
                              log
                              (
                              p
                              
                                 
                                    (
                                    
                                       X
                                       r
                                    
                                    |
                                    
                                       S
                                       r
                                    
                                    ;
                                    θ
                                    )
                                 
                                 ψ
                              
                              P
                              
                                 
                                    (
                                    
                                       S
                                       r
                                    
                                    )
                                 
                                 
                                    ψ
                                    η
                                 
                              
                              )
                              ,
                           
                        
                     where 
                        
                           X
                           r
                        
                      is the rth training utterance, S
                     
                        r
                      represents the reference label associated with 
                        
                           X
                           r
                        
                     
                     
                        4
                     
                     
                        4
                        For unsupervised adaptation, S
                           
                              r
                            consists of the 1-best recognition candidate.
                      and r is the total number of training utterances, 
                        p
                        (
                        
                           X
                           r
                        
                        |
                        
                           S
                           r
                        
                        ;
                        θ
                        )
                      is the acoustic likelihood and P(S
                     
                        r
                     ) is the language score. ψ and η are the acoustic scaling and language model weights, respectively. The acoustic likelihood is given as,
                        
                           (3)
                           
                              p
                              (
                              
                                 X
                                 r
                              
                              |
                              
                                 S
                                 r
                              
                              ;
                              θ
                              )
                              =
                              
                                 ∑
                                 
                                    
                                       
                                          β
                                       
                                    
                                    ∈
                                    B
                                 
                              
                              
                              
                                 ∏
                                 
                                    t
                                    =
                                    1
                                 
                                 T
                              
                              p
                              (
                              
                                 
                                    
                                       x
                                    
                                 
                                 t
                              
                              |
                              
                                 β
                                 t
                              
                              ;
                              θ
                              )
                              P
                              (
                              
                                 β
                                 t
                              
                              |
                              
                                 β
                                 
                                    t
                                    −
                                    1
                                 
                              
                              ;
                              θ
                              )
                              ,
                           
                        
                     where 
                        B
                      is the set of all possible state sequences 
                        β
                     
                     =[β
                     1, …, β
                     
                        T
                     ] associated with the transcription S
                     
                        r
                     . P(β
                     
                        t
                     |β
                     
                        t−1
                     ;
                     θ) is the HMM state transition probability and p(x
                     
                        t
                     |β
                     
                        t
                     
                     ;
                     θ) is the HMM state emission probability. We model the HMM state emission probabilities using GMMs as,
                        
                           (4)
                           
                              p
                              (
                              
                                 
                                    
                                       x
                                    
                                 
                                 t
                              
                              |
                              
                                 β
                                 t
                              
                              ;
                              θ
                              )
                              =
                              
                                 ∑
                                 n
                              
                              P
                              (
                              n
                              )
                              N
                              (
                              
                                 
                                    
                                       x
                                    
                                 
                                 t
                              
                              ;
                              
                                 
                                    
                                       μ
                                    
                                 
                                 n
                              
                              ,
                              
                                 
                                    
                                       Σ
                                    
                                 
                                 n
                              
                              )
                           
                        
                     where 
                        μ
                     
                     
                        n
                      and 
                        Σ
                     
                     
                        n
                      are the mean vector and covariance matrix corresponding to the nth Gaussian component of the GMM.

In the following, we introduce the following notation to simplify the expressions,
                        
                           (5)
                           
                              p
                              (
                              
                                 X
                                 r
                              
                              ,
                              
                                 S
                                 r
                              
                              ;
                              θ
                              )
                              ≜
                              p
                              
                                 
                                    (
                                    
                                       X
                                       r
                                    
                                    |
                                    
                                       S
                                       r
                                    
                                    ;
                                    θ
                                    )
                                 
                                 ψ
                              
                              P
                              
                                 
                                    (
                                    
                                       S
                                       r
                                    
                                    )
                                 
                                 
                                    ψ
                                    η
                                 
                              
                              .
                           
                        
                     Note that the acoustic scaling or lattice smoothing factor, ψ, is introduced here for consistency with other criteria that are defined over lattices. It controls the amount of hypotheses in the lattices that will contribute to the objective function (McDermott and Nakamura, 2008).

MMI is a well-known discriminative criterion that was first introduced in Nadas et al. (1988). It can be interpreted as the direct optimization of the posterior probability 
                           p
                           (
                           
                              S
                              r
                           
                           |
                           
                              X
                              r
                           
                           ;
                           θ
                           )
                        . Using Bayes’ rule, the objective function of MMI is obtained as,


                        
                           
                              (6)
                              
                                 
                                    F
                                    MMI
                                 
                                 (
                                 θ
                                 )
                                 =
                                 
                                    1
                                    ψ
                                 
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 log
                                 
                                    
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ;
                                       θ
                                       )
                                    
                                    
                                       
                                          ∑
                                          n
                                       
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          n
                                       
                                       ;
                                       θ
                                       )
                                    
                                 
                                 ,
                              
                           
                        where S
                        
                           n
                         is a recognition candidate associated with the training utterance 
                           
                              X
                              r
                           
                        . As shown in Eq. (6) MMI updates the model parameters by increasing the contribution to the reference model, while the contributions of the competitors are reduced. In Eq. (6) we expressed the MMI objective function in a non-standard way, by introducing the division by the acoustic scaling constant ψ. This follows the notations used in McDermott et al. (2009, 2010) and it enables to show that MMI is a smoothed version of the hinge loss function (McDermott et al., 2009) (this approximation becomes close when ψ takes large values). Moreover, introducing this scaling constant makes the relation between MMI and the other discriminative criteria more explicit as discussed later.

The MMI criterion was further extended to include a margin term or boosting factor as follows (Povey et al., 2008),


                        
                           
                              (7)
                              
                                 
                                    F
                                    σ
                                    BMMI
                                 
                                 (
                                 θ
                                 )
                                 =
                                 
                                    1
                                    ψ
                                 
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 log
                                 
                                    
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ;
                                       θ
                                       )
                                    
                                    
                                       
                                          ∑
                                          n
                                       
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          n
                                       
                                       ;
                                       θ
                                       )
                                       
                                          e
                                          
                                             ψ
                                             σ
                                             
                                                E
                                                
                                                   n
                                                   ,
                                                   r
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where 
                           
                              E
                              
                                 n
                                 ,
                                 r
                              
                           
                         represents the number of errors between the reference label S
                        
                           r
                         and the recognition candidate S
                        
                           n
                        . 
                           
                              E
                              
                                 n
                                 ,
                                 r
                              
                           
                         can be expressed in terms of word, phone or phone-frame errors. In the following we use phone-frame errors as defined in Zheng and Stolcke (2005). 
                           
                              e
                              
                                 ψ
                                 σ
                                 
                                    E
                                    
                                       n
                                       ,
                                       r
                                    
                                 
                              
                           
                         is a margin or boosting term that makes it possible to emphasize recognition candidates with a large number of errors in the denominator. The boosting term is controlled by a margin parameter, σ. With the boosting term, the model will have to discriminate better reference labels from recognition candidates with a large number of errors to increase the objective function during training. As a result, we may expect that low error candidates will be more likely to be recognized during testing. This is a similar effect to margin maximization in a support vector machine (SVM) (Heigold et al., 2008).

To simplify the notations, we introduce a pseudo-probability function, Ψ, defined as (Nakamura et al., 2009),
                           
                              (8)
                              
                                 
                                    Ψ
                                    σ
                                 
                                 (
                                 
                                    X
                                    r
                                 
                                 ,
                                 
                                    S
                                    r
                                 
                                 ,
                                 θ
                                 )
                                 =
                                 
                                    ∑
                                    n
                                 
                                 p
                                 (
                                 
                                    X
                                    r
                                 
                                 ,
                                 
                                    S
                                    n
                                 
                                 ;
                                 θ
                                 )
                                 
                                    e
                                    
                                       ψ
                                       σ
                                       
                                          E
                                          
                                             n
                                             ,
                                             r
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        We can notice that for σ→−∞ only the term for 
                           
                              E
                              
                                 n
                                 ,
                                 r
                              
                           
                           =
                           0
                         (i.e. corresponding to the reference) remains in the summation. Using the pseudo-probability function of Eq. (8), we can rewrite the BMMI objective function as,


                        
                           
                              (9)
                              
                                 
                                    F
                                    σ
                                    BMMI
                                 
                                 (
                                 θ
                                 )
                                 =
                                 
                                    1
                                    ψ
                                 
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 log
                                 
                                    
                                       
                                          Ψ
                                          
                                             −
                                             ∞
                                          
                                       
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ,
                                       θ
                                       )
                                    
                                    
                                       
                                          Ψ
                                          σ
                                       
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ,
                                       θ
                                       )
                                    
                                 
                                 .
                              
                           
                        This expression of the BMMI objective function will allow us to clarify relations between the different discriminative criteria.

MPE is another frequently used discriminative criterion (Povey and Woodland, 2002; Heigold et al., 2008). Compared with MMI, MPE aims at a direct minimization of the recognition error, which is a measure that is more relevant for ASR applications. The MPE objective function is given by the mean of the recognition errors over the recognition candidates, where the errors are calculated with respect to the reference labels. Although the name implies phone errors, here we use the same definition of errors as in Section 2.1, i.e. phone-frame error. The MPE objective function is defined as follows (here for brevity, we directly introduce the boosted version of MPE (Heigold et al., 2008)),
                           
                              (10)
                              
                                 
                                    F
                                    σ
                                    MPE
                                 
                                 (
                                 θ
                                 )
                                 =
                                 −
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 
                                    
                                       
                                          ∑
                                          k
                                       
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          k
                                       
                                       ;
                                       θ
                                       )
                                       
                                          e
                                          
                                             ψ
                                             σ
                                             
                                                E
                                                
                                                   k
                                                   ,
                                                   r
                                                
                                             
                                          
                                       
                                       
                                          E
                                          
                                             k
                                             ,
                                             r
                                          
                                       
                                    
                                    
                                       
                                          ∑
                                          n
                                       
                                       p
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          n
                                       
                                       ;
                                       θ
                                       )
                                       
                                          e
                                          
                                             ψ
                                             σ
                                             
                                                E
                                                
                                                   n
                                                   ,
                                                   r
                                                
                                             
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        Note that we negated the objective function compared with its conventional expression to remain consistent with the problem formulation of Eq. (1).

Using the pseudo-probability function defined in Eq. (8), and observing that the numerator in Eq. (10) is the partial derivative of the pseudo-probability function relative to the margin parameter σ modulo acoustic scaling ψ, we can rewrite the MPE objective function as,


                        
                           
                              (11)
                              
                                 
                                    
                                       
                                          
                                             F
                                             σ
                                             MPE
                                          
                                          (
                                          θ
                                          )
                                       
                                       
                                          =
                                          −
                                          
                                             1
                                             ψ
                                          
                                          
                                             ∑
                                             
                                                r
                                                =
                                                1
                                             
                                             R
                                          
                                          
                                             
                                                
                                                   ∂
                                                   
                                                      ∂
                                                      σ
                                                   
                                                
                                                
                                                   Ψ
                                                   σ
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                             
                                             
                                                
                                                   Ψ
                                                   σ
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                             
                                          
                                          ,
                                       
                                    
                                    
                                       
                                       
                                          =
                                          −
                                          
                                             1
                                             ψ
                                          
                                          
                                             ∑
                                             
                                                r
                                                =
                                                1
                                             
                                             R
                                          
                                          
                                             ∂
                                             
                                                ∂
                                                σ
                                             
                                          
                                          log
                                          
                                             Ψ
                                             σ
                                          
                                          (
                                          
                                             X
                                             r
                                          
                                          ,
                                          
                                             S
                                             r
                                          
                                          ,
                                          θ
                                          )
                                          .
                                       
                                    
                                 
                              
                           
                        
                     

Finally, using the definition of a derivative in terms of limits, we can express the MPE objective function as,


                        
                           
                              (12)
                              
                                 
                                    
                                       
                                          
                                             F
                                             σ
                                             MPE
                                          
                                          (
                                          θ
                                          )
                                       
                                       
                                          =
                                          −
                                          
                                             1
                                             ψ
                                          
                                          
                                             lim
                                             
                                                
                                                   
                                                      
                                                         
                                                            ϵ
                                                            →
                                                            0
                                                            ,
                                                         
                                                         
                                                            
                                                               σ
                                                               1
                                                            
                                                            =
                                                            σ
                                                            ,
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         σ
                                                         2
                                                      
                                                      =
                                                      σ
                                                      +
                                                      ϵ
                                                   
                                                
                                             
                                          
                                          
                                             ∑
                                             
                                                r
                                                =
                                                1
                                             
                                             R
                                          
                                          
                                             
                                                log
                                                
                                                   Ψ
                                                   
                                                      
                                                         σ
                                                         2
                                                      
                                                   
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                                −
                                                log
                                                
                                                   Ψ
                                                   
                                                      
                                                         σ
                                                         1
                                                      
                                                   
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                             
                                             
                                                
                                                   σ
                                                   2
                                                
                                                −
                                                
                                                   σ
                                                   1
                                                
                                             
                                          
                                          ,
                                       
                                    
                                    
                                       
                                       
                                          =
                                          
                                             1
                                             ψ
                                          
                                          
                                             lim
                                             
                                                
                                                   
                                                      
                                                         
                                                            ϵ
                                                            →
                                                            0
                                                            ,
                                                         
                                                         
                                                            
                                                               σ
                                                               1
                                                            
                                                            =
                                                            σ
                                                            ,
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         σ
                                                         2
                                                      
                                                      =
                                                      σ
                                                      +
                                                      ϵ
                                                   
                                                
                                             
                                          
                                          
                                             1
                                             
                                                
                                                   σ
                                                   2
                                                
                                                −
                                                
                                                   σ
                                                   1
                                                
                                             
                                          
                                          
                                             ∑
                                             
                                                r
                                                =
                                                1
                                             
                                             R
                                          
                                          log
                                          
                                             
                                                
                                                   Ψ
                                                   
                                                      
                                                         σ
                                                         1
                                                      
                                                   
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                             
                                             
                                                
                                                   Ψ
                                                   
                                                      
                                                         σ
                                                         2
                                                      
                                                   
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   r
                                                
                                                ,
                                                θ
                                                )
                                             
                                          
                                          .
                                       
                                    
                                 
                              
                           
                        Eq. (12) clarifies the relation between the BMMI and MPE objective functions as the ratio of pseudo-probability function Ψ
                        
                           σ
                         with different margin values. For BMMI, the numerator margin σ
                        1 is −∞, while for MPE the numerator and denominator margins tend to the same value. This relation is exploited in the next Section to define the dMMI criterion.

The dMMI criterion was first proposed for generalizing BMMI and MPE criteria (McDermott et al., 2009, 2010). The dMMI objective function is defined as,


                        
                           
                              (13)
                              
                                 
                                    F
                                    
                                       
                                          σ
                                          1
                                       
                                       ,
                                       
                                          σ
                                          2
                                       
                                    
                                    dMMI
                                 
                                 (
                                 θ
                                 )
                                 =
                                 
                                    1
                                    ψ
                                 
                                 
                                    1
                                    
                                       
                                          σ
                                          2
                                       
                                       −
                                       
                                          σ
                                          1
                                       
                                    
                                 
                                 
                                    ∑
                                    
                                       r
                                       =
                                       1
                                    
                                    R
                                 
                                 log
                                 
                                    
                                       
                                          Ψ
                                          
                                             
                                                σ
                                                1
                                             
                                          
                                       
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ,
                                       θ
                                       )
                                    
                                    
                                       
                                          Ψ
                                          
                                             
                                                σ
                                                2
                                             
                                          
                                       
                                       (
                                       
                                          X
                                          r
                                       
                                       ,
                                       
                                          S
                                          r
                                       
                                       ,
                                       θ
                                       )
                                    
                                 
                                 .
                              
                           
                        As with BMMI and MPE, the dMMI objective function is the ratio of two pseudo probability functions. However, with dMMI, the margin parameters for both the numerator and the denominator terms can take arbitrary values. By setting σ
                        1 at a large negative value (i.e. σ
                        1→−∞), dMMI becomes equivalent to BMMI, except for a multiplicative constant.
                           5
                        
                        
                           5
                           In theory, this constant does not have any influence on the optimization. However, in practice it can affect the value of the learning rate for gradient optimization or the value of the weight for I-smoothing. In this work, we do not use I-smoothing with dMMI and employ the RPROP algorithm for the optimization, which only relies on the signs of the gradient. Therefore the multiplicative constant has no practical influence in our case.
                         Similarly, looking at Eq. (12), we can see that setting σ
                        1 and σ
                        2 at values close to each other (i.e. σ
                        1
                        →
                        σ
                        2), dMMI becomes equivalent to MPE. Accordingly, dMMI generalizes MPE and BMMI, but also introduces intermediate criteria that will be of particular interest in this paper. The relation between dMMI, BMMI and MPE is summarized in Fig. 1
                        .

Note that the margin term of the denominator of dMMI has the same meaning as the conventional margin term of BMMI. Therefore, the margin term σ
                        2 is usually set at a positive value as with BMMI. By setting σ
                        1 at a negative value, the numerator margin enables a smoothed definition of the reference labels, i.e. only the recognition candidates with few errors remain in the summation of the numerator. This smoothed definition of references is expected to make dMMI more robust to errors in the reference labels as often occurs in unsupervised adaptation than MPE or BMMI. In the following sub-sections, we further elaborate this claim by interpreting the dMMI criteria as a smoothed version of BMMI or MPE objective functions.

It is possible to interpret the dMMI objective function as a smoothed version of the BMMI objective function, i.e. as a weighted sum of BMMI objective functions that use different recognition candidates as reference labels, each term in the summation being weighted by a factor that decreases as the recognition candidate becomes further from the reference label S
                           
                              r
                           . Let us rearrange the terms in the denominator of Eq. (13) to reveal the above,


                           
                              
                                 
                                    (14)
                                    
                                       
                                          F
                                          
                                             
                                                σ
                                                1
                                             
                                             ,
                                             
                                                σ
                                                2
                                             
                                          
                                          dMMI
                                       
                                       (
                                       θ
                                       )
                                       =
                                       
                                          1
                                          ψ
                                       
                                       
                                          1
                                          
                                             
                                                σ
                                                2
                                             
                                             −
                                             
                                                σ
                                                1
                                             
                                          
                                       
                                       
                                          ∑
                                          
                                             r
                                             =
                                             1
                                          
                                          R
                                       
                                       log
                                       
                                          
                                             
                                                
                                                   ∑
                                                   k
                                                
                                                
                                                   
                                                      p
                                                      (
                                                      
                                                         X
                                                         r
                                                      
                                                      ,
                                                      
                                                         S
                                                         k
                                                      
                                                      ;
                                                      θ
                                                      )
                                                      
                                                         e
                                                         
                                                            ψ
                                                            
                                                               σ
                                                               1
                                                            
                                                            
                                                               E
                                                               
                                                                  k
                                                                  ,
                                                                  r
                                                               
                                                            
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         ∑
                                                         n
                                                      
                                                      p
                                                      (
                                                      
                                                         X
                                                         r
                                                      
                                                      ,
                                                      
                                                         S
                                                         n
                                                      
                                                      ;
                                                      θ
                                                      )
                                                      
                                                         e
                                                         
                                                            ψ
                                                            
                                                               σ
                                                               2
                                                            
                                                            
                                                               E
                                                               
                                                                  n
                                                                  ,
                                                                  k
                                                               
                                                            
                                                         
                                                      
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                                     e
                                                                     
                                                                        ψ
                                                                        
                                                                           σ
                                                                           2
                                                                        
                                                                        (
                                                                        
                                                                           E
                                                                           
                                                                              n
                                                                              ,
                                                                              r
                                                                           
                                                                        
                                                                        −
                                                                        
                                                                           E
                                                                           
                                                                              n
                                                                              ,
                                                                              k
                                                                           
                                                                        
                                                                        )
                                                                     
                                                                  
                                                               
                                                               ︸
                                                            
                                                         
                                                         
                                                            ≈
                                                            1
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                                 
                                    (15)
                                    
                                       ≈
                                       
                                          1
                                          ψ
                                       
                                       
                                          1
                                          
                                             
                                                σ
                                                2
                                             
                                             −
                                             
                                                σ
                                                1
                                             
                                          
                                       
                                       
                                          ∑
                                          
                                             r
                                             =
                                             1
                                          
                                          R
                                       
                                       log
                                       
                                          
                                             
                                                
                                                   ∑
                                                   k
                                                
                                                
                                                   
                                                      
                                                         
                                                            
                                                               p
                                                               (
                                                               
                                                                  X
                                                                  r
                                                               
                                                               ,
                                                               
                                                                  S
                                                                  k
                                                               
                                                               ;
                                                               θ
                                                               )
                                                            
                                                            
                                                               
                                                                  ∑
                                                                  n
                                                               
                                                               p
                                                               (
                                                               
                                                                  X
                                                                  r
                                                               
                                                               ,
                                                               
                                                                  S
                                                                  n
                                                               
                                                               ;
                                                               θ
                                                               )
                                                               
                                                                  e
                                                                  
                                                                     ψ
                                                                     
                                                                        σ
                                                                        2
                                                                     
                                                                     
                                                                        E
                                                                        
                                                                           n
                                                                           ,
                                                                           k
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                      ︸
                                                   
                                                   
                                                      ≜
                                                      
                                                         f
                                                         
                                                            
                                                               σ
                                                               2
                                                            
                                                         
                                                         BMMI
                                                      
                                                      (
                                                      
                                                         X
                                                         r
                                                      
                                                      ,
                                                      
                                                         S
                                                         k
                                                      
                                                      )
                                                   
                                                
                                                
                                                   e
                                                   
                                                      ψ
                                                      
                                                         σ
                                                         1
                                                      
                                                      
                                                         E
                                                         
                                                            k
                                                            ,
                                                            r
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                                 
                                    (16)
                                    
                                       =
                                       
                                          1
                                          ψ
                                       
                                       
                                          1
                                          
                                             
                                                σ
                                                2
                                             
                                             −
                                             
                                                σ
                                                1
                                             
                                          
                                       
                                       
                                          ∑
                                          
                                             r
                                             =
                                             1
                                          
                                          R
                                       
                                       log
                                       
                                          
                                             
                                                
                                                   ∑
                                                   k
                                                
                                                
                                                   f
                                                   
                                                      
                                                         σ
                                                         2
                                                      
                                                   
                                                   BMMI
                                                
                                                (
                                                
                                                   X
                                                   r
                                                
                                                ,
                                                
                                                   S
                                                   k
                                                
                                                )
                                                
                                                   e
                                                   
                                                      ψ
                                                      
                                                         σ
                                                         1
                                                      
                                                      
                                                         E
                                                         
                                                            k
                                                            ,
                                                            r
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                       ,
                                    
                                 
                              
                            where 
                              
                                 f
                                 
                                    
                                       σ
                                       2
                                    
                                 
                                 BMMI
                              
                              (
                              
                                 X
                                 r
                              
                              ,
                              
                                 S
                                 k
                              
                              )
                            is equivalent to the BMMI objective function for a training utterance 
                              
                                 X
                                 r
                              
                            when assuming the kth recognition candidate S
                           
                              k
                            is a reference label. We can make the approximation in Eq. (15) by noting that if we set σ
                           1 at a negative value, the margin term 
                              
                                 e
                                 
                                    ψ
                                    
                                       σ
                                       1
                                    
                                    
                                       E
                                       
                                          k
                                          ,
                                          r
                                       
                                    
                                 
                              
                            will become very small when the number of errors becomes large. This is illustrated in Fig. 2
                           , which plots the margin term as a function of the number of errors for different values of the margin parameter σ
                           1. We observe that for σ
                           1 values smaller than e.g. −10, the margin term becomes very small when there are more than a few errors. Consequently, only the recognition candidates with few errors will remain in the summation term of the numerator, and therefore we can make the following approximations, 
                              
                                 E
                                 
                                    n
                                    ,
                                    r
                                 
                              
                              ≈
                              
                                 E
                                 
                                    n
                                    ,
                                    k
                                 
                              
                            and 
                              
                                 e
                                 
                                    ψ
                                    
                                       σ
                                       2
                                    
                                    (
                                    
                                       E
                                       
                                          n
                                          ,
                                          r
                                       
                                    
                                    −
                                    
                                       E
                                       
                                          n
                                          ,
                                          k
                                       
                                    
                                    )
                                 
                              
                              ≈
                              1
                            in the denominator of Eq. (14).

Eq. (16) reveals that dMMI with σ
                           1 set at a relatively large negative value is a weighted sum of BMMI objective functions that employ different recognition candidates close to S
                           
                              r
                            as reference labels. Therefore, dMMI emphasizes less reference labels S
                           
                              r
                            than BMMI. We believe that this intrinsic smoothing of dMMI may be beneficial to reduce the sensitivity to errors in the reference labels S
                           
                              r
                           .

We can also interpret the dMMI objective function as the integration of MPE objective functions over a margin parameter interval as follows (McDermott et al., 2009, 2010),


                           
                              
                                 (17)
                                 
                                    
                                       
                                          
                                             
                                                1
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                   −
                                                   
                                                      σ
                                                      1
                                                   
                                                
                                             
                                             
                                                ∫
                                                
                                                   
                                                      σ
                                                      1
                                                   
                                                
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                             
                                             
                                                F
                                                σ
                                                MPE
                                             
                                             (
                                             θ
                                             )
                                             d
                                             σ
                                          
                                          
                                             =
                                             
                                                1
                                                ψ
                                             
                                             
                                                1
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                   −
                                                   
                                                      σ
                                                      1
                                                   
                                                
                                             
                                             
                                                ∑
                                                
                                                   r
                                                   =
                                                   1
                                                
                                                R
                                             
                                             
                                                ∫
                                                
                                                   
                                                      σ
                                                      1
                                                   
                                                
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                             
                                             −
                                             
                                                ∂
                                                
                                                   ∂
                                                   σ
                                                
                                             
                                             log
                                             
                                                Ψ
                                                σ
                                             
                                             (
                                             
                                                X
                                                r
                                             
                                             ,
                                             
                                                S
                                                r
                                             
                                             ,
                                             θ
                                             )
                                          
                                       
                                       
                                          
                                          
                                             =
                                             
                                                1
                                                ψ
                                             
                                             
                                                1
                                                
                                                   
                                                      σ
                                                      2
                                                   
                                                   −
                                                   
                                                      σ
                                                      1
                                                   
                                                
                                             
                                             
                                                ∑
                                                
                                                   r
                                                   =
                                                   1
                                                
                                                R
                                             
                                             log
                                             
                                                
                                                   
                                                      Ψ
                                                      
                                                         
                                                            σ
                                                            1
                                                         
                                                      
                                                   
                                                   (
                                                   
                                                      X
                                                      r
                                                   
                                                   ,
                                                   
                                                      S
                                                      r
                                                   
                                                   ,
                                                   θ
                                                   )
                                                
                                                
                                                   
                                                      Ψ
                                                      
                                                         
                                                            σ
                                                            2
                                                         
                                                      
                                                   
                                                   (
                                                   
                                                      X
                                                      r
                                                   
                                                   ,
                                                   
                                                      S
                                                      r
                                                   
                                                   ,
                                                   θ
                                                   )
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                             =
                                             
                                                F
                                                
                                                   
                                                      σ
                                                      1
                                                   
                                                   ,
                                                   
                                                      σ
                                                      2
                                                   
                                                
                                                dMMI
                                             
                                             (
                                             θ
                                             )
                                             ,
                                          
                                       
                                    
                                 
                              
                           where we used the definition of MPE given in Eq. (11).

Note that for σ
                           >0, 
                              
                                 F
                                 σ
                                 MPE
                              
                            can be understood as the average error obtained by boosting recognition candidates that contain a large number of errors. This boosting effect may be useful to compensate for the potential low occupancy of recognition candidates with large numbers of errors, and therefore forcing the model to be more discriminative. However, when the reference labels contain errors, such a clear distinction between correct and incorrect hypotheses may become difficult and affect performance.

When setting σ at a negative value, recognition candidates with a small number of errors are emphasized in the MPE objective function. In this case, the MPE criterion becomes less discriminative because it focuses on reducing errors for recognition candidates with only few errors and the contribution of recognition candidates with larger numbers of errors becomes small.

By integrating over a margin interval, dMMI realizes a smoothed version of the MPE criterion. The smoothing is controlled by the margin interval. For example, by setting σ
                           1 at a relatively large negative value, more weights will be given to recognition candidates with small numbers of errors, making the corresponding criterion less discriminative than conventional MPE, but more robust to errors in the labels.

From the above discussion and Section 2.3.1, we observe that dMMI can have two distinct interpretations depending on whether we look at it as a generalization of the BMMI or the MPE criteria. In both cases, setting the value of σ
                           1 at an appropriate value in the range (−∞, 0] should define criteria that may be more robust to errors in the reference labels than MPE or BMMI.

Our aim is to confirm the robustness of dMMI to errors in reference labels for unsupervised adaptation. For this purpose, we employ LR adaptation, which is frequently used for acoustic model adaptation. After briefly reviewing the principles of LR adaptation, we introduce dMMI-LR and discuss practical implementation issues. Finally, we elaborate on the relation between dMMI-LR and other adaptation approaches.

Linear regression-based adaptation such as MLLR (Gales and Woodland, 1996; Leggetter and Woodland, 1995) is widely used for supervised and unsupervised speaker adaptation. It consists of adapting the GMM–HMM acoustic model parameters using a linear regression as follows (Leggetter and Woodland, 1995),
                           
                              (18)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   μ
                                                
                                             
                                          
                                          ˆ
                                       
                                    
                                    l
                                 
                                 =
                                 
                                    
                                       
                                          A
                                       
                                    
                                    l
                                 
                                 
                                    
                                       
                                          
                                             μ
                                          
                                       
                                    
                                    l
                                 
                                 +
                                 
                                    
                                       
                                          b
                                       
                                    
                                    l
                                 
                                 =
                                 
                                    
                                       
                                          L
                                       
                                    
                                    l
                                 
                                 
                                    
                                       
                                          ξ
                                       
                                    
                                    l
                                 
                                 ,
                              
                           
                        where 
                           μ
                        
                        
                           l
                         and 
                           
                              
                                 
                                    
                                       
                                          
                                             μ
                                          
                                       
                                    
                                    ˆ
                                 
                              
                              l
                           
                         are the mean vectors of the lth Gaussian of the acoustic model before and after adaptation. A
                        
                           l
                         and b
                        
                           l
                         are a transformation matrix and a bias vector, respectively. The LR transformation can be written in a simplified way as on the right-hand side of Eq. (18), which is obtained by introducing the following notations L
                        
                           l
                        
                        ≜[A
                        
                           l
                        
                        b
                        
                           l
                        ] and 
                           
                              
                                 
                                    ξ
                                 
                              
                              l
                           
                           ≜
                           
                              
                                 [
                                 
                                    
                                       
                                          μ
                                       
                                    
                                    l
                                    ⊤
                                 
                                 1
                                 ]
                              
                              ⊤
                           
                        .

Eq. (18) expresses adaptation only for the mean vectors of the Gaussians of the acoustic model. It is possible to perform the adaptation of the covariance matrices in a similar way, or by using the same transformation matrices for the mean vectors and covariance matrices as in constrained MLLR (CMLLR) (Gales and Woodland, 1996).
                           6
                        
                        
                           6
                           Note that dMMI-based variance adaptation has also been investigated in the context of noise robust ASR (Delcroix et al., 2012).
                         Moreover, several topologies of the LR transformation matrices have been investigated including full, diagonal and block-diagonal matrices. The latter two are often used when the amount of adaptation data is limited. CMLLR can also be used for limited amount of data, since it can be implemented as a feature transformation, which requires fewer parameters and may therefore be less sensitive to over-fitting. In the following we use MLLR with full transform matrices since in our experiments we deal with tasks where the amount of adaptation data is considered to be sufficient.

Using different LR transforms for each Gaussian of the acoustic model greatly increases the number of adaptation parameters. Instead, the LR transforms are usually shared among similar Gaussians. This can be realized using the binary tree clustering of the Gaussians of the acoustic model (Gales and Woodland, 1996). During adaptation, the occupancy count of each cluster in the binary tree is computed, but the adaptation parameters are calculated only for the clusters in the tree that have an occupancy count superior to a given threshold. For clusters that have an occupancy count value smaller than the threshold, the adaptation parameters of the parent cluster in the binary tree are used. This procedure ensures a sufficient amount of data with which to calculate the LR transforms.

We use C
                        
                           k
                         to denote the set of Gaussians belonging to the kth cluster, and L
                        
                           k
                         to denote the corresponding LR transform. The set of all the adaptation parameters θ
                        ≜[L
                        1, …, L
                        
                           K
                        ] is optimized as,
                           
                              (19)
                              
                                 
                                    θ
                                    ˆ
                                 
                                 =
                                 
                                    argmax
                                    θ
                                 
                                 
                                    F
                                    θ
                                 
                                 (
                                 
                                    X
                                    r
                                 
                                 ,
                                 
                                    S
                                    r
                                 
                                 )
                                 ,
                              
                           
                        where 
                           
                              X
                              r
                           
                         is the sequence of feature vectors x
                        
                           t
                         associated with the rth adaptation utterance, i.e. 
                           
                              X
                              r
                           
                           ≜
                           [
                           
                              
                                 
                                    x
                                 
                              
                              0
                           
                           ,
                           …
                           ,
                           
                              
                                 
                                    x
                                 
                              
                              t
                           
                           ,
                           …
                           ,
                           
                              
                                 
                                    x
                                 
                              
                              T
                           
                           ]
                         and S
                        
                           r
                         is the set of corresponding reference labels. For unsupervised adaptation, S
                        
                           r
                         is obtained from a first recognition pass and therefore inevitably contains errors.

Conventional MLLR uses the likelihood as an objective function (Leggetter and Woodland, 1995). In this paper we investigate the use of the dMMI objective criterion instead. Note that others investigated the use of MPE or MMI for LR based adaptation (Wallhoff et al., 2000; Uebel and Woodland, 2001; Wang and Woodland, 2004; Gibson and Hain, 2012).

We use gradient-based optimization to solve the problem of Eq. (19). We employ a lattice implementation to represent the set of recognition candidates. When using the dMMI objective function in Eq. (19), the gradient with respect to the adaptation parameters can be expressed as,
                           
                              (20)
                              
                                 
                                    
                                       ∂
                                       
                                          F
                                          
                                             θ
                                             ,
                                             
                                                σ
                                                1
                                             
                                             ,
                                             
                                                σ
                                                2
                                             
                                          
                                          dMMI
                                       
                                    
                                    
                                       ∂
                                       
                                          
                                             
                                                L
                                             
                                          
                                          k
                                       
                                    
                                 
                                 =
                                 
                                    ∑
                                    t
                                 
                                 
                                 
                                    ∑
                                    
                                       q
                                       ∈
                                       
                                          Q
                                          t
                                       
                                    
                                 
                                 
                                 
                                    ∑
                                    
                                       l
                                       ∈
                                       
                                          C
                                          
                                             k
                                             ,
                                             q
                                          
                                       
                                    
                                 
                                 
                                    γ
                                    
                                       q
                                       ,
                                       θ
                                       ,
                                       
                                          σ
                                          1
                                       
                                       ,
                                       
                                          σ
                                          2
                                       
                                    
                                    dMMI
                                 
                                 
                                    γ
                                    
                                       l
                                       ,
                                       t
                                    
                                 
                                 
                                    Σ
                                    l
                                    
                                       −
                                       1
                                    
                                 
                                 (
                                 
                                    
                                       
                                          x
                                       
                                    
                                    t
                                 
                                 −
                                 
                                    
                                       
                                          μ
                                       
                                    
                                    l
                                 
                                 )
                                 
                                    
                                       
                                          ξ
                                       
                                    
                                    l
                                    ⊤
                                 
                                 ,
                              
                           
                        where Q
                        
                           t
                         is the set of all lattice arcs that contain the feature vector x
                        
                           t
                        , C
                        
                           k,q
                         is the set of Gaussians within arc q belonging to cluster C
                        
                           k
                        , γ
                        
                           l,t
                         is the posterior probability of Gaussian l and 
                           
                              γ
                              
                                 q
                                 ,
                                 θ
                                 ,
                                 
                                    σ
                                    1
                                 
                                 ,
                                 
                                    σ
                                    2
                                 
                              
                              dMMI
                           
                         is the dMMI arc posterior probability or occupancy. The occupancy can be calculated by running the forward-backward algorithm twice on the same lattice once with σ
                        1 and once with σ
                        2 as (McDermott et al., 2010),
                           
                              (21)
                              
                                 
                                    γ
                                    
                                       q
                                       ,
                                       θ
                                       ,
                                       
                                          σ
                                          1
                                       
                                       ,
                                       
                                          σ
                                          2
                                       
                                    
                                    dMMI
                                 
                                 =
                                 
                                    
                                       
                                          γ
                                          
                                             q
                                             ,
                                             θ
                                             ,
                                             
                                                σ
                                                2
                                             
                                          
                                       
                                       −
                                       
                                          γ
                                          
                                             q
                                             ,
                                             θ
                                             ,
                                             
                                                σ
                                                1
                                             
                                          
                                       
                                    
                                    
                                       
                                          σ
                                          2
                                       
                                       −
                                       
                                          σ
                                          1
                                       
                                    
                                 
                                 ,
                              
                           
                        where γ
                        
                           q,θ,σ
                         is the standard BMMI arc posterior probability calculated with the forward-backward algorithm. The term 
                           
                              ∑
                              
                                 q
                                 ∈
                                 
                                    Q
                                    t
                                 
                              
                           
                           
                              γ
                              
                                 q
                                 ,
                                 θ
                                 ,
                                 
                                    σ
                                    1
                                 
                                 ,
                                 
                                    σ
                                    2
                                 
                              
                              dMMI
                           
                           
                              γ
                              
                                 l
                                 ,
                                 t
                              
                           
                           
                              Σ
                              l
                              
                                 −
                                 1
                              
                           
                           (
                           
                              
                                 
                                    x
                                 
                              
                              t
                           
                           −
                           
                              
                                 
                                    μ
                                 
                              
                              l
                           
                           )
                         in Eq. (20) corresponds to the same statistics accumulated for the discriminative training of the acoustic models. Consequently, dMMI-LR can be implemented by simple modifications of an existing implementation of BMMI discriminative training.

Note that for cluster-based LR adaptation, the LR transforms are updated at the clusters of the binary tree that have an occupancy count larger than a certain threshold. For dMMI-LR we use the occupancy counts calculated using the ML criterion instead of that given by Eq. (21) since the latter may take unrealistic values (i.e. negative values). The same strategy has been used for other discriminative criterion based adaptation (Uebel and Woodland, 2001).

Several approaches can be employed for gradient optimization. Here we use the RPROP algorithm (Riedmiller and Braun, 1993) as it has been used successfully for discriminative training (McDermott et al., 2007; Heigold et al., 2012). We also employ an early stopping technique, where we fix the number of iterations using a development set.

dMMI-LR shares characteristics with other acoustic model adaptation techniques. The use of a discriminative criterion for LR based acoustic model adaptation has been proposed previously, and includes such approaches as MMI-LR (Wallhoff et al., 2000; Uebel and Woodland, 2001), MPE-LR (Wang and Woodland, 2004; Gibson and Hain, 2012), MCE-LR (Wu and Huo, 2007; Hazen and McDermott, 2007) and soft-margin based LR (Matsuda et al., 2009). Most of these techniques target supervised adaptation where the quality of the reference labels is high. For unsupervised adaptation, several approaches have been proposed to mitigate problems with errors in the reference labels. For example, the 1-best recognition results usually used as labels were replaced by lattices for MAP (Matsui and Furui, 1996) and MLLR adaptation (Nguyen et al., 1999; Padmanabhan et al., 2000; Uebel and Woodland, 2001, 2001). Lattice-based MLLR achieves a smoothed definition of the references similar to dMMI-LR. However, it does not include the margin term that makes it possible to focus on recognition candidates with low errors.

Another approach consists of calculating adaptation parameters only using words with high confidence scores. Such an approach was used for MLLR (Zeppenfeld et al., 1997; Uebel and Woodland, 2001) and extended to unsupervised discriminative adaptation (Wallhoff et al., 2000; Wang and Woodland, 2008; Gibson and Hain, 2012). In Wang and Woodland (2008) and Gibson and Hain (2012) the authors proposed weighting the terms in the numerator of the MPE objective function with an estimate of the correctness of each word in the reference labels. Accordingly, attention is given to reference labels with few errors in the mean error calculation. The word correctness estimation can be obtained from confusion networks (Wang and Woodland, 2008) or by using an SVM-based binary classifier (Gibson and Hain, 2012). These approaches achieve a similar smoothing effect to the margin term in the numerator of the dMMI objective function. However, for dMMI, the smoothing is intrinsic to the objective function. There are also implementation differences between our work and that of Wang and Woodland (2008) and Gibson and Hain (2012). Wang and Woodland (2008) and Gibson and Hain (2012) requires a separate module to estimate the word correctness. Moreover, they employ different lattices generated with strong and weak language models for the numerator and denominator of the objective function. The proposed dMMI-LR uses the same lattices for the numerator and denominator, which may simplify the implementation.

Finally, let us mention another interesting approach for unsupervised adaptation designed to estimate discriminative mapping transforms between MLLR and MPE-LR transforms (Yu et al., 2009). The discriminative mapping transforms can be estimated during training and are therefore unaffected by the quality of the reference labels when performing unsupervised adaptation. In this regard, our approach is fundamentally different because we perform direct adaptation experiments using the test data as adaptation data.

@&#EXPERIMENTS@&#

We conduct experiments with two lecture recognition tasks. The first task (CSJ) consists of relatively short Japanese presentations at conferences. The second task (MIT-OCW) consists of long English university lectures. For both tasks we perform per-presentation/lecture, unsupervised speaker adaptation.

The CSJ corpus is a speech corpus that consists of Japanese presentations recorded with a headset microphone (Maekawa et al., 2000; Maekawa, 2003). The corpus includes recordings of actual academic presentations recorded at conferences related to nine different academic fields. The corpus also includes simulated public speech (non-academic presentation about everyday life topics), which consists of sessions of 10–12min of spontaneous presentations recorded in recording studios. The corpus includes about 7 million words.


                        Table 1
                         shows the amount of data used for the training and testing sets of CSJ. The training data consist of 228h of academic presentations and 258h of simulated public speech. 80% of the academic presentations is spoken by males. In contrast the simulated public speech is approximately balanced in terms of gender. As a result, the training data contains about 310h of male speech and only 176h of female speech. The out-of-vocabulary (OOV) rate of the test sets is 0.6%.

We used test set 2 and test set 1 as development (Dev.) and evaluation (Eval.) sets, respectively. There is also a third test set that consists only of simulated public speech, but it is usually not employed (McDermott et al., 2007). Both sets consist of 10 academic presentations. The average duration of a presentation is about 12min.

All experiments were performed using acoustic models consisting of left-to-right phone HMMs with phone state probabilities modeled with GMMs. The models contained 4100 context-dependent HMM states each modeled with a GMM of 32 mixture components. The acoustic models were trained with the CSJ training data set. We trained two sets of acoustic models, one with ML and one with dMMI. For the model trained with dMMI, we used the following margin parameters, σ
                           1
                           =−2 and σ
                           2
                           =2.

The acoustic features used for recognition consist of 12 order MFCCs, the energy coefficient, delta and delta–delta coefficients (39 coefficients in total). The features were processed with cepstral mean normalization (CMN).

The language model consisted of word trigram models trained using 7.2M words of manually transcribed lecture speech. The vocabulary size of the lexicon was 6.3K.

We performed unsupervised speaker adaptation, where we processed each session in a batch manner, i.e. we used all the data of a given presentation to generate recognition lattices, estimate adaptation parameters and perform the final recognition evaluation. All parameters (i.e. margin parameters, number of iterations, …) were tuned on the development set and the same parameters were used for the evaluation set. We set the occupancy count threshold for MLLR at 5000, which corresponds to about 18 LR transformation matrices. This value was chosen for the occupancy count threshold as it achieved the best performance on the development set for MLLR. The same occupancy count threshold was used for BMMI-LR and dMMI-LR.

For BMMI-LR and dMMI-LR we used the acoustic models adapted with MLLR as initial models. This ensured a good initial condition and is equivalent to the common practice in discriminative training of using an acoustic model trained with ML as the initial value. Note that a similar initialization has been used previously in other discriminative adaptation studies (Uebel and Woodland, 2001; Wu and Huo, 2007; Wang and Woodland, 2008; Gibson and Hain, 2012).

The margin parameter σ used for BMMI-LR was set at 0.1. For dMMI-LR, we used the same value for the margin parameter of the denominator, i.e. σ
                           2
                           =0.1. We chose this value because it gave best performance for adaptation in a small preliminary experiment and because it enables to approach MPE when setting σ
                           1 at −0.1. The margin parameter of the numerator, σ
                           1 was tuned using the development set. We used I-smoothing for BMMI-LR to smooth to ML, but not for dMMI-LR as it did not provide performance gains.

The performance was measured in terms of word error rate (WER) averaged over the 10 test sessions.

@&#RESULTS@&#


                           Table 2
                            shows the results we obtained when using the acoustic models trained with ML and dMMI. All the adaptation results were obtained with gradient-based optimization using the RPROP algorithm. Note that in preliminary experiments we confirmed that for MLLR gradient-based optimization performed slightly better than the expectation maximization (EM) algorithm that is usually used. This has also been reported in other studies (Wu and Huo, 2007), and can probably be attributed to the fact that the gradient-based implementation does not require matrix inversion, therefore making the optimization more stable. In the following, all results are given for gradient-based MLLR.

The table shows the results without adaptation and with adaptation with MLLR, lattice-based MLLR, BMMI-LR and dMMI-LR. The results with the ML model are used to gain a fair comparison between dMMI-LR and BMMI-LR. Indeed, we could argue that using an acoustic model trained with dMMI works in favor of dMMI-LR.
                              7
                           
                           
                              7
                              Note that we did not use the same margin parameters for dMMI training and dMMI-LR adaptation. Consequently, strictly speaking, the discriminative criteria employed for training and adaptation are different.
                           
                        

In this experiment, we used two types of labels to confirm the influence of the quality of the reference labels. The first types of labels are the 1-best recognition results obtained with the baseline acoustic models without adaptation (baseline labels). The results with these reference labels are shown in the first part of Table 2 (Systems II to V).The second types of labels are obtained using the acoustic model adapted with MLLR (new labels). The results with the new reference labels are shown in the second part of Table 2 (Systems VI to VIII).

Let us first discuss the results for the first part of Table 2 (i.e. Systems II to V). MLLR adaptation (System II) works particularly well in this task, especially for the development set. The training data are largely biased towards male speakers, whereas the development set contains 5 male and 5 female speakers. Therefore, adaptation is particularly effective for the female speakers, which explains the large performance improvement on the development set. In contrast, the evaluation set contains only male speakers and accordingly speaker adaptation causes smaller but still noticeable performance improvement.

Lattice-based MLLR (System III) slightly improves the performance for the development set but the results do not generalize to the evaluation set. For BMMI-LR (System IV), we observe a small reduction in WER when using the dMMI acoustic model but a small performance degradation when using the ML acoustic model. This seems to confirm the sensitivity of BMMI to the quality of the reference labels. In contrast, dMMI-LR (System V) consistently improves performance by more than 1 percentage point for the ML acoustic model and between 0.6 and 0.3 percentage points for the dMMI acoustic model. The value of the numerator margin parameter used for dMMI-LR was σ
                              1
                              =−30 as it was shown to perform the best for the development set (see Section 4.1.3). The improvement brought about by dMMI-LR over MLLR was significant with significance level below 0.01 for the acoustic model trained with ML, and 0.05 for the acoustic model trained with dMMI.

These results show the potential of the dMMI criterion for unsupervised adaptation. The larger improvement obtained for the ML acoustic model is probably due to the fact that the models obtained after adaptation become discriminatively trained. Therefore performance improves compared with an ML trained or adapted system as it is generally observed with discriminative training. Moreover, the fact that performance improves even when the baseline WER is about 20% confirms that dMMI-LR can somehow mitigate errors in the reference labels.

The last part of Table 2 shows the performance obtained when labels are recalculated after a first run of MLLR (Systems VI to VIII). Once again we observe superior performance for dMMI-LR (System VIII) compared with conventional MLLR (VI) or BMMI-LR (VII). Note that in this case we set the numerator margin parameters σ
                              1 for dMMI-LR at −20 for the ML acoustic model, and at −15 for the dMMI-AM acoustic model as discussed in Section 4.1.3.


                           Fig. 3
                            plots the performance of dMMI-LR for the development set as a function of the numerator margin parameter σ
                           1 for acoustic models trained with ML and dMMI. We plot the results for dMMI-LR and MLLR with and without new labels (labels obtained after the first run of MLLR).


                           Fig. 3 clearly reveals that there is an optimal value for the margin parameter and it differs from the values for MPE or BMMI, i.e. σ
                           1 close to 0 or σ
                           1→−∞. This observation confirms that for an appropriate choice of margins, the smoothed definition of the reference in dMMI improves performance when reference labels contain errors.

Interestingly, by comparing the curves obtained with and without new labels, we observe that the optimal value of the margin parameter σ
                           1 changes depending on the quality of the reference labels. With the new labels, a larger value of σ
                           1 gives better performance. In this case, dMMI moves towards the MPE criterion, which is more discriminative. It seems reasonable that when the reference label quality improves a more discriminative criterion can be used. Note that this experiment can be related to an MPE-LR unsupervised adaptation experiment (Wang and Woodland, 2008), where care was taken to obtain accurate reference labels in order to achieve good adaptation performance. In Wang and Woodland (2008), MPE-LR with relatively accurate labels outperformed MLLR.


                           Fig. 4
                            plots the WER as a function of the number of iterations for the CSJ development set for MLLR, BMMI-LR and dMMI-LR, when using the ML based acoustic model. Note that the curves for BMMI-LR, dMMI-LR and MLLR with new labels start from the 30th iteration because they all employ the model obtained with MLLR after 30 iterations as initial value. The number of iterations is relatively large, because we used a small initial learning rate for RPROP to assure convergence.

Although the results in Table 2 were obtained using early stopping with a number of iterations that gave the best performance for the development set, the relatively smooth convergence curve of dMMI-LR suggests that the results may not be affected too severely by the choice of the number of iterations as long as it is large enough. Note that even if we did not perform I-smoothing for dMMI-LR, we do not observe much overfitting at least up to 30 iterations. We expect that the performance may start to degrade with a larger number of iterations.

It is interesting to observe the performance of a discriminative training criterion as a function of the complexity of the model, i.e. here the number of adaptation transformations. This can be realized here simply by changing the value of the occupancy count threshold, which directly affects the number of LR transforms used. Fig. 5
                            plots the WER as a function of the number of LR transforms used for MLLR and dMMI-LR. We varied the value of the occupancy count threshold between 5000 and 500, corresponding to a number of LR transforms ranging from 18 to 170. The best performance could be obtained both for MLLR and dMMI-LR using an occupancy count threshold of 5000, which corresponds to about 18 LR transformation matrices. Although not shown in the figure, the performance degrades when using a smaller number of transformations.

The performance with MLLR is relatively stable when using a sufficient number of LR transformation matrices. Note that the fact that the performance do not degrade much when using a large number of LR transforms can be attributed to the use of the gradient-based implementation of MLLR. Indeed, when using gradient-based optimization, MLLR does not require matrix inversions as with conventional EM-based MLLR (Leggetter and Woodland, 1995). Therefore, it becomes possible to use fewer data samples with each transform (Wu and Huo, 2007). We confirmed this intuition with an informal experiment that revealed that with EM-based MLLR, the performance degradation increased as the number of transforms increased.

dMMI-LR improves the performance compared with MLLR in most cases. However, we observed a performance degradation with increased model complexity, i.e. an increased number of transforms. This is consistent with the general observation that performance improvement over ML of discriminative criteria becomes smaller as we increase the number of model parameters for a fixed amount of training data (Heigold et al., 2012).

We also performed experiments using another large vocabulary corpus to confirm the findings from the CSJ experiment. Here we use the MIT-OCW speech corpus (Glass et al., 2007), which consists of university lectures given by MIT professors. The duration of each lecture is approximately 50min.

The training data consist of 104 lectures corresponding to a total duration of 110h of speech. We use development and evaluation test sets that consist of 2 and 8 lectures, respectively. The OOV rate of the test sets is 3.1%.

This task is well suited for speaker adaptation, because there is a relatively large amount of speaker specific data since each lecture is given by a single speaker.

In this experiment we also used left-to-right phone HMMs for acoustic models. As with the CSJ experiment, the HMM state probability densities were modeled with a GMM with 32 components. There were a total of 2546 context dependent states, which was automatically determined by variational Bayes (Watanabe et al., 2006). In the experiment, we only present results with a discriminatively trained acoustic model that was obtained using dMMI with margin parameters σ
                           1
                           =−2 and σ
                           2
                           =3. Note that the margin values for the dMMI training were set according to McDermott et al. (2010) as it gave the best performance on the development set for this task.

As with the CSJ experiments of Section 4.1, we used acoustic feature vectors consisting of 12-dimension MFCCs with energy, delta and delta–delta (39 dimensions in total). The feature vectors were processed with CMN.

The language model consisted of word trigram models trained using 6.2M words of manually transcribed lecture speech. The vocabulary size of the lexicon was 16.5K.

As in the previous experiment, we used unsupervised batch adaptation on a per lecture basis. We also used an occupancy count threshold set at 5000, and an acoustic model adapted with MLLR as the initial value for BMMI-LR and dMMI-LR. The margin parameter for BMMI-LR was set at 0.1. For dMMI-LR we used σ
                           2
                           =0.1 and tuned σ
                           1 on the development set. We used I-smoothing for BMMI-LR but not for dMMI-LR. These settings are equivalent to those used for the CSJ experiments.

A notable difference with the CSJ experiment is the amount of data available for speaker adaptation, i.e. about 10min for CSJ and 50min for MIT-OCW.

@&#RESULTS@&#


                           Table 3
                            shows the results for the development and evaluation sets of the MIT-OCW task without and with adaptation using MLLR, Lattice-MLLR, BMMI-LR and dMMI-LR. In this experiment to achieve a fair comparison, all reference labels used for adaptation were obtained from the baseline dMMI AM acoustic model without adaptation. The results obtained for the MIT-OCW task exhibited a similar trend to those for the CSJ task in Section 4.1.2. In particular, dMMI-LR outperformed BMMI-LR, and improved the performance compared with MLLR by about 1 percentage point for both the development and evaluation sets.

Note that we also confirmed that dMMI-LR improved the performance compared with MLLR for all the lectures in the test sets with relative improvements ranging from 1% to 7.4% depending on the lectures. Moreover, the improvement brought about by dMMI-LR over MLLR was significant according to the matched pair sentence segment test (significance level below 0.001) calculated using the NIST scoring toolkit (Fiscus, 2012).

The value of the numerator margin σ
                           1 used for the results in Table 3 was chosen using the development set. Fig. 6
                            plots the WER as a function of the margin parameter σ
                           1 for the development set of MIT-OCW. We observe that the best performance was obtained with σ
                           1
                           =−10 and we used this value of σ
                           1 for the results in Table 3. Although the best performance was obtained for σ
                           1
                           =−10, performance improvement can be achieved for a relatively large range of σ
                           1 values, i.e. σ
                           1
                           ∈[−30, −5]. Interestingly, we can also observe performance improvement for σ
                           1 values in the same range for the experiments in the CSJ task (see Fig. 3). This observation suggests that although the optimal σ
                           1 value can be affected by the quality of the reference labels and the task, some improvement over MLLR can be obtained with dMMI-LR for a wide range of σ
                           1 values.

@&#CONCLUSION@&#

In this paper we reviewed the recently proposed dMMI criterion and discussed its use for unsupervised adaptation. We showed that dMMI generalizes MPE and MMI criteria. Moreover, dMMI with properly set margin parameters can define references in a smoothed manner, which may reduce the sensitivity against errors in reference labels. This property of the dMMI criterion was confirmed for unsupervised speaker adaptation tasks. In particular, we showed that dMMI-LR could outperform MLLR and BMMI-LR. In our experiments with two different LVCSR tasks, we observed that the optimal value of the margin parameter differed depending on the task and the quality of the reference labels. However, WER improvement could be obtained for a relatively wide range of numerator margin values on both tasks (for numerator margin values set between −30 and −5).

In this paper, we used unsupervised speaker adaptation because it is a good way to demonstrate the robustness of dMMI to errors in the reference labels. Our experiments were performed using a conventional GMM–HMM based recognizer. However, dMMI-LR could also be useful in tandem-based systems (Yoshioka et al., 2014). Moreover, dMMI has also been used for training WFST weights for a deep neural network (DNN) based system (Kubo et al., 2012, 2013) and could be used for the sequence training of DNN-HMM acoustic models (Kingsbury, 2009; Mohamed et al., 2010; Vesely et al., 2013; McDermott et al., 2014). Issues with errors in the reference labels also occur with acoustic model training, and therefore dMMI also has potential in such situations. An investigation of the robustness of dMMI to reference label quality for DNN-based ASR systems constitutes our potential future work.

@&#ACKNOWLEDGEMENTS@&#

We wish to thank the editor and the anonymous reviewers whose comments contributed to the improvement of the quality of this paper. We would also like to thank the members of the media information laboratory of NTT Communication Science Laboratories for fruitful discussions and in particular our former colleagues Dr. Erik McDermott (now with Google) and Dr. Shinji Watanabe (now with Mitsubishi Electric Research Laboratories (MERL)). This work was partially supported by JSPS KAKENHI Grant Number 26280063.

@&#REFERENCES@&#


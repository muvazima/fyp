@&#MAIN-TITLE@&#PcHD: Personalized classification of heartbeat types using a decision tree

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We propose a new method for personalized arrhythmia classification of an individual׳s heartbeats by Holter monitoring.


                        
                        
                           
                           We use a decision tree to classify beats.


                        
                        
                           
                           We demonstrate the efficacy of this classifier by means of experiments against the MIT-BIH arrhythmia database.


                        
                        
                           
                           Our classifier is very accurate; it reduces the number of false alarms and missing events.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Heartbeat classification

Decision tree model

Personalization

Electrocardiogram

Pan-Tompkins algorithm

Holter monitoring

@&#ABSTRACT@&#


               
               
                  The computer-aided interpretation of electrocardiogram (ECG) signals provides a non-invasive and inexpensive technique for analyzing heart activity under various cardiac conditions. Further, the proliferation of smartphones and wireless networks makes it possible to perform continuous Holter monitoring. However, although considerable attention has been paid to automated detection and classification of heartbeats from ECG data, classifier learning strategies have never been used to deal with individual variations in cardiac activity. In this paper, we propose a novel method for automatic classification of an individual׳s ECG beats for Holter monitoring. We use the Pan-Tompkins algorithm to accurately extract features such as the QRS complex and P wave, and employ a decision tree to classify each beat in terms of these features. Evaluations conducted against the MIT-BIH arrhythmia database before and after personalization of the decision tree using a patient׳s own ECG data yield heartbeat classification accuracies of 94.6% and 99%, respectively. These are comparable to results obtained from state-of-the-art schemes, validating the efficacy of our proposed method.
               
            

@&#INTRODUCTION@&#

Arrhythmia is an irregular heartbeat or abnormal heart rhythm. The symptoms of arrhythmia are diverse, from minor chest palpitations to a sudden heart attack. If detected at a late stage, arrhythmia is liable to recur frequently, and this is associated with a high risk of death [1]. It is therefore important for patients showing symptoms of arrhythmia, however mild, to be diagnosed as early as possible. Unfortunately, many patients are unaware of their symptoms or are unwilling to visit a hospital, and even those who seek diagnosis may exhibit normal cardiac behavior during their visit. Consequently, there is growing demand for a remote electrocardiogram (ECG) monitoring system that can function continuously and at any location.

Fortunately, the recently developed Holter monitoring device can be integrated with modern smartphones to serve precisely this function (see 
                     Fig. 1), allowing patients to continue their normal routines while their ECG data are sent over a wireless network to a monitoring center for interpretation. If a decision support system identifies a dangerous condition, it alerts medical staffs at the monitoring center, who make a diagnosis and then inform the patient immediately, instructing them as to the most appropriate action to take.

Individual heartbeats in ECG data are primarily characterized by five peaks and valleys (labeled P, Q, R, S, and T) [2], and these can be used to detect arrhythmia. A number of successful arrhythmia classification systems [3–16] have been reported; however, none of these systems take individual cardiac peculiarities into account, even though it has been demonstrated that individuals of the same age, sex, weight, and height can have completely different baseline ECG patterns [17]. It has even been suggested that individuals could be identified by their ECG signals [17,18].

On the basis of these ideas, we propose a new method for arrhythmia classification of an individual׳s heartbeats by Holter monitoring. Specifically, we use the Pan-Tompkins algorithm [2] to accurately extract ECG features, and then use a decision tree to classify beats according to these features. We demonstrate the efficacy of this decision tree classifier by means of extensive experiments using the MIT-BIH arrhythmia database [19].

Our work makes the following two main contributions: (1) a systematic design methodology for a remote ECG monitoring system, and (2) a more accurate classification method that reduces the number of false alarms and missing events by considering more types of heartbeat.

The remainder of this paper is organized as follows: In Section 2, we briefly review work related to ECG feature detection and classification. Section 3 presents our proposed method for extracting features and classifying an individual׳s ECG beats. In Section 4, we profile our experimental dataset, before Sections 5 and 6 present and analyze our experimental results. Finally, in Section 7, we give some concluding remarks and outline possible directions for future study.

@&#RELATED WORK@&#

In this section, we briefly describe previous work related to heartbeat detection and classification.

ECG traces of heartbeats measure the two main activities of the heart: ventricular, characterized by the QRS complex and T waves; and atrial, characterized by P waves [20]. Analysis of the QRS complex remains the simplest noninvasive method of diagnosing a variety of heart diseases. Pan and Tompkins [2] developed a real-time algorithm that is widely used to detect the QRS complex in ECG beats. Further, a number of researchers have proposed detection systems that use the QRS complex; e.g., Ye et al. [3] and Prasad and Sahambi [5] explored the characterization of ECG beats using wavelet features. The wavelet transform is a powerful tool for analyzing non-stationary signals; however, it is expensive from a computational viewpoint. De Chazal et al. [6,7], Rodriguez et al. [9], Llamedo and Martinez [10], De Oliveira et al. [12], Yeap et al. [13], and Zhang et al. [14] used waveform features to detect the QRS complex, while Osowski et al. [8] used higher-order statistics and Hermite coefficient features that can be effective for modeling cumulative indicators, but complicated signals need to be approximated by a linear combination of these functions. Chiarugi et al. [20] and Almeida et al. [21] proposed techniques for detecting P wave, characteristics of atrial activity after the detection of the QRS complex.

Recently, a variety of automatic classification methods for ECG beats have been proposed based on machine learning algorithms [3–16]. Ye et al. [3] and Osowski et al. [8] used a support vector machine (SVM), known to be an excellent and generalizable tool for classification. Ceylan et al. [4], Prasad and Sahambi [5], Yeap et al. [13], and Haseena et al. [15] used artificial neural networks (ANNs) based on a combination of many classifiers. De Chazal et al. [6,7] and Llamedo and Martinez [10] used linear discriminants for heartbeat classification, while Rodriguez et al. [9] and Zhang et al. [14] used decision trees, one of the most common and practical methods for inductive inference. De Lannoy et al. [11] used conditional random fields to classify sequential observations of ECG beats, while De Oliveira et al. [12] used dynamic Bayesian networks to combine information from adjacent events. However, SVM and ANN methods are difficult to understand and interpret. A decision tree is much simpler, and has been shown to provide good results in arrhythmia detection [9].

Decision trees are one of the most widely used and practical learning methods. A number of researchers have used decision trees for heartbeat classification [14,22,24,25]. Zhang et al. [14] extracted features from ECG waveforms using wavelet transforms, and then applied a decision tree to cluster the ECG signals. In the feature extraction process, they used principal component analysis to remove the mutual dependence of features, applied component analysis to make the features independent, and added the RR interval (the interval between successive R points); the ID3 algorithm was used for classification. They classified 31,000 beat segments from the MIT-BIH arrhythmia database as either normal (N), left bundle branch block (B), right bundle branch block (R), paced beat (P), ventricular premature beat (V), or atrial premature beat (A), and achieved recognition accuracy of 96.31%.

Masetic and Subasi [22] proposed a method of detecting congestive heart failure using the autoregressive Burg algorithm and the C4.5 decision tree [23]. Beat segments were detected and separated into two categories: ‘normal’ and ‘congestive heart failure’. Their decision tree was trained using 1300 beat segments from the MIT–BIH arrhythmia database and 1500 beat segments from the BIDMC congestive heart failure database, and their proposed model achieved an accuracy of 99.86%.

Charfi and Kraiem [24] conducted a comparative study of ECG classification using decision trees. They used the Pan–Tompkins algorithm for feature extraction, and compared the C4.5, Improved C4.5, Chi squared automatic interaction detector (CHAID), and Improved CHAID classification algorithms. In classifying four types of beats (normal, right bundle branch block, and atrial fibrillation) C4.5 achieved the best accuracy of 96.87%.

Mert et al. [25] proposed an approach for ECG classification that uses an ensemble decision tree. In the feature extraction process, they used filtering to remove direct current (DC) bias and power line interference, and computed windowing, RR ratio to previous value, RR difference from mean value, the windowed ECG signal between 30 samples before R point and 79 samples after R point (FF), FF ratio to previous FF value, and FF difference from mean value. In the classification process, they used a bagged decision tree. They achieved accuracies of 98.3% and 99.34% using a decision tree and a bagged decision tree respectively.


                        
                        Table 1 compares some related studies that have used decision tree learning. The techniques listed achieved very high accuracies; however, they examined a limited number of types of beat, which can lead to unrealistic results. In this paper, we will consider many more types of heartbeat (i.e., 20) and a large number of heartbeats (108,000), which improves the ability of our classification method to detect the features within an ECG signal.

De Chazal et al. [6] proposed a patient-oriented heartbeat typology to better reflect reality. In their technique, training and testing is based on a patient׳s records within a pessimistic framework. The method proposed by De Chazal et al. [6] achieved a promising accuracy of 87.65%, with a sensitivity of 90.43% and a specificity of 73%.


                     
                     Fig. 2 gives an overview of our proposed system. The training phase is based on ECG data from a number of patients, with the subsequent test phase based on ECG data from a particular patient. Prior to personalization, the trained decision tree is a global model and can be used for general classification, but cannot fully account for individual variations. By adding the personalized test phase, we localize the trained decision tree, and thereby enhance its ability to identify variations in heartbeat.


                     
                     Fig. 3 depicts a typical ECG signal for analysis by our system. The system first trains the decision tree via feature extraction and selection, and then uses the decision tree to classify a patient׳s beats based on the extracted features. The training phase of our classification system comprises feature extraction, feature selection, and classifier training. The digitized ECG is first input to the feature extraction stage. DC drift cancellation and normalization are applied to remove artifacts such as baseline wander and high-frequency noise, before the signal is passed to the modules that detect the QRS complex and P wave.

The feature selection stage reconfigures the results of these modules as features of the waveform. The classifier training stage repeatedly computes uncertainty and selects the best feature. One or more classifier units choose a class of heartbeat in response to the input feature. Typically, the classifiers use the most discriminative feature (set during system development) to optimize performance. The modules forming the various stages are discussed in detail below.

We use the Pan-Tompkins algorithm [2] to accurately extract the QRS complexes. This is a real-time algorithm that employs a band-pass filter, differentiator, and integrator over a moving window. The algorithm cascades low-pass and high-pass filters. We configure the low-pass filter with a cutoff frequency of 11Hz, a gain of 36, and a delay of six samples, and the high-pass filter with a cutoff frequency of 5Hz, a gain of 32, and a delay of 16 samples. The filtered ECG signal is then differentiated to provide the slope information required to identify the QRS complex, and then it is squared. Integrating the moving window produces further waveform feature information, particularly the slope of the R wave. The QRS complex detection module shown in 
                        Fig. 4 depicts the step-by-step output of the Pan-Tompkins algorithm in the heartbeat detection module.

The P wave detection module searches for candidate P waves within the bounds selected by a sub-module. Although a few promising methods have been proposed, it is difficult to detect P waves because of their diversity and the presence of abnormalities and artifacts. Most public databases, including the MIT–BIH arrhythmia database, include annotation for R peaks, but none for P waves. If the P wave is located in half of the nominal duration of the P wave, we use half of that duration as the bound. The P wave duration is measured between a given S point and the next Q point. To find the S and Q points of each cycle, we assume that an S point is the first valley after an R point has been detected, and that a Q point is the valley just before an R point.

The feature selection module is primarily concerned with detecting the QRS complex and P waves. The interval features relating to base points are calculated for each heartbeat, after which six attributes (including the positions of the R and P waves) are extracted (see 
                        Table 2).

We use the J4.8 algorithm [26], which is Weka׳s implementation of the C4.5 decision tree learner, as an extension of the basic ID3 algorithm [27]. This extension considers discrete numerically valued target function domains. The classifier is trained by calculating the uncertainty of the features, and then selecting the most certain. This step is repeated until the system has classified all beats in the training data. Uncertainty is calculated according to the entropy, which is expressed as follows:
                           
                              (1)
                              
                                 Entropy
                                 
                                 (
                                 F
                                 )
                                 =
                                 −
                                 
                                    ∑
                                    
                                       i
                                       =
                                       1
                                    
                                    N
                                 
                                 
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                 
                                 
                                 
                                    
                                       log
                                    
                                    
                                       2
                                    
                                 
                                 
                                 
                                    
                                       p
                                    
                                    
                                       i
                                    
                                 
                              
                           
                        where F denotes a set of heartbeats with extracted features as attributes, N denotes the number of heartbeat types, and p
                        
                           i
                         denotes the proportion of F belonging to the ith type. For a specific attribute, if all members are in the same class, then the entropy of the attribute is zero; if the number of positive and negative examples is equal, then the entropy of the attribute is one (see 
                        Fig. 5). We use information gain to compute the uncertainty of a feature. Given a collection S, information gain is defined as follows:
                           
                              (2)
                              
                                 Gain
                                 
                                 (
                                 S
                                 .
                                 F
                                 )
                                 =
                                 Entropy
                                 
                                 (
                                 F
                                 )
                                 −
                                 
                                    
                                       ∑
                                       
                                          v
                                          ∈
                                          V
                                          a
                                          l
                                          u
                                          e
                                          s
                                          (
                                          F
                                          )
                                       
                                    
                                    
                                       
                                          
                                             |
                                             
                                                
                                                   S
                                                
                                                
                                                   v
                                                
                                             
                                             |
                                          
                                          
                                             |
                                             S
                                             |
                                          
                                       
                                    
                                 
                                 Entropy
                                 
                                 (
                                 
                                    
                                       F
                                    
                                    
                                       v
                                    
                                 
                                 )
                                 .
                              
                           
                        
                     

The feature selection module then selects the most general of all the features on the basis of information gain. We apply a post-pruning strategy (a.k.a backward pruning), and set a minimum of two instances of heartbeat at each leaf.

We presume that the medical staff whose decisions the system is intended to support have no knowledge of data mining or machine learning. This makes interpretability very important, and is a major reason for our adoption of a decision tree, as results are provided in a form that is relatively easy to understand (
                        Fig. 6).

The MIT-BIH arrhythmia database was developed as a standard test dataset for electrocardiography. It contains 48 half-hour excerpts from two channels (MLII and V5) of ambulatory ECG recordings (see 
                     Table 3), obtained from 47 subjects studied by the BIH Arrhythmia Laboratory between 1975 and 1979. The signals were band-pass filtered at 0.1–100Hz and digitized at 360Hz. The database has been used extensively to validate algorithms for arrhythmia detection and classification [2–16,22,24–25]. It also provides us with a basis for comparison with other algorithms. Note that we use only the single MLII channel.


                     Table 3 provides a statistical overview of 17 beat types. The column headed (@) contains totals for the following events: beat not classified during learning (?), change in signal quality (~), isolated QRS-like artifact (|), and rhythm change (+). 
                     Table 4 provides information on the various types of beat in the MIT-BIH arrhythmia database. These are 20 different types of ventricular and atrial beats, all annotated for signal quality and rhythm change, and all successfully classified by our decision tree.

@&#RESULTS@&#

We first evaluated the performance of our method in terms of beat detection, which affects subsequent classification. We considered the sensitivity, specificity, and accuracy, which are defined as follows:
                        
                           (3)
                           
                              Sensitivity
                              =
                              TP
                              /
                              (
                              TP
                              +
                              FN
                              )
                              ,
                           
                        
                     
                     
                        
                           (4)
                           
                              
                              Specificity
                              =
                              TN
                              /
                              (
                              TN
                              +
                              FP
                              )
                              ,
                           
                        
                     
                     
                        
                           (5)
                           
                              Accuracy
                              =
                              (
                              TP
                              +
                              TN
                              )
                              /
                              (
                              TP
                              +
                              FP
                              +
                              FN
                              +
                              TN
                              )
                              ,
                           
                        
                     where TP is the number of true positives, TN is the number of true negatives, FP is the number of false positives, and FN is the number of false negatives. 
                     Table 5 summarizes the results obtained by applying the Pan-Tompkins algorithm to the MIT-BIH arrhythmia database. These show that the algorithm has an average beat detection accuracy of 97.06%, with an average sensitivity of 97.22% and an average specificity of 96.89%. Note that recording 107 has many abnormal beats with unusually large, atypically peaked P waves, resulting in a low specificity (49.95%). This result might be improved through a deeper analysis of the P wave, but that is beyond the scope of the present paper.

The second part of our performance evaluation involved the classification of ECG data of an individual׳s heartbeats. We used the complete database to train our decision tree classifier. The training set consisted of all recordings except those of the individual under consideration. 
                     Table 6 shows the results obtained with the training data: rates of 94.61%, 85.28%, and 89.95% for sensitivity, specificity, and accuracy, respectively, with standard deviations of 4.67, 20.04, and 9.49.

Next, we used the individual data removed from the training set to personalize the decision tree and classify the beats in part of that recording. For this experiment, we utilized a k-fold cross-validation method [28] to estimate the performance of the decision tree. The ECG beats were divided into k subsets of approximately equal size. The classifier was then tested k times, leaving out one of the subsets each time, but using the omitted subset to compute the error in the prediction, and its performance was averaged across k times.

Cross-validation requires both historic and future data with respect to the beat that is currently being classified. However, because our ECG database only covers a limited time period (i.e. 30min), we implicitly ignored the temporal ordering of beats in our k-fold cross-validation. We simply considered (k-1) beat blocks (any combinations) of the record to be historical data, used these to train the decision tree, and classified the remaining block, as shown in 
                     Fig. 7. We believe that this is a valid assumption in Holter ECG monitoring of patient for whom have historical data is available, which is the situation that we are considering.

We set the value of k to 10 and applied our ten-fold cross-validation to the single recording, and obtained results of 97.99%, 72.52%, and 85.26% for sensitivity, specificity, and accuracy, respectively, with standard deviations of 2.8, 35.45, and 17.46 (see 
                     Table 7). Conversely, without personalization, we obtained a low accuracy rate of 4%, with a very low specificity rate of 12%. As regards volume of data, we initially trained the decision tree using the first 15min of data, and tested the beats using the last 3min. Then we increased the amount of training data to 27min, and used the remaining 3min as test data. The results in 
                     Table 8 show that this increase in the amount of training data raises the average sensitivity, specificity, and accuracy by 1.5%, 0.3%, and 0.85%, respectively.

Although there may be some learning bias favoring the performance of our personalized system, these results appear to confirm the applicability of our methods to personal, resource-constrained environments, such as smartphone-based Holter monitors.

@&#DISCUSSION@&#


                     
                     Fig. 8 shows the improvement in classification accuracy using our personalized classification system. On average, our method is 3% more sensitive than non-personalized classification. The proposed system gave superior results for all but one record and, in the case of record 214, achieved a 17% improvement. We also obtained a low specificity, averaging 12% less than for non-personalized classification (72.52 vs. 85.28). This is due to the over-fitting problem associated with decision tree algorithms, which generally occurs when a model is trained with a relatively small dataset. 
                     Table 9 shows the records that produced high FP rates for the original beats. Note that recordings 111, 122, 121, and 230 have specificities of around 0%. We can confirm that these results relate to the nature of certain classes. For instance, recording 214 consists of the L and V classes; however, whereas the L class has 2123 beats, the V class has only one beat. Because this one beat produced an FP, the resulting FP rate for the V class is 100%. Similar circumstances hold for recordings 122, 121, and 230.

To demonstrate that it is possible to improve the specificity, we again connected an ECG recording for training and testing. We also doubled the number of beats to 60min of data by duplicating records from a 30min recording. Using the proposed system, we applied ten-fold cross-validation to this new dataset, and obtained averages of 99.09%, 81.67%, and 90.38% for sensitivity, specificity, and accuracy, respectively. This higher specificity also had a lower standard deviation than with the original dataset. We further experimented with 48 times the original number of beats. The size of this dataset was similar to that used for the global model. These data yielded a 100% score for sensitivity, specificity, and accuracy. Conducting the evaluation using heartbeats from one individual may be considered an optimistic experimental setup, and could lead to unrealistic results. The evaluations conducted without the individual׳s data, using a pessimistic method, also achieved results comparable with those from other techniques.

The major contribution of our work is the consideration of an individual׳s heartbeat, and the consequent organization of training and testing. Although direct comparison with the methods in Table 1 is problematic, the proposed decision tree model can accommodate complicated patterns, and considers many more types of beats. We have compared the results of classification with and without the use of an individual׳s data (see Tables 6 and 7), and examined the effect of the amount of training data on the results of classification using personal beats (Table 8). These results can be used as a baseline to evaluate the potential of our work. We believe that, if the proposed system were used for 24-h Holter monitoring, the amount of data acquired would improve the outcome of personalization, leading to higher sensitivity, specificity, and accuracy.

We have presented and evaluated a novel system for the personal monitoring of cardiac activity that uses a decision tree to classify ECG data from the distinctive waveform features of individual heartbeats. The results of evaluations conducted against the MIT-BIH arrhythmia database indicate that the proposed system is very accurate, with a low FP rate, and demonstrate that personalization of the decision tree significantly improves performance.

In the future, we will add a “live mode” to our classification system for use in practical, mobile Holter monitoring. We also plan to improve the classification accuracy by using two channels to locate morphological features, using a harmonic classification forest with and without the individual׳s beats, and revising the P wave module to analyze atrial activity.

None declared.

@&#ACKNOWLEDGMENT@&#

The authors would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the quality of the paper. This research was supported in part by the MSIP (Ministry of Science, ICT & Future Planning), Korea, under the ITRC (Information Technology Research Center) support program (NIPA-2014-H0301-14-1044) supervised by the NIPA (National ICT Industry Promotion Agency) and in part by the Basic Science Research Program through the National Research Foundation of Korea (NRF) funded by the MSIP (NRF-2013R1A1A1059188).

@&#REFERENCES@&#


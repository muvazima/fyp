@&#MAIN-TITLE@&#Scalable gastroscopic video summarization via similar-inhibition dictionary selection

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           We design a dictionary selection model via the similar-inhibition constraint.


                        
                        
                           
                           We propose a scalable gastroscopic video summarization algorithm.


                        
                        
                           
                           We build the first gastroscopic video summarization dataset with 30 videos.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Video summarization

Key frame

Similar-inhibition dictionary selection

Image attention prior

Gastroscopic video

@&#ABSTRACT@&#


               
               
                  Objective
                  This paper aims at developing an automated gastroscopic video summarization algorithm to assist clinicians to more effectively go through the abnormal contents of the video.
               
               
                  Methods and materials
                  To select the most representative frames from the original video sequence, we formulate the problem of gastroscopic video summarization as a dictionary selection issue. Different from the traditional dictionary selection methods, which take into account only the number and reconstruction ability of selected key frames, our model introduces the similar-inhibition constraint to reinforce the diversity of selected key frames. We calculate the attention cost by merging both gaze and content change into a prior cue to help select the frames with more high-level semantic information. Moreover, we adopt an image quality evaluation process to eliminate the interference of the poor quality images and a segmentation process to reduce the computational complexity.
               
               
                  Results
                  For experiments, we build a new gastroscopic video dataset captured from 30 volunteers with more than 400k images and compare our method with the state-of-the-arts using the content consistency, index consistency and content-index consistency with the ground truth. Compared with all competitors, our method obtains the best results in 23 of 30 videos evaluated based on content consistency, 24 of 30 videos evaluated based on index consistency and all videos evaluated based on content-index consistency.
               
               
                  Conclusions
                  For gastroscopic video summarization, we propose an automated annotation method via similar-inhibition dictionary selection. Our model can achieve better performance compared with other state-of-the-art models and supplies more suitable key frames for diagnosis. The developed algorithm can be automatically adapted to various real applications, such as the training of young clinicians, computer-aided diagnosis or medical report generation.
               
            

@&#INTRODUCTION@&#

More and more people are suffering from stomach diseases, and the trend is rising [1]. As an effective technique to show the interior of a stomach directly, gastroscopy has been widely used for clinical examination, especially for the early detection of gastric cancer. Usually, the entire procedure lasts approximately 20 min, and a video containing approximately 15,000 frames is captured. However, the visual inspection of such a large number of frames is a challenging task, even for the most experienced clinicians. To more easily browse through such a video archive, a clinician records approximately 20–50 images manually during the examination for diagnosis and later generates a medical report. Nonetheless, the manual annotation may have the following shortcomings:
                        
                           •
                           Because of the need to perform multiple tasks simultaneously, clinicians may miss some important information for the final diagnosis.

Due to the lack of enough experience, some junior clinicians cannot guarantee accuracy when analyzing the massive data continuously. Especially when the operation is not timely, clinicians may select poor quality images.

After the completion of the manual operation, the number of selected frames is fixed, which cannot meet the needs of different scenarios and may increase the time cost for re-analysis.

In fact, the above process is a typical video summarization procedure, i.e., selecting some frames with the most important and meaningful semantic content from a full-length video sequence [2–5]. Therefore, in this paper, we intend to design a computer-aided gastroscopic video summarization algorithm to overcome these problems and assist clinicians to more effectively go through the abnormal contents of the video. The computer-aided system based on our algorithm can be adopted in real applications, such as the training of young clinicians, computer-aided diagnosis or medical report generation.

For video summarization [6–10], most state-of-the-art methods mainly focus on the summarization of structured videos, such as sports, cartoons or surveillance videos. In comparison, the automatic summarization of unstructured data, e.g., gastroscopic videos, is much more challenging. First, gastroscopic videos contain deformable and low-texture context, which makes it more difficult to extract semantic information. Second, due to the complexity of the inner human cavity and arbitrary movement of the camera, some gastroscopic images are of poor quality, which makes an accurate video summarization difficult. Finally, the objective of gastroscopic video summarization is for diagnosis, so the result of video summarization should highlight the suspected regions. Some previous models, e.g., the group sparsity dictionary selection model [2] in our previous work, cannot handle the above challenges very well. For gastroscopic videos, the result cannot encompass all video content, and some similar frames are also frequently selected as key frames. Therefore, we design a new similar-inhibition dictionary selection model by adopting the similar-inhibition constraint to select elements with more diversity between each other. Based on the similar-inhibition constraint, the video structure information will be taken into account to cover as much video content as possible in comparison with traditional sparse dictionary selection models. Furthermore, we also integrate an attention prior into the group sparsity term to reduce the gap between low-level features and high-level concepts. The main contributions of this paper reside in three aspects:
                        
                           •
                           We design a new dictionary selection model by adopting the similar-inhibition constraint, which reinforces the diversity of the selected subset.

By taking into account the attention prior, we propose a scalable gastroscopic video summarization algorithm via similar-inhibition dictionary selection, which can select key frames with the most semantic information efficiently.

We collect and build a new gastroscopic video summarization dataset from 30 volunteers with approximately 432,000 frames, and we annotate the ground truth for evaluation as well. To the best of our knowledge, this dataset is the first gastroscopic video summarization dataset.

The rest of this paper is arranged as follows. Section 2 discusses the related works. In Section 3, we present the formulation of the problem. Section 4 describes the implementation of our video summarization. Section 5 presents various experiments and comparisons. Finally, Section 6 concludes the paper.

@&#RELATED WORKS@&#

The problem of video summarization has attracted significant attention, especially over the past few years, and [9,11] propose detailed reviews of existing techniques. To capture the content changes in a video sequence, most existing approaches first segment the whole video into shots using shot detection methods and then select key frames from each shot [12,13]. The simplest method is to select the first/middle/last frame of each shot as key frames. Shahraray and Gibbon [14] propose a content-based sampling method to select key frames. Panagiotakis et al. [15] first choose the first and last frames of each shot as key frames and then compute the remaining key frames with the maximum equidistant in the sense of the Iso-Content. Taking the pre-determined number of key frames as a constraint, Lee and Kim [16] adjust the positions and time-intervals of key frames by reducing the distortion iteratively. These algorithms can be called sequential algorithms and produce acceptable results for videos with simple structures, such as movies and news, where the presence of a shot indicates new content.

Another approach intends to group the frames into visually similar clusters and selects frames relevant to the cluster centers as key frames [17,18]. Zhuang et al. [19] group the frames in clusters and selects the key frames from the largest clusters. Jiang et al. [20] use the k-means method to cluster the data points in Laplacian subspace and select the key frames from a three layer video structure. To reduce the redundancy of video for personal video recorders, Gao et al. [21] remove redundant video content to select key frames using the hierarchical agglomerative cluster method. Lee et al. [22] first use novel egocentric saliency cues to train a category-independent regression model for predicting how likely an image region belongs to an important person or object. Then, a new video is partitioned into events by clustering scenes with similar global appearance. For each cluster, the region with the highest importance score is selected as its representative. Although clustering techniques have been quite effective, the loss of semantic details is almost inevitable, leading to a significant semantic gap.

There are also many optimization-based algorithms. By solving a specifically designed objective function under selection criteria, the optimal data points are selected as key frames. For instance, Shih [23] combines the visual saliency-based attention features with the contextual game status information of sports videos and selects the key frames with the maximal visual attention scores. Liu et al. [24] model the summarization procedure as a maximum a posterior problem by integrating both shot boundary detection and key frame selection. In [2], the key frames are selected via a novel dictionary selection model, and similar ideas are also applied in [25–28].

For medical endoscopy, one important field is the inspection of the gastrointestinal tract (GT tract) [29]. Many computer-aided endoscopy diagnosis systems have been proposed to assist clinicians in improving the accuracy of medical diagnosis using the images or videos recorded in the inspection of a GT tract. According to the specific lesions, these systems can be classified to handle bleeding [30,31], tumors [32,33], Helicobacter pylori [34], cancer [35,36], Crohn's disease [37] and polyps [38]. Moreover, some other applications include pose detection for endoscopy [39], video segmentation [40] and three-dimensional reconstruction of the digestive wall [41]. For video summarization, as discussed above, most previous works mainly focus on the summarization of structured videos, which have well-defined temporal structures and characteristics for selecting key frames. In comparison, the endoscope video of our problem is more subjective and difficult for summarization. To our best knowledge, the state-of-the-art works for endoscope video summarization merely adopt wireless capsule endoscopy (WCE) data, such as [42–44], while ours focuses on the summarization of the traditional gastroscopic video. Although a gastroscopic video is obtained in a supervised condition and lasts approximately 20 min, it is also necessary to select some key frames to abstract the gastroscopic video. First, the gastroscopic video contents are diverse, and there is much redundant information, which confirms the necessity to obtain a quick idea of what happens in the video. Then, when the prolonged video, e.g., WCE, needs to be segmented into shots for processing [45,43], the gastroscopic video is long enough in terms of the information. Finally, the gastroscopic video contents are uncontrollable, although the video is obtained under the supervision of clinicians, which is similar to the video summarization of sports/news videos recorded by photographers [46–48].

The purpose of video summarization is to select the most representative frames from the underlying video source that represent the video contents properly. In this paper, we formulate the problem of gastroscopic video summarization as a dictionary selection issue, i.e., to select an optimal subset from the original video frames via dictionary learning under various constraints. The video sequence can be represented as an initial dictionary 
                        B
                        =
                        [
                        
                           b
                           1
                        
                        ,
                        
                           b
                           2
                        
                        ,
                        .
                        .
                        .
                        ,
                        
                           b
                           N
                        
                        ]
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           
                              d
                              ×
                              N
                           
                        
                      (N is the number of frames and d is the feature dimension), where each column vector 
                        
                           b
                           i
                        
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           d
                        
                      denotes a video frame represented as a feature vector. In the traditional dictionary selection-based method [2], the reconstruction error, which indicates the ability to use the selected frames to reconstruct the original video contents, and the sparsity, which indicates the number of selected frames, are taken into consideration. The problem is formulated as Eq. (1):


                     
                        
                           (1)
                           
                              
                                 min
                                 X
                              
                              :
                              
                                 1
                                 2
                              
                              ∥
                              B
                              −
                              BX
                              
                                 ∥
                                 F
                                 2
                              
                              +
                              λ
                              ∥
                              X
                              
                                 ∥
                                 
                                    2
                                    ,
                                    1
                                 
                              
                              ,
                           
                        
                     where 
                        X
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           
                              N
                              ×
                              N
                           
                        
                      is the pursuit coefficient matrix, the Frobenius norm ∥X
                     ∥
                     
                        F
                      is defined as 
                        ∥
                        X
                        
                           ∥
                           F
                        
                        :
                        =
                        
                           
                              (
                              
                                 ∑
                                 
                                    i
                                    ,
                                    j
                                 
                              
                              
                                 X
                                 ij
                                 2
                              
                              )
                           
                           
                              1
                              /
                              2
                           
                        
                     , and the ℓ2,1 norm is defined as 
                        ∥
                        X
                        
                           ∥
                           
                              2
                              ,
                              1
                           
                        
                        :
                        =
                        
                           ∑
                           
                              i
                              =
                              1
                           
                           N
                        
                        ∥
                        
                           X
                           
                              i
                              .
                           
                        
                        
                           ∥
                           2
                        
                      (X
                     
                        i. denotes the ith row of x). The ℓ2,1 norm is indeed a general version of the ℓ1 norm because if x is a vector, then ∥X
                     ∥
                     2,1
                     =∥
                     X
                     ∥
                     1. Moreover, ∥X
                     ∥
                     2,1 is equivalent to ∥x
                     ∥
                     1 by constructing a new vector 
                        x
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           N
                        
                      with x
                     
                        i
                     
                     =∥
                     X
                     
                        i.
                     ∥
                     2. Relatively speaking, the ℓ2,1 norm can enforce the consistency of the sparsity on the solution, i.e., the solution needs to contain some “0” rows such that the corresponding features in B are not selected to reconstruct any frames [2]. Generally, the first term reconstruction error indicates that the original dictionary B can be reconstructed with higher accuracy using the subset. The second term group sparsity constraint indicates that the size of the selected subset should be as small as possible. Each row of x illustrates the contributions of one frame to reconstruct other frames. Now, we can select the key frames based on the row values. The ℓ2-norm of each row, 
                        
                           w
                           i
                        
                        =
                        ∥
                        
                           X
                           
                              i
                              .
                           
                        
                        
                           ∥
                           2
                        
                     , can be considered as the weight/importance of b
                     
                        i
                      for dictionary selection, i.e., the greater the value of 
                        
                           w
                           i
                        
                      is, the higher the probability b
                     
                        i
                      is selected to build the dictionary (i.e., key frame in our case), where 
                        
                           w
                           i
                        
                        =
                        0
                      means that the corresponding b
                     
                        i
                      plays no role. For the issue of gastroscopic video summarization, Eq. (1) is not enough because we hope the contents of key frames selected by our model can cover sufficient, unique, useful information and can be diverse as much as possible, while Eq. (1) may select some similar or useless images. Therefore, we define the similar-inhibition constraint and the attention prior to build our new dictionary model, which intend to reduce the redundancy between each selected element and reinforce more useful information.

Our gastroscopic video summarization problem can be formulated as:


                     
                        
                           (2)
                           
                              
                                 min
                                 X
                              
                              :
                              
                                 1
                                 2
                              
                              ∥
                              B
                              −
                              BX
                              
                                 ∥
                                 F
                                 2
                              
                              +
                              λ
                              ∥
                              PX
                              
                                 ∥
                                 
                                    2
                                    ,
                                    1
                                 
                              
                              +
                              β
                              
                                 ∑
                                 
                                    i
                                    ,
                                    j
                                    =
                                    1
                                 
                                 N
                              
                              ∥
                              
                                 X
                                 
                                    i
                                    .
                                 
                              
                              
                                 ∥
                                 2
                              
                              
                                 S
                                 ij
                              
                              ∥
                              
                                 X
                                 
                                    j
                                    .
                                 
                              
                              
                                 ∥
                                 2
                              
                              ,
                           
                        
                     where λ and β are the preset tuning parameters, which balance the weight of these three terms, i.e., reconstruction error term, group sparsity term and similar-inhibition term. 
                        P
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           
                              N
                              ×
                              N
                           
                        
                      and 
                        S
                        =
                        {
                        
                           S
                           ij
                        
                        }
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           
                              N
                              ×
                              N
                           
                        
                      play important roles in characterizing the group sparsity and similar-inhibition constraint, respectively. The first term is the reconstruction error constraint as in Eq. (1). The second term is the group sparsity constraint, which introduces a prior matrix 
                        P
                        ∈
                        
                           
                              
                                 ℝ
                              
                           
                           
                              N
                              ×
                              N
                           
                        
                      to encourage the selection of frames with more attention. P is a diagonal matrix, with the ith diagonal element as P
                     
                        ii
                     
                     =1/M
                     
                        i
                     . The larger the value of M
                     
                        i
                      is, the more attention the corresponding frame gets and the smaller the cost is as well. More details about the attention prior are proposed in Section 4.4. The third term is the similar-inhibition constraint, which aims to reinforce the diversity and penalize the condition that the rows of two similar elements are nonzero at the same time. For each sample pair (b
                     
                        i
                     , b
                     
                        j
                     ), if b
                     
                        i
                      is similar to b
                     
                        j
                     , then one should assign a large weight to S
                     
                        ij
                     , which helps prevent the choice of two similar frames as key frames. Otherwise, S
                     
                        ij
                      should be set to a very small value, which has a negligible impact on choosing both b
                     
                        i
                      and b
                     
                        j
                      as key frames. To make the similar-inhibition term more flexible, different from the fixed interval used by Liu et al. [49], we formulate the weight matrix as


                     
                        
                           (3)
                           
                              
                                 S
                                 ij
                              
                              =
                              exp
                              
                                 
                                    
                                       −
                                       
                                          
                                             ∥
                                             
                                                b
                                                i
                                             
                                             −
                                             
                                                b
                                                j
                                             
                                             
                                                ∥
                                                F
                                                2
                                             
                                          
                                          
                                             
                                                σ
                                                s
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                              ,
                              
                              
                              
                              i
                              ,
                              j
                              =
                              1
                              ,
                              …
                              ,
                              N
                              ,
                           
                        
                     where σ
                     
                        s
                      is a constant (here, we set 
                        
                           σ
                           s
                           2
                        
                        =
                        24
                     .) and S
                     
                        ij
                     
                     ∈(0, 1]. The more similar b
                     
                        i
                      and b
                     
                        j
                      are, the larger S
                     
                        ij
                      is. By doing this, similar frames can be mutually inhibited so that the selected key frames are more diverse. Under these three terms, our new model can grab more useful information from the original video and help clinicians quickly go through the abnormal contents of the video in a more efficient manner.

Because the third term is nonconvex, the above objective function in Eq. (2) is difficult to solve. Therefore, we use an efficient iterative algorithm to solve this problem in our paper. We first transform Eq. (2) as


                        
                           
                              (4)
                              
                                 
                                    min
                                    X
                                 
                                 :
                                 
                                    1
                                    2
                                 
                                 ∥
                                 B
                                 −
                                 BX
                                 
                                    ∥
                                    F
                                    2
                                 
                                 +
                                 λ
                                 ∥
                                 PX
                                 
                                    ∥
                                    
                                       2
                                       ,
                                       1
                                    
                                 
                                 +
                                 β
                                 ∥
                                 WX
                                 
                                    ∥
                                    
                                       2
                                       ,
                                       1
                                    
                                 
                                 ,
                              
                           
                        where 
                           W
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              
                                 N
                                 ×
                                 N
                              
                           
                         is a diagonal matrix, with the ith diagonal element as


                        
                           
                              (5)
                              
                                 
                                    W
                                    ii
                                 
                                 =
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                       ,
                                       .
                                       .
                                       .
                                       ,
                                       N
                                    
                                 
                                 
                                    S
                                    ij
                                 
                                 ∥
                                 
                                    X
                                    
                                       j
                                       .
                                    
                                 
                                 
                                    ∥
                                    2
                                 
                                 ,
                              
                           
                        
                     

When W is fixed, Eq. (4) is transformed into a weighted ℓ2,1 optimization problem. Inspired by [50,49], the weighted ℓ2,1 optimization problem can be effectively solved by minimizing the following objective function


                        
                           
                              (6)
                              
                                 
                                    min
                                    X
                                 
                                 :
                                 
                                    1
                                    2
                                 
                                 ∥
                                 B
                                 −
                                 BX
                                 
                                    ∥
                                    F
                                    2
                                 
                                 +
                                 λ
                                 Tr
                                 (
                                 
                                    X
                                    T
                                 
                                 P
                                 Θ
                                 PX
                                 )
                                 +
                                 β
                                 Tr
                                 (
                                 
                                    X
                                    T
                                 
                                 W
                                 Φ
                                 WX
                                 )
                                 ,
                              
                           
                        where 
                           Θ
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              
                                 N
                                 ×
                                 N
                              
                           
                         is a diagonal matrix, with the ith diagonal element as


                        
                           
                              (7)
                              
                                 
                                    Θ
                                    ii
                                 
                                 =
                                 
                                    1
                                    
                                       2
                                       ∥
                                       
                                          
                                             (
                                             PX
                                             )
                                          
                                          i
                                       
                                       
                                          ∥
                                          2
                                       
                                    
                                 
                                 ,
                              
                           
                        and 
                           Φ
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              
                                 N
                                 ×
                                 N
                              
                           
                         is a diagonal matrix, with the ith diagonal element as


                        
                           
                              (8)
                              
                                 
                                    Φ
                                    ii
                                 
                                 =
                                 
                                    1
                                    
                                       2
                                       ∥
                                       
                                          
                                             (
                                             WX
                                             )
                                          
                                          i
                                       
                                       
                                          ∥
                                          2
                                       
                                    
                                 
                                 ,
                              
                           
                        
                     

When W, Θ and Φ are fixed, the original problem can be turned into a general convex optimization problem. Therefore, an iterative procedure is adopted. In each iteration, x is calculated with the current W, Θ and Φ via Eq. (6), and then W, Θ and Φ are updated based on the current calculated x. The iterative procedure is repeated until the algorithm converges. The detailed process can be found in Algorithm 1.


                     
                        Algorithm 1
                        Optimization method
                              
                                 
                                    Require: 
                                    B, P, S, λ, β, T, ϵ
                                 


                                    Ensure: 
                                    X
                                    ★
                                 

  1: Set t
                                    =0. Initialize 
                                       
                                          X
                                          0
                                       
                                       ∈
                                       
                                          
                                             
                                                ℝ
                                             
                                          
                                          
                                             N
                                             ×
                                             N
                                          
                                       
                                     as a random matrix and 
                                       
                                          W
                                          ii
                                          0
                                       
                                       =
                                       
                                          ∑
                                          
                                             j
                                             =
                                             1
                                             ,
                                             .
                                             .
                                             .
                                             ,
                                             N
                                          
                                       
                                       
                                          S
                                          ij
                                       
                                       ∥
                                       
                                          X
                                          
                                             j
                                             .
                                          
                                          0
                                       
                                       
                                          ∥
                                          2
                                       
                                    , 
                                       
                                          Φ
                                          0
                                       
                                       ∈
                                       
                                          
                                             
                                                ℝ
                                             
                                          
                                          
                                             N
                                             ×
                                             N
                                          
                                       
                                     and 
                                       
                                          Θ
                                          0
                                       
                                       ∈
                                       
                                          
                                             
                                                ℝ
                                             
                                          
                                          
                                             N
                                             ×
                                             N
                                          
                                       
                                     as identity matrices.

  2: while 
                                    t< T ⋂ ∥X
                                    
                                       t
                                    
                                    −
                                    X
                                    
                                       t−1
                                    ∥
                                    
                                       Fro
                                    
                                    >
                                    ϵ 
                                    do
                                 

  3: Get X
                                    
                                       t+1 = 
                                       
                                          
                                             (
                                             
                                                B
                                                T
                                             
                                             B
                                             +
                                             λ
                                             P
                                             Θ
                                             P
                                             +
                                             β
                                             W
                                             Φ
                                             W
                                             )
                                          
                                          
                                             −
                                             1
                                          
                                       
                                       
                                          B
                                          T
                                       
                                       B
                                    ,

  4: Update W
                                    
                                       t+1 by Eq. (5), Θ
                                       t+1 by Eq. (7),

  5: Update Φ
                                       t+1 by Eq. (8),

  6: 
                                    t
                                    =
                                    t
                                    +1,

  7: end while
                                 

  8: return 
                                    X
                                    ★
                                    =
                                    X
                                    
                                       T
                                    
                                 

In this section, we provide the implementation of our gastroscopic video summarization and the overview of our framework is illustrated in Fig. 1
                     . First, we evaluate the gastroscopic image quality via a supervised framework and detect non-informative frames from the gastroscopic video sequence. Second, the video is segmented into shots in an efficient way depending on the dramatic changes between consecutive frames. Finally, with the help of our new similar-inhibition dictionary selection model, the most representative frames are selected from each shot.

By taking into account the unique condition of gastroscopic video acquisition, we extract some image features with rotation invariance and translation invariance. In general, the color and texture of tissue in the human body are important properties that provide very useful information for making medical diagnoses, and there are many computer-aided diagnosis systems that employ color and texture features for image representation, such as [51–53]. There are many types of color space [54]; however, it is hard to determine which one is more effective. Here, we adopt the following seven color histograms as descriptors: HIS-I histogram, HSV-HV histogram, RGB histogram, Norm RGB histogram, RG histogram, Opponent histogram and HUE histogram. For texture features, we adopt the LBP histogram [55,56]. The histograms of features are extracted as they are relative invariant to image scale changes, translation and rotation about the viewing axis. The feature dimensions for the eight features are 15, 30, 45, 45, 30, 45, 15 and 15, respectively. Finally, we combine both color and texture features together, with the feature dimension as d
                        =240, to represent the video frames.

Due to the complexity of the internal human cavity and the fact that a gastroscope cannot be well controlled, the quality of some gastroscopic images is so poor that even clinicians themselves cannot make a diagnosis, including frames oversaturated by reflection, too dark or obscure, as shown in Fig. 2
                        . We refer to these frames as non-informative frames, which have negative effect on the performance of video summarization. To eliminate these images, we formulate the problem of gastroscopic video quality evaluation as a supervised framework and detect non-informative frames from a gastroscopic video sequence. We divide the frames into four categories, namely, informative frames, over-saturated frames, dark frames and obscure frames. The latter three are referred to as non-informative frames. For experiments, the ground truth is annotated by clinicians, which includes 2610 informative frames, 790 oversaturated frames, 640 dark frames and 1158 obscure frames. The ground truth extracts the same features as in Section 4.1. We randomly select 10% of the ground truth as the test set and the remaining 90% as the training set. Then, a Random Forests (RF) [57] classifier is trained using the training set. The evaluation results on the test set are shown in Table 1
                        . It shows that the average accuracy is approximately 95%, with the average false positive rate lower than 1.3%. Therefore, we can accurately detect the non-informative frames. Before video summarization, the image quality is evaluated by the trained RF model and the detected non-informative frames are excluded from the original video sequence.

For video summarization, if we consider the whole video as a unit to process, then we will produce heavy computational complexity. Due to the diversity of contents, we may be unable to obtain satisfactory results. Therefore, we segment the whole video sequence into shots with suitable lengths for efficient computation. Overly short video shots cannot cover enough video contents; on the contrary, overly long video shots will induce lower efficiency.

We design a video segmentation method based on the assumption that the semantic contents of images on both sides of the video shot boundary should change dramatically. To measure the similarity between consecutive frames, we use the histogram intersection [58] as:


                        
                           
                              (9)
                              
                                 R
                                 (
                                 
                                    b
                                    
                                       i
                                       −
                                       1
                                    
                                 
                                 ,
                                 
                                    b
                                    i
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             t
                                             =
                                             1
                                          
                                          d
                                       
                                       min
                                       (
                                       
                                          b
                                          
                                             i
                                             −
                                             1
                                          
                                       
                                       (
                                       t
                                       )
                                       ,
                                       
                                          b
                                          i
                                       
                                       (
                                       t
                                       )
                                       )
                                    
                                    
                                       
                                          ∑
                                          
                                             t
                                             =
                                             1
                                          
                                          d
                                       
                                       
                                          b
                                          i
                                       
                                       (
                                       t
                                       )
                                    
                                 
                                    
                                 ,
                              
                           
                        where b
                        
                           i−1 and b
                        
                           i
                         are the histogram features, i is the frame index, and T is the feature dimension index. The min operant implies the intersection of the histograms, and the result of the intersection is the number of pixels from b
                        
                           i−1 that have corresponding pixels of the same color/texture information in b
                        
                           i
                        . The intersection is normalized by the number of pixels in the model histogram. The larger R(.)∈[0, 1] is, the more similar b
                        
                           i−1 and b
                        
                           i
                         are. Then, the dissimilarity is defined as:


                        
                           
                              (10)
                              
                                 
                                    D
                                    i
                                 
                                 =
                                 1
                                 −
                                 R
                                 (
                                 
                                    b
                                    
                                       i
                                       −
                                       1
                                    
                                 
                                 ,
                                 
                                    b
                                    i
                                 
                                 )
                                    
                                 ,
                              
                           
                        where D
                        
                           i
                         denotes the difference between consecutive frames, and D
                        
                           i
                        
                        =0 means b
                        
                           i−1 and b
                        
                           i
                         are the same. We can calculate a 1D curve of D
                        
                           i
                         and then segment the video into shots, i.e., calculating the position of the boundary, mainly based on two criteria:
                           
                              (1)
                              
                                 D
                                 
                                    i
                                  is a local extreme point and satisfies the condition D
                                 
                                    i
                                 
                                 ≥
                                 μ
                                 
                                    d
                                 
                                 +
                                 α
                                 ×
                                 σ
                                 
                                    d
                                  (where μ
                                 
                                    d
                                  and σ
                                 
                                    d
                                  are the mean value and standard deviation of the histogram difference, respectively), i.e., b
                                 
                                    i−1 and b
                                 
                                    i
                                  should change dramatically.

The length of the segmented video shot L should be between a meaningful range L
                                 ∈[L
                                 
                                    Min
                                 , L
                                 
                                    Max
                                 ]; in our case, 200≤
                                 L
                                 ≤2000.

For the gastroscopic video, clinicians tend to focus on the abnormal lesions, which reflect the human psychological preferences [23], i.e., attention. Therefore, we take both gaze and content change information as the attention prior knowledge to reduce the gap between low-level features and high-level concepts, aiming to make the result of summarization fit the clinicians’ actual preferences better.


                        a. Gaze prior: The human eye is usually attracted by the salient regions of a significant color distribution or strong contrast in the frame [23]. The locations of these salient regions indicate whether the corresponding frames can provide sufficient contents and better observation angles for clinicians to make the final diagnosis. For frames with similar contents, the closer the salient region is to the center of the corresponding frame, the more important the corresponding frame is and the large probability that it is selected as a key frame. Thus, to model gaze, we first obtain the saliency map via the method proposed in [59] and then compute the Euclidean distance of the saliency map centroid to the frame center. Finally, the gaze attention score for each frame is defined as


                        
                           
                              (11)
                              
                                 
                                    M
                                    g
                                    i
                                 
                                 =
                                 1
                                 −
                                 ∥
                                 
                                    C
                                    i
                                 
                                 −
                                 
                                    O
                                    i
                                 
                                 
                                    ∥
                                    2
                                 
                                 ,
                              
                           
                        where C
                        
                           i
                         is the normalized coordinate of the saliency map centroid and O
                        
                           i
                         is the normalized coordinate of the frame center, with i as the frame index. A large 
                           
                              M
                              g
                              i
                           
                           ∈
                           [
                           0
                           ,
                           1
                           ]
                         indicates more attention. Fig. 3
                         gives a simple introduction. The compared two frames in (a)/(b) are close in the temporal sequence and show the same lesion region under different observation angles, respectively. We can see that the frame with a better observation angle can obtain a large gaze attention score compared with the frame with the similar lesion content. This indicates that the gaze attention prior provides a reasonable value to evaluate the importance of frame content.


                        b. Content change prior: In general, rapid content change usually implies low attention or normal behavior, and we can overview. Rapid content change between frames indicates that the corresponding frames have limited ability to reconstruct other frames, which is consistent with the reconstruction error. Moreover, rapid content change has a great negative effect on the quality of images. To model content change, we estimate the optical flow [60] for each frame and then compute the mean amplitude 
                           
                              
                                 
                                    u
                                    i
                                 
                              
                              ¯
                           
                         of each frame optical flow. The content change attention score for each frame is defined as


                        
                           
                              (12)
                              
                                 
                                    M
                                    c
                                    i
                                 
                                 =
                                 1
                                 −
                                 
                                    
                                       
                                          
                                             u
                                             ¯
                                          
                                          i
                                       
                                    
                                    
                                       
                                          max
                                          
                                             j
                                             =
                                             1
                                             …
                                             N
                                          
                                       
                                       
                                          
                                             u
                                             ¯
                                          
                                          j
                                       
                                    
                                 
                                 ,
                              
                           
                        where N denotes the number of frames, 
                           
                              
                                 u
                                 ¯
                              
                              j
                           
                         represents the mean amplitude of the motion field of frame j, and 
                           
                              M
                              c
                              i
                           
                           ∈
                           [
                           0
                           ,
                           1
                           ]
                        . The larger 
                           
                              M
                              c
                              i
                           
                         is, the more attention it gets.

To model the attention prior, linear fusion schemes are used for the fusion of various attention scores to generate an aggregated attention score [61]. The general form of linear fusion schemes is as follows:


                        
                           
                              (13)
                              
                                 M
                                 =
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    λ
                                    j
                                 
                                 
                                    M
                                    j
                                 
                                 ,
                                 
                                 
                                 
                                 
                                    ∑
                                    
                                       j
                                       =
                                       1
                                    
                                    n
                                 
                                 
                                    λ
                                    j
                                 
                                 =
                                 1
                                 ,
                              
                           
                        where λ
                        
                           j
                         is the weight of the attention value M
                        
                           j
                         and reflects the relative importance between M
                        
                           j
                        (j
                        =1…
                        n), and N is the number of various attention scores. In this paper, the weight λ
                        
                           j
                         of the attention value M
                        
                           j
                         is determined as:


                        
                           
                              (14)
                              
                                 
                                    λ
                                    j
                                 
                                 =
                                 
                                    
                                       
                                          σ
                                          j
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          n
                                       
                                       
                                          σ
                                          k
                                       
                                    
                                 
                                 ,
                              
                           
                        where σ
                        
                           j
                         indicates the standard deviation of the attention score M
                        
                           j
                        . For each frame, the final attention prior is obtained by combining the above two factors, namely,


                        
                           
                              (15)
                              
                                 
                                    M
                                    i
                                 
                                 =
                                 
                                    λ
                                    g
                                 
                                 
                                    M
                                    g
                                    i
                                 
                                 +
                                 
                                    λ
                                    c
                                 
                                 
                                    M
                                    c
                                    i
                                 
                                 ,
                              
                           
                        
                     


                        Fig. 4
                         gives an example to verify the validity of the attention prior. There are three key frames selected within the shot. The ground truth or the selected key frames have a relatively large attention score.

For each video shot, we can use the remaining informative frames to initialize a dictionary as 
                           B
                           =
                           [
                           
                              b
                              1
                           
                           ,
                           
                              b
                              2
                           
                           ,
                           .
                           .
                           .
                           ,
                           
                              b
                              N
                           
                           ]
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              
                                 d
                                 ×
                                 N
                              
                           
                        , where each column 
                           
                              b
                              i
                           
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              d
                           
                         denotes a frame represented as a feature vector and N is the length of a video shot. We can obtain a sparse solution of 
                           X
                           ∈
                           
                              
                                 
                                    ℝ
                                 
                              
                              
                                 N
                                 ×
                                 N
                              
                           
                         using Algorithm 1, i.e., x is sparse in terms of rows, and we can calculate a sparse weight curve 
                           
                              w
                              i
                           
                           ,
                           i
                           ∈
                           {
                           1
                           …
                           N
                           }
                        . We can rank the frames based on the values of 
                           
                              w
                              i
                           
                         and select any number of key frames according to the values in descending order.

For video summarization, we not only aim at selecting some representative frames to summarize the video but also want to identify some key-shots. For a gastroscopic video, the shots conveying the lesion information are defined as key-shots, which usually are important for clinicians for diagnosis and should be displayed early. As discussed above, we model each frame attention prior via two cues, namely, gaze and content change. Here, the mean of the attention score within a shot is computed to rank the shots. A larger value implies more importance. Moreover, the distribution of the number of key frames within each shot can also be determined by the attention score. K denotes the total number of key frames, and the number of key frames for each shot S can be determined as:


                        
                           
                              (16)
                              
                                 
                                    K
                                    s
                                 
                                 =
                                 ⌈
                                 
                                    
                                       
                                          M
                                          s
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             s
                                             =
                                             1
                                             …
                                             S
                                          
                                       
                                       
                                          M
                                          s
                                       
                                    
                                 
                                 ⌉
                                 ,
                              
                           
                        
                        M
                        
                           s
                         is the mean attention score within the video shot S. A larger M
                        
                           s
                         indicates that the shot S contains more content and obtains more attention. It also represents that shot S may provide more information for making the final diagnosis. Thus, the larger M
                        
                           s
                         is, the more key frames are selected in this shot; otherwise, less key frames are selected in this shot.

@&#EXPERIMENTS@&#

In this section, we build a new gastroscopic video summarization dataset and validate our method by comparing it with the state-of-the-arts. When video summarization algorithms can be roughly divided into three categories [62], i.e., sequential algorithms, clustering-based algorithms and optimization-based algorithms, in our paper, we select several algorithms from each category for a fair comparison, such as evenly spaced key frames (ESKF) [63], the k-means-based method [20], k-medoids-based method [64] and dictionary selection-based video summarization (DSVS) [2]. For a fair comparison, each compared method selects the same number of key frames as the ground truth in our experiments.

By cooperating with Chinese PLA General Hospital, we collected a total of 30 gastroscopic videos; Tables 2 and 3
                        
                         give detailed descriptions of these 30 videos, in which two of them are from healthy patients, i.e., there is no visible lesion, and the other 28 are with various lesions, such as gastritis, cancer, ulcers and polyps. Each video contains approximately 5000–35,000 frames. The frame rate ranges from 20 to 31 frames per second (FPS). There are large invalid regions, such as black backgrounds and textual descriptions in the original frames, that make no contribution to the diagnosis. Thus, when the original image resolution is 768×576, we crop the ROI (only the image region in the deep blue square is regarded as the ROI, as shown in Fig. 5
                        ) to a size of 489×409 to test our algorithm. The ground truth, which usually includes most of the important tissues/organs and covers all visible lesion regions, is annotated by clinicians. The average video length is approximately 560 s, and the average number of key frames is approximately 35 in the ground truth.

To evaluate the content similarity between the selected key frames and the corresponding ground truth, we follow the assignment in [65] and define the content consistency score (CCS) as


                        
                           
                              (17)
                              
                                 CCS
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          K
                                       
                                       
                                          δ
                                          c
                                       
                                       (
                                       
                                          e
                                          k
                                       
                                       ,
                                       
                                          g
                                          k
                                       
                                       )
                                    
                                    K
                                 
                                 ,
                              
                           
                        where


                        
                           
                              (18)
                              
                                 
                                    δ
                                    c
                                 
                                 (
                                 
                                    e
                                    k
                                 
                                 ,
                                 
                                    g
                                    k
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                
                                                   
                                                   1
                                                   
                                                   if
                                                      
                                                   ∥
                                                   
                                                      b
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      b
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   ∥
                                                   ≤
                                                   
                                                      C
                                                      th
                                                      c
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   
                                                   0
                                                   
                                                   else
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              b
                              
                                 
                                    g
                                    k
                                 
                              
                           
                         denotes the feature vector of the corresponding ground truth g
                        
                           k
                        ; e
                        
                           k
                        
                        =
                        map
                        
                           c
                        (g
                        
                           k
                        ) is the selected key frame corresponding to g
                        
                           k
                        , where map
                        
                           c
                        (.) is a one to one mapping function that maps each g
                        
                           k
                         to its best matching e
                        
                           k
                         in terms of content; 
                           
                              b
                              
                                 
                                    e
                                    k
                                 
                              
                           
                         denotes the feature vector of e
                        
                           k
                        ; 
                           
                              C
                              th
                              c
                           
                         is the content threshold, with 
                           
                              C
                              th
                              c
                           
                           =
                           0.2
                        ; K is the number of selected key frames, which is consistent with the ground truth. A larger CCS indicates that more selected key frames are consistent with the corresponding ground truth in terms of content, i.e., the corresponding algorithm obtains a better performance.

The CCS results are shown in Table 4
                        . The average CCS of ESKF is 0.543, which is the worst performance of all algorithms. This is mainly because ESKF fails to take account of the image content and video rhythm. The effectiveness of such a method is highly dependent on the video content and may only produce relatively satisfactory results for simple videos. For example, ESKF obtains the second best results of all algorithms for videos 1, 10 and 30, while obtains the worst results for most of the other videos. The average CCS of k-means is 0.601 and of k-medoids is 0.603. The performance of the k-means-based method is similar to that of the k-medoids-based method, which is not only reflected in the average performance but also in each video performance. Due to only taking into account the point-to-point difference/similarity, the extracted key frames of clustering-based methods lose the temporal information of the original video. However, this type of information is clearly helpful for quickly grasping the video content. Therefore, the results of the k-means-based method and k-medoids-based method are not satisfactory, especially for videos 1, 3, 4 and 28. The DSVS method extracts the key frames via sparse dictionary selection under two terms, i.e., reconstruction error term and group sparsity term. The average CCS of DSVS is 0.634, which is the closest result to our method. However, when DSVS does not take into account the inter-frame similarity, the extracted key frames may contain very similar contents. Moreover, it is not very stable, and in some videos, the method cannot obtain competitive results, such as videos 1, 6, 8, 15 and 29. Finally, the average CCS of our SIDSVS is 0.739, which outperforms all other methods. Our SIDSVS obtains the best result in 23 of the 30 videos. Specifically, we obtain near perfect results with large gaps to other methods on some videos, such as videos 1, 6 and 9.

We also verify the frame index consistency between the selected key frames and the ground truth [65]. Based on the frame index distance, we assess each selected key frame as {better matching, good matching, general matching and bad matching} with the quantified scores: {3, 2, 1, 0}. The detailed definition of the index consistency score (ICS) is


                        
                           
                              (19)
                              
                                 ICS
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          K
                                       
                                       
                                          δ
                                          i
                                       
                                       (
                                       
                                          e
                                          k
                                       
                                       ,
                                       
                                          g
                                          k
                                       
                                       )
                                    
                                    K
                                 
                                 ,
                              
                           
                        where


                        
                           
                              (20)
                              
                                 
                                    δ
                                    i
                                 
                                 (
                                 
                                    e
                                    k
                                 
                                 ,
                                 
                                    g
                                    k
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                
                                                   
                                                   
                                                   3
                                                   
                                                   if
                                                      
                                                   |
                                                   
                                                      I
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      I
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   |
                                                      
                                                   ≤
                                                      
                                                   
                                                      I
                                                      th
                                                      1
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   
                                                   
                                                   2
                                                   
                                                   if
                                                      
                                                   
                                                      I
                                                      th
                                                      1
                                                   
                                                   <
                                                      
                                                   |
                                                   
                                                      I
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      I
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   |
                                                      
                                                   ≤
                                                      
                                                   
                                                      I
                                                      th
                                                      2
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   
                                                   
                                                   1
                                                   
                                                   if
                                                      
                                                   
                                                      I
                                                      th
                                                      2
                                                   
                                                   <
                                                      
                                                   |
                                                   
                                                      I
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      I
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   |
                                                      
                                                   ≤
                                                      
                                                   
                                                      I
                                                      th
                                                      3
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   
                                                   
                                                   0
                                                   
                                                   if
                                                      
                                                   |
                                                   
                                                      I
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      I
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   |
                                                      
                                                   >
                                                      
                                                   
                                                      I
                                                      th
                                                      3
                                                   
                                                      
                                                   ,
                                                
                                             
                                             
                                                
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              I
                              
                                 
                                    g
                                    k
                                 
                              
                           
                         denotes the frame index of the corresponding ground truth g
                        
                           k
                        ; e
                        
                           k
                        
                        =
                        map
                        
                           i
                        (g
                        
                           k
                        ) is the selected key frame corresponding to g
                        
                           k
                        , where map
                        
                           i
                        (.) is a one to one mapping function that maps each g
                        
                           k
                         to its best matching e
                        
                           k
                         in terms of index; 
                           
                              I
                              
                                 
                                    e
                                    k
                                 
                              
                           
                         denotes the index of e
                        
                           k
                        ; 
                           
                              I
                              th
                              *
                           
                         is the index threshold, with 
                           
                              I
                              th
                              1
                           
                           =
                           24
                        , 
                           
                              I
                              th
                              2
                           
                           =
                           72
                         and 
                           
                              I
                              th
                              3
                           
                           =
                           216
                        , respectively. A larger ICS indicates that more selected key frames are consistent with the corresponding ground truth in terms of index, i.e., the corresponding algorithm obtains a better performance.

The ICS results are shown in Table 5
                        . Due to the selected key frames being uniformly distributed in the sequence, ESKF obtains the worst result, with an average ICS
                        =1.396. Although the k-means-based method, k-medoids-based method and DSVS all do not take into consideration the temporal information, DSVS gets a slightly better result than the clustering-based methods, especially in videos 1, 10 and 23. This is mainly because under the group sparsity constraint, DSVS selects more frames with the better ability to reconstruct other frames and promotes the model with some local properties. The average ICS of our SIDSVS is 1.984, which is better than other state-of-the-arts with a large margin. Moreover, our SIDSVS obtains the best results in 24 of the 30 videos. The best performance benefits from our similar-inhibition term, which prevents the selection of similar frames as key frames. Therefore, when the selected number is consistent, our method selects more useful information.

Moreover, we take into consideration both image content and time differences, as suggested in [65], for comparison. Two frames are considered to match each other only if they are similar in scene content and occur within a short period. We named this criterion the content index consistency score (CICS), and the detailed definition is:


                        
                           
                              (21)
                              
                                 CICS
                                 =
                                 
                                    
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          K
                                       
                                       δ
                                       (
                                       
                                          e
                                          k
                                       
                                       ,
                                       
                                          g
                                          k
                                       
                                       )
                                    
                                    K
                                 
                                 ,
                              
                           
                        where


                        
                           
                              (22)
                              
                                 δ
                                 (
                                 
                                    e
                                    k
                                 
                                 ,
                                 
                                    g
                                    k
                                 
                                 )
                                 =
                                 
                                    
                                       
                                          
                                             
                                                
                                                
                                                   
                                                   1
                                                   
                                                   if
                                                      
                                                   ∥
                                                   
                                                      b
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      b
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   ∥
                                                   ≤
                                                   
                                                      C
                                                      th
                                                   
                                                   ⋂
                                                   ∥
                                                   
                                                      I
                                                      
                                                         
                                                            e
                                                            k
                                                         
                                                      
                                                   
                                                   −
                                                   
                                                      I
                                                      
                                                         
                                                            g
                                                            k
                                                         
                                                      
                                                   
                                                   ∥
                                                   ≤
                                                   
                                                      I
                                                      th
                                                   
                                                
                                             
                                             
                                                
                                                
                                                   
                                                   0
                                                   
                                                   else
                                                   ,
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                        
                           
                              b
                              
                                 
                                    g
                                    k
                                 
                              
                           
                         and 
                           
                              I
                              
                                 
                                    g
                                    k
                                 
                              
                           
                         are the same as in Eqs. (17) and (19). e
                        
                           k
                        
                        =
                        map(g
                        
                           k
                        ) is the selected key frame corresponding to g
                        
                           k
                        , where map(.) is a one to one mapping function that maps each g
                        
                           k
                         to its best matching e
                        
                           k
                         in terms of content and index; C
                        
                           th
                         and I
                        
                           th
                         are the content and index thresholds, with C
                        
                           th
                        
                        =0.2 and I
                        
                           th
                        
                        =100, respectively. The larger CICS is, the more selected key frames are consistent with the ground truth in terms of both the content and index, i.e., the better performance the algorithm gets.

The CICS results are shown in Table 6
                        . The worst average result is from ESKF (0.311), which is consistent with the results of CCS and ICS. The results of the k-means-based method, k-medoids-based method and DSVS have a very small difference (0.357 vs. 0.341 vs. 0.340). They are all based on low-level features and neglect the importance of the data itself. From Table 6, it can be seen that our SIDSVS outperforms all other methods with an average CICS
                        =0.626. Specifically, we obtain near perfect results with large gaps to other methods on all videos. On the one hand, the similar-inhibition constraint makes the selected key frames more diverse in terms of content; on the other hand, the attention prior provides a method to evaluate the importance of each frame. Under the three terms, namely, the reconstruction error, group sparsity and similar-inhibition, our SIDSVS model provides results that are more in line with clinicians’ preferences.


                        Figs. 6–9 provide some comparison examples between the ground truth, ESKF, k-means-based method, k-medoids-based method, DSVS and our SIDSVS method, illustrating the advantage of the proposed method over the other methods. In Fig. 6
                        , the diagnosis of this volunteer is gastric polyp. When the selected key frames via all methods are similar in content, our approach can select the frames with more suitable observation angles due to the attention prior. Then, the clinicians can mine more information from these frames for diagnosis. Meanwhile, other methods may select some frames that are difficult to read, such as the last key frame of ESKF and the first frame of k-means. In Fig. 7
                        , the diagnosis of this volunteer is gastric cancer. While there are some complex scenes, our SIDSVS obtains the best result with a large margin over other methods. The selected key frames by DSVS contain much repetitive content. By introducing the similar-inhibition constraint, our method selects the frames with more diversity. In Fig. 8
                        , the diagnosis of this volunteer is gastric ulcer. Compared with other methods, our results can effectively reflect the lesion information by selecting more frames from the lesion part, making the final diagnosis easier. In Fig. 9
                        , even though the diagnosis of this volunteer is healthy, the key frames selected by our SIDSVS cover more diverse information about the video.

@&#CONCLUSIONS@&#

To better navigate gastroscopic video content for diagnosis and future research, a new scheme of gastroscopic video summarization has been proposed in this paper. By representing each video frame as a feature vector, we convert the gastroscopic video summarization problem into a sparse dictionary selection problem under three terms, namely, reconstruction error, group sparsity and similar-inhibition. Moreover, we compute an attention score by merging two cues, i.e., gaze and content change, and add it into the model as a prior cue. Our method not only provides a scalable solution to video summarization, which allows us to select any given number of key frames, but can also reinforce the diversity of the selected key frames. The preliminary results obtained on our new gastroscopic video dataset validate that our method outperforms the state-of-the-art video summarization models.

@&#ACKNOWLEDGEMENTS@&#

This work is supported by the National Science and Technology Support Program (2012BAI14B03), NSFC (61105013, 61375014, 61533015) and also the Foundation of Chinese Scholarship Council.

@&#REFERENCES@&#


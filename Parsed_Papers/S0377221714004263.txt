@&#MAIN-TITLE@&#Preference-inspired co-evolutionary algorithms using weight vectors

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           A new decomposition based algorithm PICEA-w is proposed.


                        
                        
                           
                           PICEA-w adaptively varies the weights.


                        
                        
                           
                           Adaptive weights bring robustness to different problem geometries.


                        
                        
                           
                           PICEA-w outperforms other leading decomposition based algorithms.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Evolutionary algorithms

Multi-objective optimisation

Many-objective

Co-evolution

Weights

@&#ABSTRACT@&#


               
               
                  Decomposition based algorithms perform well when a suitable set of weights are provided; however determining a good set of weights a priori for real-world problems is usually not straightforward due to a lack of knowledge about the geometry of the problem. This study proposes a novel algorithm called preference-inspired co-evolutionary algorithm using weights (PICEA-w) in which weights are co-evolved with candidate solutions during the search process. The co-evolution enables suitable weights to be constructed adaptively during the optimisation process, thus guiding candidate solutions towards the Pareto optimal front effectively. The benefits of co-evolution are demonstrated by comparing PICEA-w against other leading decomposition based algorithms that use random, evenly distributed and adaptive weights on a set of problems encompassing the range of problem geometries likely to be seen in practice, including simultaneous optimisation of up to seven conflicting objectives. Experimental results show that PICEA-w outperforms the comparison algorithms for most of the problems and is less sensitive to the problem geometry.
               
            

@&#INTRODUCTION@&#

Multi-objective optimisation problems (MOPs) arise in many real-world applications, where multiple conflicting objectives must be simultaneously satisfied. Typically, the optimal solution set of MOPs is not a single solution but comprises of a set of trade-off solutions. Multi-objective evolutionary algorithms (MOEAs) are well suited for solving MOPs since (i) their population-based nature leads naturally to the generation of an approximate trade-off surface in a single run and (ii) they tend to be robust to underlying cost function characteristics (Coello, Lamont, & Van Veldhuizen, 2007, pp. 5–7).

Over the last two decades, a variety of MOEA approaches have been proposed. Most of these approaches are based on the concept of Pareto-dominance and niching technique suggested by Goldberg (1989): for example, MOGA (Fonseca & Fleming, 1993), NSGA-II (Deb, Pratap, Agarwal, & Meyarivan, 2002) and SPEA2 (Zitzler, Laumanns, & Thiele, 2002). It is accepted that Pareto-dominance based MOEAs perform well on MOPs with 2 and 3 objectives. However, their search capability often degrades significantly as the number of objectives increase (Ishibuchi, Tsukamoto, & Nojima, 2008). This is because that the proportion of non-dominated objective vectors in the population grows large when MOPs have more than 3 objectives, i.e., so-called many-objective problems (Purshouse & Fleming, 2003). As a result, insufficient selection pressure can be generated towards the Pareto front (Purshouse & Fleming, 2007).

In addition to the Pareto-dominance based approaches, there has been considerable effort invested in other types of MOEAs. One of the most promising alternatives
                        1
                     
                     
                        1
                        There are also other types of MOEAs such as indicator based MOEAs (Zitzler & Künzli, 2004), e.g., SMS-EMOA (Emmerich, Beume, & Naujoks, 2005) and HypE (Bader & Zitzler, 2011); and modified dominance based MOEAs, e.g., ɛ-EMOA (Deb, Mohan, & Mishra, 2005).
                      is to use a decomposition approach (Hughes, 2003; Zhang & Li, 2007), denoted as D-MOEA in this study. Note that in some studies decomposition based methods are also called aggregation based or scalarising function based methods (Hughes, 2003; Ishibuchi, Sakane, Tsukamoto, & Nojima, 2010). Decomposition based MOEAs transfer a MOP into a set of single objective problems by means of scalarising functions with different weights. Compared with Pareto-dominance based approaches, decomposition based approaches have a number of advantages such as high search ability for combinatorial optimisation, computational efficiency on fitness evaluation and high compatibility with local search (Zhang & Li, 2007; Ishibuchi et al., 2010). The seminal decomposition based MOEA, i.e., MOEA/D, that popularised this method, has been used in many real-world applications.
                        2
                     
                     
                        2
                        Professor Qingfu Zhang maintains a website which records the related research and applications of MOEA/D: http://dces.essex.ac.uk/staff/zhang/webofmoead.htm.
                      Its modified version, i.e., MOEA/D-DRA (Zhang, Liu, & Li, 2009) won the “Unconstrained multi-objective evolutionary algorithm” competition at the 2009 Congress on Evolutionary Computation.

Despite these advantages, more recent studies have identified that decomposition based algorithms, e.g., MOEA/D, (i) face difficulties on problems having a complex Pareto front geometry
                        3
                     
                     
                        3
                        Pareto front geometry and problem geometry are used interchangeably in this paper.
                      (Gu, Liu, & Tan, 2012) and (ii) though performing well on bi-objective problems, are not particularly useful for many-objective problems due to a loss of solution diversity (Wang, Purshouse, & Fleming, 2013). These issues are likely to arise from an inappropriate specification of search directions (which are determined by the weights) a priori, itself arising from a general lack of problem knowledge. In other words the choice of the scalarising functions’ underlying search directions is typically problem-dependent and therefore is difficult if no information about the problem characteristics is known before the search proceeds. For example, evenly distributed search directions are good for problems having a linear Pareto optimal front, see Fig. 1(a): however, they are not suitable for problems with complex Pareto optimal fronts, e.g., disconnected, see Fig. 1(b).

Our interest remains in a posteriori decision-making, that is, providing decision-makers with both a proximal and diverse representation of the entire Pareto optimal front. This study then proposes a novel strategy to adaptively modify the search directions (i.e., weights) on line for decomposition based MOEAs so as to obtain a good approximation of the Pareto optimal front for problems having different geometries.

This new strategy adopts the concept of preference-inspired co-evolution (Purshouse, Jalbaˇ, & Fleming, 2011; Wang et al., 2013), that is, candidate solutions are co-evolved with weight vectors (used as preferences) during the search. The usefulness of weights is maintained by being evaluated using the current population of candidates solutions. It is hypothesised that via co-evolution suitable weights can be constructed on the fly and thus leading decomposition based algorithms to be less sensitive to problem geometries and also to scale up well on many-objective problems.

The rest of this paper is organised as follows. Section 2 introduces some related work to this study which contains an introduction to decomposition based MOEAs and their issues as well as a brief review of some representative decomposition based MOEAs. Section 3 elaborates the proposed co-evolution based weights adaptation strategy and the associated algorithm: preference-inspired co-evolutionary algorithms using weights (PICEA-w). Section 4 describes the experiment setup. Section 5 presents the experiment results. A further discussion of the algorithm PICEA-w is provided in Section 6. Section 7 concludes.

@&#RELATED WORK@&#

Without loss of generality, a minimisation MOP is defined as follows:
                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   minimise
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      
                                                         f
                                                         m
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                         
                                                         )
                                                      
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      m
                                                      =
                                                      1
                                                      ,
                                                      2
                                                      ,
                                                      ⋯
                                                      ,
                                                      M
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                      subject
                                                      
                                                         
                                                            0.35
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      to
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      
                                                         g
                                                         j
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                         
                                                         )
                                                      
                                                      ≤
                                                      0
                                                      ,
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      j
                                                      =
                                                      1
                                                      ,
                                                      2
                                                      ,
                                                      ⋯
                                                      ,
                                                      J
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      
                                                         h
                                                         k
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                         
                                                         )
                                                      
                                                      =
                                                      0
                                                      ,
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      k
                                                      =
                                                      1
                                                      ,
                                                      2
                                                      ,
                                                      ⋯
                                                      ,
                                                      K
                                                   
                                                
                                             
                                          
                                          
                                             
                                                
                                                   
                                                
                                             
                                             
                                                
                                                   
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      
                                                         x
                                                         li
                                                      
                                                      ≤
                                                      
                                                         x
                                                         i
                                                      
                                                      ≤
                                                      
                                                         x
                                                         ui
                                                      
                                                      ,
                                                      
                                                         
                                                            1
                                                            e
                                                            m
                                                         
                                                         
                                                            0
                                                            e
                                                            x
                                                         
                                                      
                                                      i
                                                      =
                                                      1
                                                      ,
                                                      2
                                                      ,
                                                      ⋯
                                                      ,
                                                      n
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        
                     
                  

A solution x is a vector of n decision variables: 
                        
                           
                              x
                           
                           =
                           
                              (
                              
                                 x
                                 1
                              
                              ,
                              
                                 x
                                 2
                              
                              ,
                              ⋯
                              ,
                              
                                 x
                                 n
                              
                              )
                           
                           ,
                           
                              
                                 0.35
                                 e
                                 m
                              
                              
                                 0
                                 e
                                 x
                              
                           
                           
                              x
                           
                           ∈
                           
                              
                                 R
                              
                              n
                           
                        
                     . Each decision variable xi
                      is subject to a lower bound xli
                     , and an upper xui
                      bound. fm
                      represents the mth objective function. M is the number of objectives (generally, M > 2). J and K are the number of inequality and equality constraints, respectively.

Decomposition based algorithms handle a MOP by simultaneously solving a set of single objective problems defined by means of scalarising functions with different weights. The optimal solution of each single objective problem, defined by a weighted scalarising function, corresponds to one Pareto optimal solution of a MOP. The weight vector defines a search direction for the scalarising function. Thus, one can then employ different weights to search for a set of diversified Pareto optimal solutions.

Typically, in decomposition based algorithms weights can either be initialised as an even distribution before the search, or randomly generated, or adaptively modified during the search. A variety of scalarising functions can be employed in decomposition based algorithms. The weighted sum and the weighted Chebyshev are two frequently-used scalarising functions, and can be written as follows:

                           
                              •
                              The weighted sum scalarising function:
                                    
                                       (2)
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            g
                                                         
                                                         ws
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                         
                                                         ∣
                                                         
                                                            w
                                                         
                                                         )
                                                      
                                                      =
                                                      
                                                         ∑
                                                         
                                                            i
                                                            =
                                                            1
                                                            ,
                                                            2
                                                            ,
                                                            ⋯
                                                            ,
                                                            M
                                                         
                                                      
                                                      
                                                         {
                                                         
                                                            λ
                                                            i
                                                         
                                                         
                                                            (
                                                            
                                                               f
                                                               i
                                                            
                                                            
                                                               (
                                                               
                                                                  x
                                                               
                                                               )
                                                            
                                                            −
                                                            
                                                               z
                                                               
                                                                  i
                                                               
                                                               *
                                                            
                                                            )
                                                         
                                                         ,
                                                         
                                                            λ
                                                            i
                                                         
                                                         =
                                                         1
                                                         /
                                                         
                                                            w
                                                            i
                                                         
                                                         }
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

The weighted Chebyshev scalarising function:
                                    
                                       (3)
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            g
                                                         
                                                         wc
                                                      
                                                      
                                                         (
                                                         
                                                            x
                                                         
                                                         ∣
                                                         
                                                            w
                                                         
                                                         )
                                                      
                                                      =
                                                      
                                                         
                                                            APTARANORMAL
                                                            max
                                                         
                                                         
                                                            i
                                                            =
                                                            1
                                                            ,
                                                            2
                                                            ,
                                                            ⋯
                                                            ,
                                                            M
                                                         
                                                      
                                                      
                                                         {
                                                         
                                                            λ
                                                            i
                                                         
                                                         
                                                            (
                                                            
                                                               f
                                                               i
                                                            
                                                            
                                                               (
                                                               
                                                                  x
                                                               
                                                               )
                                                            
                                                            −
                                                            
                                                               z
                                                               
                                                                  i
                                                               
                                                               *
                                                            
                                                            )
                                                         
                                                         ,
                                                         
                                                            λ
                                                            i
                                                         
                                                         =
                                                         1
                                                         /
                                                         
                                                            w
                                                            i
                                                         
                                                         }
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              

Note that often λi
                         is defined directly as wi
                        . However, here we define λi
                         as 1/wi
                         in order to simplify the related analysis later, i.e., avoiding the inconsistency of search directions and weights. In such definition the search direction determined by a weight vector is identical to the direction from the ideal point
                           4
                        
                        
                           4
                           An Ideal point is a vector composed of all the best (e.g., minimum for minimisation problems) values of each objective.
                         to the given weight vector (Giagkiozis, Purshouse, & Fleming, 2013a).

For minimisation problems, both gws
                        (x∣w) and gwc
                        (x∣w) should be minimised. In both Eqs. 2 and 3, w = (w
                        1, w
                        2, …, wM
                        ) represents a weight vector, 
                           
                              
                                 w
                                 i
                              
                              ∈
                              
                                 [
                                 0
                                 ,
                                 1
                                 ]
                              
                              ,
                              
                                 ∑
                                 
                                    i
                                    =
                                    1
                                 
                                 
                                    i
                                    =
                                    M
                                 
                              
                              
                                 w
                                 i
                              
                              =
                              1
                           
                         and 
                           
                              
                                 
                                    
                                       z
                                    
                                 
                                 *
                              
                              =
                              
                                 (
                                 
                                    z
                                    
                                       1
                                    
                                    *
                                 
                                 ,
                                 
                                    z
                                    
                                       1
                                    
                                    *
                                 
                                 ,
                                 ⋯
                                 ,
                                 
                                    z
                                    
                                       M
                                    
                                    *
                                 
                                 )
                              
                           
                         is a reference point. Typically, the reference point is updated once a better (smaller) value of fi
                         is found during the algorithm execution, see Eq. (4):
                           
                              (4)
                              
                                 
                                    
                                       
                                          
                                             
                                                z
                                                
                                                   i
                                                
                                                *
                                             
                                             =
                                             
                                                APTARANORMAL
                                                min
                                             
                                             
                                                {
                                                
                                                   f
                                                   i
                                                
                                                
                                                   (
                                                   
                                                      x
                                                   
                                                   )
                                                
                                                ∣
                                                
                                                   x
                                                
                                                ∈
                                                
                                                   Ω
                                                
                                                }
                                             
                                             −
                                             
                                                ɛ
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           Ω
                         shows all the examined solutions during the algorithm execution, and ɛ is a very small positive value. Essentially, if the ideal point is available, the reference point should be set as the ideal point.

It is worth mentioning that the weighted sum scalarising function encounters difficulties with certain problem geometry, that is, the fact it is not possible to find Pareto optimal solutions in concave regions of the Pareto optimal front unless some additional technique (e.g., ɛ-constraint method) is applied (Kim & De Weck, 2005; Kim & De Weck, 2006). The Chebyshev scalarising function does not have such an issue. However, its search ability is not as great as the weighted sum approach: in terms of a specified weighted Chebyshev function, the proportion of solutions that are considered as better than a given reference point is 
                           
                              
                                 1
                                 
                              
                              
                                 
                                    2
                                 
                                 
                                    (
                                    M
                                    −
                                    1
                                    )
                                 
                              
                           
                        . Thus, the search ability of the Chebyshev function degrades significantly as the number of objectives increases. Readers are referred to Ishibuchi, Sakane, Tsukamoto, and Nojima (2009), Ishibuchi et al. (2010) and Giagkiozis and Fleming (2012) for more details.

Additionally, decomposition based MOEAs combine different objectives into one metric. These objectives might have various units of measurement. Thus, it is important to rescale different objectives to dimension-free units before aggregation. Moreover, normalisation is useful for obtaining evenly distributed solutions when the objectives are disparately scaled. Typically, the normalisation procedure transforms an objective value fi
                         (in Eqs. (2) or (3)) by
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   f
                                                   ¯
                                                
                                                i
                                             
                                             =
                                             
                                                
                                                   
                                                      f
                                                      i
                                                   
                                                   −
                                                   
                                                      z
                                                      
                                                         i
                                                      
                                                      ide
                                                   
                                                
                                                
                                                   
                                                      z
                                                      
                                                         i
                                                      
                                                      nad
                                                   
                                                   −
                                                   
                                                      z
                                                      
                                                         i
                                                      
                                                      ide
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        where 
                           
                              
                                 
                                    
                                       z
                                    
                                 
                                 
                                    i
                                    d
                                    e
                                 
                              
                              =
                              
                                 (
                                 
                                    z
                                    
                                       1
                                    
                                    ide
                                 
                                 ,
                                 
                                    z
                                    
                                       2
                                    
                                    ide
                                 
                                 ,
                                 ⋯
                                 ,
                                 
                                    z
                                    
                                       M
                                    
                                    ide
                                 
                                 )
                              
                           
                         is the ideal point and 
                           
                              
                                 
                                    
                                       z
                                    
                                 
                                 
                                    n
                                    a
                                    d
                                 
                              
                              =
                              
                                 (
                                 
                                    z
                                    
                                       1
                                    
                                    nad
                                 
                                 ,
                                 
                                    z
                                    
                                       2
                                    
                                    nad
                                 
                                 ,
                                 ⋯
                                 ,
                                 
                                    z
                                    
                                       M
                                    
                                    nad
                                 
                                 )
                              
                           
                         is the nadir point.
                           5
                        
                        
                           5
                           A nadir point is a vector composed of all the worst (e.g., maximum for minimisation problems) Pareto optimal objective values in a MOP.
                         After normalisation objective values are within [0, 1]. If the true 
                           
                              z
                              
                                 i
                              
                              ide
                           
                         and 
                           
                              z
                              
                                 i
                              
                              nad
                           
                         are not available (they are often difficult to obtain, especially for z
                        
                           nad
                         (Deb, Miettinen, & Chaudhuri, 2010)), we can use the smallest and largest fi
                         of all non-dominated solutions found so far to estimate 
                           
                              z
                              
                                 i
                              
                              ide
                           
                         and 
                           
                              z
                              
                                 i
                              
                              nad
                           
                        , respectively.

This section reviews a selection of decomposition based MOEAs. These algorithms are classified into two categories, i.e., using pre-defined weights or using adaptive weights. Note that in this study we refer to pre-defined weights as weights that are randomly generated during the search or initialised as an even distribution before the search.

Hajela and Lin’s genetic algorithm (denoted as HLGA) (Hajela, Lee, & Lin, 1993) and multi-objective genetic local search (MOGLS (Ishibuchi & Murata, 1998)) are two representative decomposition based MOEAs that use random weights.
                              
                                 •
                                 In HLGA and I-MOGLS (MOGLS of Ishibuchi & Murata (1998)), a random weight vector is generated as follows: firstly randomly generate M numbers, e.g., a
                                    1, a
                                    2, …, aM
                                     and ai
                                     ≥ 0; secondly normalise ai
                                     by 
                                       
                                          
                                             a
                                             i
                                          
                                          
                                             
                                                ∑
                                                
                                                   i
                                                   =
                                                   1
                                                
                                                M
                                             
                                             
                                                a
                                                i
                                             
                                          
                                       
                                     to obtain a valid component for a weight vector, i.e., 
                                       
                                          
                                             w
                                             i
                                          
                                          =
                                          
                                             
                                                a
                                                i
                                             
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   M
                                                
                                                
                                                   a
                                                   i
                                                
                                             
                                          
                                       
                                    . This method has a limitation: the generated weights are dense in the centre while sparse at the edge. This is because the method is equivalent to directly projecting all randomly distributed points in a hypercube to a hyperplane, see Fig. 2
                                    .


                                    Jaszkiewicz (2002) proposed another variant of MOGLS (denoted as J-MOGLS) in which components of a weight vector are calculated by Eq. (6), where function rand() returns a random value within the interval (0,1) according to a uniform probability distribution.
                                       
                                          (6)
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            
                                                               
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  
                                                                     
                                                                        w
                                                                        1
                                                                     
                                                                     =
                                                                     1
                                                                     −
                                                                     
                                                                        
                                                                           rand
                                                                           (
                                                                           )
                                                                        
                                                                        
                                                                           M
                                                                           −
                                                                           1
                                                                        
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  ⋯
                                                               
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  
                                                                     
                                                                        w
                                                                        i
                                                                     
                                                                     =
                                                                     
                                                                        (
                                                                        1
                                                                        −
                                                                        
                                                                           ∑
                                                                           
                                                                              j
                                                                              =
                                                                              1
                                                                           
                                                                           
                                                                              i
                                                                              −
                                                                              1
                                                                           
                                                                        
                                                                        
                                                                           w
                                                                           j
                                                                        
                                                                        )
                                                                     
                                                                     
                                                                        (
                                                                        1
                                                                        −
                                                                        
                                                                           
                                                                              rand
                                                                              (
                                                                              )
                                                                           
                                                                           
                                                                              M
                                                                              −
                                                                              1
                                                                           
                                                                        
                                                                        )
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  ⋯
                                                               
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  
                                                               
                                                            
                                                            
                                                               
                                                                  
                                                                     
                                                                        w
                                                                        M
                                                                     
                                                                     =
                                                                     1
                                                                     −
                                                                     
                                                                        ∑
                                                                        
                                                                           j
                                                                           =
                                                                           1
                                                                        
                                                                        
                                                                           i
                                                                           −
                                                                           1
                                                                        
                                                                     
                                                                     
                                                                        w
                                                                        j
                                                                     
                                                                  
                                                               
                                                            
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    
                                 

MOEA/D and MSOPS (Hughes, 2003) are two representative decomposition based MOEAs that employ evenly distributed weights.

In MOEA/D weights are evenly distributed on the first quadrant of the hyperplane f
                                    1 + f
                                    2 + ⋅⋅⋅ + fM
                                     = 1. Specifically, weights are formed by all normalised weight vectors with components chosen from the set {0, 1/H, …, (H − 1)/H, 1}, where H is a positive integer number (known as the simplex-lattice design method (Tan, Jiao, Li, & Wang, 2012)). The same method has also been used in the cellular multi-objective genetic algorithm in an earlier study (Murata, Ishibuchi, & Gen, 2001). For example, for 2-objective problems, if H is specified as 100, then we can generate 
                                       
                                          
                                             C
                                             
                                                101
                                             
                                             1
                                          
                                          =
                                          101
                                       
                                     groups of weight vectors (0, 1), (0.01, 0.99), …, (1, 0). It is worth mentioning that the number of weights generated using this method increases significantly when M increases; the number of weights is determined by 
                                       
                                          C
                                          
                                             M
                                             −
                                             1
                                          
                                          
                                             H
                                             +
                                             M
                                             −
                                             1
                                          
                                       
                                    . Given H = 30 the number of weights is 5456 for M = 4, while the number increases to 46,376 when M = 5.

In MSOPS the author proposed an approach which generates evenly distributed points on a hypersphere 
                                       
                                          
                                             f
                                             
                                                1
                                             
                                             2
                                          
                                          +
                                          
                                             f
                                             
                                                2
                                             
                                             2
                                          
                                          +
                                          ⋯
                                          +
                                          
                                             f
                                             
                                                M
                                             
                                             2
                                          
                                          =
                                          1
                                       
                                     via minimising a metric V defined by Eq. (7). These points can be transformed into valid weights by using the equation: 
                                       
                                          
                                             w
                                             i
                                          
                                          =
                                          
                                             
                                                x
                                                i
                                             
                                             
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   M
                                                
                                                
                                                   x
                                                   i
                                                
                                             
                                          
                                       
                                     where xi
                                     is the ith component of a point.
                                       
                                          (7)
                                          
                                             
                                                
                                                   
                                                      
                                                         V
                                                         =
                                                         
                                                            
                                                               
                                                                  APTARANORMAL
                                                                  max
                                                               
                                                               N
                                                            
                                                            
                                                               i
                                                               =
                                                               1
                                                            
                                                         
                                                         
                                                            
                                                               0.35
                                                               e
                                                               m
                                                            
                                                            
                                                               0
                                                               e
                                                               x
                                                            
                                                         
                                                         
                                                            
                                                               
                                                                  APTARANORMAL
                                                                  max
                                                               
                                                               N
                                                            
                                                            
                                                               j
                                                               =
                                                               1
                                                               ,
                                                               j
                                                               ≠
                                                               i
                                                            
                                                         
                                                         
                                                            (
                                                            
                                                               
                                                                  x
                                                               
                                                               i
                                                            
                                                            ·
                                                            
                                                               
                                                                  x
                                                               
                                                               j
                                                            
                                                            )
                                                         
                                                      
                                                   
                                                
                                             
                                          
                                       
                                    The metric V measures the worst-case angle of two nearest neighbours. The dot product x
                                    
                                       i
                                     · x
                                    
                                       j
                                     provides the cosine of angle between the vectors x
                                    
                                       i
                                     and x
                                    
                                       j
                                    . The inner maximisation finds the nearest two neighbours in terms of the angle between them. The outer maximum operator finds the largest angle between two nearest neighbours. The optimal set of weights is produced when the outer maximum is minimised.

The main issue of using pre-defined weights is that the obtained solutions might not be well spread. This is because problem geometries are often unknown beforehand and therefore determining a suitable set of weights in order to obtain evenly distributed solutions is difficult (this will be explained later). To overcome this limitation, researchers have attempted to use adaptive weights in decomposition based algorithms.

A variety of methods for weights adaptation have been proposed. MSOPS-II (Hughes, 2007) is one such method. In MSOPS-II weight vectors are generated by bootstrapping these from the on-line archive of locally non-dominated solutions. Specifically, the weight vectors are updated as follows: take the current weight vectors and augment it with a validate weight vector created by a normalised non-dominated solution in turn. Once a weight vector is augmented, we compute angles between two nearest neighbours; identify the nearest neighbour; and then remove the most crowded one.


                           Jiang, Cai, Zhang, and Ong (2011) improved MOEA/D by using Pareto adaptive weights, paλ. The approach paλ automatically adjusts weights according to the geometry characteristics of the Pareto front. Specifically, this approach assumes that the Pareto optimal front is symmetric of the form 
                              
                                 
                                    f
                                    
                                       1
                                    
                                    p
                                 
                                 +
                                 
                                    f
                                    
                                       2
                                    
                                    p
                                 
                                 +
                                 ⋯
                                 +
                                 
                                    f
                                    
                                       M
                                    
                                    p
                                 
                                 =
                                 1
                              
                           . Based on the non-dominated solutions in the archive, parameter p is estimated. Having determined p, evenly distributed points on the approximated symmetric shape are generated; these are then converted to valid weights. The use of paλ can significantly improve the performance of MOEA/D when the problem geometry is close to the form: 
                              
                                 
                                    f
                                    
                                       1
                                    
                                    p
                                 
                                 +
                                 
                                    f
                                    
                                       2
                                    
                                    p
                                 
                                 +
                                 ⋯
                                 +
                                 
                                    f
                                    
                                       M
                                    
                                    p
                                 
                                 =
                                 1
                              
                           . However, this method faces difficulty on problems with asymmetric and disconnected Pareto fronts.


                           Gu et al. (2012) proposed to incorporate a dynamic weight design method into MOEA/D (denoted as DMOEA/D) in order to enable MOEA/D to perform well on problems having different geometries. Specifically, in every ten generations weights are re-generated according to the shape of the current non-dominated Pareto front. A piecewise linear interpolation method is applied to fit a curve (2-objective case) of the current non-dominated solutions. For each objective fi, Ni
                            interpolation points, of which the projection on the ith objective is uniform, are generated. Ni
                            is determined by 
                              
                                 
                                    
                                       
                                          10
                                       
                                       
                                          M
                                          −
                                          1
                                       
                                    
                                    N
                                    
                                       ∏
                                       
                                          j
                                          =
                                          1
                                          ,
                                          j
                                          ≠
                                          i
                                       
                                       M
                                    
                                    
                                       D
                                       j
                                    
                                 
                                 
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       M
                                    
                                    
                                       ∏
                                       
                                          j
                                          =
                                          1
                                          ,
                                          j
                                          ≠
                                          i
                                       
                                       M
                                    
                                    
                                       D
                                       j
                                    
                                 
                              
                            where N is the population size and Dj
                            is the maximum value of the projection of the current non-dominated solutions on the ith objective. At the same time, non-dominated solutions whose distance to the interpolation point is smaller than 
                              
                                 
                                    D
                                    j
                                 
                                 10
                              
                            are removed. All the ∑Ni
                            interpolation points serve as an approximation to the Pareto front. These interpolation points are then ordered by an objective (e.g. f
                           1). Solutions that are adjacent in f
                           1 are clustered into one group. The maximum number of solutions in a group is [∑Ni
                           /N′] + 1, where N′ is the number of currently non-dominated solutions. A weight vector is then created by converting the point defined by the mean of the solutions in a group. Experimental results show that this adaptive method works well on 2- and 3-objective problems. This adaptive approach is reported to be applicable to many-objective problems, however, no experimental results are shown.


                           Qi et al. (2013) also proposed an algorithm named MOEA/D-AWA where weights are periodically adjusted. Specifically, MOEA/D-AWA applies a two-stage strategy to deal with the generation of the weight vectors. First, a set of pre-determined weights are used until the population is considered converged to some extent. Then a portion of the weight vectors are adjusted according to the obtained solutions based on a geometric analysis. Weights toward a sparse region are newly created, and weights toward a dense region are removed. The density of solutions is measured by the k-nearest neighbour approach (Deb et al., 2002). MOEA/D-AWA is demonstrated to perform well on many-objective problems having a low-dimensional Pareto optimal front. It also outperforms DMOEA/D for most of the selected bi- and tri-objective problems.

All the above MOEAs attempt to maintain evenly distributed solutions on the fly. There are also some methods that aim to first obtain as many diversified solutions as possible and then apply some ad hoc methods to the obtained solutions so as to get evenly distributed solutions. EMOSA belongs to this type Li and Landa-Silva (2011). It hybridises MOEA/D with simulated annealing. The simulated annealing based local search is applied to improve the current solution of each single objective problem. In EMOSA weights are adaptively modified as follows: for each member 
                              
                                 
                                    F
                                 
                                 _
                                 
                                    
                                       s
                                    
                                    i
                                 
                              
                            in the current population, firstly find the closest neighbour (e.g., 
                              
                                 
                                    F
                                 
                                 _
                                 
                                    
                                       s
                                    
                                    j
                                 
                              
                           ) to 
                              
                                 
                                    F
                                 
                                 _
                                 
                                    
                                       s
                                    
                                    i
                                 
                              
                            and its associated weight vector w
                           
                              j
                           . Secondly, identify the weights in the pre-defined weight set (in Li & Landa-Silva (2011) this weight set is formed by a set of evenly distributed weights generated by using the simplex-lattice design method) whose Euclidean distance to w
                           
                              j
                            is larger than the distance between w
                           
                              i
                            and w
                           
                              j
                           . Thirdly, amongst the identified weights, select all the weights of which the distance between them and w
                           
                              i
                            is smaller than the distance between them and all the neighbours of w
                           
                              i
                           . The definition of the neighbourhood (T) is the same as MOEA/D. If there are multiple weights then pick one randomly. Evenly distributed solutions are obtained by applying the ɛ-dominance strategy to the offline archive solutions. Experimental results show that EMOSA outperforms three multi-objective memetic algorithms (I-MOGLS, the improved I-MOGLS and MOEA/D) on 2- and 3-objective knapsack problems and travelling salesman problems. However, its performance on many-objective problems is not discussed.

Overall the use of adaptive weights is potentially helpful to handle the issue of problem geometry for decomposition based algorithm. However, none of the existing approaches has clearly shown their benefits on MaOPs; in addition, it is suspected that adapting weights during the search may affect the convergence performance of MOEAs (as will be discussed next).

This section discusses two difficulties encountered by decomposition based algorithms: problem geometry and many-objective optimisation.

In a decomposition based algorithm, each Pareto optimal solution corresponds to an optimal solution of a single objective problem that is defined by a weighted scalarising function. That is to say, once the weighted scalarising function is determined, the distribution of the obtained Pareto optimal solutions is determined. Furthermore, once the scalarising function is chosen, the distribution of solutions would only be affected by the distribution of the employed weights.


                           Gu et al. (2012) and Giagkiozis et al. (2013a) discussed what the optimal distribution of weights should be for a specified Pareto front when using different scalarising functions. For example, when the Chevbyshev scalarising function is used, see Eq. (3), the optimal weight to search for a solution x is 
                              
                                 (
                                 
                                    
                                       
                                          f
                                          1
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          f
                                          i
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                 
                                 ,
                                 
                                    
                                       
                                          f
                                          2
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          f
                                          i
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                 
                                 ,
                                 ⋯
                                 ,
                                 
                                    
                                       
                                          f
                                          M
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                    
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          M
                                       
                                       
                                          f
                                          i
                                       
                                       
                                          (
                                          
                                             x
                                          
                                          )
                                       
                                    
                                 
                                 )
                              
                           . Knowing this, it is easy to understand that the optimal distribution of weights for different problem geometries changes. Fig. 3 illustrates the optimal distribution of weights for problems having convex and concave geometries. Take Fig. 3(a) as an example, the optimal distribution of weights for a concave Pareto front is dense in the centre while sparse at the edge.

Due to a lack of knowledge of the underlying problem geometry, it is usually not straightforward to determine a proper distribution of weights a priori for decomposition based algorithms. Although the use of adaptive weights is potentially helpful in handling this issue, it is suspected that adaptive weights might have a deleterious effect on an algorithm’s convergence.

Decomposition based algorithms using evenly distributed weights, such as MOEA/D and MSOPS face difficulties on many-objective problems. This is because the number of Pareto optimal solutions that are required to describe the entire Pareto optimal front of a MaOP is very large (Ishibuchi et al., 2008). In a decomposition based algorithm each weight vector typically corresponds to one Pareto optimal solution. The evenly distributed weights are often initialised before the search and remain unchanged during the search. It is therefore difficult to employ a limited number of weights to obtain a full and representative approximation of the entire Pareto optimal front. To illustrate this issue, we apply MOEA/D with 20 evenly distributed weights to solve the 2-objective DTLZ2 problem. Fig. 4
                           (a) and (b) show the obtained non-dominated solutions in the last generation and in the archive, respectively, after running MOEA/D for 500 generations. It is obvious that the obtained solutions are not sufficient to approximate the entire Pareto optimal front. It should be noted that due to the stochastic nature of MOEAs, neighbouring solutions of the s
                           
                              w
                            are likely to be obtained during the search. s
                           
                              w
                            is referred as the optimal solution of a single objective problem defined by the weighted scalarising function g(x∣w). However, it is less likely to find solutions that are distant from s
                           
                              w
                           .

A natural way to solve the limitation, i.e., a lack of solution diversity, is by employing a large number of weights. However, it is argued that compared with the number of solutions required to describe the entire Pareto optimal front, the number of employed weights is always relatively small. Besides, for some decomposition based MOEAs, e.g., MOEA/D, the population size is required to be equal to the number of weights. It is not easy to strike an effective balance between the population size and the number of generations under a fixed computational budget – the larger the population size, the more the beneficial dynamics of evolution are curtailed.

Another alternative is to use non-fixed weights. Typically, non-fixed weights could be either randomly generated or adaptively modified during the search. The use of non-fixed weights enables MOEAs to have more opportunities to explore different regions, thereby obtaining a set of diversified solutions. However, this might slow down the convergence speed of an algorithm. It is hypothesised that when using fixed weights, solutions are guided towards the Pareto optimal front straightly along the search directions constructed by the weights, see Fig. 5
                           (a); when using non-fixed weights, the constructed search directions keep changing. This suggests that solutions are guided towards the Pareto optimal front in a polyline trajectory as shown in Fig. 5(b), that is, the convergence speed is degraded (Giagkiozis, Purshouse, & Fleming, 2013b). Certainly, it should be admitted that in some cases, e.g., multi-modal problems, the use of random/adaptive weights is helpful to maintain diversified solutions and to prevent the algorithm from being trapped in the local optima, resulting in a better convergence.

Overall, decomposition based algorithms using pre-defined weights suffer from the issue of problem geometry. Although this issue can be handled by employing adaptive weights, it is suspected that adaptive weights degrade the algorithm’s convergence speed. Thus, it is important to develop an effective weights adaptation strategy to address this issue.

This section proposes a novel algorithm called preference-inspired co-evolutionary algorithm using weight vectors (PICEA-w) in which weights are adaptively modified by co-evolving with candidate solutions along the search process. The co-evolution enables appropriate sets of weights to be constructed adaptively such that candidate solutions are guided towards the Pareto optimal front effectively. It is expected that PICEA-w would be less sensitive to the problem geometry and also perform well on many-objective problems.

Similar to a general decomposition based MOEA, PICEA-w decomposes a MOP into a set of single objective problems that are defined by different weighted scalarising functions. The main feature of PICEA-w is that the scalarising functions’ underlying weights are adaptively modified in a co-evolutionary manner during the search. Specifically, in PICEA-w candidate solutions are ranked by each of the weighted scalarising functions, creating a ranking matrix. The fitness of candidate solutions is then calculated based on the ranking matrix. Weights are co-evolved with the candidate solutions towards an optimal distribution, and these are also responsible for striking a balance between the exploration and exploitation. For each selected solution, an effective weight is selected which ranks this solution as the best (maintain the convergence – exploitation) and is distant from this solution (improve the diversity – exploration).

We implement PICEA-w within a (μ + λ) elitist framework shown as Fig. 6
                     . Populations of candidate solutions and weight vectors, S and W, of fixed size, N and Nw
                     , are evolved for a fixed number of generations. At each generation t, parents S(t) are subjected to genetic variation operators to produce N offspring, Sc(t). Simultaneously, Nw
                      new weight vectors, Wc(t), are randomly generated. S(t) and Sc(t), W(t) and Wc(t), are then pooled respectively and the combined populations are sorted according to fitness. Truncation selection is applied to select the best N solutions as the new candidate solution population, S(t + 1) and Nw
                      solutions as the new weights population W(t + 1). Additionally, an offline archive is employed to store all the non-dominated solutions found during the search. Evenly distributed solutions are obtained by using the clustering technique described in Zitzler et al. (2002) after the optimisation process has conducted.

                        Algorithm 1
                        Preference-inspired co-evolutionary algorithm using weights (PICEA-w)

                              
                                 
                              
                           
                        

The pseudo-code of PICEA-w is presented in Algorithm 1. In the following we explain the main steps of PICEA-w.
                        
                           •
                           Line 1 initialises the offline archive ArchiveF as the null set 
                                 ⌀
                              .

In lines 2 and 3, N candidate solutions S are initialised and their objective values 
                                 
                                    F
                                    _
                                    S
                                 
                               are calculated. The offline archive, ArchiveF is updated by function updateArchive in line 4.

Line 5 applies function weightGenerator to generate Nw
                               random weights.

In line 7 function geneticOperation is applied to generate offspring candidate solutions Sc. Their objective values 
                                 
                                    F
                                    _
                                    Sc
                                 
                               are calculated in line 8. S and 
                                 
                                    Sc
                                    ,
                                    F
                                    _
                                    S
                                 
                               and 
                                 
                                    F
                                    _
                                    Sc
                                 
                               are pooled together, respectively in line 9.

Line 10 generates another set of weights Wc. In line 11, W and Wc are pooled together.

Line 12 sets the parameter θ which would be used in function coEvolve to implement a local operation.

Line 13 co-evolves the joint candidate solutions JointS and the joint weights JointW, and so to obtain new parent S and W.

Line 14 updates the offline archive with newly obtained solutions 
                                 
                                    F
                                    _
                                    S
                                 
                              .

Line 16 select ASize evenly distributed solutions BestF from ArchiveF using the function pruningArchive.

The core part of PICEA-w lies in the function coEvolve which will be elaborated next. Prior to introducing this function, we describe the following four functions: weightGenerator, geneticOperation, thetaConfiguration, updateArchive and pruningArchive.

                        
                           (i)
                           Function weightGenerator forms a new weight set Wc with Nw
                               weight vectors that are generated according to Eq. (6) (Jaszkiewicz, 2002). Alternatively, Wc can be formed by randomly sampling Nw
                               weights from an evenly distributed candidate weight set Ψ. Ψ can be created by, for example, the simplex-lattice design method (as described in p. 8).


                              
                                 
                              
                           


                              
                                 
                              
                           

Function geneticOperation applies genetic operators to produce offspring Sc. Many genetic operators are available, for example, single point crossover, uniform crossover, simulated binary crossover, simplex crossover, one bit-flip mutation, polynomial mutation. These genetic operators have their own advantages and disadvantages. In this study the SBX and PM operators are chosen. It should be noted that for different problems different genetic operators may lead to different algorithm performance. Selecting suitable genetic operators is often algorithm- and problem-dependent (Srinivas & Patnaik, 1994).

Function thetaConfiguration adjusts parameter θ by Eq. (8), that is, θ increases linearly from a small value to 
                                 
                                    π
                                    2
                                 
                               radians.
                                 
                                    (8)
                                    
                                       
                                          
                                             
                                                
                                                   θ
                                                   =
                                                   
                                                      π
                                                      2
                                                   
                                                   ×
                                                   
                                                   
                                                      t
                                                      maxGen
                                                   
                                                   ;
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           

The use of θ implements a local selection at the early stage of the evolution while a global selection at the late stage of the evolution. A local selection means that a candidate solution only competes with its neighbours; and a global selection means that a candidate solution competes with all the other candidate solutions (Wang, Fleming, & Purshouse, 2014). The benefits of this strategy will be demonstrated later (in Section 6).

Function updateArchive updates the offline archive ArchiveF by 
                                 
                                    F
                                    _
                                    S
                                 
                              . For each solution (e.g. 
                                 
                                    
                                       F
                                    
                                    _
                                    
                                       
                                          s
                                       
                                       i
                                    
                                 
                              ) in 
                                 
                                    F
                                    _
                                    S
                                 
                              , if 
                                 
                                    
                                       F
                                    
                                    _
                                    
                                       
                                          s
                                       
                                       i
                                    
                                 
                               is dominated by a solution in the archive, then 
                                 
                                    
                                       F
                                    
                                    _
                                    
                                       
                                          s
                                       
                                       i
                                    
                                 
                               is rejected. Otherwise it is accepted as a new archive member. Simultaneously, solutions in the archive that are dominated by 
                                 
                                    
                                       F
                                    
                                    _
                                    
                                       
                                          s
                                       
                                       i
                                    
                                 
                               are removed.

Function pruningArchive employs the clustering method in SPEA2 (Zitzler et al., 2002) to obtain a specified number of evenly distributed solutions. It iteratively removes the most crowded solution from ArchiveF until only ASize solutions are left.

Function coEvolve evaluates the performance of candidate solutions and weight vectors, and then selects new parent population S and W from the joint population JointS and JointW, respectively. A candidate solution gains higher fitness by performing well on more weighted scalarising functions. A weight vector only gains fitness by being rewarded from the candidate solutions that are ranked as the best by this weight. The pseudo-code of function coEvolve is as follows.
                        Function 1
                        coEvolve (JointS, JointF, W)

                              
                                 
                                    
                                    
                                       
                                          
                                             
                                             
                                             
                                             Input: The joint population 
                                                
                                                   JointS
                                                   ,
                                                   JointF
                                                   ,
                                                   JointW
                                                
                                             , the parameter 
                                                θ
                                             
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             Output: New parents, 
                                                
                                                   S
                                                   ,
                                                   F
                                                   _
                                                   S
                                                   ,
                                                   W
                                                
                                             
                                          
                                       
                                       
                                          1 
                                             
                                                
                                                   R
                                                   ←
                                                
                                              
                                             rankingSW(
                                                
                                                   JointF
                                                   ,
                                                   JointW
                                                   ,
                                                   θ
                                                
                                             )
                                          
                                       
                                       
                                          2 
                                             
                                                
                                                   (
                                                   F
                                                   _
                                                   S
                                                   ,
                                                   S
                                                   ,
                                                   ix
                                                   )
                                                   ←
                                                
                                              
                                             selectS(
                                                
                                                   JointF
                                                   ,
                                                   JointS
                                                   ,
                                                   R
                                                
                                             ) 
                                          
                                       
                                       
                                          3 
                                             
                                                
                                                   W
                                                   ←
                                                
                                              
                                             selectW(
                                                
                                                   JointW
                                                   ,
                                                   F
                                                   _
                                                   S
                                                   ,
                                                   R
                                                   ,
                                                   ix
                                                
                                             )
                                          
                                       
                                    
                                 
                              
                           
                        

Line 1 applies function rankingSW to rank JointF by each weighted scalarising function. Specifically, for each w ∈ JointW, we first identify its neighbouring candidate solutions. The neighbourhood is measured by the angle between a candidate solution, s and a weight vector, w. If the angle is smaller than the θ value, then s and w are defined as neighbours. See Fig. 7, s
                              1 is a neighbour of w as α
                              11 < θ while s
                              2 is not (α
                              12 > θ). Then we rank these neighbouring candidate solutions based on their performance measured by the corresponding weighted Chebyshev scalarizing function. This produces a 
                                 
                                    [
                                    2
                                    N
                                    ×
                                    
                                    2
                                    
                                       N
                                       w
                                    
                                    ]
                                 
                               ranking matrix, denoted as R. Rij
                               represents the rank of the candidate solution s
                              
                                 i
                               on the weighted Chebyshev function using w
                              
                                 j
                              , i.e., gwc
                              (s
                              
                                 i
                              ∣w
                              
                                 j
                              ). The best solution is ranked 1. The rank for solutions that are not neighbours of the w is set as inf, i.e., the solutions are ignored. The Chebyshev scalarising function is used in PICEA-w due to its guarantee of producing a Pareto optimal solution for each weight vector, and also its robustness on problem geometries.

Line 2 applies function selectS to select the best N candidate solutions as new parents S. Note that ix returns the index of S in JointS. Specifically, the following steps are executed.


                              
                                 
                                    •
                                    Sort each row of the ranking matrix R in an ascending order, producing another matrix Rsort. Rsort
                                        holds in the first column the smallest (best performance) ranking result achieved by each candidate solution across all the weighted scalarising functions. Simultaneously, the second column holds the second smallest ranking result for each candidate solution and so on.

All candidate solutions are lexicographically ordered based on Rsort
                                       . This returns a rank (denoted as r) for each candidate solution. The fitness of a candidate solution is then determined by 2N − r. Truncation selection is applied to select the best N solutions as new parents, S.

Line 3 applies function selectW to select the most suitable weight vector from JointW for each of the survived candidate solutions, i.e., members in the new parent S. The basic idea of the selection is to balance exploration and exploitation. To do so, two criteria are set for the weights selection. First, for each candidate solution the selected weight must be the one that ranks the candidate solution as the best. Secondly, if more than one weight is found by the first criterion, we choose the one that is the furthest from the candidate solution. The first criterion is helpful in driving the search quickly towards the Pareto front; the second criterion is helpful in guiding the search to explore new areas. More specifically, for a candidate solution s
                              
                                 i
                              , first we identify all the weights that rank s
                              
                                 i
                               the best. If there is only one weight, then this weight is selected for s
                              
                                 i
                              . This guarantees that the survived candidate solution s
                              
                                 i
                               will not lose its advantage in the next generation as there is still one weight that ranks this candidate solution the best unless a better solution along this direction is generated. If so, the convergence performance is improved. If more than one weight is found, we select the weight that has the largest angle between s
                              
                                 i
                               and itself. In this way, the algorithm is guided to investigate some unexplored areas, i.e., improving the diversity. It is worth mentioning that the second criterion is not considered unless multiple weights are identified by the first criterion. This guarantees that while exploring for a better diversity, the exploitation for a better convergence is also maintained. The pseudo-code of the function selectW is described as follows:

                                 Function 2
                                 selectW (
                                       
                                          JointW
                                          ,
                                          F
                                          _
                                          S
                                          ,
                                          R
                                          ,
                                          ix
                                       
                                    )

                                       
                                          
                                       
                                    
                                 

Line 1
                                       
                                       
                                       
                                        initialises the new weight set as 
                                          ⌀
                                       . Line 2 forms a new ranking matrix R′ by selecting the ix-th row of R, where ix is the index of 
                                          
                                             F
                                             _
                                             S
                                          
                                        in the JointF.


                                       
                                          
                                       
                                    


                                       
                                          
                                       
                                    

Line 3 ranks the contribution of weights to each of the candidate solutions according to R′. The results are stored in matrix R″. 
                                          
                                             R
                                             
                                                ij
                                             
                                             
                                                ′
                                                ′
                                             
                                          
                                        describes the relative order of contribution that a candidate solution s
                                       
                                          i
                                        received from a weight vector w
                                       
                                          j
                                       . The lower the rank, the higher the contribution.

Line 5
                                       
                                        finds all the weight vectors that give the highest contribution to solution s
                                       
                                          i
                                       , i.e., weights that have 
                                          
                                             
                                                R
                                                
                                                   ij
                                                
                                                
                                                   ′
                                                   ′
                                                
                                             
                                             =
                                             1
                                          
                                       . If there is only one weight then we choose this weight for s
                                       
                                          i
                                       . If multiple weights are found then we choose the weight w
                                       
                                          k
                                        that has the largest angle with 
                                          
                                             
                                                F
                                             
                                             _
                                             
                                                
                                                   s
                                                
                                                i
                                             
                                          
                                        (lines 6–11). To avoid multiple selections of a weight, once the weight w
                                       
                                          k
                                        is selected the k-th column of 
                                          
                                             R
                                             
                                                ij
                                             
                                             
                                                ′
                                                ′
                                             
                                          
                                        is set as inf.

Additionally, function angle computes the angle, α, between a candidate solution (i.e., 
                                          
                                             
                                                
                                                   F
                                                
                                                _
                                                
                                                   
                                                      s
                                                   
                                                   i
                                                
                                                
                                                   
                                                      
                                                         z
                                                      
                                                   
                                                   *
                                                
                                             
                                             →
                                          
                                       ) and a weight vector (i.e., 
                                          
                                             
                                                
                                                   
                                                      w
                                                   
                                                   i
                                                
                                                
                                                   
                                                      
                                                         z
                                                      
                                                   
                                                   *
                                                
                                             
                                             →
                                          
                                       ). The dot product of two normalised vectors returns the cosine of the angel between the two vectors. Thus, 
                                          
                                             α
                                             =
                                             
                                                APTARANORMAL
                                                arccos
                                             
                                             (
                                             
                                                
                                                   
                                                      F
                                                   
                                                   _
                                                   
                                                      
                                                         s
                                                      
                                                      i
                                                   
                                                   
                                                      
                                                         
                                                            z
                                                         
                                                      
                                                      *
                                                   
                                                
                                                →
                                             
                                             ·
                                             
                                                
                                                   
                                                      
                                                         w
                                                      
                                                      i
                                                   
                                                   
                                                      
                                                         
                                                            z
                                                         
                                                      
                                                      *
                                                   
                                                
                                                →
                                             
                                             )
                                          
                                       .

To further explain the co-evolution procedure, let us consider a bi-objective minimisation instance shown in Fig. 8 with four candidate solutions and four weight vectors, i.e. N = Nw
                      = 2. Table 1 presents the settings for this example, including objective values of the four candidate solutions, the four weights and the θ value and the reference point z*.

The angle αij
                      between each pair of s
                     
                        i
                      and w
                     
                        j
                      is calculated, and is shown in Table 2. From the table, we know that when θ is set to 
                        
                           π
                           18
                        
                      radians, w
                     1 has two neighbours s
                     1 and s
                     2; w
                     2 has only one neighbour s
                     3; w
                     3 has two neighbours s
                     3 and s
                     4; w
                     4 has no neighbour.


                     Table 3 shows the selection process of candidate solutions. First candidate solutions are ranked by each of the weighted Chebyshev functions. Then the fitness of each candidate solution is calculated according to the procedure of function selectS. Based on the fitness, s
                     1
                     
                        
                           (
                           
                              Fit
                              
                                 
                                    s
                                 
                                 1
                              
                           
                           =
                           2
                           )
                        
                      and s
                     3
                     
                        
                           (
                           
                              Fit
                              
                                 
                                    s
                                 
                                 3
                              
                           
                           =
                           3
                           )
                        
                      are selected as new parent candidate solutions S (see Table 4).

Next we select the weight for each candidate solution in the S. Firstly, we randomly select one solution from S without replacement, e.g. s
                     1. Then we identify the weights that contribute the most to s
                     1, that is, s
                     1 is ranked the best on these weights. There is only one weight i.e., w
                     1 that contributes to s
                     1 and therefore w
                     1 is selected. After this, another candidate solution is randomly selected from the set Sâ§¹s
                     1, e.g., s
                     3. Similarly, we find the weights on which s
                     3 performs the best. Both w
                     2 and w
                     3 satisfy the condition. Then we look at the second criterion. It is found that the angle between s
                     3 and w
                     3 is larger than that between s
                     3 and w
                     2 and so w
                     3 is selected for s
                     3. This procedure continues until each candidate solution in the S is assigned a weight vector.

Additionally, in PICEA-w the number of weight vectors Nw
                      is not required to be equal to the number of candidate solutions N. However, since in each generation each of the survived candidate solution is assigned a different weight vector, it is required that 2Nw
                      ≥ N.

With respect to the time complexity of PICEA-w, evaluation of a population of candidate solutions runs at 
                        
                           O
                           (
                           M
                           ×
                           
                           N
                           )
                        
                     , where M is the number of objectives and N is the number of candidate solutions. The main cost of PICEA-w is on function coEvolve in which three sub-functions are involved. The sub-function rankingSW ranks all candidate solutions on each weight vector and so runs at 
                        
                           O
                           (
                           
                              
                                 N
                              
                              2
                           
                           ×
                           
                           
                              N
                              w
                           
                           )
                        
                     . The sub-function selectS selects the best N solutions from 2N solutions which runs at 
                        
                           O
                           (
                           
                              
                                 N
                              
                              2
                           
                           )
                        
                     . The sub-function selectW requires to calculate the angle between each pair of candidate solution and weight vector which runs at 
                        
                           O
                           (
                           N
                           ×
                           
                           
                              N
                              w
                           
                           )
                        
                     . Therefore, the overall time complexity of PICEA-w is 
                        
                           O
                           (
                           
                              
                                 N
                              
                              2
                           
                           ×
                           
                           
                              N
                              w
                           
                           )
                        
                     .

Eight test problems are used in this study. They are constructed by applying different shape functions provided in the WFG toolkit to the standard WFG4 benchmark problem (Huband, Hingston, Barone, & While, 2006). The WFG parameters k (position parameter) and l (distance parameter) are set to 18 and 14, i.e., the number of decision variables is n = k + l = 32 for each problem instance. These problems are invoked in 2-, 4- and 7-objective instances. The source code of these problems can be downloaded from http://www.sheffield.ac.uk/acse/staff/rstu/ruiwang/index.


                        
                           
                              •
                              WFG41 is the same as the WFG4 problem which has a concave Pareto optimal front.

WFG42 has a convex Pareto optimal front. It is built by replacing the concave shape function used in WFG4 with the convex shape function.

WFG43 has a strong concave Pareto optimal front. It is built by scaling the concave shape function with power 
                                    
                                       1
                                       4
                                    
                                 .

WFG44 has a strong convex Pareto optimal front. It is built by scaling the convex shape function with power 
                                    
                                       1
                                       4
                                    
                                 .

WFG45 has a mixed Pareto optimal front. It is built by replacing the concave shape function used in WFG4 with the mixed shape function.

The Pareto optimal front of WFG46 is a hyperplane. It is built by replacing the concave shape function used in WFG4 with the linear shape function.

The Pareto optimal front of WFG47 is disconnected and concave. It is built by replacing the concave shape function used in WFG4 with the concave (for the first M − 1 objectives) and the disconnected (for the last objective) shape function. Parameters used in the disconnected function are set as 
                                    
                                       α
                                       =
                                       β
                                       =
                                       
                                          1
                                          2
                                       
                                       ,
                                       A
                                       =
                                       2
                                    
                                 .

The Pareto optimal front of WFG48 is disconnected and convex. It is built by replacing the concave shape function used in WFG4 with the convex (for the first M − 1 objectives) and the disconnected (for the last objective) shape function. Parameters used in the disconnected function are set as 
                                    
                                       α
                                       =
                                       β
                                       =
                                       
                                          1
                                          2
                                       
                                       ,
                                       A
                                       =
                                       2
                                    
                                 .

The Pareto optimal front of these problems has the same trade-off magnitudes, and it is within [0,2]. Thus, the nadir point for these problems is [2, 2, …, 2]. The Pareto optimal fronts of these problems are shown in Appendix A. Please note that WFGn-Y refers to problem WFGn with Y objectives.

To benchmark the performance of PICEA-w, four competitor MOEAs are considered. All the competitors use the same algorithmic framework as PICEA-w, and the Chebyshev scalarising function is chosen. The only difference lies in the method of constructing JointW.

                           
                              •
                              The first algorithm (denoted as RMOEA) forms JointW by combining Nw
                                  weights that are randomly selected from current JointW and another set of Nw
                                  randomly generated weights. RMOEA represents decomposition based MOEAs using random weights, e.g., I-MOGLS and J-MOGLS.

The second competitor MOEA applies 2Nw
                                  weights that are evenly distributed on a unit-length hyperplane as JointW (denoted as UMOEA). UMOEA represents decomposition based MOEAs using evenly distributed weights, e.g., MSOPS and MOEA/D.

The other two considered competitor MOEAs use adaptive weights. The weights adaptation strategies are extracted from DMOEA/D and EMOSA, respectively. The reason for choosing these two algorithms is that DMOEA/D is demonstrated to perform
                                  well on problems having complex Pareto front geometries and EMOSA is found to outperform MOGLS and MOEA/D on 2- and 3-objective problems (Li & Landa-Silva, 2011). Note that the neighbourhood size used in DMOEA/D and EMOSA is set as T
 = 10 which we demonstrated in previous work to offer good performance (Wang et al., 2013).

Each algorithm is performed for 31 runs, each run for 25,000 function evaluations. For all algorithms the population size of candidate solutions and weights are set as N = 100 and Nw
                         = 100, respectively. The simulated binary crossover (SBX) and polynomial mutation (PM) are applied as genetic operators. The recombination probability pc
                         of SBX is set to 1 per individual and mutation probability pm
                         of PM is set to 1/n per decision variable. The distribution indices ηc
                         of SBX and ηm
                         of PM are set as 15 and 20, respectively. These parameter settings are summarised in Table 5 and are fixed across all algorithm runs.

The hypervolume metric (HV) (Zitzler & Thiele, 1999) is used as performance metric, and the method developed by Fonseca, Paquete, and López-Ibáñez (2006) is used to compute the HV value. A favourable hypervolume (larger, for a minimisation problem) implies a better combination of proximity and diversity. The approximation sets used in the HV calculation are the members of the offline archive of all non-dominated points found during the search, since this is the set most relevant to a posteriori decision-making. For reasons of computational feasibility, prior
                         to analysis the set is pruned to a maximum size of 100 using the SPEA2 truncation procedure (Zitzler et al., 2002). Note that prior to calculating the HV, we normalise all objective values to be within the range [0, 1] by the nadir point (Deb et al., 2010) (which assumes equal relative importance of normalised objectives across the search domain). The reference point for the hypervolume calculation is set as 
                           
                              
                                 r
                                 i
                              
                              =
                              1.2
                              ,
                              
                                 
                                    1
                                    e
                                    m
                                 
                                 
                                    0
                                    e
                                    x
                                 
                              
                              i
                              =
                              1
                              ,
                              2
                              ,
                              ⋯
                              ,
                              M
                           
                        . Readers for more details of the dependency of hypervolume value and the chosen reference point are referred to Knowles and Corne (2002); Knowles, Corne, and Fleischer (2003) and Auger, Bader, Brockhoff, and Zitzler (2009).

Performance comparisons between algorithms based on the HV metric are made according to a rigorous non-parametric statistical framework, drawing on recommendations in Zitzler, Thiele, Laumanns, Fonseca, and da Fonseca (2003). Specifically, we first test the hypothesis that all algorithms perform equally using the Kruskal–Wallis test. If this hypothesis is rejected at the 95% confidence level, we then consider pair-wise comparisons between the algorithms using the Wilcoxon-ranksum two-sided comparison procedure at the 95% confidence level, employing Šidák correction to reduce Type I errors (Curtin & Schulz, 1998).

To visualise the performance of PICEA-w, we plot the obtained Pareto front (that has the median HV metric value across the 31 runs) as well as the co-evolved weights of the 2-objective problems in Figs. 9 and 10.

From the results, it is observed that, for most of problems, the obtained solutions spread evenly along the Pareto front, that is, the performance of PICEA-w is robust to the problem geometry. In addition, the distribution of the obtained weights approximates to the optimal distribution for each problem (this will be further discussed in Section 6.3). For example, problem WFG43-2 features strong concavity and the distribution of the obtained weights is dense in the centre while sparse in the edge. WFG44-2 features strong convexity and the distribution of the co-evolved weights is sparse in the centre while dense in the edge. A much clearer observation can be made on problems WFG47-2 and WFG48-2. On these two problems the co-evolution leads most of weights to be constructed in the relevant place, intersecting the Pareto optimal front.

Results of the Kruskal–Wallis tests followed by pair-wise Wilcoxon-ranksum plus Šidák correction tests based on the performance metric are provided in this Section. The initial Kruskal–Wallis test breaks the hypothesis that all five algorithms are equivalent. Therefore the outcomes of pair-wise statistical comparisons for 2-, 4- and 7-objective WFG problems are shown in Tables 6–8 respectively. A smaller rank value indicates better performance; ordering within a rank is purely alphabetical.

For 2-objective problems, it is observed from Table 6 that:

                           
                              (i)
                              UMOEA performs the best for WFG41, WFG42, WFG45 and WFG46, for which the Pareto optimal fronts are neutral. However, UMOEA exhibits worse performance on the rest of four problems. Specifically, its performance is worse than PICEA-w on three out of the four problems; and is worse than DMOEA/D and EMOSA on WFG43 and WFG44.

The three adaptive weights based D-MOEAs have comparable performance on five problems (WFG41, WFG43, WFG44, WFG45 and WFG46). On WFG47 and WFG48, DMOEA/D and EMOSA have comparable performance and both are worse than PICEA-w. On WFG42, PICEA-w and EMOSA have comparable performance and they both perform better than DMOEA/D.

RMOEA is the worst optimiser for all the problems.

For 4-objective problems, it is observed from Table 7 that:

                           
                              (i)
                              The performance of UMOEA degrades. It is inferior to the three adaptive weights based D-MOEAs for all the problems. It even performs worse than RMOEA for five out of the eight problems, and on the other three problems (WFG41, WFG42 and WFG46) UMOEA performs comparably with RMOEA.

PICEA-w is always amongst the top performing algorithms. It is exclusively the best for four problems, i.e., WFG41, WFG46, WFG47 and WFG48.

With respect to
                                  EMOSA and DMOEA/D, it is found that EMOSA exhibits a better or comparable performance for all the problems.

Although RMOEA performs better than UMOEA, it is worse than the three adaptive weights based algorithms.

As the number of objectives increases to 7, we can observe from Table 8 that the performance of PICEA-w become more promising:

                           
                              (i)
                              PICEA-w ranks exclusively or jointly (on WFG45 and WFG46) the best for all the problems.

Among the remaining four algorithms, EMOSA is the most effective. It performs better than DMOEA/D for five out of the eight problems, and is comparable to DMOEA/D for the remaining three problems.

Although DMOEA/D is worse than PICEA-w and EMOSA, it is better than RMOEA for most of the problems.

RMOEA performs better than UMOEA for all the problems. UMOEA performs the least well.

To further investigate the performance of the algorithms, we also separately calculated the proximity (as measured by generational distance – GD (Van Veldhuizen & Lamont, 2000)) and diversity (as measured by the Δ (Deb et al., 2002)) measures for the 2-, 4- and 7-objective WFG41 problems. The Pareto optimal front of WFG41 is the surface of an M-dimension hyper-sphere with radius r = 2 in the first quadrant, which is amenable to uniform sampling. We sample 20,000 points as the reference set for calculating the performance metrics.

From Table 9, it is found that

                           
                              •
                              In terms of convergence UMOEA performs the best while RMOEA performs the worst for all three problems. Among the other three algorithms, PICEA-w performs better than DMOEA/D and EMOSA for WFWG41-4 and WFG41-7. For WFG41-2, PICEA-w performs comparably with DMOEA/D. Both algorithms are better than EMOSA.

In terms of diversity PICEA-w is amongst the top performing algorithms for all three problems. EMOSA performs competitively with PICEA-w on WFG41-2 and WFG41-4, however, it is worse than PICEA-w on WFG41-7. DMOEA/D is worse than EMOSA and PICEA-w on WFG41-4 and WFG41-7, but is better than RMOEA and UMOEA on these two problems. Comparing UMOEA with RMOEA, RMOEA is worse on WFG41-2 while better on the other
                                  two many-objective problems.

This section further demonstrates the effect of weights adaptation by comparing PICEA-w against MOEA/D on two Pareto-Box problems introduced in Ishibuchi, Hitotsuyanagi, Ohyanagi, and Nojima (2011). The Pareto-Box problem minimises distances to each of the given points in the two-dimensional decision space. For example, if three points are given (e.g., A, B and C), the constructed Pareto-Box problem is a three-objective problem, and is written as follows:
                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             Minimize
                                             
                                                
                                                   1
                                                   e
                                                   m
                                                
                                                
                                                   0
                                                   e
                                                   x
                                                
                                             
                                             
                                                {
                                                distance
                                                (
                                                A
                                                ,
                                                
                                                   x
                                                
                                                )
                                                ,
                                                distance
                                                (
                                                B
                                                ,
                                                
                                                   x
                                                
                                                )
                                                ,
                                                distance
                                                (
                                                C
                                                ,
                                                
                                                   x
                                                
                                                )
                                                }
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        where x is a decision vector.

In this study, the decision space is set within 
                           
                              [
                              0
                              ,
                              100
                              ]
                              ×
                              
                              [
                              0
                              ,
                              100
                              ]
                           
                        . The first problem has four points, that is, A = [50, 90], B = [50, 10], C = [48, 12], D = [52, 12]; the second problem considers six points: A = [50, 90], B = [50, 10], C = [48, 12], D = [52, 12], E = [48, 88], D = [52, 88]. The population size N is set as 220 and 252 for the four-objective and six-objective problem, respectively. The number of weights is set equal to N. Other parameters are set the same as that adopted in Table 5.

Experimental results of a single run of each algorithm on the four-objective Pareto-Box problem are shown in Fig. 11. Pareto optimal solutions are points inside the four points A, B, C and D. From Fig. 11, we can observe that solutions obtained by PICEA-w spread across the whole region. However, for MOEA/D we observe some regions with no solutions. With respect to the convergence performance, MOEA/D is better. Most of the obtained solutions are inside the four points. Similar results are obtained for the six-objective Pareto-Box problem, see Fig. 12, MOEA/D has better convergence performance, while its diversity performance is inferior to PICEA-w.

Although solutions obtained by PICEA-w can almost cover the entire Pareto optimal front, the uniformity of these solutions is not as good as expected. One possible reason could be that the weights adaptation strategy is specially designed for maintaining good diversity in objective-space. There is no guarantee that good diversity in objective-space leads to good diversity in decision-space. Maintaining good diversity in both objective-space and decision-space is an important and challenging issue, which needs to be further studied in future.

@&#DISCUSSIONS@&#

UMOEA, which employs a set of pre-defined evenly distributed weights, faces difficulties on many-objective problems or problems having extremely complex geometry. The reason is that evenly distributed weights lead to a poor distribution of solutions for problems whose geometry is not similar to a hyper-plane. Simultaneously, as the employed weights are fixed, UMOEA can only obtain a limited number of solutions and these are insufficient to approximate the entire Pareto optimal front, particularly for many-objective problems. Certainly, when the problem is low-dimension and has a neutral Pareto optimal front, UMOEA performs well, e.g., the 2-objective WFG41, WFG42, WFG45 and WFG46.

RMOEA, which employs weights that are randomly generated in each generation, performs worse than UMOEA for low-dimension problems. The reason is that, as mentioned earlier, the search directions in RMOEA are not fixed as in UMOEA but keep changing during the whole search process. This leads RMOEA to have an inferior convergence performance compared with UMOEA. However, RMOEA tends to perform better than UMOEA for high-dimension problems. This is also due to the use of random weights, that is, random weights guide the algorithm to search different regions of the Pareto optimal front, therefore leading to a set of diversified solutions, i.e., a better diversity performance.

The three adaptive weights based D-MOEAs perform better than UMOEA and RMOEA for the four 2-objective problems (WFG43, WFG44, WFG47 and WFG48) that have complex Pareto optimal front and for most of the many-objective problems. This indicates that the weights adaptation strategies employed in these algorithms are helpful for handling the issue of problem geometry and many-objective optimisation. Given a closer examination, it is found that amongst the three algorithms, the co-evolution based weights adaptation is the most effective one. It appropriately balances the exploration and exploitation and so enables PICEA-w to perform well for most of the problems. Moreover, during the co-evolution, weights gradually learn the geometry of the problem and evolve towards an optimal distribution. This leads PICEA-w to be less sensitive to problem geometry.

In PICEA-w a parameter θ, which measures the angle between a candidate solution and a weight vector is employed to implement local selection. Here we demonstrate the impact of the local selection mechanism.

The 2- and 4-objective WFG47 are selected as test problems. Two different choices of θ are examined. The first choice sets θ as π/2 radians during the whole search process, which indicates that the evaluation of candidate solutions is executed globally. That is, every solution competes against all the other solutions. The second setting sets θ as π/18 radians during the whole search process, which indicates that the evaluation of candidate solutions is always executed locally. That is, every solution competes against its neighbours. All the other parameters are the same as adopted in Table 5. We use PICEA-w1 and PICEA-w2 to denote PICEA-w using θ = π/2 and θ = π/18 radians, respectively. These two variants are compared with PICEA-w in which θ is adjusted by Eq. (8).

All algorithms are executed for 31 runs. To visualise the performance of PICEA-w, Pareto fronts (that have the median HV metric value across the 31 runs) obtained by PICEA-w1 and PICEA-w2 are shown in Fig. 13. Experimental results in terms of the HV metric are shown in Table 10. The symbol ‘ − ’, ‘ = ’or ‘ + ’means the considered algorithm performs statistically worse, equal or better than PICEA-w at 95% confidence level subjected to the Wilcoxon-ranksum two-sided comparison procedure.

From the results we can observe that (i) PICEA-w1 performs worse than PICEA-w for all the problems; and (ii) PICEA-w2 performs comparably with PICEA-w on the 2-objective WFG47, whilst performs worse than PICEA-w on WFG47-4.

The poor performance of PICEA-w1 in terms of the HV metric is because PICEA-w1 has not found the entire Pareto optimal front, see Fig. 13. The reason could be that each solution globally competes with other solutions, which leads some potentially useful, though dominated, solutions to be removed at the early stage of the evolution. For example, in Fig. 14, although solutions in region A are dominated, they are helpful to search for Pareto optimal solutions in region B. Using small θ at the beginning is helpful in keeping those locally good solutions in region A and therefore obtaining the entire Pareto optimal front.

The reason for the poor performance of PICEA-w2 is likely to be that the local selection has a deleterious effect on convergence. This operation might assign higher fitness to some dominated solutions. Although this is helpful from a diversity perspective, it slows down the convergence speed as some dominated solutions are stored during the search. This side effect becomes more significant on higher-dimension problems since convergence is inherently more difficult to achieve on many-objective fitness landscapes. Eq. (8), used to adjust θ, though simple, is an effective strategy to balance convergence and diversity performance. In future, a refined strategy for configuring θ should be investigated.

In PICEA-w the weights also evolve towards the optimal distribution during the search. The optimal distribution of weights is defined as that which corresponds to a uniform distribution of solutions in objective-space. Comparing Figs. 9 and 10 with Figs. A.15 and A.16 (shown in Appendix A), we can observe that for most of the problems the distribution of the co-evolved weights approximates qualitatively to the optimal distribution.

Moving beyond visual inspection,we employ a non-parametric method – the two-sample multi-dimensional Kolmogorov–Smirnov (K–S) test for the independence of two distributions (Peacock, 1983; Justel, Peña, & Zamar, 1997) – to quantitatively examine the similarity between the optimal and evolved weight sets. For the purposes of this analysis, we can conceive of the state of PICEA-w at some generation, t, as representing some stochastic and/or emergent distribution function from which the weight vectors are sampled. Any run of PICEA-w represents samples from an instance of the distribution function. We therefore perform a K–S test for each run of the algorithm, comparing against a single set of sample weights drawn from the optimal distribution for each problem. To provide an indication of the effect of sample (i.e. population) size on the K–S results, and against the effect of alternative weight distributions, we also provide comparison K–S results for the optimal weights sample against: (i) another sample from the optimal distribution; (ii) a sample from a uniform distribution of weights; and (iii) a sample from an even distribution of weights. The methods for generating the sample sets are summarised below:

                           
                              (i)
                              Optimal weights: Nw
                                  solutions from the Pareto optimal front are uniformly sampled. The selected solutions are then scaled and normalised to create valid weight vectors (see Section 2.3.1).

Co-evolved weights: use the Nw
                                  adapted weights in the last generation of PICEA-w (the algorithm is run 31 times to generate 31 sets of such weights).

Uniform weights: uniformly sample Nw
                                  points from line x + y = 1, x, y ≥ 0.

Even weights: use the simplex-lattice design method (see p. 8) to generate Nw
                                  weights.

For each case, the null hypothesis of the K–S test is that both sets of weights are drawn from the same underlying distribution. The K–S statistic quantifies a distance (denoted as D) between the empirical distribution functions of the two samples. The D metric value is calculated using the method described in Peacock (1983). We also calculate the p-values for the independence test. Results are presented in Table 11, for which we show the 10%, 50% and 90% deciles for the PICEA-w comparisons to provide an indication of uncertainty in the performance of the algorithm. The PICEA-w results are sorted so that 10% is better performing and 90% is worse performing.

For the WFG48 problem, for uniformly and evenly distributed samples, we observe that the K–S test identifies that these samples come from a different distribution to the optimal distribution of weights with 95% certainty. In all other cases, the null hypothesis is not broken. Considering the PICEA-w results, it can be seen that in general the D metric lies between that resulting from an optimal versus optimal comparison and those from the known alternative distributions, even at the 90% decile. The best runs of PICEA-w produce results very close to those of an optimal sample. Note that, for WFG46, evenly distributed weights approximate well to the optimal distribution because the Pareto optimal front of WFG46 is a linear line (i.e. an even distribution is actually optimal in this case).

Overall, from both the qualitative and the quantitative examinations, we have shown that the distribution of the co-evolved weights is more similar to the optimal weights distribution than a distribution of uniform weights and even weights for most of the problems. This provides good evidence, at a mechanism level, for the good performance of PICEA-w, in comparison to RMOEA and UMOEA.

@&#CONCLUSION@&#

Decomposition based algorithms comprise a popular class of evolutionary multi-objective optimiser, and have been demonstrated to perform well when a suitable set of weights are provided. However, determining a good set of weights a priori for real-world problems is usually not straightforward due to a lack of knowledge on the underlying problem structure. This study has proposed a new decomposition based algorithm for multi-objective optimisation, PICEA-w, that eliminates the need to specify appropriate weights in advance of performing the optimisation. Specifically, weights are adaptively modified by being co-evolved with candidate solutions during the search process. The co-evolution enables suitable weights to be constructed adaptively during the optimisation process, thus guiding the candidate solutions towards the Pareto optimal front effectively. Through rigorous empirical testing, we have demonstrated the benefits of PICEA-w compared to other leading decomposition based algorithms. The chosen test problems encompass the range of problem geometries likely to be seen in practice, including simultaneous optimisation of up to seven conflicting objectives. The main findings are as follows:

                        
                           (1)
                           PICEA-w is less sensitive to the problem geometry, and outperforms other leading decomposition based algorithms on many-objective problems. Moreover, it is shown that when guiding candidate solution towards the Pareto optimal front, weights also evolve towards the optimal distribution.

The two adaptive weights based decomposition based MOEAs perform well on most of the 2-objective problems. However, their performance is not noticeably outstanding on most of the many-objective problems. This is because that the weights adaptation strategy employed in these algorithms cannot strike an effective balance between exploration and exploitation.

UMOEA (e.g., MOEA/D and MSOPS) faces difficulties on problems having complex Pareto optimal fronts and on many-objective problems. The poor performance of UMOEA is due to a lack of solution diversity. However, UMOEA is found to perform the best in terms of convergence. This could perhaps because the employed weights are kept fixed during the whole search process, which guide candidate solutions towards Pareto optimal front directly.

RMOEA (e.g., HLGA and MOGLS) also faces difficulties on problems having a complex Pareto optimal front. Noticeably, although it performs worse than UMOEA on bi-objective problems, it performs better than UMOEA on many-objective problems. The reason is that, for bi-objective problems, the employed evenly distributed weights are sufficient to describe the entire Pareto optimal front and therefore the diversity performance of UMOEA is not much inferior to RMOEA. However, UMOEA demonstrates a better convergence performance than RMOEA. For many-objective problems, the limited number of weights employed in UMOEA is not sufficient to approximate the entire Pareto optimal front while the use of random weights enables the search to explore different regions of the Pareto optimal front, producing better solution diversity.

The main limitation of this study is that its findings are based on real-parameter function optimisation problems. It is also important to assess the performance of PICEA-w on other problem types, e.g. multi-objective combinatorial problems, and also, crucially, real-world problems. With respect to further research, it is our view that, first, given the superiority of PICEA-w to other decomposition based MOEAs on many-objective problems, it would be valuable to compare PICEA-w against other competitive many-objective optimisers such as HypE and PICEA-g. Also, it would be valuable to investigate the performance of PICEA-w on multi-objective combinatorial problems. Thirdly, the search ability of decomposition based MOEAs is affected by the chosen scalarising function. It would be useful to investigate how to choose a suitable scalarising function for different problems (Ishibuchi et al., 2009). Fourthly, in the current version of PICEA-w, new weight vectors are randomly generated; it would be interesting to see how the performance of PICEA-w would be affected if genetic operators are applied to generate new weights. Lastly, different weights lead to different Pareto optimal solutions: therefore, PICEA-w could be easily extended to incorporate the decision maker’s real preferences during the optimisation process and so to search for solutions that are interest to the decision makers.

@&#ACKNOWLEDGEMENTS@&#

This research was conducted in the Department of Automatic Control and Systems Engineering, The University of Sheffield and the first author is grateful for the facilities and support provided by the University.

Optimal solutions of these eight modified WFG4 problems satisfy the condition below, see Eq. (A.1) (Huband et al., 2006):
                        
                           (A.1)
                           
                              
                                 
                                    
                                       
                                          
                                             x
                                             
                                                i
                                                =
                                                k
                                                +
                                                l
                                                :
                                                n
                                             
                                          
                                          =
                                          2
                                          i
                                          ×
                                          
                                          0.35
                                       
                                    
                                 
                              
                           
                        
                     where n is the number of decision variables and n = k + l, k and l are the position and distance parameters. To obtain an approximation of the Pareto optimal front, we first randomly generate 20,000 optimal solutions for the test problem and compute their objective values. Second, we employ the clustering technique employed in SPEA2 (Zitzler et al., 2002) to select a set of evenly distributed solutions from all the generated solutions.

The Pareto optimal fronts of these problems are shown in Figs. A.15 and A.16 for 2-objective problems, respectively. Additionally, the optimal distribution of weights for each of the problems is also plotted. They are calculated according to the method provided by Giagkiozis et al. (2013a).

@&#REFERENCES@&#


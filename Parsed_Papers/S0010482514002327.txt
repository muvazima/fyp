@&#MAIN-TITLE@&#Automatic exudate detection by fusing multiple active contours and regionwise classification

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We introduce an automatic exudate detection method.


                        
                        
                           
                           We take advantage of several image enhancement methods.


                        
                        
                           
                           We extract the precise contours of exudate candidates by an active contour method.


                        
                        
                           
                           We apply region-wise classifier for labeling of candidates.


                        
                        
                           
                           Our method outperforms several state-of-the-art approaches.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Exudate detection

Active contour method

Region-wise classification

Diabetic retinopathy screening

Contours combination

Multiple pre-processing

@&#ABSTRACT@&#


               
               
                  In this paper, we propose a method for the automatic detection of exudates in digital fundus images. Our approach can be divided into three stages: candidate extraction, precise contour segmentation and the labeling of candidates as true or false exudates. For candidate detection, we borrow a grayscale morphology-based method to identify possible regions containing these bright lesions. Then, to extract the precise boundary of the candidates, we introduce a complex active contour-based method. Namely, to increase the accuracy of segmentation, we extract additional possible contours by taking advantage of the diverse behavior of different pre-processing methods. After selecting an appropriate combination of the extracted contours, a region-wise classifier is applied to remove the false exudate candidates. For this task, we consider several region-based features, and extract an appropriate feature subset to train a Naïve–Bayes classifier optimized further by an adaptive boosting technique. Regarding experimental studies, the method was tested on publicly available databases both to measure the accuracy of the segmentation of exudate regions and to recognize their presence at image-level. In a proper quantitative evaluation on publicly available datasets the proposed approach outperformed several state-of-the-art exudate detector algorithms.
               
            

@&#INTRODUCTION@&#

More than 360 million people suffered from diabetes in 2012 worldwide. The number of the diagnosed cases has grown rapidly in the last few years and this tendency is estimated to continue [1]. Long-term diabetes also affects the eyes, resulting in a disease called diabetic retinopathy (DR). If DR remains undiagnosed or is treated inappropriately, it can lead to loss of vision. Moreover, DR is the most common cause of blindness in the world. However, there exist suitable ways of treatment to slow down this damage of the eyes. Thus, an automatic screening system for DR would have great importance mainly in developing countries, where near 40% of the cases remain undiagnosed. Such a system is useful if it is able to detect the first signs of the disease. Such signs of DR are microaneurysms and exudates. Exudates arise when fluid exudes from tissue due to its injured capillaries. Since the fluid contains protein, cellular debris and white blood cells, exudates appear as yellowish, bright patches on the retinal background. That is, considering intensity differences, exudates can be distinguished more efficiently from the background than microaneurysms from blood vessel segments. On the other hand, the fluid can flow without restrain, so the exudates have various sizes and irregular shape, which makes the automatic detection of exudates challenging as well.

In the corresponding literature, a large number of exudate detection algorithms has been proposed. In general, we can divide these approaches into two main groups. The first group contains algorithms based on grayscale morphology [2–4], while the second one consists of methods considering pixel/region-wise classification [5–9]. Furthermore, we can find some special approaches (e.g. [10–12]) falling out of these groups. Walter et al. [2] proposed a method using morphological closing to eliminate blood vessels, and then the local standard deviation is calculated and thresholded to find the candidate regions. Finally, morphological reconstruction is applied to find the contours of the exudates. Sopharak et al. [3] introduced a technique which is based on optimally adjusted morphological operations. Since the optic disc is also a bright patch, it is eliminated and Otsu׳s algorithm is used for thresholding to locate regions with high intensities. Welfer et al. [4] applied morphological operations and H-maxima transform after contrast enhancement on the channel L in the color space CIE 1976 L*u*v*. Sopharak et al. [5] proposed a method using fuzzy c-means clustering in order to determine whether a pixel belongs to an exudate or not. Then, morphological operations are applied to refine the segmentation result. Sopharak et al. [6] designed an algorithm for exudate detection, which applied pixel-based classification. Namely, a Naïve–Bayes classifier sorts each pixel-based on five extracted features. The method proposed in [7] also considers pixel-based classification, but the training database is defined for each analyzed image separately. That is, the algorithm first detects small isolated exudates and uses those pixels as a positive training set. Then, the rest of the image pixels are classified based on their corresponding properties. Niemeijer et al. [8] proposed a multi-level classification approach for segmentation of pixels which belongs to bright lesions with high probability. These pixels are grouped into clusters and the clusters are labeled as exudates, cotton-wool spots or drusens. Jaafar et al. [10] proposed exudate detection based on a split-and-merge technique. This algorithm splits the images into disjoint regions first, and merges them based on local variance afterwards. Finally, a histogram-based adaptive thresholding is applied to each merged region. Ali et al. [11] proposed an atlas based method to detect exudates. Harangi et al. [12] published an active contour-based method for exudate detection using only the green intensity channel of the image.

In this paper, we propose a method for exudate detection which combines the mainstream approaches (morphology and classification) within a single framework. Our aim is to take advantage of several image enhancement methods for recognizing the precise boundaries of candidates extracted by a morphology-based candidate extractor. The motivation behind this objective is that the features extracted from the precisely segmented regions are more appropriate to differentiate the true exudates from the false ones. So, we recommend the use of several different pre-processing algorithms to extract contour candidates by an active contour method for each preprocessed image. The final exudate contour is found by a combination of these contour candidates. Finally, a region-wise classifier is applied to decide whether the candidates should be considered as exudates or not. The proposed fusion of grayscale morphology and active contour-based segmentation with region-wise classification can outperform several state-of-the-art approaches according to our empirical results.

The rest of the paper is organized as follows. In Section 2, we describe the applied data sets for experimental evaluation. In Section 3, we introduce the algorithm [2] applied for rough candidate extraction, list the involved image pre-processing methods and present our novel methodology. Section 4 is dedicated to our comparative experimental results regarding some other state-of-the-arts exudate detection methods. Finally, some discussions and conclusions are given in Section 5.

We use the publicly available DIARETDB1 – Standard Diabetic Retinopathy Database [13] and the HEI-MED – Hamilton Eye Institute Macular Edema Dataset [14] for our experimental studies. The dataset DIARETDB1 contains 89 fundus images with a 50° Field-of-View (FOV) and resolution of 1500×1152 pixels. 53 images contain exudates based on the labeling of 4 clinical experts. Each expert marked manually the most representative points of the exudates in these images, and the coordinates of these points are stored in text files. Based on these manually-marked anchor points, a local ophthalmologist segmented manually the exudates further in these images. Thus, we have gained 53 binary masks containing the precise exudate boundaries. For feature selection and the training of the region-wise classifier (see Section 3.4 for more details), the dataset DIARETDB1 is divided into training and test part by taking into account the distribution of normal and abnormal images as proposed by Kauppi et al. [13]. The training set consists of 24 images containing exudates and 4 images with no such lesions. The dataset HEI-MED consists of 169 images of resolution 2196×1958 pixels with a 45° FOV, among which 54 images are classified manually by an ophthalmologist as containing exudates. The binary images containing the manually segmented exudates for HEI-MED images are not available, so we use this image set for evaluation at image-level only. For both image sets, the images have been captured from patients belonging to heterogeneous ethnic groups so the datasets do not correspond to any typical population as it is published in [13,14]. Consequently, the retinal pigmentations of these images are quite diverse.

@&#METHODOLOGY@&#

In this section, we introduce our proposed method which combines the advantage of several image pre-processing methods and applies a novel approach for exudate detection using an active contour method (ACM). The candidate extractor technique [2] is based on grayscale morphology and has high sensitivity, since it basically marks every bright region as an exudate. To keep up this high sensitivity, but also increasing the specificity, we try to reduce the number of false positive regions. For this purpose, we exclude the non-exudate regions by region-wise classification and to enhance the accuracy of this classification, we detect the boundaries of the exudates as precisely as possible, since the features used for region-wise classification are based on the contour, shape and composing pixels of the region.

Our method starts with rescaling the images to normalize the resolution to common height of 1500 pixels. Next, a rough candidate extractor is applied to retrieve the possible exudate regions. Because of the high similarity in appearance between the exudates and the optic disc, we exclude the region of the optic disc (OD) from the candidate regions. For the localization of the OD, we apply an ensemble-based method [15]. The main motivation of this approach is to compensate the weaknesses of the different OD detectors with fusing their results. In this way, the performance of the individual OD detectors can be outperformed [15]. The combined result is considered to be the final OD region, which is excluded from the further process of exudate detection. After OD removal, the boundaries of the remaining exudate candidates are used to initialize an ACM. To determine the precise boundaries, the ACM is applied separately on nine disparate enhanced varieties of the input image having different intensity and contrast. Then, the nine extracted boundaries are combined. Finally, some features are extracted from each candidate, and a properly adjusted Naïve–Bayes classifier labels each candidate as exudate or non-exudate. The schematic workflow of the proposed approach is also given in 
                     Fig. 1.

A morphology-based technique for exudate detection given by Walter et al. [2] can extract candidate regions for exudates quite reliably. However, this method works improperly on the retinal images of young patients, where shiny regions spread along the temporal arcade (main vessels). Moreover, the boundaries of the detected exudates are less natural due to the applied structural elements and the method detects several false positives as well. For these reasons, we use the results obtained by [2] only as an initial mask for a more precise detection step.

Walter et al. [2] consider high local contrast and intensity in the green channel of the fundus image as the most important properties of exudates. Since there is also high contrast between the vessels and the background, the method eliminates the vascular system by a simple grayscale morphological closing. On the vessel-free image, the local variation is calculated at each pixel inside a window and the regions with low local variations are excluded. The OD is also eliminated from the image because it is similar to exudates regarding brightness and contrast. The remaining bright regions are excluded from the original image and the holes are filled in by morphological reconstruction. The result looks like a healthy image without bright lesions, so when it is subtracted from the original one, the difference image contains the bright exudate candidates only. Finally, thresholding is performed on the remaining candidates to eliminate false exudate pixels. This algorithm has three parameters: the size of the window (W=11), the contrast threshold (α
                        1=3) and the brightness threshold (α
                        2=8) which were set as proposed by Walter et al. [2]. The boundaries of these extracted regions will be used as initial positions for the active contour segmentation method.

Several papers dealing with digital fundus image processing propose the green channel for image analysis, since it gives the highest contrast between the anatomical parts, lesions and the retinal background. According to this recommendation, we simply extract the green channel G from the RGB fundus image. Moreover, we also consider the channel I from the color space HSI, where I is defined as the average of the red, green and blue channel. In this way, we can keep some relevant information also from the red and blue channels. Besides using the intensity images G and I, we apply seven more pre-processing methods proposed in the literature of fundus imaging focusing mainly on exudate detection [2,4,6,7,10]. The corresponding pre-processing algorithms highlight several typical features of exudates to increase the accuracy of the detection and our aim is to exploit the advantage of all of them. For this reason, an active contour method (see Section 3.3) minimizes the energy function regarding the result of each pre-processing algorithm. The reason of selecting these seven methods [7,16–21] also lies in the fact that they provide larger image contrast compared to others [22–27] and thus have proved to be efficient in combining with ACM. Also note that the selected pre-processing algorithms provide different intensity values inside and outside the contour of the lesions which is necessary, since the ACM method is efficient if these two regions have different average intensities. Thus, some pre-processing methods (e.g. the one based on the Riesz Transfom [29]) cannot be applied here, since they provide nearly zero values at both inside and outside the expected contour. Now, we list the seven included methods.

Chromaticity normalization [16] can normalize the green intensity channel according to the portion of the green among the colors as
                              
                                 (1)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          C
                                          N
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                G
                                             
                                             
                                                o
                                                r
                                                i
                                                g
                                             
                                          
                                       
                                       
                                          
                                             
                                                R
                                             
                                             
                                                o
                                                r
                                                i
                                                g
                                             
                                          
                                          +
                                          
                                             
                                                G
                                             
                                             
                                                o
                                                r
                                                i
                                                g
                                             
                                          
                                          +
                                          
                                             
                                                B
                                             
                                             
                                                o
                                                r
                                                i
                                                g
                                             
                                          
                                       
                                    
                                    ,
                                 
                              
                           where I
                           
                              CN
                            is the resulting intensity channel, and R
                           
                              orig
                           , G
                           
                              orig
                           , B
                           
                              orig
                            are the original intensity channels of the image in the color space RGB respectively. This method is usually applied, when the scene is captured by a camcorder and the illumination of the object is not uniform in a video. In our case, it is suited to reduce the bright reflection of retinal images of young patients.

A robust contrast enhancement method has been proposed by Sanchez et al. [7]. To follow instructions of the authors to enhance the image for further analysis, we convert the RGB image into the color space YIQ and replace the channel Y by the weighted sum of the channels Y, I and Q as
                              
                                 (2)
                                 
                                    
                                       
                                          Y
                                       
                                       
                                          m
                                          o
                                          d
                                       
                                    
                                    =
                                    1.5
                                    Y
                                    +
                                    
                                       (
                                       
                                          −
                                          1
                                       
                                       )
                                    
                                    I
                                    +
                                    
                                       (
                                       
                                          −
                                          1
                                       
                                       )
                                    
                                    Q
                                    .
                                 
                              
                           After this modification, we convert Y
                           
                              mod
                           
                           IQ back to R
                           
                              mod
                           
                           G
                           
                              mod
                           
                           B
                           
                              mod
                           . In the resulting image I
                           
                              CE
                           , the bright regions become brighter, while the dark ones darker.

Contrast-Limited Adaptive Histogram Equalization (CLAHE) [17] improves the contrast of the image locally. The sufficiently high contrast on the fundus image is very important, since besides high intensity, the contrast is another useful feature in exudate detection. After applying CLAHE, the exudates can be better distinguished from the background on the resulting image I
                           
                              CL
                           .

Grey-world normalization [18] divides each color channel by its respective average intensity, so it is suitable to suppress shining along temporal arcades. As the green channel contains the largest amount of information about the lesions and anatomical parts, we consider only the gray world normalization of the green channel as
                              
                                 (3)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          G
                                          N
                                       
                                    
                                    =
                                    
                                       
                                          
                                             
                                                G
                                             
                                             
                                                o
                                                r
                                                i
                                                g
                                             
                                          
                                       
                                       
                                          G
                                          ¯
                                       
                                    
                                    ,
                                 
                              
                           where G
                           
                              orig
                            is the original green intensity channel of the input image, I
                           
                              GN
                            is the resulting intensity channel and 
                              
                                 G
                                 ¯
                              
                            is the average intensity of the green channel respectively.

The illumination is usually non-uniform in retinal images due to the variation of the retinal tissues and the spherical shape of the eye. To suppress non-uniform illumination, we apply illumination correction [19]. To perform this image enhancement technique, a spatially large (90×90) median filter is applied to the input image. To get the corrected image I
                           
                              IC
                           , the blurred image is subtracted from the original one.

Besides illumination correction, we can also simulate uniform illumination by using illumination equalization [20]. The adjusted intensity values are derived for each pixel as
                              
                                 (4)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          I
                                          E
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    =
                                    
                                    
                                       
                                          G
                                       
                                       
                                          o
                                          r
                                          i
                                          g
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                    +
                                    m
                                    −
                                    
                                       
                                          
                                             G
                                             ¯
                                          
                                       
                                       
                                          w
                                       
                                    
                                    (
                                    x
                                    ,
                                    y
                                    )
                                 
                              
                           where G
                           
                              orig
                           (x,y) is the original green intensity value at the position (x,y), m is the desired average intensity (in our case m=128), and 
                              
                                 
                                    
                                       G
                                       ¯
                                    
                                 
                                 
                                    w
                                 
                              
                              (
                              x
                              ,
                              y
                              )
                            is the mean intensity value within a local neighborhood (45×45) of the pixel (x,y) respectively.

White top-hat transformation [21] is a morphological operator designed for extracting bright regions from the image. Since the opening operator realizes an erosion followed by a dilation, the darker regions will suppress the brighter ones on the opened image. When this relatively dark image is subtracted from the original one, the intensity peaks are enhanced and the exudates can be distinguished better from the background on the resulting image I
                           
                              WT
                           .

Our aim is to determine the most precise boundary for each exudate candidate to improve the accuracy of the region-wise classification. To detect the precise boundaries, we propose the application of an active contour method which minimizes the energy function regarding the nine variant G, I, I
                        
                           CN
                        , I
                        
                           GN
                        , I
                        
                           CL
                        , I
                        
                           CE
                        , I
                        
                           IC
                        , I
                        
                           IE
                        , I
                        
                           WT
                         of the input image after which we combine the nine extracted contours.

The traditional active contour model (also known as snake) is not an appropriate tool for exudate boundary detection, since the usually defined complex energy function prefers the high gradients of the image and the smooth curvature of the contour. However, high contrast may be present close to the vessels in fundus images and the curvature of the contour of the exudates varies irregularly. Thus, to overcome these difficulties, we propose the usage of a level-set framework to detect the true boundary of the exudate candidates. This framework considers the 2D contour C as an embedded part of a 3D surface and C is represented as the zero-level-set, where the 3D surface is intersected by the image plane. This approach allows the contour to vary iteratively from pixel to pixel by modifying the 3D surface and the image is divided into separate regions so that the defined energy function is minimized. There are two main drawbacks of level-set methods. Namely, the handling of the 3D surface makes them rather slow, and the definition of the initial contour is also difficult. To reduce the computational time, Whitaker proposed the sparse field method (SFM) [28]. Here, the 3D surface is represented by lists of points L
                           0, L
                           −1, L
                           +1, L
                           −2, L
                           +2,… according to the distance of the points from the intersection image plane, where L
                           0 contains the pixels of the zero-level-set, and L
                           −1
                           /L
                           +1 contains the inner/outer adjacent pixels respectively. The changes of the 3D surface are followed by moving the pixels from/to the appropriate lists. To initialize the zero-level-set, we use the boundary points of the extracted candidates found by the method described in Section 3.1. In this way, the ACM can determine the zero-level-set for the next iteration automatically by minimizing the following Chan-Vese energy function:
                              
                                 (5)
                                 
                                    
                                       
                                          E
                                       
                                       
                                          Chan
                                          -
                                          Vese
                                          
                                       
                                    
                                    =
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                    
                                       (
                                       C
                                       )
                                    
                                    +
                                    
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                    
                                       (
                                       C
                                       )
                                    
                                    .
                                 
                              
                           The energy function (5) is suitable for exudate boundary detection, since it depends only on the difference of the pixel intensities p
                           
                              x,y
                            and the respective average intensities inside (c
                           1) and outside (c
                           2) the contour C as formulated in the following way:
                              
                                 (6)
                                 
                                    
                                    
                                       
                                          F
                                       
                                       
                                          1
                                       
                                    
                                    
                                       (
                                       C
                                       )
                                    
                                    =
                                    
                                    
                                       ∑
                                       
                                          (
                                          x
                                          ,
                                          y
                                          )
                                          ∈
                                          inside
                                          
                                             (
                                             C
                                             )
                                          
                                       
                                    
                                    
                                       
                                          |
                                          
                                             
                                                
                                                   p
                                                
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                             
                                             −
                                             
                                                
                                                   c
                                                
                                                
                                                   1
                                                
                                             
                                          
                                          |
                                       
                                       2
                                    
                                    ,
                                 
                              
                           
                           
                              
                                 (7)
                                 
                                    
                                       
                                          F
                                       
                                       
                                          2
                                       
                                    
                                    
                                       (
                                       C
                                       )
                                    
                                    =
                                    
                                    
                                       ∑
                                       
                                          (
                                          x
                                          ,
                                          y
                                          )
                                          ∈
                                          outside
                                          
                                             (
                                             C
                                             )
                                          
                                       
                                    
                                    
                                       
                                          |
                                          
                                             
                                                
                                                   p
                                                
                                                
                                                   x
                                                   ,
                                                   y
                                                
                                             
                                             −
                                             
                                                
                                                   c
                                                
                                                
                                                   2
                                                
                                             
                                          
                                          |
                                       
                                       2
                                    
                                    .
                                 
                              
                           The energy function (5) takes its minimum, when both the inside and outside regions are the most homogeneous regarding pixel intensities.

As we have described in Section 3.2, besides the intensity channels G and I we consider seven different image pre-processing methods to improve the contrast and the information content of the input image regarding exudates. After extracting G, I, I
                           
                              CN
                           , I
                           
                              GN
                           , I
                           
                              CL
                           , I
                           
                              CE
                           , I
                           
                              IC
                           , I
                           
                              IE
                           , I
                           
                              WT
                            from the input fundus image, the Chan–Vese energy function is evaluated on each of these variants by the ACM. With the energy function, the ACM is applied separately on the nine disparate enhanced images to produce nine different contours B
                           1,…,B
                           9 for each exudate candidate as shown in 
                           Fig. 2. These regions bounded by the contours B
                           1,…,B
                           9 are denoted by R
                           1,…,R
                           9 respectively.

Our next step is to extract a precise boundary for the candidate based on these nine contours/regions. Precise boundary detection has been found to be essential to provide appropriate features for a region-wise classification of true/false candidates. To let the different preprocessors take an effect on the final contour/region of a specific candidate, we fuse the corresponding extracted information in terms of combining the regions R
                           
                              i
                            (i=1,…,9) in the following way. First, we create the union of the regions as 
                              ℛ
                              =
                              
                                 ∪
                                 
                                    i
                                    =
                                    1
                                 
                                 9
                              
                              
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                 
                              
                            and to each pixel 
                              p
                              ϵ
                              ℛ
                            we assign a score as
                              
                                 (8)
                                 
                                    Score
                                    
                                       (
                                       p
                                       )
                                    
                                    =
                                    
                                       |
                                       
                                          {
                                          
                                             i
                                             
                                             :
                                             
                                             p
                                             ϵ
                                             
                                                
                                                   R
                                                
                                                
                                                   i
                                                
                                             
                                             ,
                                             
                                             
                                             i
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             9
                                          
                                          }
                                       
                                       |
                                    
                                    ,
                                 
                              
                           where |.| represents the set cardinality, that is, the number of detected regions R
                           
                              i
                            (i=1,…,9) containing p. If p falls out of all the regions R
                           
                              i
                            it gets score 0, whereas it falls inside all of them, it gets score 9. This assignment leads to nine new regions R′1,…,R′9 as
                              
                                 (9)
                                 
                                    
                                       
                                          R
                                       
                                       
                                          i
                                       
                                       
                                          ′
                                       
                                    
                                    =
                                    
                                       {
                                       
                                          p
                                          ∈
                                          ℛ
                                          
                                          :
                                          
                                          Score
                                          
                                             (
                                             p
                                             )
                                          
                                          ≥
                                          i
                                       
                                       }
                                    
                                    ,
                                    
                                    
                                    
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    9
                                 
                              
                           with R′
                              i
                            consisting of pixels having score greater than or equal to i. Note that, we have R′1⊇R′2⊇… ⊇R′9, with R′1=
                              ℛ
                           . In this way, we merge the nine extracted regions R
                           
                              i
                            (i=1,…,9) and determine nine new regions R′
                              i
                            (i=1,…,9) with their respective boundaries B′
                              i
                            (i=1,…,9). Besides fusing the regions R
                           
                              i
                            (i=1,…,9), we have found that the final region should represent a stable state as well. That is, we select that R′1
                           ,…,R′9 as the final region, which is the most similar to its neighbors R′
                              i−1 and R′
                              i+1 regarding the fusion. As extreme, less meaningful cases, 
                              
                                 
                                    R
                                 
                                 
                                    1
                                 
                                 
                                    ′
                                 
                              
                              =
                              
                                 ∪
                                 
                                    i
                                    =
                                    1
                                 
                                 9
                              
                              
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                              
                            and 
                              
                                 
                                    R
                                 
                                 
                                    9
                                 
                                 
                                    ′
                                 
                              
                              =
                              
                                 ∩
                                 
                                    i
                                    =
                                    1
                                 
                                 9
                              
                              
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                              
                            are excluded from this analysis. For a precise formulation of this process, we measure the similarities between two adjacent regions by computing their symmetric difference as
                              
                                 (10)
                                 
                                    d
                                    
                                       (
                                       
                                          
                                             
                                                R
                                             
                                             
                                                i
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                R
                                             
                                             
                                                i
                                                +
                                                1
                                             
                                             
                                                ′
                                             
                                          
                                       
                                       )
                                    
                                    =
                                    
                                       
                                          |
                                          
                                             
                                                (
                                                
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         i
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∪
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         i
                                                         +
                                                         1
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                                )
                                             
                                             \
                                             
                                                (
                                                
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         i
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                   ∩
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         i
                                                         +
                                                         1
                                                      
                                                      
                                                         ′
                                                      
                                                   
                                                
                                                )
                                             
                                          
                                          |
                                       
                                       
                                          |
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   i
                                                
                                                
                                                   ′
                                                
                                             
                                          
                                          |
                                       
                                    
                                    ,
                                    
                                    i
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    8
                                    ,
                                 
                              
                           where \ denotes the set difference operator. The denominator 
                              |
                              
                                 
                                    
                                       R
                                    
                                    
                                       i
                                    
                                    
                                       ′
                                    
                                 
                              
                              |
                            in (10) is applied for scale-invariance. According to our experimental results, that R′
                              F
                            with 
                              F
                              ∈
                              {
                              2
                              ,
                              …
                              ,
                              8
                              }
                            should be selected as the final exudate region for which
                              
                                 (11)
                                 
                                    d
                                    
                                       (
                                       
                                          
                                             
                                                R
                                             
                                             
                                                F
                                                −
                                                1
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                R
                                             
                                             
                                                F
                                             
                                             
                                                ′
                                             
                                          
                                       
                                       )
                                    
                                    +
                                    
                                    d
                                    
                                       (
                                       
                                          
                                             
                                                R
                                             
                                             
                                                F
                                             
                                             
                                                ′
                                             
                                          
                                          ,
                                          
                                             
                                                R
                                             
                                             
                                                F
                                                +
                                                1
                                             
                                             
                                                ′
                                             
                                          
                                       
                                       )
                                    
                                    =
                                    
                                       
                                          min
                                       
                                       
                                          i
                                          =
                                          2
                                          ,
                                          …
                                          ,
                                          8
                                       
                                    
                                    
                                       (
                                       
                                          d
                                          
                                             (
                                             
                                                
                                                   
                                                      R
                                                   
                                                   
                                                      i
                                                      −
                                                      1
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                ,
                                                
                                                   
                                                      R
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      ′
                                                   
                                                
                                             
                                             )
                                          
                                          +
                                          
                                          d
                                          
                                             (
                                             
                                                
                                                   
                                                      R
                                                   
                                                   
                                                      i
                                                   
                                                   
                                                      ′
                                                   
                                                
                                                ,
                                                
                                                   
                                                      R
                                                   
                                                   
                                                      i
                                                      +
                                                      1
                                                   
                                                   
                                                      ′
                                                   
                                                
                                             
                                             )
                                          
                                       
                                       )
                                    
                                    .
                                    
                                 
                              
                           
                        

This procedure is performed for each candidate separately to have the set of the candidates with precisely detected contours. Naturally, some candidates are not true exudates, but we determine the best fitted boundary for each candidate individually to improve the accuracy of the region-wise classification. An example for this procedure is also shown in 
                           Fig. 3 where the measured similarities are also included.

As we have mentioned in Section 3.1, the method used for candidate extraction has high sensitivity, since it finds almost all exudates in the input image. At the same time, it marks each bright region (mainly the ones are close to vessels on retinal images of youngsters) as exudate which leads to many false positive hits. If we consider all these candidates as the result of detection of exudates, the specificity of the automatic screening system drops. To exclude the false positive candidates besides keeping up high sensitivity, we propose a region-wise classification step which labels each candidate region as exudate or non-exudate. This step can be considered as a post-processing step, where each candidate region with precisely detected boundary is classified by an optimally adjusted Naïve–Bayes classifier based on region-based features.

For this region-wise classification, we extract descriptors from each exudate candidate found by the candidate extractor method [2]. These descriptors are based on the respective intensity values of pixels composing the properly detected candidate and are calculated from the morphological behavior (shape) of the precisely detected region and its boundary. In this way, for candidate classification initially we consider 106 region-wise descriptors listed in 
                        Table 1.

In Table 1, we have enclosed all the descriptors extracted from the candidate regions of a training dataset regardless of their classification performance, so it contains such descriptors that are less efficient for this task. To select the meaningful features for classification, we evaluated their corresponding performance by two-sample t-tests. We note that, we tested some commonly used classifiers (Naïve–Bayes, k-Nearest Neighbors) with several feature selection methods like PCA, relative entropy, minimum attainable classification error, ROC analysis, Wilcoxon test, etc. based on class separability criteria. We found the Naïve–Bayes classifier and the two-sample t-test as the most efficient for our case. Namely, the Naïve–Bayes classifier reached the highest Accuracy value (84.37%) when it used features selected by two-sample t-test for labeling. For the sake of completeness, we list the highest Accuracy values of Naïve–Bayes, when it used features selected by other methods. The following feature selection methods are included (with highest Accuracy is also indicated): PCA (80.38%), minimum attainable classification error (Bhattacharyya) (80.44%), relative entropy (80.51%), ROC analysis (81.09%) and Wilcoxon test (81.61%). Now we give the proper description of feature selection based on two-sample t-test.

To rank the descriptors based on their performance obtained by the two-sample t-test, we used 28 training images from the dataset DIARETDB1. These images were considered as input to the candidate extractor method. Then, we generated the nine different preprocessed images, finally determined the precise boundary for each candidate by the proposed boundary detection algorithm. The output binary images contained exudate candidates (1239 regions) with precise boundary and we labeled manually the candidates as true exudates (955 true positive) or not (284 false positive) according to the manually segmented binary images described in Section 2. Based on this labeling, the t-test can be performed for each descriptor given in Table 1 according to the following formula:
                           
                              (12)
                              
                                 
                                    
                                       t
                                    
                                    
                                       j
                                    
                                 
                                 =
                                 
                                    
                                       (
                                       
                                          
                                             μ
                                          
                                          
                                             
                                                
                                                   j
                                                
                                                
                                                   F
                                                
                                             
                                          
                                       
                                       −
                                       
                                          
                                             μ
                                          
                                          
                                             
                                                
                                                   j
                                                
                                                
                                                   T
                                                
                                             
                                          
                                       
                                       )
                                       
                                          
                                             n
                                             m
                                             (
                                             n
                                             +
                                             m
                                             −
                                             2
                                             )
                                             /
                                             (
                                             n
                                             +
                                             m
                                             )
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                (
                                                
                                                   n
                                                   −
                                                   1
                                                
                                                )
                                             
                                             
                                                
                                                   σ
                                                
                                                
                                                   
                                                      
                                                         j
                                                      
                                                      
                                                         F
                                                      
                                                   
                                                
                                                
                                                   2
                                                
                                             
                                             +
                                             (
                                             m
                                             −
                                             1
                                             )
                                             
                                                
                                                   σ
                                                
                                                
                                                   
                                                      
                                                         j
                                                      
                                                      
                                                         T
                                                      
                                                   
                                                
                                                
                                                   2
                                                
                                             
                                          
                                       
                                    
                                 
                                 ,
                              
                           
                        where t
                        
                           j
                         denotes the performance of the j-th descriptor, 
                           n
                         is the number of the true exudate regions (955) and 
                           m
                         is the number of the false ones (284) considering the whole set of the candidates for the training set. 
                           
                              
                                 μ
                              
                              
                                 
                                    
                                       j
                                    
                                    
                                       T
                                    
                                 
                              
                           
                         (resp. 
                           
                              
                                 μ
                              
                              
                                 
                                    
                                       j
                                    
                                    
                                       F
                                    
                                 
                              
                           
                        ) denotes the mean, while 
                           
                              
                                 σ
                              
                              
                                 
                                    
                                       j
                                    
                                    
                                       T
                                    
                                 
                              
                           
                         (resp. 
                           
                              
                                 σ
                              
                              
                                 
                                    
                                       j
                                    
                                    
                                       F
                                    
                                 
                              
                           
                        ) denotes the standard deviation of the j-th descriptor of all true (
                           resp
                           .
                           
                         false) exudates respectively.

To find the meaningful descriptors, we ranked them based on their performance values t
                        
                           j
                        , and tried to find those k descriptors which provided highest accuracy. For this aim, we divided the set of 1239 manually labeled regions extracted from 28 training images into training and test sets. Then, a Naïve–Bayes classifier was trained on the first k (k=1,…,106) region-wise features extracted from the training regions. Next, we observed the performance of the classifier on the test regions using these k features. We found that the Naïve–Bayes classifier reached the highest Accuracy value (derived from the number of true positive, true negative, false positive, and false negative cases), when the first k=29 descriptors (see them in 
                        Table 2) were selected from the ranked list as features (see 
                        Fig. 4(a)). For this evaluation, we separated the regions into a training and test set by K-fold cross validation (K=10) and evaluated the performance of the classifier for a given feature set at 10 times. For the sake of completeness, the accuracies of different combination of classifiers (Naïve–Bayes, k-Nearest Neighbors) and feature selection methods regarding the numbers of features can be seen in Fig. 4(a) and (b). These empirical results also serve as further proof for our former claim that the applied ACM method is an appropriate tool for the detection of the irregularly variable contours of the exudates. As it can be observed in Fig. 4(c)–(f), the accuracies of classifiers decrease if the exudate candidates are extracted by Gradient Vector Flow (GVF) [30] or Markovian Segmentation Model (MRF) [31].

The simple Naïve–Bayes classifier reaches relatively high accuracy regarding the correct labeling of the exudate candidates using the selected 29 features. As for implementation, the built-in Matlab R2010b class of Naïve–Bayes [32] is used. To increase further the performance of the Naïve–Bayes classifier, we apply the adaptive boosting (AdaBoost) technique [33]. To realize the idea that the performance of ensemble learning is usually better than single learning, to set up an ensemble of classifiers, the training data set is separated into two disjoint sets T
                        1 and T
                        2. The first classifier learns on T
                        1 and classifies the elements of T
                        2. In the next turn, the new classifier is trained on mainly the previously misclassified elements to teach it for the instances that are hard to classify, and so on. Finally, these classifiers make a decision about a label of a new instance by weighted majority voting, where the weights come from the individual accuracies of the classifier. In this way, an ensemble of several Naïve-Bayes classifiers can achieve 10% higher accuracy in labeling the candidates as exudates or non-exudates in our framework.

@&#RESULTS@&#

We evaluated our proposed exudate detection method on the test part of the dataset DIARETDB1 and on the whole dataset HEI-MED. The accuracy of the proposed method was evaluated at both image and lesion-level as described next.

The test part of DIARETDB1 includes 29 (from 61) and HEI-MED 54 (from 169) images which contain exudates according to the publicly available annotation of clinical experts. Based on this knowledge, we measured the performance of the proposed method first at image-level. Namely, we considered the classification result for an image as a true positive (resp. true negative) if the input image contained (resp. did not contain) exudates according to both our proposed method and the ground-truth. We had a false positive, when the proposed method recognized bright regions of the input image as exudates, though based on the ground-truth no exudates were labeled manually. We had a false negative in the reversed case. Based on the true/false positive/negative cases, we calculated Sensitivity (also known as true positive rate), Specificity (also known as true negative rate which equals to 1-false positive rate) and Accuracy as follows:
                           
                              (13)
                              
                                 A
                                 c
                                 c
                                 u
                                 r
                                 a
                                 c
                                 y
                                 =
                                 
                                    
                                       #
                                       
                                       o
                                       f
                                       
                                       t
                                       r
                                       u
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                       s
                                       +
                                       #
                                       
                                       o
                                       f
                                       
                                       t
                                       r
                                       u
                                       e
                                       
                                       n
                                       e
                                       g
                                       a
                                       t
                                       i
                                       v
                                       e
                                       s
                                    
                                    
                                       #
                                       
                                       o
                                       f
                                       
                                       t
                                       r
                                       u
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                       s
                                       +
                                       #
                                       
                                       o
                                       f
                                       
                                       f
                                       a
                                       l
                                       s
                                       e
                                       
                                       n
                                       e
                                       g
                                       a
                                       t
                                       i
                                       v
                                       e
                                       s
                                       +
                                       #
                                       
                                       o
                                       f
                                       
                                       f
                                       a
                                       l
                                       s
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                       s
                                       +
                                       #
                                       
                                       o
                                       f
                                       
                                       t
                                       r
                                       u
                                       e
                                       
                                       n
                                       e
                                       g
                                       a
                                       t
                                       i
                                       v
                                       e
                                       s
                                    
                                 
                              
                           
                        to measure the performance at image-level.

Based on these measures, we were able to compare our method with some other state-of-the-art exudate detector algorithms quantitatively. As we can see in 
                        
                        Tables 3 and 4, in these tests the proposed algorithm (set in bold) outperformed the algorithms [2–7,10] involved in our comparative study with respect to the Accuracy value. Note that, Accuracy can also be derived from Sensitivity and Specificity, so Accuracy is high if and only if both Sensitivity and Specificity are large. For the sake of completeness, Tables 3 and 4 also include the results of our proposed region-wise classification method without precise boundary detection. In this case, the ACM detected the exudates based only on the green intensity channel. Note that, we obtained similar results when only a single preprocessing method was applied instead of extraction of the green channel to the input image before contour detection. Moreover, it can be observed the application of all the nine pre-processing methods simultaneously and the detection of the precise boundary of the candidates leads to a meaningful improvement in region-wise classification as well.

For the sake of the completeness, we also enclose the receiver operating characteristics (ROC) of the proposed method to demonstrate its robustness at image level on the datasets DIARETDB1 and HEI-MED (see 
                        Fig. 5). To create the ROC curve, we applied different threshold levels for the weighted majority voting result of the boosted Naïve–Bayes classifiers to accept exudate candidates as true ones. As in [3–6,10] the authors did not define an adjustable parameter, a complete ROC analysis cannot take place for them. Instead, we indicate only their single available (Sensitivity, 1-Specificity) figures in Fig. 5. However, a full comparative ROC analysis with [2,7] and the proposed method without precise boundary detection is included in the figure. The competitiveness of the proposed method can be observed regarding ROC analysis as well.

We also show the accuracy of our proposed method regarding the precise detection of the exudates. For this evaluation, we used such 53 binary images as ground-truth which were created manually by a local eye specialist based on the rough labeling of four experts defining the ground-truth for DIARETDB1.

For the comparison of a ground-truth binary image R
                        
                           m
                         with a segmentation result R
                        
                           s
                         of a detector, Walter et al. [2] proposed the following true positive, false negative and false positive figures:
                           
                              (14)
                              
                                 t
                                 r
                                 u
                                 e
                                 
                                 p
                                 o
                                 s
                                 i
                                 t
                                 i
                                 v
                                 e
                                 =
                                 
                                 
                                    |
                                    
                                       
                                          
                                             R
                                          
                                          
                                             m
                                          
                                       
                                       ∩
                                       
                                          
                                             R
                                          
                                          
                                             s
                                          
                                       
                                    
                                    |
                                 
                                 ,
                              
                           
                        
                        
                           
                              (15)
                              
                                 f
                                 a
                                 l
                                 s
                                 e
                                 
                                 n
                                 e
                                 g
                                 a
                                 t
                                 i
                                 v
                                 e
                                 =
                                 
                                 
                                    |
                                    
                                       
                                          
                                             R
                                          
                                          
                                             m
                                          
                                       
                                       \
                                       
                                          (
                                          
                                             
                                                
                                                   R
                                                
                                                
                                                   m
                                                
                                             
                                             ∩
                                             
                                                (
                                                
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         s
                                                      
                                                   
                                                   ⊕
                                                   B
                                                
                                                )
                                             
                                          
                                          )
                                       
                                    
                                    |
                                 
                                 ,
                              
                           
                        
                        
                           
                              (16)
                              
                                 f
                                 a
                                 l
                                 s
                                 e
                                 
                                 p
                                 o
                                 s
                                 i
                                 t
                                 i
                                 v
                                 e
                                 =
                                 
                                 
                                    |
                                    
                                       
                                          
                                             R
                                          
                                          
                                             s
                                          
                                       
                                       \
                                       
                                       
                                          (
                                          
                                             
                                                (
                                                
                                                   
                                                      
                                                         R
                                                      
                                                      
                                                         m
                                                      
                                                   
                                                   ⊕
                                                   B
                                                
                                                )
                                             
                                             ∩
                                             
                                                
                                                   R
                                                
                                                
                                                   s
                                                
                                             
                                          
                                          )
                                       
                                    
                                    |
                                 
                                 ,
                              
                           
                        where ⊕B is a morphological dilation executed with a 3×3 structuring element B. Based on these definitions, we considered Sensitivity and Positive Predicted Value (PPV) to calculate the F-Score for performance measurement at lesion-level as
                           
                              (17)
                              
                                 P
                                 P
                                 V
                                 =
                                 
                                 
                                    
                                       t
                                       r
                                       u
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                    
                                    
                                       t
                                       r
                                       u
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                       +
                                       f
                                       a
                                       l
                                       s
                                       e
                                       
                                       p
                                       o
                                       s
                                       i
                                       t
                                       i
                                       v
                                       e
                                    
                                 
                                 ,
                              
                           
                        
                        
                           
                              (18)
                              
                                 F
                                 -
                                 S
                                 c
                                 o
                                 r
                                 e
                                 =
                                 
                                    
                                       2
                                       ×
                                       S
                                       e
                                       n
                                       s
                                       i
                                       t
                                       i
                                       v
                                       i
                                       t
                                       y
                                       ×
                                       P
                                       P
                                       V
                                    
                                    
                                       S
                                       e
                                       n
                                       s
                                       i
                                       t
                                       i
                                       v
                                       i
                                       t
                                       y
                                       +
                                       P
                                       P
                                       V
                                    
                                 
                                 .
                              
                           
                        
                     

As a comparative study, in 
                        Table 5 we have enclosed the performance of the algorithms [2–6] and also the result of exudate segmentation by applying ACM on the green channel without any pre-processing and contour combination. It can be seen that the proposed approach considering the combination of ACM outputs outperformed the simple contour detection and all the other algorithms at lesion-level considering F-Score. Note that, F-Score is the most important performance measure in our case, since it is high if and only if both Sensitivity and PPV are large (see also (18)). The algorithms given in [7,10] are not involved in this lesion-level comparison, since they were not optimized for precise exudate boundary detection. The low accuracy figures for some algorithms may come from the fact that they were tested on smaller databases with images having low resolution.

For the sake of completeness, 
                        Fig. 6 demonstrates the differences between the results of the proposed algorithm and the state-of-the-art methods involved in our comparative study. Fig. 6 includes the final outputs of [2–7,10] and the proposed method for a sample image containing both hard and soft exudates.

In 
                        Fig. 7, we show some detection results obtained by the proposed algorithm for images having different intensity appearance. See Appendix A for visual comparison between the result of the proposed method and the final output of [2–7,10] on these images with different intensity behavior. As it can be observed in these sample images, our approach detect basically all the exudates that consist of bright pixels and have irregular, sharp border. In 
                        Fig. 8, we also demonstrate the performance of the proposed algorithm for the detection of other, more expanded bright lesions like drusens and cotton wool spots. Since the candidate extraction step locates all the bright regions, we can initialize the proposed precise boundary segmentation method with them. It makes the region-wise classifier to identify these lesions as exudates if they share sufficiently many from the considered features. As it can be seen in Fig. 8, the algorithm works well till the point, when the sharp edges of the lesion start to disappear and the features of the detected regions become more different from those of the exudates (e.g. number of holes, edge properties). This consideration suggests that with a different feature set our framework might be tuned also for the detection of other bright lesions besides exudates. However, we have not performed quantitative analysis for drusens and cotton wool spots, since corresponding manual annotation are hardly available publicly at the moment.

The detection of the precise boundaries of exudates is less important in clinical practice, but improves the correct labeling of the candidates. As it can be seen in 
                        Fig. 9, when we use only the green channel for ACM, some candidates disappear and thus, the classifier is not able to label them. Moreover, several descriptive features can be extracted from the precisely detected regions, so the classifier can distinguish the true and false exudates better.

@&#DISCUSSION AND CONCLUSION@&#

In this paper, we have presented a novel exudate segmentation approach which is based on the combination of grayscale morphology, active contour method and region-wise classification. The result of a grayscale morphology-based exudate detection method is considered as the initial mask for the active contour method. We apply sparse field algorithm as a level-set-method to minimize the Chan–Vese energy function. Nine different image enhancement results are involved for minimizing the energy function, and from the extracted nine regions we select the most appropriate one. The proposed exudate segmentation method finds the contours more precisely and reduces the number of false positive pixels and improves the reliability of the region based features. The exudate candidates are labeled as exudate or non-exudate through a region-wise classification step. For this task, we extract carefully selected descriptors for each candidate. For feature selection, we used a two-sample t-test, while for classification the Naïve–Bayes classifier is optimized by AdaBoost.

Considering the image-level accuracy, our proposed method achieved Accuracy values 86% and 80% on the publicly available datasets DIARETDB1 and HEI-MED respectively. With these results, the proposed technique gained higher accuracy in comparison to several other state-of-the-art approaches.

The proposed approach is dedicated to the detection of bright lesions caused by diabetic retinopathy, especially for exudates. That is, the selected pre-processing methods enhance the contrast between the bright lesions and their dark background. The candidate extractor method finds the regions which might contain these bright lesions, while the forthcoming region-wise classifier is trained to select the bright patches with irregular contours as exudates. Naturally, if we change the components of the approach appropriately, it could be applied also for the segmentation of expanded dark lesions like hemorrhages with some examples shown in 
                     Fig. 10. That is, a future attempt can be to find the necessary modifications to specialize our approach also for the detection of dark retinal lesions.

According to Abramoff et al. [34], such screening algorithms cannot be recommended for clinical practice. However, our proposed methodology with high Accuracy at image-level can be applicable as part of a complex system to make decision about additional investigation of the patient. Also note that, the precise boundary detection has an implicitly important influence on clinical practice with through increasing image-level accuracy.

The presented method was implemented in Matlab, and we used a single core 2.4GHz CPU with 2GB memory for testing. The precise boundary for each candidate is extracted using sequential computations. Moreover, the applied candidate extractor algorithm provides a large number of candidates. These are the reasons for the currently relatively high computational time 31 seconds per image, which could be drastically decreased e.g. with parallel implementation. For the sake of completeness, we enclose the computational times of the re-implemented algorithms, which are involved in our comparative studies: Sopharak et al. [3] – 6.63s, Sánchez et al. [7] – 27s, Welfer et al. [4] – 9.75s, Sopharak et al. [5] – 86s, Walter et al. [2] – 6.42s, Sopharak et al. [6] – 17s, Jaafar et al. [10] – 12s. These times do not include the optic disc detection step.

None declared.

@&#ACKNOWLEDGMENT@&#

This work was partly supported by the project DRSCREEN – Developing a computer based image processing system for diabetic retinopathy screening of the National Office for Research and Technology of Hungary (Contract nos. OM-00194/2008, OM-00195/2008, OM-00196/2008) and by the European Union and the State of Hungary, co-financed by the European Social Fund in the framework of TÁMOP-4.2.4.A/ 2-11/1-2012-0001 ‘National Excellence Program’.

See Figs. 
                     
                     
                     A1–A3.

@&#REFERENCES@&#


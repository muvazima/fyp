@&#MAIN-TITLE@&#Handwriting recognition of digits, signs, and numerical strings in Persian

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Introduction of a new database (PHOND) for handwriting Recognition of Digits, Signs etc. in Persian.


                        
                        
                           
                           Presentation of a modified framing feature for handwriting Recognition.


                        
                        
                           
                           Recognition of digits, signs, and numerical strings in Persian using PHOND and other databases.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Optical character recognition

Persian handwritten database

Handwritten digits and signs

Multi-digit numbers

Numerical strings

@&#ABSTRACT@&#


               Graphical abstract
               
                  
                     
                        
                           Image, graphical abstract
                           
                        
                     
                  
               
            

@&#INTRODUCTION@&#

Nowadays, recognition systems are used in many fields that have different natures. Optical Character Recognition (OCR) was started from the recognition of machine printed digits and characters. Afterward, it was developed for the recognition of machine printed words. Gradually, handwritten digit, character and word recognition were introduced into this domain. Several research works have been focusing towards evolving the newer techniques that would reduce the preprocessing time and provide higher recognition accuracy [1].

A handwritten character recognition system may be classified as on-line or off-line system. In offline character recognition system, the document is first generated, digitized, stored in the computer and then it is processed. In case of online character recognition system, character is processed during the creation. External factors like pressure, speed of writing, stroke making and etc. do not have any influences in case of offline system, but they have great impact on the online system.

Recognition of handwritten characters is one of the most interesting topics in pattern recognition. Applications of OCR are in different areas, especially digit recognition, which deals with postal mail sorting, bank check processing, form data entry, vehicle plate recognition, postal address block detection and recognition, camera OCR etc. [1].

English, Chinese, and Kanji handwritten number recognition have been a focus of study for a long time and high recognition rates are reported. Persian language is spoken by more than 110 million people, mainly in Iran, Afghanistan, Tajikistan, and partly in some other countries [2]. There are also other languages, which use the same alphabets and digits or subsets of them such as Arabic, Urdu, and Pashto.

In Persian language, words, sentences, and dates are written from right to left, but numbers are written from left to right, which match the style of writing numbers in English language. Ten digits in Persian language are shown in Fig. 1
                     . Digits 4 and 6 can be written in two different shapes. Considering these facts, it is crucial to have a standard database in order to improve research on Persian handwritten digit and number recognition.

Standard databases play vital roles in pattern recognition tasks. To compare the different algorithms and select the best one, they must be examined using a same database. Only the results obtained from the standard databases can be reliable and useful for evaluating the performance of various approaches. Consequently, standard databases can strongly provide advancement in OCR research works.

In the last few decades, numerous methods have been proposed for machine recognition of handwritten characters, especially for the more popular languages such as English [3,4], Japanese [5,6], and Chinese [6,7]. The number of countries with the English language is not small. However, some of the researchers in other countries also are working on the English handwritten datasets. Therefore, after a on face searching, it seems that the recognition of Latin numeral characters has attracted much attention [7,8,9]. Because it is a handy case for testing various techniques (preprocessing, feature extraction, and classification) and it has many applications (postal mail sorting, check reading, form processing, etc.). So far, many effective recognition methods have been proposed and high accuracies up to 99% on some handwritten digit databases have been reported [4,10].

For the recognition of Persian (Arabic) handwritten digits, several works have been reported and few ones like [11,12] have investigated the handwritten number recognition. A lot of data such as addresses are written on envelopes; amount are written on checks; names, addresses, identity numbers, and Rial (Currency of Iran) values are written on invoices and forms by hand and these had to be entered into the computer for processing.

This paper introduces a database that named PHOND, Persian Handwritten Optical Numbers & Digits. PHOND is a new standard database for offline handwritten Persian (Arabic) digits, signs, numerical strings, courtesy amounts, and postal codes. It is suitable for using in optical number recognition research works. Furthermore, PHOND can be employed in recognition of numbers in other languages such as Urdu, Kurd, and Arabic. These languages use the same digits and signs in writing.

In addition, in this paper, toward the number recognition, numeral images are segmented to digits and then our modified framing feature is extracted from the digits. For extracting the modified framing feature, a digit image is divided into some frames and for each frame, average distance, average angle and outer profiles are calculated. Experimental results illustrate that our proposed modified framing feature results higher recognition rate up to ≈ 99% compared to the previous methods.

Different experiments are done using PHOND and previous handwritten databases and the results are compared with other research works about handwritten recognition.

The organization of this paper is as follows: Related work in Handwritten Recognition is described in Section 2. Section 3 covers the related databases to this paper. In Section 4, PHOND is introduced and the way of data collection to provide it is described. In Section 5, comparison between our new database, PHOND and other databases is provided. Section 6 describes our method for handwritten number recognition. Some experiments have been done on PHOND and previous databases and the results have been shown in Section 7. Finally, conclusions and future work are presented in Section 8.

@&#RELATED WORK@&#

Soltanzadeh et al. [13] developed a technique that uses four views based on the structural features of the digits. It transforms the Arabic/Persian digits into four one-dimensional features based on top, bottom, left, and right views. These views represented the number of white pixels from the side of the view to the boundary of the digit. In this research, Support Vector Machines (SVM) and Multilayer Perceptron (MLP) neural network were used for classification and Arabic check database of CENPARMI was used to report the results. Digits were normalized to 64 × 64 pixels before the feature extraction stage and recognition rates of 94.14% and 91.25% were reported using SVM and MLP, respectively. For handwritten Farsi numeral recognition, Soltanzadeh et al. [14] extract features from the outer profiles, crossing counts and projection histograms [14]. The resulted 64-dimentional feature vector is classified using one-versus-all SVM classifiers, with polynomial and radial basis function (RBF) kernels, respectively. Using 4974 samples for training and 3939 samples for testing, they obtained accuracies of 99.44% (polynomial kernel) and 99.57% (RBF kernel).

Solimanpour et al. in [15] tested the method of [14] on the Farsi handwriting database of CENPARMI. The database has 11,000 Farsi numeral samples for training, 2000 samples for verifying, and 5000 samples for testing. Using the verifying data for selecting kernel parameters for SVM classifier, they obtained a test accuracy of 97.32%. This lower accuracy indicates that the samples in CENPARMI database are more challenging than those, which are presented in [14].

Javidi et al. [7] presented a method to combine multiple classifiers based on a static structure. This method established based on decision templates (DT). They do not only rely on the similarity between a test sample x and c decision template matrices. Moreover, to make a decision about pattern x they construct q wrong decision templates, and compute likeness between pattern x and these matrices. They call this Wrong Decision Templates (WDT). To evaluate this model, HODA Persian handwritten digit database is used and the constructing WDT matrices besides DT matrices, improve the performance of the conventional DT for Farsi handwritten digit recognition, such that the recognition rate of 98.16% is achieved. Alirezanejad et al. [16] proposed a method to extract the framing features of a one-number Persian image in which for the final verification of the extracted features, a three-layer neural network (mesh) of Perceptron has been utilized. This method extracts some ideal features from a one-number image that are stable against rotation, movement, size change, and noise. Finally, the recognition rate of 92.7% is achieved. Sadri et al. [17] presented a system for segmentation and recognition of handwritten Persian bank checks. Their focus in this paper is on segmentation and recognition of handwritten courtesy amounts and dates of Persian checks. They present the results of their tests on different levels of check fields include isolated digits, courtesy amounts, and dates.

In [18], the Persian digit images are represented by line segments, which are used to model and recognize the digits. Additional features and classifiers are needed for discriminating the digit pairs ‘‘0–5’’, ‘‘7–8’’, and ‘‘4–6’’. Said et al. [18] fed the pixels of the normalized digit image as is into a neural network for classification, where the number of the hidden units for the neural network classifier is determined dynamically.

Recently some research works addressed the recognition of Arabic (Indian) and Persian numerals. Researchers in these publications used their own data. In [19], angle, ring, horizontal, and vertical span features were used with a left-to-right Hidden Markov Model (HMM). Salah et al. [20] developed a serial model for visual digit classification based on the primitive selective attention mechanism. The technique was based on parallel scanning of a down-sampled image to find interesting locations through a saliency map, and by extracting key features at high resolution.

Bernoulli mixture models [21] were used to model binary representations of Arabic (Indian) digits using maximum likelihood estimation for digit classification. The digits were preprocessed by pasting each digit onto a white square background whose center was aligned with the digit center of mass. Then each digit was sub-sampled into a smaller square of pixels from which the binary vector was extracted. Different sizes of sub-sampled squares were tested by using the Bernoulli mixture classifier. A sub-sampling value of 20 was considered appropriate for the task. The paper presented a graph with an error rate of ≈2.5% when using the CENPARMI database.

The authors in [22] mapped a digit image to a 12-segment pattern. The ratio of the black pixels in each segment to the black pixels of the digit was taken as the feature for that segment. Two cascaded MLP neural networks were used, the first to identify the control points of the digit, and the second to recognize the digit. The authors reported recognition rate of 97.6% for their own data set.

Mozaffari et al. [23] used structural decomposition of the Farsi/Arabic digits where the skeleton of the digit was extracted and decomposed into primitives. Terminal and intersection points were the commonly used features in that approach. Changes in the average and variance of the X and Y coordinates of each primitive were used to form the feature vector. To increase the accuracy, the algorithm was applied to each quadrant of the digit, resulted in a vector of 32 features (i.e. 8 features per quadrant). Recognition rate of 94.44% was reported.

The research of [24] explains that expanding the training set for handwriting recognition can be beneficial even when the added data is synthesized from the original training data. The recognition rate was improved due to its handwriting synthesis system.

In [25] a prototype generation technique is proposed for handwriting digit recognition. An evolutionary approach is used for improving prototype-based classification. Prototype synthesis is employed to build a reduced training set. Experimental tests on the MNIST dataset demonstrated that this technique represents a good trade-off among accuracy, classification speed and robustness to handwriting style changes.

A recognizer for hand-drawn mathematical expressions is proposed in [26]. It identifies multiple interpretations of the input based on output of lower-level classifiers. The Bayesian probabilistic model is used for scoring and comparing recognized parse trees.

Many databases for handwritten recognition have been gathered and used in various languages and applications.

CENPARMI
                        1
                     
                     
                        1
                        Center of Pattern Recognition and Machine Intelligence.
                      digit database [27] is available from Concordia University. It contains 6000 digits collected from the envelop images of USPS
                        2
                     
                     
                        2
                        United States Postal Service.
                     . In this database, 4000 images, 400 samples per class, are specified for training and the remaining 2000 images are considered for the test set.

CENPARMI Arabic check database [28] is extracted from real Arabic bank checks. The database includes Arabic digits, legal and courtesy amounts. This database consists of 7390 isolated digits for training and 3035 digits for testing.

In CENPARMI Persian numeral database [14], each of 10 classes has 1100 samples for training, 200 samples for verifying, and 500 samples for testing.

MNIST, which is a modified version of the NIST
                        3
                     
                     
                        3
                        National Institute of Standards and Technology.
                      database [29] was extracted from the NIST databases SD3 and SD7. The training and test sets are composed from both SD3 and SD7 databases. Samples are normalized into 20×20 grayscale images and the aspect ratio is reserved. Then the normalized images are located in a 28×28 frame. Numbers of training and test samples are 60,000 and 10,000, respectively.

CEDAR
                        4
                     
                     
                        4
                        Center of Excellence for Document Analysis and Recognition.
                      digit database [30] is available from CEDAR, SUNY
                        5
                     
                     
                        5
                        The State University of New York.
                      at Buffalo. Its images were scanned at 300 dpi. The training and test sets contain 18,468 and 2711 digits, respectively. The number of samples in both training and test sets differs for each class. Since some images in the test set are poorly segmented, a subset of 2213 well-segmented images is also provided for testing.

In SRU
                        6
                     
                     
                        6
                        Shahid Rajaee University.
                      database [31], for the training and testing processes, 8600 digit images were collected written by 860 different people. Each person had written down each of the ten digits. The participants were selected among the undergraduate students from universities in Tehran. Training set of this database includes 5000 samples and 1450 samples were considered for validation. Test set involves 2150 samples. All of the samples were scanned at 300 dpi resolution in grayscale format. The size of images is 40 × 40 pixels.

IFHCDB
                        7
                     
                     
                        7
                        Isolated Farsi Handwritten Character Database.
                      database was released by Amirkabir University in 2006 [32]. It includes 52,380 isolated characters and 17,740 numerals gathered from exam forms of Iranian high school and guidance school entrance, during the years 2004–2006. In numeral section, for classes ‘4’ and ‘6’, each one has two different shapes, which can be regarded as different classes. However, the minor shape of each class has a small number of samples: 75 for ‘
                        
                     ’ and 105 for ‘
                        
                     ’.

HODA database, which contains handwritten digits, is presented in 2007 [33]. Binary images of 102,352 digits were extracted from about 12,000 registration forms of two types, filled by B.Sc. and senior high school students. This database is divided into a set of 60,000 samples for training and a set of 20,000 samples for testing. LMCA is an online and offline dual Arabic handwriting database. 55 participants were invited to contribute to the development of the handwritten LMCA database [34]. ADBase is composed of 70,000 digits written by 700 participants. Each participant wrote each digit (from 0 to 9) twenty times. Forms were scanned with 300 dpi resolution, then digits are automatically extracted, categorized, and bounded by bounding boxes [35]. Table 1
                      summarizes the features of some popular digit databases.

Some other databases have been prepared for Persian or Arbic handwritten recognition. For example The IFN/ENITdatabase [36] contains material for training and testing of Arabic handwriting recognition. There are more than 2200 binary images of handwriting sample forms from 411 writers, about 26,000 binary word images have been isolated from the forms and saved individually for ease of access. It contains 26,459 city words and 212,211 characters and ligatures

In [37] ADAB database is introduced with Arabic on-line handwritten words. This database was used in a competition held at the tenth International Conference on Document Analysis and Recognition.

All of the above databases only have digits and numbers, but they do not have numerical strings and signs that can appear in numerical strings. Therefore, for developing the research works in handwritten numerical string recognition, we need a database that can cover weaknesses of previous databases.

In this section, we describe the way of data collection for constructing PHOND database. Furthermore, we will explain different features of each item considered in PHOND database.

A data entry form is designed for our data collection process. A sample of the filled entry form is shown in Fig. 2
                        . This form contains the following items:
                           
                              ▪
                              Isolated digits including 9،... ،3،2،1،0 (corresponding to 0, 1, 2,3 ..., 9 in English)

Isolated signs including ‘/’, ‘-‘, ‘،’ and ‘,’

Multi-digit numbers including 2-digit number, 3-digit number, …, 9-digit number

Numerical strings including the numbers consist of four or five digits and one sign, the numbers consist of six or seven digits and one or two sign (s), and the numbers consist of eight or nine digits and two or three signs

End sign of courtesy amounts in Persian language

Courtesy amount

Postal codes

The data entry forms were filled by 180 writers selected from different ages, genders, and jobs. We ensured that the data in each set were unique and there were no relation between sets.

Numerical string is a number consists of 4–9 digits and 1–3 sign(s). To extract the digits, signs and numerical strings, we convert the color (RGB) images of forms into grayscale. Then the images transformed into binary by using a thresholding method. For selecting the threshold, from some well-known thresholding such as [38–40], we use the classical algorithm of Otsu [40], which performs satisfactorily on our database. However, Otsu's thresholding algorithm may not be satisfactory for large databases, therefore we can use the fast algorithm for thresholding introduced in [39].

After providing binary images, at this moment we find the regions of interest considering coordinates and segment the forms into the fields. The segmentation method is described in Section 6.

In the following subsections, we will explain each field of PHOND database in details.

Each participant wrote 10 isolated digits and 4 isolated signs in each form. Consequently, 180 samples are collected for each digit and sign totally. For expanding our database, we segment numbers and numerical strings into digits and signs. Then, 20 samples of each sign are extracted from each form randomly. Therefore, 3600 samples for each sign are collected. For equal distribution of all classes, 20 samples of each digit are extracted from each form randomly which results in 3600 samples of each digit. Accordingly, PHOND database has 3600 samples for each isolated digit and sign. In other words, PHOND database has 50,400 samples of isolated digits and signs. Fig. 3
                         shows some samples of isolated digits and signs in the database.

In each form, for each class of multi-digit numbers, there are two mandatory fields and two arbitrary fields. As respects, there are eight classes. Eight classes include k-digit numbers, k = 2–9. Therefore, each participant wrote 32 multi-digit numbers in each form. Finally, 720 samples for each multi-digit number are collected which were used to form our database of Persian multi-digit numbers. Accordingly, PHOND has 720 samples for each multi-digit number. In other words, it has 5760 samples for multi-digit numbers.

On each form, there are four determinate fields and four arbitrary fields. Each participant wrote 80 numerical strings in each form. Finally, 1440 samples for each class of numerical strings are collected. Some samples of numerical strings in PHOND database are shown in Fig. 4.
                        
                     

Accordingly, our database has 1440 samples for each numerical string. In other words, PHOND has 14,400 samples of numerical strings.

To construct PHOND, each participant wrote one end sign of courtesy amounts in Persian language, and four courtesy amounts (two samples mandatory and two samples arbitrary) in each form. Consequently, 180 samples are collected from end sign of courtesy amounts and 720 samples are collected from courtesy amounts, totally. Fig. 5
                         shows some samples of end sign of courtesy amounts in Persian language and some samples of courtesy amounts.

Each participant wrote four postal codes (two determinate samples and two arbitrary samples) in each form. Hence, totally 720 samples are collected for postal codes.

PHOND database is divided into explicit training and testing sets (70% of samples are selected for training and remaining 30% for testing) to facilitate the sharing of results among researchers as well as performance comparisons.

Each image was saved with a name that indicates its belonging set (training or testing), its class and its sampling number in that class. PHOND database includes 72,180 samples in total (50,526 samples for training and 21,654 samples for testing). The distribution of the number of samples in general is presented in Table 2.
                        
                     

Although the number of some types of strings is not much high, but totally the number of each character is much more than the number of strings.

Comparison between our new database, PHOND and other databases is presented in Table 3
                     . In this assessment, we focused on the content of the databases. This evaluation shows that popular digits databases in handwritten recognition field except one of them, only have isolated digits. Only one of the databases (CENPARMI Persian) has multi-digit numbers, courtesy amounts, and dates. In addition, CENPARMI Arabic only has courtesy amounts. Nevertheless, our database, PHOND includes:
                        
                           -
                           Isolated digits

Isolated signs

Multi-digit numbers

Numerical strings

Courtesy amounts

Postal codes

Comparison between PHOND database and other Persian/Arabic databases in terms of language and number of samples is presented in Table 3. In these comparisons, we focused on the number of isolated digits of databases.

In this section, we describe handwritten number recognition based on PHOND and other databases. Modified Framing Feature is a new feature we introduce in Section 6.4.2. The steps considered for the general handwritten recognition are as bellows.

Preprocessing is one of the most important steps in recognition of handwriting. Phase 1 of preprocessing is binarization in which we convert the grayscale images into binary images. In this step, we use proper thresholding and gray level normalization techniques to standardize the gray levels of background and foreground regions of the numeral images. By thresholding a gray-scale image, we can obtain a binary image (with level 0 for foreground and level 1 for background). For selecting the threshold, we use the classical algorithm of Otsu [40], which performs satisfactorily on our experimental databases. Nevertheless, Otsu algorithm may be satisfactory for small databases, therefore we can use the fast algorithm for thresholding presented in [40].

After binarization, we segment a number into digits. The first step in segmentation is finding the number of objects in the binary image using the 8-connected pixels. Subsequently, we find the coordinate of each object and segment the image into digits. Finally, we eliminate the useless objects as shown in Fig. 6.
                        
                     

The first step in phase 2 of preprocessing is slant correction. After segmentation, with the help of a slant correction algorithm the slants of isolated digits are corrected. After slant correction, the next step of preprocessing is trimming and the final step is normalization. A handwritten digit image normalization technique provides predetermined pixel dimensions and a normalized skew. Normalization is standardizing the digit location and the size in the image. The most popular normalization method is Linear Normalization (LN). It bounds the character strokes with a rectangle and linearly maps the rectangle into a standard size (usually a square). Higher recognition accuracies can be achieved using Moment Normalization (MN). Image moments provide robust estimates for text characteristics such as size and position of words within an image. For handwriting recognition the normalization procedure is applied to image slices independently [41]. By MN, the centroid (center of gravity) of character image is aligned with the geometric center of a normalized plane, and the scales of x-axis and y-axis are determined by second-order moments, which reset the boundary (symmetric with respect to the centroid) of character for aligning with the square of normalized plane. Furthermore, as an alternative of MN method, we employ the normalization method proposed in [41] and its effect is reported in the experiment Section.

In this paper, the trimmed separated digits are normalized to the size of 80 × 80 pixels. Subsequently, they are placed in the center of the image. Eqs. (1) and (2) are used for normalization.
                           
                              (1)
                              
                                 
                                    
                                       H
                                       
                                          n
                                          e
                                          w
                                       
                                    
                                    =
                                    80
                                 
                              
                           
                        
                        
                           
                              (2)
                              
                                 
                                    
                                       W
                                       
                                          n
                                          e
                                          w
                                       
                                    
                                    =
                                    
                                       (
                                       
                                          80
                                          ×
                                          w
                                       
                                       )
                                    
                                    /
                                    h
                                 
                              
                           
                        where w and h are the width and height of the trimmed digit image and Hnew
                         and Wnew
                         are the new height and width of the image, respectively. An example of trimming and normalizing process is shown in Fig. 7.
                        
                     

Feature extraction is the heart of any pattern recognition application. The feature extraction methods for handwritten character recognition are based on two types of features: statistical and structural. The statistical features are derived from the statistical distributions of pixels, such as zoning, moments, projection histograms, or direction histograms. Structural features are based on the topological and geometrical properties of the character, like strokes and their directions, endpoints or intersection of segments and loops.

When the preprocessing and segmentation has been done, we apply some feature extraction techniques to the segments to obtain features, which is followed by application of classification and post processing techniques. It is essential to emphasize on the feature extraction phase as it has an observable impact on the efficiency of the recognition system. To optimally design and achieving a higher recognition rate, we use the Modified framing feature.

In Standard Framing Feature, the first step is narrowing the digit image. Narrowing is done to obtain the body of the digit without eliminating fine details. After narrowing, the digit image is divided into 24 frames with 6 rows and 4 columns as shown in Fig. 8(
                           a). Finally, after framing the image, standard deviation and average angle are extracted as the features of these frames. Standard deviation is achieved as Eq. (3) in any point [16]:
                              
                                 (3)
                                 
                                    
                                       σ
                                       =
                                       
                                          1
                                          n
                                       
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          n
                                       
                                       
                                          (
                                          
                                             X
                                             −
                                             
                                                X
                                                i
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           where X is the average position of the pixels of the narrowed digit of every frame and Xi
                            indicates the position of the pixel number i in every frame. In addition, the average angle feature is obtained by Eq. (4):
                              
                                 (4)
                                 
                                    
                                       
                                          a
                                          i
                                       
                                       =
                                       
                                          1
                                          n
                                       
                                       
                                          ∑
                                          
                                             j
                                             =
                                             1
                                          
                                          n
                                       
                                       
                                          θ
                                          j
                                       
                                    
                                 
                              
                           where ai
                            is the average angle feature of the frame i. n indicates the number of pixels in the image of digit which lie in the frame i. θj
                            is the angle of pixel j in the frame i that is calculated according to the horizontal level.

In this paper, we propose Modified Framing Feature. In this method, the thinning step is eliminated for reducing the pre-processing time and complexity, so the first step of feature extraction in the proposed method is framing. In framing step, the image of digit is divided into 16 frames by size of 20 × 20 pixels as shown in Fig. 8 (b). After framing, average distance and average angle are extracted as the features of these frames.

Distance of pixel k in frame b with position (i, j) is calculated by Eq. (5):
                              
                                 (5)
                                 
                                    
                                       
                                          d
                                          
                                             k
                                             b
                                          
                                       
                                       =
                                       
                                          
                                             (
                                             
                                                
                                                   i
                                                   2
                                                
                                                +
                                                
                                                   j
                                                   2
                                                
                                             
                                             )
                                          
                                          
                                             1
                                             2
                                          
                                       
                                       =
                                       
                                          
                                             
                                                i
                                                2
                                             
                                             +
                                             
                                                j
                                                2
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

In addition, the average distance is calculated by Eq. (6):
                              
                                 (6)
                                 
                                    
                                       
                                          γ
                                          b
                                       
                                       =
                                       
                                          1
                                          
                                             n
                                             b
                                          
                                       
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          
                                             n
                                             b
                                          
                                       
                                       
                                          d
                                          
                                             k
                                             b
                                          
                                       
                                       
                                       b
                                       =
                                       1
                                       ,
                                       2
                                       ,
                                       3
                                       ,
                                       …
                                       ,
                                       16
                                    
                                 
                              
                           where nb
                            is the number of pixels in frame b. Angle of pixel k in frame b with position (i, j) is calculated by Eq. (7):
                              
                                 (7)
                                 
                                    
                                       
                                          θ
                                          b
                                       
                                       =
                                       a
                                       r
                                       c
                                       t
                                       a
                                       n
                                       
                                          (
                                          
                                             −
                                             
                                                j
                                                i
                                             
                                          
                                          )
                                       
                                    
                                 
                              
                           
                        

Furthermore, average angle calculated by Eq. (8):
                              
                                 (8)
                                 
                                    
                                       
                                          a
                                          b
                                       
                                       =
                                       
                                          1
                                          
                                             n
                                             b
                                          
                                       
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          
                                             n
                                             b
                                          
                                       
                                       
                                          θ
                                          
                                             k
                                             b
                                          
                                       
                                       
                                       b
                                       =
                                       1
                                       ,
                                       2
                                       ,
                                       3
                                       ,
                                       …
                                       ,
                                       16
                                    
                                 
                              
                           
                        

Finally, for each frame, outer profiles feature is extracted. For extracting outer profiles feature, four different views (from top, bottom, left, and right) are considered, and the number of white pixels is counted in each view of frames until reaching to the first black pixels. In Fig. 8(c), an example of extracting outer profiles feature in each frame is shown. Thus, four features are extracted for each frame and totally six features are extracted for each frame. Finally, 96 features are extracted for each digit.

Classification is the main decision making stage of OCR system. It uses the features extracted in the previous stage to identify a segment according to the present rules. In recognition of Persian handwritten numbers, we use K-Nearest Neighbor (KNN), and Support Vector Machine (SVM) classifiers.

In KNN, Euclidean distance is used for determining the similarity between samples. LibSVM [19] is a simple, easy-to-use, and efficient software for SVM classification and regression. The outputs of LibSVM represent probabilities information in its classification results. We employ one-against-one (pairwise) strategy in a multi-class problem. In the pairwise approach, k2
                         support vector machines are trained for a k-class problem. Given k classes of data, for any test sample x, the goal is to estimate pi
                        , which is obtained from all rij
                        . In this case, rij
                         is a one-against-one class probability and is obtained from the known training data by solving the optimization problem in Eq. (9):
                           
                              (9)
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         
                                                            m
                                                            i
                                                            n
                                                         
                                                      
                                                   
                                                   
                                                      
                                                         p
                                                      
                                                   
                                                
                                                
                                                
                                                
                                                
                                                   1
                                                   2
                                                
                                                
                                                
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   k
                                                
                                                
                                                   ∑
                                                   
                                                      j
                                                      :
                                                      j
                                                      ≠
                                                      i
                                                   
                                                
                                                
                                                   
                                                      (
                                                      
                                                      
                                                         r
                                                         
                                                            j
                                                            i
                                                         
                                                      
                                                      
                                                      
                                                         p
                                                         i
                                                      
                                                      −
                                                      
                                                      
                                                         r
                                                         
                                                            i
                                                            j
                                                         
                                                      
                                                      
                                                      
                                                         p
                                                         j
                                                      
                                                      )
                                                   
                                                   2
                                                
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             
                                                s
                                                u
                                                b
                                                j
                                                e
                                                c
                                                t
                                                
                                                
                                                t
                                                o
                                                
                                                
                                                
                                                   ∑
                                                   
                                                      i
                                                      =
                                                      1
                                                   
                                                   k
                                                
                                                
                                                   p
                                                   i
                                                
                                                =
                                                1
                                                ,
                                                
                                                
                                                
                                                   p
                                                   i
                                                
                                                ≥
                                                0
                                                ,
                                                
                                                ∀
                                                i
                                                .
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             w
                                             h
                                             e
                                             r
                                             e
                                             
                                             
                                             
                                                p
                                                i
                                             
                                             =
                                             p
                                             
                                                (
                                                
                                                   y
                                                   =
                                                   i
                                                   |
                                                   x
                                                
                                                )
                                             
                                             ,
                                             
                                             i
                                             =
                                             1
                                             ,
                                             …
                                             ,
                                             k
                                             ,
                                             
                                             
                                                r
                                                
                                                   i
                                                   j
                                                
                                             
                                             ≈
                                             p
                                             
                                                (
                                                
                                                   y
                                                   =
                                                   i
                                                   |
                                                   y
                                                   =
                                                   i
                                                   
                                                   o
                                                   r
                                                   
                                                   j
                                                   ,
                                                   
                                                   x
                                                
                                                )
                                             
                                             .
                                          
                                       
                                    
                                 
                              
                           
                        
                     

@&#EXPERIMENTAL RESULTS@&#

Some experiments are done on PHOND and other databases to show the recognition results based on PHOND and investigate the effectiveness of the Modified Framing Feature. We consider the same class for classes ‘4’ and ‘6’, that each one has two different shapes.

KNN is a simple classifier that is used to measure the effectiveness of the extracted features. We consider K = 1 and 3 in our experiments. Moreover, SVM is applied to measure the effectiveness of the extracted features and RBF, Linear and Polynomial kernels are employed in SVM.

1-NN and 3-NN classifiers achieve average recognition rates of 97.68% and 97.82% for isolated digits on HODA, respectively. The recognition rate of different levels is presented in Table 4.
                        
                     

The RBF kernel with C = 0 and gamma = 0.1, Linear kernel with C = 0.3 and Polynomial kernel with degree = 3, C = 0.1 and gamma = 0.1 resulted average recognition rates of 96.01%, 98.46% and 99.07% for isolated digits on HODA, respectively. Intuitively, the gamma parameter defines how far the influence of a single training example reaches, with low values meaning ‘far’ and high values meaning ‘close’. The C parameter trades off misclassification of training examples against the simplicity of the decision surface.

3-NN classifier achieves average recognition rates of 97.89% for isolated digits on PHOND. The recognition rate of different levels is presented in Table 4. The results of experiments illustrate that using PHOND database for recognition of numbers (in contrast to isolated digits) high detection rate above 94% is archived. In the last column, we investigate the effect of using another normalization method. As we can see on average, the results are not changed considerably. In some subsets a little increment and in the others a little decrement is seen.


                        Table 5
                         displays the confusion matrix of the SVM classifier with a polynomial kernel for isolated digits in HODA database. In both matrixes, number 3 reduces the recognition rates.


                        Table 6
                         shows the confusion matrix of 3-NN classifier on PHOND
                        
                         database.

For a comparison of our proposed feature extraction method with other researchers, we consider the best results that are reported. In comparison with research of Alirezanejad et al. [16], our proposed feature extraction results higher recognition rate and reduces the preprocessing time. Table 7 shows the comparison of our proposed method and the method proposed in Ref. [31].


                        Table 8 shows the comparison of our proposed method with other research works on other databases. As the results illustrate, the proposed feature extraction method for recognition of handwritten numbers has higher performance compared to the previous methods.


                        Table 9 demonstrates the comparison of the proposed method and other research works on other databases.

@&#CONCLUSIONS AND FUTURE WORK@&#

In this paper, we have presented a new standard database called PHOND, consisting of handwritten Persian digits, signs, multi-digit numbers, numerical strings, courtesy amounts, and postal codes. PHOND can serve as a basis for future research works in offline recognition of Persian handwritten numbers. PHOND database consists of 72,180 binary images of offline handwritten digits, signs, multi-digit numbers, numerical strings, courtesy amounts, and postal codes.

PHOND database is available to the research community. To acquire the database for free one can contact with the author via an email. The images have been placed into six directories entitled Isolated digits, Isolated signs, Multi-digit numbers, Numerical strings, Courtesy amounts and Postal codes.

Furthermore, in this paper, a modified framing feature was proposed and applied for handwriting recognition based on different databases. Several experiments were done to show the accuracy of recognition using SVM and KNN classifiers and various databases.

In the future, the database may be expanded by collecting more data entry forms, and adding more sets such as Persian dates and legal amounts.

@&#ACKNOWLEDGMENTS@&#

This research has been supported by a Grant from the University of Tehran (No. 29999/01/01).

@&#REFERENCES@&#


@&#MAIN-TITLE@&#An ejection chain approach for the quadratic multiple knapsack problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           This paper presents an ejection chain approach (ECA) to tackle the quadratic multiple knapsack problem (QMKP).


                        
                        
                           
                           To our knowledge, this is the first paper to employ the ejection chain to solve the QMKP.


                        
                        
                           
                           A powerful neighborhood construction phase based on greedy and random operators is embedded in our ECA procedure.


                        
                        
                           
                           ECA improves upper bounds for 34 instances and matches the best known results for the remaining ones except 6 cases.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Ejection chain

Quadratic multiple knapsack problem

Adaptive perturbation

Metaheuristics

@&#ABSTRACT@&#


               
               
                  In an algorithm for a problem whose candidate solutions are selections of objects, an ejection chain is a sequence of moves from one solution to another that begins by removing an object from the current solution. The quadratic multiple knapsack problem extends the familiar 0–1 knapsack problem both with several knapsacks and with values associated with pairs of objects. A hybrid algorithm for this problem extends a local search algorithm through an ejection chain mechanism to create more powerful moves. In addition, adaptive perturbations enhance the diversity of the search process. The resulting algorithm produces results that are competitive with the best heuristics currently published for this problem. In particular, it improves the best known results on 34 out of 60 test problem instances and matches the best known results on all but 6 of the remaining instances.
               
            

@&#INTRODUCTION@&#

The quadratic multiple knapsack problem (QMKP) (Hiley & Julstrom, 2006) extends the well-known 0–1 knapsack problem in two aspects. First, each knapsack possesses its own capacity, and each object can be assigned to at most one knapsack. Second, in addition to their individual values, objects have values in pairs that accrue to the total objective value when both objects in a pair are assigned to the same knapsack. The objective of QMKP is to fill the knapsacks with objects of maximum total value without exceeding the capacity of any knapsack. As a generalization and a combination of the multiple knapsack problem (Hung & Fisk, 1978) and the quadratic knapsack problem (Gallo, Hammer, & Simeone, 1980), QMKP is known to be NP-hard (Hiley & Julstrom, 2006).

Meta-heuristic algorithms (García-Martínez, Glover, Rodriguez, Lozano, & R., 2013; García-Martínez, Rodriguez, & Lozano, 2014; Hiley & Julstrom, 2006; Sundar & Singh, 2010) are powerful tools for handling the QMKP problem. Among these algorithms, local search is one of the most well-known techniques. However, local searches based on simple neighborhood moves may easily fall into the local optima. To overcome this drawback, a variable depth method called ejection chain approach examines a large search space by generating a sequence of interrelated simple moves to create compound moves. In the past two decades, ejection chain methods have been widely used to tackle a variety of challenging optimization problems (see Section 2.2). The current work is motivated by these applications to employ ejection chain methods for the QMKP.

Different from most local search heuristics that directly move from one solution to another, the ejection chain approach first moves to intermediate structures, called reference structures, before moving to another solution. During these procedures, a certain amount of infeasibility is imposed on the initial solution, which has to be ejected to obtain a new feasible solution. The ejection of infeasibility can be delayed to create a chain by moving to other reference structures. At each step of the chain, feasible solutions can be obtained by ejecting the infeasibility. Hence, the approach is termed ejection chain algorithm (ECA). The ejection chain approach can explore much larger search spaces in a compact manner than traditional local search heuristics based on simple neighborhood moves.

The main contributions of this paper are summarized as follows:

                        
                           •
                           To our knowledge, this work is the first to employ the ejection chain method to solve the QMKP. In addition, this technique has never been used to address other knapsack problems.

Both greedy and random operators are embedded in the proposed ejection chain local search. This study also proposes an effective perturbation phase based on two specialized perturbation operators and an adaptive management mechanism.

The performance of the ECA is tested on 60 benchmark instances that were extensively used in previous studies. The outcomes show the efficacy of this algorithm in terms of both solution quality and robustness. In particular, the ECA generates results competitive with those of state-of-the-art approaches presented in literature by improving the best known results on 34 instances and matching the best known results on all but 6 of the remaining instances.

The effects of some important parameter settings and components of the proposed algorithm are analyzed.

The remainder of the paper is organized as follows: Section 2 presents the mathematical formulation of the QMKP and the related works. Section 3 describes the main components of the ECA. Section 4 presents the comprehensive computational results and comparisons between the ECA and some other best-performing algorithms in literature. The effects of several important components and the parameter settings of the proposed algorithm are analyzed in Section 5. Finally, Section 6 concludes this study and gives suggestions for future research directions.

The QMKP involves assigning a set of objects into knapsacks, such that the total profit of all objects in the knapsacks is maximized without violating the capacity constraint of any knapsack. It includes a set 
                           
                              N
                              =
                              {
                              1
                              ,
                              …
                              ,
                              n
                              }
                           
                         of n objects and a set 
                           
                              M
                              =
                              {
                              1
                              ,
                              …
                              ,
                              m
                              }
                           
                         of m knapsacks. Each object i ∈ N has a profit value vi
                         and a weight wi
                        . Each pair of objects i ∈ N and j ∈ N (i ≠ j) has a profit value vij
                        , while each knapsack k ∈ M possesses a capacity Ck
                        . Each object should be assigned to at most one knapsack k such that the total weight of the objects in each knapsack k does not exceed its capacity Ck
                        . The value of an assignment of objects N to knapsacks M is the sum of the linear values of the included objects and the quadratic values of the object pairs that fall into the same knapsack. In the QMKP, the objective is to maximize the total profit value Vsum
                        . The decision variable xik
                         is 1 if object i is assigned to knapsack k; otherwise, the value is 0. Thus, QMKP can be formulated as follows:

                           
                              (1)
                              
                                 
                                    
                                       M
                                       a
                                       x
                                       
                                       
                                       
                                       
                                          V
                                          
                                             s
                                             u
                                             m
                                          
                                       
                                       =
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          n
                                       
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          m
                                       
                                       
                                          x
                                          
                                             i
                                             k
                                          
                                       
                                       
                                          v
                                          i
                                       
                                       +
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          
                                             n
                                             −
                                             1
                                          
                                       
                                       
                                          ∑
                                          
                                             j
                                             =
                                             i
                                             +
                                             1
                                          
                                          n
                                       
                                       
                                          ∑
                                          
                                             k
                                             =
                                             1
                                          
                                          m
                                       
                                       
                                          x
                                          
                                             i
                                             k
                                          
                                       
                                       
                                          x
                                          
                                             j
                                             k
                                          
                                       
                                       
                                          v
                                          
                                             i
                                             j
                                          
                                       
                                    
                                    ,
                                 
                              
                           
                        subject to

                           
                              (2)
                              
                                 
                                    
                                       ∑
                                       
                                          k
                                          =
                                          1
                                       
                                       m
                                    
                                    
                                       x
                                       
                                          j
                                          k
                                       
                                    
                                    ≤
                                    1
                                    ;
                                    
                                    
                                    
                                    
                                    j
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    n
                                    ,
                                 
                              
                           
                        
                        
                           
                              (3)
                              
                                 
                                    
                                       ∑
                                       
                                          j
                                          =
                                          1
                                       
                                       n
                                    
                                    
                                       x
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       w
                                       j
                                    
                                    ≤
                                    
                                       C
                                       k
                                    
                                    ;
                                    
                                    
                                    
                                    
                                    k
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    m
                                    ,
                                 
                              
                           
                        
                        
                           
                              (4)
                              
                                 
                                    
                                       x
                                       
                                          j
                                          k
                                       
                                    
                                    ∈
                                    
                                       {
                                       0
                                       ,
                                       1
                                       }
                                    
                                    ;
                                    
                                    
                                    
                                    
                                    
                                    
                                    j
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    n
                                    ;
                                    
                                    
                                    
                                    
                                    k
                                    =
                                    1
                                    ,
                                    …
                                    ,
                                    m
                                    .
                                 
                              
                           
                        In the above formulation, objective function (1) aims to maximize the total profit value. Constraint (2) guarantees that each object can be assigned to at most one knapsack. Constraint (3) ensures that the total weight of any knapsack does not exceed its capacity. Constraint (4) imposes binary restrictions on decision variables.

@&#RELATED WORKS@&#

In this section, related works on the algorithms for solving the QMKP and applications of the ejection chain approach are briefly reviewed.


                        Hiley and Julstrom (2006) presented the first study on QMKP in literature. The authors introduced three heuristic methods, namely, greedy heuristic, stochastic hill-climber method, and genetic algorithm. Greedy heuristic method filled one knapsack with one object at a time by choosing an unassigned object with the maximum profit/weight ratio. Hill-climber method removed some objects from the knapsacks, and then refilled the knapsacks by applying the afore mentioned greedy heuristic method. Genetic algorithm encoded candidate solutions as strings with lengths equal to the number of objects and employed the hill-climber method as its mutation operator. Singh and Baghel (2007) presented a new steady-state grouping genetic algorithm for QMKP. Saraç and Sipahioglu (2007) proposed another genetic algorithm to solve QMKP. They developed a specialized crossover operator to generate feasible solutions and presented two distinct mutation operators. Sundar and Singh (2010) introduced an artificial bee colony (ABC) algorithm based on the swapping of unassigned objects with already assigned ones. Experimental results demonstrated the superiority of the approach over several reference algorithms in terms of solution quality. The computational results obtained by Wang, Kochenberger, and Glover (2012) indicated that the branch and cut method can effectively solve the quadratic knapsack problem with multiple knapsack constraints.

Recently, García-Martínez et al. (2014) combined a novel local search procedure with an iterated greedy approach based on a tabu mechanism for QMKP. They extended the local search method proposed by Sundar and Singh (2010) to exchange any two objects assigned to different knapsacks. The tabu-based destruction mechanism stores the components that were recently removed from the incumbent solution via short-term memory and prevents these components from being added into the partial solution again. García-Martínez et al. (2013) also addressed the QMKP by using the strategic oscillation (SO) method. They defined critical levels for QMKP and designed strategies to exploit the constraint structure by effectively exploring solutions in the feasible and infeasible regions close to the constraint boundaries.

For applications of the ECA, Glover (1996) originally designed an ejection chain strategy to generate neighborhoods of compound moves with attractive properties for the traveling salesman problem. Rego and Roucairol (1996) employed an ejection chain procedure to generate compound moves to solve the vehicle routing problem. Yagiura, Ibaraki, and Glover (2004) embedded the ejection chain approach into neighborhood construction combined with tabu search to address the generalized assignment problem. Other successful and recent applications of this methodology are detailed in Burke and Curtois (2010); Kingston (2012); Lozano, Duarte, Gortázar, and R. (2012); Rego, James, and Glover (2010); Sevaux, Rossi, Soto, Duarte, and R. (2013).

The ECA is initiated by selecting elements to undergo a change of state (e.g., to remove one object from its knapsack) (Glover, 1996). Then, it explicitly identifies a so-called reference structure, which is similar to but slightly different from a solution, for example violating some constraints or missing some elements. On the basis of several predefined transition rules, moves are generated from one reference structure to another, and back from reference structures to solutions. The transition rules, together with the reference structures, define the ejection neighborhood moves.
                  

In general, the framework of the ECA consists of three phases: initial solution construction, ejection chain local search, and adaptive perturbation. More precisely, a greedy constructive algorithm first produces a promising solution as the initial solution. Then, it iteratively alternates between an ejection chain local search phase (to perform intensive search) and a perturbation phase (to discover new promising search spaces) to obtain a successful tradeoff between intensification and diversification.

The proposed ejection chain approach for the QMKP is outlined in Algorithm 1. First, Init_Solution is used to generate an initial solution S
                        0 by following a greedy constructive heuristic (line 3). Then, an ejection chain local search procedure Ejection_Chain employs a first-improvement strategy to obtain a local optimum S′ (line 7). If the solution quality cannot be further improved, a perturbation phase Adaptive_Perturbation will adaptively perturb the incumbent solution S′ to diversify the search (line 15). These two procedures are repeated until the stopping criterion (i.e., maximum computing time) is satisfied. During this process, S
                        * records the best solution found so far and no_improv_iter denotes the number of iterations without improving the best solution S
                        * (lines 9–13). The following sections describe the main components of the ECA.


                        Hiley and Julstrom (2006) presented a greedy constructive heuristic that can produce initial solutions for the ECA. The greedy constructive heuristic examines the relative value densities of objects to be assigned to knapsacks. Initially, all the knapsacks are empty. Then, an unassigned object is assigned to a knapsack with the highest value density. Each assignment of an object to a knapsack mandates the updating of value densities of the remaining unassigned objects with respect to that knapsack.

To facilitate precision, García-Martínez et al. (2014) defined Δ(i, k), which is denoted as the profit value associated with assigning object i to knapsack k in Eq. 5, and D(i, k), which is defined as its division by the weight of object i in Eq. 6. This study uses this greedy constructive heuristic to iteratively assign an unassigned object to a knapsack if this operation generates the maximal value of D(i, k). After each assignment, the objective function is calculated by Eq. 7.

                           
                              (5)
                              
                                 
                                    Δ
                                    
                                       (
                                       i
                                       ,
                                       k
                                       )
                                    
                                    =
                                    
                                       V
                                       i
                                    
                                    +
                                    
                                       ∑
                                       
                                          j
                                          ∈
                                          N
                                       
                                    
                                    
                                       x
                                       
                                          j
                                          k
                                       
                                    
                                    
                                       V
                                       
                                          i
                                          j
                                       
                                    
                                    ,
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    i
                                    ∈
                                    N
                                    ,
                                    
                                    k
                                    ∈
                                    M
                                    ,
                                 
                              
                           
                        
                        
                           
                              (6)
                              
                                 
                                    D
                                    
                                       (
                                       i
                                       ,
                                       k
                                       )
                                    
                                    =
                                    Δ
                                    
                                       (
                                       i
                                       ,
                                       k
                                       )
                                    
                                    /
                                    
                                       w
                                       i
                                    
                                    ,
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    i
                                    ∈
                                    N
                                    ,
                                    
                                    k
                                    ∈
                                    M
                                    ,
                                 
                              
                           
                        
                        
                           
                              (7)
                              
                                 
                                    f
                                    
                                       (
                                       
                                          S
                                          ′
                                       
                                       )
                                    
                                    =
                                    f
                                    
                                       (
                                       S
                                       )
                                    
                                    +
                                    Δ
                                    
                                       (
                                       i
                                       ,
                                       k
                                       )
                                    
                                    ,
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    
                                    i
                                    ∈
                                    N
                                    ,
                                    
                                    k
                                    ∈
                                    M
                                    .
                                 
                              
                           
                        
                     

The proposed local search procedure uses a first-improvement based hill climbing algorithm with an ejection chain neighborhood. To form an ejection chain, ejection moves and trial moves are alternately executed. One type of ejection move is to remove an object j from its knapsack to generate an incomplete solution, where object j remains free. Such a solution is called the reference structure. Another type of ejection move is to shift an object to the knapsack from which another object has just been ejected in the previous ejection move. This type of ejection move is applied to reference structures, to form a chain effect. Finally, a trial move attempts to assign the free object j into the most profitable knapsack to make a complete solution at each chain level.

For example, if an object is ejected (as an ejection move) and immediately added into another knapsack (as a trial move), this is considered a shift move. That is, a shift move is a special case of ejection chain move. Similarly, a swap move is also a special case of ejection chain move.


                        Fig. 1
                         illustrates an example. Object j
                        0 is first ejected from its knapsack k
                        0 to generate a reference solution. Given that the weight of object j
                        0 exceeds the excess weight of any knapsack, a trial solution that assigns object j
                        0 to any knapsack does not exist. Then, let j
                        2 be the object whose assignment to knapsack k
                        0 is the most suitable among the objects that satisfy the capacity constraint. j
                        2 is assigned to knapsack k
                        0, that is, the ejection move of j
                        2 is triggered by the ejection of j
                        0. At this point, a trial solution can be obtained through a trial move that assigns object j
                        0 to knapsack k
                        2. Otherwise, object j
                        0 is still free and object j
                        1 is selected according to the same rule and is assigned to knapsack k
                        2. Another trial solution is generated by performing a trial move that assigns object j
                        0 to knapsack k
                        1. This process is repeated until the stopping condition is met.

The ejection chain local search is presented in Algorithm 2
                        . In general, this local search is based on a first improvement strategy, which indicates that, for each iteration, once a trial solution is better than the current solution, the incumbent solution becomes the trial solution. This process is repeated until the local optimum is reached. Specifically, for current solution S, Ejection_Move1 is applied to construct the first reference solution SR
                         by removing object j from its knapsack (line 9). If no better trial solution is obtained, then all assigned objects will be candidates for removal in constructing the initial reference solution (line 7). This phase then transforms into another type of process Ejection_Move2 to iteratively generate subsequent candidate reference solutions (lines 10–25). As previously mentioned, two strategies based on greedy and random heuristics are employed to generate the reference solution (lines 19–23). Then, a trial solution ST
                         is generated by reassigning the first removed object j into the most profitable knapsack (i.e., maximum objective increment) by the process Trial_Move (line 12).

During the ejection chain local search procedure, the ECA employs two strategies to select the object in each ejection move: a greedy strategy based on the maximum objective increment value and a random strategy to randomly select a reference solution to enhance search diversification. At each iteration, the probability of selecting the greedy mechanism is α, whereas that of the random mechanism is 
                           
                              1
                              −
                              α
                           
                         (lines 19–23). The trial solution does not always exist if the weight of the first ejected object j exceeds the excess weight of any knapsack. In this case, the trial solution is the current reference solution, i.e., ST
                         ← SR
                        . In addition, the length of the chain is denoted as len and its value is set to 1 after the first reference solution is generated. In the whole procedure, the length of the chain cannot exceed the maximum value cl.

Important points of the ejection chain local search procedure are highlighted below:

                           
                              •
                              Each object can be selected at most once in one ejection chain search process starting by ejecting each assigned object.

The set of objects without any knapsack is regarded as a group in one special knapsack whose capacity constraint is neglected. Objects without knapsacks are also candidates in constructing reference solutions.

In an extreme situation of an ejection move, if the excess weight of the current knapsack is smaller than the weight of any object, the knapsack is replaced with another knapsack with the maximum excess weight to continue the procedure.
                              

Adaptive perturbation phase aims to jump out of the search region of the incumbent solution and diversify the search to a new starting solution, while inheriting certain elite information from the current solution. As described in Algorithm 3, the proposed perturbation phase alternates between Random_Remove and two construction strategies: Greedy_Construct and Greedy_and_Random_Construct. First, Random_Remove randomly chooses a number of nr
                         assigned objects and removes them from their knapsacks. Then, the solution is iteratively constructed until no object can be further assigned to any knapsack. The selection of the two construction strategies Greedy_Construct and Greedy_and_Random_Construct depends on whether the number of iterations without improving the best solution (no_improv_iter) exceeds a predetermined value β. These construction mechanisms are illustrated as follows:

                           
                              •
                              
                                 Greedy_Construct: This strategy iteratively chooses one object i with the maximum D(i, k) value from a set of unassigned objects, including those recently removed, to refill knapsack k without violating the capacity constraint. This mechanism is similar to the greedy constructive heuristic introduced in Section 3.2.


                                 Greedy_and_Random_Construct: At each iteration of this construction strategy, the best z candidate moves in terms of the values of D(i, k) are selected and ranked in a non-descending order. Then, the probability of choosing the hth object-knapsack pair is 
                                    
                                       h
                                       /
                                       
                                          ∑
                                          
                                             i
                                             =
                                             1
                                          
                                          z
                                       
                                       i
                                       ,
                                    
                                 
                                 
                                    
                                       (
                                       h
                                       =
                                       1
                                       ,
                                       …
                                       ,
                                       z
                                       )
                                    
                                 .

The ECA was coded in C++ and run on a PC with a Quad-Core AMD Athlon 3 GHz CPU and 2GigaByte RAM under a Windows 7 operating system. The experiments were conducted on two sets (
                        
                           d
                           =
                           0.25
                        
                      and 0.75) of 60 benchmark instances
                        1
                     
                     
                        1
                        
                           http://www.optsicom.es/qmkp/.
                     ,
                        2
                     
                     
                        2
                        
                           http://www.uco.es/grupos/kdis/kdiswiki/index.php/TIG-QMKP.
                     . These problem instances are characterized by the proportion d of non-zero profit vij
                     , number of objects n, number of knapsacks m, and capacities of the knapsacks c (80% of the sum of the weights of all objects divided by the number of knapsacks).


                        Table 1
                         presents the descriptions and settings of important parameters used in the ECA. The last column denotes the values of these parameters for all the QMKP instances. Given that different groups exhibit varying characteristics, these parameters can be tuned with respect to each benchmark group. To demonstrate the robustness and effectiveness of the proposed ECA, a set of parameter values is fixed for all the benchmark instances, with the exception of threshold β.

To evaluate the effectiveness of the proposed ECA algorithm and facilitate future comparisons, this study reports the detailed results of the ECA (best and average objective values, standard deviation (SD), and time required to generate the results).
                        
                        
                     

The ECA is compared with the ABC algorithm by Sundar and Singh (2010), tabu-enhanced iterated greedy algorithm (TIG) by García-Martínez et al. (2014), and strategic oscillation algorithm (SO) by García-Martínez et al. (2013). ABC algorithm was run on a Linux based 3.0 GigaHertz Core 2 Duo system with 2GigaByte RAM, whereas both SO and TIG were performed on a computer with a 2.8 GigaHertz Intel Core i7903 processor with 12GigaByte RAM. The computer used to run the ABC is very similar to ours, whereas the computers employed by both SO and TIG are slightly faster than ours. Nonetheless, this study merely reports the actual running time on the computers without time conversion given that all tested computers are very similar to one another.

The proposed ECA is tested on each instance 40 times, and each run stops when the time meets the average time Time as reported in literature. As depicted in Tables 2 and 3, Best, Avg, and SD denotes the best objective values, the average objective values, and the standard deviations of the objective values, respectively. The last column Tav represents the average running time to obtain the best values by the ECA (in seconds).

For all 60 benchmark instances, the ECA does not detect solutions that are worse than the previous best known solutions except in six cases. The performance of this algorithm is also competitive in terms of runtime in comparison with other state-of-the-art algorithms. Specifically, the ECA improves the best known results on 34 out of 60 instances (18 instances with d = 0.25 and 16 instances with d = 0.75).

The results of Tables 2 and 3 are also summarized in Table 4, where columns Value and Number represent the average values and the number of best results in terms of Best, Avg, and SD over all the QMKP instances, respectively.

Based on Table 4, the ECA outperforms other reference algorithms in terms of both Value and Number for all the evaluation criteria related to Best, Avg, and SD. The proposed ECA achieves better results than other reference algorithms in terms of the best and average results on 54 and 43 out of 60 instances, respectively. The ECA also performs better than SO (and is significantly superior to other algorithms) in terms of standard deviation (ECA’s 95.91 versus SO’s 97.08), although both ECA and SO generate the best results on 23 instances.

In column 5 of Tables 2 and 3, Time represents the total running times of the reference algorithms for each specific instance. Although the average computing time Tav of the ECA to obtain the best results cannot be directly compared with Time, Tav is less than Time on all instances. If the total running time is set as Time in column 5, the ECA can still obtain the same results reported in the table, and outcome indicates that the ECA is comparable with the reference algorithms in terms of computational efficiency. In addition, previous best performing algorithms outperform CPLEX under the same time limit.

In summary, these experimental results demonstrate the competitiveness of the ECA in terms of solution quality, computational efficiency, and robustness.

As mentioned in Section 3.3, computational efficiency of the ejection chain local search is related to the maximum chain length cl. To determine the effect of different cl values, various versions of the ECA are re-run with cl values of 2, 6, and 12. For each cl value, each problem instance is run 40 times. Other components and parameters are fixed as described in Section 4.1.


                        Table 5 summarizes the overall performance comparison among different versions of the ECA with varying cl values (2, 6, and 12). The notations are as provided above. ECA
                        
                           
                              (
                              c
                              l
                              =
                              6
                              )
                           
                         obtains the best results for 49 out of 60 instances, unlike the other two versions. ECA
                        
                           
                              (
                              c
                              l
                              =
                              6
                              )
                           
                         also yields the best results in terms of Avg for 41 problem instances, and outperforms ECA
                        
                           
                              (
                              c
                              l
                              =
                              12
                              )
                           
                         on all the instances. Furthermore, ECA
                        
                           
                              (
                              c
                              l
                              =
                              12
                              )
                           
                         consumes considerably more computational time than the other two variants. Specifically, the average time Tav for different values of cl over the 60 instances are 292.56, 318.57, and 337.33 for 
                           
                              c
                              l
                              =
                              2
                              ,
                           
                        
                        
                           
                              c
                              l
                              =
                              6
                           
                         and 
                           
                              c
                              l
                              =
                              12
                              ,
                           
                         respectively.

To summarize, ECA
                        
                           
                              (
                              c
                              l
                              =
                              6
                              )
                           
                         can facilitate a good tradeoff between solution quality and computational efficiency.

The proposed ECA relies on two perturbation operators, that use parameter β to adaptively control the probability of selecting each operator. To analyze the effect of different combinations of the two perturbation operators, the value of β is set to 2000, 5, and 0, where 
                           
                              β
                              =
                              0
                           
                         indicates that only the Greedy_and_Random_Construct strategy is used. The other two versions uses the combinations of these two strategies.
                        
                     


                        Table 6 summarizes the overall performance comparison of the different versions of the ECA given varying β values. The notations are as provided above. Given the problem set with 
                           
                              d
                              =
                              0.25
                              ,
                           
                         
                        ECA
                        
                           
                              (
                              β
                              =
                              5
                              )
                           
                         yields better results than the other two variants in terms of best and average solution quality. However, this variant consumes slightly more computational time than the other two variants.

For the problem set with 
                           
                              d
                              =
                              0.75
                              ,
                           
                         
                        ECA
                        
                           
                              (
                              β
                              =
                              2000
                              )
                           
                         dominates the other two variants on almost all instances (with only one exception) in terms of both Best and Avg. ECA
                        
                           
                              (
                              β
                              =
                              0
                              )
                           
                         performs the best in terms of Tav but displays the lowest solution quality.

These observations show the importance of the adaptive perturbation mechanism and provide insight into the selection of appropriate β values for different QMKP instances.

@&#CONCLUSION@&#

This work presents the ECA to solve the QMKP. Key features of the proposed approach include a powerful chain local search procedure based on random and greedy strategies and an adaptive mechanism to enhance search diversification.

Experimental results on a set of benchmark instances show that the proposed approach competes favorably with the best-performing algorithms for the QMKP. In particular, the ECA can generate the current best solutions for most QMKP instances, and the best known results are improved on 34 out of the 60 tested instances. The ECA also displays a competitive performance in terms of both average results and standard deviation compared with the best reference algorithms presented in literature. The experiments also demonstrate the effectiveness of important parameters and the beneficiary of the proposed strategies in the perturbation phase.

This study can be extended in several directions. First, a powerful tabu search method can be employed to improve search capability of the ejection chain search phase. Second, outcomes may be enhanced further by investigating other neighborhood search operators and perturbation strategies. Finally, given that the various ideas introduced in this paper have been used to successfully solve the QMKP, the effectiveness of these concepts may be tested on other knapsack and assignment problems.

@&#ACKNOWLEDGMENT@&#

We greatly appreciate the anonymous referees for their helpful comments, which helped significantly improve the paper. We also thank Dr. Zhuo Wang for his kind assistance in facilitating the discussion on the ejection chain algorithm and Dr. Chance Carraway for his valuable suggestions to improve the paper. This research was supported in part by the National Natural Science Foundation of China under Grant numbers 61370183 and 71471057, as well as by the program for New Century Excellent Talents in University (NCET-12-0219).

@&#REFERENCES@&#


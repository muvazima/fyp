@&#MAIN-TITLE@&#Sequential and parallel large neighborhood search algorithms for the periodic location routing problem

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We develop different sequential and parallel metaheuristics for the periodic location routing problem.


                        
                        
                           
                           Computational results show that our algorithms outperform previous methods.


                        
                        
                           
                           We also suggest a simple and effective parallelization strategy.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Location routing

Large neighborhood search

Parallel metaheuristics

@&#ABSTRACT@&#


               
               
                  We propose a large neighborhood search (LNS) algorithm to solve the periodic location routing problem (PLRP). The PLRP combines location and routing decisions over a planning horizon in which customers require visits according to a given frequency and the specific visit days can be chosen. We use parallelization strategies that can exploit the availability of multiple processors. The computational results show that the algorithms obtain better results than previous solution methods on a set of standard benchmark instances from the literature.
               
            

@&#INTRODUCTION@&#

The periodic location routing problem (PLRP) is an important problem in supply chain management that combines location decisions with routing decisions and visit day assignment. A set of customers has to be served with a predefined frequency from a set of capacitated depots. Although the frequency is given, the exact service days have to be determined. Furthermore, there is a fixed cost that has to be paid for each vehicle used over the planning horizon. The objective is to minimize travel costs, opening costs of the depots and fixed costs of the used vehicles.

Solving location and routing decisions simultaneously is particularly appealing in problems where these two decisions are on the same decision level. This is frequently the case in problem settings where location decisions are easier to modify, for example, when they involve rented locations or do not require big investments. Furthermore, in many problem settings the depot costs can be broken down to the considered planning horizon so that they are at the same order of magnitude as the routing costs. Location routing problems are also interesting from a strategic point of view where building detailed routes can give a better approximation of future routing costs. An extensive literature review including a description of different applications for location routing and a classification scheme is given in Nagy and Salhi (2007). More recent surveys can be found in Prodhon and Prins (2014), Drexl and Schneider (2014), Drexl and Schneider (2015) and Lopes, Ferreira, Santos, and Barreto (2013).

The PLRP was first introduced in Prodhon (2008) and it is related to the periodic vehicle routing problem (PVRP) and the location routing problem (LRP). The PVRP deals with serving a set of customers over a given planning horizon. Customers have predefined frequencies and a related set of predefined visit combinations.

The PVRP is a well-studied problem and a number of mainly heuristic solution methods have been proposed to solve it. A recent exact method was proposed in Baldacci, Bartolini, Mingozzi, and Valletta (2011). Recent meta-heuristic approaches can be found in Gulczynski, Golden, and Wasil (2011), where integer programming and the record-to-record travel algorithm were combined, and in Cordeau and Maischberger (2012), where a parallel iterated tabu search heuristic was proposed. Finally, in Vidal, Crainic, Gendreau, Lahrichi, and Rei (2012) evolutionary search, local search and elaborate population-diversity management schemes were combined.

When the visit frequency is not given, but must be decided, the problem results in a PVRP with service choice (Francis, Smilowitz, and Tzur, 2006). However, in this paper we assume that the visit frequencies are given and only the particular visit days can be chosen from a set of visit day combinations.

Moreover, the PLRP can be seen as an extension of the LRP to a planning horizon. In the LRP, a set of possible capacitated depots is given to serve customer demand. The goal is to simultaneously select a subset of these depots to open and to solve the corresponding multi-depot vehicle routing problem (MDVRP) such that the routing cost and the opening cost of the depots are minimized. Recent heuristic methods for the LRP with capacitated depots and vehicles include Hemmelmayr, Cordeau, and Gabriel Crainic (2012), Contardo, Cordeau, and Gendron (2014), Escobar, Linfati, and Toth (2013) and Ting and Chen (2013). Exact solution methods were developed in Baldacci, Mingozzi, and Wolfler-Calvo (2011), Belenguer, Benavent, Prins, Prodhon, and Wolfler Calvo (2011) and Contardo, Cordeau, and Gendron (2014).

There are only a few papers in the literature that combine location and routing decisions over a planning horizon in which customers have to be served multiple times. Albareda-Sambola, Fernández, and Nickel (2012) tackled a multiperiod location routing problem where location and routing decisions are made at different time scales. In this problem, decisions regarding facility location can only be made in selected time periods of the planning horizon and cannot be changed during time periods between them. Furthermore, unlike in the PLRP, the customer specifies the exact time periods of service.

Previous solution methods for the PLRP include an iterative heuristic (Prodhon, 2008), a memetic algorithm with population management (Prodhon and Prins, 2008) and an ELS with path relinking (Prodhon, 2009). These methods are outperformed in Prodhon (2011) by a later method, a hybrid evolutionary algorithm (HELS). In this algorithm, an evolutionary local search (ELS) works on the selection of visit day combinations. The ELS is hybridized with a randomized extended Clarke and Wright algorithm (RECWA), which was originally designed for the LRP (Prins, Prodhon, and Wolfler Calvo, 2006). It is used for each day separately. Then, the depots that are opened for all days of the planning period are chosen according to different ratios that measure the suitability of opening a depot based on the percentage of daily use and the percentage of total demand satisfied per depot.


                     Pirkwieser and Raidl (2010) developed a variable neighborhood search (VNS) algorithm combined with ILP-based very large neighborhood searches for the LRP and the PLRP. The VNS uses neighborhoods that change visit combinations for customers, exchange segments of customers between routes of the same and of different depots and change the location decisions by opening or closing depots. They introduced three different ILP-based large neighborhood searches. The first neighborhood search, V
                     1, operates on a route level, in which depots can be opened or closed and routes can be relocated to different depots on the same day. The second approach, V
                     2 , also allows changing the visit day combinations of customers. The routes used in V
                     2 come from a set of feasible solutions of the VNS. The third approach is similar to ILP-based refinement techniques (De Franceschi, Fischetti, and Toth, 2006). It removes sequences of customers from given routes and an ILP is used to find the optimal insertion points. This approach is solved for each day. These results were further improved in the thesis (Pirkwieser, 2012) by adapted parameter settings, for instance a longer runtime.

Parallel computing enables the development of fast and robust solution methods for instance by exploiting the availability of multiple processors on computing clusters or multi-core processors. In the following, we will describe the most recent parallelization strategies for vehicle routing problems. For further information on parallel metaheuristics, we refer to the book of Alba (2005) and to the survey of Crainic and Toulouse (2010). Moreover, a survey with a focus on vehicle routing problems that covers heuristic and exact parallel solution methods can be found in Crainic (2008).


                     Crainic and Nourredine (2005) introduced a classification for parallel metaheuristics along three dimensions. The first dimension indicates whether the search is controlled by a master process (1C) or by several processes together (pC). The second dimension indicates the quantity and the quality of information exchanged. There is rigid (RS) and knowledge synchronization (KS) for synchronous communication and collegial (C) and knowledge collegial (KC) for asynchronous communication, where the respective difference is the amount and quality of information exchanged. The third dimension can be classified as SPSS, SPDS, MPSS or MPDS standing for same or multiple starting point and same or different search strategies used by the processes.


                     Cordeau and Maischberger (2012) proposed a parallel iterated tabu search heuristic for four different routing problems: the VRP, the PVRP, the MDVRP, and the site dependent VRP with and without time windows. In their parallel algorithm, each process starts from a different initial solution. Some of the parameters of the iterated tabu search are chosen independently in the processes. At given points, knowledge about the solutions is shared. Each process p ∈ {1, 2, …, N} decides whether to accept its working solution with a probability 1 − (λ/η)2, where λ is the current iteration and η is the total number of iterations, or go to the jth best solution, where 
                        
                           j
                           =
                           ⌊
                           
                              p
                           
                           ⌋
                        
                     . Therefore, most working solutions will be accepted in the beginning, while toward the end the best solutions will be accepted, so that the processes can focus on trying to improve the best solution. The authors can show that the algorithm yields very good results for several variants of vehicle routing problems.


                     Groër, Golden, and Wasil (2011) developed a parallel algorithm for the VRP that combines integer programming and heuristic search. A master process is used to control the search, while the remaining processes can be either heuristic solvers or set covering solvers. The heuristic solvers run a metaheuristic based on the record-to-record travel algorithm and the set covering solvers solve set covering problems with routes taken from the heuristic solvers.


                     Jin, Crainic, and Løkketangen (2012) designed an algorithm that achieves very competitive results for the VRP. They use four tabu search threads that each uses different neighborhoods. The best solutions found are exchanged periodically through the use of a solution pool.


                     Lahrichi et al. (2012) developed integrative cooperative search (ICS) that can tackle multi-attribute combinatorial optimization problems. ICS performs a decomposition of the problem in partial problems that are solved by partial solvers. Integrators select partial solutions and combine them to complete solutions. These complete solutions are sent to the complete solver group. In this work, they apply the method to the MDPVRP and get results that improve upon previous methods.

In the context of parallel computing, it is also important to mention GPU based computing. It takes advantage of the rapid increase in GPU performance. Modern commodity PCs include a multi-core CPU and one or more GPUs. For this parallel, heterogeneous architecture, solution methods are developed. An introduction to modern computer architectures and GPU programming is given in Brodtkorb, Hagen, Schulz, and Hasle (2013), which is part one of a survey in two parts. Part two (Schulz, Hasle, Brodtkorb, and Hagen, 2013) gives a broad overview of the existing literature on parallel computing in discrete optimization aimed at modern PCs. The survey has a strong focus on routing problems. The authors conclude that GPU computing in discrete optimization is still in its infancy. The development of solution methods that exploit the heterogeneity of modern PCs efficiently is still an open research field that is interesting and highly relevant.

In this paper, we propose sequential and parallel variants of a large neighborhood search algorithm (LNS) to solve the PLRP. The computational results show that our algorithm outperforms previous solution methods in terms of solution quality. We can show that for standard benchmark instances from the literature, substantial improvements are possible both in the average solution quality as well as in the quality of best known solutions found. Moreover, we also develop two parallel versions of the algorithm that make use of the availability of clusters of computers. We propose a simple methodology for parallelization that can easily be applied to other problems and algorithms.

The remainder of this paper is organized as follows. Section 2 gives a detailed problem description, in Section 3 the solution method is outlined, while in Section 4, the computational experiments are described. Finally, Section 5 concludes the paper.

The PLRP can be defined on an undirected graph G = (V, E), where V is the set of nodes and E is the set of edges. The set V consists of two subsets of nodes: the subset I of possible depot locations and the subset J of customers. Each depot has a capacity Wi
                      and an opening cost Oi
                     , that is charged once in the planning horizon when the depot is opened. The traveling cost cij
                      between node i and node j is given.

A planning period of several days H is considered in which customer demand has to be satisfied. Each customer j has a given visit frequency fj
                     . Associated with this visit frequency is a set of service day combinations Cj
                     , i.e., the specific days on which the customer can be visited. For example, in a five day planning period, a customer with frequency one can be visited either on day one, two, three, four or five. For each customer, the total demand over the planning horizon, which is assumed to be cyclic, is given. The demand of customer j on day t of service combination r ∈ Cj
                      is given by djtr
                     , which is the accumulated demand since the last service.

There is a maximum number of vehicles K. Vehicles are homogenous, capacitated and each vehicle is with a fixed cost when it is used. The vehicle cost is charged if a vehicle is used at least one time in the horizon. Each vehicle can only make a single route per day and must come back to its depot of departure. Let Rit
                      be the number of routes assigned to depot i on day t, then the fleet size Ni
                      of depot i is Ni
                      = max {Rit
                     : t ∈ H}. The total number of vehicles required is ∑
                        i ∈ I
                     
                     Ni
                     . Consider for example a solution with two open depots and two days, in which, on the first day, two routes originate from depot one and one from depot two, while on the second day, one originates from depot one and two from depot two. In that case four vehicles are necessary since for both depots, the number of vehicles required is two respectively.

In the PLRP the following decisions have to be made: selecting which depots to open, which service combination must be assigned to each customer and how many vehicles to assign to each depot such that customer demand is satisfied. The objective function considers the minimization of the sum of the routing cost, of the vehicle cost, and of opening cost of depots. Finally, the capacity constraints of depots and vehicles are respected, and customers are visited on feasible visit day assignments.

We developed a LNS algorithm to solve the problem. LNS was proposed by Shaw (1998), and is similar to the ruin and recreate principle proposed in Schrimpf, Schneider, Stamm-Wilbrandt, and Dueck (2000). An overview of the LNS heuristic and its variants and extensions can be found in Pisinger and Ropke (2010).

The general idea of LNS is the usage of large neighborhoods that are usually composed of destroy and repair operators. A destroy operator ruins part of the solution while a repair operator is used to reconstruct it. In case of the PLRP, the destroy operators remove customers and put them to the temporary customer pool. Then the customers are reinserted in the partial solution by the repair operators. An extension of LNS, adaptive large neighborhood search (ALNS) was proposed by Ropke and Pisinger (2006) for the pickup and delivery problem. The difference is that the operators are chosen based on a score that reflects the past success of these operators.

We use several different types of destroy and repair operators that are explained below. Contrary to ALNS, in our LNS implementation, the operators are chosen randomly in each iteration no matter how successful or unsuccessful they were in previous iterations.

The initial solution is constructed by assigning each customer a random combination, and by opening a random depot. The number of depots to be opened is a random number between the total demand divided by the average depot capacity, which should reflect an estimation of the minimum number of depots needed, and the total number of depots. Then, customers are assigned one by one to their closest depot and for each depot a set of routes is constructed by using the Savings Algorithm of Clarke and Wright (1964). The depot capacity constraint can be violated in this step.

We allow the constraints on the number of vehicles, the depot capacity and the vehicle capacity to be violated. Therefore, a weighted penalty function is applied. The objective function is given by f(s) = c(s) + αd(s) + βe(s) + γg(s). The travel cost, opening cost of depots and fixed cost for each vehicle used over the planning horizon are captured in c(s). The violations of the vehicle capacity, number of vehicles, and satellite capacity constraints are d(s), e(s) and g(s) respectively, while α, β and γ represent the corresponding weights. These weights are adjusted during the search process. Whenever a violation occurs, the respective weight is multiplied by a factor δ > 1, when the solution is feasible with respect to the respective constraint, its weight is divided by δ as long as the weight remains in the interval [ι; κ]. In a feasible solution d(s), e(s) and g(s) equal zero.

Each operator l removes a number of ql
                         customers, where ql
                         is a random uniformly distributed integer between ρl
                         and τl
                        . We use in total eight destroy operators that can be differentiated by the level on which they operate. There are three destroy operators that change the depot configuration (close-depot, open-depot, swap-depot). There are two destroy operators that assign new visit day combinations to customers (change-combination, multiday-route-removal) and finally there are three destroy operators that only operate on a given day (related-removal, worst-removal, route-removal).

The operator close-depot closes a random depot and moves all customers currently assigned to it to the customer pool. The operator open-depot opens a randomly selected depot among the ones currently closed and the ql
                         closest customers to this depot are moved to the customer pool. In the operator swap-depot one depot is closed, while another one is opened. All customers assigned to the closed depot are removed. The new depot to be opened is chosen in a roulette wheel selection based on the inverse distance to the closed depot.


                        Change-combination and multiday-route-removal remove ql
                         customers and reassign new visit day combinations to them. While change-combination removes random customers, multiday-route-removal tries to decrease the number of vehicles used by removing routes and assigning customers previously associated with these routes to new visit days. The vehicle to be removed is the vehicle that is needed the least number of days, where ties are broken arbitrarily. All customers that are assigned to these routes are removed and are assigned new visit day combinations.

The remaining three destroy operators only operate per day, i.e., customers are not assigned a new visit combination, but are simply removed from their current position on a given day. For these operators, a day is chosen randomly in a roulette wheel selection. The probability that a day is chosen is proportional to the total demand on that day.

In related-removal, a random customer is picked as a seed customer and the q − 1 closest customers are removed from their positions on the given day. The q worst customers are removed from their positions in worst-removal. Worst refers to customers for which the difference in cost of the solution with the customer to the solution without the customer is high. This difference, the so-called removal cost, is divided by the average travel cost of the ingoing arcs of the corresponding node. Furthermore, the removal cost is perturbed by a factor d ∈ [0.8, 1.2] to randomize the search. The operators related-removal and worst-removal are modified versions of the operators suggested in Ropke and Pisinger (2006). In route-removal, a route is chosen randomly and all assigned customers are removed. The opening of a new route at that depot, on that day is forbidden, unless it is the only open depot. Preliminary experiments showed that all these operators are useful and needed to obtain good solutions. The operators change-combination and multiday-route-removal are new, the operators that change the depot configuration were previously introduced in Hemmelmayr et al. (2012) and the operators that only operate per day were also previously introduced in Hemmelmayr et al. (2012) and are slight modifications of the ones used in Ropke and Pisinger (2006).

The repair operators insert customers that have been removed by the destroy operators in the partial solution. We use one main operator, greedy-insertion and variations of it. It is based on the one in Ropke and Pisinger (2006).

The operator greedy-insertion inserts a customer in a new or existing route that minimizes the insertion cost, i.e., the sum of travel cost, depot opening cost and vehicle usage cost. This operator is a faster version of the one suggested in Ropke and Pisinger (2006). While in their paper, customers are ordered according to the minimum insertion cost, we use a random order because we wanted to have a fast and simple but still efficient operator. Hence, after the insertion of one customer, there is no need to update the insertion cost of the customers remaining in the list. There are two variations of the basic greedy-insertion operator. The operator greedy-insertion-perturbation uses a perturbation in the insertion cost as a diversification mechanism. Therefore, the insertion cost is perturbed by a factor d ∈ [0.8, 1.2]. After the change-combination and multiday-route-removal operators, the greedy-insertion-multiday version can be selected that computes the best insertion over all visit day combinations.

A local search procedure is performed for promising solutions, i.e., solutions that are within a threshold θ of the best found solution. The following operators are used for local search: move, swap and 2-opt. The operators are performed sequentially for the daily VRPs of each open depot. Therefore, the assignment of customers to depots and also the assignment of visit day combinations are not changed during the local search phase. They are used in a first-improvement fashion as long as improvements can be realized. The move and swap operators are used inter-route and intra-route, while 2-opt is used intra-route. Move tries to relocated single customers. Swap exchanges two segments of customers. Segment lengths of one to three customers are possible and the two segments exchanged can have different lengths.

We developed four different versions of the algorithm: two sequential and two parallel. The first version is the regular sequential version (LNS-S), which is shown in Algorithm 1
                        . It starts from an initial solution. In each iteration, a destroy and a repair operator are chosen randomly until the stopping condition is reached. For the acceptance decision simulated annealing (SA) is used as a mechanism to also accept non-improving solutions. The parameters such as the temperature and the cooling scheme are described in Section 4.1.

The second version is a hierarchical version (LNS-HIER-S). Algorithm 2
                         shows the basic steps. It is similar to LNS-S except that the problem is decomposed in two levels. The first decision level decides which depots to open, while in the second level the resulting MDPVRP is solved, with depots fixed to open or close according to the first stage decision. In the first level only destroy neighborhoods of the set Df
                        , that change the depot configuration, are applied. These are swap-depot, open-depot and close-depot. In the second level only the remaining destroy operators are used. The repair operators can be used in either level. The algorithm starts from the initial solution, performs one LNS iteration in the first level and fixes the depots to open or close accordingly. Then the second stage LNS is performed until the maximum number of second-stage iterations is reached and the solution is returned to the first level. Finally, in the first level, it is decided whether to accept the new incumbent or not and the next iteration starts. The acceptance decision in the first level is based on SA, while in the second level only improving solutions are accepted. The main idea of this version is that it follows a decomposition of the problem in a location part and a (MDPVRP) routing part.

The third version is a parallel hierarchical version (LNS-HIER-P) that parallelizes the second level of LNS-HIER-S. The first stage is computed by only one process, the master process, while the second stage is computed by all processes in parallel. In the first stage, the solution is destroyed with an operator from the set Df
                         and repaired again. Using this solution as a starting solution, each process solves the resulting MDPVRP in the second stage until the maximum number of second stage iterations is reached. Once all processes are finished, the best solution among all processes is taken and returned to the first stage. There it is decided whether to accept it or not and the next iteration starts. Algorithm 3
                         shows a pseudocode for LNS-HIER-P in which P represents the number of processes. According to the classification in Crainic and Nourredine (2005) this is a 1C/KS/SPSS algorithm. There is 1-control by the master process and knowledge synchronization (KS) because the master delegates a larger part of its work. Moreover, the algorithm uses same initial point, same search strategy, which means that the processes start from the same initial solution and use the same algorithm. This is a synchronous parallelization strategy in which all processes stop at predefined intervals to exchange information.

Finally, the fourth version is a parallelization of LNS-S called LNS-P, which is displayed in Algorithm 4
                        . The processes start from different, randomly generated initial solutions and they all use different starting temperatures. Whenever a new best solution is found, it is communicated to central memory. After κ iterations without improvement, a new search segment starts. Then each process either continues with its current working solution or requests the current best solution from central memory. The working solution is kept with probability 1 − (λ/η)2, where λ is the current iteration and η is the total number of iterations. This acceptance decision is the same as in Cordeau and Maischberger (2012), but unlike them we do not consider the jth best, but the global best solution. This makes sure that in the early stages of the algorithm, the processes are more likely to continue with their working solution, while in the end all processes try to improve the best solution. Moreover, toward the end of the search, after κ′ iterations, the temperature is increased to the initial temperature whenever a new search segment is started so that the search can escape from local optima in the final stages of the algorithm. To speed up the search and prevent that too much unnecessary information is being sent, a new best solution is only sent to central memory after an initial of 200 iterations and there is a minimum of 100 iterations after which a new best solution is sent to central memory. This algorithm classifies (Crainic and Nourredine, 2005) as pC/C/MPDS with p-control and an asynchronous collegial cooperation model through the use of a shared memory. Multiple points different strategies are used since each process uses its own starting solution and the strategies use a different parameter for the SA temperature. In this asynchronous communication each process is responsible for its own search and for the communication with other processes.

We have tested our algorithm on the set of 30 instances proposed in Prodhon (2008). The instances differ in the number of depots m ∈ {5, 10}, the number of customers n ∈ {20, 50, 100, 200}, vehicle capacity Q ∈ {70, 150} and the number of clusters β ∈ {0, 2, 3}, where 0 corresponds to a uniform distribution. The instances are named accordingly: n-m-β-[a, b], where a refers to the low capacity case (80) and b to the high capacity case (130). The planning horizon consists of five working days and two idle days. Each customer has a predefined visit frequency. There are three different possible frequencies: one, two or three. The corresponding visit day combinations for frequency one are {{1},{2},{3},{4},{5}}, for frequency two {{1,3} {1,5}{2,5}} and for frequency three {1,3,5}. The demand djrt
                      of customer j on day t depends on the combination r chosen. We refer to Prodhon (2011) for a detailed description of how to compute djrt
                      and for further details on the instances.

The algorithm was implemented in C + +, compiled with Intel compiler v12.0 and run on a cluster of Intel Xeon X5670 at 2.93 gigahertz. The parallel versions were run with OpenMPI version 1.4.3. Four processors were used by LNS-HIER-P and seven by LNS-P.

We compared the algorithm to the best solution methods from the literature. These are the HELS proposed by Prodhon (2011) and the VNS with ILP-based neighborhoods of Pirkwieser and Raidl (2010) and Pirkwieser (2012).

The parameter settings were decided according to experiments on a subset of instances. The number of customers to remove in the destroy phase depends on the operator chosen. In every iteration, it is a random integer between ρl
                         and τl
                        , except for the operators close-depot, swap-depot, multiday-route-removal and route-removal. For these operators the customers that are removed are the customers assigned to the depots or routes that will be closed. For the operator open-depot, the number is chosen between 
                           
                              0.2
                              
                                 
                                    #
                                    V
                                    i
                                    s
                                    i
                                    t
                                    s
                                 
                                 T
                              
                           
                         and 
                           
                              0.6
                              
                                 
                                    #
                                    V
                                    i
                                    s
                                    i
                                    t
                                    s
                                 
                                 T
                              
                              ,
                           
                         where 
                           
                              #
                              V
                              i
                              s
                              i
                              t
                              s
                           
                         represents the total number of visits, which is the number of customers multiplied by their respective frequency, and T is the number of days in the planning period. For the operator change-combination, ql
                         is selected between 1 and 0.5Nc
                        , where Nc
                         represents the customers that have more than one visit combination and hence can be considered in the operator change-combination. Finally, for the operators related-removal and worst-removal, ql
                         is between one and the number of customers visited on that day. These operators can remove a fairly large number of customers. Preliminary tests showed that removing a smaller number of customers yields worse results.

For the weighted penalty function the following parameters were chosen: δ was set to 1.1, ι to 5 and κ to 10,000. Our tests showed that changes in these parameters have only a minor influence on the performance of the algorithm.

The stopping condition of the algorithm is 5 × 106 iterations. The parallel version stops after every process has finished this number of iterations. For the hierarchical version, 500 iterations on the upper level and 10,000 iterations on the lower level are performed. The threshold θ that identifies a promising solution that will undergo local search is set to 5 percent.

The parameters used for the SA acceptance decision are set such that solutions that are worse than w (percent) of the initial solution are accepted with a probability of 0.5, where w is set to 0.1. In the parallel implementation, LNS-P, the different processes select their w randomly between 0.01 and 0.3. The cooling is performed in a way that in every iteration the temperature T is decreased by 
                           
                              
                                 
                                    T
                                    start
                                 
                                 η
                              
                              ,
                           
                         where η is the total number of iterations. Preliminary experiments showed that the algorithm is insensitive to the cooling scheme used, but that it is necessary to use a mechanism that allows acceptance of non-improving solutions.

Moreover, a tabu list is used that forbids that an operator is used to open or close a depot that has just recently been opened or closed. The size of the tabu list is ⌈0.1m⌉, where m is the number of depots. So for the instances with 5 depots, there is no tabu list, for instances with 10 depots, the size of the tabu list is 1.

In the LNS-P algorithm, the number of iterations without improvement, κ, after which a new solution can be requested is set to 5000 and the number of iterations after which the temperature is increased to the initial temperature, κ′, is 0.8η.

We compare our solution method to the HELS algorithm of Prodhon (2011) and to the best performing method of Pirkwieser and Raidl (2010), which is the VNS + V1, 2. We will also use the results of Pirkwieser (2012), which are newer results of an improved version of the algorithm in Pirkwieser and Raidl (2010). These methods will be denoted as P (Prodhon, 2011), PR (Pirkwieser and Raidl, 2010) and PT (Pirkwieser, 2012) in the sequel. In Prodhon (2011), the best value of the objective function over 10 runs is reported, while in Pirkwieser and Raidl (2010), the average solution over 30 runs is shown and in Pirkwieser (2012) the average cost over 10 runs as well as the minimum out of these 10 runs is given. The results for our algorithms are the average and minimum over five runs.

Concerning runtimes, the following computing environments were used: Pirkwieser and Raidl (2010) coded their algorithm in C + +, compiled it with Intel compiler v12.0 and executed it on a single core of a Intel Core2 Quad Q9550 at 2.83 gigahertz with 8 gigabytes RAM. In Pirkwieser (2012), the algorithms were compiled with GCC 4.5 and executed on a single core of a 2.53 gigahertz Intel Xeon E5540 with 3 gigabytes RAM dedicated per core. Finally, Prodhon (2011) used an Intel Centrino 2 at 1.2 gigahertz and 1 gigabytes of RAM for the experiments.

We will show the average and minimum results, if available, of the algorithms P, PR and PT and of our algorithm (version LNS-S). Table 1
                         shows the percentage gap to the new best known solutions for the average and the minimum of the respective algorithms. Furthermore, T*, the time needed to find the best solution in each run, and T, the duration of one run of the algorithm until the maximum number of iterations, are given. Both T and T* are averaged over five runs. From the previous algorithms, P is outperformed by PT and PR. As mentioned above, PT are newer results of a slightly improved version of PR with longer runtime. It yields better results than PR in terms of solution quality, but needs a longer runtime. LNS-S can achieve better results than PT. LNS-S needs a longer runtime, but it can reduce the average gap to the best known solutions substantially from 3.76 percent to 0.74 percent.


                        Table 2
                         shows an analysis of the insertion operators and local search. The table shows the gap (percent) to a version of the algorithm that uses all the insertion operators and θ equals 5 percent (row LS: θ 5) and the runtime in seconds. The tests were performed for a subset of instances and results are averaged over these instances.

We tested different versions of the algorithm by varying the insertion operators used. By keeping everything else the same, there is one version without greedy-insertion, one without greedy-insertion-perturbation and one without greedy-insertion-multiday. The results show that the solution quality deteriorates slightly and the runtime increases slightly when the operators greedy-insertion and greedy-insertion-perturbation are left out. Omitting greedy-insertion-multiday results in a deterioration of 1 percent and is therefore not recommendable.

We also tested a version where the regret-insertion operator was used additionally to the three standard insertion operators. Regret-insertion was proposed in Ropke and Pisinger (2006). It computes a regret value that expresses the regret of not placing a customer in the best positions, but in the second best or third best and so on. Customers are then sorted according to their regret values in decreasing order, so that customers with a high regret are inserted earlier to avoid that their best insertion position is no longer available. After each insertion of a customer from the list of untreated customers, the regret values of the remaining customers have to be updated by taking the respective changes of the insertion positions into account. This operator is more sophisticated than greedy-insertion, but it also needs a longer runtime to incorporate the updates performed. We saw that using regret-insertion does not improve the solution quality, but increases the runtime. Therefore, it was decided to omit this operator since its role can be replaced by LS.

Moreover, we also experimented with the usage of LS. LS is performed for any solution with an objective value less than or equal to (100 + θ) (percent) of the best found solution so far. The table shows results for θ equals 0, 3, 5, and 10 percent. Please note that 5 is the default version. As can be seen, a solution where there is no LS performed, yields quite bad results. Moreover, there is a trade-off between runtime and solution quality that has to be considered when deciding for a more time-consuming insertion operator or to perform more LS. We found that θ equals 5 is a good parameter setting.


                        Table 3
                         shows results for the sequential and parallel variants compared to the best performing method by Pirkwieser (2012). LNS-HIER-P is run on four parallel processors and LNS-P is run on 7 parallel processors where one of the processors is managing the central memory. The total number of iterations is 5,000,000. We also report results for a shorter version of LNS-P with 714,500 iterations, where the number of iterations multiplied by the number of processors used roughly matches the number of iterations of the sequential version. The time T indicates wall-clock time, i.e., the time needed from start to the end of the parallel algorithm.

The hierarchical versions follow a natural decomposition of the problem. However, these versions are outperformed by their non-hierarchical counterparts. They need a longer runtime and have an inferior solution quality. In the upper level, the depot configuration is fixed while in the lower level the problem is solved for this given configuration. One disadvantage of this method is that it also explores “bad” depot configurations and hence wastes computation time exploring these regions. Moreover, the parallel version uses synchronous communication. Synchronous strategies have the disadvantage that there is a larger computational overhead, since all processes must wait for each other before they can proceed with their tasks.

Comparing the parallel and sequential non-hierarchical versions of LNS, we can see that LNS-P can obtain a better solution quality than LNS-S. Even for the shorter version of LNS-P the solution quality is still better than LNS-S so that the use of parallelism is an important advantage. Results show that the parallel versions perform better than the sequential ones. The main advantage is that it provides an easy diversification mechanism. With a comparable number of iterations, the parallel version still outperforms the sequential one. Moreover, we can also see that the minimum of LNS-S is worse than LNS-P with 5,000,000 iterations, so it can show the value of communication used in the parallel version.

Detailed results can be found in Table A.1 in the Appendix. All four versions can obtain a solution quality that is between 1.5 and 3 percent better than the results of Pirkwieser (2012). However, they have a smaller runtime, with 91.9 seconds on average.


                        Table 4
                         gives the new found best known solutions compared to the previously best found solutions. These are the best solutions identified during all the experiments. The previous solutions were found by Pirkwieser (2012) except for instance 20-5-1b for which the solution was reported in Prodhon (2011). Our algorithm finds new best known solutions or ties in all but one instance. On average, the new best found solutions are more than 2 percent better than the previous ones.

@&#CONCLUSION@&#

We have presented new sequential and parallel algorithms for the PLRP. The PLRP is an important problem, but has not received much attention in the literature so far. Our algorithms can outperform previous solution methods in terms of solution quality. Compared to the best performing algorithm so far, a VNS with ILP-based neighborhood searches (Pirkwieser, 2012), our algorithms are between 1.5 and 3 percent better. We can also find new best known solutions or ties for all 30 instances but one with an average improvement of 2.17 percent.

Moreover, we proposed a simple methodology for parallelization that can easily be adopted to other algorithms and problems and showed that it can improve sequential versions. So whenever multiple processes are available it pays off to use parallelization to get better solutions in a shorter time.

Future work will focus on improving the parallel version of the algorithm. One direction is to not only exchange the best solution, but several and include diversity metrics when accepting a new solution. Another interesting approach is to run different searches in parallel. At the moment only the initial temperature is different for the processes, but by running more different algorithms in parallel the performance can probably be improved.

@&#ACKNOWLEDGMENTS@&#

The author would like to thank two anonymous referees for their valuable comments that helped to improve the quality of this paper.


                     
                  

@&#REFERENCES@&#


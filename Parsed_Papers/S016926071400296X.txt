@&#MAIN-TITLE@&#Event-driven, pattern-based methodology for cost-effective development of standardized personal health devices

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Experiences applying X73PHD show a trade-off between interoperability and costs.


                        
                        
                           
                           Reducing hardware, software costs and time-to-market is crucial for X73PHD adoption.


                        
                        
                           
                           An event-driven, patterns-based methodology for cost-effective development is shown.


                        
                        
                           
                           The methodology could foster the production of cost-effective X73-compliant PHDs.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Cost-effective

Event-driven

Interoperability

ISO/IEEE11073

Pattern-based

Personal health device (PHD)

@&#ABSTRACT@&#


               
               
                  Experiences applying standards in personal health devices (PHDs) show an inherent trade-off between interoperability and costs (in terms of processing load and development time). Therefore, reducing hardware and software costs as well as time-to-market is crucial for standards adoption. The ISO/IEEE11073 PHD family of standards (also referred to as X73PHD) provides interoperable communication between PHDs and aggregators. Nevertheless, the responsibility of achieving inexpensive implementations of X73PHD in limited resource microcontrollers falls directly on the developer. Hence, the authors previously presented a methodology based on patterns to implement X73-compliant PHDs into devices with low-voltage low-power constraints. That version was based on multitasking, which required additional features and resources. This paper therefore presents an event-driven evolution of the patterns-based methodology for cost-effective development of standardized PHDs. The results of comparing between the two versions showed that the mean values of decrease in memory consumption and cycles of latency are 11.59% and 45.95%, respectively. In addition, several enhancements in terms of cost-effectiveness and development time can be derived from the new version of the methodology. Therefore, the new approach could help in producing cost-effective X73-compliant PHDs, which in turn could foster the adoption of standards.
               
            

@&#INTRODUCTION@&#

Nowadays, developed and emerging economies are fostering solutions that enhance the healthcare quality, for example, by offering new services based on technological systems [1]. Population demands, however, may challenge the budgetary balance, since such services are offered depending – among other factors – on the associated cost [2]. Affordable personal health devices (PHDs) will therefore play a crucial role in new telemonitoring scenarios. At the same time, standardization of PHDs has been found as a key enabler for the provision of high quality services [3]. However, the application of standards in PHDs presents an inherent trade-off between interoperability and processing load. Therefore, developing implementation methodologies able to limit the processing load to a minimum is of utmost importance.

The ISO/IEEE11073 (X73) family of standards for PHDs (X73PHD) is aimed at providing seamless integration of PHDs into personal health solutions [4]. However, while it facilitates the exchange of medical measurements in a transparent way, the complexity of the protocol requires higher performance hardware in comparison to non-standardized ad-hoc protocols [5].

All these previous considerations led the authors to propose a patterns-based methodology as a solution to optimize the implementation of PHDs with low-voltage low-power (LV–LP) constrains [6] (hereinafter referred to as version 1.0). The patterns-based approach relied on the low variability between the fields of the X73PHD-compliant frames. This method has been applied during 3 years in the NAsisTIC project [7], as well as in other related experiences [8–10]. Version 1.0 was based on the multitasking paradigm. This implied the need of a module that provides some operating system features – threading and inter-process communications (IPC). Such features required additional resources, especially in terms of processor cycles, as well as a more complex programing and debugging process. Hence there was a need to thoroughly revise and refine the principles defining version 1.0 of the methodology. Thus, the main objective of this work is to define an improved version, hereinafter referred to as version 2.0. Particularly, the specific objectives include testing version 2.0 and comparing the results to version 1.0.

This paper therefore presents the new event-driven, patterns-based methodology and discusses the lessons learned from a 3-year experience using the previously proposed methodology. The new software architecture, along with the enhanced methodology, is presented in Section 2. Results are provided in Section 3. A comprehensive discussion of the results is conducted in Section 4. Finally, conclusions are drawn in Section 5.

The X73PHD standard is aimed at providing an interoperable interface between PHDs and gateways (also referred to as “agents” and “managers” in X73PHD, respectively). To do that, X73PHD specifies an application layer for this agent-to-manager point-to-point communication based on the concepts of the Domain Information Model (DIM), the service model, and the Finite State Machine (FSM). On one hand, the DIM is an object oriented static model that represents data managed by agents. On the other hand, the service model and FSM define the dynamic behavior that allows managers to interoperate with agents and access their DIMs. The X73PHD family is mainly specified in the optimized exchange protocol (X73-20601) and PHD specializations (X73-104yy). The former defines a general framework and a general PHD model to virtually define any possible PHD configuration, whereas the latter detail particularizations of the general model to a specific class or type of PHD (such as blood pressures, thermometers, medication monitors, etc.).

The interactions between the agent and the manager can be observed in the transport layer as application protocol data units (APDUs). The APDUs are usually generated for each transaction of DIM-related objects and attributes. Nevertheless, considering a specific agent configuration and a specific type of APDU, many parts of the APDU are fixed in position (offset from APDU's beginning) and content. Most of these fields are a consequence of using medical device encoding rules (MDER) encoding and meta-information included in Abstract Syntax Notation One (ASN.1) structures and they can be computed very efficiently without needing to encode/decode the whole APDU. For example, length fields can be obtained as the remaining length of the APDU. Others would be directly generated from the measurements (value and time stamp). In this context, the authors defined the APDU-pattern as a set of rules that can be used to analyze and synthesize a specific type of APDU in a specific agent configuration. The patterns-based methodology is based on this concept to limit the overhead due to APDU management.

Version 1.0 of the patterns-based methodology and the high level software architecture is shown in Fig. 1(a), lying between the application and transport layers. In this figure, the influence of the IPC and threading module is shown, which adds complexity and need for resources. In this paper, an evolution of this concept is presented. The new software architecture (version 2.0) is shown in Fig. 1(b), also lying between the application and transport layers. In this new version, the dependency with the IPC and threading module has been eliminated. The application layer adapts agent inputs to the X73PHD Kernel. The Pattern Library logically represents the collection of APDU patterns for an agent configuration as mentioned above. The X73PHD Kernel manages the X73PHD protocol state, analyzing and synthesizing APDUs in an X73PHD communication, as defined by the Pattern Library. This program is driven by the application layer and manages the transport layer. The transport layer interface provides methods to the X73PHD Kernel to initiate a connection procedure, to stop a connection, to abort it, to send and APDU and to receive APDUs. There can be several reliable or best effort channels, which are used according to the X73PHD core document (ISO/IEEE11073-20601).

The idea of APDU patterns is useful to explain the fundamentals of the patterns-based methodology. Nevertheless, in terms of software, the Patterns Library is usually embedded into the analysis and synthesis source code, making them difficult to be differentiated. There are three main algorithms, which manage the X73PHD. These correspond to the APDU analyzer, the APDU synthesizer, and the FSM module, which, in the new version of the methodology, are implemented using the event-driven paradigm and the programing style defined below. In this way, an event is fully processed at once by the main thread.

In version 2.0, the APDU analyzer is implemented as a single function. The analysis handler checks the incoming APDUs to extract the relevant information without changing the state of the X73PHD stack. That is to say, it summarizes the APDU that is later post processed by the FSM. The algorithm uses decision trees to reduce latency (in comparison to version 1.0). A conceptual diagram representing an example of a hypothetical analyzer is shown in Fig. 2
                        . The root of the tree is the start point of the analysis. As the analysis algorithm advances in the tree, it processes the APDU as indicated by its nodes. Forks in the tree represent choices at run-time. A leaf determines a type of APDU. When the algorithm reaches the leaf at run-time, the analysis is concluded and the information is sent to one of the FSM handlers. The whole set of branches between the root and a leaf identifies an APDU-pattern. Moreover, APDU patterns may overlay (see Fig. 3
                        ). When it happens, they share a branch in the tree (from the root to a given intermediate node).

The correctness of the APDUs is checked throughout the whole process. Each field of the APDU is analyzed for correctness (comparing it with a fixed value or against a range of values), as well as to extract relevant information to temporal variables. When the checking fails, an error indicating the reason is given to the controlling layer. If it succeeds, the temporal variables are passed to the calling code using callbacks.

In terms of C language, tree's branches are implemented using switch-case structures. Fields in the middle of forks are matched against X73PHD where possible. An example of the core for the analysis handler is show below. There are several interesting points there:
                           
                              1)
                              Memory alignment: APDUs fields that expand two or four bytes start at even or 4-multiple positions.

Function parameters: the APDU analyzer is basically implemented as a function, receiveApdu, with three parameters passed from the network layer. These parameters are the transport channel id (an integer), where the APDU was received, the buffer holding the APDU (APDU field in Listing 1
                                 ), and its length in bytes (bytes field 1). The channel id can be omitted in most cases where there is just one transport channel in use (as in Listing 1).

Return value: the return value indicates the calling code that must be released by the memory in which the APDU is allocated. This is passed as parameter once the function returns. This is useful in cases where the application needs to hold the APDU in memory after the analysis function returns for later processing.

Preprocessor macros: the macros are defined for the sake of clarity in order to limit the verbosity of the code. APDU16 provides a shortcut to load a 16-bit integer from the APDU. REQUIRE is used to check APDU length requirements. This macro is used in tree branches to check whether there are enough bytes in the APDU to process that branch. DYN_SIZE and FIXED_SIZE are used to check the length values within the APDU. DYN_SIZE calculates the length value from the parameter passed to the function. ARRAY is a shortcut to match some bytes of the APDU with the bytes in a buffer.

APDU post processing: the results of the analysis are passed to the rest of the program using callbacks. When this algorithm gets to a leaf, the variables gathered during the process are passed as parameters (e.g. handleRxAbort, handleRxAssocResponse). If an error is found during the analysis (either syntactically or semantically), the condition is noticed using special callbacks (e.g. handleBadlyStructuredApdu, handleBadProtocol).

In version 2.0, the APDU synthesizer is implemented as an event handler which generates the content of the APDU unambiguously from the passed parameters. The algorithm followed by the function can be represented by a decision tree, as in the analysis handler case. An example is shown in Fig. 4
                        . The root of the tree is the starting point of the synthesis. As the algorithm walks the tree, it selects some branches over the others. Each branch contains the instructions (APDU-pattern) to generate a part of the APDU. When a leaf is reached, the APDU synthesis process is completed.

The tree takes the apduId parameter to identify the path to a leaf that represents the complete APDU. The synthesis handler is implemented as a function with the following features:
                           
                              1)
                              Parameters: the function has three fixed parameters followed by a variable number of parameters. The first parameter, apduId, is a variable length vector of 8-bit integers identifying the APDU to be generated (see Fig. 2). In terms of the C language example, the integers allow the selection in switch-case structures. The second parameter is the length of the APDU. The length is calculated previously by the calling function, because that function knows which APDU is generated and it can infer its length easily. The third parameter is a pointer to the buffer where the APDU is being stored. This buffer is managed by the calling code, including its previous allocation in the heap.

Return value: the synthesis function returns no value. It assumes that the parameters provided by the calling code are correct and generates the proper APDU according to them. The calling code is responsible for the correctness of the parameters.

Macros: the synthesis handler defines several macros to make the code easier to be understood. Some of these macros are PACK_U16 (network byte order conversion and store in the APDU), PACK_DYN_SIZE (store of length field, calculated using the length parameter), and PACK_OBSERVATION_SCAN_LIST (a shortcut to call the pack observation scan list method).

Dynamic values: they are dynamically generated from structures in random access memory (RAM). These are generated using functions that deal with these structures. In the example, the pack observation scan list function is used to fill the event report data. This function has an observationScanList parameter that represents a linked list of measurements, i.e. a compact representation for Metric instances.

Additional variable length list of parameters: depending on the apduId, the variables that need to be passed are different. For example, no additional parameter is required to generate an association request, but, in the case of the data event report, several arguments are required. These include the invokeId (request Invoke-ID), the relativeTime (Relative-Time of the event report), and the eventData (the reported data containing measurements). All these additional parameters are passed in a variable argument list.

The FSM module manages the changes in the state and all related information, as it did in version 1.0. In version 2.0, the FSM module is implemented following an event-driven model where each event is implemented as a function (event handler). Such functions handle the state and the order of operation execution. States in this component are obtained from X73PHD stack equivalents.

For instance, the handleRxAssocResponse handler in the example of Fig. 2 is triggered by the analysis handler when it matches an association response (see Listing 1). In that case, for example if the result was accepted(0), the handler changes the state of the FSM to the operating state. In other case, if the result is accepted-unknown-config(3), the handler sends a configuration event report. The handler internally calls the fsmStateChange function, which is used to notify state changes.

The startNotiConfirmedFixed handler in the example of Fig. 2 is called by the FSM to initiate an EVENT service procedure. As it can be seen, it uses a different state variable that handles the state of the EVENT service. The createInvokeId function is used to allocate a structure that holds temporally the information of the request, associated with an Invoke-Id (Listing 2
                        ).

Version 2.0 of the methodology has been tested in different devices and microcontroller architectures, in a testing set-up analogous to that carried out with version 1.0:
                           
                              -
                              Testing devices. In order to test the concepts proposed in this methodology, several X73PHD specializations – an Electrocardiogram (ECG) recorder [11], a blood pressure monitor (X73-10407 [12]), a thermometer (X73-10408 [13]), and a weighing scale (X73-10415 [14]) – were implemented. These PHDs implement the same DIM, service model and FSM as those PHDs tested in version 1.0. Some other elements, which are not part of any standard configuration, were also tested, including: agent and manager initiated requests, persistent metric store and scanner object implementation, and multiple transport channels, among others. The numeric results shown in the subsequent subsections may be used to estimate other implementations. The standard weighing scale configuration (ID 1500) was selected as the reference implementation. It serves as a base and can be extended to other more complex configurations. In addition, the hardware that can be found in a low-cost weighing scale has similar features that the hardware used for most low-cost, wireless devices.

A conceptual diagram of the reference implementation architecture was shown in Fig. 1. The weighing scale specialization is implemented using the buffered input/output approach proposed in [15]. The implementation uses C standard library functions malloc() and free() as methods for dynamically allocating and deallocating buffers. The implementation assumes that the transport layer provides a single reliable channel and no best effort channel is needed. Measurement buffering has not been implemented, hence only one measurement is sent in each event report.

Microcontroller architectures: The source code was compiled on different microcontroller architectures including 32-bit ARM7TDMI (LPC2294), 16-bit (MSP430) and 8-bit 8052 (ADuC841). The ARM7TDMI architecture was selected for footprint comparison purposes, since it is widely used for 32-bit microprocessors.

@&#RESULTS@&#

The results of this new version of the methodology are shown in this section. Two main key issues have been considered: memory consumption and processor usage.
                        
                           1)
                           Memory consumption: the results of memory consumption obtained are shown in Fig. 5
                               and in the upper area of Table 1
                              . Read-only (RO) code field corresponds to the segment of the program's instructions, and RO data field to the segment of the program's constant data. Read-write (RW) data correspond to program variables and modifiable memory used by the program. RW data does not consider heap allocations. Its size has to be estimated for the destination application. The two biggest APDUs are taken, in order to calculate worst case estimations. In the case of this implementation, the largest APDU corresponds to the MDS – attribute response which requires as much as 114 bytes (6 attributes are implemented). The second largest APDU corresponds to an Event-Report-Noti-Config request which requires 72 bytes. Then, an approach for the smallest heap footprint introduced by the implementation due to the X73PHD stack (referred to as S
                              min), should be:
                                 
                                    (1)
                                    
                                       
                                          
                                             S
                                             
                                                min
                                             
                                          
                                          >
                                          114
                                          +
                                          72
                                          =
                                          186
                                           
                                          bytes
                                       
                                    
                                 
                              As shown in Table 1, the memory consumption in version 2.0 has experimented an 11.59% decrease (mean value) compared to version 1.0.

Processor usage: regarding processor usage, the cycles required to complete some key operations have been calculated (see Fig. 6
                               and lower area of Table 1). The operations include:

The analysis of the most significant incoming APDUs such as the association response APDU (A), the configuration event report response APDU (B), the get all Medical Device System (MDS) attributes response (C), and the data event report response (D).

The synthesis of the most significant outgoing APDUs such as the association request APDU (E), the configuration event report request APDU (F), the get MDS attributes request (G), and the data event report request (H).As shown in Table 1, the processor usage (measured in terms of latency) in version 2.0 has decreased 45.95% compared to version 1.0.

@&#DISCUSSION@&#

This section is divided into two parts. The first part of the discussion is focused in the quantitative outcomes drawn as a result of the analysis of memory consumption and processor usage. In the second part, the main improvements and the implications thereof are discussed.

The results on memory consumption and processor usage shown in Section 3 are discussed below:
                           
                              1)
                              Memory consumption: as shown in the upper rows of the second-to-right most column of Table 1 (and Fig. 5), RO code in version 2.0 has decreased 24.49% compared to version 1.0. This is due to the simplification of both the analysis and synthesis algorithms as well as the low requirements of event-driven architecture, since there was no need to include code to IPCs. RO data and RW data have grown instead (13.29% and 18.64%, respectively). This is due to the new programming style. Many fixed APDU parts are defined as constant buffers in RO data, which increases RO data footprint but simplifies the program, finally reducing the RO code. In addition, the event-driven model requires serving an event at once, which usually entails chaining several function calls. Thus, the compiler is not allowed to release stack memory until such functions run in their entirety. The heap was not used in version 1.0 and in version 2.0 takes a small amount of bytes (186) used to store APDU buffers temporally. The use of the heap is mandatory in this event-driven architecture, but it provides other advantages, such as the easiness of programing and debugging process. The overall memory consumption has decreased in 11.59%. This implies that the new balance of memory consumption produces a noteworthy enhancement, as compared to the previous version of the methodology, even though some operations require more memory. These data are mean values, but similar outcomes can be expected for comparable agent configurations.

Processor usage: as shown in the lower rows of the second-to-right most column of Table 1 (and Fig. 6), the processor usage (measured in terms of latency) in version 2.0 has decreased in all operations, ranging from 37.32% to 53.36%, thus producing an overall reduction of 45.95%, which is a substantial decrease. This is due to the use of an event-driven architecture. In the version 1.0, the APDUs are processed byte-by-byte in order to limit buffering needs, Nevertheless, that approach imposed an extra CPU overhead due to context switching between tasks. However, in this new approach, APDUs are buffered and processed at once, which reduces the total CPU usage. The main implication of this reduction is a longer battery duration (i.e. higher autonomy), especially in those specializations that process big amounts of data, such as ECG, etc. Again, the data shown here are mean values extracted from the experiments performed, but straightforward extrapolation can be applied to other comparable agents.

The main overall improvement of version 2.0, as compared to version 1.0, is the definition of new event-driven-based algorithms used in the APDU analyzer and the APDU synthesizer and the FSM module, compared to the multitasking approach used in version 1.0. As a consequence, the following enhancements have been introduced:
                           
                              -
                              The new algorithms – analysis, synthesis, and FSM handlers – are now methodologically defined. This therefore enables an automated implementation of the methodology, which in turn limits development time and cost.

The clear role separation on the analysis, synthesis, and FSM handlers makes them more reusable.

The step-by-step definition of the methodology has been improved.

The use of tasks is no longer needed. Therefore, there is no need for multitask functionalities (corresponding to multithreading and IPC module in version 1.0) and its overhead can be avoided.

Events are fully processed at once. Therefore, the algorithms used in the analysis and synthesis handlers are faster as they do not require context switching between threads.

More specifically, the improvements of each of the parts of the system – analysis, synthesis, and FSM handlers – are discussed as follows. Compared to the version 1.0, the following enhancements have been introduced in the analysis handler:
                           
                              -
                              The entry point to this module is now unique. In addition, a function that uses the APDU as input has been defined and implemented. Finally, this module is implemented as a stateless function.

The novel, straightforward implementation based on switch-case structures to analyze the APDUs produces faster executable machine code, since the C compiler would be able to optimize further.

Compared to version 1.0, the following enhancements have been introduced in the synthesis handler:
                           
                              -
                              The unique entry point is a function that uses the APDU path within the synthesis tree and the variables needed to fill the variable content gaps. In addition, the module is implemented as a stateless function.

Similarly as in the analysis handler, the implementation is based on switch-case structures. Therefore, the machine code required to synthesize the APDUs from the APDU path runs faster.

Compared to version 1.0, the following enhancements have been introduced in the FSM module:
                           
                              -
                              The FSM module has been defined as a collection of handlers that are specialized to process a specific event.

The new programing style allows the FSM both to implement several versions of the X73PHD standard and to easily incorporate several configurations within the agent.

Finally, the version 1.0 was limited to incorporate unit testing due to the tight coupling between modules and the use of threading. The new event-based architecture established in version 2.0 simplifies the integration of unit testing. An open source framework was used to test the analysis, synthesis and FSM handlers separately for every agent tested [16]. The analysis handler was tested to analyze a wide set of correct and incorrect APDUs and to generate the correct event. Then, synthesis handler was tested to generate the APDUs that the agent may need. Last, the FSM handlers were tested to handle and process any possible event that could happen in the agents and to generate the correct output (i.e. function calls and arguments).

@&#CONCLUSIONS@&#

An event-driven evolution of the previously defined pattern-based methodology for the development of X73PHD-compliant PHDs has been developed, implemented, tested and compared to the previous version. The results showed that, following the newly defined guidelines, the memory consumption decrease in 11.59%, while the latency is reduced in 45.95% (mean values). In addition, the improvements incorporated in this new version, such as clearer separation of roles, removal of threading, and simpler integration of unit testing, may result in limited likelihood of programing errors, removal of unnecessary overheads, faster analysis and synthesis of patterns, easier testing and debugging as well as they enable the automated implementation of PHDs. Therefore, this novel approach significantly reduces development costs and time-to-market as compared to version 1.0, which helps in promoting the adoption of standards in PHDs.

The authors declare that they have no conflict of interest.

@&#ACKNOWLEDGMENTS@&#

This work was supported in part by NAsisTIC, project IIM14089.RI1 (Government of Navarra, Spain). The work of J.D. Trigo was supported by the Public University of Navarre under project Res. 637/2014.

@&#REFERENCES@&#


@&#MAIN-TITLE@&#Analysis of eligibility criteria representation in industry-standard clinical trial protocols

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           We compare textual complexity of full-text and ClinicalTrials.gov (CT) protocols.


                        
                        
                           
                           We use cosine-similarity measures to identify clusters for standardization.


                        
                        
                           
                           We find that CT protocols are very condensed and convey lesser information.


                        
                        
                           
                           Developing a template set is feasible and could lead to efficient criteria design.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Clinical trials

Information retrieval

Natural language processing

Controlled vocabulary

Eligibility determination

@&#ABSTRACT@&#


               
               
                  Previous research on standardization of eligibility criteria and its feasibility has traditionally been conducted on clinical trial protocols from ClinicalTrials.gov (CT). The portability and use of such standardization for full-text industry-standard protocols has not been studied in-depth. Towards this end, in this study we first compare the representation characteristics and textual complexity of a set of Pfizer’s internal full-text protocols to their corresponding entries in CT. Next, we identify clusters of similar criteria sentences from both full-text and CT protocols and outline methods for standardized representation of eligibility criteria. We also study the distribution of eligibility criteria in full-text and CT protocols with respect to pre-defined semantic classes used for eligibility criteria classification. We find that in comparison to full-text protocols, CT protocols are not only more condensed but also convey less information. We also find no correlation between the variations in word-counts of the ClinicalTrials.gov and full-text protocols. While we identify 65 and 103 clusters of inclusion and exclusion criteria from full text protocols, our methods found only 36 and 63 corresponding clusters from CT protocols. For both the full-text and CT protocols we are able to identify ‘templates’ for standardized representations with full-text standardization being more challenging of the two. In our exploration of the semantic class distributions we find that the majority of the inclusion criteria from both full-text and CT protocols belong to the semantic class “Diagnostic and Lab Results” while “Disease, Sign or Symptom” forms the majority for exclusion criteria. Overall, we show that developing a template set of eligibility criteria for clinical trials, specifically in their full-text form, is feasible and could lead to more efficient clinical trial protocol design.
               
            

@&#INTRODUCTION@&#

Clinical trials are an intrinsic part of the medical research and drug development process of most pharmaceutical and biotechnology companies. Policy makers and governmental organizations are also naturally interested in evaluating the efficacy, accuracy and safety of drugs trials that could potentially affect millions of people around the world. Eligibility criteria in clinical trials are a set of requirements that a patient or participant must meet to be eligible for inclusion in a study. From the perspective of a study sponsor, these requirements ensure that all participants in a cohort satisfy some general criteria and thus give a higher confidence in predicting possible outcome of an intervention.

Eligibility criteria are usually expressed in human-readable free-text which is easily comprehensible to patient, public and researchers alike. However this form of representation of eligibility criteria makes it challenging for computable and standardized representation. Currently, there are no data or terminology standards for representing or authoring eligibility criteria in a standard format [1–3]. Given the plethora of applications of eligibility criteria, ranging from criteria reuse to patient matching from Electronic Medical Records (EMR) [4,5] it is of great importance to address the problem of computable knowledge-based representation for eligibility criteria. The primary motivation of our study is to determine the feasibility of creating a set of standard representations of eligibility criteria that would be applicable to a broad set of clinical trials. Uniformly represented eligibility criteria can facilitate the process of identification and merging of similar patient populations across studies for the purpose of patient recruitment. Consequently, this can reduce not only the time spent in performing trials that have already been conducted under similar conditions but can also help in reducing the expenses associated with participant recruitment substantially. Secondary outcomes of interest would be easier encoding of eligibility criteria to find patients via EMRs, faster and accurate authoring of eligibility criteria, and higher quality protocols. For example, a standardized representation of an eligibility criterion could be linked to a specific, standard set of ICD-9 codes that could then be used as filters to identify patients across EMR systems.

We begin by comparing the textual and characteristic differences of industry-standard full-text protocols to corresponding protocols from ClinicalTrials.gov (CT) [6], a registry of clinical studies from around the world. We then explore methods for deriving computable and standardized representation of eligibility criteria, in the form of templates, from a set of full-text and CT protocols used in Pfizer’s pain medication-related studies.

Our contributions in this paper are two-fold. First, we explore the nature of representation of eligibility criteria from industry-standard full-text protocols and compare their characteristics to corresponding CT eligibility criteria. Second, we propose a novel method for standardized representation of eligibility criteria (using sentence similarity and clustering strategies) in the form of “templates”. To the best of our knowledge, this is the first study in the domain of standardized representation of eligibility criteria that deals with in-depth analysis of eligibility criteria characteristics in their full-text form. Most related research deal with considerably simpler and concise eligibility criteria from CT.

Computable clinical trial protocols and corresponding eligibility criteria representations have been studied extensively in the past two decades. Studies have been conducted to identify a set of common data elements that can be used for developing standard protocol representation [7]. There have been attempts to use natural language processing for parsing eligibility criteria statements to extract generic query patterns for eligibility criteria representation [8,9]. Research has also been focused on the identification of Unified Medical Language System (UMLS) - based [10] semantic classes for criteria statements [11,12]. The complexity of eligibility criteria representation has also been studied quantitatively with significant proportion of criteria being judged semantically complex [13].

There have been extensive studies in computer-based and formal eligibility criteria knowledge representations. A CDISC-sponsored project called ASPIRE [14] aims to provide formal representation of a core set of eligibility criteria and also provides a set of data elements which can be used for searching and filtering protocols. The Eligibility Rule Grammar and Ontology (ERGO) [15], uses an information model, composed of noun phrases, expressions and criteria, to provide a general syntax for representing eligibility criteria. The EliXR system [3] provides a semi-automated data-driven approach for semantic representation of eligibility criteria. It uses an integrated semantic processing framework based on UMLS for eliciting semantic role labels that can be used for annotating eligibility criteria. The Standards-Based Active Guideline Environment (SAGE) [16] provides a set of structured and standard terminologies for encoding computable guidelines into structured templates. The Clinical Research Filtered Query (CRFQ) Project [17] provides a standardization of criteria using various semantic parameters like demographic data, disease data, etc. The use cases of these systems vary from filtering trials satisfying particular conditions to the identification of patients for a protocol.

Previous research [18] has demonstrated the benefit of using a set of disease-categorized protocols for designing efficient clinical trial authoring tools. Significant research has also been conducted in developing decision support systems for clinical trials. Expert systems like the protocol inspection and critiquing tool (PICASSO) [19] support critiquing of clinical trial protocols and can be used to standardize new protocols. Knowledge-based decision support systems like Design-a-Trial (DaT) [20] help efficient creation of rigorous protocols documents for designed trials. The ontology-based system, TrialWiz, [21] designed to alleviate the complexity of the protocol encoding process can be used for easy authoring of clinical trial protocols. More advanced authoring tools that facilitate collaboration of protocol authors from different backgrounds have also been proposed [22]. Other than these applications, several open-source (e.g. OpenClinica [23]) and proprietary (e.g. Cytel [24], Medidata [25]) software have also been designed for assisting or automating the clinical trial protocol design process.

Although several of the above mentioned tools and applications have been developed for standardized and computable representation of eligibility criteria few can deal with the complexity of eligibility criteria as presented in full-text protocols. Most of these applications [13–15] are either semi-automated or designed using CT protocols. They still require intense manual involvement and lack flexibility for accommodating complex eligibility criteria from full-text protocols. While these tools may be capable of generating computable and knowledge-based representation of basic eligibility criteria, their utility, usability and adoptability to eligibility criteria from industry-standard protocols have not been tested rigorously. We also note that the use of automated tools for criteria standardization has very limited uptake in the industry as few of them cater to the complexities of full-text protocols. Therefore, we perform a detailed comparison of eligibility criteria representation from CT and Pfizer’s clinical trial protocols and propose a novel method which can be used for industry-standard standardization. In contrast to several of the above mentioned tools, our template-based standardization approach caters to criteria reuse, which is a major objective in most pharmaceutical companies [26].

In this paper we present an analysis of eligibility criteria from full-text and CT protocols across 3 dimensions. First, we compare the representation characteristics and textual complexity of eligibility criteria from full-text and their corresponding CT protocols. Second, we perform a semantic class-based comparison of these two forms of eligibility criteria representation. Finally, we generate templates based on a novel method for industry-standard full-text protocol standardization.

We selected a set of 32 full-text clinical trial protocols in the domain of Pfizer’s pain-related drug research designed between the years 2002 and 2009. In a majority of these studies, the primary objective was to evaluate the efficacy, safety or tolerability of the drugs in various patient groups under different conditions for pains related to diabetic neuropathy, total-knee arthroplasty, fibromyalgia, osteoarthritis, etc. We used the study identifier of the full-text protocols to retrieve the 32 corresponding XML-formatted protocols from CT, which currently houses over 120,000 clinical trial protocols [6]. Organizations that sponsor or conduct clinical trials are required to submit study information to a clinical trial registry like CT if they plan to publish the findings in a major journal. We wanted to compare eligibility criteria from Pfizer’s full-text clinical trial protocols with the corresponding protocols retrieved from CT to assess the characteristic differences between the representation of CT and full-text. In essence, this will inform us of the complexity and processing overhead in terms of computational methods used for various studies on eligibility criteria (such as standardized representation).

We first compared the representation characteristics of the eligibility statements of the full-text and CT protocols from our dataset. We then compared the textual complexity of the “Eligibility Criteria” sections of the full-text protocols with the corresponding study protocols downloaded from CT. We use cumulative and average word counts and sentence counts for this purpose.

We analyze the eligibility criteria representation across 32 full-text protocols and their corresponding CT protocols, representing a cross-section of Pfizer protocols in the pain therapeutic area. Our goal here is to develop a sentence-similarity based approach to identify groups of similar sentences having similar conceptual properties but different textual representation across various protocols. Fig. 1
                         shows the underlying algorithm for this process.

In this step we converted all the full-text PDF files to their corresponding text format using standard conversion tools. The converted text files were verified to not contain Optical Character Recognition (OCR) errors. These files were then parsed using regular expressions to identify the “Eligibility Criteria” sections. Each “Eligibility Criteria” section was further segmented into Inclusion and Exclusion Criteria for further processing. Similar pre-processing was also performed on the XML files from CT.

The Inclusion and Exclusion criteria sections for both the full-text and CT protocols generally comprise of related but disjoint sentences grouped together. These were segmented into sentences using a maximum entropy-based sentence boundary detector, MxTerminator [27]. However, since some criteria sections (appearing as bulleted lists) did not end with periods, we had to follow additional steps to split such sections. On the other hand, separated sentences which were in fact coherent and represented continuing ideas had to be coupled together as a single unit.

In this step we processed the individual sentences obtained from the previous step using the National Library of Medicine’s MetaMap program [28]. MetaMap can identify coherent words and phrases from a particular sentence and map them to Unified Medical Language System (UMLS) metathesaurus concepts. We then compared each sentence with every other sentence in the pool of criteria sentences and identified the ones where all the UMLS concept identifiers (CUI) matched exactly. This process helped in ironing out the minor differences in similar sentences with identical concepts but different representations. Word to word matching of sentences was not employed here because even the subtle variability in spelling or sentence structure could not be handled by using that method. The output of this step is a set of sentences that are identical to one or more sentences. Box 1
                            shows the advantage of using MetaMap similarity over simple word to word matching based identical sentence detection. For Sentence 1, we can see that the versions 1 and 2 represent the same criteria, except with different values for a specific test (Creatinine clearance). For Sentence 2, ‘less than’ has different representation in the two versions. Also the screening values for platelet count, which are identical in essence, are represented in different format in the two versions. Using concept matching of MetaMap we can overcome these minor structural, grammatical or numeral variations to elicit the fundamental similarities between sentences. The importance of such abstraction has also been explained previously. The set of remaining sentences, classified as non-identical, are processed in the next step.

In this step we identify similar sentences from the set of non-identical sentences using cosine similarity [29]. While cosine similarity has been used extensively for clustering similar sentences and documents [30–33], it has not been explored in the domain of eligibility criteria standardization. For this purpose we create an index of all non-identical sentences using the SMART information retrieval system [34]. Each sentence is treated as an individual record and cosine similarity is calculated with every other sentence in the pool. SMART, based on a vector space model, represents each sentence as a vector of words with different weights associated with each term of a sentence. Standard preprocessing steps like stemming and stopword removal were executed before calculating the cosine similarity of sentences. The cosine measure of similarity for length-normalized pair of vectors q and di
                           , where q represents a query and di
                            represents a document set,

is calculated as follows: 
                              
                                 
                                    sim
                                    (
                                    q
                                    ,
                                    
                                       
                                          d
                                       
                                       
                                          i
                                       
                                    
                                    )
                                    =
                                    
                                       
                                          
                                             
                                                ∑
                                             
                                             
                                                j
                                                =
                                                1
                                             
                                             
                                                t
                                             
                                          
                                          
                                             
                                                w
                                             
                                             
                                                qj
                                             
                                          
                                          
                                             
                                                w
                                             
                                             
                                                ij
                                             
                                          
                                       
                                       
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   
                                                      t
                                                   
                                                
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      qj
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                          ×
                                          
                                             
                                                
                                                   
                                                      ∑
                                                   
                                                   
                                                      j
                                                      =
                                                      1
                                                   
                                                   
                                                      t
                                                   
                                                
                                                
                                                   
                                                      w
                                                   
                                                   
                                                      ij
                                                   
                                                   
                                                      2
                                                   
                                                
                                             
                                          
                                       
                                    
                                 
                              
                           
                        

Here wqj
                            and wij
                            are the term weights for the vectors q and di
                            represented as t-dimensional vectors. In our case, query q is a given criteria statement which is compared to the document set di
                            represented as a pool of the criteria statements (not including q).

In SMART we select the standard atc term weighting scheme. Here a represents the term frequency component and is calculated as an augmented term frequency, t represents the collection frequency component and is calculated as the inverse document frequency, while c represents the normalization component calculated as the cosine normalization. A set of similar sentences can be, in essence, treated as a coherent cluster.

In this step we select sentences which are similar to a particular sentence. A threshold similarity score of 0.5 (selected on an empirical basis) is used for selecting similar sentences. For each sentence in the pool we find a cluster of similar sentences. A sentence included in a particular cluster is eliminated for inclusion in any other cluster. A higher similarity score threshold gives fewer similar sentences and hence greater number of clusters while a lower similarity score gives more similar sentences clustered into fewer groups. Since an absolute threshold scores does not always result in perfect sentence clusters, we used a post-processing step where each cluster of similar sentences was manually verified to not contain unrelated sentences. Further, clusters were merged based on overlapping or associated ideas. Overall our clustering method with fixed clustering threshold performed well and only 10-20% of the sentences from the inclusion and exclusion criteria had to be manually reassigned for full-text or CT criteria. We found this approach and threshold scores reasonable for our study. Given the complexity of the eligibility criteria sentences from our full-text protocols we did not find any automated tools or applications appropriate for standardization. If a particular sentence does not have any similar sentences (based on the criteria defined above), we consider that sentence to be the only entity in that cluster. Such sentences are assumed to form singleton clusters. A sample clustering of sentences is shown in Fig. 3. In this example, sentences 1, 2 and 4 are detected as similar sentences in one cluster while sentences 3 and 5 are detected as similar sentences in a different cluster. However based on the criteria defined above, we merged these clusters together in the post-processing step. This gave us five sentences which have different textual characteristics and representation but linked by the same underlying concept. Thus the sentence clustering step helped us identify the variability in representation of eligibility criteria. This forms the basis of our standardization approach for eligibility criteria which preserves the underlying properties of each sentence cluster while providing an abstraction of the finer details. For a cluster of sentences, we first identify the key concepts (e.g. diseases or symptoms, pathological tests, therapies or surgeries, etc.) represented in the set of inclusion and exclusion criteria. We then identify the range of values (if any) that correspond to these concepts and represent those with a variable while preserving the units associated with such values. These elements are then manually structured in the form of a template.

The identical sentences and the sentence clusters obtained from the previous steps were manually labeled using the semantic classification of clinical research eligibility criteria identified in [11,12]. It is important to note here that the semantic classes used for labeling the sentence clusters were derived only from [11,12] and no extraneous semantic classes were introduced for sentence classification. A total of 27 semantic classes under 6 topic groups were used as reference. For example, the topic group “demographics” contains six semantic classes, namely, address, age, literacy, gender, ethnicity, and special patient characteristics (for details on the other topic groups refer to [11,12]).

@&#RESULTS@&#

We compared the representation characteristics of the eligibility statements from the full-text and CT protocols from our dataset. We found that the criteria statements from the CT protocols are more concise than the corresponding statements from the full-text. The CT protocol statements generally provide a high level abstraction of the detailed representation of the full-text protocols. In Box 2
                        , we compare the statements of CT protocols with matching statements from full-text protocols.

Statements I1, I2 and E1 represent the two inclusion criteria and the only exclusion criteria for one of the CT protocols and corresponding statements from the full-text protocol. Statements I1 and I2 of the CT protocol are both simplified versions of their corresponding full-text protocol statements. Though these statements contain the gist of the criteria under discussion, the CT eligibility criteria are an abstraction of the details provided in the full-text. Similarly, the statement E1 of the CT protocol conveys the same idea as the full-text without elaborating on the details. However, we note that several critical eligibility statements are not included in the CT protocols. For example, inclusion criteria (such as “A score of ⩾40mm on the visual analog scale (VAS) of the Short-Form McGill Pain Questionnaire (SF-MPQ) at baseline (V1 and V3)”) or exclusion criteria statements (such as “Have had a malignancy other than basal cell carcinoma within the past 2years”) that provide finer details for patient selection are omitted in the CT protocols. While explicit representation of these details is not a mandatory requirement for CT postings, research on computational methods for studying eligibility criteria generally gloss over these inherent complexities [4]. In particular, full-text protocols would provide a more challenging setting for text mining or natural language processing tasks compared to the CT protocols.

Overall, we found that the eligibility criteria sections of study protocols from CT are considerably shorter compared to the corresponding full-text version. The number of inclusion and exclusion criteria in a typical full-text protocol is almost 5 times greater than the corresponding CT protocol (the total number of inclusion and exclusion criteria sentences from full-text protocols are 374 and 712 versus 100 and 169 from CT protocols). For the 32 protocols the average word count for the CT eligibility criteria sections was 150 words compared to 982 words of full-text protocols. The lowest word count for CT protocols was 14 while the highest was 737. For the full-text protocols the lowest word count was 425 while the highest was 2007.

From Table 1
                         we can see that even though exclusion criteria in CT protocols have more words than the corresponding inclusion criteria, the difference in their word count (12%) is lesser compared to the corresponding full-text protocols (40%). It is also important to note that the inclusion and exclusion criteria from CT protocols encompass only a small fraction (22% and 12%, respectively) of the actual textual content of the full-text protocols.


                        Fig. 2
                         presents the word count of each full-text protocol along with the word-count of corresponding CT protocols. The distribution of word count for the inclusion and exclusion criteria are also shown within each stacked bar. The chart has been sorted by the total word count of full-text protocols from left to right. Interestingly, we see no overall correlation between the word count of full-text protocols and CT protocols. Sparing a few cases (e.g. Protocol #1), higher word count of full-text protocols does not ensure high word count of corresponding CT protocols. It is important to note here that CT protocols, intended for recruitment, and the full-text criteria, intended for actual enrollment, have different audiences and purposes. Hence there might not be any apparent correlation between the authoring styles or word-counts of these two types of representations.

Following the methods outlined in Section 3.3.3, we studied the distribution of identical and non-identical sentences from the inclusion and exclusion criteria for full-text and CT protocols respectively (Table 2
                        ). We note that the percentage of identical sentences in the inclusion criteria for full-text protocols (44%) and CT protocols (30%) is significantly more than identical sentences in the exclusion criteria (8% and 22.5%). The primary reason for such difference in distribution is the greater variability of criteria in the exclusion section. In our dataset we noted that inclusion criteria from full-text or CT follow a more standard approach in defining screening conditions. For example, criteria statements on demographic information (age, gender, ethnicity, etc.) or ethical considerations (consent or compliance with study) have the least variability in the inclusion criteria.


                        Table 3
                         shows the total number of clusters identified for the inclusion and exclusion criteria sections as well as the distribution of clusters for each semantic class for the full-text and CT protocols respectively. Semantic classes such as “Capacity” or “Ethnicity” form singleton clusters for inclusion criteria for both full-text and CT protocols while “Preference” and “Compliance with protocol” form singleton clusters for both types of protocols. For inclusion criteria, the semantic class “Diagnostic and Lab Results” contains the maximum number of clusters for both full-text and CT protocols. In case of exclusion criteria, “Disease, Sign or Symptom” and “Pharma Substance and Drugs” form majority of the clusters.


                        Table 4
                         shows the classification of inclusion and exclusion criteria from Pfizer’s full-text protocols and CT protocols based on the semantic classes. The percentage of criteria statements belonging to each semantic class is also shown in Table 4. We note that some semantic classes such as age/sex
                           2
                           The classes age and gender were grouped together based on their co-occurrence in the full-text criteria statements
                        
                        
                           2
                        , ethnicity or neoplastic status are present in only one type of criteria statements. It is also interesting to note that most of the sentences in the inclusion criteria belong to the “Diagnostic and Lab Results” category while “Disease, Sign or Symptom” is the most dominant class for exclusion criteria. The distribution of different classes for the inclusion and exclusion criteria gives us an overall idea of the nature of statements present in these sections and shows the contrast in the emphasis of these two sections.

In Fig. 3
                         we consider a set of five similar sentences (numbered 1–5) having distinct properties in terms of textual and numeral representation. However all of them share the same underlying concept i.e. a threshold value for alanine aminotransferase (ALT) or aspartate aminotransferase (AST) for eligibility in a particular study. This can be abstracted in the form of a central idea around which the different representations are formed. In our example, this central idea (referred to as “template”) is “ALT or AST clinical laboratory values>
                        N times the ULN” where N is a variable. Such templates are prototypical of all the sentences in the cluster. It is important to note that this template identification is based on heuristics and can be expressed in various ways as long as it represents the core idea of the sentence cluster. Following a similar strategy we can form a template for any cluster shown in Table 3. Sample template sentences from the “Disease, Sign or Symptom” category can be found in Table 5
                        . In this table, we show the variations in terms of the number of sentences belonging to various clusters and their possible templates. The categories of diseases or symptoms they belong to are also shown. Of note, criteria often contain concrete examples such as those delineated in the “Disease, Sign or Symptom” entry in Table 4 above.

The outcome of this template-based representation process is a set of prototypes that provide generalization of the criteria statements across protocols while preserving the core concepts. Thus any eligibility criteria can be expressed with this set of predefined templates. In essence, these templates will potentially reduce the effort of a protocol designer in formulating criteria. However it is important to note here that the templates generated from the CT protocols do not match in number or complexity to those from the full-text protocols. Hence repurposing of CT templates for full-text is not feasible without loss of information. Once we have identified a set of criteria templates for a given domain (e.g. pain-related drugs) we can use such templates to design other protocols in the same domain. Identification of templates in various domains and their combination should allow us to abstract out commonly occurring templates that generally appear in most eligibility criteria (e.g. demographics, consent, etc.). We can also identify templates unique to particular domains. This type of regularity in representation will pave way for standardized and computable eligibility criteria. We also noted in Table 2 that only 8% and 22.5% of inclusion criteria in the full-text and CT protocols are identical across various studies. Identification of clusters and thereby template formation can provide significant benefits for standardized representation in such cases with greater variability. Use cases of this template-based representation can be found in research in query-based information retrieval or information extraction from full-text protocols that cater to eligibility determination. Other use cases can be found in the areas of natural language processing, expression language standards, criteria designing and criteria authoring mechanisms.

@&#DISCUSSION@&#

The comparison between CT and the full-text criteria shows the expected higher complexity in the actual trial protocols. The number of inclusion and exclusion criteria in the full-text protocols is several times greater than the corresponding CT protocols. Also each criterion from the full-text protocols is generally more elaborate and contains additional information that supplements the core information which is otherwise not presented in CT protocols. This is not surprising since CT’s purpose is mainly for general and reference information, while the full-text protocols are for actually running the trial. The impact of this finding for analyzing clinical trials, however, is that systems built over data from CT may not be sufficiently robust for analyzing full-text protocols. This is one of the primary reasons for low uptake of standardization tools, built over CT eligibility criteria, in the industry. We believe that pointing out the differences in representation of full-text vs. CT criteria will help in delineating more robust systems for industry-standard criteria standardization in the future.

As evidenced in the examples in Table 5, it is feasible to create a set of standard templates for commonly used eligibility criteria. Though there will always be unique clusters in sets of criteria, since each trial is looking to answer a unique question, ultimately one could use this set to produce a bank of standardized criteria (i.e. templates) that could be used across biomedical research. The major benefit would be simplifying authoring and quality control of protocols, as well as making the computational analysis of the text of protocols more straightforward.

Our template-based standardization strategy likely benefits from the human expertise invested in refining the clusters and assigning templates to such clusters. Since accuracy of the templates was one of the most pivotal aspects for integration into the industrial protocol generation workflow, we chose to manually curate the templates.

A major contribution of this research is the set of templates that can also be used in any protocol/criteria authoring tool. In future research we plan to test the applicability of our templates as a plug-in to an eClinical protocol designing and authoring tool.

In future work we also would like to explore better methods for finding similar sentences. Though cosine similarity does fairly well in identifying similar sentences based on word-vectors, it lacks the capability of finding semantically similar words. For such fine-grained comparison we plan to use UMLS::Similarity[35] which can determine semantic similarity between pairs of biomedical concepts. The scalability of our clustering and template generation approaches, especially, the semantic processing and knowledge representation techniques employed in our methods requires further investigation.

@&#LIMITATIONS@&#

Our study is constrained by the limited availability of full-text protocols (which is often governed by confidentiality and privacy policies of companies) from a particular sub-domain of clinical trials (namely, pain-related drugs). While our semi-automated process for clustering and template generation may not scale to 120,000 protocols [6] from diverse therapeutic areas they can at least scale to the pain therapeutic area. As evidenced in our paper, similarity of representation of eligibility criteria across these protocols points to the fact that we would have minor gains from adding many more. We also note that while our dataset is mostly company and therapeutic area specific, previous studies have pointed to presence of several common design elements, including inclusion and exclusion criteria representation, across protocols [36,37]. Since industry protocols are all made to be reviewed by the same audience (ultimately regulators like the FDA), this adds an underlying structure and thus our assumption seems reasonable that most industry protocols are structured similarly, and that there is likely as much intra-company difference as there is inter-company difference. In future research we would like to generate protocols in other domains and perform cross-domain template comparisons for gauging the generalizability of our findings. This might give us an insight into the bigger picture of clinical trial design irrespective of the domain and can ideally help us in identifying general templates versus domain-specific ones.

One of the limitations of our template based standardization is the lack of flexibility in representing temporal and certainty related constraints. We would like to explore tools for automatic identification of temporal and certainty expressions in future research [38,39]. Also the use of MetaMap for semantic concept identification may have certain limitations. Co-reference resolution and conjugated representation for drug or disease terms are not handled by MetaMap [40]. We would like to explore the extent of such issues in future research.

@&#CONCLUSIONS@&#

This research aimed at developing techniques for standardized representation of eligibility criteria from industry-standard full-text protocols. A comparison of full protocols vs. their representations in Clinicaltrials.gov supported the need for this approach, since the full protocols were generally very complex. We proposed a method built around using sentence similarity and clustering for identifying groups of similar sentence. We then proposed a novel method for template-based representation of eligibility criteria that can lead to standardization of criteria statements. A combination of these templates potentially offers a standard and formal representation of any eligibility criteria. Such template-based criteria would be amenable for computational processing such as information retrieval, information extraction, etc. Ideally, this process should result in representation of computable criteria for eligibility matching across different protocols. We hope that our effort helps in eliciting differences between the commonly used CT protocols and their full-text counterpart and thus pave the path for building systems that can easily handle industry standard full-text criteria.

@&#ACKNOWLEDGMENTS@&#

The authors would like to thank the editor and anonymous reviewers for their comments and suggestions on improving the quality and merit of this paper. We would like to thank Matthew Crawford for his helpful suggestions during the initial phase of this work. We are also grateful to Padmini Srinivasan for her helpful comments on revising the paper.

@&#REFERENCES@&#


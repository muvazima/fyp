@&#MAIN-TITLE@&#Eikonal-based region growing for efficient clustering

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Fast and efficient superpixel algorithm based on the Eikonal equation


                        
                        
                           
                           Dynamic color-based potential function


                        
                        
                           
                           Parameter-free refinement of the superpixels


                        
                        
                           
                           Equivalent or better performances than the state-of-the-art


                        
                        
                           
                           Flexibility of the approach


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Superpixels

Segmentation

Clustering

Eikonal equation

@&#ABSTRACT@&#


               
               
                  We describe an Eikonal-based algorithm for computing dense oversegmentation of an image, often called superpixels. This oversegmentation respects local image boundaries while limiting undersegmentation. The proposed algorithm relies on a region growing scheme, where the potential map used is not fixed and evolves during the diffusion. Refinement steps are also proposed to enhance at low cost the first oversegmentation. Quantitative comparisons on the Berkeley dataset show good performance on traditional metrics over current state-of-the art superpixel methods.
               
            

@&#INTRODUCTION@&#

With the increasing amount of available data, and the need for fast and accurate processing, the simplification of data becomes a crucial point for many applications. A convenient way to address this task is to consider that data can be modeled with a graph G
                     =(V, E, w), where V is the set of vertices, Eis a set of edges, and w
                     >0 is the weight function that models the interaction between vertices. Exhibiting clusters of this graph leads to a simplification of the data and decreases the size of the problem. Many techniques of graph clustering have been proposed such as cut-based, spectral or random walk methods (see [16] for a comprehensive review of these techniques).

Recent works [3] adapt the eikonal equation to graphs in order to perform over-clustering from an initial set of annotated vertices V
                     0. Let f
                     :
                     V
                     →ℝ be a real-valued function that assigns a real value f(u) to each vertex u
                     ∈
                     V. The reformulation of the Eikonal equation in the graph domain leads to the equation:
                        
                           (1)
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                
                                                   
                                                      
                                                         ∇
                                                         w
                                                         f
                                                      
                                                   
                                                   
                                                      u
                                                   
                                                
                                             
                                             p
                                          
                                          =
                                          P
                                          
                                             u
                                          
                                          
                                          ∀
                                          u
                                          ∈
                                          V
                                       
                                    
                                    
                                       
                                          f
                                          
                                             u
                                          
                                          =
                                          ϕ
                                          
                                             u
                                          
                                          
                                          ∀
                                          u
                                          ∈
                                          
                                             V
                                             0
                                          
                                       
                                    
                                 
                              
                           
                        
                     where (∇
                        w
                     
                     −
                     f)(u) is the weighted morphological gradient at a vertex u (see [11] for details), P is a positive function, and ϕ is an initialization function.

In this paper, we focus on grid graphs for image processing with the aim of grouping perceptually and adjacent pixels into meaningful regions, the so-called superpixels. Superpixels have become an important step in many computer vision applications such as segmentation [8,22], object localization [7], depth estimation [24], and scene labeling [5].

Some properties of an algorithm that generate superpixels are often desirable: (1) Superpixels should adhere well to object boundaries while limiting undersegmentation errors, (2) as superpixel methods are used as preprocessing, the algorithm should have a low complexity, and (3) it has to be simple to use (i.e. few parameters). In addition, some other properties may be desired: the control of the amount of superpixels, or the compactness of them.

Several superpixel algorithms exist in the literature, and they can be roughly divided into two approaches: The first consists in gradually growing superpixels from an initial set of centers. This approach includes Watershed [21], Turbopixels [10], SLIC [1], Consistent Segmentation [25] and Quick Shift [19]. The second approach relies on a graph formulation of the problem and aims at finding an optimal cut according to an objective function that takes similarities of neighboring pixels into account. This approach includes Entropy-based energy function method [12], optimal cuts [14,13], graph-cut [20], and agglomerative clustering of the nodes of the graph [6].

In this paper, we propose a new algorithm for superpixel generation: Eikonal-based Region Growing Clustering
                     
                        1
                     
                     
                        1
                        Source code and executable of ERGC can be found athttps://sites.google.com/site/pierrebuyssens/ergc.
                      (ERGC) that starts from an initial set of seeds and dilates them, and then refines the result oversegmentation by adding/moving cuts. It formulates the superpixel segmentation task as a solution of an Eikonal equation. Eq. (1) becomes:
                        
                           (2)
                           
                              
                                 
                                    
                                       
                                          
                                             
                                                ∇
                                                U
                                                
                                                   x
                                                
                                             
                                          
                                          =
                                          F
                                          
                                             x
                                          
                                          
                                          ∀
                                          x
                                          ∈
                                          I
                                       
                                    
                                    
                                       
                                          U
                                          
                                             x
                                          
                                          =
                                          0
                                          
                                          ∀
                                          x
                                          ∈
                                          Γ
                                       
                                    
                                 
                              
                           
                        
                     where 
                        I
                      is the image domain, F a positive function, Γ the set of initial seeds, and U(x) the traveling time or geodesic distance of x from source Γ. Focusing on grid graphs, it can be solved efficiently with the Fast-Marching method. The major change proposed in this paper concerns the function F, which is not fixed and evolves during the front evolution. It is detailed at Section 2.2.

ERGC is simple to use (by default, the only parameter is the desired number of superpixels), as fast as other superpixel methods, and outperforms them on two of the three traditional metrics.

The rest of the paper is organized as follows: Section 2 details the proposed potential function F, and the ERGC algorithm. Section 3 gives qualitative and quantitative comparisons of performances between ERGC and state-of-the-art methods. Some aspects and extensions of the proposed method are than discussed in Section 4, while Section 5 concludes the paper.

In the following we adopt several notations to simplify the reading of the paper. A particular pixel of image 
                           I
                         is noted 
                           p
                         and consists of a coordinate couple (x
                        
                           
                              p
                           
                        ,
                        y
                        
                           
                              p
                           
                        ). A region 
                           R
                        
                        
                           i
                         consists of a seed pixel 
                           s
                        
                        
                           i
                         and a size N
                        
                           i
                         in pixels. The color of a pixel 
                           p
                         is noted 
                           C
                        
                        
                           
                              p
                           
                        , and the mean color of a region R
                        
                           i
                         is noted 
                           C
                        
                        
                           
                              i
                           
                        .

Note that the color images are considered in the CIELAB colorspace, so the color vector of a pixel (or a region) 
                           C
                         reduces to [l,
                        a,
                        b]
                           T
                        .

Since a superpixel method aims at grouping perceptually and adjacent pixels into meaningful regions, we propose a potential function F that conveys this desirable property. The right term of Eq. (2) is computed according to the mean color of the adjoining region:
                           
                              (3)
                              
                                 
                                    F
                                    c
                                 
                                 
                                    p
                                    
                                       R
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             C
                                             p
                                          
                                          −
                                          
                                             C
                                             i
                                          
                                       
                                    
                                    2
                                    2
                                 
                                 .
                              
                           
                        
                     

This potential function measures the perceptual color distance between the pixel 
                           p
                         and the region R
                        
                           i
                        . For color images in the CIELAB colorspace, F reduces to:
                           
                              (4)
                              
                                 
                                    F
                                    c
                                 
                                 
                                    p
                                    
                                       R
                                       i
                                    
                                 
                                 =
                                 
                                    
                                       
                                          
                                             l
                                             p
                                          
                                          −
                                          
                                             l
                                             i
                                          
                                       
                                    
                                    2
                                 
                                 +
                                 
                                    
                                       
                                          
                                             a
                                             p
                                          
                                          −
                                          
                                             a
                                             i
                                          
                                       
                                    
                                    2
                                 
                                 +
                                 
                                    
                                       
                                          
                                             b
                                             p
                                          
                                          −
                                          
                                             b
                                             i
                                          
                                       
                                    
                                    2
                                 
                              
                           
                        where [l
                        
                           i
                        ,
                        a
                        
                           i
                        ,
                        b
                        
                           i
                        ]
                           T
                         is the mean color vector of region R
                        
                           i
                        .

In comparison to traditional gradient-based approaches [3] where F(
                           p
                        )=‖∇
                           I
                        ‖, the proposed formulation favors the grouping of similar pixels, even for pixels that are far from the initial seeds (Fig. 2
                        
                        ).

As a numerical solver of the Eikonal Eq. (2), we adopt the Fast-Marching method introduced by Sethian in [17]. It uses a priority queue to order the pixels as being the current estimate of the geodesic distance to the closest seed (see [15] for a detailed description of the Fast-Marching algorithm).

Within the Fast-Marching algorithm, each time a pixel 
                           p
                         is inserted to a region R
                        
                           i
                        , the attributes of this region are easily updated:
                           
                              (5)
                              
                                 
                                    
                                       
                                          
                                             
                                                C
                                                i
                                             
                                          
                                          
                                             ←
                                          
                                          
                                             
                                                
                                                   
                                                      C
                                                      i
                                                   
                                                   ×
                                                   
                                                      N
                                                      i
                                                   
                                                   +
                                                   
                                                      C
                                                      p
                                                   
                                                
                                                
                                                   
                                                      N
                                                      i
                                                   
                                                   +
                                                   1
                                                
                                             
                                          
                                       
                                       
                                          
                                             
                                                N
                                                i
                                             
                                          
                                          
                                             ←
                                          
                                          
                                             
                                                N
                                                i
                                             
                                             +
                                             1
                                          
                                       
                                    
                                 
                                 .
                              
                           
                        
                     

This formulation clearly makes the potential of a pixel dependant on the features of an adjoining region, which is updated during the process. It promotes the diffusion to pixels whose color is close to the color of the region, hence creating homogeneous superpixels. A region can also absorb smoothly localized noisy pixels since such a pixel contributes weakly to the mean color of the region.

Algorithm 6 summarized the Fast-Marching algorithm with our proposed potential function. Within the algorithm, a state Σ is given to each pixel and changes during the processing: COMPUTED states that the solution for a pixel has been computed (i.e. its solution will not change anymore), ALIVE states that the solution of a pixel is being computed, and FAR AWAY states that a pixel has not yet been visited. The algorithm involves a heap structure of ALIVE points, noted L, and each time a pixel p with coordinates (x, y) is visited, its local solution is computed w.r.t. its neighbors Neigh(p):
                           
                              (6)
                              
                                 U
                                 
                                    p
                                 
                                 =
                                 
                                    
                                       
                                          
                                             
                                                1
                                                2
                                             
                                             
                                                
                                                   U
                                                   
                                                      q
                                                   
                                                   +
                                                   U
                                                   
                                                      r
                                                   
                                                   +
                                                   
                                                      Δ
                                                   
                                                
                                             
                                             
                                             if
                                             
                                             Δ
                                             ≥
                                             0
                                          
                                       
                                       
                                          
                                             ⁢
                                             min
                                             ⁡
                                             
                                                
                                                   U
                                                   
                                                      q
                                                   
                                                   +
                                                   U
                                                   
                                                      r
                                                   
                                                
                                             
                                             +
                                             F
                                             
                                             otherwise
                                          
                                       
                                    
                                 
                              
                           
                        where F is computed with Eq. (3), q and r are the neighbors of p such that U(q)=min(U(x
                        −1,y),U(x
                        +1,y)), U(r)=min(U(x,y
                        −1),U(x,y
                        +1)), and ∆ corresponds to solving the equation (u−
                        U(r))2
                        +(u
                        −
                        U(q))2
                        =
                        F
                        2 (see [15] for details).
                           Algorithm 1
                           
                              Fast-Marching algorithm with the proposed potential function.
                                 
                                    
                                 
                              
                           


                        Fig. 1 compares the geodesic distance map computed on a synthetic image (left) with the gradient-based potential function (middle) and the proposed one (right), with an initial seed depicted by the white dot. This example exhibits the main feature of the proposed potential function. With the gradient-based potential function (middle), the front propagates on the white square before having recovered all the black area. Some pixels belonging to the square then have a lower geodesic distance than pixels belonging to the black area. A good segmentation of the square based on these distances is then impossible. With the proposed potential function (right), the front propagates first entirely on the black area before entering onto the white square. A good segmentation of the square can then easily be achieved.

Such a result can be interpreted in the following way: For the gradient-based potential function, when a front arrives on a contour, its speed heavily decreases as the potential is high. Nevertheless, after a given time, the front ends up passing through the contour, and the potential becomes low again, so the front can evolve with a high speed. This behavior is not a surprise and can be seen on the red–blue image of Fig. 2. The proposed potential function adds to the diffusion a sort of memory of the initial color of the seeds. When a front arrives on a region with a different color, the potential becomes very high. Even if the front passes through the interface separating the two regions, the potential remains very high, hence prohibiting the diffusion too much.


                        Fig. 2 compares the behavior of the proposed potential function and the gradient-based approach [3] on a color synthetic image with two seeds, and on a natural image with three seeds. In both cases, the proposed formulation gives a better segmentation.

The initialization consists of sampling K seed pixels on a regular grid with an interval S equal to 
                           S
                           =
                           
                              
                                 N
                                 /
                                 K
                              
                           
                         with N the number of pixels in the image (initialization similar to [1] and [10]).

The mean and variance color of the seed pixel and its 4-connexity neighboring pixels is then computed. The same computation is performed for pixels that lie in a 3×3 neighborhood, and the seed is moved to the pixel that lowers the variance color. Such a perturbation of the initial seeds avoids potential outlier pixels as seeds, favorably initializes the diffusion, and gives a more robust initial mean color for each superpixel.

After the initialization, a front propagation is performed with an online update of the superpixels. Complexity of the diffusion relies essentially on the complexity of the Fast-Marching algorithm, which is roughly in 
                           O
                           
                              
                                 nlog
                                 
                                    n
                                 
                              
                           
                         with an appropriate heap for sorting the pixels according to their geodesic distance. Despite this theoretical complexity, the proposed algorithm is very fast in practice, and is nearly linear in time. Note that using different data structures (and additional storage), different 
                           O
                           
                              n
                           
                         implementations have been proposed in [23,9].

In this section, we propose a refinement of the clustering that iteratively adds new seeds after a full pass of the algorithm. Since initial seeds are placed on a grid, some objects of the image may not contain an appropriate seed, and these objects may not be finally well segmented (Fig. 3
                        ). In such a case the resulting geodesic distance map U exhibits high values in this area (Fig. 3). The refinement consists of adding a new seed to the location of the maximum geodesic distance, and to recompute the solution of Eq. (2). Since it is unnecessary to apply the algorithm to the whole image, only a small part of the image around the new seed is considered (Fig. 3). The refinement is summarized as follows:
                           
                              1.
                              Perform a full pass of ERGC with the seeds placed on a grid,

add a new seed to the location of the maximum geodesic distance found at the previous step,

let R
                                 
                                    i
                                  be the superpixel in which there is the new seed (red superpixel of Fig. 3), perform ERGC for pixels belonging to R
                                 
                                    i
                                  and its adjacent superpixels (blue superpixels of Fig. 3). At this step, the seeds of the refined superpixels are left unchanged,

iterate steps 2 and 3 until the number of desired new seeds is reached.

A resulting refinement iteration, and the associated geodesic distance map are shown in Fig. 3. The cost of a refinement iteration depends on the number of pixels considered. Nevertheless, this refinement is considerably less costly than a full ERGC pass, since it only deals with a small part of the image. Given superpixels of size 
                           S
                           =
                           
                              
                                 N
                                 /
                                 K
                              
                           
                        , and letbbe the number of adjacent superpixels of R
                        
                           i
                        , the complexity of one refinement iteration is roughly 
                           O
                           
                              
                                 bSlog
                                 
                                    
                                       b
                                       S
                                    
                                 
                              
                           
                        , which can be approximated with 
                           O
                           
                              
                                 
                                    
                                       
                                          N
                                          K
                                       
                                    
                                 
                                 log
                                 
                                    
                                       
                                          N
                                          K
                                       
                                    
                                 
                              
                           
                        . For information, one refinement iteration costs approximately 3
                        ms for 500 initial seeds, and 8
                        ms for 100 initial seeds on a Berkeley image. These time calculations have been obtained with a standard laptop equipped with an Intel mono core 1.30GHz processor and 4GB RAM.

In this section, we propose a simple procedure to increase the quality of the oversegmentation without increasing the total number of superpixels. It consists in adding a new superpixel while removing a “weak” one, such that the global number of superpixels remains constant.

The selection of the superpixel to remove consists of 3 steps:
                           
                              1.
                              Given an oversegmentation of the image, compute the underlying Region Adjacency Graph (RAG),

For each vertex v of the graph, compute its normalized volume vol:


                                 
                                    
                                       (7)
                                       
                                          vol
                                          
                                             v
                                          
                                          =
                                          
                                             
                                                
                                                   
                                                      ∑
                                                      
                                                         u
                                                         ∼
                                                         v
                                                      
                                                   
                                                   
                                                
                                                
                                                w
                                                
                                                   u
                                                   v
                                                
                                             
                                             
                                                Card
                                                
                                                   
                                                      N
                                                      v
                                                   
                                                
                                             
                                          
                                       
                                    
                                 where u
                                 ∼
                                 v denotes two adjacent vertices, w(u,
                                 v) the weight of the edge connecting u and v, and 
                                    
                                       N
                                       v
                                    
                                  the set of neighbors of v.

Select the superpixel corresponding to the vertex with the minimal normalized volume as the superpixel to remove.

This procedure selects the superpixel that is the closest to its neighbors. The weight function is the 
                           
                              L
                              2
                           
                         norm and reflects the difference between two adjacent superpixels.

The initial oversegmentation is then refined by adding a new superpixel with the procedure in Section 2.5 detailed above, while the superpixel to remove is simply discarded.

The whole procedure is iterated until a criterion is reached. In the following, it is stopped when ∫
                           I
                        
                        
                        U no longer decreases. We also add a limit of 10 iterations, which in practice, is rarely reached.


                        Fig. 4
                         shows a refinement of an initial oversegmentation by moving 3 superpixels. Both oversegmentations contain 150 superpixels. The complexity of this refinement is low since it is similar to the refinement by adding new seeds.

Although a spatial constraint can easily be added to F (see Fig. 3), by default the only parameter of ERGC is the number of desired superpixels. The whole algorithm consists of 3 steps:
                           
                              1.
                              Proceed to the initial diffusion with 90% of the desired seeds placed on a grid,

Refine the oversegmentation by adding the remaining 10% of seeds (Section 2.5),

Iterate the moving seeds procedure (Section 2.6) until the stopping criterion is reached.

For example, the algorithm produces 200 superpixels by first placing 180 seeds on the initial grid, then by adding 20 more seeds with the procedure described in Section 2.5.

These ratios ensure that the whole algorithm runs in a reasonable amount of time (about half a second on a Berkeley image).

We compare ERGC to state-of-the-art methods SLIC
                        2
                     
                     
                        2
                        
                           http://ivrg.epfl.ch/supplementary_material/RK_SLICSuperpixels.
                     
                     [1], Entropy Rate Superpixels
                        3
                     
                     
                        3
                        
                           http://www.umiacs.umd.edu/mingyliu/research.
                     
                     [12] (ERS), SEEDS
                        4
                     
                     
                        4
                        
                           http://www.vision.ee.ethz.ch/software.
                     
                     [18], TurboPixels
                        5
                     
                     
                        5
                        
                           http://www.cs.toronto.edu/babalex/research.html.
                     
                     [10] (TP), and Gradient-based diffusion [3] (GrB). Examples of superpixel segmentations produced by each method appear in Fig. 7
                     
                     
                     .

The popular SLIC method proposed in [1] adapts k-means in the image plane to iteratively exhibit superpixels. The addition of a spatial constraint term produces regular regions that adhere quite well to image. The ERS algorithm proposed in [12] oversegments an image via an objective function composed of two terms: entropy rate of a random walk on a graph and a balancing term. By default, it produces irregular superpixels that adapt to local image structure, but is quite slow in practice. Starting from an initial superpixel partitioning (a grid), SEEDS [18] continuously refines the superpixels by modifying the boundaries. Based on a simple hill-climbing optimization, it minimizes an energy function based on enforcing color similarity between the boundaries and the superpixel color histogram. This fast algorithm produces the most irregular superpixels of the literature. The TurboPixels algorithm [10] consists in iterating three steps: (1) evolve the boundaries of the superpixels for a given number of time steps, (2) compute the squeletton of these boundaries, and (3) update velocities of the boundaries. TP produces regular superpixels that often fail to adapt to local image structure, especially when the desired number of superpixels is low. Moreover, it is the slowest algorithm among the top performers. Finally, the gradient-based diffusion method GrB proposed in [3] essentially solves the Eikonal equation with a gradient-based potential function. It suffers from leaks inherent of this potential function as outlined in Section 2.2 (examples shown in Figs. 1 and 2).

The Berkeley dataset [2] is used as a benchmark. It consists of 500 images of size 481×321 (or 321×481) and several ground truth manual segmentations for each image.


                     Fig. 6 shows quantitative results on standard metrics, including boundary recall, undersegmentation error and achievable segmentation accuracy. We also add a compactness metric that reflects the compacity of the superpixels. As a baseline for boundary recall, undersegmentation error and achievable segmentation accuracy metrics, we also show the performances of a grid of square superpixels (GRID).

All results are computed from scratch using these evaluation metrics and the same hardware. Default parameters are used for the state-of-the-art methods.

Boundary recall (BR) measures the fraction of ground truth edges that is also present in superpixel segmentation within a distance threshold t. In our experiments, t is fixed to 2 as in [1,12,18]. Fig. 6 shows boundary recall measures for each method according to the number of superpixels. As the number of superpixels increases, the boundary recall is naturally higher. SEEDS outperforms all other algorithms on this metric. Nevertheless, this result has to be appreciated in the light of the superpixels' compactness. As shown in Fig. 6 (second and third rows), ERS and SEEDS superpixels have the lowest mean compactness values. For a fixed number of superpixels, there are then much more ERS or SEEDS superpixel boundaries in the segmentation, which naturally increases the boundary recall value.

Undersegmentation error (UE) is shown in Fig. 6. Given a ground truth and superpixel segmentation, this error measures the fraction of bleeding caused by superpixels that overlap a given ground truth segment. The standard formulation is
                           
                              (8)
                              
                                 U
                                 E
                                 
                                    s
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                             i
                                          
                                          
                                       
                                       
                                       
                                          
                                             ∑
                                             
                                                k
                                                :
                                                
                                                   s
                                                   k
                                                
                                                ∩
                                                
                                                   g
                                                   i
                                                
                                                ≠
                                                ∅
                                             
                                          
                                          
                                       
                                       
                                       
                                          
                                             
                                                s
                                                k
                                             
                                             −
                                             
                                                g
                                                i
                                             
                                          
                                       
                                    
                                    
                                       
                                          
                                             ∑
                                             i
                                          
                                          
                                       
                                       
                                       
                                          
                                             g
                                             i
                                          
                                       
                                    
                                 
                              
                           
                        where s
                        
                           k
                         are the outputs of the superpixel algorithm, g
                        
                           i
                         the ground truth segments, and |.| denotes the size of an element.

There are significant changes in this evaluation according to the authors, because it is not clear how to treat pixels that lie on a boundary between two labels. In [1], the authors report a 5% tolerance margin, while authors in [12] remove the boundaries of s
                        
                           k
                         for the undersegmentation computation.

In this paper, we use the corrected undersegmentation error (CUE) proposed by the authors of SEEDS
                           6
                        
                        
                           6
                           
                              http://arxiv.org/pdf/1309.3848v1.eps.
                         defined as:
                           
                              (9)
                              
                                 CUE
                                 
                                    s
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                             k
                                          
                                          
                                       
                                       
                                       |
                                       
                                          s
                                          k
                                       
                                       −
                                       
                                          g
                                          max
                                       
                                       
                                          
                                             s
                                             k
                                          
                                       
                                       |
                                    
                                    
                                       
                                          
                                             ∑
                                             i
                                          
                                          
                                       
                                       
                                       |
                                       
                                          g
                                          i
                                       
                                       |
                                    
                                 
                              
                           
                        where g
                        
                           max
                        (s
                        
                           k
                        ) indicates the matching ground truth segment of s
                        
                           k
                         with the largest overlap. This corrected undersegmentation error measure seems more accurate and does not rely on any ad-hoc solution.

Finally this fraction is simply averaged across all ground truth segments and all images. Fig. 6 shows that the undersegmentation error of ERGC is the lowest upon the considered state-of-the-art methods.

Achievable segmentation accuracy (ASA) is a performance upperbound measure. It gives the highest performance when taking superpixels as units for object segmentation. Each superpixel is labeled with the label of the ground truth segment with the largest overlap. The fraction of correctly labeled pixels is the achievable accuracy:
                           
                              (10)
                              
                                 A
                                 S
                                 A
                                 
                                    s
                                 
                                 =
                                 
                                    
                                       
                                          
                                             ∑
                                             k
                                          
                                          
                                       
                                       
                                       
                                          
                                             ⁢
                                             max
                                             ⁡
                                          
                                          i
                                       
                                       |
                                       
                                          s
                                          k
                                       
                                       ∩
                                       
                                          g
                                          i
                                       
                                       |
                                    
                                    
                                       
                                          
                                             ∑
                                             i
                                          
                                          
                                       
                                       
                                       
                                          g
                                          i
                                       
                                    
                                 
                                 .
                              
                           
                        
                     


                        Fig. 6 shows that ERGC gives the best achievable segmentation accuracy compared to the other methods.

We introduce this metric in addition to traditional ones to measure the compactness of the superpixels. Compactness represents the degree to which the superpixel shape is compact. It is defined as the ratio of the area of a region to the area of a circle with the same perimeter. It is calculated as follows:
                           
                              (11)
                              
                                 COMP
                                 
                                    
                                       s
                                       k
                                    
                                 
                                 =
                                 
                                    
                                       4
                                       π
                                       |
                                       
                                          s
                                          k
                                       
                                       |
                                    
                                    
                                       p
                                       k
                                       2
                                    
                                 
                              
                           
                        where p
                        
                           k
                         is the perimeter of the superpixel s
                        
                           k
                        . The compactness is equal to 1 for a disc, π/4 for a square. Fig. 6 plots the mean compactness for each algorithm and for a different number of superpixels. Compactness for the grid of square superpixels (GRID) is the highest (around 0.85), and is not shown on Fig. 6.


                        Fig. 5 plots the evaluation of the proposed algorithm and its evolution within the two proposed refinement: the curves ERGC(a), ERGC(b) and ERGC(f) stand for the algorithm performances without any refinement, with only the adding superpixel refinement, and with the two proposed refinement, respectively. One can particularly appreciate the improvements of the performances while refining iteratively the superpixels. Fig. 5 also plots the performances of the proposed algorithm with a spatial constraint (m
                        =10 in Eq. (12)) and SLIC (for comparison purposes). Adding a spatial constraint decreases slightly the BR, UE, and ASA performances of the algorithm in comparison to a potential based on color distances only (Eq. (3)), but produces more compact superpixels. Moreover, these performances are still higher than the popular algorithm SLIC.

In this section, we propose several extensions to our initial framework that illustrate the flexibility of the approach.

ERGC has been introduced for 2D images. It naturally extends to 3D volumes to produce supervoxels with minor modifications of the algorithm. Fig. 8
                         displays a supervoxel segmentation of a 3D volume from the MICCAI-2007 Grand Challenge dataset. For display purposes, only the interior part of the body is shown.

For clarity of the display purposes, a spatial constraint has been added to F to generate images of Fig. 3, 4 and 8. This constraint, similar to the one proposed in [1], penalizes pixels 
                           p
                         that are far from an initial seed 
                           s
                           i
                        , and is of the form 
                           
                              
                                 
                                    
                                       p
                                       −
                                       
                                          
                                             s
                                             i
                                          
                                          2
                                          2
                                       
                                    
                                 
                                 S
                              
                           
                           ×
                           m
                         where m is the constraint parameter. In this case, the potential function is of the form:
                           
                              (12)
                              
                                 F
                                 =
                                 
                                    
                                       
                                          
                                             C
                                             p
                                          
                                          −
                                          
                                             C
                                             i
                                          
                                       
                                    
                                    2
                                    2
                                 
                                 +
                                 
                                    
                                       
                                          
                                             p
                                             −
                                             
                                                s
                                                i
                                             
                                          
                                       
                                       2
                                       2
                                    
                                    S
                                 
                                 ×
                                 m
                              
                           
                        
                     

Adding such a spatial constraint increases the superpixel compactness and tends to produce square superpixels in flat areas, see Figs. 3 and 4. Nevertheless, as this is a constraint applied on the diffusion, it decreases slightly BR, UE and ASA performances.

The proposed approach can easily be extended with additional terms to produce more powerful potential functions. We propose to combine the initial color-based potential function with edge maps. Based on structured forest, the approach proposed in [4] gives for each pixel 
                           p
                         the probability E(p) that 
                           p
                         belongs to an edge. Within the Fast-Marching algorithm, the potential of pixels belonging to region R
                        
                           i
                         is computed as:
                           
                              (13)
                              
                                 F
                                 =
                                 
                                    
                                       
                                          
                                             C
                                             p
                                          
                                          −
                                          
                                             C
                                             i
                                          
                                       
                                    
                                    2
                                    2
                                 
                                 ⋅
                                 
                                    
                                       ϵ
                                       +
                                       
                                          
                                             ⁢
                                             max
                                             ⁡
                                          
                                          
                                             γ
                                             
                                                
                                                   p
                                                   i
                                                
                                                →
                                                
                                                   s
                                                   i
                                                
                                             
                                          
                                       
                                       E
                                    
                                 
                              
                           
                        where ϵ is a small constant to avoid F being zero, and 
                           
                              max
                              
                                 γ
                                 
                                    
                                       p
                                       i
                                    
                                    →
                                    
                                       s
                                       i
                                    
                                 
                              
                           
                         (E)is the maximum edge probability along the geodesic 
                           
                              γ
                              
                                 
                                    p
                                    i
                                 
                                 →
                                 
                                    s
                                    i
                                 
                              
                           
                         (see Fig. 9
                        ).

Note that this maximum edge probability along the geodesic can easily be carried out through the diffusion process, such that the extra processing time is marginal: computing the geodesic explicitly is not mandatory.

Adding such an edge information to the potential prevents more the front from leaking to a region from another. It is also useful in case of microtextures such as grass for instance. Edge probabilities in such areas are close to zero, making the potential of the pixels low. The propagating front is then not slowed down too much by the locally varying colors of the texture. Fig. 11
                        
                         compares the performances of this variant of ERGC, together with the initial ERGC method (without edges) and the top performer among the state-of-the-art methods for each metric. Note that compacity values are not plotted for this method since it is very similar to the initial ERGC method (Fig. 6).

The method proposed in this paper (detailed in Section 2) computes the superpixels in only one iteration. In this section, we go beyond this limitation and propose an iterative version of ERGC. Iterating the process allows us to refine the seeds of the superpixels such that the next iteration produces better regions.

Given an initial superpixel R
                        
                           i
                         with its seed 
                           s
                           i
                        , the refinement is performed as follows:
                           
                              1.
                              Select all the pixels 
                                    p
                                    i
                                 
                                 ∈
                                 
                                    R
                                    i
                                  such that their color is the closest from Ci
                                 ,

from this set of seed candidates, select only those that are spatially the closest from 
                                    s
                                    i
                                 .

This refinement scheme is illustrated in Fig. 10. It may produce several new seeds per superpixels. In such a case, these seeds share the same label, and form, after the diffusion, a sole superpixel. The spatial selection is performed to avoid the generation of too many new seeds that may produce a degenerate superpixel after several iterations.

In our experiments, the number of iteration is fixed to 10 and the configuration of seeds that lowers ∫
                           I
                        
                        
                        U is retained.

At the cost of multiple iterations, this iterative variant enhances the whole performances of the algorithm (Fig. 11).

For completeness purposes, Fig. 11 also shows the performances of the iterative variant of ERGC with the use of edges probability maps. Finally, a comparison of relative processing times among all methods is provided in Table 1
                        .

@&#CONCLUSION@&#

Superpixels have become an important preprocessing tool for many image based applications. In this paper, we proposed a method based on the eikonal equation that quickly creates accurate superpixels. Through the empirical experiments, we showed that ERGC outperforms existing superpixel methods in two of three metrics, while being outperformed by SEEDS and ERS on boundary recall. This last result has to be appreciated in the light of their superpixel compactness, the lowest within the state-of-the-art.

Proposed here for the generation of superpixels/supervoxels, we think that the diffusion framework can offer an interesting choice in many other image processing tasks. ERGC can also be extended to arbitrary graphs to perform local or non-local image and data processing, and data clustering (supervertices).

@&#ACKNOWLEDGMENTS@&#

This work is part of the french SIRTDose project funded by the grant “Physique Cancer” 2012 (INSERM-Plan Cancer). The authors wants to thank the authors of [1] and [18] for the fruitful discussions about superpixels and their evaluation. The authors also would like to thank the anonymous reviewers for their valuable comments and suggestions to improve the quality of the paper.

@&#REFERENCES@&#


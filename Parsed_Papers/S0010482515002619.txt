@&#MAIN-TITLE@&#A clinical decision support system for diagnosis of Allergic Rhinitis based on intradermal skin tests

@&#HIGHLIGHTS@&#


               
               
                  
                     
                        
                           
                           Allergic Rhinitis is a symptomatic disorder of the nose due to allergen exposure.


                        
                        
                           
                           A clinical decision support system (CDSS) for diagnosis of Rhinitis is proposed.


                        
                        
                           
                           Skin test results of 872 patients were obtained from an allergy testing centre.


                        
                        
                           
                           The clinical relevance of the CDSS was validated and compared with existing methods.


                        
                        
                           
                           In expert׳s absence, the system assists junior clinicians in decision making.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Allergic Rhinitis

Allergens

Skin tests

Clinical decision support system

Rule base

@&#ABSTRACT@&#


               
               
                  Backgrounds and objectives
                  Allergic Rhinitis is a universal common disease, especially in populated cities and urban areas. Diagnosis and treatment of Allergic Rhinitis will improve the quality of life of allergic patients. Though skin tests remain the gold standard test for diagnosis of allergic disorders, clinical experts are required for accurate interpretation of test outcomes. This work presents a clinical decision support system (CDSS) to assist junior clinicians in the diagnosis of Allergic Rhinitis.
               
               
                  Methods
                  Intradermal Skin tests were performed on patients who had plausible allergic symptoms. Based on patient׳s history, 40 clinically relevant allergens were tested. 872 patients who had allergic symptoms were considered for this study. The rule based classification approach and the clinical test results were used to develop and validate the CDSS. Clinical relevance of the CDSS was compared with the Score for Allergic Rhinitis (SFAR). Tests were conducted for junior clinicians to assess their diagnostic capability in the absence of an expert.
               
               
                  Results
                  The class based Association rule generation approach provides a concise set of rules that is further validated by clinical experts. The interpretations of the experts are considered as the gold standard. The CDSS diagnoses the presence or absence of rhinitis with an accuracy of 88.31%. The allergy specialist and the junior clinicians prefer the rule based approach for its comprehendible knowledge model.
               
               
                  Conclusion
                  The Clinical Decision Support Systems with rule based classification approach assists junior doctors and clinicians in the diagnosis of Allergic Rhinitis to make reliable decisions based on the reports of intradermal skin tests.
               
            

@&#INTRODUCTION@&#

Allergic diseases are the consequences of symptoms that occur due to an interaction between the environment and an individual׳s immune system, resulting in the discharge of histamine and other pro-inflammatory mediators. Allergic Rhinitis (AR) is a symptomatic disorder of the nose, induced after allergen exposure by an immunoglobulin E-mediated inflammation of the membranes lining the nose. It is characterised by nasal congestion, rhinorrhoea, sneezing, itching of nose and postnasal drainage [1]. Patients with Allergic Rhinitis may have nasal symptoms that affect their quality of life and their day-to-day activities [2]. A survey conducted in India by Kumar et al. reported that Allergic Rhinitis was prevalent in 26.1% of school children. When considered with the socio-economic status, 27.1% of the lower class people, 33.3% of the middle class people, and 28.6% of upper class people living in urban areas were observed to have respiratory allergic diseases [3]. The characteristic symptoms of rhinitis were observed in 75% of children and 80% of asthmatic adults in India [4]. About 63.7% individuals affected with Allergic Rhinitis coexist with sinusitis. AR adds up to nearly 55% of all allergies present in India [5]. Furthermore there is very little research work conducted in the study of allergies and Allergic Rhinitis when compared to other areas in the medical domain. Literature and research, regarding the clinical features and symptoms of the patients with Allergic Rhinitis in India, is not exhaustive. Allergic diseases have not received the attention it deserves by both patients as well as clinicians [6].

Allergic diseases certainly require a unique gold standard test for detection and diagnosis. Works in literature use different tests for reporting an allergic disease. Gold standard tests that use only history findings of patients and physical examination are less sensitive and specific than those that incorporate specific immunoglobulin E (IgE) testing. The gold standard using a composite of the history, examination, food habits and specific IgE testing is the most commonly used method, but the methods of combining results has variations. Hence an appropriate method of assessment is necessary to assist clinicians in decision-making.

There are three gold standard tests which are used to diagnose Allergic Rhinitis, namely, Clinical criteria test, Composite test and Challenge test [7]. Clinical criteria gold standard test depends on the correlation between the patient׳s symptoms with clinical criteria set by expert opinion. Composite gold standard test use a combination of skin prick tests (SPT), in-vitro tests and nasal provocation tests. In challenge gold standard tests, the nasal passages are exposed directly to an allergen in increasing concentrations.

Diagnosis of Rhinitis requires a careful history analysis, well-targeted testing for allergic sensitization and physical examination. A prior knowledge about the aerobiology of the region in which the patient lives and patterns of allergen exposure is essential. Skin testing of a specific IgE is not easily accessible and cannot be interpreted precisely by primary care physicians in underserved areas [8]. Quality control measures and proper performance of skin testing are very important to produce correct results. Timely identification of allergens is vital as it may reduce the manifestation of symptoms. Allergens may vary depending on the age, potential allergen exposures, food habits and area of the country. Prick/puncture technique (percutaneous) or intradermal (intracutaneous) technique can be used for skin tests. Intradermal testing is more sensitive than prick/puncture testing [9]. To properly understand and interpret skin tests for specific IgE, it is essential to know which aeroallergens are present locally, are clinically important and have allergenic cross-reactivity with botanically related species [10]. Another limitation of SPT is that definitions of positive results of skin tests may vary from one physician to another. There are chances for inconsistent diagnosis. For example, many skin test studies compare the diameters of the wheals generated by allergens with the diameter of the wheal generated by the histamine control solution to classify test results as positive. Relatively unbiased test performance characteristics may enable junior clinicians to come out with confident decisions and suggestions. [7].

Though several methods exist for diagnosis and treatment of allergic diseases, a complete resolution of symptoms cannot be obtained. Computer-based predictive models are rarely used in diagnosis of allergic diseases [11]. Due to lack of independent unbiased allergy testing methods, this work proposes a computer-aided approach to assist clinicians in diagnosis and decision-making process. The development in computing and technology, has led to the use of Clinical Decision Support System (CDSS) in medical centres and hospitals for efficient and reliable diagnosis and prognosis. Furthermore CDSS are used for Dental education [12], Ventilator treatment [13], Cancer Diagnosis [14], Cancer Treatment [15], Diagnosis of heart diseases [16] and Heart Failure [17], Diagnosis of neuromuscular disorders [18] Respiratory pattern analysis [19] and many more. The CDSS in this work uses a rule based knowledge mining approach, for detection of Allergic Rhinitis from the results of the Intradermal Skin Tests.

The remainder of this paper is organised as follows: Section 2 presents the works in literature related to this work. Section 3 presents the framework of the Clinical Decision Support System along with the needed background definitions and notations. Section 4 provides information about the materials, dataset and the methods used in the experiment. Section 5 discusses the results followed by the conclusion and scope for future work.

@&#RELATED WORK@&#

Singh et al. have studied the effect of aeroallergens such as pollen, fungi, animal dander and dust in acting as triggers for respiratory allergy. Specifically, they have surveyed the concentration of airborne pollen in different parts of India. Studies reveal that pollen types such as Casuarina, Parthenium, Spathodia, Eucalyptus, Peltophorum and Cyperaceae are dominant in southern parts of India [20]. Furthermore, Cassia, Ageratum, Salvadora, Ricinus and Artemisia scoparia are considered to be important aeroallergens. Allergen-avoidance is an important measure in treating allergy. Their work does not provide any insight about diagnosis or treatment of aeroallergen-caused diseases.

Annesi et al. have developed a quantitative Score for Allergic Rhinitis (SFAR) ranging between 0 and 16 [21]. The score is based on eight criteria which are as follows: First, nasal symptoms such as running nose, blocked nose, second, accompaniment of symptoms with water eyes and itching, third, the season in which the symptoms occur, fourth, triggers of nasal symptoms such as inhalants, fifth, perceived allergic status, sixth, previous medical diagnosis of allergy, seventh, allergy tests reported to be positive and finally, family history. Data were obtained from 269 outpatients during a period of 30 days in 1997 at ENT clinics of four hospitals in France. The score was also validated with doctor׳s diagnosis and psychometric tests. SFAR achieved 74% sensitivity and 83% specificity. The score is based on Skin Prick Tests and ImmunoglobulinE levels and hence it cannot be used independently for diagnosis.

Chae et al. have developed an asthma diagnosis system [22]. The authors have compared the diagnostic efficiency of three supervised machine learning techniques namely neural network (NN), case-based reasoning (CBR) and discriminant analysis. Data were collected from 294 patients at Bronchial Asthma clinics at Yonsei University Severance hospital. The neural network is trained using a gradient descent based back-propagation algorithm. Twenty one characteristics of the patient and the results of the SPT constituted the input to the NN. Five hidden layer nodes with 20,000 training cycles produced optimal results. Compared to the diagnostic results of a doctor, the neural network achieves 92% accuracy. The CBR model was implemented using an expert system tool, ART-IM (Automated Reasoning Tool for Information Management). It achieved an overall accuracy of 84%. In discriminant analysis knowledge model, the authors have analysed the patient characteristics based on 14 questionnaire items, lab tests and SPT. The characteristics were grouped into three homogeneous factors. The discriminant function predicted the asthma status. The system achieved an overall accuracy of 90%. The authors have worked on a similar system for Allergic Rhinitis over 444 patients at the Otolaryngology Department of Inje University Paik Hospital. The system achieved 76%, 62% and 78% for NN, CBR and discriminant analysis respectively.

The Clinical Decision Support System uses a typical rule based knowledge mining approach to analyse the results (data) from the SPT and diagnose the presence/absence of AR. This section presents the working of the system with a detailed description of the framework and the mathematical models.

Let D represent a dataset consisting of rows and columns. D consists of k distinct attributes A
                        
                           1
                        
                        ,A
                        
                           2
                        
                        …..A
                        
                           k
                         and a class attribute C. Each attribute has a definite domain A
                        
                           1
                        ={a
                        
                           11
                        
                        , a
                        
                           12
                        
                        ,…a
                        
                           1m
                        }, A
                        
                           2
                        ={a
                        
                           21
                        
                        ,a
                        
                           22
                        
                        ,….a
                        
                           2m
                        }…..A
                        
                           k
                        ={a
                        
                           k1
                        
                        ,a
                        
                           k2
                        
                        ,…a
                        
                           km
                        }and C={c
                        
                           1
                        
                        ,c
                        
                           2
                        
                        ,…..c
                        
                           mc
                         }where c
                        
                           1
                        
                        ,c
                        
                           2
                        
                        …c
                        
                           mc
                         are class labels. Each row (sample/instance), r, in D corresponds to a record and can be described as <A
                        
                           1
                        =a
                        
                           1,1..m
                         >,<A
                        
                           2
                        =a
                        
                           2,1..m
                         >,…< A
                        
                           K
                        =a
                        
                           k1..m
                        >,<C=c
                        
                           1..m
                         >.

Number of rows N
                        
                           r
                         in D represent the number of instances in D, which may be also represented as |D|.

A classification rule, r, is of the form Antecedent→Consequent (X→Y)
                           
                              
                                 X
                                 ∋
                                 
                                    
                                       x
                                    
                                    
                                       1
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       2
                                    
                                 
                                 ,
                                 
                                    
                                       x
                                    
                                    
                                       3
                                       …
                                       ..
                                       .
                                    
                                 
                                 
                                    
                                       x
                                    
                                    
                                       k
                                    
                                 
                              
                           
                        where x
                        
                           1
                        =<A
                        
                           1
                        =a
                        
                           1,1..m
                         >, x
                        
                           2
                        =<A
                        
                           2
                        =a
                        
                           2,1..m
                        >,… x
                        
                           k
                        =<A
                        
                           K
                        =a
                        
                           k1..m
                        >and Y 
                        
                           ∋
                         
                        y
                        c 
                        where y
                        
                           c
                        =<C=c
                        
                           1..m
                        >.

A ruleset R is a collection of rules, 
                           R
                           ∋
                         {r
                        
                           1
                        
                        ,r
                        
                           2
                        
                        ,…r
                        
                           n
                        }.

Support of a classification rule r, r: X→Y, refers to the per cent of cases in D that contain r 
                        [30].
                           
                              
                                 S
                                 u
                                 p
                                 p
                                 o
                                 r
                                 t
                                 (
                                 r
                                 )
                                 =
                                 
                                    
                                       C
                                       o
                                       u
                                       n
                                       t
                                       
                                          (
                                          r
                                          )
                                       
                                    
                                    
                                       |
                                       D
                                       |
                                    
                                 
                                 =
                                 P
                                 r
                                 o
                                 b
                                 a
                                 b
                                 i
                                 l
                                 i
                                 t
                                 y
                                 (
                                 X
                                 →
                                 Y
                                 )
                              
                           
                        
                     

Confidence of the rule r refers to the ratio between the number of cases in |D| that belong to r to the number of cases whose Antecedent X is the same as that of r
                        
                           
                              
                                 For
                                 
                                 r
                                 :
                                 X
                                 →
                                 Y
                                 
                                 C
                                 o
                                 n
                                 f
                                 i
                                 d
                                 e
                                 n
                                 c
                                 e
                                 (
                                 r
                                 )
                                 =
                                 
                                    
                                       C
                                       o
                                       u
                                       n
                                       t
                                       (
                                       r
                                       )
                                    
                                    
                                       C
                                       o
                                       u
                                       n
                                       t
                                       (
                                       X
                                       )
                                    
                                 
                                 =
                                 P
                                 r
                                 o
                                 b
                                 a
                                 b
                                 i
                                 l
                                 i
                                 t
                                 y
                                 
                                    (
                                    
                                       X
                                       →
                                       Y
                                       /
                                       X
                                    
                                    )
                                 
                              
                           
                        
                     

Rules below the minimum support (minsup) and minimum confidence (minconf) threshold are pruned.

The framework of the clinical decision support system is shown in 
                        Fig. 1. The major components of the CDSS system are the pre-processing subsystem and classification subsystem. The results of the Intra dermal skin test constitute the raw data. The data is partitioned into two mutually exclusive partitions called the train data and test data, using a holdout approach [23]. Two-third of the data is designated as train data (training set) and the remaining is the test data (testing set).

The data is preprocessed in order to improve the quality of the data. The preprocessing subsystem performs data sampling and feature (attribute) selection. A dataset is imbalanced if the classification categories are not approximately equally represented [24]. In general, a natural distribution is often not the best distribution for a learning algorithm (inducer) that is used to build a classifier. In this work, the train data has 581 samples out of which only 210 belong to the positive class. Since the class distribution in the raw IDST dataset is imbalanced, an oversampling technique is used to produce a balanced class distribution.
                              
                                 
                                    
                                    
                                    
                                       
                                          Input:
                                          Raw IDST train data
                                       
                                       
                                          
                                          
                                             
                                                B
                                             
                                             
                                                
                                                   samples
                                                
                                             ={Φ} //set containing borderline samples of minority class
                                       
                                       
                                          Process:
                                          Boderline Synthetic Minority Oversampling Technique [25]
                                          
                                       
                                       
                                          Step 1:
                                          
                                             
                                                For
                                              each sample ‘r’ in minority class, calculate m nearest neighbours (m=5).
                                       
                                       
                                          
                                          
                                             
                                                begin
                                             
                                          
                                       
                                       
                                          Step 2:
                                          
                                             
                                                
                                                If all m neighbours belong to majority class
                                       
                                       
                                          
                                          
                                             
                                                
                                                
                                                then r is considered as noise
                                       
                                       
                                          Step 3:
                                          
                                             
                                                
                                                If r׳s majority nearest neighbours is larger than the minority ones
                                       
                                       
                                          
                                          
                                             
                                             
                                             then 
                                                B
                                             
                                             
                                                
                                                   samples
                                                
                                             ←r
                                          
                                       
                                       
                                          
                                          
                                             
                                                end
                                             
                                          
                                       
                                       
                                          Step 4:
                                          
                                             For each r in set 
                                                B
                                             
                                             
                                                
                                                   samples
                                                
                                             
                                          
                                       
                                       
                                          
                                          
                                             begin
                                          
                                       
                                       
                                          Step 5:
                                          Compute the m nearest neighbours
                                       
                                       
                                          Step 6:
                                          Choose a neighbour at random, and compute the difference (diff)
                                       
                                       
                                          Step 7:
                                          Generate a random value (gap) between 0 and 1
                                       
                                       
                                          Step 8:
                                          Synthetic sample=Actual sample+gap
                                             * 
                                             diff
                                          
                                       
                                       
                                          
                                          
                                             REPEAT Steps 5 to Step 8 for each attribute A in a sample r
                                          
                                       
                                       
                                          
                                          
                                             end
                                          
                                       
                                       
                                          Output: Dataset with a balanced class distribution
                                       
                                    
                                 
                              
                           
                        

The balanced data set, is subjected to feature selection (attribute reduction). 
                           Table 1 presents the complete feature set (attributes). It consists of allergens (inhalants, contactants, ingestants), allergic symptoms and other information regarding a patient. Attribute indices 1–80 are allergens, 81–88 are the allergic symptoms and 89–91 are information regarding the patient. The values for the allergens are the results of the skin test. The allergic symptoms are binary valued (yes/no) attributes. The attribute ‘Family History’ is also a binary valued attribute which states the presence/absence of allergic symptoms among the members of the patient׳s family.

Three approaches were used for attribute evaluation and selection. First, the Information Gain (
                              
                                 
                                    I
                                 
                                 
                                    A
                                 
                              
                              (
                              D
                              )
                           ) [26] of all attributes was computed. Second, all the attributes were evaluated and ranked based on the worth of an attribute by measuring the correlation (Pearson׳s) with the class attribute. Third, the attributes were validated by the allergy specialist and suggestions were incorporated. Expert׳s opinion on the choice of attribute was more valid than gain-based and correlation selection procedure. Hence the combination of these three approaches gives an optimal subset of attributes. Out of 91 attributes (features), 40 were selected. The remaining allergens, generally, are not significant triggers to allergic symptoms among most patients who participated in the study.

Input: Balanced Dataset

Process:

A dataset D has |D| samples belonging to ‘m’ distinct classes. The expected reduction in the information requirement caused by knowing the value of an attribute A is given by Eq. (1)
                           
                              
                                 (1)
                                 
                                    G
                                    a
                                    i
                                    n
                                    
                                       (
                                       A
                                       )
                                    
                                    =
                                    I
                                    
                                       (
                                       D
                                       )
                                    
                                    −
                                    
                                       
                                          I
                                       
                                       
                                          A
                                       
                                    
                                    
                                       (
                                       D
                                       )
                                    
                                 
                              
                           
                           
                              
                                 (2)
                                 
                                    
                                       
                                          I
                                       
                                       
                                          A
                                       
                                    
                                    
                                       (
                                       D
                                       )
                                    
                                    =
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          a
                                          m
                                       
                                    
                                    
                                       
                                          |
                                          
                                             
                                                D
                                             
                                             
                                                i
                                             
                                          
                                          |
                                       
                                       
                                          |
                                          D
                                          |
                                       
                                    
                                    ×
                                    I
                                    (
                                    
                                       
                                          D
                                       
                                       
                                          i
                                       
                                    
                                    )
                                 
                              
                           
                           
                              
                                 (3)
                                 
                                    I
                                    
                                       (
                                       D
                                       )
                                    
                                    =
                                    −
                                    
                                       ∑
                                       
                                          i
                                          =
                                          1
                                       
                                       
                                          m
                                          c
                                       
                                    
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    
                                       
                                          log
                                       
                                       
                                          2
                                       
                                    
                                    (
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    )
                                 
                              
                           where p
                           
                              i
                            is the probability that an instance belongs to class C
                           
                              i
                            is estimated by
                              
                                 
                                    
                                       
                                          p
                                       
                                       
                                          i
                                       
                                    
                                    =
                                    
                                       
                                          |
                                          
                                             
                                                C
                                             
                                             
                                                i
                                             
                                          
                                          ,
                                          D
                                          |
                                       
                                       
                                          |
                                          D
                                          |
                                       
                                    
                                 
                              
                           
                        

Attribute ‘A’ has distinct a values, 1≤a≤am, and the Class Attribute ‘C’ has mc classes.

The Pearson׳s correlation coefficient (ρ) for an attribute A (ρ
                           
                              A
                           ) is computed to validate the results of the Information Gain based Attribute evaluation.
                              
                                 
                                    
                                       
                                          ρ
                                       
                                       
                                          A
                                       
                                    
                                    =
                                    
                                       1
                                       
                                          |
                                          D
                                          |
                                          −
                                          1
                                       
                                    
                                    
                                       (
                                       
                                          
                                             
                                                a
                                                −
                                                
                                                
                                                   A
                                                   ¯
                                                
                                             
                                             
                                                S
                                                
                                                   
                                                      D
                                                   
                                                   
                                                      A
                                                   
                                                
                                             
                                          
                                          ×
                                          
                                             
                                                c
                                                −
                                                
                                                
                                                   C
                                                   ¯
                                                
                                             
                                             
                                                S
                                                
                                                   
                                                      D
                                                   
                                                   
                                                      C
                                                   
                                                
                                             
                                          
                                       
                                       )
                                    
                                 
                              
                           where 
                              
                                 A
                                 ¯
                              
                            and 
                              
                                 C
                                 ¯
                              
                            is the mean of Attribute A and C respectively SD is the standard deviation.

However, Pearson correlation coefficient [27] estimated for two categorical variables will return the phi coefficient, 
                              ∅
                            which is computed as follows:
                              
                                 
                                    
                                       
                                          ρ
                                       
                                       
                                          A
                                       
                                    
                                    =
                                    
                                       
                                          ∅
                                       
                                       2
                                    
                                    =
                                    
                                       
                                          
                                             
                                                χ
                                             
                                             2
                                          
                                       
                                       
                                          |
                                          D
                                          |
                                       
                                    
                                 
                              
                           where 
                              
                                 
                                    χ
                                 
                                 2
                              
                            is the Pearson׳s Chi-Squared statistic [28].

Based on the suggestions of the allergy specialist and the inferences from the above tests an optimal subset of features is selected.

Output: Processed dataset with optimal set of attributes.

The information gain and the correlation coefficient values for all attributes are presented in Appendix I.

The classification subsystem consists of rule generation, cross validation, expert evaluation, a rule base and a classifier. The CBA-RG (Class-Based Association Rule Generation) algorithm is used for rule generation [29].


                           
                              
                                 
                                    
                                    
                                       
                                          Input: Training dataset
                                       
                                       
                                          Process:
                                       
                                       
                                          Step 1: Generate candidate rules using Apriori approach [30]
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             FOR EACH Rule r
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             BEGIN
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             
                                             Step 2: Evaluate Confidence(r)
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             
                                             Step 3: If Confidence(r)>minconf
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             
                                             
                                             
                                             
                                             
                                             
                                             Then R←r
                                          
                                       
                                       
                                          END
                                       
                                       
                                          Step 2: Order the rules based on Support and confidence Interestingness measures.
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             Rule r
                                             
                                                i
                                              precedes r
                                             
                                                j
                                              
                                             if Confidence(r
                                             
                                                i
                                             
                                             )>Confidence(r
                                             
                                                j
                                             
                                             )
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             else if Confidence(r
                                             
                                                i
                                             
                                             )=Confidence(r
                                             
                                                j
                                             
                                             ) then r
                                             
                                                i
                                              
                                             precedes r
                                             
                                                j
                                              
                                             if Support(r
                                             
                                                i
                                             
                                             )>Support(r
                                             
                                                j
                                             
                                             )
                                          
                                       
                                       
                                          
                                             
                                             
                                             
                                             
                                             else if Confidence(r
                                             
                                                i
                                             
                                             )=Confidence(r
                                             
                                                j
                                             
                                             )AND Support(r
                                             
                                                i
                                             
                                             )=Support(r
                                             
                                                j
                                             
                                             ) then the rules areplaced in the generated order.
                                       
                                       
                                          Output: Ruleset R
                                          
                                       
                                    
                                 
                              
                           
                        


                           
                           Fig. 2 presents the contents of the rule base before expert validation

Low threshold values resulted in generation of more than forty thousand rules; hence the minsup and minconf values were set to 0.5 and 0.9 respectively. However, some potential rules that were filtered were incorporated on expert validation. Finally the rules are stored in the rule base for classifying instances from the test dataset.

Cross-validation (CV) with ‘k’ folds is a technique whereby the dataset D, is randomly split into k folds of approximately equal size. The classifier (model) is trained and tested k times. Each time (k-1) folds are used for training and the remaining one fold is used for testing. In classification, k-fold cross-validation is the best method to use for validating and selecting a classifier [31]. Associative classifier (CBA), Decision tree classifier (C4.5), Support Vector Machine (SVM), Multi-layer perceptron classifier (MLP), Naïve Bayes classifier (NB) and k-nearest neighbour classifier (kNN) are validated. In order to make the test unbiased, cross validation is applied over the same features and same partitions. The samples in each partition remain the same when each fold is iteratively tested. However, different runs had different samples in the folds inorder to avoid the variations and perturbations that may exist due to cross validation. 10 independent runs of 10-fold cross-validation were performed. The complete results of cross validations are presented in Appendix II.

The best rules extracted by the system (based on support and confidence measures) are validated. A panel of experts were involved in the validation process. The rules and results after processing the data were presented to them. Their combined suggestions were then incorporated. Clinical judgement is far more comprehensive than pure mathematics and machine learning. There may be additional subconscious factors which are overlooked by the model. Though the development of the decision support system is automated using data mining techniques, it is not possible to represent the complete knowledge and experience of an expert [32]. Hence the expert makes minor changes based on his experience. Furthermore, the CDSS is intended to be used by clinicians in southern parts of India. Hence these adjustments will not lead to over-fitting but makes the CDSS more apt for the prevailing situation.

The classifier interacts with the rule base, and fetches the best matching rule for a query instance.
                              
                                 
                                    
                                    
                                       
                                          Input: Test data
                                       
                                       
                                          Process:
                                       
                                       
                                          Step 1:Match the attribute values of the test data (query Instance) with the rules in the rule base.
                                       
                                       
                                          Step 2:The class label of the most fitting rule that is of higher precedence is class for the test sample.
                                       
                                       
                                          Step 3:If there is no rule to match the sample (test query), the fallout rule (Default rule) [23] is used for classification.
                                       
                                       
                                          Output: Diagnostic result
                                       
                                    
                                 
                              
                           
                        

The clinical history of the patient is obtained which include name, age, gender (physical attributes) and allergic symptoms. A customised list of allergens was tested based on the lifestyle and food habits of the patients. The complete list of allergens based on the food habits and environmental conditions of the people of Chennai, South India, is presented in Table 1.

Intradermal skin tests were performed following established methods using the allergen extracts, negative controls (saline) and positive controls (histamine). The upper half of the volar surface of the forearm was selected for the test. About 0.01ml of the allergen is injected into the epidermis using sterile, disposable, plastic 1ml tuberculin syringe. Patients were asked to stop taking antihistamines and anti-allergic drugs and medications. 
                     Table 2 lists the medication to be avoided before allergy testing. Consecutive readings, on an hourly basis, were taken. A positive reaction is depicted by a wheal and a flare reaction [33]. A negative response (NR) to a skin test usually indicates that the patient is not sensitive to that allergen.

Intradermal Skin Test (IDST) data were collected from 872 patients who visited the Good Samaritan Kilpauk Lab and Allergy Testing Centre, Chennai, Tamilnadu, India during October and December 2012, March and April 2013. The patients were referred by ENT Surgeons and general physicians because of nasal problems or other plausible allergic symptoms. 413 males and 459 females, of all age groups, were included in the study.

The Association Rule based classification approach used in this framework is compared with other classification approaches namely, decision tree induction approach (C4.5) [34], Probabilistic approach (Naive Bayes classifier) [23], Neural Network Approach (Multi-layer Perceptron) [35], Distance based approach (k Nearest Neighbour) [36] and Support Vector Machines [37]. Classifiers are the core of a decision support system. The choice of a classifier depends on the need and purpose of the classifier for that domain of application. In allergy diagnosis, where reasoning is important, the experts and the clinicians preferred the rule base approach as it is simple and understandable. Furthermore rule based classification approaches are easier to validate when compared to neural networks and support vector machines. The classification approaches are evaluated by 10×10-fold cross-validation using WEKA workbench with default settings [38]. Furthermore the diagnostic performance of junior clinicians was accessed in the absence of the expert. A set of test samples (test data) were given to the junior clinicians. They manually analysed the results of the IDST data and diagnosed the presence or absence of Allergic Rhinitis. The CDSS was also tested using the test data and the performance was evaluated. The complete results of the experiment and justifications are presented in the following section.

@&#EXPERIMENTAL RESULTS@&#

In this work four performance evaluation measures were used. The four measures namely, Precision, Sensitivity and Specificity and Accuracy differ in their evaluation focus. Precision evaluates the agreement of the class label with the positive labels predicted by the classifier. Sensitivity is used to evaluate the effectiveness of a classifier to identify positive labels whereas specificity evaluates how effectively a classifier identifies negative labels. Accuracy evaluates the overall classification efficiency of the classifier.
                        
                           (4)
                           
                              Precision
                              =
                              
                                 
                                    Samples
                                    
                                    correctly
                                    
                                    classified
                                    
                                    as
                                    
                                    positive
                                    
                                 
                                 
                                    Total
                                    
                                    samples
                                    
                                    classified
                                    
                                    as
                                    
                                    positive
                                 
                              
                              
                           
                        
                     
                     
                        
                           (5)
                           
                              Sensitivity
                              
                              =
                              
                                 
                                    Samples
                                    
                                    correctly
                                    
                                    classified
                                    
                                    as
                                    
                                    positive
                                 
                                 
                                    Total
                                    
                                    positive
                                    
                                    samples
                                    
                                    in
                                    
                                    the
                                    
                                    test
                                    
                                    dataset
                                 
                              
                           
                        
                     
                     
                        
                           (6)
                           
                              Specificity
                              =
                              
                                 
                                    Samples
                                    
                                    correctly
                                    
                                    classified
                                    
                                    as
                                    
                                    negative
                                 
                                 
                                    Total
                                    
                                    negative
                                    
                                    samples
                                    
                                    in
                                    
                                    the
                                    
                                    test
                                    
                                    dataset
                                 
                              
                           
                        
                     
                     
                        
                           (7)
                           
                              Accuracy
                              =
                              
                                 
                                    Samples
                                    
                                    correctly
                                    
                                    classified
                                 
                                 
                                    Total
                                    
                                    samples
                                    
                                    classified
                                 
                              
                              
                           
                        
                     
                  


                     
                     Table 3 shows the list of features selected based on correlation analysis, Information Gain (IG) and expert validation. 
                     Table 4 shows the performance of the different classifiers. The classifiers were chosen based on their approaches used for building the classification model. 10×10-fold Cross-validation was performed to select a suitable classifier. 
                     Table 5 shows the performance of the CDSS based on feature set used and 
                     Table 6 shows the performance of the CDSS before and after oversampling the borderline minority samples.


                     
                     Table 7 presents the performance of three junior clinicians in the absence of an expert. Each clinician was asked to analyse and diagnose a set of samples (test data) manually based on the IDST results. The average classification accuracy achieved by the clinicians is 58.2%.

The clinical relevance of the clinical decision support system was validated and compared with the score for allergic rhinitis (SFAR) [21]. The scoring criterion is presented in 
                     Table 8. On a scale of 16, if a sample has a score ≥7, then it is classified as Allergic Rhinitis positive. The SFAR score based classification approach achieves an accuracy of 84.28%. To evaluate the performance and clinical relevance of this work, the trained CDSS is tested with the raw IDST test data. From the results presented in 
                     Table 9 it can be inferred that the CDSS without expert validation performs better than junior clinicians and the SFAR based diagnosis.

Data reduction and data sampling techniques were used in the preprocessing subsystem. Feature selection is used to obtain an optimal reduced feature set. In feature selection, it can be observed that the expert has made slight alterations in the feature set to make it more relevant. For example, the feature ‘Family History’ is important in determining allergic disorders, but it was omitted by the mathematical reduction approaches. The initial set of features (allergens) used in this work was framed by the panel of experts at the allergy centre. Tests are continually performed at the centre for more than four decades and the allergens are also revised based on the people׳s present food habits and environmental conditions. For example, food items such as oats, corn, mushroom, and coco are becoming prominent food items in the daily diet for the past few years, with regard to people in Chennai and nearby rural areas. Hence the list of allergens is updated on a yearly basis.

Data sampling is used to obtain a balanced dataset. Though oversampling may slightly modify the data distribution due to addition of synthetic samples, the performance of the learning algorithm (inducer) and the model (classifier) is improved. Furthermore in medical applications the samples belonging to class of interest (positive class) is usually less which makes classification less effective. From the results, it can be inferred that the sensitivity and the overall accuracy of the classifier improves on oversampling of minority samples.

In the classification subsystem, based on comparative performance of the classification approaches, the CDSS was developed using the rule based classifier (CBA). Furthermore the rule base approach presents the knowledge model in an IF-THEN format. Hence the clinicians too prefer the rule based CDSS, as the results and justifications are more understandable than probabilistic and distance based approaches.


                        
                        Figs. 2 and 3 present the contents of the rule base before and after expert validation respectively. The rule base consists of the best rules that are generated by class based association rule generation. However, it can be noticed that the antecedent of a few rules are subsets of other rules or combination of rules. For example, Rule 15 (kovaikai=0 sneeze=no⇒Rhinitis=negative) is a subset of rule 7 (kovaikai=0 running nose=no sneeze=no⇒Rhinitis=negative). Rule 17 (sneeze=no⇒Rhinitis=negative) and rule 19 (shark=0 sneeze=no⇒Rhinitis=negative) are subsets of rule 11(shark=0 sneeze=no headache=no⇒Rhinitis=negative). These rules may be removed at extra computation cost or by increasing the support and confidence thresholds, but expert validation adds more intuition and meaning to the rule base contents. It can be inferred that the modifications made by expert improves the performance of the CDSS.

Though the system framework presented in this manuscript can be adopted for the development of a DSS for a different location, the allergens (attributes) would certainly be different. Likewise, the class-based associative rule generation approach can be used for associative classification however the rules will definitely not be the same. For example, Kim et al. have developed a MAST- immunoblot assay for reliable diagnosis of allergic rhinitis [39]. They have conducted skin tests over 193 patients who visited the Yeouido St. Mary׳s Hospital, Korea. They have used 52 allergens for skin test which are different from the set of allergens that we have used.

Hence, the generic DSS framework and the methodological approach presented in the manuscript can be used for any clinical DSS however the intradermal test data, allergens and rules may completely differ, so the final DSS can only be used only in Chennai and southern parts of India for diagnosis for allergic rhinitis

@&#CONCLUSION@&#

The prevalence of Allergic Rhinitis has significantly increased in recent years. But efficient and reliable tests for diagnosis are still lacking. Avoidance of allergens may reduce the effect of allergic symptoms. The gold standard tests used for the diagnosis of allergic diseases need an expert to validate the final outcome. In order to assist junior physicians and clinicians in the process of diagnosis of allergic diseases, this work uses a computer-aided knowledge mining approach for extracting novel information from data. It was observed that experts and clinicians preferred a rule based approach for knowledge representation. The system is tailored to suit to the common allergens (inhalants, contactants and ingestants) prevalent in Chennai, South India. The clinical decision support system can be made even more adaptive by dynamic validation of the rule base and the rule-inference methods. The efficiency of the system can be further improved by introducing meta-heuristic data pre-processing techniques and by using ensemble classification approaches. Thus clinical decision making, among junior clinicians, can be enhanced where by allergic diseases can be diagnosed in a more precise manner. Early diagnosis and treatment can minimise the manifestation of symptoms in the patients whereby, the quality of life of the patients affected with Allergic Rhinitis is enhanced.

@&#ACKNOWLEDGEMENT@&#

The authors sincerely thank Dr. L. George Moses, Allergy specialist, and the clinicians at the Good Samaritan Lab Services and Allergy Testing Centre, Kilpauk, Chennai, India, for providing the data, valuable suggestions and guidelines for this work.

Supplementary data associated with this article can be found in the online version at doi:10.1016/j.compbiomed.2015.07.019.


                     
                        
                           
                              Supplementary data
                           
                           
                        
                     
                  


                     
                        
                           
                              Supplementary data
                           
                           
                        
                     
                  

@&#REFERENCES@&#


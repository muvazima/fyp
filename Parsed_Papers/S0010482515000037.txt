@&#MAIN-TITLE@&#The role of real-time in biomedical science: A meta-analysis on computational complexity, delay and speedup

@&#HIGHLIGHTS@&#


               
                  
                  
                     
                        
                           
                           Real-time: The promise of performance in real world scenarios.


                        
                        
                           
                           In this review we have discussed 120 real-time processing papers in the biomedical engineering field.


                        
                        
                           
                           The majority of papers lacks appropriate measures to support the real-time claim.


                        
                        
                           
                           An appropriate measure for theoretical claims on real-time is computational complexity.


                        
                        
                           
                           An appropriate measure for practical claims on real-time is speedup.


                        
                     
                  
               
            

@&#KEYPHRASES@&#

Real-time

Computational complexity

Speedup

Delay

Health care systems

@&#ABSTRACT@&#


               
               
                  
                     Purpose: The concept of real-time is very important, as it deals with the realizability of computer based health care systems.
                  
                     Method: In this paper we review biomedical real-time systems with a meta-analysis on computational complexity (CC), delay (
                        Δ
                     ) and speedup (S
                     
                        p
                     ).
                  
                     Results: During the review we found that, in the majority of papers, the term real-time is part of the thesis indicating that a proposed system or algorithm is practical. However, these papers were not considered for detailed scrutiny. Our detailed analysis focused on papers which support their claim of achieving real-time, with a discussion on CC or S
                     
                        p
                     . These papers were analyzed in terms of processing system used, application area (AA), CC, 
                        Δ
                     , S
                     
                        p
                     , implementation/algorithm (I/A) and competition.
                  
                     Conclusions: The results show that the ideas of parallel processing and algorithm delay were only recently introduced and journal papers focus more on Algorithm (A) development than on implementation (I). Most authors compete on big 
                        O
                      notation (O) and processing time (PT). Based on these results, we adopt the position that the concept of real-time will continue to play an important role in biomedical systems design. We predict that parallel processing considerations, such as S
                     
                        p
                      and algorithm scaling, will become more important.
               
            

@&#INTRODUCTION@&#

Biomedical engineering has to find solutions for escalating health care cost, varying availability of care, aging population and high burden of chronic disease related health behaviors. These physical problem solutions have to transform health care to improve the quality-of-life of patients and loved ones by being evidence-based, patient-centered, preventive, and proactive. Biomedical systems design is a key element to achieve these goals. Therefore, research in how to construct biomedical systems is so important. Now, biomedical science, as all sciences, is an evolutionary endeavor, where scientists and engineers collaborate and compete. The way in which these two actions are conducted shapes the direction of the research field. The advent of cheap and high performance computing has added a new direction to biomedical engineering. Biomedical scientists have started with the collaborative endeavor of constructing biomedical processing systems and they compete in terms of computational complexity (CC), speedup (S
                     
                        p
                     ) and delay (
                        Δ
                     ). However, one thing is special with the computing field: the rate of progress is incredibly high [1–4]. This enormous amount of change makes it difficult to keep a particular work relevant beyond the next hardware and software cycle. Especially, statements about real-time on specific processing systems tend to become outdated soon after implementation.

Despite the detrimental exposure to the fast changing processing machines, the concept of real-time has become extremely popular with biomedical scientists. A keyword search on the PubMed
                        1
                     
                     
                        1
                        
                           www.ncbi.nlm.nih.gov/entrez/query.fcgi accessed April 2013.
                      database for biomedical publications reveals that a total of 8477 papers mention real-time together with processing. This number itself is already astonishing, but the real surprise is the way in which this number is reached. Fig. A1 shows how the number of publications is distributed over the years from 1964 to 2013. The bar graph shows an insignificant increase in the number of research papers from 1964 to 1985. This changes around 1986,
                        2
                     
                     
                        2
                        The area of the 
                              
                                 
                                    IBM
                                 
                                 
                                    ©
                                 
                              
                            personal computer started during that time.
                      from this time onwards the number of research papers increased by about 15 every year. A second marked change in the yearly increase of research publications comes around 2004.
                        3
                     
                     
                        3
                        During that time the Internet took off.
                      From this year onwards the number of research publications increases by approximately 69. In 2013 the number of research publications jumps by 236 papers to a yearly total of 1075. There are several factors which contribute to this accelerating increase in real-time related papers. One of which is that more computing journals were indexed in PubMed. However, more fundamentally the increase of real-time related work can be linked to steep improvements in computers and computer science [5,6]. The origins of the term real-time can be traced back to the field of computer simulations, which, at that time, belonged to computer science. Until now, computer scientists hold up strict standards on what this term means [7,8]. Fundamentally, real-time just means that a system has the ability to perform a well-defined number of operations in an equally well-defined amount of time [9]. In order to support the claim that a system is real-time, we need to establish both the operations and the time available to execute these operations. Unfortunately, in the field of biomedical engineering, the meaning of real-time is blurred. This blurring is caused by a more abstract interpretation of real-time, which makes it more ambiguous. Many of these abstract interpretations reduce the concept of real-time to mean that asystem or an algorithm is implementable and that it works in practical settings. Regrettably, such statements are final, because in the process of abstraction the information, of what makes the system or the algorithm real-time, is lost. As a consequence, it is only possible to compete with such systems in an economic (price), but not in a scientific (CC, S
                     
                        p
                      or Δ) way. This is a problem, because science needs competition to push the boundaries of what can be achieved. Therefore, a careless use of the term real-time hinders scientific process by putting up a smoke screen, i.e. in many cases there is a fundamental failure to communicate assumptions and boundary conditions used to achieve the real-time property.

With this review we pay tribute to the rising importance of real-time for biomedical processing systems. We adopt the position that this importance will continue to rise in future and the term real-time will become synonymous with a high degree of practicality and realizability of proposed methods and systems. However, we recognize that there is a danger that high powered statements about real-time become empty, especially when the term is not well defined. The excessive use of the term real-time hinders the recognition of systems, which achieve real-time in the strict sense. We analyzed this problem by reviewing all papers in the PubMed database which mention real-time processing together with CC or S
                     
                        p
                     . The fact that only 134 papers, out of 8477 real-time processing related papers, mention CC or S
                     
                        p
                      indicates that many authors fail to define real-time properly. The analysis of the 134 papers focused on seven different criteria. The first of which was a survey on the application area (AA) of the biomedical real-time processing system. The second criteria classified the work into either implementation (I) or algorithm (A). In general, I is more practical and A is more theoretical. The considerations on implementation/algorithm (I/A) impact on criteria three, the processing system used. Analysis criteria four to six were focused on CC, Δ and S
                     
                        p
                     . The final analysis rubric was concerned with competition. This criterion indicates whether or not the authors compete on specific real-time results either with their realizations of foreign work or with other published results. We present the analysis results in one table and four bar graphs. The results reflect the diversity of the term real-time processing in the biomedical domain. We found that it is used to describe work that ranges from very theoretical algorithm development all the way to practical system implementations on specific hardware and software environments. Furthermore, we detected that the ideas of parallel processing were not reflected sufficiently in theoretical work. Developing algorithms for parallel processing systems has great potential to speedup the processing time (
                        PT
                     ). This needs further exploration, so that biomedical engineering stays on track to achieve preventive and proactive health care systems which serve patients in real-time.

The review is organized as follows: the next section introduces the methods which were used to analyze real-time aspects of biomedical processing systems. Section 3 presents the review results. The discussion, in Section 4, focuses on the background of the review methodology and on result interpretation. The paper concludes with Section 5.

@&#METHODS@&#


                     Fig. A2 illustrates the layout of the review procedure. All keyword searches were carried out on the PubMed database. This information resource is specifically designed for biomedical engineering. On the their web-page, PubMed claims that “PubMed comprises more than 24 million citations for biomedical literature from MEDLINE, life science journals, and online books”. Hence, by using this resource, we have focused our search to the biomedical area. As a consequence, the subsequent search queries do not include specific references to biomedical engineering.

Our initial keyword search was ‘‘real-time AND processing’’. This search resulted in 8477 hits. In two subsequent keyword searches, within the results, one for ‘‘computational complexity’’ and the other one for speedup, we found 112 and 39 papers, respectively. These 136 papers were filtered by removing duplicates and papers which were not concerned with medical applications. The remaining 134 papers were subjected to a meta-analysis.

The text below describes the individual steps of this meta-analysis. We start with the AA, because this sets the real-time aspect into perspective with the goal of the work. This relationship is further explored by categorizing the work in practical (I) or theoretical (A) design. Once the nature of the work is established, we move on to discuss the processing system which was used to realize the work. Having analyzed the processing system, we are able to establish performance measures, such as CC, S
                     
                        p
                      and Δ. Finally, these performance measures can, and indeed should, be used to compete. Therefore, we have investigated the level of competition on real-time parameters in the last analysis step of this review.

Real-time processing systems are used in problem solutions for a wide range of biomedical applications. The real-time aspect can be mission critical, as it is the case for neurological control [10], or it can be a matter of mere convenience, as it is the case for image processing [11,12] and genetic processing [13,14]. Therefore, it is important to know the application area in order to evaluate the real-time aspect of research work with a high level of credibility. We have grouped the scientific papers under review into one of the four distinct AAs:
                           
                              •
                              
                                 Signal processing (Si): Signal processing deals with both creation and analysis of signals. These signals can take the form of measurements which are obtained from time- or spatially varying physical quantities [15]. Biomedical signals contain important information about nature and status of the living systems under study. Hence, an analysis of these signals can yield useful physiological and clinical information [16]. Many advanced physiological signal processing methods have recently been introduced, especially in the nonlinear domain [16]. In her biomdedical signal processing review, Cerutti adopts the position that techniques, which assess physiological signals at different scales, will become cornerstones of personalized medicine [17].


                                 Image processing (Im): Image processing deals with algorithms which take an image as input. Examples for biomedical image processing are cardiovascular imaging, lung computed tomography (CT) analysis, magnetic resonance spectroscopic imaging nuclear and molecular imaging [18]. The algorithm outputs either an image or a set of parameters related to the image. Dhawan et al. reviewed optical imaging methods for biomedical and clinical applications [19]. He highlights the importance of image processing for disease diagnosis.


                                 Genetic analysis (GA): Genetic analysis is the overall process of studying fields of science that involve genetics and molecular biology. Wang reviewed genetic algorithms and sequencing technology [20]. The author ranks high throughput as one of the important breakthroughs that was achieved with current sequencing technology.


                                 Not in list (–): Most of the papers in this category contain theoretical algorithm development. These papers indicate that real-time can only be obtained when the CC is low. However, these papers do not cite a specific application area. For example, Fernandez-Delgado et al. [21] have used a fast parallel processing structure for calculating perceptron weights. These perceptrons can be used in a wide range of biomedical systems where the CC of a decision making algorithm needs to be low. Another AA, outside the classes discussed above, is treatment monitoring and modeling [22].

In biomedical engineering, the term real-time is associated with either A or I. The following list discusses the methods for the I/A assessment rubric:
                           
                              •
                              Algorithm (A): An algorithm is a step-by-step procedure which describes processing tasks, such as calculation, data processing, and automated reasoning [23]. For example, Karadayi et al. discussed algorithms that improve state of the art 3-D ultrasound systems [24]. Xu and Wunsch provided biomedical researchers with an overview of the status quo of clustering algorithms, in order to help them to select the most suitable methods for their own applications [25].

Implementation (I): In general, an implementation is the systematic uptake of research findings into routine practice with the clear goal to improve both effectiveness and quality of health care [26]. For this review, we adopt a more focused meaning: an implementation is the realization of a technical specification or algorithm as a program, software component, system through computer programming and deployment [27]. For example, Nizami et al. implemented a real-time artefact detection system to maximize the quality of physiologic data acquired in critical care units [28]. Schalk and Leuthardt reviewed state-of-the-art models for brain–computer interfaces to provide a vision for clinical implementations [29]. The paper by Warrick et al. examined microenvironmental screening in terms of outcomes and benefits, key elements of the screening process, challenges for implementation, and a possible role for microfluidics as the screening platform [30]. Berger et al. predicted that microchip implementations of neural networks will have a positive impact on rehabilitation [31].

Neither algorithm nor implementation was discussed (–).

In a scientific setting, the selection of a processing system is determined, to a large extent, by the thesis of the work. Hence, the processing system plays a central role when authors make a case for the real-time capabilities of their proposed work. The following list details the different processing systems which were found during this review:
                           
                              •
                              
                                 Simulation environment (SIM): A computer simulation aims to animate an abstract model of a particular system [32]. For many medical applications, these models take the form of a system which processes physiological data with an algorithm structure. Such systems have become a very useful part of biomedical engineering, because they can be used to explore and thereby gain new insights into new technology, as well as to estimate the performance of systems which are too complex for analytical solutions [33]. For example, Phan et al. created patient specific models which helped them to understand neuropsychological, behavioral, and social phenomena [34]. Trayanova et al. described a model for cardiac defibrillation, with which they studied sudden cardiac death [35]. Physiological models are of paramount importance to therapies that employ pacing of the heart, and particularly cardiac resynchronization therapy [36]. Cobelli et al. discussed models for optimal diabetes control [37]. Faust et al. discussed biomedical systems design techniques based on formal models [38].


                                 Central processing unit (CPU): A CPU carries out the instructions of a computer program by performing basic arithmetic, logic, and input/output operations [39]. Biomedical researchers and engineers use this architecture to implement practical problem solutions. Many of these systems serve as proof of concept realizations for theoretical methods. All research work in this category was based on non-real-time operating systems which shared the CPU processing power among multiple tasks. Strictly speaking, such operating systems fail to meet hard real-time criteria [40].


                                 Embedded (EMB) systems: Embedded computer systems are designed for specific control functions within a larger system, often with real-time computing constraints [41]. EMB systems constitute highly focused problem solutions. In general, such systems target practical applications, many of which involve physiological signal acquisition and control. Therefore, EMB systems have strict requirements on real-time. The trend in embedded system goes towards using operating systems, albeit real-time operating systems. These real-time operating systems give some sort of guarantee on how much processing power is given to a specific task during a time frame.


                                 Graphics processing unit (GPU): A GPU is a dedicated electronic circuit which is designed for rapid memory manipulations to accelerate the building of images in a frame buffer [42]. In general, GPUs are massively parallel processors that are connected to potentially large amounts of random-access memory (RAM) via high speed interfaces. For a limited range of biomedical applications, such processing structures are very attractive. Algorithm development for GPU systems is usually concerned with the S
                                 
                                    p
                                  that can be obtained due to the parallel nature of the processor. In most of the papers, that describe GPU systems, real-time means a lower 
                                    PT
                                 .


                                 Very large-scale integration (VLSI): VLSI is the process of creating integrated circuits by combining thousands of transistors into a single chip [43]. Fundamentally, all digital processors are VLSI structures. However, for this review, we have focused the VLSI concept such that it refers to a processing system which was specifically tailored to an algorithm. This specialization can lead to cost effective and innovative solutions for complex problems in biomedical engineering [44]. For example, VLSI technology was used in interfacing the human body to medical implants for on chip deoxyribonucleic acid (DNA) analysis [45].


                                 Not in list (–): Most papers in this category focused on pure algorithm development.

CC theory classifies computational problems in terms of their inherent difficulty, and relating those classes to each other [46]. Hence, the CC theory can be used to determine the practical limits of computerized processing.
                           
                              •
                              
                                 Big 
                                 
                                    O
                                  
                                 notation (O): The big 
                                    O
                                  notation classifies algorithms by the way they respond to changes in the input data size [47]. In general, this response is measured in terms of processing time and memory requirements. To make the measure meaningful for a wide range of algorithms, the big 
                                    O
                                  notation states growth rates: different algorithms with the same growth rate may be represented using the same big 
                                    O
                                  expression. For example, Fasano et al. claim that if the CC of an electrocardiogram pre-processing algorithm is 
                                    O
                                    (
                                    n
                                    log
                                    n
                                    )
                                 , where 
                                    n
                                  is the size of the vector to be processed, then it is suitable for real-time applications [48].


                                 Processing time (
                                    PT
                                 ): This measure reflects the human perception of the passage of time from the start to the completion of a task, therefore it is also called wall-clock time. When a computer processes a task, 
                                    PT
                                  measures the wall-clock time that elapses from the start of an operation to the end. This measure includes the time that passes due to (a) programmed (artificial) delays or (b) waiting for resources to become available. For example, Logesparan et al. put forward that the simulation time is a discriminating measure of the CC that is not specific to a particular implementation architecture [49].


                                 Hardware complexity (
                                    H
                                 ): This property expresses how many logic gates a VLSI system requires. Hardware implementations involve both computational and interface attributes, therefore these two metrics need to be taken into account when the hardware complexity is established [50,51]. For example, Mountney et al. compare hardware and software 
                                    PT
                                  for particle filtering [52]. Their results indicate that VLSI implementations improve filter throughput.

Computational complexity (CC) was not discussed (–).

In parallel computing, S
                        
                           p
                         refers to how much a parallel algorithm implementation is faster than a corresponding sequential implementation [53]. For example, Coupé et al. investigated the S
                        
                           p
                         of optimized blockwise nonlocal means filters, which are used to denoise 3-D magnetic resonance images [12].
                           
                              •
                              
                                 S
                                 
                                    p
                                  was discussed (✓).


                                 S
                                 
                                    p
                                  was not discussed (–).

This property expresses how fast the system responds. Δ is especially important for interactive systems, such as neurological [54] and prosthesis control [55]. There are three operations which contribute to Δ: data acquisition, processing and control signal output [56]. The processing time of a digital control algorithm is determined by 
                           O
                         and the processing system used [57]. Therefore, the processing time can be adjusted by selecting another processing system or an algorithm with lower 
                           O
                        . However, the data input delay cannot be adjusted so easily, because it is determined by the sampling frequency and the algorithm requirements. For example, input data filtering will always introduce a delay which cannot be adjusted by selecting a faster processing system. Therefore, input data delays are more fundamental than processing delays. Furthermore, delays can be stated independently from the underlying processing system [58]. As for this review, we established one of the following two conditions:
                           
                              
                                 
                                    •
                                 
                              
                              
                                 Δ was discussed (✓).


                                 Δ was not discussed (–).

The term real-time describes a system property which is linked to the combination of processing system and algorithm. Either a system is real-time capable or not, therefore it is impossible to rank systems in order of their real-time property. However, such competition is possible when we analyze the way in which real-time was achieved. Hence, the competition has to focus on processing system, AA, CC, Δ, S
                        
                           p
                         or I/A. The competition assessment rubric contains either a short description on how the authors compete with real-time related properties or no text (–), when the authors did not include an adequate description of competition on real-time aspects.

This section describes the analysis results for the 134 papers published. By doing so, we gain insight into the way authors applied the real-time concept. The results were obtained by examining the papers with the methods described in the previous section. Table A1 summarizes the studies on biomedical engineering evaluated based on real time properties. The table entries are ordered in terms of publication date. Section 3.1 provides statistical analysis and result discussion.

@&#ANALYSIS@&#


                        Fig. A3 indicates the number of papers which discuss a processing system that belongs to one of the six categories, outlined in Section 2.3. About 42 studies were based on the CPU processing system. This relatively large number comes as no surprise, because CPU based systems are still the most pervasive processing platforms for scientific applications. The 30 papers, which mention SIM as processing platform, indicate the large amount of theoretical work on real-time systems. In contrast, the 13 papers on EMB focus on practical applications. Many of them describe the creation of low power mobile devices. The 11 VLSI related papers also focus on practical applications where the requirements for processing speed or energy efficiency were even more stringent. The GPU applications, described in 10 papers, were also practical in nature. Much of the GPU work was concerned with parallel processing and S
                        
                           p
                        .

The bar graph in Fig. A4 lists the number of papers which focus on individual application areas. The bar graph indicates that most real-time work is concerned with physiological Si. Medical Im and GA have also real-time requirements, but the graph shows that less real-time related work is done in these areas. One reason for the significant difference between Si on one side and Im together with GA on the other side is the fact that medical image acquisition and DNA extraction methods are still offline procedures. The real-time aspects of such offline systems are predominantly measured as 
                           PT
                        . For example, a decreased 
                           PT
                         can reduce the time taken for a computer aided diagnosis [59,60]. In contrast, neurological implants [61,62] and prosthesis control [55,63] require a precise timing for feedback signals. As a result, considerations for real-time are essential for control systems to meet the requirements.

The bar graph in Fig. A5 details the number of papers which use specific terminology to discuss CC. The theoretical method of 
                           O
                         was mentioned 41 times. Eighteen of these papers also compete based on this parameter. The more practical measure of 
                           PT
                         was used 25 times. In 19 papers, this measure was used to compete. 
                           H
                         can only be measured in VLSI systems, this makes it a very specific performance measure. Therefore, competition on this parameter happens in only one paper. Almost half of the papers studied did not define CC.

The bar graph in Fig. A6 analyzes the number of papers which detail Δ, S
                        
                           p
                        , A and I. Only 10 papers discuss the Δ property. Most of these papers consider the 
                           PT
                         as being the delay, i.e. Δ is introduced as the processing time for a specific task. About 81 of the analyzed papers were concerned with theoretical algorithm development. Implementations featured in only 42 papers. Six papers discuss both algorithm design and implementation.

This concludes the in depth analysis of the papers studied. These analysis results form the background for the discussion presented in the next section.

@&#DISCUSSION@&#

We have structured this discussion into three sections. The first section details the methodology which was adopted for this review. The section provides some background on the decisions which led to the current review design. The subsequent result discussion gives further insights and interpretation on how the real-time aspect was covered in the analyzed papers. The last section is concerned with advanced real-time questions that were not raised in any of the papers under review.

The initial aim of this review was to investigate the importance of real-time for biomedical engineering. A qualitative evaluation of biomedical application areas suggests that many of these areas have real-time requirements. Hence, this topic should be very important. For example, patient care needs to be delivered in real-time, therefore all systems which target this application area need to operate in real-time as well. However, it is difficult to generalize from one or two application areas to the whole research field and qualitative reasoning does not quantify the importance. To find a measure of importance, it is necessary to have a statistical basis which represents the field under investigation well. To address this point, we have chosen keyword searches on the PubMed database to gather statistical information for this review. The method was chosen because on-line literature searches of bibliographic databases, such as PubMed, are now integral to the lives of clinicians [64]. Furthermore, even basic searches yield a huge amount of knowledge and advanced functions can focus the search results. We are aware that there is a large number of medical databases on the World Wide Web, which offer search facilities on a particular subject and the ability to analyze citations. With the decision to base our study on the PubMed database, we follow the recommendation from Falagas et al. [65]. They compared the content coverage and practical utility of Google Scholar, Web of Science, Scopus, and PubMed. From the official database Web pages, they extracted information on the range of journals covered, search facilities and restrictions, and update frequency. By analyzing this information, they found that PubMed is the best database for papers on biomedical research.

After we established PubMed, as information source for this review, we moved on to conduct keyword searches. The first keyword search was straight forward: ‘‘real-time’’ from the beginning of the records to and including 2013. This search query returned 122,059 individual papers. It is impossible to discuss all 122,059 publications which mention real-time. Furthermore, this search result includes a large number of papers that mention real-time quantitative polymerase chain reaction (PCR) [66]. This data acquisition technique has nothing to do with electronic processing. Therefore, we focused our analysis by refining the search term to “real-time AND processing”. Even after adjusting the focus, the PubMed database returned 8477 results from the beginning of the records up to and including the year 2013. Even after making the search term more specific, the number of results is too high for a detailed review. Hence, further refinement was needed. This refinement was based on the fact that real-time can only be explained by describing processing properties, such as CC, S
                        
                           p
                         or Δ. Hence, we focused the information gathering by searching for ‘‘real-time’’ and (‘‘computational complexity’’ or speedup). These focused searches resulted in 134 results. These papers were used as basis for this review.

The results show that there is more work on theoretical algorithm development (86 papers) than on practical implementations (50). This result has high information content, because it is contrary to the assumption that real-time is only relevant for implementations. Therefore, it is interesting to know the parameters used to describe the real-time performance. Thirty-one of the theoretical papers on algorithm development use the 
                           O
                         notation to describe real-time. In contrast, the 
                           O
                         measure is used in just 11 practical papers which focused on implementation.
                           4
                        
                        
                           4
                           Some of the papers discuss both I and A. Therefore, some papers belong to both sets, i.e. Chen [67] belongs to the set of theoretical papers and to the set of practical papers which focus on 
                                 O
                              . This is the reason why the accumulated cardinality (31+11=42) is larger than the number of papers that focus on 
                                 O
                               (41, as reported in Fig. A5).
                         
                        
                           PT
                         was used in 18 theoretical papers and in 12 practical papers to describe real-time.
                           5
                        
                        
                           5
                           The discrepancy between the accumulative cardinalities (18+12=19) with the reported amount of 
                                 PT
                               papers can also be explained by the fact that some of the papers are both I and A.
                         Considering the baseline, i.e. the number of algorithm and implementation papers, we found that 41.18% of the algorithm papers and only 30% of the implementation papers use 
                           O
                        . With similar considerations for the 
                           PT
                         parameter, we computed 14.8% for algorithm papers and 16.7% for implementation papers. These results suggest that the 
                           O
                         notation is more suitable for theoretical work and 
                           PT
                         is more tuned to practical implementations. Fig. A7 depicts the relationship between I/A and the technique used to describe the real-time capability.

The most fundamental definition of real-time, namely a specific amount of operations in a specific amount of time, applies to VLSI processing systems. Even with these two parameters established, there is still a trade-off between manufacturing process, silicon area, power consumption and cost. Therefore, prior to implementing a biomedical VLSI system, this trade-off needs to be resolved. Raghunathan et al. [54] came close to these considerations in their paper on implantable seizure detection systems. Six of the remaining seven VLSI papers focus on algorithm implementations in field programmable gate arrays. Such devices are normally used for prototyping and proof of concept implementations. For example, Zumsteg et al. [68] and Zviagintsev et al. [69] discuss the implementation of digital spike-sorting circuits for neural prosthetic systems on such field programmable gate arrays.

Straight forward performance measures, such as CC, S
                        
                           p
                         and Δ, are necessary for objective competition. These measures enable statements like: the “The proposed method computational complexity is at least five times lower compared to MRM
                           6
                        
                        
                           6
                           Multiple reaction monitoring.
                        -based method” [70]. However, these measures are not sufficient to assess safety and stability of biomedical real-time systems. An important aspect of safety is the level of certainty that a system is always behaving according to the specification. In other words, we require that the system state should be the result of the previous states and the current input, i.e. it should be deterministic. Determinism is important for both processing outcome and 
                           PT
                        . For example, the discussion in the previous section shows that 
                           PT
                         is more practical than 
                           O
                        . This is understandable, because in a practical setting it is important to know how much time the processor requires to complete a task. However, CC is deterministic and 
                           PT
                        , as defined in Section 2.4, is not. To illustrate this fact, we assume that CPUs and EMBs are interrupt driven systems. That means, an interrupt can come in at any time and delay or prolong the time it takes for the processor to complete a task. Matters are even worse with non real-time operating systems, because other programs may be scheduled and thereby take away processing time from a critical task, this delays or prolongs the 
                           PT
                        . Such a nondeterministic 
                           PT
                         is certainly a stability issue which might trigger a safety problem. None of the analyzed papers takes this into consideration.

All the analyzed papers lack a discussion on how to measure the quality with which the real-time property is achieved. Such a discussion is important, because the quality of biomedical real-time systems impacts on the well being and safety of patients. One objective way to assess the system quality is to analyze the design process. In general, a higher degree of formality will increase the result quality. For example, formal methods can help to avoid stable failures, such as deadlock and livelock, in parallel implementations. The absence of these stable failures improves reliability, safety and functionality of biomedical systems. Hence, formal methods enable real-time systems that work reliably in a practical setting. To improve the reliability of a real-time system by design is desirable.

Apart from formalizing the design process, it is also necessary to manage both hardware and software complexities. Complex hardware is more expensive and complex software is more difficult to maintain. Therefore, designers have to resolve the trade-off between hardware and software before implementing a real-time system. The way in which this choice and indeed all the other choices are resolved will determine the lifecycle of the physical problem solution. Considerations about finding a balance between hardware and software complexity are very practical and therefore they are driven by the current state of these domains. As a consequence, they are extremely volatile to changes and there is a real danger that the knowledge becomes outdated very fast. However, formal methods, especially in association with parallel processing, are firmly grounded with general considerations of processing machines. Therefore, establishing formal processing properties, for both algorithm design and system implementation, should be relevant beyond the next hardware and software cycle. These considerations suggest that formal and model driven biomedical system design for parallel processors is an interesting, albeit little explored, area for future research.

@&#CONCLUSIONS@&#

In this review we have discussed 134 real-time processing papers in the biomedical engineering field. These papers were found through keyword searches on the PubMed database. Out of the 134 analyzed papers only 56 compete on real-time parameters. For the remaining 78 papers, the real-time concept indicates that the proposed method or implementation is practical or implementable. During the review we found that the concept of algorithm and processing delay is very important for real-time control systems. S
                     
                        p
                      was mentioned in 35 papers and only nine of these papers competed on the S
                     
                        p
                      parameter. The relatively small number of papers that mention S
                     
                        p
                      is a problem, because the concept of parallel processing, with S
                     
                        p
                      as performance parameter, is crucial to utilize the full processing power of multicore processing systems. Hence, both implementation and algorithm development need to adopt the ideas of parallel processing and compete on parameters like S
                     
                        p
                     .

The review results support our position that real-time is an important concept for biomedical engineering. It is applicable to diverse fields like bioinformatics, biomedical imaging and physiological signal processing. One reason for this wide application area comes from the fact that the underlying processing systems become more and more capable. Hence, it is natural to move offline processing algorithms, into the real-time domain. However, there is a danger that real-time becomes an empty promise, because without a discussion on performance parameters, such as CC or S
                     
                        p
                     , it is impossible to assess how difficult it was to achieve real-time. Furthermore, it is impractical to compete on real-time itself, it is only practical to compete on properties which enable real-time, such as processing system, as well as S
                     
                        p
                      and CC of algorithms.

We predict that in future the parallel nature of processing systems will have a profound impact on algorithm development and implementation of biomedical systems. Performance parameters, like scalability, communication overhead and communication load, will become more prominent. The ideas of parallel processing and constant information transfer in pervasive communication networks will pave the way to integrated health information systems which enable personalized care. On the medical side, these systems will acquire physiological data, support diagnosis and treatment monitoring. On the infrastructure side, these systems will generate, distribute and store heath records; thereby they shape clinical real-time work flows.

None declared.


                     Fig. A1
                      shows how the number of publications is distributed over the years from 1964 to 2013. Fig. A2
                      illustrates the layout of the review procedure. Fig. A3
                      indicates the number of papers which discuss a processing system. Fig. A4
                      lists the number of papers which focus on individual application areas. Fig. A5
                      details the number of papers which use specific terminology to discuss CC. Fig. A6
                      analyzes the number of papers which detail Δ, S
                     
                        p
                     , A and I. Fig. A7
                      depicts the relationship between I/A and the technique used to describe the real-time capability.


                     Table A1
                      summarizes the studies on biomedical engineering evaluated based on real time properties.

@&#REFERENCES@&#

